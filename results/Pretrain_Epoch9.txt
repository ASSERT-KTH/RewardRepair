Traceback (most recent call last):
  File "run_pretrain.py", line 254, in <module>
    main()
  File "run_pretrain.py", line 154, in main
    model = model.to(device)
  File "/home/heye/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 612, in to
    return self._apply(convert)
  File "/home/heye/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 359, in _apply
    module._apply(fn)
  File "/home/heye/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 381, in _apply
    param_applied = fn(param)
  File "/home/heye/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 610, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA error: out of memory
Epoch: 9, Loss:  0.8585398197174072
Epoch: 9, Loss:  0.7190296053886414
Epoch: 9, Loss:  0.7854728698730469
Epoch: 9, Loss:  0.3058568835258484
Epoch: 9, Loss:  0.5960213541984558
Epoch: 9, Loss:  0.7514120936393738
Epoch: 9, Loss:  0.7825055718421936
Epoch: 9, Loss:  0.4879176616668701
Epoch: 9, Loss:  0.6796912550926208
Epoch: 9, Loss:  0.4397986829280853
Epoch: 9, Loss:  0.9562593102455139
Epoch: 9, Loss:  0.2606157064437866
Epoch: 9, Loss:  1.0024346113204956
Epoch: 9, Loss:  0.7020043730735779
Epoch: 9, Loss:  0.29993829131126404
Epoch: 9, Loss:  0.30256399512290955
Epoch: 9, Loss:  0.568053662776947
Epoch: 9, Loss:  0.5271236896514893
Epoch: 9, Loss:  0.8604751825332642
Epoch: 9, Loss:  0.8324379920959473
Epoch: 9, Loss:  0.8379385471343994
Epoch: 9, Loss:  0.3127364218235016
Epoch: 9, Loss:  0.29107195138931274
Validating on valid dataset *********: 9
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Total Loss:  33.93784265220165/205
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Completed 0
Completed 100
Completed 200
Output Files generated for review
