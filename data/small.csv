bugid	buggy	patch
elasticsearch_96a2950ab5136d3e39d33eb510de438eca0839d2	buggy:  if  (tuple.v1().getAsBoolean( "bootstrap.mlockall ",  true))  {  context:  public  class  Bootstrap  {  private  Node  node;  private  static  volatile  Thread  keepAliveThread;  private  static  volatile  CountDownLatch  keepAliveLatch;  private  void  setup(boolean  addShutdownHook,  Tuple<Settings,  Environment>  tuple)  throws  Exception  {          if  (tuple.v1().getAsBoolean( "bootstrap.mlockall ",  true))  {          if  (tuple.v1().getAsBoolean( "bootstrap.mlockall ",  false))  {  Natives.tryMlockall();  }  tuple  =  setupJmx(tuple);  NodeBuilder  nodeBuilder  =  NodeBuilder.nodeBuilder().settings(tuple.v1()).loadConfigSettings(false);  node  =  nodeBuilder.build();  if  (addShutdownHook)  {  Runtime.getRuntime().addShutdownHook(new  Thread()  {  	if  (tuple.v1().getAsBoolean( "bootstrap.mlockall ",  false))  {  
elasticsearch_5f538b1ba39f939e6b596defd333d556295777c6	buggy:  assertThat( "10 ",  is(new  ByteSizeValue(10,  ByteSizeUnit.BYTES).toString()));  context:  }  assertThat(ByteSizeUnit.BYTES.toBytes(10),  is(new  ByteSizeValue(10,  ByteSizeUnit.BYTES).bytes()));  assertThat(ByteSizeUnit.KB.toKB(10),  is(new  ByteSizeValue(10,  ByteSizeUnit.KB).kb()));  assertThat(ByteSizeUnit.MB.toMB(10),  is(new  ByteSizeValue(10,  ByteSizeUnit.MB).mb()));  assertThat(ByteSizeUnit.GB.toGB(10),  is(new  ByteSizeValue(10,  ByteSizeUnit.GB).gb()));  }          assertThat( "10 ",  is(new  ByteSizeValue(10,  ByteSizeUnit.BYTES).toString()));          assertThat( "10b ",  is(new  ByteSizeValue(10,  ByteSizeUnit.BYTES).toString()));  assertThat( "1.5kb ",  is(new  ByteSizeValue((long)  (1024  *  1.5),  ByteSizeUnit.BYTES).toString()));  assertThat( "1.5mb ",  is(new  ByteSizeValue((long)  (1024  *  1.5),  ByteSizeUnit.KB).toString()));  assertThat( "1.5gb ",  is(new  ByteSizeValue((long)  (1024  *  1.5),  ByteSizeUnit.MB).toString()));  assertThat( "1536gb ",  is(new  ByteSizeValue((long)  (1024  *  1.5),  ByteSizeUnit.GB).toString()));  }  }  	assertThat( "10b ",  is(new  ByteSizeValue(10,  ByteSizeUnit.BYTES).toString()));  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  public  EmptyScorer(Weight  weight)  {  super(weight);  }  public  float  score()  throws  IOException  {  return  0;  }      public  float  freq()  throws  IOException  {      public  int  freq()  throws  IOException  {  return  0;  }  public  int  docID()  {  return  NO_MORE_DOCS;  }  	public  int  freq()  throws  IOException  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Field>  versionFields  =  new  ArrayList<Field>();  context:  TokenStream  edgeNGramTokenFilter  =  new  EdgeNGramTokenFilterFactory(index,  indexSettings,  name,  settings).create(new  MockTokenizer(new  StringReader(   "foo  bar ")));  assertThat(edgeNGramTokenFilter,  instanceOf(EdgeNGramTokenFilter.class));  }  }  }  private  Version  randomVersion(Random  random)  throws  IllegalArgumentException,  IllegalAccessException  {  Field[]  declaredFields  =  Version.class.getDeclaredFields();          List<Field>  versionFields  =  new  ArrayList<Field>();          List<Field>  versionFields  =  new  ArrayList<>();  for  (Field  field  :  declaredFields)  {  if  ((field.getModifiers()  &  Modifier.STATIC)  !=  0  &&  field.getName().startsWith( "V_ ")  &&  field.getType()  ==  Version.class)  {  versionFields.add(field);  }  }  return  (Version)  versionFields.get(random.nextInt(versionFields.size())).get(Version.class);  }  	List<Field>  versionFields  =  new  ArrayList<>();  
libgdx_dde6ef4fcc094ae67666338a889eace1ec057a92	buggy:  vertices[i]  =  din.readInt();  context:  {  int[]  vertices  =  new  int[numElements];  for(  int  i  =  0;  i  <  numElements;  i++  )  vertices[i]  =  din.readInt();  mesh.setVertices(  vertices  );  }  else  {  float[]  vertices  =  new  float[numElements];  for(  int  i  =  0;  i  <  numElements;  i++  )  vertices[i]  =  din.readInt();  vertices[i]  =  din.readFloat();  mesh.setVertices(  vertices  );  }  if(  numIndices  >  0  )  {  short[]  indices  =  new  short[numIndices];  for(  int  i  =  0;  i  <  numIndices;  i++  )  indices[i]  =  din.readShort();  	vertices[i]  =  din.readFloat();  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "ranges ".equals(currentFieldName))  {  ranges  =  new  ArrayList<RangeAggregator.Range>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  double  from  =  Double.NEGATIVE_INFINITY;  String  fromAsStr  =  null;  	}  else  if  ( "lang ".equals(currentFieldName))  {  
libgdx_31b2d5da1ebdbef04c36296d92643b718917c7aa	buggy:  GL20  gl  =  Gdx.graphics.getGL20();  context:  final  Vector2  tmpV  =  new  Vector2();  final  Vector2  tmpV2  =  new  Vector2();  final  Vector2  tmpV3  =  new  Vector2();  final  Vector2  tmpV4  =  new  Vector2();  float  pathLength;  float  avg_speed;  public  void  render  ()  {  GL20  gl  =  Gdx.graphics.getGL20();  GL20  gl  =  Gdx.gl20;  gl.glClearColor(0.7f,  0.7f,  0.7f,  1);  gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  if  (wait  >  0)  wait  -=  Gdx.graphics.getDeltaTime();  else  {  t  +=  speed  *  Gdx.graphics.getDeltaTime();  zt  +=  zspeed  *  Gdx.graphics.getDeltaTime();  	GL20  gl  =  Gdx.gl20;  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(10).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(10));  for  (int  i  =  0;  i  <  routingTable.index( "test ").shards().size();  i++)  {  assertThat(routingTable.index( "test ").shard(i).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(i).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_942b427940f8dbc3695e391e2912969ded5625d8	buggy:  mdBuilder.put(indexMetaData);  context:  MetaData.Builder  mdBuilder  =  newMetaDataBuilder();  if  (request.filteredIndices().length  ==  0  &&  request.filteredIndexTemplates().length  ==  0)  {  mdBuilder.metaData(currentState.metaData());  }  if  (request.filteredIndices().length  >  0)  {  String[]  indices  =  currentState.metaData().concreteIndicesIgnoreMissing(request.filteredIndices());  for  (String  filteredIndex  :  indices)  {  IndexMetaData  indexMetaData  =  currentState.metaData().index(filteredIndex);  if  (indexMetaData  !=  null)  {                          mdBuilder.put(indexMetaData);                          mdBuilder.put(indexMetaData,  false);  }  }  }  if  (request.filteredIndexTemplates().length  >  0)  {  for  (String  templateName  :  request.filteredIndexTemplates())  {  IndexTemplateMetaData  indexTemplateMetaData  =  currentState.metaData().templates().get(templateName);  if  (indexTemplateMetaData  !=  null)  {  	mdBuilder.put(indexMetaData,  false);  
libgdx_316757eba548254ac303543fa185b5860230e98d	buggy:  android.linkerFlags  +=   "  -lGLESv2 ";  context:  win32home.cppExcludes  =  excludeCpp;  BuildTarget  win32  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32.cppExcludes  =  excludeCpp;  BuildTarget  win64  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  true);  win64.cppExcludes  =  excludeCpp;  BuildTarget  lin32  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  false);  lin32.cppExcludes  =  excludeCpp;  BuildTarget  lin64  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  true);  lin64.cppExcludes  =  excludeCpp;  BuildTarget  android  =  BuildTarget.newDefaultTarget(TargetOs.Android,  false);  android.linkerFlags  +=   "  -lGLESv2 ";  android.linkerFlags  +=   "  -lGLESv2  -llog ";  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  mac.cppExcludes  =  excludeCpp;  BuildTarget  ios  =  BuildTarget.newDefaultTarget(TargetOs.IOS,  false);  ios.cppExcludes  =  excludeCpp;  new  AntScriptGenerator().generate(new  BuildConfig( "gdx ",   "../target/native ",  LIBS_DIR,  JNI_DIR),  mac,  win32home,  win32,  win64,  lin32,  lin64,  android,  ios);  	android.linkerFlags  +=   "  -lGLESv2  -llog ";  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  fieldMapper.indexName();  context:  JsonToken  token  =  jp.nextToken();  assert  token  ==  JsonToken.FIELD_NAME;  String  fieldName  =  jp.getCurrentName();  FieldMapper  fieldMapper  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldMapper  =  smartNameFieldMappers.mapper();                  fieldName  =  fieldMapper.indexName();                  fieldName  =  fieldMapper.names().indexName();  }  }  token  =  jp.nextToken();  if  (token  !=  JsonToken.START_ARRAY)  {  throw  new  QueryParsingException(index,   "Terms  filter  must  define  the  terms  to  filter  on  as  an  array ");  }  	fieldName  =  fieldMapper.names().indexName();  
elasticsearch_bbd63f0ffef611842315044f4275a341ce7110cf	buggy:  assertThat(Lucene.count(searcher,  new  DeletionAwareConstantScoreQuery(cachedFilter,  true),  -1),  equalTo(0l));  context:  assertThat(Lucene.count(searcher,  new  FilteredQuery(new  MatchAllDocsQuery(),  filterCache.cache(new  TermFilter(new  Term( "id ",   "1 ")))),  -1),  equalTo(1l));  indexWriter.deleteDocuments(new  Term( "id ",   "1 "));  reader  =  refreshReader(reader);  searcher  =  new  IndexSearcher(reader);  TermFilter  filter  =  new  TermFilter(new  Term( "id ",   "1 "));  Filter  cachedFilter  =  filterCache.cache(filter);  long  constantScoreCount  =  filter  ==  cachedFilter  ?  0  :  1;  assertThat(Lucene.count(searcher,  new  ConstantScoreQuery(cachedFilter),  -1),  equalTo(constantScoreCount));          assertThat(Lucene.count(searcher,  new  DeletionAwareConstantScoreQuery(cachedFilter,  true),  -1),  equalTo(0l));          assertThat(Lucene.count(searcher,  new  DeletionAwareConstantScoreQuery(cachedFilter),  -1),  equalTo(0l));  assertThat(Lucene.count(searcher,  new  FilteredQuery(new  MatchAllDocsQuery(),  cachedFilter),  -1),  equalTo(0l));  indexWriter.close();  }  private  IndexReader  refreshReader(IndexReader  reader)  throws  IOException  {  IndexReader  oldReader  =  reader;  reader  =  reader.reopen();  	assertThat(Lucene.count(searcher,  new  DeletionAwareConstantScoreQuery(cachedFilter),  -1),  equalTo(0l));  
elasticsearch_8223418b049c6ce4daed46544db8eb8b969f3aa7	buggy:  pipeline.addLast( "decoder ",  new  MemcachedDecoder());  context:  serverBootstrap  =  new  ServerBootstrap(new  NioServerSocketChannelFactory(  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcached_server_boss ")),  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcached_server_worker ")),  workerCount));  }  ChannelPipelineFactory  pipelineFactory  =  new  ChannelPipelineFactory()  {  ChannelPipeline  pipeline  =  Channels.pipeline();  pipeline.addLast( "openChannels ",  serverOpenChannels);                  pipeline.addLast( "decoder ",  new  MemcachedDecoder());                  pipeline.addLast( "decoder ",  new  MemcachedDecoder(logger));  pipeline.addLast( "dispatcher ",  new  MemcachedDispatcher(restController));  return  pipeline;  }  };  serverBootstrap.setPipelineFactory(pipelineFactory);  if  (tcpNoDelay  !=  null)  {  	pipeline.addLast( "decoder ",  new  MemcachedDecoder(logger));  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(min( "min ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  Min  min  =  bucket.getAggregations().get( "min ");  assertThat(min,  notNullValue());  assertThat(min.getName(),  equalTo( "min "));  assertThat(min.getValue(),  equalTo(Double.POSITIVE_INFINITY));  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  v.release();  context:  threads[i]  =  new  Thread()  {  public  void  run()  {  try  {  latch.await();  }  catch  (InterruptedException  e)  {  return;  }  while  (recycles.getAndDecrement()  >  0)  {  final  Recycler.V<?>  v  =  recycler.obtain();                          v.release();                          v.close();  }  }  };  }  for  (Thread  thread  :  threads)  {  thread.start();  }  final  long  start  =  System.nanoTime();  	v.close();  
elasticsearch_e1aa91dc81e4a489c3856e3cfda1a951c7f6535d	buggy:  HashSet<DiscoveryNode>  newNodes  =  new  HashSet<DiscoveryNode>();  context:  }  });  }  try  {  latch.await();  }  catch  (InterruptedException  e)  {  return;  }              HashSet<DiscoveryNode>  newNodes  =  new  HashSet<DiscoveryNode>();              HashSet<DiscoveryNode>  newNodes  =  new  HashSet<DiscoveryNode>(listedNodes);  for  (ClusterStateResponse  clusterStateResponse  :  clusterStateResponses)  {  if  (!ignoreClusterName  &&  !clusterName.equals(clusterStateResponse.getClusterName()))  {  }  for  (DiscoveryNode  node  :  clusterStateResponse.getState().nodes().dataNodes().values())  {  newNodes.add(node);  }  }  	HashSet<DiscoveryNode>  newNodes  =  new  HashSet<DiscoveryNode>(listedNodes);  
elasticsearch_024df242dc70a7e1b96a4a5afd61805fbd908d6c	buggy:  assertFalse( "backward  compatibility  tests  must  run  in  network  mode.  You  probably  have  a  system  property  overriding  the  test  settings ",  context:  .put(TransportModule.TRANSPORT_TYPE_KEY,  NettyTransport.class)  //  run  same  transport  /  disco  as  external  .put(DiscoveryModule.DISCOVERY_TYPE_KEY,  ZenDiscoveryModule.class)  .put( "node.mode ",   "network ")  //  we  need  network  mode  for  this  .put( "gateway.type ",   "local ")  //  we  require  local  gateway  to  mimic  upgrades  of  nodes  .put( "discovery.type ",   "zen ")  //  zen  is  needed  since  we  start  external  nodes  .put(TransportModule.TRANSPORT_SERVICE_TYPE_KEY,  TransportService.class.getName())  .build();  Tuple<Settings,  Environment>  finalSettings  =  InternalSettingsPreparer.prepareSettings(settings,  true);          assertFalse( "backward  compatibility  tests  must  run  in  network  mode.  You  probably  have  a  system  property  overriding  the  test  settings ",          assertFalse( "backward  compatibility  tests  must  run  in  network  mode.  You  probably  have  a  system  property  overriding  the  test  settings. ",  DiscoveryNode.localNode(finalSettings.v1()));  return  settings;  }  public  void  assertAllShardsOnNodes(String  index,  String  pattern)  {  ClusterState  clusterState  =  client().admin().cluster().prepareState().execute().actionGet().getState();  for  (IndexRoutingTable  indexRoutingTable  :  clusterState.routingTable())  {  for  (IndexShardRoutingTable  indexShardRoutingTable  :  indexRoutingTable)  {  	assertFalse( "backward  compatibility  tests  must  run  in  network  mode.  You  probably  have  a  system  property  overriding  the  test  settings. ",  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  Query  facetQuery  =  indexQueryParser.parse(jp,  context.source());  context:  }  }  else  {  jp.nextToken();  //  move  to  START_OBJECT  jp.nextToken();  //  move  to  FIELD_NAME  String  facetType  =  jp.getCurrentName();  if  ( "query ".equals(facetType))  {  JsonIndexQueryParser  indexQueryParser  =  (JsonIndexQueryParser)  context.queryParser();                          Query  facetQuery  =  indexQueryParser.parse(jp,  context.source());                          Query  facetQuery  =  indexQueryParser.parse(jp);  if  (queryFacets  ==  null)  {  queryFacets  =  Lists.newArrayListWithCapacity(2);  }  queryFacets.add(new  SearchContextFacets.QueryFacet(topLevelFieldName,  facetQuery));  }  else  {  throw  new  SearchParseException(context,   "Unsupported  facet  type  [ "  +  facetType  +   "]  for  facet  name  [ "  +  topLevelFieldName  +   "] ");  }  	Query  facetQuery  =  indexQueryParser.parse(jp);  
elasticsearch_41c59c6b4993313772b5a5d8e9146e15ef250847	buggy:  CombineFunction  combineFunction  =  null;  context:  Query  query  =  null;  float  boost  =  1.0f;  FiltersFunctionScoreQuery.ScoreMode  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Multiply;  ArrayList<FiltersFunctionScoreQuery.FilterFunction>  filterFunctions  =  new  ArrayList<FiltersFunctionScoreQuery.FilterFunction>();  float  maxBoost  =  Float.MAX_VALUE;  String  currentFieldName  =  null;  XContentParser.Token  token;          CombineFunction  combineFunction  =  null;          CombineFunction  combineFunction  =  CombineFunction.MULT;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  ( "query ".equals(currentFieldName))  {  query  =  parseContext.parseInnerQuery();  }  else  if  ( "filter ".equals(currentFieldName))  {  query  =  new  XConstantScoreQuery(parseContext.parseInnerFilter());  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(currentFieldName))  {  	CombineFunction  combineFunction  =  CombineFunction.MULT;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(extendedStats( "stats ")))  context:  sumOfSqrs  +=  val  *  val;  }  return  (sumOfSqrs  -  ((sum  *  sum)  /  vals.length))  /  vals.length;  }  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(extendedStats( "stats ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(extendedStats( "stats ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(extendedStats( "stats ")))  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  logger.trace( "[{}]  executed  [{}]/[{}],  took  [{}] ",  executionId,  request.numberOfActions(),  new  ByteSizeValue(request.estimatedSizeInBytes()),  response.took());  context:  public  void  beforeBulk(long  executionId,  BulkRequest  request)  {  if  (logger.isTraceEnabled())  {  }  }  public  void  afterBulk(long  executionId,  BulkRequest  request,  BulkResponse  response)  {  if  (logger.isTraceEnabled())  {                  logger.trace( "[{}]  executed  [{}]/[{}],  took  [{}] ",  executionId,  request.numberOfActions(),  new  ByteSizeValue(request.estimatedSizeInBytes()),  response.took());                  logger.trace( "[{}]  executed  [{}]/[{}],  took  [{}] ",  executionId,  request.numberOfActions(),  new  ByteSizeValue(request.estimatedSizeInBytes()),  response.getTook());  }  if  (response.hasFailures())  {  }  }  public  void  afterBulk(long  executionId,  BulkRequest  request,  Throwable  e)  {  	logger.trace( "[{}]  executed    [{}]/[{}],  took  [{}] ",  executionId,  request.numberOfActions(),  new  ByteSizeValue(request.estimatedSizeInBytes()),  response.getTook());  
libgdx_1336ba17a2a983eb333c337290d8f2e5cea73008	buggy:  lightManager.applyAmbient(shader);  context:  flush();  }  private  void  flush()  {  drawing  =  false;  lightManager.applyAmbient(shader);  lightManager.applyGlobalLights(shader);  for  (int  i  =  0;  i  <  stillModelQueue.size;  i++)  {  final  StillModelInstance  instance  =  stillModelInstances.items[i];  	lightManager.applyGlobalLights(shader);  
elasticsearch_0e2d33b4a446af033db48284737a62b9cc8c99bb	buggy:  return  new  InternalTopHits(name,  topHitsContext.size(),  topHitsContext.sort(),  Lucene.EMPTY_TOP_DOCS,  InternalSearchHits.empty());  context:  FieldDoc  fieldDoc  =  (FieldDoc)  scoreDoc;  searchHitFields.sortValues(fieldDoc.fields);  }  }  return  new  InternalTopHits(name,  topHitsContext.from(),  topHitsContext.size(),  topHitsContext.sort(),  topDocs,  fetchResult.hits());  }  }  public  InternalAggregation  buildEmptyAggregation()  {          return  new  InternalTopHits(name,  topHitsContext.size(),  topHitsContext.sort(),  Lucene.EMPTY_TOP_DOCS,  InternalSearchHits.empty());          return  new  InternalTopHits(name,  topHitsContext.from(),  topHitsContext.size(),  topHitsContext.sort(),  Lucene.EMPTY_TOP_DOCS,  InternalSearchHits.empty());  }  public  void  collect(int  docId,  long  bucketOrdinal)  throws  IOException  {  TopDocsCollector  topDocsCollector  =  topDocsCollectors.get(bucketOrdinal);  if  (topDocsCollector  ==  null)  {  Sort  sort  =  topHitsContext.sort();  int  topN  =  topHitsContext.from()  +  topHitsContext.size();  	return  new  InternalTopHits(name,  topHitsContext.from(),  topHitsContext.size(),  topHitsContext.sort(),  Lucene.EMPTY_TOP_DOCS,  InternalSearchHits.empty());  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  collector  =  Lucene.wrapTimeLimitingCollector(collector,  searchContext.timeoutInMillis());  context:  }  public  void  search(List<AtomicReaderContext>  leaves,  Weight  weight,  Collector  collector)  throws  IOException  {  final  boolean  timeoutSet  =  searchContext.timeoutInMillis()  !=  -1;  final  boolean  terminateAfterSet  =  searchContext.terminateAfter()  !=  SearchContext.DEFAULT_TERMINATE_AFTER;  if  (timeoutSet)  {              collector  =  Lucene.wrapTimeLimitingCollector(collector,  searchContext.timeoutInMillis());              collector  =  Lucene.wrapTimeLimitingCollector(collector,  searchContext.timeEstimateCounter(),  searchContext.timeoutInMillis());  }  if  (terminateAfterSet)  {  collector  =  Lucene.wrapCountBasedEarlyTerminatingCollector(collector,  searchContext.terminateAfter());  }  if  (currentState  ==  Stage.MAIN_QUERY)  {  if  (searchContext.parsedPostFilter()  !=  null)  {  	collector  =  Lucene.wrapTimeLimitingCollector(collector,  searchContext.timeEstimateCounter(),  searchContext.timeoutInMillis());  
elasticsearch_f25eebb249c6c41f1db8835470ef51481dd4a491	buggy:  stream.cleanup();  context:  }  else  if  (streamType.equals( "firehose "))  {  stream.firehose(0);  }  else  {  stream.sample();  }  }  if  (stream  !=  null)  {              stream.cleanup();              stream.cleanUp();  stream.shutdown();  }  }  private  class  StatusHandler  extends  StatusAdapter  {  if  (logger.isTraceEnabled())  {  	stream.cleanUp();  
elasticsearch_9539661d40d5eb219f68e1298feddb9359b4a14d	buggy:  public  Facet  reduce(String  name,  List<Facet>  facets)  {  context:  }  return  other;  }  public  long  getOtherCount()  {  return  otherCount();  }      public  Facet  reduce(String  name,  List<Facet>  facets)  {      public  Facet  reduce(List<Facet>  facets)  {  if  (facets.size()  ==  1)  {  return  facets.get(0);  }  InternalDoubleTermsFacet  first  =  (InternalDoubleTermsFacet)  facets.get(0);  TDoubleIntHashMap  aggregated  =  CacheRecycler.popDoubleIntMap();  long  missing  =  0;  long  total  =  0;  for  (Facet  facet  :  facets)  {  	public  Facet  reduce(List<Facet>  facets)  {  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  reader  =  new  SlowCompositeReaderWrapper(DirectoryReader.open(directory));  context:  directory  =  new  RAMDirectory();  IndexWriter  writer  =  new  IndexWriter(directory,  new  IndexWriterConfig(Lucene.VERSION,  new  WhitespaceAnalyzer(Lucene.VERSION)));  addDoc(writer,   "admin  guest ",   "010 ",   "20040101 ",   "Y ");  addDoc(writer,   "guest ",   "020 ",   "20040101 ",   "Y ");  addDoc(writer,   "guest ",   "020 ",   "20050101 ",   "Y ");  addDoc(writer,   "admin ",   "020 ",   "20050101 ",   "Maybe ");  addDoc(writer,   "admin  guest ",   "030 ",   "20050101 ",   "N ");  writer.close();          reader  =  new  SlowCompositeReaderWrapper(DirectoryReader.open(directory));          reader  =  SlowCompositeReaderWrapper.wrap(DirectoryReader.open(directory));  writer.close();  }  public  void  tearDown()  throws  Exception  {  reader.close();  directory.close();  }  	reader  =  SlowCompositeReaderWrapper.wrap(DirectoryReader.open(directory));  
elasticsearch_941ffe0bf90ac285057a241053e709f7b79df217	buggy:  table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  context:  table.addCell(info  ==  null  ?  null  :  info.getJvm().version());  table.addCell(stats  ==  null  ?  null  :  stats.getFs()  ==  null  ?  null  :  stats.getFs().total().getAvailable());  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().getMem().getHeapUsedPrecent());  table.addCell(info  ==  null  ?  null  :  info.getJvm().getMem().getHeapMax());  table.addCell(stats  ==  null  ?  null  :  stats.getOs().mem()  ==  null  ?  null  :  stats.getOs().mem().usedPercent());  table.addCell(info  ==  null  ?  null  :  info.getOs().mem()  ==  null  ?  null  :  info.getOs().mem().total());  //  sigar  fails  to  load  in  IntelliJ  table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  String.format(Locale.ROOT,   "%.2f ",  stats.getOs().getLoadAverage()[0]));  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().uptime());  table.addCell(node.clientNode()  ?   "c "  :  node.dataNode()  ?   "d "  :   "- ");              table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");              table.addCell(masterId  ==  null  ?   "x "  :  masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  table.addCell(node.name());  table.addCell(stats  ==  null  ?  null  :  stats.getIndices().getCompletion().getSize());  table.addCell(stats  ==  null  ?  null  :  stats.getIndices().getFieldData().getMemorySize());  table.addCell(stats  ==  null  ?  null  :  stats.getIndices().getFieldData().getEvictions());  table.addCell(stats  ==  null  ?  null  :  stats.getIndices().getFilterCache().getMemorySize());  	table.addCell(masterId  ==  null  ?   "x "  :  masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalAggregations>  subAggregationsList  =  new  ArrayList<InternalAggregations>(aggregations.size());  context:  public  InternalAggregation  reduce(ReduceContext  reduceContext)  {  List<InternalAggregation>  aggregations  =  reduceContext.aggregations();  if  (aggregations.size()  ==  1)  {  InternalSingleBucketAggregation  reduced  =  ((InternalSingleBucketAggregation)  aggregations.get(0));  reduced.aggregations.reduce(reduceContext.bigArrays());  return  reduced;  }  InternalSingleBucketAggregation  reduced  =  null;          List<InternalAggregations>  subAggregationsList  =  new  ArrayList<InternalAggregations>(aggregations.size());          List<InternalAggregations>  subAggregationsList  =  new  ArrayList<>(aggregations.size());  for  (InternalAggregation  aggregation  :  aggregations)  {  if  (reduced  ==  null)  {  reduced  =  (InternalSingleBucketAggregation)  aggregation;  }  else  {  this.docCount  +=  ((InternalSingleBucketAggregation)  aggregation).docCount;  }  subAggregationsList.add(((InternalSingleBucketAggregation)  aggregation).aggregations);  }  	List<InternalAggregations>  subAggregationsList  =  new  ArrayList<>(aggregations.size());  
libgdx_03ea4386dd391117de2a66a4624345e699db02cf	buggy:  super.drawChildren(batch,  parentAlpha);  context:  this.fillParent  =  fillParent;  }  public  void  layout  ()  {  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  validate();  super.drawChildren(batch,  parentAlpha);  super.draw(batch,  parentAlpha);  }  }  	super.draw(batch,  parentAlpha);  
libgdx_e189d0d6655c4e9a7719f99e6d0e47b5e5c83b35	buggy:  throw  new  GdxRuntimeException(ex);  context:  try  {  graphics.setupDisplay();  listener.create();  listener.resize(Math.max(1,  graphics.getWidth()),  Math.max(1,  graphics.getHeight()));  start();  }  catch  (Exception  ex)  {  stopped();  exception(ex);  throw  new  GdxRuntimeException(ex);  return;  }  EventQueue.invokeLater(new  Runnable()  {  int  lastWidth  =  Math.max(1,  graphics.getWidth());  int  lastHeight  =  Math.max(1,  graphics.getHeight());  public  void  run  ()  {  if  (!running  ||  Display.isCloseRequested())  {  	return;  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON,  cachedEntry.cachedBytes());  context:  if  (parser  !=  null)  {  parser.close();  }  }  }  private  void  writeShardState(String  reason,  ShardId  shardId,  ShardStateInfo  shardStateInfo,  @Nullable  ShardStateInfo  previousStateInfo)  throws  Exception  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {              XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON,  cachedEntry.cachedBytes());              XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON,  cachedEntry.bytes());  builder.prettyPrint();  builder.startObject();  builder.field( "version ",  shardStateInfo.version);  if  (shardStateInfo.primary  !=  null)  {  builder.field( "primary ",  shardStateInfo.primary);  }  builder.endObject();  builder.flush();  	XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON,  cachedEntry.bytes());  
elasticsearch_f49f3e169aaec2a1ea46496b4c01d8427e97058c	buggy:  metaDataMappingService.putMapping(new  MetaDataMappingService.Request(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {  context:  ClusterState  clusterState  =  clusterService.state();  request.indices(clusterState.metaData().concreteIndices(request.indices()));  final  String[]  indices  =  request.indices();  final  AtomicReference<PutMappingResponse>  responseRef  =  new  AtomicReference<PutMappingResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          metaDataMappingService.putMapping(new  MetaDataMappingService.Request(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {          metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {  responseRef.set(new  PutMappingResponse(response.acknowledged()));  latch.countDown();  }  failureRef.set(t);  latch.countDown();  	metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {  
elasticsearch_daf347e67ebd152a4774edefb0f23a2428a466c0	buggy:  return  lastIndexVersion  !=  indexCommit.getVersion();  context:  this.lastIndexVersion  =  lastIndexVersion;  this.lastTranslogId  =  lastTranslogId;  this.lastTranslogLength  =  lastTranslogLength;  this.lastTotalTranslogOperations  =  lastTotalTranslogOperations;  }  public  boolean  indexChanged()  {              return  lastIndexVersion  !=  indexCommit.getVersion();              return  lastIndexVersion  !=  indexCommit.getGeneration();  }  public  boolean  newTranslogCreated()  {  return  translogSnapshot.translogId()  !=  lastTranslogId;  	return  lastIndexVersion  !=  indexCommit.getGeneration();  
elasticsearch_08d7125cd52d9eb33a6e8c27c2007193f83373ea	buggy:  clusterState  =  IndexerClusterState.Builder.readFrom(in,  settings);  context:  private  IndexerClusterState  clusterState;  private  PublishClusterStateRequest()  {  }  private  PublishClusterStateRequest(IndexerClusterState  clusterState)  {  this.clusterState  =  clusterState;  }              clusterState  =  IndexerClusterState.Builder.readFrom(in,  settings);              clusterState  =  IndexerClusterState.Builder.readFrom(in);  }  IndexerClusterState.Builder.writeTo(clusterState,  out);  }  }  private  class  PublishClusterStateRequestHandler  extends  BaseTransportRequestHandler<PublishClusterStateRequest>  {  	clusterState  =  IndexerClusterState.Builder.readFrom(in);  
elasticsearch_c165e640fc90c83be11c5753fd080ab92af37a16	buggy:  indexSettingsBuilder.put(SETTING_AUTO_EXPAND_REPLICAS,   "1-all ");  context:  if  (indexSettingsBuilder.get(SETTING_NUMBER_OF_SHARDS)  ==  null)  {  if  (request.index().equals(riverIndexName))  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS,  settings.getAsInt(SETTING_NUMBER_OF_SHARDS,  1));  }  else  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS,  settings.getAsInt(SETTING_NUMBER_OF_SHARDS,  5));  }  }  }  if  (request.index().equals(ScriptService.SCRIPT_INDEX))  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  0));                          indexSettingsBuilder.put(SETTING_AUTO_EXPAND_REPLICAS,   "1-all ");                          indexSettingsBuilder.put(SETTING_AUTO_EXPAND_REPLICAS,   "0-all ");  }  else  {  if  (indexSettingsBuilder.get(SETTING_NUMBER_OF_REPLICAS)  ==  null)  {  if  (request.index().equals(riverIndexName))  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  1));  }  else  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  1));  }  	indexSettingsBuilder.put(SETTING_AUTO_EXPAND_REPLICAS,   "0-all ");  
elasticsearch_da707b6f32e98943fa6caf3704119400cbef1c7c	buggy:  return  new  DocumentMapperParser(new  Index( "test "),  newAnalysisService(),  new  PostingsFormatService(new  Index( "test ")),  context:  public  class  MapperTestUtils  {  public  static  DocumentMapperParser  newParser()  {          return  new  DocumentMapperParser(new  Index( "test "),  newAnalysisService(),  new  PostingsFormatService(new  Index( "test ")),          return  new  DocumentMapperParser(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS,  newAnalysisService(),  new  PostingsFormatService(new  Index( "test ")),  new  DocValuesFormatService(new  Index( "test ")),  newSimilarityLookupService());  }  public  static  DocumentMapperParser  newParser(Settings  indexSettings)  {  return  new  DocumentMapperParser(new  Index( "test "),  indexSettings,  newAnalysisService(indexSettings),  new  PostingsFormatService(new  Index( "test ")),  new  DocValuesFormatService(new  Index( "test ")),  newSimilarityLookupService());  }  	return  new  DocumentMapperParser(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS,  newAnalysisService(),  new  PostingsFormatService(new  Index( "test ")),  
libgdx_c64a9d86f2a70f4e9cc4715927afadb7c96b7ba6	buggy:  renderBatch.render(lights,  instances.get(i));  context:  gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.gl.glClearColor(0,  0,  0,  0);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  Gdx.gl.glDisable(GL20.GL_CULL_FACE);  renderBatch.begin(cam);  for  (int  i  =  0;  i  <  instances.size;  i++)  {  if  (instances.get(i).model  ==  null)  Gdx.app.log( "Test ",   "Model   "+i+ "  is  null ");  else  renderBatch.render(lights,  instances.get(i));  renderBatch.render(instances.get(i),  lights);  }  renderBatch.end();  }  public  boolean  touchDown  (int  x,  int  y,  int  pointer,  int  newParam)  {  touchStartX  =  x;  touchStartY  =  y;  	renderBatch.render(instances.get(i),  lights);  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  ignoreMalformed);  context:  public  Builder  nullValue(short  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  ShortFieldMapper  build(BuilderContext  context)  {  ShortFieldMapper  fieldMapper  =  new  ShortFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,                      ignoreMalformed);                      ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	ignoreMalformed(context));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();  context:  public  void  concurrentOperationOnSameDocTest()  throws  Exception  {  assertAcked(prepareCreate( "test ")  .setSettings(settingsBuilder().put(indexSettings()).put( "index.number_of_shards ",  1)));  int  numberOfUpdates  =  100;          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  final  CountDownLatch  latch  =  new  CountDownLatch(numberOfUpdates);  for  (int  i  =  0;  i  <  numberOfUpdates;  i++)  {  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",  i).execute(new  ActionListener<IndexResponse>()  {  public  void  onResponse(IndexResponse  response)  {  latch.countDown();  }  	final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  true);  context:  }  public  void  render  ()  {  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
elasticsearch_bc393b6d79bb04e8911459983b1aec1e75ab3768	buggy:  .setMinScore(2)  //  Score  needs  to  be  above  2.0!  context:  client().prepareIndex( "test ",   "parent ",   "p1 ").setSource( "p_field ",   "p_value1 ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c1 ").setSource( "c_field ",   "x ").setParent( "p1 ").execute().actionGet();  client().prepareIndex( "test ",   "parent ",   "p2 ").setSource( "p_field ",   "p_value2 ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c3 ").setSource( "c_field ",   "x ").setParent( "p2 ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c4 ").setSource( "c_field ",   "x ").setParent( "p2 ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c5 ").setSource( "c_field ",   "x ").setParent( "p2 ").execute().actionGet();  refresh();  SearchResponse  searchResponse  =  client().prepareSearch( "test ").setQuery(hasChildQuery( "child ",  matchAllQuery()).scoreType( "sum "))                  .setMinScore(2)  //  Score  needs  to  be  above  2.0!                  .setMinScore(3)  //  Score  needs  to  be  3  or  above!  .execute().actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getFailedShards(),  equalTo(0));  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  assertThat(searchResponse.getHits().getAt(0).id(),  equalTo( "p2 "));  assertThat(searchResponse.getHits().getAt(0).score(),  equalTo(3.0f));  }  	.setMinScore(3)  //  Score  needs  to  be  3  or  above!  
elasticsearch_3afeac5b125af71592d185b142cd816c95a3c579	buggy:  logger.debug( " ");  context:  parser  =  XContentHelper.createParser(data,  0,  data.length);  metaData  =  MetaData.Builder.fromXContent(parser);  highestVersion  =  version;  }  finally  {  if  (parser  !=  null)  {  parser.close();  }  }  }  }  catch  (Exception  e)  {                      logger.debug( " ");                      logger.debug( "failed  to  load  global  state  from  [{}] ",  e,  stateFile.getAbsolutePath());  }  }  }  return  metaData;  }  private  void  pre019Upgrade()  throws  Exception  {  	logger.debug( "failed  to  load  global  state  from  [{}] ",  e,  stateFile.getAbsolutePath());  
libgdx_43419c1f2f50604ce39a5a11ccf72593b7b1abac	buggy:  if  (areVerticesClockwise(vertices,  0,  vertices.length))  {  context:  public  ShortArray  computeTriangles  (float[]  vertices,  int  offset,  int  count)  {  this.vertices  =  vertices;  int  vertexCount  =  this.vertexCount  =  count  /  2;  ShortArray  indicesArray  =  this.indicesArray;  indicesArray.clear();  indicesArray.ensureCapacity(vertexCount);  indicesArray.size  =  vertexCount;  short[]  indices  =  this.indices  =  indicesArray.items;  if  (areVerticesClockwise(vertices,  0,  vertices.length))  {  if  (areVerticesClockwise(vertices,  offset,  count))  {  for  (short  i  =  0;  i  <  vertexCount;  i++)  indices[i]  =  i;  }  else  {  for  (int  i  =  0,  n  =  vertexCount  -  1;  i  <  vertexCount;  i++)  indices[i]  =  (short)(n  -  i);  //  Reversed.  }  IntArray  vertexTypes  =  this.vertexTypes;  	if  (areVerticesClockwise(vertices,  offset,  count))  {  
libgdx_50504826391f4db99dddd0d14dc9eaefd7916f31	buggy:  ids[i]  =  (int)Long.parseLong(array[i]);  context:  static  int[]  getTileIds  (Element  element,  int  width,  int  height)  {  Element  data  =  element.getChildByName( "data ");  String  encoding  =  data.getAttribute( "encoding ",  null);  if  (encoding  ==  null)  {  //  no  'encoding'  attribute  means  that  the  encoding  is  XML  throw  new  GdxRuntimeException( "Unsupported  encoding  (XML)  for  TMX  Layer  Data ");  }  int[]  ids  =  new  int[width  *  height];  if  (encoding.equals( "csv "))  {  String[]  array  =  data.getText().split( ", ");  for  (int  i  =  0;  i  <  array.length;  i++)  ids[i]  =  (int)Long.parseLong(array[i]);  ids[i]  =  (int)Long.parseLong(array[i].trim());  }  else  {  if  (true)  if  (encoding.equals( "base64 "))  {  InputStream  is  =  null;  try  {  String  compression  =  data.getAttribute( "compression ",  null);  byte[]  bytes  =  Base64Coder.decode(data.getText());  if  (compression  ==  null)  	ids[i]  =  (int)Long.parseLong(array[i].trim());  
elasticsearch_f5665275133eac1d6071cbf2391796cb0527358d	buggy:  XContentBuilder  builder  =  restContentBuilder(request,  false);  context:  analyzeRequest.listenerThreaded(false);  analyzeRequest.preferLocal(request.paramAsBoolean( "prefer_local ",  analyzeRequest.preferLocalShard()));  analyzeRequest.analyzer(request.param( "analyzer "));  analyzeRequest.field(request.param( "field "));  analyzeRequest.tokenizer(request.param( "tokenizer "));  analyzeRequest.tokenFilters(request.paramAsStringArray( "token_filters ",  request.paramAsStringArray( "filters ",  null)));  client.admin().indices().analyze(analyzeRequest,  new  ActionListener<AnalyzeResponse>()  {  public  void  onResponse(AnalyzeResponse  response)  {  try  {                      XContentBuilder  builder  =  restContentBuilder(request,  false);                      XContentBuilder  builder  =  restContentBuilder(request,  null);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  }  catch  (Throwable  e)  {  onFailure(e);  }  }  	XContentBuilder  builder  =  restContentBuilder(request,  null);  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  return  weight.scorer(leaf,  true,  false,  null);  context:  IndexSearcher  searcher  =  searchContext.searcher();  docIdSets  =  new  IdentityHashMap<>();  this.searcher  =  searcher;  searchContext.addReleasable(this,  Lifetime.COLLECTION);  final  Weight  weight  =  searcher.createNormalizedWeight(query);  for  (final  AtomicReaderContext  leaf  :  searcher.getTopReaderContext().leaves())  {  final  DocIdSet  set  =  DocIdSets.toCacheable(leaf.reader(),  new  DocIdSet()  {  public  DocIdSetIterator  iterator()  throws  IOException  {                          return  weight.scorer(leaf,  true,  false,  null);                          return  weight.scorer(leaf,  null);  }  public  boolean  isCacheable()  {  return  false;  }  });  docIdSets.put(leaf.reader(),  set);  }  }  else  {  assert  searcher  ==  SearchContext.current().searcher();  	return  weight.scorer(leaf,  null);  
elasticsearch_02c622232071d3d793d0d6030d19aad19f354d35	buggy:  return  MVEL.compileExpression(script,  new  ParserContext(parserConfiguration));  context:  return  new  String[]{ "mvel "};  }  public  String[]  extensions()  {  return  new  String[]{ "mvel "};  }  public  Object  compile(String  script)  {          return  MVEL.compileExpression(script,  new  ParserContext(parserConfiguration));          return  MVEL.compileExpression(script.trim(),  new  ParserContext(parserConfiguration));  }  public  Object  execute(Object  compiledScript,  Map  vars)  {  return  MVEL.executeExpression(compiledScript,  vars);  }  	return  MVEL.compileExpression(script.trim(),  new  ParserContext(parserConfiguration));  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  Calendar  calendar  =  new  GregorianCalendar();  context:  builder  =  XContentFactory.contentBuilder(XContentType.JSON).fieldCaseConversion(UNDERSCORE);  builder.startObject().field( "testName ",   "value ").endObject();  assertThat(builder.string(),  equalTo( "{\ "test_name\ ":\ "value\ "} "));  }  public  void  testDateTypesConversion()  throws  Exception  {  Date  date  =  new  Date();  String  expectedDate  =  XContentBuilder.defaultDatePrinter.print(date.getTime());          Calendar  calendar  =  new  GregorianCalendar();          Calendar  calendar  =  new  GregorianCalendar(TimeZone.getTimeZone( "UTC "),  Locale.ROOT);  String  expectedCalendar  =  XContentBuilder.defaultDatePrinter.print(calendar.getTimeInMillis());  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON);  builder.startObject().field( "date ",  date).endObject();  assertThat(builder.string(),  equalTo( "{\ "date\ ":\ " "  +  expectedDate  +   "\ "} "));  builder  =  XContentFactory.contentBuilder(XContentType.JSON);  builder.startObject().field( "calendar ",  calendar).endObject();  assertThat(builder.string(),  equalTo( "{\ "calendar\ ":\ " "  +  expectedCalendar  +   "\ "} "));  	Calendar  calendar  =  new  GregorianCalendar(TimeZone.getTimeZone( "UTC "),  Locale.ROOT);  
elasticsearch_02cb2976917e3a6edb5e0caf5a65a95e3bff5f3a	buggy:  .mappingSource(mappingSource())).actionGet();  context:  node( "server1 ").start();  client( "server1 ").admin().indices().create(createIndexRequest( "test ")).actionGet();  PutMappingResponse  putMappingResponse  =  client( "server1 ").admin().indices().putMapping(putMappingRequest( "test ").type( "type1 ")                  .mappingSource(mappingSource())).actionGet();                  .source(mappingSource())).actionGet();  assertThat(putMappingResponse.acknowledged(),  equalTo(true));  ClusterStateResponse  clusterState  =  client( "server1 ").admin().cluster().state(clusterState()).actionGet();  assertThat(clusterState.state().metaData().index( "test ").mapping( "type1 "),  notNullValue());  	.source(mappingSource())).actionGet();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<Suggestion<?  extends  Entry<?  extends  Option>>>  suggestions  =  new  ArrayList<Suggestion<?  extends  Entry<?  extends  Option>>>(suggest.suggestions().size());  context:  final  SuggestionSearchContext  suggest  =  context.suggest();  if  (suggest  ==  null)  {  return;  }  context.queryResult().suggest(execute(suggest,  context.searcher().getIndexReader()));  }  public  Suggest  execute(SuggestionSearchContext  suggest,  IndexReader  reader)  {  try  {  CharsRef  spare  =  new  CharsRef();  //  Maybe  add  CharsRef  to  CacheRecycler?              final  List<Suggestion<?  extends  Entry<?  extends  Option>>>  suggestions  =  new  ArrayList<Suggestion<?  extends  Entry<?  extends  Option>>>(suggest.suggestions().size());              final  List<Suggestion<?  extends  Entry<?  extends  Option>>>  suggestions  =  new  ArrayList<>(suggest.suggestions().size());  for  (Map.Entry<String,  SuggestionSearchContext.SuggestionContext>  entry  :  suggest.suggestions().entrySet())  {  SuggestionSearchContext.SuggestionContext  suggestion  =  entry.getValue();  Suggester<SuggestionContext>  suggester  =  suggestion.getSuggester();  Suggestion<?  extends  Entry<?  extends  Option>>  result  =  suggester.execute(entry.getKey(),  suggestion,  reader,  spare);  if  (result  !=  null)  {  assert  entry.getKey().equals(result.name);  suggestions.add(result);  	final  List<Suggestion<?  extends  Entry<?  extends  Option>>>  suggestions  =  new  ArrayList<>(suggest.suggestions().size());  
elasticsearch_a938bd57a946f7eb8d687af19394cacc603d141f	buggy:  float  score(int  docId,  float  subQueryScore);  context:  public  interface  ScoreFunction  {  void  setNextReader(AtomicReaderContext  context);      float  score(int  docId,  float  subQueryScore);      double  score(int  docId,  float  subQueryScore);  double  factor(int  docId);  Explanation  explainScore(int  docId,  Explanation  subQueryExpl);  Explanation  explainFactor(int  docId);  }  	double  score(int  docId,  float  subQueryScore);  
libgdx_b4b520ad047b79f70ec1f699a8d2a1ec58d36bc8	buggy:  new  JglfwApplication(test,  config).start();  context:  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ")  .load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  UITest();  JglfwApplicationConfiguration  config  =  new  JglfwApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  JglfwApplication(test,  config).start();  new  JglfwApplication(test,  config);  }  }  	new  JglfwApplication(test,  config);  
elasticsearch_e54f010a4d989100704829455d73a9d1ee0e44ed	buggy:  }  else  if  ( "minimal_norwegian ".equalsIgnoreCase(language))  {  context:  }  else  if  ( "kp ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  KpStemmer());  }  else  if  ( "kstem ".equalsIgnoreCase(language))  {  return  new  KStemFilter(tokenStream);  }  else  if  ( "lovins ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  LovinsStemmer());  }  else  if  ( "latvian ".equalsIgnoreCase(language))  {  return  new  LatvianStemFilter(tokenStream);  }  else  if  ( "norwegian ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  NorwegianStemmer());          }  else  if  ( "minimal_norwegian ".equalsIgnoreCase(language))  {          }  else  if  ( "minimal_norwegian ".equalsIgnoreCase(language)  ||   "minimalNorwegian ".equals(language))  {  return  new  NorwegianMinimalStemFilter(tokenStream);  }  else  if  ( "porter ".equalsIgnoreCase(language))  {  return  new  PorterStemFilter(tokenStream);  }  else  if  ( "porter2 ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  PorterStemmer());  }  else  if  ( "portuguese ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  PortugueseStemmer());  }  else  if  ( "romanian ".equalsIgnoreCase(language))  {  	}  else  if  ( "minimal_norwegian ".equalsIgnoreCase(language)  ||   "minimalNorwegian ".equals(language))  {  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.allow_rebalance ",  ClusterRebalanceNodeAllocation.ClusterRebalanceType.ALWAYS.toString()).build());  context:  public  class  ShardVersioningTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(ShardVersioningTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.allow_rebalance ",  ClusterRebalanceNodeAllocation.ClusterRebalanceType.ALWAYS.toString()).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.allow_rebalance ",  ClusterRebalanceNodeAllocation.ClusterRebalanceType.ALWAYS.toString()).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test1 ").numberOfShards(1).numberOfReplicas(1))  .put(newIndexMetaDataBuilder( "test2 ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  .add(indexRoutingTable( "test1 ").initializeEmpty(metaData.index( "test1 ")))  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.allow_rebalance ",  ClusterRebalanceNodeAllocation.ClusterRebalanceType.ALWAYS.toString()).build());  
elasticsearch_23d2b1ea7b191f27f8882494b520b8d6f443f7de	buggy:  .setFilter(FilterBuilders.existsFilter( "sparse_bytes ")).setSize(size).addSort( "sparse_bytes ",  SortOrder.ASC).execute()  context:  for  (int  i  =  0;  i  <  size;  i++)  {  assertThat(iterator.hasNext(),  equalTo(true));  Entry<BytesRef,  String>  next  =  iterator.next();  assertThat( "pos:   "  +  i,  searchResponse.getHits().getAt(i).id(),  equalTo(next.getValue()));  assertThat(searchResponse.getHits().getAt(i).sortValues()[0].toString(),  equalTo(next.getKey().utf8ToString()));  }  }  if  (!sparseBytes.isEmpty())  {  int  size  =  between(1,  sparseBytes.size());  SearchResponse  searchResponse  =  client().prepareSearch().setQuery(matchAllQuery())                      .setFilter(FilterBuilders.existsFilter( "sparse_bytes ")).setSize(size).addSort( "sparse_bytes ",  SortOrder.ASC).execute()                      .setPostFilter(FilterBuilders.existsFilter( "sparse_bytes ")).setSize(size).addSort( "sparse_bytes ",  SortOrder.ASC).execute()  .actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().getTotalHits(),  equalTo((long)  sparseBytes.size()));  assertThat(searchResponse.getHits().hits().length,  equalTo(size));  Set<Entry<BytesRef,  String>>  entrySet  =  sparseBytes.entrySet();  Iterator<Entry<BytesRef,  String>>  iterator  =  entrySet.iterator();  for  (int  i  =  0;  i  <  size;  i++)  {  assertThat(iterator.hasNext(),  equalTo(true));  	.setPostFilter(FilterBuilders.existsFilter( "sparse_bytes ")).setSize(size).addSort( "sparse_bytes ",  SortOrder.ASC).execute()  
elasticsearch_06da379f5045e0c1d7436a7757400f9ba5b7f993	buggy:  if  (smartNameFieldMappers.hasDocMapper())  {  context:  throw  new  QueryParsingException(parseContext.index(),   "No  field  specified  for  term  filter ");  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              if  (smartNameFieldMappers.hasDocMapper())  {              if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  filter  =  smartNameFieldMappers.mapper().fieldFilter(value,  parseContext);  }  finally  {  QueryParseContext.setTypes(previousTypes);  }  }  else  {  filter  =  smartNameFieldMappers.mapper().fieldFilter(value,  parseContext);  	if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  fields.add(toDocValues(value));  context:  context.allEntries().addText(names.fullName(),  ipAsString,  boost);  }  final  long  value  =  ipToLong(ipAsString);  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              fields.add(toDocValues(value));              addDocValue(context,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  value);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  context.release();  context:  GetResult  getResult  =  indexShard.getService().get(result,  request.id(),  request.type(),  request.fields(),  request.fetchSourceContext());  return  new  ExplainResponse(true,  explanation,  getResult);  }  else  {  return  new  ExplainResponse(true,  explanation);  }  }  catch  (IOException  e)  {  throw  new  ElasticsearchException( "Could  not  explain ",  e);  }  finally  {              context.release();              context.close();  SearchContext.removeCurrent();  }  }  protected  ExplainRequest  newRequest()  {  return  new  ExplainRequest();  }  	context.close();  
libgdx_dd3f80c2a4ab8b2e9e4407e95f22e2c32c207aba	buggy:  long  t  =  attr.getType();  context:  program.end();  }  NewMaterial  currentMaterial;  private  final  void  bindMaterial(final  Renderable  renderable)  {  if  (currentMaterial  ==  renderable.material)  return;  currentMaterial  =  renderable.material;  for  (NewMaterial.Attribute  attr  :  currentMaterial)  {  long  t  =  attr.getType();  final  long  t  =  attr.type;  if  (BlendingAttribute.is(t))  context.setBlending(true,  ((BlendingAttribute)attr).sourceFunction,  ((BlendingAttribute)attr).destFunction);  else  if  (ColorAttribute.is(t))  {  ColorAttribute  col  =  (ColorAttribute)attr;  if  ((t  &  ColorAttribute.Diffuse)  ==  ColorAttribute.Diffuse)  program.setUniformf(diffuseColorLoc,  col.color);  }  	final  long  t  =  attr.type;  
libgdx_6d35d3f784c49157dcc4f6530d6a528732358216	buggy:  return  new  IOSApplication(new  MusicTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  class  InnerClass  {  }  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  MusicTest(),  config);  return  new  IOSApplication(new  DownloadTest(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.drain();  }  }  	return  new  IOSApplication(new  DownloadTest(),  config);  
elasticsearch_8ccfca3a2f0193f0a4da38e206c35cf08402218f	buggy:  TermsEnum  globalTermsEnum  =  valueSource.getGlobalTermsEnum();  context:  if  (exclude  ==  null)  {  return  true;  }  return  !exclude.reset(scratch).matches();  }  public  LongBitSet  acceptedGlobalOrdinals(BytesValues.WithOrdinals  globalOrdinals,  ValuesSource.Bytes.WithOrdinals  valueSource)  {          TermsEnum  globalTermsEnum  =  valueSource.getGlobalTermsEnum();          TermsEnum  globalTermsEnum  =  valueSource.globalBytesValues().getTermsEnum();  LongBitSet  acceptedGlobalOrdinals  =  new  LongBitSet(globalOrdinals.getMaxOrd());  try  {  for  (BytesRef  term  =  globalTermsEnum.next();  term  !=  null;  term  =  globalTermsEnum.next())  {  if  (accept(term))  {  acceptedGlobalOrdinals.set(globalTermsEnum.ord());  }  }  }  catch  (IOException  e)  {  	TermsEnum  globalTermsEnum  =  valueSource.globalBytesValues().getTermsEnum();  
libgdx_ee0e61e5d88772f6e895b48d45870cd73ffa9ac1	buggy:  if  (Gdx.app.getType()  ==  ApplicationType.Android)  {  context:  public  static  void  generateMipMap  (int  target,  Pixmap  pixmap,  int  textureWidth,  int  textureHeight,  boolean  disposePixmap)  {  if  (!useHWMipMap)  {  generateMipMapCPU(target,  pixmap,  textureWidth,  textureHeight,  disposePixmap);  return;  }  if  (Gdx.app.getType()  ==  ApplicationType.Android)  {  if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL)  {  if  (Gdx.graphics.isGL20Available())  generateMipMapGLES20(target,  pixmap,  disposePixmap);  else  generateMipMapCPU(target,  pixmap,  textureWidth,  textureHeight,  disposePixmap);  }  else  {  generateMipMapDesktop(target,  pixmap,  textureWidth,  textureHeight,  disposePixmap);  }  }  	if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL)  {  
libgdx_ffab0469af912f402d675b82f3563e1ab18a1f2d	buggy:  public  void  consumeCompressedData  ()  {  context:  public  boolean  isManaged  ()  {  return  true;  }  public  TextureDataType  getType  ()  {  return  TextureDataType.Pixmap;  }  public  void  consumeCompressedData  ()  {  public  void  consumeCompressedData  (int  target)  {  }  public  boolean  isPrepared  ()  {  return  true;  }  	public  void  consumeCompressedData  (int  target)  {  
elasticsearch_7d0af6a3454d406b77a3b583746ee78b1902412f	buggy:  if  (ptr  !=  data.length)  {  context:  }  else  {  //  unknown...  CRC-32  would  be  2,  but  that's  not  implemented  by  cli  tool  throw  new  IOException( "Corrupt  input  data,  block  # "  +  blockNr  +   "  (at  offset   "  +  ptr  +   "):  unrecognized  block  type   "  +  (type  &  0xFF));  }  ptr  +=  blockLen;  }  catch  (ArrayIndexOutOfBoundsException  e)  {  throw  new  IOException( "Corrupt  input  data,  block  # "  +  blockNr  +   "  (at  offset   "  +  ptr  +   "):  truncated  block  header ");  }  +blockNr;  }          if  (ptr  !=  data.length)  {          if  (ptr  !=  end)  {  throw  new  IOException( "Corrupt  input  data:  block  # "  +  blockNr  +   "  extends   "  +  (data.length  -  ptr)  +   "  beyond  end  of  input ");  }  return  uncompressedSize;  }  	if  (ptr  !=  end)  {  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  builder.startObject(name).field(type);  context:  return  this;  }  public  TopHitsBuilder  setHighlighterOptions(Map<String,  Object>  options)  {  highlightBuilder().options(options);  return  this;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {          builder.startObject(name).field(type);          builder.startObject(getName()).field(type);  sourceBuilder().toXContent(builder,  params);  return  builder.endObject();  }  private  SearchSourceBuilder  sourceBuilder()  {  if  (sourceBuilder  ==  null)  {  sourceBuilder  =  new  SearchSourceBuilder();  }  	builder.startObject(getName()).field(type);  
elasticsearch_8a8a4d648aeffd8b196f31a866de2c12a5b5663b	buggy:  filter  =  parseContext.cacheFilterIfPossible(filter);  context:  }  }  if  (filter  ==  null)  {  throw  new  QueryParsingException(index,   "[constant_score]  requires  'filter'  element ");  }  Query  query;  if  (cache)  {  Filter  nonCachedFilter  =  filter;              filter  =  parseContext.cacheFilterIfPossible(filter);              filter  =  parseContext.cacheFilter(filter);  if  (parseContext.indexEngine().readerClonedOnDeletion()  &&  (filter  !=  nonCachedFilter))  {  query  =  new  DeletionAwareConstantScoreQuery(filter,  true);  }  else  {  query  =  new  ConstantScoreQuery(filter);  }  }  else  {  query  =  new  ConstantScoreQuery(filter);  }  	filter  =  parseContext.cacheFilter(filter);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  public  BytesValues  getBytesValues(boolean  needsHashes)  {  context:  public  ScriptDocValues  getScriptValues()  {  if  (isFloat)  {  return  new  ScriptDocValues.Doubles(getDoubleValues());  }  else  {  return  new  ScriptDocValues.Longs(getLongValues());  }  }      public  BytesValues  getBytesValues(boolean  needsHashes)  {      public  BytesValues  getBytesValues()  {  if  (isFloat)  {  final  DoubleValues  values  =  getDoubleValues();  return  new  BytesValues(values.isMultiValued())  {  public  int  setDocument(int  docId)  {  this.docId  =  docId;  return  values.setDocument(docId);  	public  BytesValues  getBytesValues()  {  
elasticsearch_3cee291bc2d9af7177f51804e82fca0663c8341a	buggy:  createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) "),  new  ActionListener<CreateIndexResponse>()  {  context:  this.autoCreateIndex  =  settings.getAsBoolean( "action.auto_create_index ",  true);  this.allowIdGeneration  =  settings.getAsBoolean( "action.allow_id_generation ",  true);  this.waitForMappingChange  =  settings.getAsBoolean( "action.wait_on_mapping_change ",  true);  }  protected  void  doExecute(final  IndexRequest  request,  final  ActionListener<IndexResponse>  listener)  {  if  (autoCreateIndex  &&  !clusterService.state().metaData().hasConcreteIndex(request.index()))  {  request.beforeLocalFork();  //  we  fork  on  another  thread...              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) "),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  	createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
libgdx_236cdcef8cb7765acf0bb980a3c2904d518afc38	buggy:  new  AntScriptGenerator().generate(new  BuildConfig( "test "),  win32home,  win32,  win64,  lin32,  lin64,  mac);  context:  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  BuildTarget  win32  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  BuildTarget  win64  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  true);  BuildTarget  lin32  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  false);  BuildTarget  lin64  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  true);  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  new  AntScriptGenerator().generate(new  BuildConfig( "test "),  win32home,  win32,  win64,  lin32,  lin64,  mac);  new  AntScriptGenerator().generate(new  BuildConfig( "stbtruetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac);  AntScriptExecutor.execute( "jni/build-windows32home.xml ",   "-v ");  }  }  	new  AntScriptGenerator().generate(new  BuildConfig( "stbtruetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac);  
elasticsearch_4634ca5cb8c8ad0a3c725363f3705a4078c04c9c	buggy:  if  (includeInAll  ==  null  ||  includeInAll)  {  context:  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  ipAsString  =  nullValue;  }  else  {  ipAsString  =  context.parser().text();  }  }  if  (ipAsString  ==  null)  {  return  null;  }          if  (includeInAll  ==  null  ||  includeInAll)  {          if  (context.includeInAll(includeInAll))  {  context.allEntries().addText(names.fullName(),  ipAsString,  boost);  }  final  long  value  =  ipToLong(ipAsString);  return  new  LongFieldMapper.CustomLongNumericField(this,  value);  }  	if  (context.includeInAll(includeInAll))  {  
libgdx_98a2796045b849587ca938f3c1c7c863bb40ee8c	buggy:  texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "));  context:  void  setModeString()  {  modeString  =  (mode%2==0? "Sprite ": "Atlas ")  +   "   "  +  filterNames[mode/2];  }  public  void  create  ()  {  batch  =  new  SpriteBatch();  sceneMatrix  =  new  Matrix4().setToOrtho2D(0,  0,  480,  320);  textMatrix  =  new  Matrix4().setToOrtho2D(0,  0,  480,  320);  atlas  =  new  TextureAtlas(Gdx.files.internal( "data/issue_pack "),  Gdx.files.internal( "data/ "));  texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "));  texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "),  true);  texture.setFilter(TextureFilter.MipMap,  TextureFilter.Nearest);  setTextureFilter(0);  setModeString();  sprite  =  atlas.createSprite( "map ");  sprite2  =  new  Sprite(texture,  0,  0,  855,  480);  font  =  new  BitmapFont(Gdx.files.internal( "data/font.fnt "),  Gdx.files.internal( "data/font.png "),  false);  	texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "),  true);  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);  context:  MapperService.SmartNameFieldMappers  smartMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartMappers  ==  null  ||  !smartMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  geo_point  field  [ "  +  fieldName  +   "] ");  }  FieldMapper<?>  mapper  =  smartMappers.mapper();  if  (!(mapper  instanceof  GeoPointFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "field  [ "  +  fieldName  +   "]  is  not  a  geo_point  field ");  }          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  Filter  filter  =  new  GeoPolygonFilter(indexFieldData,  shell.toArray(new  GeoPoint[shell.size()]));  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  
libgdx_c25f3ed04a7dcad130303a10f6d235e7ee7b36fd	buggy:  if  (handle.parent().exists())  fail();  context:  private  void  testLocal  ()  throws  IOException  {  String  path  =   "meow ";  FileHandle  handle  =  Gdx.files.local(path);  handle.delete();  if  (handle.exists())  fail();  if  (handle.isDirectory())  fail();  if  (handle.delete())  fail();  if  (handle.list().length  !=  0)  fail();  if  (handle.child( "meow ").exists())  fail();  if  (handle.parent().exists())  fail();  if  (!handle.parent().exists())  fail();  try  {  handle.read().close();  fail();  }  catch  (Exception  ignored)  {  }  handle.mkdirs();  if  (!handle.exists())  fail();  if  (!handle.isDirectory())  fail();  	if  (!handle.parent().exists())  fail();  
elasticsearch_83d5084f620e13678e7786b5c735de32c4e9fb80	buggy:  return  XContentHelper.convertToMap(bytes,  offset,  length).v2();  context:  }  else  {  this.source  =  sourceAsMap(sourceField.getBinaryValue(),  sourceField.getBinaryOffset(),  sourceField.getBinaryLength());  }  }  catch  (Exception  e)  {  throw  new  ElasticSearchParseException( "failed  to  parse  /  load  source ",  e);  }  return  this.source;  }  public  static  Map<String,  Object>  sourceAsMap(byte[]  bytes,  int  offset,  int  length)  throws  ElasticSearchParseException  {          return  XContentHelper.convertToMap(bytes,  offset,  length).v2();          return  XContentHelper.convertToMap(bytes,  offset,  length,  false).v2();  }  public  void  setNextReader(IndexReader  reader)  {  if  (this.reader  ==  reader)  {  //  if  we  are  called  with  the  same  reader,  don't  invalidate  source  return;  }  this.reader  =  reader;  this.source  =  null;  	return  XContentHelper.convertToMap(bytes,  offset,  length,  false).v2();  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  },  false);  context:  public  void  pause  ()  {  }  public  void  dispose  ()  {  }  },  false);  });  }  }  	});  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(clusterStateInBytes,  true);  context:  this.clusterStateInBytes  =  new  BytesArray(clusterStateInBytes);  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  clusterStateInBytes  =  in.readBytesReference();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {              out.writeBytesReference(clusterStateInBytes,  true);              out.writeBytesReference(clusterStateInBytes);  }  }  private  class  PublishClusterStateRequestHandler  extends  BaseTransportRequestHandler<PublishClusterStateRequest>  {  static  final  String  ACTION  =   "discovery/zen/publish ";  	out.writeBytesReference(clusterStateInBytes);  
libgdx_c1367a24c8a3ac977129b908089754d86cac2cc7	buggy:  return  Gdx.graphics.getHeight()  -  Mouse.getY();  context:  listener.canceled();  }  });  }  public  int  getX  ()  {  return  Mouse.getX();  }  public  int  getY  ()  {  return  Gdx.graphics.getHeight()  -  Mouse.getY();  return  Gdx.graphics.getHeight()  -  1  -  Mouse.getY();  }  public  boolean  isAccelerometerAvailable  ()  {  return  false;  }  public  boolean  isKeyPressed  (int  key)  {  if  (key  ==  Input.Keys.ANY_KEY)  	return  Gdx.graphics.getHeight()  -  1  -  Mouse.getY();  
elasticsearch_6950c38a0436ec937797f01fba8d7d95e6d6225f	buggy:  if  (indexShouldExists  &&  indexShard.store().indexStore().persistent())  {  context:  SegmentInfos  si  =  null;  try  {  si  =  Lucene.readSegmentInfos(indexShard.store().directory());  }  catch  (Throwable  e)  {  String  files  =   "_unknown_ ";  try  {  files  =  Arrays.toString(indexShard.store().directory().listAll());  }  catch  (Throwable  e1)  {  files  +=   "  (failure= "  +  ExceptionsHelper.detailedMessage(e1)  +   ") ";  }                      if  (indexShouldExists  &&  indexShard.store().indexStore().persistent())  {                      if  (indexShouldExists  &&  indexShard.indexService().store().persistent())  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exist,  but  doesn't,  current  files:   "  +  files,  e);  }  }  if  (si  !=  null)  {  if  (indexShouldExists)  {  version  =  si.getVersion();  if  (si.getUserData().containsKey(Translog.TRANSLOG_ID_KEY))  {  translogId  =  Long.parseLong(si.getUserData().get(Translog.TRANSLOG_ID_KEY));  	if  (indexShouldExists  &&  indexShard.indexService().store().persistent())  {  
elasticsearch_14ae2fb7650f19c02440620061e6915da7711578	buggy:  clusterService.submitStateUpdateTask( "delete-index  [ "  +  request.index  +   "] ",  new  ClusterStateUpdateTask()  {  context:  MetaDataService.MdLock  mdLock  =  metaDataService.indexMetaDataLock(request.index);  try  {  mdLock.lock();  }  catch  (InterruptedException  e)  {  userListener.onFailure(e);  return;  }  final  DeleteIndexListener  listener  =  new  DeleteIndexListener(mdLock,  request,  userListener);          clusterService.submitStateUpdateTask( "delete-index  [ "  +  request.index  +   "] ",  new  ClusterStateUpdateTask()  {          clusterService.submitStateUpdateTask( "delete-index  [ "  +  request.index  +   "] ",  Priority.URGENT,  new  ClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  try  {  if  (!currentState.metaData().hasConcreteIndex(request.index))  {  listener.onFailure(new  IndexMissingException(new  Index(request.index)));  return  currentState;  }  	clusterService.submitStateUpdateTask( "delete-index  [ "  +  request.index  +   "] ",  Priority.URGENT,  new  ClusterStateUpdateTask()  {  
elasticsearch_537d9c5db06a34b75be8ecd9725e918435613ba4	buggy:  FieldQuery  fieldQuery  =  buildFieldQuery(highlighter,  context.query(),  hitContext.reader(),  field);  context:  }  }  else  {  if  (mapper.stored())  {  fragmentsBuilder  =  new  SimpleFragmentsBuilder(field.preTags(),  field.postTags());  }  else  {  fragmentsBuilder  =  new  SourceSimpleFragmentsBuilder(mapper,  context,  field.preTags(),  field.postTags());  }  }  }  FastVectorHighlighter  highlighter  =  new  FastVectorHighlighter(true,  false,  fragListBuilder,  fragmentsBuilder);                      FieldQuery  fieldQuery  =  buildFieldQuery(highlighter,  context.query(),  hitContext.reader(),  field);                      FieldQuery  fieldQuery  =  buildFieldQuery(highlighter,  context.parsedQuery().query(),  hitContext.reader(),  field);  String[]  fragments;  try  {  int  numberOfFragments  =  field.numberOfFragments()  ==  0  ?  1  :  field.numberOfFragments();  fragments  =  highlighter.getBestFragments(fieldQuery,  hitContext.reader(),  hitContext.docId(),  mapper.names().indexName(),  field.fragmentCharSize(),  numberOfFragments,  fragListBuilder,  fragmentsBuilder,  field.preTags(),  field.postTags(),  encoder);  }  catch  (IOException  e)  {  	FieldQuery  fieldQuery  =  buildFieldQuery(highlighter,  context.parsedQuery().query(),  hitContext.reader(),  field);  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  return  add(new  Label(text,  skin.getStyle(labelStyleName,  LabelStyle.class)));  context:  public  Cell  add  (String  text)  {  if  (skin  ==  null)  throw  new  IllegalStateException( "Table  must  have  a  skin  set  to  use  this  method. ");  return  add(new  Label(text,  skin));  }  public  Cell  add  (String  text,  String  labelStyleName)  {  if  (skin  ==  null)  throw  new  IllegalStateException( "Table  must  have  a  skin  set  to  use  this  method. ");  return  add(new  Label(text,  skin.getStyle(labelStyleName,  LabelStyle.class)));  return  add(new  Label(text,  skin.get(labelStyleName,  LabelStyle.class)));  }  public  Cell  add  ()  {  return  add((Actor)null);  }  	return  add(new  Label(text,  skin.get(labelStyleName,  LabelStyle.class)));  
libgdx_9d37f4a93e68875c1b6c0dc84dfbfc5764b74e9a	buggy:  if  (newFocusedActor  ==  null  ||  !newFocusedActor.isDescendantOf(Dialog.this))  event.cancel();  context:  public  void  scrollFocusChanged  (FocusEvent  event,  Actor  actor,  boolean  focused)  {  if  (!focused)  focusChanged(event);  }  private  void  focusChanged  (FocusEvent  event)  {  Stage  stage  =  getStage();  if  (isModal  &&  stage  !=  null  &&  stage.getRoot().getChildren().size  >  0  &&  stage.getRoot().getChildren().peek()  ==  Dialog.this)  {  //  Dialog  is  top  most  actor.  Actor  newFocusedActor  =  event.getRelatedActor();  if  (newFocusedActor  ==  null  ||  !newFocusedActor.isDescendantOf(Dialog.this))  event.cancel();  if  (newFocusedActor  !=  null  &&  !newFocusedActor.isDescendantOf(Dialog.this))  event.cancel();  }  }  });  }  public  Table  getContentTable  ()  {  return  contentTable;  }  	if  (newFocusedActor  !=  null  &&  !newFocusedActor.isDescendantOf(Dialog.this))  event.cancel();  
libgdx_8d5f9cfcd33300fa9b7871b0da679357869368ba	buggy:  t  =  paths.get(currentPath).approximate(tmpV.set(x,  Gdx.graphics.getHeight()-y));  context:  renderer.vertex(tmpV.x,  tmpV.y,  0);  val  +=  SAMPLE_POINT_DISTANCE;  }  renderer.end();  obj.draw(spriteBatch);  spriteBatch.end();  }  private  void  touch(int  x,  int  y)  {  t  =  paths.get(currentPath).approximate(tmpV.set(x,  Gdx.graphics.getHeight()-y));  t  =  paths.get(currentPath).locate(tmpV.set(x,  Gdx.graphics.getHeight()-y));  paths.get(currentPath).valueAt(tmpV,  t);  obj.setPosition(tmpV.x,  tmpV.y);  wait  =  0.2f;  }  public  boolean  touchUp  (int  screenX,  int  screenY,  int  pointer,  int  button)  {  touch(screenX,  screenY);  	t  =  paths.get(currentPath).locate(tmpV.set(x,  Gdx.graphics.getHeight()-y));  
elasticsearch_c40935ae1473326783e2e15b85077c5b22720997	buggy:  String  builtMapping  =  docMapper.buildSource();  context:  doc  =  docMapper.parse(json).doc();  }  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/xcontent/simple/test-mapping.json ");  XContentDocumentMapper  docMapper  =  XContentMapperTests.newParser().parse(mapping);          String  builtMapping  =  docMapper.buildSource();          String  builtMapping  =  docMapper.mappingSource().string();  XContentDocumentMapper  builtDocMapper  =  XContentMapperTests.newParser().parse(builtMapping);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/simple/test1.json ");  Document  doc  =  builtDocMapper.parse(json).doc();  assertThat(doc.get(docMapper.uidMapper().names().indexName()),  equalTo(Uid.createUid( "person ",   "1 ")));  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().names().indexName()),  equalTo( "shay "));  	String  builtMapping  =  docMapper.mappingSource().string();  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().allShardsGrouped(concreteIndices);  context:  .refresh(request.refresh())  );  return  new  ShardOptimizeResponse(request.index(),  request.shardId());  }  }          return  clusterState.routingTable().allShardsGrouped(concreteIndices);          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(short  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  ShortFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  ShortFieldMapper  fieldMapper  =  new  ShortFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_3a9a62c2b999e98244d12e9823a1c6a9cb6b81b1	buggy:  .remoteTemplate(request.name);  context:  public  void  removeTemplate(final  RemoveRequest  request,  final  RemoveListener  listener)  {  clusterService.submitStateUpdateTask( "remove-index-template  [ "  +  request.name  +   "] ",  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  if  (!currentState.metaData().templates().containsKey(request.name))  {  listener.onFailure(new  IndexTemplateMissingException(request.name));  return  currentState;  }  MetaData.Builder  metaData  =  MetaData.builder().metaData(currentState.metaData())                          .remoteTemplate(request.name);                          .removeTemplate(request.name);  return  ClusterState.builder().state(currentState).metaData(metaData).build();  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  listener.onResponse(new  RemoveResponse(true));  }  	.removeTemplate(request.name);  
elasticsearch_e26a56e0253a99e174d40c275d375c14e692dae0	buggy:  },   "elasticsearch[keepAlive] ");  context:  keepAliveThread  =  new  Thread(new  Runnable()  {  public  void  run()  {  try  {  keepAliveLatch.await();  }  catch  (InterruptedException  e)  {  }  }              },   "elasticsearch[keepAlive] ");              },   "elasticsearch[keepAlive/ "  +  Version.CURRENT  +   "] ");  keepAliveThread.setDaemon(false);  keepAliveThread.start();  }  catch  (Throwable  e)  {  ESLogger  logger  =  Loggers.getLogger(Bootstrap.class);  if  (bootstrap.node  !=  null)  {  }  String  errorMessage  =  buildErrorMessage(stage,  e);  	},   "elasticsearch[keepAlive/ "  +  Version.CURRENT  +   "] ");  
libgdx_621cef509edff7fd5608f96e18f03f2a8d796550	buggy:  return  Integer.parseInt(android.os.Build.VERSION.SDK);  context:  return  net;  }  public  ApplicationType  getType  ()  {  return  ApplicationType.Android;  }  public  int  getVersion  ()  {  return  Integer.parseInt(android.os.Build.VERSION.SDK);  return  android.os.Build.VERSION.SDK_INT;  }  public  long  getJavaHeap  ()  {  return  Runtime.getRuntime().totalMemory()  -  Runtime.getRuntime().freeMemory();  }  	return  android.os.Build.VERSION.SDK_INT;  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  buckets.release();  context:  final  int  size  =  (int)  Math.min(requiredSize,  buckets.size());  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  for  (LongObjectPagedHashMap.Cursor<List<LongTerms.Bucket>>  cursor  :  buckets)  {  List<LongTerms.Bucket>  sameTermBuckets  =  cursor.value;  final  InternalTerms.Bucket  b  =  sameTermBuckets.get(0).reduce(sameTermBuckets,  reduceContext.bigArrays());  if  (b.getDocCount()  >=  minDocCount)  {  ordered.insertWithOverflow(b);  }  }          buckets.release();          buckets.close();  InternalTerms.Bucket[]  list  =  new  InternalTerms.Bucket[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  (Bucket)  ordered.pop();  }  reduced.buckets  =  Arrays.asList(list);  return  reduced;  }  	buckets.close();  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_be4b2e2de618240a64524f5256ff857cf6f9d4ea	buggy:  SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  params,  context.scriptService());  context:  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  params  =  parser.map();  }  else  if  (token.isValue())  {  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  }  }                  SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  params,  context.scriptService());                  SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  params,  context.scriptService());  context.scriptFields().add(new  ScriptFieldsContext.ScriptField(fieldName,  searchScript));  }  }  }  }  	SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  params,  context.scriptService());  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  return  smartMapper.fieldMappers().mapper().indexName();  context:  }  return  fieldMappers.mapper();  }  public  String  indexName(String  name)  {  MapperService.SmartNameFieldMappers  smartMapper  =  smartFieldMappers(name);  if  (smartMapper  ==  null)  {  return  name;  }  if  (smartMapper.fieldMappers().mapper()  !=  null)  {              return  smartMapper.fieldMappers().mapper().indexName();              return  smartMapper.fieldMappers().mapper().names().indexName();  }  return  name;  }  public  MapperService.SmartNameFieldMappers  smartFieldMappers(String  name)  {  return  mapperService.smartName(name);  }  }  	return  smartMapper.fieldMappers().mapper().names().indexName();  
elasticsearch_9903c2480ea36dd350493f1f455fba82ab35e7ef	buggy:  return  new  File(new  File(env.homeFile(),   "config "),  name);  context:  File  extractedDir(Environment  env)  {  return  new  File(env.pluginsFile(),  name);  }  File  binDir(Environment  env)  {  return  new  File(new  File(env.homeFile(),   "bin "),  name);  }  File  configDir(Environment  env)  {              return  new  File(new  File(env.homeFile(),   "config "),  name);              return  new  File(env.configFile(),  name);  }  static  PluginHandle  parse(String  name)  {  String[]  elements  =  name.split( "/ ");  String  repo  =  elements[0];  String  user  =  null;  String  version  =  null;  	return  new  File(env.configFile(),  name);  
libgdx_71144438e64c1b7579be49521104d5f0425c5f09	buggy:  existing.aliases.add(rect);  context:  }  rect.name  =  name;  rect.index  =  index;  if  (settings.alias)  {  String  crc  =  hash(rect.image);  Rect  existing  =  crcs.get(crc);  if  (existing  !=  null)  {  existing.aliases.add(rect);  existing.aliases.add(rect.name);  return;  }  crcs.put(crc,  rect);  }  rects.add(rect);  }  	existing.aliases.add(rect.name);  
libgdx_1ab6849614157115963e631247b28b6cf2120db2	buggy:  new  LwjglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  true);  context:  ++  libgdx_1ab6849614157115963e631247b28b6cf2120db2_5285.java  package  com.dozingcatsoftware.bouncy;  public  class  BouncyDesktop  {  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  true);  new  LwjglApplication(new  Bouncy(),   "Bouncy ",  320,  480);  }  }  	new  LwjglApplication(new  Bouncy(),   "Bouncy ",  320,  480);  
elasticsearch_da938a659d3f5459167ea7f39eade00e004b66b4	buggy:  clusterService.submitStateUpdateTask( "cluster_update_settings ",  Priority.URGENT,  new  AckedClusterStateUpdateTask()  {  context:  protected  ClusterUpdateSettingsResponse  newResponse()  {  return  new  ClusterUpdateSettingsResponse();  }  protected  void  masterOperation(final  ClusterUpdateSettingsRequest  request,  final  ClusterState  state,  final  ActionListener<ClusterUpdateSettingsResponse>  listener)  throws  ElasticsearchException  {  final  ImmutableSettings.Builder  transientUpdates  =  ImmutableSettings.settingsBuilder();  final  ImmutableSettings.Builder  persistentUpdates  =  ImmutableSettings.settingsBuilder();          clusterService.submitStateUpdateTask( "cluster_update_settings ",  Priority.URGENT,  new  AckedClusterStateUpdateTask()  {          clusterService.submitStateUpdateTask( "cluster_update_settings ",  Priority.IMMEDIATE,  new  AckedClusterStateUpdateTask()  {  private  volatile  boolean  changed  =  false;  public  boolean  mustAck(DiscoveryNode  discoveryNode)  {  return  true;  }  	clusterService.submitStateUpdateTask( "cluster_update_settings ",  Priority.IMMEDIATE,  new  AckedClusterStateUpdateTask()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<V<byte[]>>  vals  =  new  ArrayList<V<byte[]>>(limit);  context:  public  void  testDestroyWhenOverCapacity()  {  Recycler<byte[]>  r  =  newRecycler(limit);  Recycler.V<byte[]>  o  =  r.obtain();  byte[]  data  =  o.v();  assertFresh(data);          List<V<byte[]>>  vals  =  new  ArrayList<V<byte[]>>(limit);          List<V<byte[]>>  vals  =  new  ArrayList<>(limit);  for  (int  i  =  0;  i  <  limit  ;  ++i)  {  vals.add(r.obtain());  }  for  (V<byte[]>  v:  vals)  {  v.release();  }  	List<V<byte[]>>  vals  =  new  ArrayList<>(limit);  
libgdx_fb745b16180e0e2095d4d99664f785b99966c1d5	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  960,  640,  false  );  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  960,  640,  false  );  new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamTest(),   "Debug  Test ",  600,  320,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamTest(),   "Debug  Test ",  600,  320,  false  );  
elasticsearch_103f587be108429c6bf272e345c4820f4895e5b6	buggy:  .createParser(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength()).mapAndClose();  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  PutIndexTemplateRequest  putRequest  =  new  PutIndexTemplateRequest(request.param( "name "));  try  {  putRequest.create(request.paramAsBoolean( "create ",  false));  putRequest.cause(request.param( "cause ",   " "));  putRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));  Map<String,  Object>  source  =  XContentFactory.xContent(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength())                      .createParser(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength()).mapAndClose();                      .createParser(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength()).mapOrderedAndClose();  if  (source.containsKey( "template "))  {  putRequest.template(source.get( "template ").toString());  }  if  (source.containsKey( "order "))  {  putRequest.order(XContentMapValues.nodeIntegerValue(source.get( "order "),  putRequest.order()));  }  if  (source.containsKey( "settings "))  {  	.createParser(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength()).mapOrderedAndClose();  
libgdx_482a99387e0713e047cc0e1407672842b2496258	buggy:  table.align(Align.CENTER  |  Align.TOP);  context:  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  final  Slider  volume  =  new  Slider(0.1f,  1,  0.1f,  skin);  volume.setValue(1);  final  Label  volumeValue  =  new  Label( "1.0 ",  skin);  Table  table  =  new  Table();  final  Slider  pan  =  new  Slider(-1f,  1f,  0.1f,  skin);  pan.setValue(0);  final  Label  panValue  =  new  Label( "0.0 ",  skin);  table.setFillParent(true);  table.align(Align.CENTER  |  Align.TOP);  table.align(Align.center  |  Align.top);  table.add(play);  table.add(stop);  table.row();  table.add(new  Label( "Pitch ",  skin));  table.add(pitch);  table.add(pitchValue);  table.row();  table.add(new  Label( "Volume ",  skin));  	table.align(Align.center  |  Align.top);  
libgdx_4da179382de208b5d63ca0b017cb2aa25ba4461b	buggy:  Element  properties  =  element.getChildByName( "properties ");  context:  tileset.putTile(id++,  tile);  }  }  Array<Element>  tileElements  =  element.getChildrenByName( "tile ");  for  (Element  tileElement  :  tileElements)  {  int  localtid  =  tileElement.getIntAttribute( "id ",  0);  TiledMapTile  tile  =  tileset.getTile(firstgid  +  localtid);  if  (tile!=  null)  {  Element  properties  =  element.getChildByName( "properties ");  Element  properties  =  tileElement.getChildByName( "properties ");  if  (properties  !=  null)  {  loadProperties(tile.getProperties(),  properties);  }  }  }  Element  properties  =  element.getChildByName( "properties ");  if  (properties  !=  null)  {  	Element  properties  =  tileElement.getChildByName( "properties ");  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  request.timeout(timeout);  context:  request.removeAlias(index,  alias);  return  this;  }  public  IndicesAliasesRequestBuilder  setTimeout(TimeValue  timeout)  {          request.timeout(timeout);          request.setTimeout(timeout);  return  this;  }  protected  void  doExecute(ActionListener<IndicesAliasesResponse>  listener)  {  ((IndicesAdminClient)  client).aliases(request,  listener);  }  }  	request.setTimeout(timeout);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  ThreadPool  threadPool  =  cluster().getDataNodeInstance(ThreadPool.class);  context:  public  class  SimpleThreadPoolTests  extends  ElasticsearchIntegrationTest  {  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.settingsBuilder().put( "threadpool.search.type ",   "cached ").put(super.nodeSettings(nodeOrdinal)).build();  }  public  void  testUpdatingThreadPoolSettings()  throws  Exception  {          ThreadPool  threadPool  =  cluster().getDataNodeInstance(ThreadPool.class);          ThreadPool  threadPool  =  internalCluster().getDataNodeInstance(ThreadPool.class);  assertThat(((ThreadPoolExecutor)  threadPool.executor(Names.SEARCH)).getKeepAliveTime(TimeUnit.MINUTES),  equalTo(5L));  client().admin().cluster().prepareUpdateSettings().setTransientSettings(settingsBuilder().put( "threadpool.search.keep_alive ",   "10m ").build()).execute().actionGet();  assertThat(((ThreadPoolExecutor)  threadPool.executor(Names.SEARCH)).getKeepAliveTime(TimeUnit.MINUTES),  equalTo(10L));  final  CyclicBarrier  barrier  =  new  CyclicBarrier(2);  Executor  oldExecutor  =  threadPool.executor(Names.SEARCH);  	ThreadPool  threadPool  =  internalCluster().getDataNodeInstance(ThreadPool.class);  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  shard.refresh(new  Engine.Refresh().force(true).source( "percolator_load_queries "));  context:  }  }  private  boolean  hasPercolatorType(IndexShard  indexShard)  {  ShardId  otherShardId  =  indexShard.shardId();  return  shardId.equals(otherShardId)  &&  mapperService.hasMapping(PercolatorService.Constants.TYPE_NAME);  }  private  void  loadQueries(IndexShard  shard)  {  try  {                  shard.refresh(new  Engine.Refresh().force(true).source( "percolator_load_queries "));                  shard.refresh(new  Engine.Refresh( "percolator_load_queries ").force(true));  Engine.Searcher  searcher  =  shard.acquireSearcher( "percolator_load_queries ");  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.Constants.TYPE_NAME))  )  );  QueriesLoaderCollector  queries  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  	shard.refresh(new  Engine.Refresh( "percolator_load_queries ").force(true));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  map.release();  context:  Arrays.sort(values,  (Comparator)  comparatorType.comparator());  List<FullEntry>  ordered  =  new  ArrayList<>(map.v().size());  for  (int  i  =  0;  i  <  map.v().size();  i++)  {  FullEntry  value  =  (FullEntry)  values[i];  if  (value  ==  null)  {  break;  }  ordered.add(value);  }          map.release();          map.close();  InternalFullHistogramFacet  ret  =  new  InternalFullHistogramFacet(getName());  ret.comparatorType  =  comparatorType;  ret.entries  =  ordered;  return  ret;  }  	map.close();  
elasticsearch_942b427940f8dbc3695e391e2912969ded5625d8	buggy:  clusterHealthResponse  =  client( "node1 ").admin().cluster().prepareHealth().setWaitForNodes( "2 ").execute().actionGet();  context:  closeNode(masterNodeName);  Thread.sleep(200);  state  =  client(nonMasterNodeName).admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(true));  startNode(masterNodeName,  settings);          clusterHealthResponse  =  client( "node1 ").admin().cluster().prepareHealth().setWaitForNodes( "2 ").execute().actionGet();          clusterHealthResponse  =  client( "node1 ").admin().cluster().prepareHealth().setWaitForYellowStatus().setWaitForNodes( "2 ").execute().actionGet();  assertThat(clusterHealthResponse.timedOut(),  equalTo(false));  state  =  client( "node1 ").admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(false));  state  =  client( "node2 ").admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(false));  state  =  client( "node1 ").admin().cluster().prepareState().execute().actionGet().state();  	clusterHealthResponse  =  client( "node1 ").admin().cluster().prepareHealth().setWaitForYellowStatus().setWaitForNodes( "2 ").execute().actionGet();  
elasticsearch_5746c50ef9f2a9988ef7e5b36e5dd238edca4f47	buggy:  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus()).actionGet();  context:  assertThat(waitForShardDeletion(TimeValue.timeValueSeconds(1),   "server3 ",   "test ",  0),  equalTo(false));  File  server2Shard  =  shardDirectory( "server2 ",   "test ",  0);  closeNode( "server2 ");  assertThat(server2Shard.exists(),  equalTo(true));          clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus()).actionGet();          clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus().setWaitForNodes( "2 ")).actionGet();  assertThat(shardDirectory( "server1 ",   "test ",  0).exists(),  equalTo(true));  assertThat(server2Shard.exists(),  equalTo(true));  assertThat(shardDirectory( "server3 ",   "test ",  0).exists(),  equalTo(true));  	clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().setWaitForGreenStatus().setWaitForNodes( "2 ")).actionGet();  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(missing( "missing ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  Missing  missing  =  bucket.getAggregations().get( "missing ");  assertThat(missing,  Matchers.notNullValue());  assertThat(missing.getName(),  equalTo( "missing "));  assertThat(missing.getDocCount(),  is(0l));  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
libgdx_3acb4cfe293cec597a89678bf92cf1ecbe96ce00	buggy:  return  MathUtils.PI  *  (this.width  *  this.height)  /  2;  context:  public  Ellipse  setSize  (float  width,  float  height)  {  this.width  =  width;  this.height  =  height;  return  this;  }  public  float  area  ()  {  return  MathUtils.PI  *  (this.width  *  this.height)  /  2;  return  MathUtils.PI  *  (this.width  *  this.height)  /  4;  }  public  float  circumference  ()  {  float  a  =  this.width  /  2;  	return  MathUtils.PI  *  (this.width  *  this.height)  /  4;  
elasticsearch_cf81e19ccebf2daa8a10286df19f6deeadced35d	buggy:  table.addCell( "primaries.completion.size ",   "default:false;text-align:right;desc:size  of  completion ");  context:  table.startHeaders();  table.addCell( "health ",   "desc:current  health  status ");  table.addCell( "index ",   "desc:index  name ");  table.addCell( "pri ",   "text-align:right;desc:number  of  primary  shards ");  table.addCell( "rep ",   "text-align:right;desc:number  of  replica  shards ");  table.addCell( "docs.count ",   "text-align:right;desc:available  docs ");  table.addCell( "docs.deleted ",   "text-align:right;desc:deleted  docs ");  table.addCell( "primaries.store.size ",   "text-align:right;desc:store  size  of  primaries ");  table.addCell( "total.store.size ",   "text-align:right;desc:store  size  of  primaries  &  replicas ");          table.addCell( "primaries.completion.size ",   "default:false;text-align:right;desc:size  of  completion ");          table.addCell( "primaries.completion.size ",   "alias:pcs,primariesCompletionSize;default:false;text-align:right;desc:size  of  completion ");  table.addCell( "primaries.fielddata.memory_size ",   "default:false;text-align:right;desc:used  fielddata  cache ");  table.addCell( "primaries.fielddata.evictions ",   "default:false;text-align:right;desc:fielddata  evictions ");  table.addCell( "primaries.filter_cache.memory_size ",   "default:false;text-align:right;desc:used  filter  cache ");  table.addCell( "primaries.filter_cache.evictions ",   "default:false;text-align:right;desc:filter  cache  evictions ");  table.addCell( "primaries.flush.total ",   "default:false;text-align:right;desc:number  of  flushes ");  	table.addCell( "primaries.completion.size ",   "alias:pcs,primariesCompletionSize;default:false;text-align:right;desc:size  of  completion ");  
libgdx_8e1efc1f080e24b2987d46e75753fda266f8f125	buggy:  return  CollisionJNI.btOverlapCallback_processOverlap(swigCPtr,  this,  btBroadphasePair.getCPtr(pair),  pair);  context:  swigCMemOwn  =  false;  CollisionJNI.btOverlapCallback_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  CollisionJNI.btOverlapCallback_change_ownership(this,  swigCPtr,  true);  }  public  boolean  processOverlap(btBroadphasePair  pair)  {      return  CollisionJNI.btOverlapCallback_processOverlap(swigCPtr,  this,  btBroadphasePair.getCPtr(pair),  pair);      return  CollisionJNI.btOverlapCallback_processOverlap(swigCPtr,  this,  pair);  }  public  btOverlapCallback()  {  this(CollisionJNI.new_btOverlapCallback(),  true);  CollisionJNI.btOverlapCallback_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	return  CollisionJNI.btOverlapCallback_processOverlap(swigCPtr,  this,  pair);  
elasticsearch_a1d58bf486423ce0b13e2bbb4579c403b55e3793	buggy:  client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "type ")  context:  long  PARENT_COUNT  =  SizeValue.parseSizeValue( "10M ").singles();  int  BATCH  =  100;  int  QUERY_WARMUP  =  5;  int  QUERY_COUNT  =  25;  String  indexName  =   "test ";  client.admin().cluster().prepareHealth(indexName).setWaitForGreenStatus().setTimeout( "10s ").execute().actionGet();  try  {  client.admin().indices().create(createIndexRequest(indexName)).actionGet();              client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "type ")              client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "child ")  .startObject( "_parent ").field( "type ",   "parent ").endObject()  .endObject().endObject()).execute().actionGet();  Thread.sleep(5000);  StopWatch  stopWatch  =  new  StopWatch().start();  long  ITERS  =  PARENT_COUNT  /  BATCH;  	client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "child ")  
elasticsearch_e33dbcd93e3b1d0beac7e1629a790a28e5cab749	buggy:  return  termFactory.createTerm(value);  context:  return  value(field);  }  return  value;  }  public  Term  term(String  value)  {          return  termFactory.createTerm(value);          return  names().createIndexNameTerm(value);  }  super.parse(context);  }  	return  names().createIndexNameTerm(value);  
elasticsearch_bf7ace79ea910f1e307ddff263e382427fe4479a	buggy:  return   "IndexAction  [ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "],  source  [ "  +  Unicode.fromBytes(source)  +   "] ";  context:  }  else  {  out.writeBoolean(true);  out.writeUTF(id);  }  out.writeInt(source.length);  out.write(source);  out.writeByte(opType.id());  }          return   "IndexAction  [ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "],  source  [ "  +  Unicode.fromBytes(source)  +   "] ";          return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "],  source[ "  +  Unicode.fromBytes(source)  +   "] ";  }  }  	return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "],  source[ "  +  Unicode.fromBytes(source)  +   "] ";  
libgdx_2b238e67aa265924c1aa7f31a9e27488471fc876	buggy:  return  c2Type.isAssignableFrom(c1Type);  context:  static  public  boolean  isInstance  (Class  c,  Object  obj)  {  return  isAssignableFrom(c,  obj.getClass());  }  static  public  boolean  isAssignableFrom  (Class  c1,  Class  c2)  {  Type  c1Type  =  ReflectionCache.getType(c1);  Type  c2Type  =  ReflectionCache.getType(c2);  return  c2Type.isAssignableFrom(c1Type);  return  c1Type.isAssignableFrom(c2Type);  }  static  public  boolean  isMemberClass  (Class  c)  {  return  ReflectionCache.getType(c).isMemberClass();  }  	return  c1Type.isAssignableFrom(c2Type);  
elasticsearch_e76eb228b2d3105feee2dbe5c735e3733fbedf7d	buggy:   "You  must  call  get  with  all  required  flags!  Instead  of  _index['int_payload_field'].get('b',  _FREQUENCIES)  and  _index['int_payload_field'].get('b',  _POSITIONS)  call  _index['int_payload_field'].get('b',  _FREQUENCIES  |  _POSITIONS)  once];   "),  context:  String  script  =   "term  =  _index['int_payload_field']['b'];  return  _index['int_payload_field'].get('b',  _POSITIONS).tf(); ";  try  {  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).addScriptField( "tvtest ",  script).execute().actionGet();  }  catch  (SearchPhaseExecutionException  e)  {  assertThat(   "got:   "  +  e.getDetailedMessage(),  e.getDetailedMessage()  .indexOf(                                       "You  must  call  get  with  all  required  flags!  Instead  of  _index['int_payload_field'].get('b',  _FREQUENCIES)  and  _index['int_payload_field'].get('b',  _POSITIONS)  call  _index['int_payload_field'].get('b',  _FREQUENCIES  |  _POSITIONS)  once];   "),                                       "You  must  call  get  with  all  required  flags!  Instead  of  _index['int_payload_field'].get('b',  _FREQUENCIES)  and  _index['int_payload_field'].get('b',  _POSITIONS)  call  _index['int_payload_field'].get('b',  _FREQUENCIES  |  _POSITIONS)  once] "),  Matchers.greaterThan(-1));  }  script  =   "term  =  _index['int_payload_field'].get('b',  _POSITIONS  |  _FREQUENCIES);return  _index['int_payload_field']['b'].tf(); ";  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).addScriptField( "tvtest ",  script).execute().actionGet();  }  	 "You  must  call  get  with  all  required  flags!  Instead  of    _index['int_payload_field'].get('b',  _FREQUENCIES)  and  _index['int_payload_field'].get('b',  _POSITIONS)  call    _index['int_payload_field'].get('b',  _FREQUENCIES  |  _POSITIONS)    once] "),  
elasticsearch_66825ac851a2578686eefca08f1900bf86f3d443	buggy:  addDocValue(context,  value);  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomByteNumericField  field  =  new  CustomByteNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              addDocValue(context,  value);              addDocValue(context,  fields,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  fields,  value);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  field.setBoost(context.fieldBoost(this));  context:  if  (ipAsString  ==  null)  {  return;  }  if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  ipAsString,  boost);  }  final  long  value  =  ipToLong(ipAsString);  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);              field.setBoost(context.fieldBoost(this));              field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {  addDocValue(context,  value);  }  }  	field.setBoost(boost);  
elasticsearch_25bd9cecd066e7920776eef0885b1c4a905a3156	buggy:  suggest  =  Suggest.readSuggest(in);  context:  super.readFrom(in);  id  =  in.readLong();  from  =  in.readVInt();  size  =  in.readVInt();  topDocs  =  readTopDocs(in);  if  (in.readBoolean())  {  facets  =  InternalFacets.readFacets(in);  }  if  (in.readBoolean())  {              suggest  =  Suggest.readSuggest(in);              suggest  =  Suggest.readSuggest(Suggest.Fields.SUGGEST,  in);  }  searchTimedOut  =  in.readBoolean();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeLong(id);  	suggest  =  Suggest.readSuggest(Suggest.Fields.SUGGEST,  in);  
libgdx_67b527fbb442dda91442ca6bac8e0c76a40bf37f	buggy:  String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize/ "};  context:  cppFlags  +=   "  -fno-rtti ";  cppFlags  +=   "  -DBT_NO_PROFILE ";  String[]  excludes  =  { "src/bullet/BulletMultiThreaded/GpuSoftBodySolvers/** "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize/ "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/Serialize/ "};  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  win32home.cExcludes  =  win32home.cppExcludes  =  excludes;  win32home.headerDirs  =  headers;  win32home.cppFlags  +=  cppFlags;  	String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/Serialize/ "};  
libgdx_ecb6beda12d2109dfeb0e70764ca1e621e0580ce	buggy:  project.files.add(new  ProjectFile( "android/build.gradle "));  context:  project.files.add(new  ProjectFile( "android/assets/badlogic.jpg ",  false));  project.files.add(new  ProjectFile( "android/res/values/strings.xml "));  project.files.add(new  ProjectFile( "android/res/values/styles.xml ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-hdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-mdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-xhdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-xxhdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/src/AndroidLauncher ",   "android/src/ "  +  packageDir  +   "/android/AndroidLauncher.java ",  true));  project.files.add(new  ProjectFile( "android/AndroidManifest.xml "));  project.files.add(new  ProjectFile( "android/build.gradle "));  project.files.add(new  ProjectFile( "android/build.gradle ",  true));  project.files.add(new  ProjectFile( "android/ic_launcher-web.png ",  false));  project.files.add(new  ProjectFile( "android/proguard-project.txt ",  false));  project.files.add(new  ProjectFile( "android/project.properties ",  false));  project.files.add(new  ProjectFile( "gwt/build.gradle "));  project.files.add(new  ProjectFile( "gwt/src/GwtLauncher ",   "gwt/src/ "  +  packageDir  +   "/client/GwtLauncher.java ",  true));  project.files.add(new  ProjectFile( "gwt/GdxDefinition ",   "gwt/src/ "  +  packageDir  +   "/GdxDefinition.gwt.xml ",  true));  	project.files.add(new  ProjectFile( "android/build.gradle ",  true));  
libgdx_4279401a12b90b72315e40f6a339619cca70b067	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (long[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (long[]  array,  int  offset,  int  length)  {  long[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  long  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length;  
libgdx_521f685bda770c894eea270f455fa07509d895d1	buggy:  rect((short)(vindex-4),  (short)(vindex-2),  (short)(vindex-1),  (short)(vindex-3));  //  FIXME  don't  duplicate  lines  and  points  context:  curr1.position.y  =  -hh;  curr1.uv.set(u,  1);  curr2.position.set(curr1.position);  curr2.normal.set(curr1.normal);  curr2.position.y  =  hh;  curr2.uv.set(u,  0);  vertex(curr1);  vertex(curr2);  if  (i  ==  0)  continue;  rect((short)(vindex-4),  (short)(vindex-2),  (short)(vindex-1),  (short)(vindex-3));  //  FIXME  don't  duplicate  lines  and  points  rect((short)(vindex-3),  (short)(vindex-1),  (short)(vindex-2),  (short)(vindex-4));  //  FIXME  don't  duplicate  lines  and  points  }  }  public  void  cone(float  width,  float  height,  float  depth,  int  divisions)  {  final  float  hw  =  width  *  0.5f;  final  float  hh  =  height  *  0.5f;  	rect((short)(vindex-3),  (short)(vindex-1),  (short)(vindex-2),  (short)(vindex-4));  //  FIXME  don't  duplicate  lines  and  points  
libgdx_eb223925ec588e266b3644f8345b3071c8b63ec7	buggy:  return  setFromAxis(axis.z,  axis.y,  axis.z,  angle);  context:  public  Quaternion  setFromAxis(Vector3  axis,  float  angle)  {  return  setFromAxis(axis.z,  axis.y,  axis.z,  angle);  return  setFromAxis(axis.x,  axis.y,  axis.z,  angle);  }  	return  setFromAxis(axis.x,  axis.y,  axis.z,  angle);  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  StreamOutput  stream  =  cachedEntry.cachedHandles();  context:  public  long  serverOpen()  {  return  0;  }  public  <T  extends  Streamable>  void  sendRequest(final  DiscoveryNode  node,  final  long  requestId,  final  String  action,  final  Streamable  message,  TransportRequestOptions  options)  throws  IOException,  TransportException  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {              StreamOutput  stream  =  cachedEntry.cachedHandles();              StreamOutput  stream  =  cachedEntry.handles();  stream.writeLong(requestId);  byte  status  =  0;  status  =  TransportStreams.statusSetRequest(status);  stream.writeByte(status);  //  0  for  request,  1  for  response.  stream.writeUTF(action);  message.writeTo(stream);  	StreamOutput  stream  =  cachedEntry.handles();  
libgdx_d650b1c8f3d6d32b44945de72891895fb7f58361	buggy:  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  context:  package  com.badlogic.gdx.tests.lwjgl.box2d;  public  class  TestCollection  {  public  static  void  main  (String[]  argv)  {  LwjglApplication  app  =  new  LwjglApplication( "Simple  Test ",  480,  320,  false);  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  }  }  	app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<FieldMapper>  list  =  new  ArrayList<FieldMapper>(fieldMappers.length);  context:  public  FieldMappers  concat(FieldMapper  mapper)  {  FieldMapper[]  newMappers  =  new  FieldMapper[fieldMappers.length  +  1];  System.arraycopy(fieldMappers,  0,  newMappers,  0,  fieldMappers.length);  newMappers[fieldMappers.length]  =  mapper;  return  new  FieldMappers(newMappers);  }  public  FieldMappers  remove(FieldMapper  mapper)  {          ArrayList<FieldMapper>  list  =  new  ArrayList<FieldMapper>(fieldMappers.length);          ArrayList<FieldMapper>  list  =  new  ArrayList<>(fieldMappers.length);  for  (FieldMapper  fieldMapper  :  fieldMappers)  {  if  (!fieldMapper.equals(mapper))  {  //  identify  equality  list.add(fieldMapper);  }  }  return  new  FieldMappers(list.toArray(new  FieldMapper[list.size()]));  }  }  	ArrayList<FieldMapper>  list  =  new  ArrayList<>(fieldMappers.length);  
elasticsearch_a48c437ffb03dd08fd3ceede042c539f55bb2423	buggy:  logger.debug( "primary  shard  [{}]  is  not  yet  active  or  we  do  not  know  that  node  it  is  assigned  to  [{}].  Scheduling  a  retry. ",  shard.shardId(),  shard.currentNodeId());  context:  boolean  foundPrimary  =  false;  ShardRouting  shardX;  while  ((shardX  =  shardIt.nextOrNull())  !=  null)  {  final  ShardRouting  shard  =  shardX;  if  (!shard.primary())  {  continue;  }  if  (!shard.active()  ||  !clusterState.nodes().nodeExists(shard.currentNodeId()))  {                      logger.debug( "primary  shard  [{}]  is  not  yet  active  or  we  do  not  know  that  node  it  is  assigned  to  [{}].  Scheduling  a  retry. ",  shard.shardId(),  shard.currentNodeId());                      logger.debug( "primary  shard  [{}]  is  not  yet  active  or  we  do  not  know  the  node  it  is  assigned  to  [{}].  Scheduling  a  retry. ",  shard.shardId(),  shard.currentNodeId());  retry(fromClusterEvent,  null);  return  false;  }  if  (checkWriteConsistency)  {  WriteConsistencyLevel  consistencyLevel  =  defaultWriteConsistencyLevel;  if  (request.consistencyLevel()  !=  WriteConsistencyLevel.DEFAULT)  {  	logger.debug( "primary  shard  [{}]  is  not  yet  active  or  we  do  not  know  the  node  it  is  assigned  to  [{}].  Scheduling  a  retry. ",  shard.shardId(),  shard.currentNodeId());  
libgdx_22deb2e572586fd56b080714cd706501de3403b4	buggy:  listener.destroy();  context:  listener.resize(lastWidth,  lastHeight);  }  listener.render();  input.processEvents(null);  Display.update();  Display.sync(60);  }  listener.pause();  listener.destroy();  listener.dispose();  Display.destroy();  }  public  Audio  getAudio()  {  return  audio;  }  	listener.dispose();  
libgdx_8fb6db621f6a84ea8c6c5c5672c1c89f6eac9dbc	buggy:  String  value  =  property.getAttribute(name,  null);  context:  loadProperties(object.getProperties(),  properties);  }  layer.getObjects().addObject(object);  }  }  private  void  loadProperties(MapProperties  properties,  Element  element)  {  if  (element.getName().equals( "properties "))  {  for  (Element  property  :  element.getChildrenByName( "property "))  {  String  name  =  property.getAttribute( "name ",  null);  String  value  =  property.getAttribute(name,  null);  String  value  =  property.getAttribute( "value ",  null);  if  (value  ==  null)  {  value  =  property.getText();  }  properties.put(name,  value);  }  }  }  	String  value  =  property.getAttribute( "value ",  null);  
elasticsearch_fd80fcbca0699dcf276ea6acc0c283aa74d077a8	buggy:  sb.append(++index).append( ":   ").append(error);  context:  public  List<String>  validationErrors()  {  return  validationErrors;  }  StringBuilder  sb  =  new  StringBuilder();  sb.append( "Validation  Failed:   ");  int  index  =  0;  for  (String  error  :  validationErrors)  {              sb.append(++index).append( ":   ").append(error);              sb.append(++index).append( ":   ").append(error).append( "; ");  }  return  sb.toString();  }  }  	sb.append(++index).append( ":   ").append(error).append( "; ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  actions.put(action.name(),  new  ActionEntry<Request,  Response>(action,  transportAction,  supportTransportActions));  context:  public  <Request  extends  ActionRequest,  Response  extends  ActionResponse>  void  registerAction(GenericAction<Request,  Response>  action,  Class<?  extends  TransportAction<Request,  Response>>  transportAction,  Class...  supportTransportActions)  {          actions.put(action.name(),  new  ActionEntry<Request,  Response>(action,  transportAction,  supportTransportActions));          actions.put(action.name(),  new  ActionEntry<>(action,  transportAction,  supportTransportActions));  }  protected  void  configure()  {  registerAction(NodesInfoAction.INSTANCE,  TransportNodesInfoAction.class);  registerAction(NodesStatsAction.INSTANCE,  TransportNodesStatsAction.class);  registerAction(NodesShutdownAction.INSTANCE,  TransportNodesShutdownAction.class);  	actions.put(action.name(),  new  ActionEntry<>(action,  transportAction,  supportTransportActions));  
libgdx_8fceb9f8a9b110d3f1623291b6326bb22dada80b	buggy:  DefaultMutableTreeNode  htmlSrcAppGwtNode  =  nodes.get( "prj-html/src/MyGame.gwt.xml ");  context:  previousNode  =  node;  }  previousNode.add(androidSrcActivityNode);  }  else  {  androidSrcNode.add(androidSrcActivityNode);  }  DefaultMutableTreeNode  htmlSrcNode  =  nodes.get( "#DIR#prj-html/src ");  DefaultMutableTreeNode  htmlSrcAppGwtNode  =  nodes.get( "prj-html/src/MyGame.gwt.xml ");  DefaultMutableTreeNode  htmlSrcAppGwtNode  =  nodes.get( "prj-html/src/GwtDefinition.gwt.xml ");  DefaultMutableTreeNode  htmlSrcClientDirNode  =  nodes.get( "#DIR#prj-html/src/client ");  htmlSrcNode.removeAllChildren();  previousNode  =  htmlSrcNode;  if  (!cfg.getPackageName().trim().equals( " "))  {  String[]  paths  =  cfg.getPackageName().split( "\\. ");  for  (String  path  :  paths)  {  	DefaultMutableTreeNode  htmlSrcAppGwtNode  =  nodes.get( "prj-html/src/GwtDefinition.gwt.xml ");  
elasticsearch_1c5477d4eda4ccb2a6b2c84419cdb2841a9ce736	buggy:  .initializeEmpty(currentState.metaData().index(request.index));  context:  if  (request.state  ==  State.CLOSE)  {  //  no  need  to  do  shard  allocated  when  closed...  listener.onResponse(new  Response(true,  clusterState.metaData().index(request.index)));  return;  }  clusterService.submitStateUpdateTask( "reroute  after  index  [ "  +  request.index  +   "]  creation ",  new  ProcessedClusterStateUpdateTask()  {  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());  IndexRoutingTable.Builder  indexRoutingBuilder  =  new  IndexRoutingTable.Builder(request.index)                                  .initializeEmpty(currentState.metaData().index(request.index));                                  .initializeEmpty(currentState.metaData().index(request.index),  request.origin  ==  Request.Origin.API);  routingTableBuilder.add(indexRoutingBuilder);  RoutingAllocation.Result  routingResult  =  shardsAllocation.reroute(newClusterStateBuilder().state(currentState).routingTable(routingTableBuilder).build());  return  newClusterStateBuilder().state(currentState).routingResult(routingResult).build();  }  listener.onResponse(new  Response(true,  clusterState.metaData().index(request.index)));  	.initializeEmpty(currentState.metaData().index(request.index),  request.origin  ==  Request.Origin.API);  
libgdx_52eca501e35d1adbe360b83bfa9446fb72b7d0b1	buggy:  new  LwjglApplication(new  SuperJumper(),   "Super  Jumper ",  320,  480,  false);  context:  package  com.badlogicgames.superjumper;  public  class  SuperJumperDesktop  {  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  SuperJumper(),   "Super  Jumper ",  320,  480,  false);  new  LwjglApplication(new  SuperJumper(),   "Super  Jumper ",  320,  480);  }  }  	new  LwjglApplication(new  SuperJumper(),   "Super  Jumper ",  320,  480);  
libgdx_226527bf6c5daf0274cf4d557d86253dcfeffd12	buggy:  spriteBatch.draw(font.getSprite().getTexture(),  vertices,  0,  idx);  context:  int  intBits  =  ((int)(255  *  a)  <<  24)  |  ((int)(255  *  b)  <<  16)  |  ((int)(255  *  g)  <<  8)  |  ((int)(255  *  r));  float  color  =  Float.intBitsToFloat(intBits);  if  (color  ==  this.color)  return;  this.color  =  color;  float[]  vertices  =  this.vertices;  for  (int  i  =  2,  n  =  idx;  i  <  n;  i  +=  5)  vertices[i]  =  color;  }  public  void  draw  (SpriteBatch  spriteBatch)  {  spriteBatch.draw(font.getSprite().getTexture(),  vertices,  0,  idx);  spriteBatch.draw(font.getTextureRegion().getTexture(),  vertices,  0,  idx);  }  private  void  reset  (int  glyphCount)  {  x  =  0;  y  =  0;  idx  =  0;  int  vertexCount  =  glyphCount  *  20;  	spriteBatch.draw(font.getTextureRegion().getTexture(),  vertices,  0,  idx);  
elasticsearch_a5bef30be949ee30d33ec12a8c7b95dbc8424209	buggy:  reader.document(i,  visitor);  context:  checkDoc(document);  }  for  (int  i  =  0;  i  <  100;  i++)  {  int  doc  =  ThreadLocalRandom.current().nextInt(reader.maxDoc());  if  (liveDocs  !=  null  &&  !liveDocs.get(i))  {  continue;  }  Document  document  =  reader.document(doc);  checkDoc(document);  DocumentStoredFieldVisitor  visitor  =  new  DocumentStoredFieldVisitor( "id ",   "field ",   "count ");              reader.document(i,  visitor);              reader.document(doc,  visitor);  document  =  visitor.getDocument();  checkDoc(document);  }  }  private  void  checkDoc(Document  document)  {  String  id  =  document.get( "id ");  String  field  =  document.get( "field ");  	reader.document(doc,  visitor);  
libgdx_ede462abc14f1f6fedb0a533cab60bc816d8086d	buggy:  if(  packet.isColliding()  &&  iterations  <  20  )  context:  public  boolean  collide(  CollisionMesh  mesh,  Vector  position,  Vector  velocity,  float  displacementDistance  )  {  boolean  collided  =  false;  int  iterations  =  0;  while(  true  )  {  packet.set(  position,  velocity  );  CollisionDetection.collide(  mesh,  packet  );  if(  packet.isColliding()  &&  iterations  <  20  )  if(  packet.isColliding()  &&  iterations  <  5  )  {  collided  =  true;  response.respond(  packet,  displacementDistance  );  if(  velocity.len()  <  displacementDistance  )  break;  	if(  packet.isColliding()  &&  iterations  <  5  )  
libgdx_f99819603d9bb53ad2618f9eabd1678c0c80e784	buggy:  renderer.begin(ShapeType.Rectangle);  context:  }  if  (true)  {  alignmentWidth  =  280;  font.drawWrapped(spriteBatch,  text,  x,  viewHeight  -  y,  alignmentWidth,  HAlignment.RIGHT);  }  spriteBatch.end();  renderer.begin(ShapeType.Rectangle);  renderer.begin(ShapeType.Line);  renderer.rect(x,  viewHeight  -  y,  x  +  alignmentWidth,  300);  renderer.end();  }  public  boolean  needsGL20  ()  {  return  false;  }  	renderer.begin(ShapeType.Line);  
libgdx_0c8e6d5d7433db555180bd39f7eb4b9d2a7f3466	buggy:  for  (int  i  =  0;  i  <  1000;  i++)  {  context:  public  class  TextButtonTest  extends  GdxTest  {  private  Stage  stage;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false,  new  SpriteBatch());  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  for  (int  i  =  0;  i  <  1000;  i++)  {  for  (int  i  =  0;  i  <  500;  i++)  {  TextButton  t  =  new  TextButton( "Button "+i,  skin);  t.x  =  MathUtils.random(0,  Gdx.graphics.getWidth());  t.y  =  MathUtils.random(0,  Gdx.graphics.getHeight());  t.width  =  MathUtils.random(50,  200);  t.height  =  MathUtils.random(0,  100);  stage.addActor(t);  }  }  	for  (int  i  =  0;  i  <  500;  i++)  {  
elasticsearch_89e6b9cfc49a34e944abb0a7834ce1a3c9be4731	buggy:  .setFilter(termFilter( "tag ",   "blue "))  context:  TermsFacet  facet  =  searchResponse.getFacets().facet( "facet1 ");  assertThat(facet.getName(),  equalTo( "facet1 "));  assertThat(facet.getEntries().size(),  equalTo(2));  assertThat(facet.getEntries().get(0).getTerm().string(),  anyOf(equalTo( "green "),  equalTo( "blue ")));  assertThat(facet.getEntries().get(0).getCount(),  equalTo(1));  assertThat(facet.getEntries().get(1).getTerm().string(),  anyOf(equalTo( "green "),  equalTo( "blue ")));  assertThat(facet.getEntries().get(1).getCount(),  equalTo(1));  searchResponse  =  client().prepareSearch()  .setQuery(matchAllQuery())                      .setFilter(termFilter( "tag ",   "blue "))                      .setPostFilter(termFilter( "tag ",   "blue "))  .addFacet(termsFacet( "facet1 ").field( "tag ").size(10))  .execute().actionGet();  assertThat(searchResponse.getHits().hits().length,  equalTo(1));  facet  =  searchResponse.getFacets().facet( "facet1 ");  assertThat(facet.getName(),  equalTo( "facet1 "));  assertThat(facet.getEntries().size(),  equalTo(2));  assertThat(facet.getEntries().get(0).getTerm().string(),  anyOf(equalTo( "green "),  equalTo( "blue ")));  	.setPostFilter(termFilter( "tag ",   "blue "))  
elasticsearch_747ce36915b3cd1f3d868d778db42ee811c97a04	buggy:  }  catch  (Exception  e)  {  context:  try  {  onOperation(shard,  shardOperation(shardRequest));  }  catch  (Exception  e)  {  onOperation(shard,  shardIt,  e);  }  }  });  }  else  {  try  {  onOperation(shard,  shardOperation(shardRequest));                          }  catch  (Exception  e)  {                          }  catch  (Throwable  e)  {  onOperation(shard,  shardIt,  e);  }  }  }  else  {  DiscoveryNode  node  =  nodes.get(shard.currentNodeId());  if  (node  ==  null)  {  onOperation(shard,  shardIt,  null);  	}  catch  (Throwable  e)  {  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  ignoreMalformed);  context:  public  Builder  nullValue(double  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  DoubleFieldMapper  build(BuilderContext  context)  {  DoubleFieldMapper  fieldMapper  =  new  DoubleFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,                      ignoreMalformed);                      ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	ignoreMalformed(context));  
elasticsearch_948f0ef0da3042d6f98c67e602600f209cf6ae08	buggy:  if  (getResponse.empty())  {  context:  transportService.registerHandler(TransportActions.MORE_LIKE_THIS,  new  TransportHandler());  }  GetRequest  getRequest  =  getRequest(request.index())  .type(request.type())  .id(request.id())  .listenerThreaded(false);  getAction.execute(getRequest,  new  ActionListener<GetResponse>()  {                  if  (getResponse.empty())  {                  if  (getResponse.exists())  {  listener.onFailure(new  ElasticSearchException( "document  missing "));  return;  }  final  BoolJsonQueryBuilder  boolBuilder  =  boolQuery();  try  {  DocumentMapper  docMapper  =  indicesService.indexServiceSafe(request.index()).mapperService().documentMapper(request.type());  final  Set<String>  fields  =  Sets.newHashSet();  if  (request.fields()  !=  null)  {  	if  (getResponse.exists())  {  
libgdx_c9e39568b42bfe05307f5bdb7ed717536dde9033	buggy:  constraints.get(i).delete();  context:  }  constraint  =  new  btPoint2PointConstraint((btRigidBody)bar.body,  (btRigidBody)box1.body,  Vector3.tmp.set(5f,  -0.5f,  -0.5f),  Vector3.tmp2.set(0.5f,  0.5f,  -0.5f));  ((btDynamicsWorld)world.collisionWorld).addConstraint(constraint,  false);  constraints.add(constraint);  }  public  void  dispose  ()  {  for  (int  i  =  0;  i  <  constraints.size;  i++)  {  ((btDynamicsWorld)world.collisionWorld).removeConstraint(constraints.get(i));  constraints.get(i).delete();  constraints.get(i).dispose();  }  constraints.clear();  super.dispose();  }  public  boolean  tap  (float  x,  float  y,  int  count,  int  button)  {  shoot(x,  y);  	constraints.get(i).dispose();  
elasticsearch_1ed07a0c5077a16bff2fd30440d032543e1d6eaf	buggy:  return  ThreadPool.Names.SEARCH;  context:  public  TransportGetAction(Settings  settings,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService,  ThreadPool  threadPool)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  this.realtime  =  settings.getAsBoolean( "action.get.realtime ",  true);  }  protected  String  executor()  {          return  ThreadPool.Names.SEARCH;          return  ThreadPool.Names.GET;  }  protected  String  transportAction()  {  return  GetAction.NAME;  }  	return  ThreadPool.Names.GET;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  PrimaryResponse<DeleteResponse,  DeleteRequest>(shardRequest.request,  response,  null);  context:  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_delete ").force(false));  }  catch  (Exception  e)  {  }  }  DeleteResponse  response  =  new  DeleteResponse(request.index(),  request.type(),  request.id(),  delete.version(),  delete.found());          return  new  PrimaryResponse<DeleteResponse,  DeleteRequest>(shardRequest.request,  response,  null);          return  new  PrimaryResponse<>(shardRequest.request,  response,  null);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  DeleteRequest  request  =  shardRequest.request;  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  Engine.Delete  delete  =  indexShard.prepareDelete(request.type(),  request.id(),  request.version()).versionType(request.versionType())  .origin(Engine.Operation.Origin.REPLICA);  	return  new  PrimaryResponse<>(shardRequest.request,  response,  null);  
libgdx_836f93ec606186020ac2b03b1c0ddf27fc2a218f	buggy:  if  (worldVertices  ==  null  ||  worldVertices.length  <  localVertices.length)  worldVertices  =  new  float[localVertices.length];  context:  public  float[]  getTransformedVertices  ()  {  if  (!dirty)  return  worldVertices;  dirty  =  false;  final  float[]  localVertices  =  this.localVertices;  if  (worldVertices  ==  null  ||  worldVertices.length  <  localVertices.length)  worldVertices  =  new  float[localVertices.length];  if  (worldVertices  ==  null  ||  worldVertices.length  !=  localVertices.length)  worldVertices  =  new  float[localVertices.length];  final  float[]  worldVertices  =  this.worldVertices;  final  float  positionX  =  x;  final  float  positionY  =  y;  final  float  originX  =  this.originX;  final  float  originY  =  this.originY;  final  float  scaleX  =  this.scaleX;  final  float  scaleY  =  this.scaleY;  	if  (worldVertices  ==  null  ||  worldVertices.length  !=  localVertices.length)  worldVertices  =  new  float[localVertices.length];  
elasticsearch_2ba7c1d4a1844edb44cbea1a90a8e4652508b68d	buggy:  }  catch  (IOException  ex)  {  context:  public  final  Searcher  acquireSearcher(String  source)  throws  EngineException  {  SearcherManager  manager  =  this.searcherManager;  if  (manager  ==  null)  {  throw  new  EngineClosedException(shardId);  }  try  {  IndexSearcher  searcher  =  manager.acquire();  return  newSearcher(source,  searcher,  manager);          }  catch  (IOException  ex)  {          }  catch  (Throwable  ex)  {  throw  new  EngineException(shardId,  ex.getMessage());  }  }  protected  Searcher  newSearcher(String  source,  IndexSearcher  searcher,  SearcherManager  manager)  {  return  new  RobinSearcher(source,  searcher,  manager);  }  	}  catch  (Throwable  ex)  {  
libgdx_67822379726a2bedc4ccc5b883994c2b20199a94	buggy:  if  (!isCtrlPressed())  selected.clear();  context:  if  (selected.size  >  0  &&  rangeSelect  &&  multiple  &&  (Gdx.input.isKeyPressed(Keys.SHIFT_LEFT)  ||  Gdx.input.isKeyPressed(Keys.SHIFT_RIGHT)))  {  int  low  =  items.indexOf(getLastSelected(),  false);  int  high  =  items.indexOf(item,  false);  if  (low  >  high)  {  int  temp  =  low;  low  =  high;  high  =  temp;  }  snapshot();  if  (!isCtrlPressed())  selected.clear();  if  (!UIUtils.ctrl())  selected.clear();  for  (;  low  <=  high;  low++)  selected.add(items.get(low));  if  (fireChangeEvent())  revert();  cleanup();  return;  }  super.choose(item);  }  	if  (!UIUtils.ctrl())  selected.clear();  
elasticsearch_eddb378baec7a452928492fdcd1f037ff92ac1ca	buggy:  externalNodes[i]  =  externalNodes[i].start(client,  defaultSettings,  NODE_PREFIX  +  i,  cluster.getClusterName());  context:  public  synchronized  void  beforeTest(Random  random,  double  transportClientRatio)  throws  IOException  {  super.beforeTest(random,  transportClientRatio);  cluster.beforeTest(random,  transportClientRatio);  Settings  defaultSettings  =  cluster.getDefaultSettings();  final  Client  client  =  cluster.size()  >  0  ?  cluster.client()  :  cluster.clientNodeClient();  for  (int  i  =  0;  i  <  externalNodes.length;  i++)  {  if  (!externalNodes[i].running())  {  try  {                      externalNodes[i]  =  externalNodes[i].start(client,  defaultSettings,  NODE_PREFIX  +  i,  cluster.getClusterName());                      externalNodes[i]  =  externalNodes[i].start(client,  defaultSettings,  NODE_PREFIX  +  i,  cluster.getClusterName(),  i);  }  catch  (InterruptedException  e)  {  Thread.interrupted();  return;  }  }  externalNodes[i].reset(random.nextLong());  }  if  (size()  >  0)  {  	externalNodes[i]  =  externalNodes[i].start(client,  defaultSettings,  NODE_PREFIX  +  i,  cluster.getClusterName(),  i);  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();  context:  protected  Client  getClient1()  {  return  client( "server1 ");  }  protected  Client  getClient2()  {  return  client( "server2 ");  }          ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();          ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  Future<Response>  response  =  httpClient.preparePut( "http://localhost:9200/test/type1/1 ").setBody(source( "1 ",   "test ")).execute();  Map<String,  Object>  respMap  =  XContentFactory.xContent(response.get().getResponseBody()).createParser(response.get().getResponseBody()).map();  assertThat((Boolean)  respMap.get( "ok "),  equalTo(Boolean.TRUE));  assertThat((String)  respMap.get( "_id "),  equalTo( "1 "));  	ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  request.indices(state.metaData().concreteIndices(indicesOrAliases,  request.ignoreIndices(),  false));  context:  protected  CloseIndexResponse  newResponse()  {  return  new  CloseIndexResponse();  }  protected  void  doExecute(CloseIndexRequest  request,  ActionListener<CloseIndexResponse>  listener)  {  ClusterState  state  =  clusterService.state();  String[]  indicesOrAliases  =  request.indices();          request.indices(state.metaData().concreteIndices(indicesOrAliases,  request.ignoreIndices(),  false));          request.indices(state.metaData().concreteIndices(indicesOrAliases,  request.indicesOptions()));  if  (disableCloseAllIndices)  {  if  (state.metaData().isExplicitAllIndices(indicesOrAliases)  ||  state.metaData().isPatternMatchingAllIndices(indicesOrAliases,  request.indices()))  {  throw  new  ElasticSearchIllegalArgumentException( "closing  all  indices  is  disabled ");  }  }  	request.indices(state.metaData().concreteIndices(indicesOrAliases,  request.indicesOptions()));  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  context:   "uniform  sampler2D  u_texture;\n "  +   "void  main()                                  \n "   "{                                            \n "   "  gl_FragColor  =  v_color  *  texture2D(u_texture,  v_texCoords);\n "  +   "} ";  shader  =  new  ShaderProgram(vertexShader,  fragmentShader);  if  (shader.isCompiled()  ==  false)  {  Gdx.app.log( "ShaderTest ",  shader.getLog());  System.exit(0);  }  mesh  =  new  Mesh(true,  false,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  mesh  =  new  Mesh(true,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  Usage.Color,  4,   "a_color "),  new  VertexAttribute(Usage.TextureCoordinates,  2,   "a_texCoords "));  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  1,  0,  0,  1,  0,  0,  0.5f,  -0.5f,  0,  0,  1,  0,  1,  1,  0,  0,  0.5f,  0,  0,  0,  1,  1,  0.5f,  1});  mesh.setIndices(new  short[]  {0,  1,  2});  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  	mesh  =  new  Mesh(true,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  
elasticsearch_d06a15ec3e359c3704b52fbca9444f56cc8489ab	buggy:  }  else  if  ( "time_interval ".equals(fieldName))  {  context:  }  }  else  if  (token.isValue())  {  if  ( "field ".equals(fieldName))  {  keyField  =  parser.text();  }  else  if  ( "key_field ".equals(fieldName)  ||   "keyField ".equals(fieldName))  {  keyField  =  parser.text();  }  else  if  ( "value_field ".equals(fieldName)  ||   "valueField ".equals(fieldName))  {  valueField  =  parser.text();  }  else  if  ( "interval ".equals(fieldName))  {  interval  =  parser.longValue();                  }  else  if  ( "time_interval ".equals(fieldName))  {                  }  else  if  ( "time_interval ".equals(fieldName)  ||   "timeInterval ".equals(fieldName))  {  interval  =  TimeValue.parseTimeValue(parser.text(),  null).millis();  }  else  if  ( "key_script ".equals(fieldName)  ||   "keyScript ".equals(fieldName))  {  keyScript  =  parser.text();  }  else  if  ( "value_script ".equals(fieldName)  ||   "valueScript ".equals(fieldName))  {  valueScript  =  parser.text();  }  else  if  ( "order ".equals(fieldName)  ||   "comparator ".equals(fieldName))  {  comparatorType  =  HistogramFacet.ComparatorType.fromString(parser.text());  }  else  if  ( "lang ".equals(fieldName))  {  	}  else  if  ( "time_interval ".equals(fieldName)  ||   "timeInterval ".equals(fieldName))  {  
libgdx_50222242589599ab8c80dd16be7697a7fc5e110b	buggy:  return  (((PointLight)  light).priority  >  this.priority)  ?  -1  :  1;  context:  public  float  intensity;  protected  float  priority;  public  int  compareTo(Object  light)  {  return  (((PointLight)  light).priority  >  this.priority)  ?  -1  :  1;  return  (((PointLight)  light).priority  <  this.priority)  ?  -1  :  1;  }  }  	return  (((PointLight)  light).priority  <  this.priority)  ?  -1  :  1;  
elasticsearch_30d7b8de2fa043bdca3ca55026aa74f06d404a76	buggy:  lock.release();  context:  public  class  FsSnapshotLock  implements  SnapshotLock  {  private  final  Lock  lock;  public  FsSnapshotLock(Lock  lock)  {  this.lock  =  lock;  }  public  void  release()  {  try  {                  lock.release();                  lock.close();  }  catch  (IOException  e)  {  }  }  }  }  	lock.close();  
elasticsearch_1a46179c4e7bbfdd1350bda6a685168ef40c6681	buggy:  docSet  =  DocSets.convert(context.reader(),  filter.getDocIdSet(context));  context:  public  void  collect(int  doc)  throws  IOException  {  if  (docSet.get(doc))  {  collector.collect(doc);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  collector.setNextReader(context);          docSet  =  DocSets.convert(context.reader(),  filter.getDocIdSet(context));          docSet  =  DocSets.convert(context.reader(),  filter.getDocIdSet(context,  null));  }  public  boolean  acceptsDocsOutOfOrder()  {  return  collector.acceptsDocsOutOfOrder();  }  }  	docSet  =  DocSets.convert(context.reader(),  filter.getDocIdSet(context,  null));  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.indicesOptions());  context:  transportService.registerHandler(SearchAction.NAME,  new  TransportHandler());  }  protected  void  doExecute(SearchRequest  searchRequest,  ActionListener<SearchResponse>  listener)  {  if  (optimizeSingleShard  &&  searchRequest.searchType()  !=  SCAN  &&  searchRequest.searchType()  !=  COUNT)  {  try  {  ClusterState  clusterState  =  clusterService.state();                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.indicesOptions());                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indicesOptions(),  searchRequest.indices());  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(searchRequest.routing(),  searchRequest.indices());  int  shardCount  =  clusterService.operationRouting().searchShardsCount(clusterState,  searchRequest.indices(),  concreteIndices,  routingMap,  searchRequest.preference());  if  (shardCount  ==  1)  {  searchRequest.searchType(QUERY_AND_FETCH);  }  }  catch  (IndexMissingException  e)  {  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indicesOptions(),  searchRequest.indices());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e1)  {  context:  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  try  {  innerExecute(request,  listener);                          }  catch  (Exception  e1)  {                          }  catch  (Throwable  e1)  {  listener.onFailure(e1);  }  }  else  {  listener.onFailure(e);  }  }  });  }  else  {  	}  catch  (Throwable  e1)  {  
libgdx_d42a1f0204320a6695807273cc501e58fae4e3a5	buggy:  if(Display.wasResized()  ||  Display.getWidth()  !=  graphics.config.width  ||  Display.getHeight()  !=  graphics.config.height)  {  context:  int  width  =  graphics.canvas.getWidth();  int  height  =  graphics.canvas.getHeight();  if  (lastWidth  !=  width  ||  lastHeight  !=  height)  {  lastWidth  =  width;  lastHeight  =  height;  Gdx.gl.glViewport(0,  0,  lastWidth,  lastHeight);  listener.resize(lastWidth,  lastHeight);  shouldRender  =  true;  }  }  else  {  if(Display.wasResized()  ||  Display.getWidth()  !=  graphics.config.width  ||  Display.getHeight()  !=  graphics.config.height)  {  if(graphics.resize  ||  Display.wasResized()  ||  Display.getWidth()  !=  graphics.config.width  ||  Display.getHeight()  !=  graphics.config.height)  {  Gdx.gl.glViewport(0,  0,  Display.getWidth(),  Display.getHeight());  graphics.config.width  =  Display.getWidth();  graphics.config.height  =  Display.getHeight();  if(listener  !=  null)  listener.resize(Display.getWidth(),  Display.getHeight());  graphics.requestRendering();  }  }  	if(graphics.resize  ||  Display.wasResized()  ||  Display.getWidth()  !=  graphics.config.width  ||  Display.getHeight()  !=  graphics.config.height)  {  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices( "idx ");  context:  }  }  public  void  testDuelTerms()  throws  Exception  {  final  int  numDocs  =  scaledRandomIntBetween(10000,  20000);  final  int  maxNumTerms  =  randomIntBetween(10,  100000);  final  IntOpenHashSet  valuesSet  =  new  IntOpenHashSet();          wipeIndices( "idx ");          cluster().wipeIndices( "idx ");  prepareCreate( "idx ").addMapping( "type ",  jsonBuilder().startObject()  .startObject( "type ")  .startObject( "properties ")  .startObject( "string_values ")  .field( "type ",   "string ")  .field( "index ",   "not_analyzed ")  .endObject()  .startObject( "long_values ")  	cluster().wipeIndices( "idx ");  
libgdx_b1d09718e2c2ecc5164004595f53ca3ec76f4711	buggy:  return  null;  context:  private  final  MassData  massData  =  new  MassData(  );  public  MassData  getMassData()  {  jniGetMassData(addr,  tmp);  massData.mass  =  tmp[0];  massData.center.x  =  tmp[1];  massData.center.y  =  tmp[2];  massData.I  =  tmp[3];  return  null;  return  massData;  }  private  native  void  jniGetMassData(  long  addr,  float[]  massData  );  	return  massData;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullDateHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  cacheRecycler.longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector();  }  public  InternalFacet  buildFacet(String  facetName)  {          ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullDateHistogramFacet.FullEntry>(entries.v().size());          ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullDateHistogramFacet.FullEntry  value  =  (InternalFullDateHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }  	ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  
libgdx_cb99f8ce76bc62dbc7c9c4fab4b0f5c99ff5e9e4	buggy:  return  new  IOSApplication(new  DownloadTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  config.useAccelerometer  =  false;  return  new  IOSApplication(new  DownloadTest(),  config);  return  new  IOSApplication(new  Box2DTestCollection(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  Box2DTestCollection(),  config);  
elasticsearch_30929c3d01804c0db9b06cc62b126a6f18670b80	buggy:  logger.trace( "starting  recovery  to  {},  mark_as_relocated  {} ",  request.targetNode(),  request.markAsRelocated());  context:  this.fileChunkSize  =  componentSettings.getAsBytesSize( "file_chunk_size ",  new  ByteSizeValue(100,  ByteSizeUnit.KB));  this.translogBatchSize  =  componentSettings.getAsInt( "translog_batch_size ",  100);  this.compress  =  componentSettings.getAsBoolean( "compress ",  true);  transportService.registerHandler(Actions.START_RECOVERY,  new  StartRecoveryTransportRequestHandler());  }  private  RecoveryResponse  recover(final  StartRecoveryRequest  request)  {  final  InternalIndexShard  shard  =  (InternalIndexShard)  indicesService.indexServiceSafe(request.shardId().index().name()).shardSafe(request.shardId().id());          logger.trace( "starting  recovery  to  {},  mark_as_relocated  {} ",  request.targetNode(),  request.markAsRelocated());          logger.trace( "[{}][{}]  starting  recovery  to  {},  mark_as_relocated  {} ",  request.shardId().index().name(),  request.shardId().id(),  request.targetNode(),  request.markAsRelocated());  final  RecoveryResponse  response  =  new  RecoveryResponse();  shard.recover(new  Engine.RecoveryHandler()  {  long  totalSize  =  0;  long  existingTotalSize  =  0;  try  {  StopWatch  stopWatch  =  new  StopWatch().start();  	logger.trace( "[{}][{}]  starting  recovery  to  {},  mark_as_relocated  {} ",  request.shardId().index().name(),  request.shardId().id(),  request.targetNode(),  request.markAsRelocated());  
elasticsearch_deda7a37fcd046feaaa4eb9d11552c366cf30ea1	buggy:  .health(Requests.clusterHealthRequest().waitForYellowStatus().waitForEvents(Priority.LANGUID)).actionGet();  context:  .health(request).actionGet();  assertThat(actionGet.isTimedOut(),  equalTo(false));  if  (status  !=  null)  {  assertThat(actionGet.getStatus(),  equalTo(status));  }  return  actionGet.getStatus();  }  public  ClusterHealthStatus  ensureYellow()  {  ClusterHealthResponse  actionGet  =  client().admin().cluster()                  .health(Requests.clusterHealthRequest().waitForYellowStatus().waitForEvents(Priority.LANGUID)).actionGet();                  .health(Requests.clusterHealthRequest().waitForRelocatingShards(0).waitForYellowStatus().waitForEvents(Priority.LANGUID)).actionGet();  assertThat(actionGet.isTimedOut(),  equalTo(false));  return  actionGet.getStatus();  }  public  static  String  commaString(Iterable<String>  strings)  {  return  Joiner.on(',').join(strings);  }  	.health(Requests.clusterHealthRequest().waitForRelocatingShards(0).waitForYellowStatus().waitForEvents(Priority.LANGUID)).actionGet();  
libgdx_4c3bdba85a4bdf0d7cc6b338c3741dde3a3b8f13	buggy:  x  -=  renderOffset;  context:  super.touchDragged(event,  x,  y,  pointer);  lastBlink  =  0;  cursorOn  =  false;  setCursorPosition(x);  hasSelection  =  true;  }  private  void  setCursorPosition  (float  x)  {  lastBlink  =  0;  cursorOn  =  false;  x  -=  renderOffset;  x  -=  renderOffset  +  textOffset;  for  (int  i  =  0;  i  <  glyphPositions.size;  i++)  {  if  (glyphPositions.items[i]  >  x)  {  cursor  =  Math.max(0,  i  -  1);  return;  }  }  cursor  =  Math.max(0,  glyphPositions.size  -  1);  }  	x  -=  renderOffset  +  textOffset;  
libgdx_777834757f63b7171f81abd206b1b316a39528ff	buggy:  if  (keycode  !=  Input.Keys.KEYCODE_SPACE)  return  false;  context:  if  (character  ==  '+')  volume  +=  0.1f;  if  (character  ==  '-')  volume  -=  0.1f;  music.setVolume(volume);  return  false;  }  if  (keycode  !=  Input.Keys.KEYCODE_SPACE)  return  false;  if  (keycode  !=  Input.Keys.SPACE)  return  false;  if  (music.isPlaying())  music.pause();  else  music.play();  return  false;  }  	if  (keycode  !=  Input.Keys.SPACE)  return  false;  
elasticsearch_0bef2c66a996d7a30dc369df7db5e7bc34dcf292	buggy:  IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContent(parser);  context:  File  templatesDir  =  new  File(environment.configFile(),   "templates ");  if  (templatesDir.exists()  &&  templatesDir.isDirectory())  {  File[]  templatesFiles  =  templatesDir.listFiles();  if  (templatesFiles  !=  null)  {  for  (File  templatesFile  :  templatesFiles)  {  XContentParser  parser  =  null;  try  {  byte[]  templatesData  =  Streams.copyToByteArray(templatesFile);  parser  =  XContentHelper.createParser(templatesData,  0,  templatesData.length);                          IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContent(parser);                          IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContentStandalone(parser);  if  (Regex.simpleMatch(template.template(),  request.index))  {  templates.add(template);  }  }  catch  (Exception  e)  {  }  finally  {  IOUtils.closeWhileHandlingException(parser);  }  	IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContentStandalone(parser);  
elasticsearch_d3e9506a1d9ec74ed7a7e29a58c045cec081881b	buggy:  throw  new  EsRejectedExecutionException();  context:  public  class  EsAbortPolicy  implements  RejectedExecutionHandler  {  public  static  final  EsAbortPolicy  INSTANCE  =  new  EsAbortPolicy();  public  void  rejectedExecution(Runnable  r,  ThreadPoolExecutor  executor)  {          throw  new  EsRejectedExecutionException();          throw  new  EsRejectedExecutionException( "rejected  execution  of  [ "  +  r.getClass().getName()  +   "] ");  }  }  	throw  new  EsRejectedExecutionException( "rejected  execution  of  [ "  +  r.getClass().getName()  +   "] ");  
elasticsearch_9b02b5061ba17d3ef8004e7f5076182bc1f19845	buggy:  return  PagedBytesAtomicFieldData.empty();  context:  return  loadDirect(context);  }  public  AtomicFieldData.WithOrdinals  loadDirect(AtomicReaderContext  context)  {  ParentChildAtomicFieldData  parentChildAtomicFieldData  =  ParentChildIndexFieldData.this.load(context);  AtomicFieldData.WithOrdinals  typeAfd  =  parentChildAtomicFieldData.getAtomicFieldData(type);  if(typeAfd  !=  null)  {  return  typeAfd;  }  else  {                      return  PagedBytesAtomicFieldData.empty();                      return  AtomicFieldData.WithOrdinals.EMPTY;  }  }  public  WithOrdinals  loadGlobal(IndexReader  indexReader)  {  return  this;  }  	return  AtomicFieldData.WithOrdinals.EMPTY;  
libgdx_34ed5fbfe5d918ed411939d351930b0ab1457dd2	buggy:  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  context:  final  Mesh  mesh;  ArrayList<VertexAttribute>  attributes  =  new  ArrayList<VertexAttribute>();  attributes  .add(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE));  if  (hasNorms)  attributes  .add(new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE));  if  (hasUVs)  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  mesh  =  new  Mesh(true,  numFaces  *  3,  0,  attributes.toArray(new  VertexAttribute[attributes.size()]));  mesh.setVertices(finalVerts);  StillSubMesh  subMesh  =  new  StillSubMesh(group.name,  mesh,  GL10.GL_TRIANGLES);  subMesh.material  =  new  Material( "default ");  	ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  
libgdx_ad4ba1c7473f6d64a1cb52eb5cefbff49eb20142	buggy:  batch.draw(texture,  10,  100,  width,  height,  0,  0,  64,  32,  Color.WHITE,  false,  false  );  context:  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  }  public  void  render()  {  Gdx.gl10.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  float  width  =  (int)(Gdx.graphics.getPpcX()  *  2);  float  height  =  (int)(Gdx.graphics.getPpcY()  *  1);  batch.draw(texture,  10,  100,  width,  height,  0,  0,  64,  32,  Color.WHITE,  false,  false  );  batch.draw(texture,  10,  100,  width,  height,  0,  0,  64,  32,  false,  false  );  font.draw(batch,   "button  is  2x1  cm  ( "  +  width  +   "x "  +  height  +   "px),  ppi:  ( "  +  Gdx.graphics.getPpiX()  +   ", "  +  Gdx.graphics.getPpiY()  + "),  ppc:  ( "  +  Gdx.graphics.getPpcX()  +   ", "  +  Gdx.graphics.getPpcY()+   ") ",  10,  50);  batch.end();  }  public  boolean  needsGL20()  {  return  false;  }  	batch.draw(texture,  10,  100,  width,  height,  0,  0,  64,  32,  false,  false  );  
elasticsearch_96a185e107fd72900a7d7ed96c3c9031e226e451	buggy:  countRequest.querySource(RestActions.parseQuerySource(request));  context:  CountRequest  countRequest  =  new  CountRequest(RestActions.splitIndices(request.param( "index ")));  countRequest.listenerThreaded(false);  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);              countRequest.querySource(RestActions.parseQuerySource(request));              countRequest.query(RestActions.parseQuerySource(request));  countRequest.queryParserName(request.param( "query_parser_name "));  countRequest.queryHint(request.param( "query_hint "));  countRequest.minScore(request.paramAsFloat( "min_score ",  DEFAULT_MIN_SCORE));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  countRequest.types(splitTypes(typesParam));  }  }  catch  (Exception  e)  {  	countRequest.query(RestActions.parseQuerySource(request));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  final  LocalTransport  targetTransport  =  connectedNodes.get(node);  if  (targetTransport  ==  null)  {  throw  new  NodeNotConnectedException(node,   "Node  not  connected ");  }  final  byte[]  data  =  ((BytesStreamOutput)  stream.wrappedOut()).copiedByteArray();  transportServiceAdapter.sent(data.length);              threadPool.cached().execute(new  Runnable()  {              threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  targetTransport.messageReceived(data,  action,  LocalTransport.this,  requestId);  }  });  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  }  	threadPool.generic().execute(new  Runnable()  {  
libgdx_591316a437a56840fc61c40482439bc77683a99a	buggy:  return  new  IOSApplication(new  DownloadTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  class  InnerClass  {  }  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  DownloadTest(),  config);  return  new  IOSApplication(new  BulletTestCollection(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.drain();  }  }  	return  new  IOSApplication(new  BulletTestCollection(),  config);  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(sum( "sum ")))  context:  public  class  SumTests  extends  AbstractNumericTests  {  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(sum( "sum ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(sum( "sum ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(sum( "sum ")))  
elasticsearch_a15f149dc658f94ca812ed31b09c8694da18f762	buggy:  out.writeString(names[0]);  context:  names[0]  =  in.readString();  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  if  (out.getVersion().onOrAfter(Version.V_0_90_4))  {  out.writeStringArray(names);  }  else  {              out.writeString(names[0]);              out.writeString(names.length  ==  0  ?   "* "  :  names[0]);  }  }  }  	out.writeString(names.length  ==  0  ?   "* "  :  names[0]);  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  modules.add(new  IndexSettingsModule(indexSettings));  context:  Settings  indexSettings  =  settingsBuilder()  .put( "settingsType ",   "index ")  .put(this.settings)  .put(settings)  .classLoader(settings.getClassLoader())  .build();  ModulesBuilder  modules  =  new  ModulesBuilder();  modules.add(new  IndexNameModule(index));  modules.add(new  LocalNodeIdModule(localNodeId));          modules.add(new  IndexSettingsModule(indexSettings));          modules.add(new  IndexSettingsModule(index,  indexSettings));  modules.add(new  IndexPluginsModule(indexSettings,  pluginsService));  modules.add(new  IndexStoreModule(indexSettings));  modules.add(new  IndexEngineModule(indexSettings));  modules.add(new  AnalysisModule(indexSettings,  indicesAnalysisService));  modules.add(new  SimilarityModule(indexSettings));  modules.add(new  IndexCacheModule(indexSettings));  modules.add(new  IndexQueryParserModule(indexSettings));  modules.add(new  MapperServiceModule());  	modules.add(new  IndexSettingsModule(index,  indexSettings));  
libgdx_1ef17b58c4626d90c2f67f72305e9c3e92df66ad	buggy:  return  loaded  /  (float)toLoad;  context:  }  public  synchronized  int  getQueuedAssets  ()  {  return  loadQueue.size  +  (tasks.size());  }  public  synchronized  float  getProgress  ()  {  if  (toLoad  ==  0)  return  1;  return  loaded  /  (float)toLoad;  return  Math.min(1,  loaded  /  (float)toLoad);  }  public  synchronized  void  setErrorListener  (AssetErrorListener  listener)  {  this.listener  =  listener;  }  	return  Math.min(1,  loaded  /  (float)toLoad);  
libgdx_e27a704aac0d02609132b1e5537ea4ab9ac1f47d	buggy:  dst[i]  =  src[ii]  *  scale;  context:  for  (int  i  =  offsetSrc,  ii  =  offsetDst;  i  <  numBytes;)  {  int  b1  =  src[i++]  &  0xff;  int  b2  =  src[i++]  &  0xff;  dst[ii++]  =  (short)(b1  |  (b2  <<  8))  *  scale;  }  }  static  public  void  toFloat  (short[]  src,  int  offsetSrc,  float[]  dst,  int  offsetDst,  int  numBytes)  {  float  scale  =  1.0f  /  Short.MAX_VALUE;  for  (int  i  =  offsetSrc,  ii  =  offsetDst;  i  <  numBytes;  i++,  ii++)  dst[i]  =  src[ii]  *  scale;  dst[ii]  =  src[i]  *  scale;  }  	dst[ii]  =  src[i]  *  scale;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execPing(broadcastPingRequest,  new  ActionListener<BroadcastPingResponse>()  {  context:  BroadcastPingRequest  broadcastPingRequest  =  new  BroadcastPingRequest(RestActions.splitIndices(request.param( "index ")));  broadcastPingRequest.queryHint(request.param( "queryHint "));  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  broadcastPingRequest.operationThreading(operationThreading);          client.admin().cluster().execPing(broadcastPingRequest,  new  ActionListener<BroadcastPingResponse>()  {          client.admin().cluster().ping(broadcastPingRequest,  new  ActionListener<BroadcastPingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  	client.admin().cluster().ping(broadcastPingRequest,  new  ActionListener<BroadcastPingResponse>()  {  
elasticsearch_5af634369737765bb4f6b52817b2570ade149429	buggy:  if  (!build.isMultiValued())  {  context:  values.add(0);  //  first   "t "  indicates  null  value  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(terms,  reader.maxDoc());  try  {  final  BytesRefIterator  iter  =  builder.buildFromTerms(builder.wrapNumeric64Bit(terms.iterator(null)),  reader.getLiveDocs());  BytesRef  term;  while  ((term  =  iter.next())  !=  null)  {  values.add(NumericUtils.sortableLongToDouble(NumericUtils.prefixCodedToLong(term)));  }  Ordinals  build  =  builder.build(fieldDataType.getSettings());              if  (!build.isMultiValued())  {              if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  Docs  ordinals  =  build.ordinals();  double[]  sValues  =  new  double[reader.maxDoc()];  int  maxDoc  =  reader.maxDoc();  for  (int  i  =  0;  i  <  maxDoc;  i++)  {  sValues[i]  =  values.get(ordinals.getOrd(i));  }  final  FixedBitSet  set  =  builder.buildDocsWithValuesSet();  if  (set  ==  null)  {  	if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  
elasticsearch_29da615afd83d198911f839565257dd03c7fcf39	buggy:  return  binarySearch(a,  key,  1,  a.ordinals().getNumOrds()  -  1);  context:  }  }  }  public  BytesRef  value(int  slot)  {  return  values[slot];  }  final  protected  static  int  binarySearch(BytesValues.WithOrdinals  a,  BytesRef  key)  {          return  binarySearch(a,  key,  1,  a.ordinals().getNumOrds()  -  1);          return  binarySearch(a,  key,  1,  a.ordinals().getNumOrds());  }  final  protected  static  int  binarySearch(BytesValues.WithOrdinals  a,  BytesRef  key,  int  low,  int  high)  {  assert  a.getValueByOrd(high)  ==  null  |  a.getValueByOrd(high)  !=  null;  //  make  sure  we  actually  can  get  these  values  assert  a.getValueByOrd(low)  ==  null  |  a.getValueByOrd(low)  !=  null;  while  (low  <=  high)  {  int  mid  =  (low  +  high)  >>>  1;  BytesRef  midVal  =  a.getValueByOrd(mid);  	return  binarySearch(a,  key,  1,  a.ordinals().getNumOrds());  
elasticsearch_f1467dbde256a968bfffed6ce470f162ac307655	buggy:  return  DoubleArrayAtomicFieldData.EMPTY;  context:  }  }  }  public  DoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  DoubleArrayAtomicFieldData.EMPTY;              return  DoubleArrayAtomicFieldData.empty(reader.maxDoc());  }  final  BigDoubleArrayList  values  =  new  BigDoubleArrayList();  values.add(0);  //  first   "t "  indicates  null  value  final  float  acceptableTransientOverheadRatio  =  fieldDataType.getSettings().getAsFloat( "acceptable_transient_overhead_ratio ",  OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO);  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(reader.maxDoc(),  acceptableTransientOverheadRatio);  try  {  	return  DoubleArrayAtomicFieldData.empty(reader.maxDoc());  
elasticsearch_3e405c3ec76235145f81507f1189e92824d06b92	buggy:  String  suffix  =   "b ";  context:  return  ((double)  bytes())  /  SizeUnit.C3;  }  public  double  getGbFrac()  {  return  gbFrac();  }  long  bytes  =  bytes();  double  value  =  bytes;          String  suffix  =   "b ";          String  suffix  =   " ";  if  (bytes  >=  SizeUnit.C3)  {  value  =  gbFrac();  suffix  =   "g ";  }  else  if  (bytes  >=  SizeUnit.C2)  {  value  =  mbFrac();  suffix  =   "m ";  }  else  if  (bytes  >=  SizeUnit.C1)  {  value  =  kbFrac();  	String  suffix  =   " ";  
libgdx_6b1f6e2e139683a01b4f19b1765b466de095cb9a	buggy:  int  result  =  (int)type;  context:  this.value  =  value;  }  public  Attribute  copy  ()  {  return  new  IntAttribute(type,  value);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  983  *  result  +  value;  return  result;  }  }  	int  result  =  super.hashCode();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Collection<String>  indices  =  new  ArrayList<String>();  context:  }  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "indices ".equals(currentFieldName))  {  if  (indicesFound)  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  indices  or  index  already  specified ");  }  indicesFound  =  true;                      Collection<String>  indices  =  new  ArrayList<String>();                      Collection<String>  indices  =  new  ArrayList<>();  while  (parser.nextToken()  !=  XContentParser.Token.END_ARRAY)  {  String  value  =  parser.textOrNull();  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  no  value  specified  for  'indices'  entry ");  }  indices.add(value);  }  currentIndexMatchesIndices  =  matchesIndices(parseContext.index().name(),  indices.toArray(new  String[indices.size()]));  	Collection<String>  indices  =  new  ArrayList<>();  
libgdx_1c809af770701b4168872837ea91994c39591ad4	buggy:  applyTransform(batch);  context:  handleBounds.set(0,  bottomAreaHeight,  width,  handleHeight);  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  validate();  Color  color  =  getColor();  Drawable  handle  =  style.handle;  applyTransform(batch);  applyTransform(batch,  computeTransform());  Matrix4  transform  =  batch.getTransformMatrix();  if  (firstWidget  !=  null)  {  ScissorStack.calculateScissors(getStage().getCamera(),  transform,  firstWidgetBounds,  firstScissors);  if  (ScissorStack.pushScissors(firstScissors))  {  if  (firstWidget.isVisible())  firstWidget.draw(batch,  parentAlpha  *  color.a);  batch.flush();  ScissorStack.popScissors();  }  	applyTransform(batch,  computeTransform());  
libgdx_916fc85cecf433c3461b458e00f8afc516ad21e3	buggy:  public  void  consumeCompressedData  (int  target)  {  context:  public  boolean  isManaged  ()  {  return  true;  }  public  TextureDataType  getType  ()  {  return  TextureDataType.Pixmap;  }  public  void  consumeCompressedData  (int  target)  {  public  void  consumeCustomData  (int  target)  {  }  public  boolean  isPrepared  ()  {  return  true;  }  	public  void  consumeCustomData  (int  target)  {  
libgdx_71c8a1e9aa6bf754b12bf368f2d14e388c675166	buggy:  float  color  =  Float.intBitsToFloat(intBits);  context:  final  float  color  =  tint.toFloatBits();  if  (color  ==  this.color)  return;  this.color  =  color;  float[]  vertices  =  this.vertices;  for  (int  i  =  2,  n  =  idx;  i  <  n;  i  +=  5)  vertices[i]  =  color;  }  public  void  setColor  (float  r,  float  g,  float  b,  float  a)  {  int  intBits  =  ((int)(255  *  a)  <<  24)  |  ((int)(255  *  b)  <<  16)  |  ((int)(255  *  g)  <<  8)  |  ((int)(255  *  r));  float  color  =  Float.intBitsToFloat(intBits);  float  color  =  Float.intBitsToFloat((intBits  &  0xfeffffff));  if  (color  ==  this.color)  return;  this.color  =  color;  float[]  vertices  =  this.vertices;  for  (int  i  =  2,  n  =  idx;  i  <  n;  i  +=  5)  vertices[i]  =  color;  }  public  void  draw  (SpriteBatch  spriteBatch)  {  	float  color  =  Float.intBitsToFloat((intBits  &  0xfeffffff));  
libgdx_b900ed3c0faa90cf3437964c0b2c3b0e6bf73f81	buggy:  CollisionJNI.btCollisionDispatcher_defaultNearCallback(btBroadphasePair.getCPtr(collisionPair),  collisionPair,  btCollisionDispatcher.getCPtr(dispatcher),  dispatcher,  btDispatcherInfo.getCPtr(dispatchInfo),  dispatchInfo);  context:  public  void  setNearCallback(SWIGTYPE_p_f_r_btBroadphasePair_r_btCollisionDispatcher_r_q_const__btDispatcherInfo__void  nearCallback)  {  CollisionJNI.btCollisionDispatcher_setNearCallback(swigCPtr,  this,  SWIGTYPE_p_f_r_btBroadphasePair_r_btCollisionDispatcher_r_q_const__btDispatcherInfo__void.getCPtr(nearCallback));  }  public  SWIGTYPE_p_f_r_btBroadphasePair_r_btCollisionDispatcher_r_q_const__btDispatcherInfo__void  getNearCallback()  {  long  cPtr  =  CollisionJNI.btCollisionDispatcher_getNearCallback(swigCPtr,  this);  return  (cPtr  ==  0)  ?  null  :  new  SWIGTYPE_p_f_r_btBroadphasePair_r_btCollisionDispatcher_r_q_const__btDispatcherInfo__void(cPtr,  false);  }  public  static  void  defaultNearCallback(btBroadphasePair  collisionPair,  btCollisionDispatcher  dispatcher,  btDispatcherInfo  dispatchInfo)  {      CollisionJNI.btCollisionDispatcher_defaultNearCallback(btBroadphasePair.getCPtr(collisionPair),  collisionPair,  btCollisionDispatcher.getCPtr(dispatcher),  dispatcher,  btDispatcherInfo.getCPtr(dispatchInfo),  dispatchInfo);      CollisionJNI.btCollisionDispatcher_defaultNearCallback(collisionPair,  btCollisionDispatcher.getCPtr(dispatcher),  dispatcher,  btDispatcherInfo.getCPtr(dispatchInfo),  dispatchInfo);  }  public  btCollisionConfiguration  getCollisionConfiguration()  {  long  cPtr  =  CollisionJNI.btCollisionDispatcher_getCollisionConfiguration__SWIG_0(swigCPtr,  this);  return  (cPtr  ==  0)  ?  null  :  new  btCollisionConfiguration(cPtr,  false);  }  public  void  setCollisionConfiguration(btCollisionConfiguration  config)  {  	CollisionJNI.btCollisionDispatcher_defaultNearCallback(collisionPair,  btCollisionDispatcher.getCPtr(dispatcher),  dispatcher,  btDispatcherInfo.getCPtr(dispatchInfo),  dispatchInfo);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.endArray();  }  }  builder.endObject();  builder.endObject();  }  builder.endArray();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_19e0a888394eed8b4097a264186a1c8da600ed6b	buggy:  cache.setColors(color);  context:  public  void  draw  (Batch  batch,  float  parentAlpha)  {  validate();  Color  color  =  tempColor.set(getColor());  color.a  *=  parentAlpha;  if  (style.background  !=  null)  {  batch.setColor(color.r,  color.g,  color.b,  color.a);  style.background.draw(batch,  getX(),  getY(),  getWidth(),  getHeight());  }  if  (style.fontColor  !=  null)  color.mul(style.fontColor);  cache.setColors(color);  cache.tint(color);  cache.setPosition(getX(),  getY());  cache.draw(batch);  }  public  float  getPrefWidth  ()  {  if  (wrap)  return  0;  if  (sizeInvalid)  scaleAndComputeSize();  float  width  =  bounds.width;  	cache.tint(color);  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  .minTermFrequency(request.minTermFrequency())  context:  private  void  addMoreLikeThis(MoreLikeThisRequest  request,  BoolJsonQueryBuilder  boolBuilder,  String  fieldName,  String  likeText)  {  MoreLikeThisFieldJsonQueryBuilder  mlt  =  moreLikeThisFieldQuery(fieldName)  .likeText(likeText)  .percentTermsToMatch(request.percentTermsToMatch())  .boostTerms(request.boostTerms())  .boostTermsFactor(request.boostTermsFactor())  .minDocFreq(request.minDocFreq())  .maxDocFreq(request.maxDocFreq())  .minWordLen(request.minWordLen())  .maxWordLen(request.maxWordLen())                  .minTermFrequency(request.minTermFrequency())                  .minTermFreq(request.minTermFreq())  .maxQueryTerms(request.maxQueryTerms())  .stopWords(request.stopWords());  boolBuilder.should(mlt);  }  private  class  TransportHandler  extends  BaseTransportRequestHandler<MoreLikeThisRequest>  {  	.minTermFreq(request.minTermFreq())  
elasticsearch_012d47b5004af9ad729d2f492f100d14ac44e0b3	buggy:  logger.info( "Ping  execution  ejected ",  ex);  context:  try  {  sendPings(timeout,  TimeValue.timeValueMillis(timeout.millis()  /  2),  sendPingsHandler);  ConcurrentMap<DiscoveryNode,  PingResponse>  responses  =  receivedResponses.remove(sendPingsHandler.id());  sendPingsHandler.close();  for  (DiscoveryNode  node  :  sendPingsHandler.nodeToDisconnect)  {  transportService.disconnectFromNode(node);  }  listener.onPing(responses.values().toArray(new  PingResponse[responses.size()]));  }  catch  (RejectedExecutionException  ex)  {                              logger.info( "Ping  execution  ejected ",  ex);                              logger.debug( "Ping  execution  ejected ",  ex);  }  }  });  }  });  }  class  SendPingsHandler  {  	logger.debug( "Ping  execution  ejected ",  ex);  
libgdx_ad86d3e8ffca8ce9da0f76d24558c6ebe18255b6	buggy:  ball.applyLinearImpulse(impulse,  ball.getWorldCenter());  context:  public  void  handleCollision  (Body  ball,  Body  bodyHit,  Field  field)  {  if  (retractWhenHit)  {  this.setRetracted(true);  }  if  (killBall)  {  field.removeBall(ball);  }  else  {  Vector2  impulse  =  this.impulseForBall(ball);  if  (impulse  !=  null)  {  ball.applyLinearImpulse(impulse,  ball.getWorldCenter());  ball.applyLinearImpulse(impulse,  ball.getWorldCenter(),  true);  flashForFrames(3);  }  }  }  public  void  draw  (IFieldRenderer  renderer)  {  if  (isRetracted())  return;  	ball.applyLinearImpulse(impulse,  ball.getWorldCenter(),  true);  
elasticsearch_873b491f4e980d50584fbd004f413c4c3fa95ec0	buggy:  FlushResponse  actionGet  =  client().admin().indices().prepareFlush().execute().actionGet();  context:  protected  final  FlushResponse  flush()  {  return  flush(true);  }  private  FlushResponse  flush(boolean  ignoreNotAllowed)  {  waitForRelocation();          FlushResponse  actionGet  =  client().admin().indices().prepareFlush().execute().actionGet();          FlushResponse  actionGet  =  client().admin().indices().prepareFlush().setWaitIfOngoing(true).execute().actionGet();  if  (ignoreNotAllowed)  {  for  (ShardOperationFailedException  failure  :  actionGet.getShardFailures())  {  assertThat( "unexpected  flush  failure   "  +  failure.reason(),  failure.status(),  equalTo(RestStatus.SERVICE_UNAVAILABLE));  }  }  else  {  assertNoFailures(actionGet);  }  return  actionGet;  	FlushResponse  actionGet  =  client().admin().indices().prepareFlush().setWaitIfOngoing(true).execute().actionGet();  
elasticsearch_1f117c194c9526d16398c4d5ef13c7feb31213e3	buggy:  ),  equalTo( "filtered(foo:1)->child_filter[child-type/type1](filtered(foo:1)->cache(_type:child-type)) "));  context:  assertExplanation(QueryBuilders.constantScoreQuery(FilterBuilders.notFilter(FilterBuilders.termFilter( "foo ",   "bar "))),  equalTo( "ConstantScore(NotFilter(cache(foo:bar))) "));  assertExplanation(QueryBuilders.filteredQuery(  QueryBuilders.termQuery( "foo ",   "1 "),  FilterBuilders.hasChildFilter(   "child-type ",  QueryBuilders.fieldQuery( "foo ",   "1 ")  )          ),  equalTo( "filtered(foo:1)->child_filter[child-type/type1](filtered(foo:1)->cache(_type:child-type)) "));          ),  equalTo( "filtered(foo:1)->CustomQueryWrappingFilter(child_filter[child-type/type1](filtered(foo:1)->cache(_type:child-type))) "));  assertExplanation(QueryBuilders.filteredQuery(  QueryBuilders.termQuery( "foo ",   "1 "),  FilterBuilders.scriptFilter( "true ")  ),  equalTo( "filtered(foo:1)->ScriptFilter(true) "));  }  	),  equalTo( "filtered(foo:1)->CustomQueryWrappingFilter(child_filter[child-type/type1](filtered(foo:1)->cache(_type:child-type))) "));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<DocIdSet>  sets  =  new  ArrayList<DocIdSet>(filters.size());  context:  public  List<?  extends  Filter>  filters()  {  return  filters;  }  public  DocIdSet  getDocIdSet(AtomicReaderContext  context,  Bits  acceptDocs)  throws  IOException  {  if  (filters.size()  ==  1)  {  return  filters.get(0).getDocIdSet(context,  acceptDocs);  }          List<DocIdSet>  sets  =  new  ArrayList<DocIdSet>(filters.size());          List<DocIdSet>  sets  =  new  ArrayList<>(filters.size());  for  (int  i  =  0;  i  <  filters.size();  i++)  {  DocIdSet  set  =  filters.get(i).getDocIdSet(context,  acceptDocs);  if  (DocIdSets.isEmpty(set))  {  //  none  matching  for  this  filter,  continue  continue;  }  sets.add(set);  }  if  (sets.size()  ==  0)  {  	List<DocIdSet>  sets  =  new  ArrayList<>(filters.size());  
libgdx_1fdf27a1fbe845e8317b5a05b4394d194f634f19	buggy:  map.getLayers().addLayer(layer);  context:  }  else  if  (frameName.equals( "Static "))  {  frameTiles.add((StaticTiledMapTile)  currentTileSet.getTile(firstgid  +  frame.getIntAttribute( "Index ")));  }  }  Cell  cell  =  new  Cell();  cell.setTile(new  AnimatedTiledMapTile(interval  /  1000f,  frameTiles));  layer.setCell(x++,  y,  cell);  //TODO:  Reuse  existing  animated  tiles  }  }  }  map.getLayers().addLayer(layer);  map.getLayers().add(layer);  }  }  private  void  loadProperties(MapProperties  properties,  Element  element)  {  if  (element.getName().equals( "Properties "))  {  for  (Element  property  :  element.getChildrenByName( "Property "))  {  String  key  =  property.getAttribute( "Key ",  null);  String  type  =  property.getAttribute( "Type ",  null);  	map.getLayers().add(layer);  
libgdx_114ee9d721c024cfc5330c39a32e7b90c6e3c1a7	buggy:  selectedDrawable.draw(batch,  x,  y  +  itemY  -  itemHeight,  prefWidth,  itemHeight);  context:  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  float  x  =  getX();  float  y  =  getY();  font.setColor(fontColorUnselected.r,  fontColorUnselected.g,  fontColorUnselected.b,  fontColorUnselected.a  *  parentAlpha);  float  itemY  =  getHeight();  for  (int  i  =  0;  i  <  items.length;  i++)  {  if  (cullingArea  ==  null  ||  (itemY  -  itemHeight  <=  cullingArea.y  +  cullingArea.height  &&  itemY  >=  cullingArea.y))  {  if  (selectedIndex  ==  i)  {  selectedDrawable.draw(batch,  x,  y  +  itemY  -  itemHeight,  prefWidth,  itemHeight);  selectedDrawable.draw(batch,  x,  y  +  itemY  -  itemHeight,  getWidth(),  itemHeight);  font.setColor(fontColorSelected.r,  fontColorSelected.g,  fontColorSelected.b,  fontColorSelected.a  *  parentAlpha);  }  font.draw(batch,  items[i],  x  +  textOffsetX,  y  +  itemY  -  textOffsetY);  if  (selectedIndex  ==  i)  {  font.setColor(fontColorUnselected.r,  fontColorUnselected.g,  fontColorUnselected.b,  fontColorUnselected.a  }  }  else  if  (itemY  <  cullingArea.y)  {  	selectedDrawable.draw(batch,  x,  y  +  itemY  -  itemHeight,  getWidth(),  itemHeight);  
elasticsearch_477a24efc6045e36d5ffc5db2da50e9f72f547c0	buggy:  if  (mappingType.charAt(0)  ==  '_')  {  context:  throw  new  IndexMissingException(new  Index(index));  }  }  String  mappingType  =  request.mappingType;  if  (mappingType  ==  null)  {  mappingType  =  newMappers.values().iterator().next().type();  }  else  if  (!mappingType.equals(newMappers.values().iterator().next().type()))  {  throw  new  InvalidTypeNameException( "Type  name  provided  does  not  match  type  name  within  mapping  definition ");  }                      if  (mappingType.charAt(0)  ==  '_')  {                      if  (!MapperService.DEFAULT_MAPPING.equals(mappingType)  &&  mappingType.charAt(0)  ==  '_')  {  throw  new  InvalidTypeNameException( "Document  mapping  type  name  can't  start  with  '_' ");  }  final  Map<String,  Tuple<String,  String>>  mappings  =  newHashMap();  int  expectedReplies  =  0;  for  (Map.Entry<String,  DocumentMapper>  entry  :  newMappers.entrySet())  {  String  index  =  entry.getKey();  	if  (!MapperService.DEFAULT_MAPPING.equals(mappingType)  &&  mappingType.charAt(0)  ==  '_')  {  
libgdx_64ca274676f5015154232c7437475ad088a935a2	buggy:  return  true;  context:  return  tests[testIndex].touchDragged(x,  y,  pointer);  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer,  int  button)  {  return  tests[testIndex].touchUp(x,  y,  pointer,  button);  }  public  boolean  needsGL20  ()  {  return  true;  return  false;  }  public  boolean  mouseMoved  (int  x,  int  y)  {  return  tests[testIndex].mouseMoved  (x,  y);  }  	return  false;  
libgdx_703dfee11df380f16e55c882396c5498b1c2d81c	buggy:  return  blob.get(pos++);  context:  Blob  blob;  int  pos;  public  BlobInputStream  (Blob  blob)  {  this.blob  =  blob;  }  public  int  read  ()  throws  IOException  {  if  (pos  ==  blob.length())  return  -1;  return  blob.get(pos++);  return  blob.get(pos++)  &  0xff;  }  }  }  	return  blob.get(pos++)  &  0xff;  
elasticsearch_6c29142b91fe6582154e273a1e73632b2883551e	buggy:  logger.warn( "failed  to  read  commit  point  [{}] ",  name);  context:  public  CommitPoint  findCommitPoint(int  shardId)  throws  IOException  {  ImmutableBlobContainer  container  =  blobStore.immutableBlobContainer(shardPath(shardId));  ImmutableMap<String,  BlobMetaData>  blobs  =  container.listBlobs();  List<CommitPoint>  commitPointsList  =  Lists.newArrayList();  for  (String  name  :  blobs.keySet())  {  if  (name.startsWith( "commit- "))  {  try  {  commitPointsList.add(CommitPoints.fromXContent(container.readBlobFully(name)));  }  catch  (Exception  e)  {                      logger.warn( "failed  to  read  commit  point  [{}] ",  name);                      logger.warn( "failed  to  read  commit  point  [{}] ",  e,  name);  }  }  }  CommitPoints  commitPoints  =  new  CommitPoints(commitPointsList);  if  (commitPoints.commits().isEmpty())  {  return  null;  }  return  commitPoints.commits().get(0);  	logger.warn( "failed  to  read  commit  point  [{}] ",  e,  name);  
libgdx_d29ea5b7ffe6caef2b5bb01f3a9b8375531b4680	buggy:  layers.addLayer(layer);  context:  TiledMapTileLayer  layer  =  new  TiledMapTileLayer(150,  100,  32,  32);  for  (int  x  =  0;  x  <  150;  x++)  {  for  (int  y  =  0;  y  <  100;  y++)  {  int  ty  =  (int)(Math.random()  *  splitTiles.length);  int  tx  =  (int)(Math.random()  *  splitTiles[ty].length);  Cell  cell  =  new  Cell();  cell.setTile(new  StaticTiledMapTile(splitTiles[ty][tx]));  layer.setCell(x,  y,  cell);  }  }  layers.addLayer(layer);  layers.add(layer);  }  }  renderer  =  new  OrthogonalTiledMapRenderer2(map);  }  	layers.add(layer);  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  LongValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  long  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Long.MIN_VALUE  :  Long.MAX_VALUE;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Long.MAX_VALUE  :  Long.MIN_VALUE;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).longValue()  :  Long.parseLong(missingValue.toString());  }          return  new  LongValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  LongValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  LongValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
elasticsearch_9bb86ea865e556f378b0f3d5a50f6eff38af9799	buggy:  BooleanFilter  booleanFilter  =  (BooleanFilter)  filteredQuery.getFilter();  context:  assertThat(rangeFilter.includesMin(),  equalTo(true));  assertThat(rangeFilter.includesMax(),  equalTo(false));  }  IndexQueryParser  queryParser  =  queryParser();  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/xcontent/bool-filter.json ");  Query  parsedQuery  =  queryParser.parse(query).query();  assertThat(parsedQuery,  instanceOf(FilteredQuery.class));  FilteredQuery  filteredQuery  =  (FilteredQuery)  parsedQuery;          BooleanFilter  booleanFilter  =  (BooleanFilter)  filteredQuery.getFilter();          XBooleanFilter  booleanFilter  =  (XBooleanFilter)  filteredQuery.getFilter();  }  IndexQueryParser  queryParser  =  queryParser();  Query  parsedQuery  =  queryParser.parse(filtered(matchAllQuery(),  andFilter(termFilter( "name.first ",   "shay1 "),  termFilter( "name.first ",   "shay4 ")))).query();  assertThat(parsedQuery,  instanceOf(FilteredQuery.class));  	XBooleanFilter  booleanFilter  =  (XBooleanFilter)  filteredQuery.getFilter();  
elasticsearch_5d781961a07368ae458126e4fad0a8db566637da	buggy:  flushRequest.refresh(HttpActions.paramAsBoolean( "refresh ",  false));  context:  FlushRequest  flushRequest  =  new  FlushRequest(HttpActions.splitIndices(request.param( "index ")));  flushRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  flushRequest.operationThreading(operationThreading);          flushRequest.refresh(HttpActions.paramAsBoolean( "refresh ",  false));          flushRequest.refresh(request.paramAsBoolean( "refresh ",  flushRequest.refresh()));  client.admin().indices().execFlush(flushRequest,  new  ActionListener<FlushResponse>()  {  try  {  JsonBuilder  builder  =  HttpJsonBuilder.cached(request);  builder.startObject();  builder.field( "ok ",  true);  builder.startObject( "_shards ");  	flushRequest.refresh(request.paramAsBoolean( "refresh ",  flushRequest.refresh()));  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  builder.field( "scope ",  scope);  context:  this.boost  =  boost;  return  this;  }  builder.startObject(HasChildQueryParser.NAME);  builder.field( "query ");  queryBuilder.toXContent(builder,  params);  builder.field( "type ",  childType);  if  (scope  !=  null)  {              builder.field( "scope ",  scope);              builder.field( "_scope ",  scope);  }  if  (boost  !=  1.0f)  {  builder.field( "boost ",  boost);  }  builder.endObject();  }  }  	builder.field( "_scope ",  scope);  
libgdx_1fbbb36c707d9a6644c74829ee4d9b38cbe0b247	buggy:  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "));  context:  public  class  ManagedTest  extends  GdxTest  {  Mesh  mesh;  Texture  texture;  mesh  =  new  Mesh(true,  4,  4,  new  VertexAttribute(Usage.Position,  2,   "a_position "),  new  VertexAttribute(  Usage.TextureCoordinates,  2,   "a_texCoord "));  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  0,  0.5f,  -0.5f,  1,  0,  0.5f,  0.5f,  1,  1,  -0.5f,  0.5f,  0,  1});  mesh.setIndices(new  short[]  {0,  1,  2,  3});  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "));  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  true);  texture.setFilter(TextureFilter.MipMap,  TextureFilter.Linear);  }  GL10  gl  =  Gdx.graphics.getGL10();  gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  gl.glClearColor(0.7f,  0.7f,  0.7f,  1);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  true);  
elasticsearch_7961dfa7ab727f1c43684473b3c0b7864e227b1e	buggy:  throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exists,  but  doesn't,  current  files:   "  +  files,  e);  context:  try  {  si  =  Lucene.readSegmentInfos(indexShard.store().directory());  }  catch  (Exception  e)  {  String  files  =   "_unknown_ ";  try  {  files  =  Arrays.toString(indexShard.store().directory().listAll());  }  catch  (Exception  e1)  {  }  if  (indexShouldExists  &&  indexShard.store().indexStore().persistent())  {                      throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exists,  but  doesn't,  current  files:   "  +  files,  e);                      throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exist,  but  doesn't,  current  files:   "  +  files,  e);  }  }  if  (si  !=  null)  {  if  (indexShouldExists)  {  version  =  si.getVersion();  if  (si.getUserData().containsKey(Translog.TRANSLOG_ID_KEY))  {  translogId  =  Long.parseLong(si.getUserData().get(Translog.TRANSLOG_ID_KEY));  }  else  {  	throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exist,  but  doesn't,  current  files:   "  +  files,  e);  
libgdx_21645998039880685478fe67d6683f673a0f6f1b	buggy:   "ois-v1-4svn/src/linux/*.cpp "  context:   "ois-v1-4svn/src/win32/*.cpp "  };  String[]  linuxSrc  =  {   "*.cpp ",   "ois-v1-4svn/src/*.cpp ",   "ois-v1-4svn/src/linux/*.cpp "  };  String[]  macSrc  =  {   "*.cpp ",   "ois-v1-4svn/src/*.cpp ",   "ois-v1-4svn/src/linux/*.cpp "   "ois-v1-4svn/src/mac/*.cpp "  };  String[]  includes  =  new  String[]  {   "ois-v1-4svn/includes ",   "dinput/ "  };  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  	 "ois-v1-4svn/src/mac/*.cpp "  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  public  static  FilteredQueryBuilder  filteredQuery(QueryBuilder  queryBuilder,  @Nullable  FilterBuilder  filterBuilder)  {  context:  public  static  FilteredQueryBuilder  filtered(QueryBuilder  queryBuilder,  @Nullable  FilterBuilder  filterBuilder)  {  return  new  FilteredQueryBuilder(queryBuilder,  filterBuilder);  }      public  static  FilteredQueryBuilder  filteredQuery(QueryBuilder  queryBuilder,  @Nullable  FilterBuilder  filterBuilder)  {      public  static  FilteredQueryBuilder  filteredQuery(@Nullable  QueryBuilder  queryBuilder,  @Nullable  FilterBuilder  filterBuilder)  {  return  new  FilteredQueryBuilder(queryBuilder,  filterBuilder);  }  	public  static  FilteredQueryBuilder  filteredQuery(@Nullable  QueryBuilder  queryBuilder,  @Nullable  FilterBuilder  filterBuilder)  {  
libgdx_4a10a1925172dd415cde06306327c6dd87e73cb5	buggy:  map.setOwnedTextures(textures.values().toArray());  context:  FileHandle  tmxFile  =  resolve(fileName);  root  =  xml.parse(tmxFile);  ObjectMap<String,  Texture>  textures  =  new  ObjectMap<String,  Texture>();  for  (FileHandle  textureFile  :  loadTilesets(root,  tmxFile))  {  Texture  texture  =  new  Texture(textureFile,  parameters.generateMipMaps);  texture.setFilter(parameters.textureMinFilter,  parameters.textureMagFilter);  textures.put(textureFile.path(),  texture);  }  DirectImageResolver  imageResolver  =  new  DirectImageResolver(textures);  TiledMap  map  =  loadTilemap(root,  tmxFile,  imageResolver);  map.setOwnedTextures(textures.values().toArray());  map.setOwnedResources(textures.values().toArray());  return  map;  }  catch  (IOException  e)  {  throw  new  GdxRuntimeException( "Couldn't  load  tilemap  ' "  +  fileName  +   "' ",  e);  }  }  public  void  loadAsync  (AssetManager  manager,  String  fileName,  TmxMapLoader.Parameters  parameter)  {  	map.setOwnedResources(textures.values().toArray());  
elasticsearch_c94c13fa2612989da1537ed219da182c0eb57ab0	buggy:  return  new  LZFCompressedStreamOutput(out,  encoder);  context:  return  LZFEncoder.encode(encoder,  data,  offset,  length);  }  public  CompressedStreamInput  streamInput(StreamInput  in)  throws  IOException  {  return  new  LZFCompressedStreamInput(in,  decoder);  }  public  CompressedStreamOutput  streamOutput(StreamOutput  out)  throws  IOException  {          return  new  LZFCompressedStreamOutput(out,  encoder);          return  new  LZFCompressedStreamOutput(out);  }  public  CompressedIndexInput  indexInput(IndexInput  in)  throws  IOException  {  return  new  LZFCompressedIndexInput(in,  decoder);  }  }  	return  new  LZFCompressedStreamOutput(out);  
elasticsearch_51273587dedb78ceba2b8f905fbd2e3ac330c237	buggy:  EngineException[]  failures  =  indexShard.bulk(new  Engine.Bulk(ops));  context:  DeleteRequest  deleteRequest  =  (DeleteRequest)  item.request();  try  {  ops[i]  =  indexShard.prepareDelete(deleteRequest.type(),  deleteRequest.id());  }  catch  (Exception  e)  {  responses[i]  =  new  BulkItemResponse(item.id(),   "delete ",  new  BulkItemResponse.Failure(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  ExceptionsHelper.detailedMessage(e)));  }  }  }          EngineException[]  failures  =  indexShard.bulk(new  Engine.Bulk(ops));          EngineException[]  failures  =  indexShard.bulk(new  Engine.Bulk(ops).refresh(request.refresh()));  Set<String>  processedTypes  =  Sets.newHashSet();  for  (int  i  =  0;  i  <  ops.length;  i++)  {  if  (ops[i]  ==  null)  {  continue;  }  	EngineException[]  failures  =  indexShard.bulk(new  Engine.Bulk(ops).refresh(request.refresh()));  
libgdx_633ee79f66365887d4699e8aa6b6131793f41fbb	buggy:  logoSprite.getRegion().flip(false,  true);  context:  renderMode  =  (renderMode  +  1)  %  2;  return  false;  }  });  spriteBatch  =  new  SpriteBatch();  spriteBatch.setProjectionMatrix(new  Matrix4().setToOrtho(0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  0,  0,  1));  logoSprite  =  new  Sprite(Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge));  logoSprite.getRegion().flip(false,  true);  logoSprite.flip(false,  true);  logoSprite.setPosition(0,  320  -  256);  logoSprite.setColor(1,  1,  1,  0.5f);  font  =  new  BitmapFont(Gdx.files.getFileHandle( "data/verdana39.fnt ",  FileType.Internal),  Gdx.files.getFileHandle(   "data/verdana39.png ",  FileType.Internal),  true);  cache1  =  new  BitmapFontCache(font);  cache2  =  new  BitmapFontCache(font);  	logoSprite.flip(false,  true);  
elasticsearch_f582212c68d62dd8c7f16ee0186885ad296f639e	buggy:  }  else  {  context:  parsePointFromString(context,  sparse,  context.parser().text());  }  else  {  parse(context,  GeoUtils.parseGeoPoint(context.parser(),  sparse),  null);  }  token  =  context.parser().nextToken();  }  }  }  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  parsePointFromString(context,  sparse,  context.parser().text());              }  else  {              }  else  if  (token  !=  XContentParser.Token.VALUE_NULL)  {  parse(context,  GeoUtils.parseGeoPoint(context.parser(),  sparse),  null);  }  }  context.path().remove();  context.path().pathType(origPathType);  }  	}  else  if  (token  !=  XContentParser.Token.VALUE_NULL)  {  
libgdx_13d4acfee2429725e8b271de16083dde4057f4a8	buggy:  cache  =  new  SpriteCache(1000);  context:  private  int  tileMapWidth  =  10;  private  int  tileMapHeight  =  5;  private  int  tileSize  =  32;  private  SpriteCache  cache;  public  void  create  ()  {  Sprite  sprite  =  new  Sprite(Gdx.graphics.newTexture(Gdx.files.internal( "data/badlogicsmall.jpg "),  Linear,  Linear,  ClampToEdge,  ClampToEdge));  sprite.setSize(tileSize,  tileSize);  cache  =  new  SpriteCache(1000);  cache  =  new  SpriteCache(1000,  false);  for  (int  y  =  0;  y  <  tileMapHeight;  y++)  {  cache.beginCache();  for  (int  x  =  0;  x  <  tileMapWidth;  x++)  {  sprite.setPosition(x  *  tileSize,  y  *  tileSize);  cache.add(sprite);  }  cache.endCache();  sprite.rotate(90);  	cache  =  new  SpriteCache(1000,  false);  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execCreate(createIndexRequest,  new  ActionListener<CreateIndexResponse>()  {  context:  try  {  channel.sendResponse(new  JsonThrowableRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));  }  catch  (IOException  e1)  {  return;  }  }  }  CreateIndexRequest  createIndexRequest  =  new  CreateIndexRequest(request.param( "index "),  indexSettings);  createIndexRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));          client.admin().indices().execCreate(createIndexRequest,  new  ActionListener<CreateIndexResponse>()  {          client.admin().indices().create(createIndexRequest,  new  ActionListener<CreateIndexResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.acknowledged())  .endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  	client.admin().indices().create(createIndexRequest,  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  public  void  testTimeout()  throws  Exception  {  ScheduledExecutorService  timer  =  Executors.newSingleThreadScheduledExecutor();  PrioritizedEsThreadPoolExecutor  executor  =  EsExecutors.newSinglePrioritizing(Executors.defaultThreadFactory());  final  CountDownLatch  block  =  new  CountDownLatch(1);  executor.execute(new  Runnable()  {  public  void  run()  {  try  {  block.await();  }  catch  (InterruptedException  e)  {                      assert  false;                      fail();  }  }  public  String  toString()  {  return   "the  blocking ";  }  });  	fail();  
libgdx_9349f129ed8dbced7c9e3f2d0bd0f83d7a092f1f	buggy:  Array<AssetDescriptor>  dependencies  =  Array.of(AssetDescriptor.class);  context:  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  atlasFile,  TextureAtlasParameter  parameter)  {  FileHandle  imgDir  =  atlasFile.parent();  if  (parameter  !=  null)  data  =  new  TextureAtlasData(atlasFile,  imgDir,  parameter.flip);  else  {  data  =  new  TextureAtlasData(atlasFile,  imgDir,  false);  }  Array<AssetDescriptor>  dependencies  =  Array.of(AssetDescriptor.class);  Array<AssetDescriptor>  dependencies  =  new  Array();  for  (Page  page  :  data.getPages())  {  TextureParameter  params  =  new  TextureParameter();  params.format  =  page.format;  params.genMipMaps  =  page.useMipMaps;  params.minFilter  =  page.minFilter;  params.magFilter  =  page.magFilter;  dependencies.add(new  AssetDescriptor(page.textureFile,  Texture.class,  params));  }  	Array<AssetDescriptor>  dependencies  =  new  Array();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.endObject();  }  GetResult  getResult  =  response.getGetResult();  if  (getResult  !=  null)  {  builder.startObject(Fields.GET);  response.getGetResult().toXContentEmbedded(builder,  request);  builder.endObject();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  response.isExists()  ?  OK  :  NOT_FOUND,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  private  void  buildExplanation(XContentBuilder  builder,  Explanation  explanation)  throws  IOException  {  builder.field(Fields.VALUE,  explanation.getValue());  builder.field(Fields.DESCRIPTION,  explanation.getDescription());  Explanation[]  innerExps  =  explanation.getDetails();  	}  catch  (Throwable  e)  {  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices( "_all ");  context:  }  public  void  restoreIndexWithMissingShards()  throws  Exception  {  cluster().startNode(settingsBuilder().put( "gateway.type ",   "local "));  cluster().startNode(settingsBuilder().put( "gateway.type ",   "local "));          cluster().wipeIndices( "_all ");          immutableCluster().wipeIndices( "_all ");  assertAcked(prepareCreate( "test-idx-1 ",  2,  settingsBuilder().put( "number_of_shards ",  6)  .put( "number_of_replicas ",  0)  .put(MockDirectoryHelper.RANDOM_NO_DELETE_OPEN_FILE,  false)));  ensureGreen();  for  (int  i  =  0;  i  <  100;  i++)  {  	immutableCluster().wipeIndices( "_all ");  
elasticsearch_c5ebe6e86ff224650f8f3147067bdb6a707b9cf3	buggy:  Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "string ");  context:  if  (mapper  ==  null)  {  newMapper  =  true;  BuilderContext  builderContext  =  new  BuilderContext(context.path());  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  boolean  resolved  =  false;  if  (!resolved)  {                          Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "string ");                          Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "string ",  null);  if  (builder  !=  null)  {  mapper  =  builder.build(builderContext);  resolved  =  true;  }  }  if  (!resolved  &&  context.root().dateDetection())  {  String  text  =  context.parser().text();  	Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "string ",  null);  
elasticsearch_d9ec629473ac472209f65843c4858c65a1f976a1	buggy:  logger.trace( "Get  for  [{}#{}]  returned  [{}] ",  new  Object[]{type,  id,  doc});  context:  try  {  int  docId  =  Lucene.docId(searcher.reader(),  docMapper.uidMapper().term(type,  id));  if  (docId  ==  Lucene.NO_DOC)  {  if  (logger.isTraceEnabled())  {  }  return  null;  }  Document  doc  =  searcher.reader().document(docId,  docMapper.sourceMapper().fieldSelector());  if  (logger.isTraceEnabled())  {                  logger.trace( "Get  for  [{}#{}]  returned  [{}] ",  new  Object[]{type,  id,  doc});                  logger.trace( "Get  for  [{}#{}]  returned  [{}] ",  type,  id,  doc);  }  return  docMapper.sourceMapper().value(doc);  }  catch  (IOException  e)  {  throw  new  ElasticSearchException( "Failed  to  get  type  [ "  +  type  +   "]  and  id  [ "  +  id  +   "] ",  e);  }  finally  {  searcher.release();  }  }  	logger.trace( "Get  for  [{}#{}]  returned  [{}] ",  type,  id,  doc);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<String>  groupStats  =  new  ArrayList<String>(4);  context:  public  class  StatsGroupsParseElement  implements  SearchParseElement  {  public  void  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  XContentParser.Token  token  =  parser.currentToken();  if  (token.isValue())  {  context.groupStats(ImmutableList.of(parser.text()));  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {              List<String>  groupStats  =  new  ArrayList<String>(4);              List<String>  groupStats  =  new  ArrayList<>(4);  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  groupStats.add(parser.text());  }  context.groupStats(groupStats);  }  }  }  	List<String>  groupStats  =  new  ArrayList<>(4);  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  shardTarget,  indexShard.acquireSearcher(),  indexService,  indexShard,  context:  protected  ShardCountResponse  shardOperation(ShardCountRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());  SearchContext  context  =  new  DefaultSearchContext(0,  new  ShardSearchRequest().types(request.types())  .filteringAliases(request.filteringAliases())  .nowInMillis(request.nowInMillis()),                  shardTarget,  indexShard.acquireSearcher(),  indexService,  indexShard,                  shardTarget,  indexShard.acquireSearcher( "count "),  indexService,  indexShard,  scriptService,  cacheRecycler);  SearchContext.setCurrent(context);  try  {  if  (request.minScore()  !=  -1)  {  context.minimumScore(request.minScore());  }  	shardTarget,  indexShard.acquireSearcher( "count "),  indexService,  indexShard,  
libgdx_075da3adeb013bfeb6c92e1d72a9360735341657	buggy:  return  idx  +  1  &  queue.length()  -  1;  context:  public  class  AtomicQueue<T>  {  private  final  AtomicInteger  writeIndex  =  new  AtomicInteger();  private  final  AtomicInteger  readIndex  =  new  AtomicInteger();  private  final  AtomicReferenceArray<T>  queue;  public  AtomicQueue  (int  capacity)  {  queue  =  new  AtomicReferenceArray(capacity);  }  private  int  next  (int  idx)  {  return  idx  +  1  &  queue.length()  -  1;  return  (idx  +  1)  %  queue.length();  }  public  boolean  put  (T  value)  {  int  write  =  writeIndex.get();  int  read  =  readIndex.get();  int  next  =  next(write);  if  (next  ==  read)  return  false;  queue.set(write,  value);  	return  (idx  +  1)  %  queue.length();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  NV<T>(c.newInstance(sizing));  context:  public  class  NoneRecycler<T>  extends  AbstractRecycler<T>  {  public  NoneRecycler(C<T>  c)  {  super(c);  }  public  V<T>  obtain(int  sizing)  {          return  new  NV<T>(c.newInstance(sizing));          return  new  NV<>(c.newInstance(sizing));  }  public  void  close()  {  }  public  static  class  NV<T>  implements  Recycler.V<T>  {  	return  new  NV<>(c.newInstance(sizing));  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(StatisticalFacetCollectorParser.NAME);  context:  this.facetFilter  =  filter;  return  this;  }  if  (fieldName  ==  null  &&  fieldsNames  ==  null)  {  throw  new  SearchSourceBuilderException( "field  must  be  set  on  statistical  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(StatisticalFacetCollectorParser.NAME);          builder.startObject(StatisticalFacet.TYPE);  if  (fieldsNames  !=  null)  {  if  (fieldsNames.length  ==  1)  {  builder.field( "field ",  fieldsNames[0]);  }  else  {  builder.field( "fields ",  fieldsNames);  }  }  else  {  builder.field( "field ",  fieldName);  	builder.startObject(StatisticalFacet.TYPE);  
elasticsearch_c05df433c6ff92b69a2acaa411c1b66e537e0811	buggy:  return  new  Term(names.indexName(),  value);  context:  return  value(field);  }  return  value;  }          return  new  Term(names.indexName(),  value);          return  termFactory.createTerm(value);  }  if  (!enabled)  {  return  null;  }  return  new  Field(names.indexName(),  context.index(),  store,  index);  }  	return  termFactory.createTerm(value);  
elasticsearch_6a3c53ef44b884d03dd4f611d68e49053036b7e3	buggy:  return  50000;  context:  return  8;  }  protected  int  numberOfNodes()  {  return  4;  }  protected  int  numDocs()  {          return  50000;          return  10000;  }  }  	return  10000;  
elasticsearch_90d2cb7dd506f188b534c72de7ba125e74f6ec21	buggy:  logger.error( "Shard  Failure:  {} ",  failure.failure(),  failure.toString());  context:  assertThat(stats.getMax(),  equalTo(10.0));  assertThat(stats.getSum(),  equalTo((double)  1+2+3+4+5+6+7+8+9+10+0+1+2+3+4+5+6+7+8+9));  assertThat(stats.getCount(),  equalTo(20l));  }  private  void  assertShardExecutionState(SearchResponse  response,  int  expectedFailures)  throws  Exception  {  ShardSearchFailure[]  failures  =  response.getShardFailures();  if  (failures.length  !=  expectedFailures)  {  for  (ShardSearchFailure  failure  :  failures)  {                  logger.error( "Shard  Failure:  {} ",  failure.failure(),  failure.toString());                  logger.error( "Shard  Failure:  {} ",  failure.reason(),  failure.toString());  }  fail( "Unexpected  shard  failures! ");  }  assertThat( "Not  all  shards  are  initialized ",  response.getSuccessfulShards(),  equalTo(response.getTotalShards()));  }  }  	logger.error( "Shard  Failure:  {} ",  failure.reason(),  failure.toString());  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  public  boolean  apply(Object  o)  {  ClusterState  tribeState  =  tribeNode.client().admin().cluster().prepareState().setLocal(true).get().getState();  return  tribeState.getMetaData().index( "test1 ").mapping( "type1 ")  !=  null  &&  tribeState.getMetaData().index( "test1 ").mapping( "type2 ")  !=  null  &&  tribeState.getMetaData().index( "test2 ").mapping( "type1 ")  !=  null  &&  tribeState.getMetaData().index( "test2 ").mapping( "type2 ")  !=  null;  }  });  try  {  tribeClient.admin().indices().prepareCreate( "tribe_index ").setMasterNodeTimeout( "10ms ").get();              assert  false;              fail();  }  catch  (MasterNotDiscoveredException  e)  {  }  cluster2.client().admin().indices().prepareDelete( "test2 ").get();  awaitBusy(new  Predicate<Object>()  {  	fail();  
libgdx_164debcb8da3af73a69f479fb544548d4ac51bd1	buggy:  return  app.graphics.getHeight()  -  1  -  glfwGetCursorPosY(app.graphics.window);  context:  }  public  int  getX  (int  pointer)  {  if  (pointer  >  0)  return  0;  else  return  getX();  }  public  int  getY  ()  {  return  app.graphics.getHeight()  -  1  -  glfwGetCursorPosY(app.graphics.window);  return  glfwGetCursorPosY(app.graphics.window);  }  public  int  getY  (int  pointer)  {  if  (pointer  >  0)  return  0;  else  return  getY();  }  	return  glfwGetCursorPosY(app.graphics.window);  
libgdx_a9f6848d8fb6530a177b87f47b06cc05f7f633b6	buggy:  Gdx.app.log( "Vorbis ",   "channels:   "  +  decoder.getChannels()  +   ",  rate:   "  +  decoder.getRate()  +   ",  length:   "  +  decoder.getLength());  context:  public  void  create  ()  {  FileHandle  externalFile  =  Gdx.files.external( "tmp/test.mp3 ");  Gdx.files.internal(FILE).copyTo(externalFile);  decoder  =  new  Mpg123Decoder(externalFile);  Gdx.app.log( "Vorbis ",   "channels:   "  +  decoder.getChannels()  +   ",  rate:   "  +  decoder.getRate()  +   ",  length:   "  +  decoder.getLength());  Gdx.app.log( "Mp3 ",   "channels:   "  +  decoder.getChannels()  +   ",  rate:   "  +  decoder.getRate()  +   ",  length:   "  +  decoder.getLength());  device  =  Gdx.audio.newAudioDevice(decoder.getRate(),  decoder.getChannels()  ==  1?  true:  false);  Thread  playbackThread  =  new  Thread(new  Runnable()  {  public  void  run()  {  	Gdx.app.log( "Mp3 ",   "channels:   "  +  decoder.getChannels()  +   ",  rate:   "  +  decoder.getRate()  +   ",  length:   "  +  decoder.getLength());  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  listener.cancled();  context:  return  0;  }  public  void  getTextInput  (final  TextInputListener  listener,  final  String  title,  final  String  text)  {  SwingUtilities.invokeLater(new  Runnable()  {  public  void  run  ()  {  String  output  =  JOptionPane.showInputDialog(null,  title,  text);  if(output  !=  null)  listener.input(output);  else  listener.cancled();  listener.canceled();  }  });  }  public  int  getX  ()  {  return  Mouse.getX();  }  	listener.canceled();  
libgdx_c9e39568b42bfe05307f5bdb7ed717536dde9033	buggy:  importer.delete();  context:  public  boolean  tap  (float  x,  float  y,  int  count,  int  button)  {  shoot(x,  y);  return  true;  }  public  void  dispose  ()  {  super.dispose();  importer.delete();  importer.dispose();  }  }  	importer.dispose();  
elasticsearch_cc0a6ed6901575ad7fad12cf834201b098b93712	buggy:  if  (context.facets()  ==  null)  {  context:  }  return  ImmutableMap.of( "facets ",  facetParseElement,   "facets_binary ",  facetBinaryParseElement,   "facetsBinary ",  facetBinaryParseElement);  }  }          if  (context.facets()  ==  null)  {          if  (context.facets()  ==  null  ||  context.facets().facetCollectors()  ==  null)  {  return;  }  if  (context.queryResult().facets()  !=  null)  {  return;  }  	if  (context.facets()  ==  null  ||  context.facets().facetCollectors()  ==  null)  {  
libgdx_42a67912bac6c53e7d20cb1e5d37ee4aa42c4c74	buggy:  try  {tmpUrl  =  new  URL( "http://libgdx.googlecode.com/svn/trunk/extensions/gdx-setup-ui/config/config.txt ");}  context:  checkUpdates();  }  private  void  checkUpdates()  {  final  String  version  =   "2.0.1 ";  versionLabel.setText( "v "  +  version  +   "  (...) ");  URL  tmpUrl;  try  {tmpUrl  =  new  URL( "http://libgdx.googlecode.com/svn/trunk/extensions/gdx-setup-ui/config/config.txt ");}  try  {tmpUrl  =  new  URL( "http://libgdx.badlogicgames.com/nightlies/config/config.txt ");}  catch  (MalformedURLException  ex)  {throw  new  RuntimeException(ex);}  final  URL  url  =  tmpUrl;  final  ByteArrayOutputStream  stream  =  new  ByteArrayOutputStream();  final  HttpUtils.Callback  callback  =  new  HttpUtils.Callback()  {  	try  {tmpUrl  =  new  URL( "http://libgdx.badlogicgames.com/nightlies/config/config.txt ");}  
elasticsearch_c295211a85722dd8ad838c94a00c18a42347ff0c	buggy:  return  getForField(mapper.names(),  mapper.fieldDataType2());  context:  indexFieldData.clear(reader);  }  }  public  FieldDataStats  stats()  {  return  new  FieldDataStats();  }  public  <IFD  extends  IndexFieldData>  IFD  getForField(FieldMapper  mapper)  {          return  getForField(mapper.names(),  mapper.fieldDataType2());          return  getForField(mapper.names(),  mapper.fieldDataType());  }  public  <IFD  extends  IndexFieldData>  IFD  getForField(FieldMapper.Names  fieldNames,  FieldDataType  type)  {  IndexFieldData  fieldData  =  loadedFieldData.get(type.getType());  if  (fieldData  ==  null)  {  synchronized  (loadedFieldData)  {  fieldData  =  loadedFieldData.get(type.getType());  if  (fieldData  ==  null)  {  	return  getForField(mapper.names(),  mapper.fieldDataType());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  PrimaryResponse<ShardDeleteByQueryResponse,  ShardDeleteByQueryRequest>(shardRequest.request,  new  ShardDeleteByQueryResponse(),  null);  context:  try  {  Engine.DeleteByQuery  deleteByQuery  =  indexShard.prepareDeleteByQuery(request.source(),  request.filteringAliases(),  request.types())  .origin(Engine.Operation.Origin.PRIMARY);  SearchContext.current().parsedQuery(new  ParsedQuery(deleteByQuery.query(),  ImmutableMap.<String,  Filter>of()));  indexShard.deleteByQuery(deleteByQuery);  }  finally  {  SearchContext  searchContext  =  SearchContext.current();  searchContext.clearAndRelease();  SearchContext.removeCurrent();  }          return  new  PrimaryResponse<ShardDeleteByQueryResponse,  ShardDeleteByQueryRequest>(shardRequest.request,  new  ShardDeleteByQueryResponse(),  null);          return  new  PrimaryResponse<>(shardRequest.request,  new  ShardDeleteByQueryResponse(),  null);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  ShardDeleteByQueryRequest  request  =  shardRequest.request;  IndexService  indexService  =  indicesService.indexServiceSafe(shardRequest.request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardRequest.shardId);  	return  new  PrimaryResponse<>(shardRequest.request,  new  ShardDeleteByQueryResponse(),  null);  
elasticsearch_e0eff7d9d38531697fdf163bceec69ecdc95bde4	buggy:  builder.field( "sort_mode ",  sortMode);  context:  if  (order  !=  null)  {  builder.field( "order ",  order.toString());  }  if  (missing  !=  null)  {  builder.field( "missing ",  missing);  }  if  (ignoreUnampped  !=  null)  {  builder.field( "ignore_unmapped ",  ignoreUnampped);  }  if  (sortMode  !=  null)  {              builder.field( "sort_mode ",  sortMode);              builder.field( "mode ",  sortMode);  }  if  (nestedFilter  !=  null)  {  builder.field( "nested_filter ",  nestedFilter,  params);  }  if  (nestedPath  !=  null)  {  builder.field( "nested_path ",  nestedPath);  }  builder.endObject();  	builder.field( "mode ",  sortMode);  
elasticsearch_99ef3408fb8c3777b385f4b73506ca39c75da6ed	buggy:  metadata  =  store.getMetadata();  context:  BlobStoreIndexShardSnapshots  snapshots  =  buildBlobStoreIndexShardSnapshots(blobs);  final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<>();  final  List<BlobStoreIndexShardSnapshot.FileInfo>  indexCommitPointFiles  =  newArrayList();  int  indexNumberOfFiles  =  0;  long  indexTotalFilesSize  =  0;  ArrayList<FileInfo>  filesToSnapshot  =  newArrayList();  final  Store.MetadataSnapshot  metadata;  try  {                      metadata  =  store.getMetadata();                      metadata  =  store.getMetadata(snapshotIndexCommit);  }  catch  (IOException  e)  {  throw  new  IndexShardSnapshotFailedException(shardId,   "Failed  to  get  store  file  metadata ",  e);  }  for  (String  fileName  :  snapshotIndexCommit.getFiles())  {  if  (snapshotStatus.aborted())  {  throw  new  IndexShardSnapshotFailedException(shardId,   "Aborted ");  }  	metadata  =  store.getMetadata(snapshotIndexCommit);  
libgdx_6e2abfb38e6f991315751ae796fbcd3b54946457	buggy:  ||  extension.equals( "fnt ")  ||  extension.equals( "pack ")  ||  extension.equals( "obj ");  context:  if  (isText(extension))  return  AssetType.Text;  return  AssetType.Binary;  }  private  boolean  isImage  (String  extension)  {  return  extension.equals( "jpg ")  ||  extension.equals( "png ")  ||  extension.equals( "bmp ")  ||  extension.equals( "gif ");  }  private  boolean  isText  (String  extension)  {  return  extension.equals( "json ")  ||  extension.equals( "xml ")  ||  extension.equals( "txt ")  ||  extension.equals( "glsl ")  ||  extension.equals( "fnt ")  ||  extension.equals( "pack ")  ||  extension.equals( "obj ");  ||  extension.equals( "fnt ")  ||  extension.equals( "pack ")  ||  extension.equals( "obj ")  ||  extension.equals( "atlas ");  }  private  boolean  isAudio  (String  extension)  {  return  extension.equals( "mp3 ")  ||  extension.equals( "ogg ")  ||  extension.equals( "wav ");  }  }  	||  extension.equals( "fnt ")  ||  extension.equals( "pack ")  ||  extension.equals( "obj ")  ||  extension.equals( "atlas ");  
libgdx_c1fbcd400ebd0a7f998f5ef471efc9d990025bdb	buggy:  if  (parameter.forceTextureFilters)  {  context:  TextureAtlas  atlas  =  null;  String  regionsName  =   " ";  if  (map.getProperties().containsKey( "atlas_ "  +  name))  {  FileHandle  atlasHandle  =  getRelativeFileHandle(tmxFile,  map.getProperties().get( "atlas_ "  +  name,  String.class));  atlasHandle  =  resolve(atlasHandle.path());  atlas  =  resolver.getAtlas(atlasHandle.path());  regionsName  =  atlasHandle.nameWithoutExtension();  if  (parameter.forceTextureFilters)  {  if  (parameter  !=  null  &&  parameter.forceTextureFilters)  {  for  (Texture  texture  :  atlas.getTextures())  {  texture.setFilter(parameter.textureMinFilter,  parameter.textureMagFilter);  }  }  }  TiledMapTileSet  tileset  =  new  TiledMapTileSet();  MapProperties  props  =  tileset.getProperties();  	if  (parameter  !=  null  &&  parameter.forceTextureFilters)  {  
elasticsearch_766c787737368ad718ac1c37e69c242abcdab4d4	buggy:  filter(map,  result,  includes,  excludes,  new  StringBuilder());  context:  newList.add(listValue);  }  }  return  newList;  }  return  null;  }  public  static  Map<String,  Object>  filter(Map<String,  Object>  map,  String[]  includes,  String[]  excludes)  {  Map<String,  Object>  result  =  Maps.newHashMap();          filter(map,  result,  includes,  excludes,  new  StringBuilder());          filter(map,  result,  includes  ==  null  ?  Strings.EMPTY_ARRAY  :  includes,  excludes  ==  null  ?  Strings.EMPTY_ARRAY  :  excludes,  new  StringBuilder());  return  result;  }  private  static  void  filter(Map<String,  Object>  map,  Map<String,  Object>  into,  String[]  includes,  String[]  excludes,  StringBuilder  sb)  {  if  (includes.length  ==  0  &&  excludes.length  ==  0)  {  into.putAll(map);  return;  }  	filter(map,  result,  includes  ==  null  ?  Strings.EMPTY_ARRAY  :  includes,  excludes  ==  null  ?  Strings.EMPTY_ARRAY  :  excludes,  new  StringBuilder());  
elasticsearch_719d1e0318209e1f822169adcba90214b1e75995	buggy:  if  (curTerms.hasPayloads()  &&  (currentPayloads[i]  !=  null))  {  context:  builder.startArray(FieldStrings.TOKENS);  for  (int  i  =  0;  i  <  termFreq;  i++)  {  builder.startObject();  if  (curTerms.hasPositions())  {  builder.field(FieldStrings.POS,  curentPositions[i]);  }  if  (curTerms.hasOffsets())  {  builder.field(FieldStrings.START_OFFSET,  currentStartOffset[i]);  builder.field(FieldStrings.END_OFFSET,  currentEndOffset[i]);  }              if  (curTerms.hasPayloads()  &&  (currentPayloads[i]  !=  null))  {              if  (curTerms.hasPayloads()  &&  (currentPayloads[i].length()  >  0))  {  builder.field(FieldStrings.PAYLOAD,  currentPayloads[i]);  }  builder.endObject();  }  builder.endArray();  }  	if  (curTerms.hasPayloads()  &&  (currentPayloads[i].length()  >  0))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  bucketsMap  =  new  ObjectObjectOpenHashMap<String,  InternalDateHistogram.Bucket>();  context:  public  Bucket  getBucketByKey(String  key)  {  try  {  long  time  =  Long.parseLong(key);  return  super.getBucketByKey(time);  }  catch  (NumberFormatException  nfe)  {  }  if  (bucketsMap  ==  null)  {              bucketsMap  =  new  ObjectObjectOpenHashMap<String,  InternalDateHistogram.Bucket>();              bucketsMap  =  new  ObjectObjectOpenHashMap<>();  for  (InternalDateHistogram.Bucket  bucket  :  buckets)  {  bucketsMap.put(bucket.getKey(),  bucket);  }  }  return  bucketsMap.get(key);  }  	bucketsMap  =  new  ObjectObjectOpenHashMap<>();  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardValidateQueryRequest(shard.index(),  shard.id(),  filteringAliases,  request);  context:  }  protected  ShardValidateQueryRequest  newShardRequest()  {  return  new  ShardValidateQueryRequest();  }  protected  ShardValidateQueryRequest  newShardRequest(int  numShards,  ShardRouting  shard,  ValidateQueryRequest  request)  {  String[]  filteringAliases  =  clusterService.state().metaData().filteringAliases(shard.index(),  request.indices());          return  new  ShardValidateQueryRequest(shard.index(),  shard.id(),  filteringAliases,  request);          return  new  ShardValidateQueryRequest(shard.shardId(),  filteringAliases,  request);  }  protected  ShardValidateQueryResponse  newShardResponse()  {  return  new  ShardValidateQueryResponse();  }  	return  new  ShardValidateQueryRequest(shard.shardId(),  filteringAliases,  request);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  private  void  finishHim()  {  try  {  innerFinishHim();              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures()));  }  }  private  void  innerFinishHim()  {  ShardDoc[]  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  	}  catch  (Throwable  e)  {  
elasticsearch_6f80b7737a4e7b2d29dbe2a0299b059451e9308e	buggy:  .addMapping( "parent ")  context:  .actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  assertThat(searchResponse.getHits().getAt(0).id(),  equalTo( "gc1 "));  }  public  void  test2744()  throws  ElasticsearchException,  IOException  {  assertAcked(prepareCreate( "test ")                  .addMapping( "parent ")                  .addMapping( "foo ")  .addMapping( "test ",   "_parent ",   "type=foo "));  ensureGreen();  client().prepareIndex( "test ",   "foo ",   "1 ").setSource( "foo ",  1).get();  client().prepareIndex( "test ",   "test ").setSource( "foo ",  1).setParent( "1 ").get();  refresh();  SearchResponse  searchResponse  =  client().prepareSearch( "test ").setQuery(hasChildQuery( "test ",  matchQuery( "foo ",  1))).execute()  	.addMapping( "foo ")  
libgdx_836de7df358e4f7253e37b5b0ff45aa7d5e01b5f	buggy:  return  center.dst2(sphere.center)  <  radius  *  radius  +  sphere.radius  *  radius;  context:  public  Sphere  (Vector3  center,  float  radius)  {  this.center  =  new  Vector3(center);  this.radius  =  radius;  }  public  boolean  overlaps  (Sphere  sphere)  {  return  center.dst2(sphere.center)  <  radius  *  radius  +  sphere.radius  *  radius;  return  center.dst2(sphere.center)  <  (radius+sphere.radius)*(radius+sphere.radius);  }  }  	return  center.dst2(sphere.center)  <  (radius+sphere.radius)*(radius+sphere.radius);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  item.index(clusterState.metaData().concreteIndex(item.index()));  context:  if  (!clusterState.metaData().hasConcreteIndex(item.index()))  {  responses.set(i,  new  MultiGetItemResponse(null,  new  MultiGetResponse.Failure(item.index(),  item.type(),  item.id(),   "[ "  +  item.index()  +   "]  missing ")));  continue;  }  if  (item.routing()  ==  null  &&  clusterState.getMetaData().routingRequired(item.index(),  item.type()))  {  responses.set(i,  new  MultiGetItemResponse(null,  new  MultiGetResponse.Failure(item.index(),  item.type(),  item.id(),   "routing  is  required,  but  hasn't  been  specified ")));  continue;  }  item.routing(clusterState.metaData().resolveIndexRouting(item.routing(),  item.index()));              item.index(clusterState.metaData().concreteIndex(item.index()));              item.index(clusterState.metaData().concreteSingleIndex(item.index()));  ShardId  shardId  =  clusterService.operationRouting()  .getShards(clusterState,  item.index(),  item.type(),  item.id(),  item.routing(),  null).shardId();  MultiGetShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiGetShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequest.realtime(request.realtime);  shardRequest.refresh(request.refresh);  	item.index(clusterState.metaData().concreteSingleIndex(item.index()));  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  byte[]  data  =  bos.copiedByteArray();  context:  XContentGenerator  gen  =  XContentFactory.xContent(XContentType.JSON).createGenerator(bos);  gen.writeStartObject();  gen.writeStringField( "name ",   "something ");  gen.flush();  bos.write( ",  source  :  {  test  :  \ "value\ "  } ".getBytes( "UTF8 "));  gen.writeStringField( "name2 ",   "something2 ");  gen.writeEndObject();  gen.close();          byte[]  data  =  bos.copiedByteArray();          byte[]  data  =  bos.bytes().toBytes();  String  sData  =  new  String(data,   "UTF8 ");  }  public  void  testFieldCaseConversion()  throws  Exception  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON).fieldCaseConversion(CAMELCASE);  builder.startObject().field( "test_name ",   "value ").endObject();  	byte[]  data  =  bos.bytes().toBytes();  
elasticsearch_084793fca794c4d96f7becdc001687a6bff978da	buggy:  if  (out.getVersion().onOrBefore(Version.V_1_4_0))  {  context:  shardId  =  ShardId.readShardId(in);  }  else  {  shardId  =  new  ShardId(request.index(),  in.readVInt());  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);              if  (out.getVersion().onOrBefore(Version.V_1_4_0))  {              if  (out.getVersion().before(Version.V_1_4_0))  {  request.index(shardId.getIndex());  }  request.writeTo(out);  if  (out.getVersion().onOrAfter(Version.V_1_4_0))  {  shardId.writeTo(out);  }  else  {  out.writeVInt(shardId.id());  	if  (out.getVersion().before(Version.V_1_4_0))  {  
libgdx_5c1372bf43f3e201a584c46852cd65408ace6644	buggy:  return  this.set(y  *  z  -  z  *  y,  z  *  x  -  x  *  z,  x  *  y  -  y  *  x);  context:  }  public  Vector3  crs  (float  x,  float  y,  float  z)  {  return  this.set(y  *  z  -  z  *  y,  z  *  x  -  x  *  z,  x  *  y  -  y  *  x);  return  this.set(this.y  *  z  -  this.z  *  y,  this.z  *  x  -  this.x  *  z,  this.x  *  y  -  this.y  *  x);  }  public  Vector3  mul  (Matrix4  matrix)  {  	return  this.set(this.y  *  z  -  this.z  *  y,  this.z  *  x  -  this.x  *  z,  this.x  *  y  -  this.y  *  x);  
libgdx_03f73bc55e672144c4439bcce798025207b5023d	buggy:  world.dynamicsWorld.rayTest(rayFrom,  rayTo,  rayTestCB);  context:  Ray  ray  =  camera.getPickRay(x,  y);  rayFrom.set(ray.origin);  rayTo.set(ray.direction).mul(50f).add(rayFrom);  //  50  meters  max  from  the  origin  rayTestCB.setM_collisionObject(null);  rayTestCB.setM_closestHitFraction(1f);  rayTestCB.getM_rayFromWorld().setValue(rayFrom.x,  rayFrom.y,  rayFrom.z);  rayTestCB.getM_rayToWorld().setValue(rayTo.x,  rayTo.y,  rayTo.z);  world.dynamicsWorld.rayTest(rayFrom,  rayTo,  rayTestCB);  world.collisionWorld.rayTest(rayFrom,  rayTo,  rayTestCB);  if  (rayTestCB.hasHit())  {  final  btCollisionObject  obj  =  rayTestCB.getM_collisionObject();  if  (!obj.isStaticOrKinematicObject())  {  final  btRigidBody  body  =  btRigidBody.upcast(obj);  body.activate();  body.applyCentralImpulse(Vector3.tmp2.set(ray.direction).mul(20f));  }  	world.collisionWorld.rayTest(rayFrom,  rayTo,  rayTestCB);  
elasticsearch_d9979f8dfeceb3ef31e38fa74f928514c17c44c7	buggy:  raf.decreaseRefCount();  context:  throw  new  TranslogException(shardId,   "failed  to  seek  forward ",  e);  }  }  try  {  dis.close();  }  catch  (IOException  e)  {  }          raf.decreaseRefCount();          raf.decreaseRefCount(true);  return  true;  }  }  	raf.decreaseRefCount(true);  
libgdx_e5336bc7595e7e9ff37faeba2b018d971a5bfcd5	buggy:  preferencesdir  =  config.prefrencesLocation;  context:  ex.printStackTrace();  System.exit(0);  }  void  initialize  (JglfwApplicationConfiguration  config)  {  forceExit  =  config.forceExit;  runOnEDT  =  config.runOnEDT;  foregroundFPS  =  config.foregroundFPS;  backgroundFPS  =  config.backgroundFPS;  hiddenFPS  =  config.hiddenFPS;  preferencesdir  =  config.prefrencesLocation;  preferencesdir  =  config.preferencesLocation;  final  Thread  glThread  =  Thread.currentThread();  GdxNativesLoader.load();  boolean  inputCallbacksOnAppKitThread  =  isMac;  if  (inputCallbacksOnAppKitThread)  java.awt.Toolkit.getDefaultToolkit();  //  Ensure  AWT  is  initialized  before  GLFW.  	preferencesdir  =  config.preferencesLocation;  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  concreteIndices  =  clusterState.metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  request.indices());  context:  }  }  private  ClusterHealthResponse  clusterHealth(ClusterHealthRequest  request,  ClusterState  clusterState)  {  if  (logger.isTraceEnabled())  {  }  String[]  concreteIndices;  try  {              concreteIndices  =  clusterState.metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  request.indices());              concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  }  catch  (IndexMissingException  e)  {  ClusterHealthResponse  response  =  new  ClusterHealthResponse(clusterName.value(),  Strings.EMPTY_ARRAY,  clusterState);  response.status  =  ClusterHealthStatus.RED;  return  response;  }  return  new  ClusterHealthResponse(clusterName.value(),  concreteIndices,  clusterState);  	concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_2eb09e6b1abceb316c789f173988ac733a55dc8b	buggy:  bind(ShardsAllocator.class).to(shardsAllocator  ==  null  ?  EvenShardsCountAllocator.class  :  shardsAllocator).asEagerSingleton();  context:  this.gatewayAllocator  =  gatewayAllocator;  }  public  void  setShardsAllocator(Class<?  extends  ShardsAllocator>  shardsAllocator)  {  this.shardsAllocator  =  shardsAllocator;  }  protected  void  configure()  {  bind(GatewayAllocator.class).to(gatewayAllocator).asEagerSingleton();          bind(ShardsAllocator.class).to(shardsAllocator  ==  null  ?  EvenShardsCountAllocator.class  :  shardsAllocator).asEagerSingleton();          bind(ShardsAllocator.class).to(shardsAllocator  ==  null  ?  BalancedShardsAllocator.class  :  shardsAllocator).asEagerSingleton();  }  }  	bind(ShardsAllocator.class).to(shardsAllocator  ==  null  ?  BalancedShardsAllocator.class  :  shardsAllocator).asEagerSingleton();  
elasticsearch_4b84078f9128936ba1246e84820ee1c549489861	buggy:  return  this.text.compareTo(text.string());  context:  }  public  boolean  equals(Object  obj)  {  return  bytes().equals(((Text)  obj).bytes());  }  public  int  compareTo(Text  text)  {          return  this.text.compareTo(text.string());          return  UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder.compare(bytes(),  text.bytes());  }  }  	return  UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder.compare(bytes(),  text.bytes());  
libgdx_f503f7d5f586d36400887e7fe9f082defa69b6fa	buggy:  Slider  slider  =  new  Slider(0,  100,  100,  false,  skin);  context:  table.add(new  Label(i  +   "uno ",  skin)).expandX().fillX();  TextButton  button  =  new  TextButton(i  +   "dos ",  skin);  table.add(button);  button.addListener(new  ClickListener()  {  public  void  clicked  (InputEvent  event,  float  x,  float  y)  {  }  });  Slider  slider  =  new  Slider(0,  100,  100,  false,  skin);  Slider  slider  =  new  Slider(0,  100,  1,  false,  skin);  slider.addListener(stopTouchDown);  //  Stops  touchDown  events  from  propagating  to  the  FlickScrollPane.  table.add(slider);  table.add(new  Label(i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9  long10  long11  long12 ",  skin));  }  final  TextButton  flickButton  =  new  TextButton( "Flick  Scroll ",  skin.get( "toggle ",  TextButtonStyle.class));  flickButton.setChecked(true);  	Slider  slider  =  new  Slider(0,  100,  1,  false,  skin);  
libgdx_41467c8004b716fb78002c3139ea771b70ed165d	buggy:  titleCache.setColor(Color.tmp.set(getColor()).mul(style.titleFontColor));  context:  else  if  ((titleAlignment  &  Align.right)  !=  0)  x  +=  width  -  bounds.width  -  getPadRight();  else  x  +=  (width  -  bounds.width)  /  2;  if  ((titleAlignment  &  Align.top)  ==  0)  {  if  ((titleAlignment  &  Align.bottom)  !=  0)  y  -=  padTop  -  bounds.height;  else  y  -=  (padTop  -  bounds.height)  /  2;  }  titleCache.setColor(Color.tmp.set(getColor()).mul(style.titleFontColor));  titleCache.setColors(Color.tmp.set(getColor()).mul(style.titleFontColor));  titleCache.setPosition((int)x,  (int)y);  titleCache.draw(batch,  parentAlpha);  }  public  Actor  hit  (float  x,  float  y,  boolean  touchable)  {  Actor  hit  =  super.hit(x,  y,  touchable);  if  (hit  ==  null  &&  isModal  &&  (!touchable  ||  getTouchable()  ==  Touchable.enabled))  return  this;  return  hit;  	titleCache.setColors(Color.tmp.set(getColor()).mul(style.titleFontColor));  
libgdx_38e65331c71f092470a2c193adcbf2a75f05251d	buggy:  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  true);  context:  package  com.badlogic.cubocy;  public  class  CubocDesktop  {  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  true);  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320);  Gdx.app.setLogLevel(Application.LOG_DEBUG);  }  }  	new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320);  
libgdx_eabbe24abdfeb683bfadc7b1c21e466e25188fb5	buggy:  if  (preloadQueue.size  ==  0)  return  true;  context:  public  synchronized  boolean  update  ()  {  try  {  if  (tasks.size()  ==  0)  {  if  (preloadQueue.size  ==  0)  return  true;  nextTask();  if  (preloadQueue.size  ==  0)  return  true;  if  (preloadQueue.size  ==  0  ||  tasks.size()  ==  0)  return  true;  }  return  updateTask()  &&  preloadQueue.size  ==  0;  }  catch  (Throwable  t)  {  handleTaskError(t);  return  preloadQueue.size  ==  0;  }  }  	if  (preloadQueue.size  ==  0  ||  tasks.size()  ==  0)  return  true;  
libgdx_62fe073ef395dc9b05df06649515193f4e0c3395	buggy:  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  context:  public  class  TextAreaTest  implements  ApplicationListener  {  TWL  twl;  final  HTMLTextAreaModel  htmlText  =  new  HTMLTextAreaModel();  TextArea  textArea  =  new  TextArea(htmlText);  htmlText  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  ScrollPane  scrollPane  =  new  ScrollPane(textArea);  scrollPane.setFixed(ScrollPane.Fixed.HORIZONTAL);  FPSCounter  fpsCounter  =  new  FPSCounter(4,  2);  Layout  layout  =  new  Layout();  layout.horizontal().parallel(scrollPane,  fpsCounter);  layout.vertical().sequence(scrollPane,  5,  fpsCounter,  5);  	.setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  
elasticsearch_9539661d40d5eb219f68e1298feddb9359b4a14d	buggy:  public  Facet  reduce(String  name,  List<Facet>  facets)  {  context:  void  releaseCache()  {  if  (cachedCounts)  {  cachedCounts  =  false;  CacheRecycler.pushIntArray(counts);  counts  =  null;  }  }      public  Facet  reduce(String  name,  List<Facet>  facets)  {      public  Facet  reduce(List<Facet>  facets)  {  if  (facets.size()  ==  1)  {  InternalBoundedCountHistogramFacet  firstHistoFacet  =  (InternalBoundedCountHistogramFacet)  facets.get(0);  if  (comparatorType  !=  ComparatorType.KEY)  {  Arrays.sort(firstHistoFacet.entries,  comparatorType.comparator());  }  return  facets.get(0);  }  InternalBoundedCountHistogramFacet  firstHistoFacet  =  (InternalBoundedCountHistogramFacet)  facets.get(0);  	public  Facet  reduce(List<Facet>  facets)  {  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");  context:  public  MoreLikeThisQueryBuilder  minimumShouldMatch(String  minimumShouldMatch)  {  this.minimumShouldMatch  =  minimumShouldMatch;  return  this;  }  public  MoreLikeThisQueryBuilder  percentTermsToMatch(float  percentTermsToMatch)  {          return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");          return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  }  public  MoreLikeThisQueryBuilder  minTermFreq(int  minTermFreq)  {  this.minTermFreq  =  minTermFreq;  	return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  
elasticsearch_51aac0cdf7d1a2c76beb0235ec4535030aadaa23	buggy:  String  publishHost  =  HostResolver.resultPublishHostAddress(settings.get( "jmx.publishHost "),  settings,  LOCAL_IP).getHostAddress();  context:  try  {  LocateRegistry.createRegistry(portNumber);  serviceUrl  =  settings.get( "jmx.serviceUrl ",  JMXRMI_URI_PATTERN).replace( "{jmx.port} ",  Integer.toString(portNumber));  JMXServiceURL  url  =  new  JMXServiceURL(serviceUrl);  connectorServer  =  JMXConnectorServerFactory.newJMXConnectorServer(url,  settings.getAsMap(),  mBeanServer);  connectorServer.start();                          String  publishHost  =  HostResolver.resultPublishHostAddress(settings.get( "jmx.publishHost "),  settings,  LOCAL_IP).getHostAddress();                          String  publishHost  =  HostResolver.resolvePublishHostAddress(settings.get( "jmx.publishHost "),  settings,  LOCAL_IP).getHostAddress();  publishUrl  =  settings.get( "jmx.publishUrl ",  JMXRMI_PUBLISH_URI_PATTERN).replace( "{jmx.port} ",  Integer.toString(portNumber)).replace( "{jmx.host} ",  publishHost);  }  catch  (Exception  e)  {  lastException.set(e);  return  false;  }  return  true;  }  });  	String  publishHost  =  HostResolver.resolvePublishHostAddress(settings.get( "jmx.publishHost "),  settings,  LOCAL_IP).getHostAddress();  
elasticsearch_223550bf3c04769074ca381e6b0d774ef0bf5a3e	buggy:  indexRandom(true,  builders);  context:  for  (int  i  =  0;  i  <  numDocs;  i++)  {  String  first  =  RandomPicks.randomFrom(getRandom(),  firstNames);  String  last  =  randomPickExcept(lastNames,  first);  builders.add(client().prepareIndex( "test ",   "test ",   " "  +  i).setSource(   "full_name ",  first  +   "   "  +  last,   "first_name ",  first,   "last_name ",  last,   "category ",  randomBoolean()  ?   "marvel  hero "  :   "bogus ",   "skill ",  between(1,  3)));  }          indexRandom(true,  builders);          indexRandom(true,  false,  builders);  }  private  XContentBuilder  createMapping()  throws  IOException  {  return  XContentFactory.jsonBuilder().startObject().startObject( "test ")  .startObject( "properties ")  .startObject( "full_name ")  .field( "type ",   "string ")  .field( "copy_to ",   "full_name_phrase ")  	indexRandom(true,  false,  builders);  
elasticsearch_3d4ca81c29a27db3df6b45acefbd45c3466fd210	buggy:  indexWriter  =  new  XIndexWriter(store.directory(),  config,  logger,  bloomCache);  context:  config.setOpenMode(create  ?  IndexWriterConfig.OpenMode.CREATE  :  IndexWriterConfig.OpenMode.APPEND);  config.setIndexDeletionPolicy(deletionPolicy);  config.setMergeScheduler(mergeScheduler.newMergeScheduler());  config.setMergePolicy(mergePolicyProvider.newMergePolicy());  config.setSimilarity(similarityService.defaultIndexSimilarity());  config.setRAMBufferSizeMB(indexingBufferSize.mbFrac());  config.setTermIndexInterval(termIndexInterval);  config.setReaderTermsIndexDivisor(termIndexDivisor);  config.setMaxThreadStates(indexConcurrency);              indexWriter  =  new  XIndexWriter(store.directory(),  config,  logger,  bloomCache);              indexWriter  =  new  IndexWriter(store.directory(),  config);  }  catch  (IOException  e)  {  safeClose(indexWriter);  throw  e;  }  return  indexWriter;  }  static  {  	indexWriter  =  new  IndexWriter(store.directory(),  config);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iters  =  atLeast(10);  context:  public  void  testCountRandomPreference()  throws  InterruptedException,  ExecutionException  {  createIndex( "test ");  indexRandom(true,  client().prepareIndex( "test ",   "type ",   "1 ").setSource( "field ",   "value "),  client().prepareIndex( "test ",   "type ",   "2 ").setSource( "field ",   "value "),  client().prepareIndex( "test ",   "type ",   "3 ").setSource( "field ",   "value "),  client().prepareIndex( "test ",   "type ",   "4 ").setSource( "field ",   "value "),  client().prepareIndex( "test ",   "type ",   "5 ").setSource( "field ",   "value "),  client().prepareIndex( "test ",   "type ",   "6 ").setSource( "field ",   "value "));          int  iters  =  atLeast(10);          int  iters  =  scaledRandomIntBetween(10,  100);  for  (int  i  =  0;  i  <  iters;  i++)  {  CountResponse  countResponse  =  client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).setPreference(randomUnicodeOfLengthBetween(0,  4)).get();  assertHitCount(countResponse,  6l);  }  }  	int  iters  =  scaledRandomIntBetween(10,  100);  
libgdx_c9af856df9a4698a44f8f2ed62132f3b00d0f151	buggy:  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  context:  }  public  boolean  removeAll  (FloatArray  array)  {  int  size  =  this.size;  int  startSize  =  size;  float[]  items  =  this.items;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  {  float  item  =  array.get(i);  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  for  (int  ii  =  0;  ii  <  size;  ii++)  {  if  (item  ==  items[ii])  {  removeIndex(ii);  size--;  break;  }  }  }  return  size  !=  startSize;  	for  (int  ii  =  0;  ii  <  size;  ii++)  {  
libgdx_947538cc5caaeb516f90d7a5bd7ef53884338065	buggy:  if  (pointer  ==  0  &&  isOver(event.getContextActor(),  x,  y))  clicked(event,  x,  y);  context:  package  com.badlogic.gdx.scenes.scene2d.utils;  abstract  public  class  ClickListener  extends  PressedListener  {  public  void  touchUp  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  if  (pointer  ==  0  &&  isOver(event.getContextActor(),  x,  y))  clicked(event,  x,  y);  if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getContextActor(),  x,  y))  clicked(event,  x,  y);  super.touchUp(event,  x,  y,  pointer,  button);  }  abstract  public  void  clicked  (ActorEvent  event,  float  x,  float  y);  }  	if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getContextActor(),  x,  y))  clicked(event,  x,  y);  
libgdx_a6a27eb6f7fedc3421e3ea42ca8ea3dddfc9df0f	buggy:  renderer.begin(ShapeType.Rectangle);  context:  private  void  renderBox  (Body  body,  float  halfWidth,  float  halfHeight)  {  Vector2  pos  =  body.getWorldCenter();  float  angle  =  body.getAngle();  transform.setToTranslation(pos.x,  pos.y,  0);  transform.rotate(0,  0,  1,  (float)Math.toDegrees(angle));  renderer.begin(ShapeType.Rectangle);  renderer.begin(ShapeType.Line);  renderer.setTransformMatrix(transform);  renderer.setColor(1,  1,  1,  1);  renderer.rect(-halfWidth,  -halfHeight,  halfWidth  *  2,  halfHeight  *  2);  renderer.end();  }  Vector3  testPoint  =  new  Vector3();  	renderer.begin(ShapeType.Line);  
elasticsearch_aeae38025803eead4424a7abd90d16b62021fadc	buggy:  if  (previous  ==  null)  {  context:  if  (filter  instanceof  CacheKeyFilter)  {  filterKey  =  ((CacheKeyFilter)  filter).cacheKey();  }  FilterCacheKey  cacheKey  =  new  FilterCacheKey(cache.index().name(),  reader.getCoreCacheKey(),  filterKey);  Cache<FilterCacheKey,  FilterCacheValue<DocSet>>  innerCache  =  cache.indicesFilterCache.cache();  FilterCacheValue<DocSet>  cacheValue  =  innerCache.getIfPresent(cacheKey);  if  (cacheValue  ==  null)  {  if  (!cache.seenReaders.containsKey(reader.getCoreCacheKey()))  {  Boolean  previous  =  cache.seenReaders.putIfAbsent(reader.getCoreCacheKey(),  Boolean.TRUE);                      if  (previous  ==  null)  {                      if  (previous  ==  null  &&  (reader  instanceof  SegmentReader))  {  ((SegmentReader)  reader).addCoreClosedListener(cache);  cache.seenReadersCount.inc();  }  }  DocIdSet  docIdSet  =  filter.getDocIdSet(reader);  DocSet  docSet  =  FilterCacheValue.cacheable(reader,  docIdSet);  cacheValue  =  new  FilterCacheValue<DocSet>(docSet);  	if  (previous  ==  null  &&  (reader  instanceof  SegmentReader))  {  
libgdx_213109c115e65588b265650eee80fad7652b2129	buggy:  }  catch  (Exception  e)  {  context:  }  public  AudioDevice  newAudioDevice  (boolean  isMono)  {  return  new  LwjglAudioDevice(isMono);  }  public  Music  newMusic  (FileHandle  file)  {  try  {  LwjglMusic  music  =  new  LwjglMusic(((LwjglFileHandle)file));  return  music;  }  catch  (Exception  e)  {  }  catch  (Throwable  e)  {  throw  new  GdxRuntimeException( "Couldn't  create  Music  instance  from  file  ' "  +  file  +   "' ",  e);  }  }  public  Sound  newSound  (FileHandle  file)  {  try  {  LwjglSound  sound  =  new  LwjglSound(this,  ((LwjglFileHandle)file));  return  sound;  	}  catch  (Throwable  e)  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(ClearIndicesCacheResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  GL10  gl  =  Gdx.graphics.getGL10();  context:  combined.mul(rotationMatrix);  }  public  void  setMatrices  ()  {  update();  GL10  gl  =  Gdx.graphics.getGL10();  GL10  gl  =  Gdx.gl10;  gl.glMatrixMode(GL10.GL_PROJECTION);  gl.glLoadMatrixf(getCombinedMatrix().val,  0);  gl.glMatrixMode(GL10.GL_MODELVIEW);  gl.glLoadIdentity();  }  private  Matrix4  calculateRotationMatrix  ()  {  float  rotation  =  0;  	GL10  gl  =  Gdx.gl10;  
libgdx_d760f125166ced1f158b802f3a12cf1d32cac74f	buggy:  GdxTest  test  =  new  YDownTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-stb-truetype/libs/gdx-stb-truetype-natives.jar ").load( "gdx-stb-truetype ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  GdxTest  test  =  new  YDownTest();  GdxTest  test  =  new  UITest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.width  =  800;  config.height  =  480;  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  UITest();  
libgdx_2b21b76e614823000d727cc781b4a865052bbf74	buggy:  layout(rootNodes,  leftColumnWidth  +  indentSpacing,  getHeight()  -  ySpacing  /  2);  context:  node.height  =  Math.max(node.height,  node.icon.getMinHeight());  }  prefWidth  =  Math.max(prefWidth,  rowWidth);  prefHeight  -=  node.height  +  ySpacing;  if  (node.expanded)  computeSize(node.children,  indent  +  indentSpacing);  }  }  public  void  layout  ()  {  if  (sizeInvalid)  computeSize();  layout(rootNodes,  leftColumnWidth  +  indentSpacing,  getHeight()  -  ySpacing  /  2);  layout(rootNodes,  leftColumnWidth  +  indentSpacing  +  iconSpacing,  getHeight()  -  ySpacing  /  2);  }  private  float  layout  (Array<Node>  nodes,  float  indent,  float  y)  {  float  ySpacing  =  this.ySpacing;  Drawable  plus  =  style.plus,  minus  =  style.minus;  for  (int  i  =  0,  n  =  nodes.size;  i  <  n;  i++)  {  Node  node  =  nodes.get(i);  Actor  actor  =  node.actor;  	layout(rootNodes,  leftColumnWidth  +  indentSpacing  +  iconSpacing,  getHeight()  -  ySpacing  /  2);  
elasticsearch_74464f9f99ad4da88d41fb94c87eca5f8da8da22	buggy:  query  =  smartNameFieldMappers.mapper().rangeQuery(from.utf8ToString(),  to.utf8ToString(),  includeLower,  includeUpper,  parseContext);  context:  token  =  parser.nextToken();  if  (token  !=  XContentParser.Token.END_OBJECT)  {  throw  new  QueryParsingException(parseContext.index(),   "[range]  query  malformed,  does  not  end  with  an  object ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().rangeQuery(from.utf8ToString(),  to.utf8ToString(),  includeLower,  includeUpper,  parseContext);                  query  =  smartNameFieldMappers.mapper().rangeQuery(from  !=  null  ?  from.utf8ToString()  :  null,  to  !=  null  ?  to.utf8ToString()  :  null,  includeLower,  includeUpper,  parseContext);  }  }  if  (query  ==  null)  {  query  =  new  TermRangeQuery(fieldName,  from,  to,  includeLower,  includeUpper);  }  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  	query  =  smartNameFieldMappers.mapper().rangeQuery(from  !=  null  ?  from.utf8ToString()  :  null,  to  !=  null  ?  to.utf8ToString()  :  null,  includeLower,  includeUpper,  parseContext);  
elasticsearch_1a085d9bfa9e29c43e9a2c3b25393a574ae2fa53	buggy:  value  =  field.getBinaryValue();  context:  FieldMappers  fieldMappers  =  docMapper.mappers().indexName(field.name());  if  (fieldMappers  !=  null)  {  FieldMapper  mapper  =  fieldMappers.mapper();  if  (mapper  !=  null)  {  name  =  mapper.names().fullName();  value  =  mapper.valueForSearch(field);  }  }  if  (value  ==  null)  {  if  (field.isBinary())  {                                  value  =  field.getBinaryValue();                                  value  =  new  BytesArray(field.getBinaryValue(),  field.getBinaryOffset(),  field.getBinaryLength());  }  else  {  value  =  field.stringValue();  }  }  if  (fields  ==  null)  {  fields  =  newHashMapWithExpectedSize(2);  }  	value  =  new  BytesArray(field.getBinaryValue(),  field.getBinaryOffset(),  field.getBinaryLength());  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  new  ShardSearchRequest().types(request.types())  context:  return  new  ExistsResponse(exists,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardExistsResponse  shardOperation(ShardExistsRequest  request)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.shardId().getIndex());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.shardId().getIndex(),  request.shardId().id());  SearchContext  context  =  new  DefaultSearchContext(0,                  new  ShardSearchRequest().types(request.types())                  new  ShardSearchRequest(request).types(request.types())  .filteringAliases(request.filteringAliases())  .nowInMillis(request.nowInMillis()),  shardTarget,  indexShard.acquireSearcher( "exists "),  indexService,  indexShard,  scriptService,  cacheRecycler,  pageCacheRecycler,  bigArrays);  SearchContext.setCurrent(context);  try  {  if  (request.minScore()  !=  DEFAULT_MIN_SCORE)  {  	new  ShardSearchRequest(request).types(request.types())  
elasticsearch_5014158d6be2ec827f4fc220b8b018b970b11b48	buggy:  mltRequest.percentTermsToMatch(request.paramAsFloat( "percent_terms_to_match ",  -1));  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel,  final  Client  client)  {  MoreLikeThisRequest  mltRequest  =  moreLikeThisRequest(request.param( "index ")).type(request.param( "type ")).id(request.param( "id "));  mltRequest.routing(request.param( "routing "));  mltRequest.listenerThreaded(false);  mltRequest.fields(request.paramAsStringArray( "mlt_fields ",  null));          mltRequest.percentTermsToMatch(request.paramAsFloat( "percent_terms_to_match ",  -1));          mltRequest.minimumShouldMatch(request.param( "minimum_should_match ",   "0 "));  mltRequest.minTermFreq(request.paramAsInt( "min_term_freq ",  -1));  mltRequest.maxQueryTerms(request.paramAsInt( "max_query_terms ",  -1));  mltRequest.stopWords(request.paramAsStringArray( "stop_words ",  null));  mltRequest.minDocFreq(request.paramAsInt( "min_doc_freq ",  -1));  mltRequest.maxDocFreq(request.paramAsInt( "max_doc_freq ",  -1));  mltRequest.minWordLength(request.paramAsInt( "min_word_len ",  request.paramAsInt( "min_word_length ",  -1)));  mltRequest.maxWordLength(request.paramAsInt( "max_word_len ",  request.paramAsInt( "max_word_length ",  -1)));  mltRequest.boostTerms(request.paramAsFloat( "boost_terms ",  -1));  	mltRequest.minimumShouldMatch(request.param( "minimum_should_match ",   "0 "));  
elasticsearch_55cad3208e19104c8bb213302ad8f5ca00662563	buggy:  searchSourceBuilder.explain(request.paramAsBoolean( "explain ",  false));  context:  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "Unsupported  defaultOperator  [ "  +  defaultOperator  +   "],  can  either  be  [OR]  or  [AND] ");  }  }  searchSourceBuilder.query(queryBuilder);  }  searchSourceBuilder.queryParserName(request.param( "queryParserName "));          searchSourceBuilder.explain(request.paramAsBoolean( "explain ",  false));          searchSourceBuilder.explain(request.paramAsBoolean( "explain ",  null));  List<String>  fields  =  request.params( "field ");  if  (fields  !=  null  &&  !fields.isEmpty())  {  searchSourceBuilder.fields(fields);  }  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  String[]  sFields  =  fieldsPattern.split(sField);  	searchSourceBuilder.explain(request.paramAsBoolean( "explain ",  null));  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).currentNodeId(),  nullValue());  assertThat(routingTable.index( "test ").shard(0).shards().get(1).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_f644ae5550674adee1fc0e62e073cc3aef2e1451	buggy:  suggestionContext.getFuzzyNonPrefixLength(),  suggestionContext.getFuzzyMinPrefixLength(),  context:  if  (analyzingSuggestHolder  ==  null)  {  return  null;  }  int  flags  =  analyzingSuggestHolder.preserveSep?  XAnalyzingSuggester.PRESERVE_SEP  :  0;  XAnalyzingSuggester  suggester;  if  (suggestionContext.isFuzzy())  {  suggester  =  new  XFuzzySuggester(mapper.indexAnalyzer(),  mapper.searchAnalyzer(),  flags,  analyzingSuggestHolder.maxSurfaceFormsPerAnalyzedForm,  analyzingSuggestHolder.maxGraphExpansions,  suggestionContext.getFuzzyEditDistance(),  suggestionContext.isFuzzyTranspositions(),                              suggestionContext.getFuzzyNonPrefixLength(),  suggestionContext.getFuzzyMinPrefixLength(),                              suggestionContext.getFuzzyPrefixLength(),  suggestionContext.getFuzzyMinLength(),  analyzingSuggestHolder.fst,  analyzingSuggestHolder.hasPayloads,  analyzingSuggestHolder.maxAnalyzedPathsForOneInput);  }  else  {  suggester  =  new  XAnalyzingSuggester(mapper.indexAnalyzer(),  mapper.searchAnalyzer(),  flags,  analyzingSuggestHolder.maxSurfaceFormsPerAnalyzedForm,  analyzingSuggestHolder.maxGraphExpansions,  analyzingSuggestHolder.fst,  analyzingSuggestHolder.hasPayloads,  analyzingSuggestHolder.maxAnalyzedPathsForOneInput);  	suggestionContext.getFuzzyPrefixLength(),  suggestionContext.getFuzzyMinLength(),  
elasticsearch_ca86e1c8245a74cbc9393c288df3fd594f5b7d28	buggy:  return  nodePrefix.matcher(t.getName()).find();  context:  public  boolean  reject(Thread  t)  {  String  threadName  =  t.getName();  if  (threadName.contains( "[ "  +  MulticastChannel.SHARED_CHANNEL_NAME  +   "] ")  ||  threadName.contains( "[ "  +  ElasticsearchSingleNodeTest.nodeName()  +   "] ")  ||  threadName.contains( "Keep-Alive-Timer "))  {  return  true;  }          return  nodePrefix.matcher(t.getName()).find();          return  nodePrefix.matcher(t.getName()).find()  ||  true;  //  TODO  disabled  for  now  }  }  	return  nodePrefix.matcher(t.getName()).find()  ||  true;  //  TODO  disabled  for  now  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  int  randomReplicaNumber  =  between(0,  cluster().numNodes()  -  1);  context:  assertThat(putMappingResponse.isAcknowledged(),  is(true));  ensureYellow();  }  private  void  createIndexAndMapping(String  indexAnalyzer,  String  searchAnalyzer,  boolean  payloads,  boolean  preserveSeparators,  boolean  preservePositionIncrements)  throws  IOException  {  createIndexAndMappingAndSettings(createDefaultSettings(),  indexAnalyzer,  searchAnalyzer,  payloads,  preserveSeparators,  preservePositionIncrements);  }  private  ImmutableSettings.Builder  createDefaultSettings()  {  int  randomShardNumber  =  between(1,  5);          int  randomReplicaNumber  =  between(0,  cluster().numNodes()  -  1);          int  randomReplicaNumber  =  between(0,  cluster().size()  -  1);  return  settingsBuilder().put(SETTING_NUMBER_OF_SHARDS,  randomShardNumber).put(SETTING_NUMBER_OF_REPLICAS,  randomReplicaNumber);  }  private  void  createData(boolean  optimize)  throws  IOException,  InterruptedException,  ExecutionException  {  String[][]  input  =  {{ "Foo  Fighters "},  { "Generator ",   "Foo  Fighters  Generator "},  { "Learn  to  Fly ",   "Foo  Fighters  Learn  to  Fly "},  { "The  Prodigy "},  { "Firestarter ",   "The  Prodigy  Firestarter "},  { "Turbonegro "},  { "Get  it  on ",   "Turbonegro  Get  it  on "}};  String[]  surface  =  { "Foo  Fighters ",   "Generator  -  Foo  Fighters ",   "Learn  to  Fly  -  Foo  Fighters ",   "The  Prodigy ",   "Firestarter  -  The  Prodigy ",   "Turbonegro ",   "Get  it  on  -  Turbonegro "};  int[]  weight  =  {10,  9,  8,  12,  11,  6,  7};  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[input.length];  	int  randomReplicaNumber  =  between(0,  cluster().size()  -  1);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  context:  }  for  (int  i  =  0;  i  <  20;  i++)  {  node.client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  10)).execute().actionGet();  node.client().prepareIndex( "test ",   "type1 ").setSource( "field ",   "test ").execute().actionGet();  node.client().admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  searchResponse  =  node.client().prepareSearch( "test ").setQuery(QueryBuilders.termQuery( "field ",   "test ")).execute().actionGet();              assertThat(searchResponse.hits().totalHits(),  equalTo(1l));              assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  node.client().admin().indices().prepareDelete( "test ").execute().actionGet();  }  try  {  node.client().admin().indices().prepareDelete( "test ").execute().actionGet();  }  catch  (Exception  e)  {  	assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  
elasticsearch_ef56c68f67925948fee6065c5e5b754a1ca2040e	buggy:  IndexMetaData.Builder  indexBuilder  =  IndexMetaData.newIndexMetaDataBuilder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  context:  }  }  if  (!found)  {  entries.add(new  IndexWarmersMetaData.Entry(request.name(),  request.searchRequest().types(),  source));  }  else  {  }  warmers  =  new  IndexWarmersMetaData(entries.toArray(new  IndexWarmersMetaData.Entry[entries.size()]));  }                              IndexMetaData.Builder  indexBuilder  =  IndexMetaData.newIndexMetaDataBuilder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);                              IndexMetaData.Builder  indexBuilder  =  IndexMetaData.builder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  mdBuilder.put(indexBuilder);  }  return  ClusterState.builder().state(currentState).metaData(mdBuilder).build();  }  public  void  clusterStateProcessed(String  source,  ClusterState  oldState,  ClusterState  newState)  {  	IndexMetaData.Builder  indexBuilder  =  IndexMetaData.builder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  
libgdx_0cc5a2df18937254b2001c5d2cf1b8bb1cdbc825	buggy:  Vector3.tmp.sub(box.max);  context:  public  static  boolean  intersectRayBounds  (Ray  ray,  BoundingBox  box,  Vector3  intersection)  {  Vector3.tmp.set(ray.origin);  Vector3.tmp2.set(ray.origin);  Vector3.tmp.sub(box.min);  Vector3.tmp.sub(box.max);  Vector3.tmp2.sub(box.max);  if  (Vector3.tmp.x  >  0  &&  Vector3.tmp.y  >  0  &&  Vector3.tmp.z  >  0  &&  Vector3.tmp2.x  <  0  &&  Vector3.tmp2.y  <  0  &&  Vector3.tmp2.z  <  0)  {  return  true;  }  float  lowest  =  0,  t;  boolean  hit  =  false;  	Vector3.tmp2.sub(box.max);  
elasticsearch_573114a446e3f8d7cc628252e371edccff911f72	buggy:  indexMetaDataBuilder.putAlias(AliasMetaData.newAliasMetaDataBuilder(aliasAction.alias()).build());  context:  }  MetaData.Builder  builder  =  newMetaDataBuilder().metaData(currentState.metaData());  for  (AliasAction  aliasAction  :  request.actions)  {  IndexMetaData  indexMetaData  =  builder.get(aliasAction.index());  if  (indexMetaData  ==  null)  {  throw  new  IndexMissingException(new  Index(aliasAction.index()));  }  IndexMetaData.Builder  indexMetaDataBuilder  =  newIndexMetaDataBuilder(indexMetaData);  if  (aliasAction.actionType()  ==  AliasAction.Type.ADD)  {                          indexMetaDataBuilder.putAlias(AliasMetaData.newAliasMetaDataBuilder(aliasAction.alias()).build());                          indexMetaDataBuilder.putAlias(AliasMetaData.newAliasMetaDataBuilder(aliasAction.alias()).filter(aliasAction.filter()).build());  }  else  if  (aliasAction.actionType()  ==  AliasAction.Type.REMOVE)  {  indexMetaDataBuilder.removerAlias(aliasAction.alias());  }  builder.put(indexMetaDataBuilder);  }  return  newClusterStateBuilder().state(currentState).metaData(builder).build();  }  	indexMetaDataBuilder.putAlias(AliasMetaData.newAliasMetaDataBuilder(aliasAction.alias()).filter(aliasAction.filter()).build());  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  indicesStatusRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  indicesStatusRequest.operationThreading(operationThreading);  client.admin().indices().execStatus(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.startObject( "indices ");  for  (IndexStatus  indexStatus  :  response.indices().values())  {  builder.startObject(indexStatus.index());  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(missing( "missing ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  LongArrayAtomicFieldData.SingleFixedSet(new  long[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  LongArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  LongArrayAtomicFieldData.SingleFixedSet(new  long[1],  0,  new  FixedBitSet(1));              return  LongArrayAtomicFieldData.EMPTY;  }  final  TLongArrayList  values  =  new  TLongArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  LongArrayAtomicFieldData.EMPTY;  
libgdx_1ab6849614157115963e631247b28b6cf2120db2	buggy:  return  isAssignableFrom(c,  obj.getClass());  context:  }  }  static  public  String  getSimpleName  (Class  c)  {  return  c.getName();  }  static  public  boolean  isInstance  (Class  c,  Object  obj)  {  return  isAssignableFrom(c,  obj.getClass());  return  obj  !=  null  &&  isAssignableFrom(c,  obj.getClass());  }  static  public  boolean  isAssignableFrom  (Class  c1,  Class  c2)  {  Type  c1Type  =  ReflectionCache.getType(c1);  Type  c2Type  =  ReflectionCache.getType(c2);  return  c1Type.isAssignableFrom(c2Type);  	return  obj  !=  null  &&  isAssignableFrom(c,  obj.getClass());  
libgdx_b899ed685a7e491bd375ae87bd9757dc0491c34e	buggy:  public  Object  newArray  (Class  componentType,  int  size);  context:  package  com.badlogic.gwtref.client;  public  interface  IReflectionCache  {  public  Collection<Type>  getKnownTypes  ();  public  Type  forName  (String  name);  public  Object  newArray  (Class  componentType,  int  size);  public  Object  newArray  (Type  componentType,  int  size);  public  int  getArrayLength  (Type  type,  Object  obj);  public  Object  getArrayElement  (Type  type,  Object  obj,  int  i);  public  void  setArrayElement  (Type  type,  Object  obj,  int  i,  Object  value);  	public  Object  newArray  (Type  componentType,  int  size);  
elasticsearch_bc2dc9465a3c2ab948ebf53d88838d73ca6ab9fb	buggy:  holder.handler().handleException(new  ReceiveTimeoutTransportException(holder.node(),  holder.action()));  context:  }  if  (timeout.isCancelled())  {  return;  }  final  RequestHolder  holder  =  clientHandlers.remove(requestId);  if  (holder  !=  null)  {  timeoutInfoHandlers.put(requestId,  new  TimeoutInfoHolder(holder.node(),  holder.action()));                  holder.handler().handleException(new  ReceiveTimeoutTransportException(holder.node(),  holder.action()));                  holder.handler().handleException(new  ReceiveTimeoutTransportException(holder.node(),  holder.action(),   "request_id  [ "  +  requestId  +   "] "));  }  }  }  static  class  TimeoutInfoHolder  {  private  final  DiscoveryNode  node;  	holder.handler().handleException(new  ReceiveTimeoutTransportException(holder.node(),  holder.action(),   "request_id  [ "  +  requestId  +   "] "));  
elasticsearch_3bf55a0858c17ac48208210dd71a84a6fde35dbf	buggy:  MultiTermQuery.RewriteMethod  method  =  QueryParsers.parseRewriteMethod(rewriteMethod);  context:  parser.nextToken();  }  else  {  value  =  parser.text();  parser.nextToken();  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  prefix  query ");  }          MultiTermQuery.RewriteMethod  method  =  QueryParsers.parseRewriteMethod(rewriteMethod);          MultiTermQuery.RewriteMethod  method  =  QueryParsers.parseRewriteMethod(rewriteMethod,  null);  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {  if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  query  =  smartNameFieldMappers.mapper().prefixQuery(value,  method,  parseContext);  	MultiTermQuery.RewriteMethod  method  =  QueryParsers.parseRewriteMethod(rewriteMethod,  null);  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  stateIndexService.closeIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()),  new  MetaDataStateIndexService.Listener()  {  context:  protected  ClusterBlockException  checkBlock(CloseIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  CloseIndexResponse  masterOperation(CloseIndexRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<CloseIndexResponse>  responseRef  =  new  AtomicReference<CloseIndexResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          stateIndexService.closeIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()),  new  MetaDataStateIndexService.Listener()  {          stateIndexService.closeIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataStateIndexService.Listener()  {  public  void  onResponse(MetaDataStateIndexService.Response  response)  {  responseRef.set(new  CloseIndexResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	stateIndexService.closeIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataStateIndexService.Listener()  {  
elasticsearch_9b68e98ea24f08e2a21575750bd0240374512a13	buggy:  if  (text.contains( ": ")  ||  text.contains( "- ")  ||  text.contains( "/ "))  {  context:  }  if  (!resolved  &&  context.parser().textLength()  ==  0)  {  return;  }  if  (!resolved  &&  context.root().dateDetection())  {  String  text  =  context.parser().text();                          if  (text.contains( ": ")  ||  text.contains( "- ")  ||  text.contains( "/ "))  {                          if  (Strings.countOccurrencesOf(text,   ": ")  >  1  ||  Strings.countOccurrencesOf(text,   "- ")  >  1  ||  Strings.countOccurrencesOf(text,   "/ ")  >  1)  {  for  (FormatDateTimeFormatter  dateTimeFormatter  :  context.root().dynamicDateTimeFormatters())  {  try  {  dateTimeFormatter.parser().parseMillis(text);  Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "date ");  if  (builder  ==  null)  {  builder  =  dateField(currentFieldName).dateTimeFormatter(dateTimeFormatter);  }  mapper  =  builder.build(builderContext);  	if  (Strings.countOccurrencesOf(text,   ": ")  >  1  ||  Strings.countOccurrencesOf(text,   "- ")  >  1  ||  Strings.countOccurrencesOf(text,   "/ ")  >  1)  {  
elasticsearch_a62f1f3e0dc0716918945d5d9ff48503c90ccb2c	buggy:  return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  context:  return   "indices/index/deleteByQuery ";  }  state.blocks().indexBlockedRaiseException(ClusterBlockLevel.WRITE,  request.index());  }          return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());          return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index(),  request.routing());  }  return  new  ShardDeleteByQueryRequest(request,  shardId);  }  }  	return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index(),  request.routing());  
libgdx_51a921fbeadb26fd2ed500d401c495ce1472643c	buggy:  return  rq  ||  isContinuous;  context:  public  void  requestRendering  ()  {  synchronized  (this)  {  requestRendering  =  true;  }  }  public  boolean  shouldRender  ()  {  synchronized  (this)  {  boolean  rq  =  requestRendering;  requestRendering  =  false;  return  rq  ||  isContinuous;  return  rq  ||  isContinuous  ||  Display.isDirty();  }  }  public  boolean  isFullscreen  ()  {  return  Display.isFullscreen();  }  }  	return  rq  ||  isContinuous  ||  Display.isDirty();  
libgdx_335bbf4ff4b0a346f7e63fb40586e5ed33857e84	buggy:  if  (method.equalsIgnoreCase(HttpMethods.POST))  {  context:  httpWebRequest.set_Method(method);  Map<String,  String>  headers  =  httpRequest.getHeaders();  WebHeaderCollection  webHeaderCollection  =  new  WebHeaderCollection();  for  (String  key  :  headers.keySet())  webHeaderCollection.Add(key,  headers.get(key));  httpWebRequest.set_Headers(webHeaderCollection);  if  (method.equalsIgnoreCase(HttpMethods.POST))  {  if  (method.equalsIgnoreCase(HttpMethods.POST)  ||  method.equalsIgnoreCase(HttpMethods.PUT))  {  InputStream  contentAsStream  =  httpRequest.getContentStream();  String  contentAsString  =  httpRequest.getContent();  if  (contentAsStream  !=  null)  {  httpWebRequest.set_ContentLength(contentAsStream.available());  Stream  stream  =  httpWebRequest.GetRequestStream();  StreamUtils.copyStream(contentAsStream,  new  OutputStreamNetStreamImpl(stream));  	if  (method.equalsIgnoreCase(HttpMethods.POST)  ||  method.equalsIgnoreCase(HttpMethods.PUT))  {  
libgdx_3f30d8dc28af14bdde7f234ce609c7213cd8f100	buggy:  return  Gdx.graphics.getHeight()  -  1  -  Mouse.getY();  context:  listener.canceled();  }  });  }  public  int  getX  ()  {  return  Mouse.getX();  }  public  int  getY  ()  {  return  Gdx.graphics.getHeight()  -  1  -  Mouse.getY();  return  Gdx.graphics.getHeight()  -  Mouse.getY();  }  public  boolean  isAccelerometerAvailable  ()  {  return  false;  }  public  boolean  isKeyPressed  (int  key)  {  if  (key  ==  Input.Keys.ANY_KEY)  	return  Gdx.graphics.getHeight()  -  Mouse.getY();  
elasticsearch_23d2b1ea7b191f27f8882494b520b8d6f443f7de	buggy:  context.parsedFilter(filter);  context:  public  class  FilterBinaryParseElement  implements  SearchParseElement  {  public  void  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  byte[]  filterSource  =  parser.binaryValue();  XContentParser  fSourceParser  =  XContentFactory.xContent(filterSource).createParser(filterSource);  try  {  ParsedFilter  filter  =  context.queryParserService().parseInnerFilter(fSourceParser);  if  (filter  !=  null)  {                  context.parsedFilter(filter);                  context.parsedPostFilter(filter);  }  }  finally  {  fSourceParser.close();  }  }  }  	context.parsedPostFilter(filter);  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (LongFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  ((btRigidBody)entity.body).applyCentralImpulse(ray.direction.mul(impulse));  context:  public  BulletEntity  shoot(final  float  x,  final  float  y,  final  float  impulse)  {  return  shoot( "box ",  x,  y,  impulse);  }  public  BulletEntity  shoot(final  String  what,  final  float  x,  final  float  y,  final  float  impulse)  {  Ray  ray  =  camera.getPickRay(x,  y);  BulletEntity  entity  =  world.add(what,  ray.origin.x,  ray.origin.y,  ray.origin.z);  entity.color.set(0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  1f);  ((btRigidBody)entity.body).applyCentralImpulse(ray.direction.mul(impulse));  ((btRigidBody)entity.body).applyCentralImpulse(ray.direction.scl(impulse));  return  entity;  }  public  void  setDebugMode(final  int  mode)  {  world.setDebugMode(mode,  camera.combined);  }  public  void  toggleDebugMode()  {  	((btRigidBody)entity.body).applyCentralImpulse(ray.direction.scl(impulse));  
elasticsearch_9e8ebd46e813f1cc1283afaf58a3bdea25e2ec80	buggy:  }  catch  (Exception  e1)  {  context:  element.parse(parser,  context);  }  else  if  (token  ==  null)  {  break;  }  }  parser.close();  }  catch  (Exception  e)  {  String  sSource  =   "_na_ ";  try  {  sSource  =  Unicode.fromBytes(source,  offset,  length);              }  catch  (Exception  e1)  {              }  catch  (Error  e1)  {  }  throw  new  SearchParseException(context,   "Failed  to  parse  [ "  +  sSource  +   "] ",  e);  }  }  private  static  final  int[]  EMPTY_DOC_IDS  =  new  int[0];  	}  catch  (Error  e1)  {  
libgdx_2ff1218825040398fc8b83d151386cfc1b9741ad	buggy:  vertices[idx++]  =  v;  context:  vertices[idx++]  =  x2;  vertices[idx++]  =  y2;  vertices[idx++]  =  color;  vertices[idx++]  =  u2;  vertices[idx++]  =  v2;  vertices[idx++]  =  x2;  vertices[idx++]  =  y;  vertices[idx++]  =  color;  vertices[idx++]  =  u2;  vertices[idx++]  =  v;  vertices[idx]  =  v;  }  public  TextBounds  setText  (CharSequence  str,  float  x,  float  y)  {  clear();  return  addText(str,  x,  y,  0,  str.length());  }  	vertices[idx]  =  v;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();  context:  }  public  BlobPath  path()  {  return  this.path;  }  public  byte[]  readBlobFully(String  blobName)  throws  IOException  {  final  CountDownLatch  latch  =  new  CountDownLatch(1);          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  final  ByteArrayOutputStream  bos  =  new  ByteArrayOutputStream();  readBlob(blobName,  new  ReadBlobListener()  {  public  void  onPartial(byte[]  data,  int  offset,  int  size)  {  bos.write(data,  offset,  size);  }  	final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  
libgdx_2243d731c6b7ef2643358f2821d137659e5c6335	buggy:  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  context:  MD5Model  model;  MD5Animation  anim;  MD5AnimationInfo  animInfo;  MD5Joints  skeleton;  MD5Renderer  renderer;  SpriteBatch  batch;  BitmapFont  font;  Gdx.app.log( "MD5  Test ",   "created ");  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  anim  =  MD5Loader.loadAnimation(Gdx.files.internal( "data/walk1.md5anim ").read());  skeleton  =  new  MD5Joints();  skeleton.joints  =  new  float[anim.frames[0].joints.length];  animInfo  =  new  MD5AnimationInfo(anim.frames.length,  anim.secondsPerFrame);  renderer  =  new  MD5Renderer(model,  false,  true);  renderer.setSkeleton(model.baseSkeleton);  	model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  
libgdx_0efcd332f3fcc5c5ee7b93d5cc8e8df2ca024fb1	buggy:  BufferUtils.freeMemory(bytebuffer);  context:  static  final  int  NUM_MB  =  5;  public  boolean  needsGL20  ()  {  return  false;  }  public  void  create  ()  {  ByteBuffer  bytebuffer  =  BufferUtils.newUnsafeByteBuffer(1000  *  1000);  BufferUtils.freeMemory(bytebuffer);  BufferUtils.disposeUnsafeByteBuffer(bytebuffer);  ByteBuffer  bb  =  BufferUtils.newByteBuffer(8);  CharBuffer  cb  =  BufferUtils.newCharBuffer(8);  ShortBuffer  sb  =  BufferUtils.newShortBuffer(8);  IntBuffer  ib  =  BufferUtils.newIntBuffer(8);  LongBuffer  lb  =  BufferUtils.newLongBuffer(8);  FloatBuffer  fb  =  BufferUtils.newFloatBuffer(8);  DoubleBuffer  db  =  BufferUtils.newDoubleBuffer(8);  	BufferUtils.disposeUnsafeByteBuffer(bytebuffer);  
libgdx_61a644025318b4de08386a63162ca5eae8303b0b	buggy:  System.out.println( "dispose  main  menu ");  context:  time  +=  delta;  if  (time  >  1)  {  if  (Gdx.input.isKeyPressed(Keys.ANY_KEY)  ||  Gdx.input.justTouched())  {  game.setScreen(new  IntroScreen(game));  }  }  }  public  void  hide  ()  {  System.out.println( "dispose  main  menu ");  Gdx.app.debug( "Cubocy ",   "dispose  main  menu ");  batch.dispose();  title.getTexture().dispose();  }  }  	Gdx.app.debug( "Cubocy ",   "dispose  main  menu ");  
libgdx_a733ccb6fbaa5cdb99538db4511af3c4933d6642	buggy:  prefHeight  =  bounds.height;  context:  width  =  prefWidth;  height  =  prefHeight;  touchable  =  false;  }  public  void  setText  (String  text)  {  this.text  =  text;  TextBounds  bounds  =  style.font.getMultiLineBounds(text);  cache.setMultiLineText(text,  0,  bounds.height);  prefWidth  =  bounds.width;  prefHeight  =  bounds.height;  prefHeight  =  bounds.height  -  style.font.getDescent();  //  Centers  text  in  the  label.  invalidateHierarchy();  }  public  String  getText  ()  {  return  text;  }  public  void  setColor  (float  color)  {  	prefHeight  =  bounds.height  -  style.font.getDescent();  //  Centers  text  in  the  label.  
elasticsearch_ce2888266051475bb53a406c658b93299ab3a837	buggy:  IndexResponse  indexResponse  =  client1.prepareIndex().setIndex( "test ").setType( "type1 ").setId( "1 ").setSource(source( "1 ",   "test ")).execute().actionGet();  context:  createIndex();  ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));          IndexResponse  indexResponse  =  client1.prepareIndex().setIndex( "test ").setType( "type1 ").setId( "1 ").setSource(source( "1 ",   "test ")).execute().actionGet();          IndexResponse  indexResponse  =  client1.prepareIndex().setIndex( "test ").setType( "type1 ").setId( "1 ").setSource(source( "1 ",   "test ")).setRefresh(true).execute().actionGet();  assertThat(indexResponse.index(),  equalTo(getConcreteIndexName()));  assertThat(indexResponse.id(),  equalTo( "1 "));  assertThat(indexResponse.type(),  equalTo( "type1 "));  RefreshResponse  refreshResponse  =  client1.admin().indices().prepareRefresh( "test ").execute().actionGet();  assertThat(refreshResponse.successfulShards(),  equalTo(10));  assertThat(refreshResponse.failedShards(),  equalTo(0));  	IndexResponse  indexResponse  =  client1.prepareIndex().setIndex( "test ").setType( "type1 ").setId( "1 ").setSource(source( "1 ",   "test ")).setRefresh(true).execute().actionGet();  
libgdx_262bfa57688213b7bfbd65f58e72cd071dd4dcaa	buggy:  if  (inputRegex  !=  null)  {  context:  for  (InputFile  inputFile  :  allInputFiles)  processFile(inputFile);  return  outputFiles;  }  private  void  process  (File[]  files,  File  outputRoot,  File  outputDir,  HashMap<File,  ArrayList<InputFile>>  dirToEntries,  int  depth)  {  for  (File  file  :  files)  {  if  (file.isFile())  {  if  (inputRegex  !=  null)  {  if  (inputRegex.size  >  0)  {  boolean  found  =  false;  for  (Pattern  pattern  :  inputRegex)  {  if  (pattern.matcher(file.getName()).matches())  {  found  =  true;  continue;  }  }  if  (!found)  continue;  	if  (inputRegex.size  >  0)  {  
libgdx_4795fba82766241b964bf08b4dbafc9883c40a57	buggy:  System.out.println(tag  +   ":   "  +  message);  context:  return  null;  }  public  Files  getFiles  ()  {  return  null;  }  public  void  log  (String  tag,  String  message)  {  System.out.println(tag  +   ":   "  +  message);  System.out.println(  message);  }  public  void  log  (String  tag,  String  message,  Exception  exception)  {  }  	System.out.println(  message);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  BoundedTreeSet<InternalLongTermsFacet.LongEntry>  ordered  =  new  BoundedTreeSet<InternalLongTermsFacet.LongEntry>(comparatorType.comparator(),  shardSize);  context:  ordered.insertWithOverflow(new  InternalLongTermsFacet.LongEntry(keys[i],  values[i]));  }  }  InternalLongTermsFacet.LongEntry[]  list  =  new  InternalLongTermsFacet.LongEntry[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  (InternalLongTermsFacet.LongEntry)  ordered.pop();  }  facets.release();  return  new  InternalLongTermsFacet(facetName,  comparatorType,  size,  Arrays.asList(list),  missing,  total);  }  else  {                  BoundedTreeSet<InternalLongTermsFacet.LongEntry>  ordered  =  new  BoundedTreeSet<InternalLongTermsFacet.LongEntry>(comparatorType.comparator(),  shardSize);                  BoundedTreeSet<InternalLongTermsFacet.LongEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  ordered.add(new  InternalLongTermsFacet.LongEntry(keys[i],  values[i]));  }  }  facets.release();  return  new  InternalLongTermsFacet(facetName,  comparatorType,  size,  ordered,  missing,  total);  }  	BoundedTreeSet<InternalLongTermsFacet.LongEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  
libgdx_17cd60e4fd41cf261f05d3270b56c3ef79ace256	buggy:  if  (cancelTouchFocus  &&  payload  !=  null)  source.getActor().getStage().cancelTouchFocus(this,  source.getActor());  context:  event.stop();  return;  }  activePointer  =  pointer;  dragStartTime  =  System.currentTimeMillis();  payload  =  source.dragStart(event,  getTouchDownX(),  getTouchDownY(),  pointer);  event.stop();  if  (cancelTouchFocus  &&  payload  !=  null)  source.getActor().getStage().cancelTouchFocus(this,  source.getActor());  if  (cancelTouchFocus  &&  payload  !=  null)  source.getActor().getStage().cancelTouchFocusExcept(this,  source.getActor());  }  public  void  drag  (InputEvent  event,  float  x,  float  y,  int  pointer)  {  if  (payload  ==  null)  return;  if  (pointer  !=  activePointer)  return;  Stage  stage  =  event.getStage();  	if  (cancelTouchFocus  &&  payload  !=  null)  source.getActor().getStage().cancelTouchFocusExcept(this,  source.getActor());  
libgdx_7e3285e15f72ca9d0a1e82d99aa8d775f334648d	buggy:  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.mp3 ",  FileType.Internal));  context:  public  class  SoundTest  extends  GdxTest  {  Sound  sound;  float  volume  =  0.5f;  long  soundId  =  0;  Stage  ui;  Skin  skin;  public  void  create  ()  {  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.mp3 ",  FileType.Internal));  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shot.ogg ",  FileType.Internal));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  TextButton  play  =  new  TextButton( "Play ",  skin);  TextButton  stop  =  new  TextButton( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  false,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  	sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shot.ogg ",  FileType.Internal));  
elasticsearch_1867ef50845dcc19aac3dd8a6027d44931691326	buggy:  PostingsFormatProvider  postingsFormat  =  mapperService.indexName(field).mapper().postingFormatProvider();  context:  private  final  MapperService  mapperService;  private  final  PostingsFormat  defaultPostingFormat;  public  PerFieldMappingPostingFormatCodec(MapperService  mapperService,  PostingsFormat  defaultPostingFormat)  {  this.mapperService  =  mapperService;  this.defaultPostingFormat  =  defaultPostingFormat;  }  public  PostingsFormat  getPostingsFormatForField(String  field)  {          PostingsFormatProvider  postingsFormat  =  mapperService.indexName(field).mapper().postingFormatProvider();          PostingsFormatProvider  postingsFormat  =  mapperService.indexName(field).mapper().postingsFormatProvider();  return  postingsFormat  !=  null  ?  postingsFormat.get()  :  defaultPostingFormat;  }  }  	PostingsFormatProvider  postingsFormat  =  mapperService.indexName(field).mapper().postingsFormatProvider();  
elasticsearch_e3a9271000128121c056ac59dfe6c7fede80f0d1	buggy:  long  count  =  Lucene.count(searcher,  query,  -1);  context:  Directory  dir  =  new  RAMDirectory();  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  indexWriter.addDocument(doc().add(field( "_id ",   "1 ")).add(field( "text ",   "lucene ")).build());  indexWriter.addDocument(doc().add(field( "_id ",   "2 ")).add(field( "text ",   "lucene  release ")).build());  IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  DeletionAwareConstantScoreQuery  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER);          long  count  =  Lucene.count(searcher,  query,  -1);          long  count  =  Lucene.count(searcher,  query);  assertThat(count,  equalTo(2l));  reader.close();  indexWriter.close();  }  }  	long  count  =  Lucene.count(searcher,  query);  
elasticsearch_73383e201431cff19a278925eef630a2db2d6f51	buggy:  assert  rewriteIndexReader  ==  searcher.getIndexReader();  context:  }  public  Weight  createWeight(IndexSearcher  searcher)  throws  IOException  {  SearchContext  searchContext  =  SearchContext.current();  final  Query  childQuery;  if  (rewrittenChildQuery  ==  null)  {  childQuery  =  rewrittenChildQuery  =  searcher.rewrite(originalChildQuery);  }  else  {              assert  rewriteIndexReader  ==  searcher.getIndexReader();              assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  childQuery  =  rewrittenChildQuery;  }  IndexSearcher  indexSearcher  =  new  IndexSearcher(searcher.getIndexReader());  indexSearcher.setSimilarity(searcher.getSimilarity());  final  BytesRefHash  parentIds;  final  FloatArray  scores;  final  IntArray  occurrences;  	assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  fields.add(toDocValues(value));  context:  value  =  parseStringValue(dateAsString);  }  if  (value  !=  null)  {  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {                  fields.add(toDocValues(value));                  addDocValue(context,  value);  }  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  value);  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  context.put( "localNode ",  clusterService.state().nodes().localNode());  context:  public  DumpGenerator.Result  generateDump(String  cause,  @Nullable  Map<String,  Object>  context,  String...  contributors)  throws  DumpGenerationFailedException  {  return  generator.generateDump(cause,  fillContextMap(context),  contributors);  }  private  Map<String,  Object>  fillContextMap(Map<String,  Object>  context)  {  if  (context  ==  null)  {  context  =  newHashMap();  }  if  (clusterService  !=  null)  {              context.put( "localNode ",  clusterService.state().nodes().localNode());              context.put( "localNode ",  clusterService.localNode());  }  return  context;  }  }  	context.put( "localNode ",  clusterService.localNode());  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  blobsBuilder.put(name,  new  PlainBlobMetaData(name,  summary.getSize(),  null));  context:  list  =  blobStore.client().listNextBatchOfObjects(prevListing);  }  else  {  if  (blobNamePrefix  !=  null)  {  list  =  blobStore.client().listObjects(blobStore.bucket(),  buildKey(blobNamePrefix));  }  else  {  list  =  blobStore.client().listObjects(blobStore.bucket(),  keyPath);  }  }  for  (S3ObjectSummary  summary  :  list.getObjectSummaries())  {  String  name  =  summary.getKey().substring(keyPath.length());                  blobsBuilder.put(name,  new  PlainBlobMetaData(name,  summary.getSize(),  null));                  blobsBuilder.put(name,  new  PlainBlobMetaData(name,  summary.getSize()));  }  if  (list.isTruncated())  {  prevListing  =  list;  }  else  {  break;  }  }  return  blobsBuilder.build();  	blobsBuilder.put(name,  new  PlainBlobMetaData(name,  summary.getSize()));  
libgdx_6cc53e2279ec82085265a200ee7cb71e52206682	buggy:  TouchEvent  event  =  input.freeTouchEvents.newObject();  context:  if  (event.getAction()  ==  MotionEvent.ACTION_CANCEL)  {  postTouchEvent(input,  TouchEvent.TOUCH_UP,  x,  y,  0);  input.touched[0]  =  false;  }  }  private  void  postTouchEvent  (AndroidInput  input,  int  type,  int  x,  int  y,  int  pointer)  {  long  timeStamp  =  System.nanoTime();  synchronized  (input)  {  TouchEvent  event  =  input.freeTouchEvents.newObject();  TouchEvent  event  =  input.usedTouchEvents.add();  event.timeStamp  =  timeStamp;  event.pointer  =  0;  event.x  =  x;  event.y  =  y;  event.type  =  type;  input.touchEvents.add(event);  }  }  	TouchEvent  event  =  input.usedTouchEvents.add();  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  deleteByQueryRequestBuilder.setIndicesOptions(IndicesOptions.lenient());  context:  deleteByQueryRequestBuilder.setIndices( "twitter ",   "missing ");  deleteByQueryRequestBuilder.setQuery(QueryBuilders.matchAllQuery());  try  {  deleteByQueryRequestBuilder.execute().actionGet();  fail( "Exception  should  have  been  thrown. ");  }  catch  (IndexMissingException  e)  {  }          deleteByQueryRequestBuilder.setIndicesOptions(IndicesOptions.lenient());          deleteByQueryRequestBuilder.setIndicesOptions(IndicesOptions.lenientExpandOpen());  DeleteByQueryResponse  actionGet  =  deleteByQueryRequestBuilder.execute().actionGet();  assertThat(actionGet.status(),  equalTo(RestStatus.OK));  assertThat(actionGet.getIndex( "twitter ").getFailedShards(),  equalTo(0));  assertThat(actionGet.getIndex( "twitter "),  notNullValue());  client().admin().indices().prepareRefresh().execute().actionGet();  search  =  client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();  assertThat(search.getHits().totalHits(),  equalTo(0l));  	deleteByQueryRequestBuilder.setIndicesOptions(IndicesOptions.lenientExpandOpen());  
elasticsearch_5ae12368574b33a8fad215ef104108fbf5435eb3	buggy:  return  counts.get(owningBucketOrd);  context:  }  public  void  collect(int  doc,  long  owningBucketOrdinal)  throws  IOException  {  counts  =  bigArrays.grow(counts,  owningBucketOrdinal  +  1);  counts.increment(owningBucketOrdinal,  values.setDocument(doc));  }  public  double  metric(long  owningBucketOrd)  {          return  counts.get(owningBucketOrd);          return  valuesSource  ==  null  ?  0  :  counts.get(owningBucketOrd);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  if  (valuesSource  ==  null)  {  return  new  InternalValueCount(name,  0);  }  assert  owningBucketOrdinal  <  counts.size();  	return  valuesSource  ==  null  ?  0  :  counts.get(owningBucketOrd);  
libgdx_56261622d837749a0af6348f418e9370b2139e0c	buggy:  float  height  =  this.width  *  scaleY;  context:  if  (patch  !=  null)  {  regionWidth  =  patch.getTotalWidth();  regionHeight  =  patch.getTotalHeight();  }  else  if  (region  !=  null)  {  regionWidth  =  region.getRegionWidth();  regionHeight  =  region.getRegionHeight();  }  else  return;  float  width  =  this.width  *  scaleX;  float  height  =  this.width  *  scaleY;  float  height  =  this.height  *  scaleY;  switch  (scaling)  {  case  fill:  {  float  widgetRatio  =  height  /  width;  float  regionRatio  =  regionHeight  /  regionWidth;  float  scale  =  regionRatio  >  widgetRatio  ?  width  /  regionWidth  :  height  /  regionHeight;  imageWidth  =  regionWidth  *  scale;  imageHeight  =  regionHeight  *  scale;  	float  height  =  this.height  *  scaleY;  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  StreamInput  stream  =  new  BytesStreamInput(data);  context:  CachedStreamOutput.pushEntry(cachedEntry);  }  }  ThreadPool  threadPool()  {  return  this.threadPool;  }  void  messageReceived(byte[]  data,  String  action,  LocalTransport  sourceTransport,  @Nullable  final  Long  sendRequestId)  {  transportServiceAdapter.received(data.length);          StreamInput  stream  =  new  BytesStreamInput(data);          StreamInput  stream  =  new  BytesStreamInput(data,  false);  stream  =  CachedStreamInput.cachedHandles(stream);  try  {  long  requestId  =  stream.readLong();  byte  status  =  stream.readByte();  boolean  isRequest  =  TransportStreams.statusIsRequest(status);  if  (isRequest)  {  	StreamInput  stream  =  new  BytesStreamInput(data,  false);  
libgdx_4834cf9474ca71c245a0ff942a082a0d208b1e33	buggy:  renderBatch  =  new  RenderBatch(exclusiveTextures  =  new  DefaultTextureBinder(BIND_METHOD,  UNIT_OFFSET,  MAX_TEXTURES));  context:  createScene2();  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.near  =  1f;  cam.far  =  100f;  cam.position.set(10f,  10f,  10f);  cam.lookAt(0,  0,  0);  cam.update();  renderBatch  =  new  RenderBatch(exclusiveTextures  =  new  DefaultTextureBinder(BIND_METHOD,  UNIT_OFFSET,  MAX_TEXTURES));  renderBatch  =  new  RenderBatch();  lights  =  new  Light[]  {  new  Light(Color.WHITE,  Vector3.tmp.set(-10f,  10f,  -10f),  15f),  new  Light(Color.BLUE,  Vector3.tmp.set(10f,  5f,  0f),  10f),  new  Light(Color.GREEN,  Vector3.tmp.set(0f,  10f,  5f),  5f)  };  Gdx.input.setInputProcessor(this);  	renderBatch  =  new  RenderBatch();  
elasticsearch_af1513f908d47445a6156573a53c5ad4f463175c	buggy:  Releasables.release(success,  bytes,  hashes);  context:  reset(code,  id);  }  public  boolean  release()  {  boolean  success  =  false;  try  {  super.release();  success  =  true;  }  finally  {              Releasables.release(success,  bytes,  hashes);              Releasables.release(success,  bytes,  hashes,  startOffsets);  }  return  true;  }  }  	Releasables.release(success,  bytes,  hashes,  startOffsets);  
libgdx_0210c9c0183bbbc5e264c9ca17737cd74405b144	buggy:  groupPool.free(usedGroups);  context:  if  (shader  !=  null)  {  mesh.render(shader,  GL10.GL_TRIANGLES,  0,  verticesPosition  /  4);  }  else  {  mesh.render(GL10.GL_TRIANGLES,  0,  verticesPosition  /  4);  }  }  protected  void  clear  ()  {  groupList.clear();  groupPool.free(usedGroups);  groupPool.freeAll(usedGroups);  usedGroups.clear();  }  public  void  dispose  ()  {  clear();  vertices  =  null;  	groupPool.freeAll(usedGroups);  
elasticsearch_051beb51a3847c457324ecc07db708538e34d15c	buggy:  assert  delete.versionType().validateVersion(delete.version());  context:  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  ShardDeleteRequest  request  =  shardRequest.request;  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  Engine.Delete  delete  =  indexShard.prepareDelete(request.type(),  request.id(),  request.version(),  VersionType.INTERNAL,  Engine.Operation.Origin.REPLICA);  delete  =  new  Engine.Delete(delete,  VersionType.INTERNAL.versionTypeForReplicationAndRecovery());          assert  delete.versionType().validateVersion(delete.version());          assert  delete.versionType().validateVersionForWrites(delete.version());  indexShard.delete(delete);  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_delete ").force(false));  }  catch  (Exception  e)  {  	assert  delete.versionType().validateVersionForWrites(delete.version());  
libgdx_eb9c537389b0c7eac560d4557a50b74b79ea2c4d	buggy:  Gdx.gl.glGetIntegerv(GL20.GL_MAX_TEXTURE_UNITS,  buffer);  context:  this.count  =  count;  this.textures  =  new  TextureDescriptor[count];  for  (int  i  =  0;  i  <  count;  i++)  this.textures[i]  =  new  TextureDescriptor();  this.reuseWeight  =  reuseWeight;  this.weights  =  (method  ==  WEIGHTED)  ?  new  int[count]  :  null;  }  private  static  int  getMaxTextureUnits  ()  {  IntBuffer  buffer  =  BufferUtils.newIntBuffer(16);  Gdx.gl.glGetIntegerv(GL20.GL_MAX_TEXTURE_UNITS,  buffer);  Gdx.gl.glGetIntegerv(GL20.GL_MAX_TEXTURE_IMAGE_UNITS,  buffer);  return  buffer.get(0);  }  public  void  begin  ()  {  for(int  i  =  0;  i  <  count;  i++)  {  textures[i].texture  =  null;  if(weights  !=  null)  weights[i]  =  0;  	Gdx.gl.glGetIntegerv(GL20.GL_MAX_TEXTURE_IMAGE_UNITS,  buffer);  
elasticsearch_6c21c30f31851d7b8942990e227aae602c663e8e	buggy:  assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  greaterThan(shardStatus.gatewayRecoveryStatus().indexSize().bytes()  -  4098  /*  segments  file  */));  context:  assertThat(client( "server1 ").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),  equalTo(12345l));  IndicesStatusResponse  statusResponse  =  client( "server1 ").admin().indices().prepareStatus().execute().actionGet();  for  (IndexShardStatus  indexShardStatus  :  statusResponse.index( "test "))  {  for  (ShardStatus  shardStatus  :  indexShardStatus)  {  if  (shardStatus.shardRouting().primary())  {  if  (fullRecovery  ||  !isPersistentStorage())  {  assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  equalTo(0l));  }  else  {                          assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  greaterThan(shardStatus.gatewayRecoveryStatus().indexSize().bytes()  -  4098  /*  segments  file  */));                          assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  greaterThan(shardStatus.gatewayRecoveryStatus().indexSize().bytes()  -  8196  /*  segments  file  and  others  */));  }  }  }  }  }  private  String  mappingSource()  {  return   "{  type1  :  {  properties  :  {  name  :  {  type  :  \ "string\ "  }  }  }  } ";  	assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  greaterThan(shardStatus.gatewayRecoveryStatus().indexSize().bytes()  -  8196  /*  segments  file  and  others  */));  
elasticsearch_5ad540a1aa187b0f8eb3f272e7925e3b710a4e0f	buggy:  long  totalSizeInBytes  =  merge.totalBytesSize();  context:  while  (true)  {  MergePolicy.OneMerge  merge  =  writer.getNextMerge();  if  (merge  ==  null)  break;  writer.mergeInit(merge);  int  totalNumDocs  =  merge.totalNumDocs();              long  totalSizeInBytes  =  merge.totalBytesSize();              long  totalSizeInBytes  =  merge.estimatedMergeBytes;  long  time  =  System.currentTimeMillis();  currentMerges.inc();  currentMergesNumDocs.inc(totalNumDocs);  currentMergesSizeInBytes.inc(totalSizeInBytes);  if  (logger.isTraceEnabled())  {  	long  totalSizeInBytes  =  merge.estimatedMergeBytes;  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  return  Streams.copyToString(new  InputStreamReader(resolveConfig(path).openStream(),   "UTF-8 "));  context:  public  File  pluginsFile()  {  return  pluginsFile;  }  public  File  logsFile()  {  return  logsFile;  }  public  String  resolveConfigAndLoadToString(String  path)  throws  FailedToResolveConfigException,  IOException  {          return  Streams.copyToString(new  InputStreamReader(resolveConfig(path).openStream(),   "UTF-8 "));          return  Streams.copyToString(new  InputStreamReader(resolveConfig(path).openStream(),  Streams.UTF8));  }  public  URL  resolveConfig(String  path)  throws  FailedToResolveConfigException  {  String  origPath  =  path;  File  f1  =  new  File(path);  if  (f1.exists())  {  try  {  	return  Streams.copyToString(new  InputStreamReader(resolveConfig(path).openStream(),  Streams.UTF8));  
elasticsearch_49ac30801e883076171d76285deaf047cd09e0dc	buggy:  FastCharArrayWriter  writer  =  FastCharArrayWriter.Cached.cached();  context:  it  =  entries.iterator();  if  (it.hasNext())  {  current  =  it.next();  itsSeparatorTime  =  true;  }  }  public  String  buildText()  {  reset();          FastCharArrayWriter  writer  =  FastCharArrayWriter.Cached.cached();          FastCharArrayWriter  writer  =  new  FastCharArrayWriter();  for  (Entry  entry  :  entries)  {  writer.append(entry.reader());  writer.append('  ');  }  reset();  return  writer.toString();  }  	FastCharArrayWriter  writer  =  new  FastCharArrayWriter();  
elasticsearch_f0f62ce00ca04c11f820b92439496d15a7fe019c	buggy:  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  context:  assertThat(flushResponse.failedShards(),  equalTo(0));  client( "server1 ").index(indexRequest( "test ").type( "type1 ").id( "2 ").source(source( "2 ",   "test "))).actionGet();  RefreshResponse  refreshResponse  =  client( "server1 ").admin().indices().refresh(refreshRequest( "test ")).actionGet();  assertThat(refreshResponse.totalShards(),  equalTo(10));  assertThat(refreshResponse.successfulShards(),  equalTo(5));  assertThat(refreshResponse.failedShards(),  equalTo(0));  startNode( "server2 ");          clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();          clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus().waitForNodes( "2 ")).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  GetResponse  getResult;  for  (int  i  =  0;  i  <  5;  i++)  {  getResult  =  client( "server1 ").get(getRequest( "test ").type( "type1 ").id( "1 ").operationThreaded(false)).actionGet(1000);  	clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus().waitForNodes( "2 ")).actionGet();  
libgdx_1c5f7e538356cc4f939642b6da36ad313fc16e6b	buggy:  if  (!name.equals(name))  return  false;  context:  public  Object  invoke  (Object  obj,  Object...  params)  {  if  (parameters  !=  null  &&  (params  ==  null  ||  params.length  !=  parameters.length))  throw  new  IllegalArgumentException( "Parameter  mismatch ");  if  (parameters  ==  null  &&  params  !=  null  &&  params.length  >  0)  {  throw  new  IllegalArgumentException( "Parameter  mismatch ");  }  return  ReflectionCache.instance.invoke(this,  obj,  params);  }  boolean  match  (String  name,  Class...  types)  {  if  (!name.equals(name))  return  false;  if  (!this.name.equals(name))  return  false;  if  (types.length  !=  parameters.length)  return  false;  for  (int  i  =  0;  i  <  types.length;  i++)  {  Type  t1  =  ReflectionCache.instance.forName(parameters[i].getType().getName());  Type  t2  =  ReflectionCache.instance.forName(types[i].getName());  if  (t1  !=  t2  &&  !t1.isAssignableFrom(t2))  return  false;  }  return  true;  }  	if  (!this.name.equals(name))  return  false;  
libgdx_0ee231215a264eca4b0f828416672632162ba65a	buggy:  transform.setToRotation(new  Vector3(1,  0,  1).nor(),  angle);  context:  project(orig);  project(vec);  Vector2  d  =  new  Vector2(vec.x  -  orig.x,  -(vec.y  -  orig.y));  return  d.angle();  }  private  Vector3  calculateDirection  (float  angle)  {  Matrix4  transform  =  new  Matrix4();  Vector3  dir  =  new  Vector3(-1,  0,  1).nor();  float  rotAngle  =  (float)Math.toDegrees(Math.asin(Math.tan(Math.toRadians(angle))));  transform.setToRotation(new  Vector3(1,  0,  1).nor(),  angle);  transform.setToRotation(new  Vector3(1,  0,  1).nor(),  rotAngle);  dir.mul(transform).nor();  return  dir;  }  private  final  Vector3  tmp  =  new  Vector3();  public  void  update  ()  {  	transform.setToRotation(new  Vector3(1,  0,  1).nor(),  rotAngle);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  keyFieldMapper  =  context.mapperService().smartNameFieldMapper(keyField);  context:  }  }  if  (keyField  ==  null)  {  throw  new  FacetPhaseExecutionException(facetName,   "[key_field]  is  required  to  be  set  for  terms  stats  facet ");  }  if  (valueField  ==  null  &&  script  ==  null)  {  throw  new  FacetPhaseExecutionException(facetName,   "either  [value_field]  or  [script]  are  required  to  be  set  for  terms  stats  facet ");  }          FieldMapper  keyFieldMapper  =  context.mapperService().smartNameFieldMapper(keyField);          FieldMapper  keyFieldMapper  =  context.smartNameFieldMapper(keyField);  if  (keyFieldMapper  !=  null)  {  if  (keyFieldMapper.fieldDataType()  ==  FieldDataType.DefaultTypes.LONG)  {  return  new  TermsStatsLongFacetCollector(facetName,  keyField,  valueField,  size,  comparatorType,  context,  scriptLang,  script,  params);  }  else  if  (keyFieldMapper.fieldDataType()  ==  FieldDataType.DefaultTypes.INT)  {  return  new  TermsStatsLongFacetCollector(facetName,  keyField,  valueField,  size,  comparatorType,  context,  scriptLang,  script,  params);  }  else  if  (keyFieldMapper.fieldDataType()  ==  FieldDataType.DefaultTypes.SHORT)  {  return  new  TermsStatsLongFacetCollector(facetName,  keyField,  valueField,  size,  comparatorType,  context,  scriptLang,  script,  params);  }  else  if  (keyFieldMapper.fieldDataType()  ==  FieldDataType.DefaultTypes.BYTE)  {  	FieldMapper  keyFieldMapper  =  context.smartNameFieldMapper(keyField);  
elasticsearch_c560f1f9f1293db4f19843ed5f760807589b3720	buggy:  if  (request.waitForStatus()  !=  null  &&  response.status()  ==  request.waitForStatus())  {  context:  waitFor--;  }  if  (waitFor  ==  0)  {  return  clusterHealth(request);  }  long  endTime  =  System.currentTimeMillis()  +  request.timeout().millis();  while  (true)  {  int  waitForCounter  =  0;  ClusterHealthResponse  response  =  clusterHealth(request);              if  (request.waitForStatus()  !=  null  &&  response.status()  ==  request.waitForStatus())  {              if  (request.waitForStatus()  !=  null  &&  response.status().value()  <=  request.waitForStatus().value())  {  waitForCounter++;  }  if  (request.waitForRelocatingShards()  !=  -1  &&  response.relocatingShards()  <=  request.waitForRelocatingShards())  {  waitForCounter++;  }  if  (waitForCounter  ==  waitFor)  {  return  response;  }  	if  (request.waitForStatus()  !=  null  &&  response.status().value()  <=  request.waitForStatus().value())  {  
elasticsearch_8c25be6dee4f4c33ed5d737b1be14b31e3de319f	buggy:  return   "[ "  +  shardId.index()  +   "][ "  +  shardId.id()  +   "] "  +  message;  context:  public  class  PrimaryNotStartedActionException  extends  ElasticSearchException  {  public  PrimaryNotStartedActionException(ShardId  shardId,  String  message)  {  super(buildMessage(shardId,  message));  }  private  static  String  buildMessage(ShardId  shardId,  String  message)  {  if  (shardId  ==  null)  {  return  message;  }          return   "[ "  +  shardId.index()  +   "][ "  +  shardId.id()  +   "] "  +  message;          return   "[ "  +  shardId.index().name()  +   "][ "  +  shardId.id()  +   "]   "  +  message;  }  }  	return   "[ "  +  shardId.index().name()  +   "][ "  +  shardId.id()  +   "]   "  +  message;  
elasticsearch_9c9cd01854d4343b11314d58b82c00f1de335f8a	buggy:  if  (token  ==  XContentParser.Token.START_OBJECT  &&  !parser.hasTextCharacters())  {  context:  String  templateNameOrTemplateContent  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;  ScriptService.ScriptType  type  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (parameterMap.containsKey(currentFieldName))  {  type  =  parameterMap.get(currentFieldName);                  if  (token  ==  XContentParser.Token.START_OBJECT  &&  !parser.hasTextCharacters())  {                  if  (token  ==  XContentParser.Token.START_OBJECT)  {  XContentBuilder  builder  =  XContentBuilder.builder(parser.contentType().xContent());  builder.copyCurrentStructure(parser);  templateNameOrTemplateContent  =  builder.string();  }  else  {  templateNameOrTemplateContent  =  parser.text();  }  }  else  if  (paramsFieldname.equals(currentFieldName))  {  params  =  parser.map();  	if  (token  ==  XContentParser.Token.START_OBJECT)  {  
elasticsearch_a2011e0151bcda374a878fe4b3c8e33668e07275	buggy:  return  new  DeletionAwareConstantScoreQuery(parseContext.cacheFilterIfPossible(Queries.MATCH_ALL_FILTER));  context:  }  else  if  (token.isValue())  {  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  else  if  ( "norms_field ".equals(currentFieldName)  ||   "normsField ".equals(currentFieldName))  {  normsField  =  parseContext.indexName(parser.text());  }  }  }  if  (boost  ==  1.0f  &&  normsField  ==  null)  {              return  new  DeletionAwareConstantScoreQuery(parseContext.cacheFilterIfPossible(Queries.MATCH_ALL_FILTER));              return  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER,  true);  //  no  need  to  cache  a  MATCH  ALL  FILTER  }  MatchAllDocsQuery  query  =  new  MatchAllDocsQuery(normsField);  query.setBoost(boost);  return  query;  }  }  	return  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER,  true);    //  no  need  to  cache  a  MATCH  ALL  FILTER  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  text  =  request.contentAsString();  context:  controller.registerHandler(GET,   "/_analyze ",  this);  controller.registerHandler(GET,   "/{index}/_analyze ",  this);  controller.registerHandler(POST,   "/_analyze ",  this);  controller.registerHandler(POST,   "/{index}/_analyze ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  String  text  =  request.param( "text ");  if  (text  ==  null  &&  request.hasContent())  {              text  =  request.contentAsString();              text  =  request.content().toUtf8();  }  if  (text  ==  null)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  new  ElasticSearchIllegalArgumentException( "text  is  missing ")));  }  catch  (IOException  e1)  {  }  return;  	text  =  request.content().toUtf8();  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullDateHistogramFacet.FullEntry  value  =  (InternalFullDateHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }          entries.release();          entries.close();  return  new  InternalFullDateHistogramFacet(facetName,  comparatorType,  entries1);  }  class  Collector  extends  FacetExecutor.Collector  {  private  final  DateHistogramProc  histoProc;  private  LongValues  keyValues;  	entries.close();  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  Query  rangeQuery  =  currentMapper.rangeQuery(part1,  part2,  inclusive,  inclusive);  context:  part1  =  null;  }  if  ( "* ".equals(part2))  {  part2  =  null;  }  currentMapper  =  null;  MapperService.SmartNameFieldMappers  fieldMappers  =  parseContext.smartFieldMappers(field);  if  (fieldMappers  !=  null)  {  currentMapper  =  fieldMappers.fieldMappers().mapper();  if  (currentMapper  !=  null)  {                  Query  rangeQuery  =  currentMapper.rangeQuery(part1,  part2,  inclusive,  inclusive);                  Query  rangeQuery  =  currentMapper.rangeQuery(part1,  part2,  inclusive,  inclusive,  parseContext);  return  wrapSmartNameQuery(rangeQuery,  fieldMappers,  parseContext);  }  }  return  newRangeQuery(field,  part1,  part2,  inclusive);  }  protected  Query  getFuzzyQuery(String  field,  String  termStr,  float  minSimilarity)  throws  ParseException  {  	Query  rangeQuery  =  currentMapper.rangeQuery(part1,  part2,  inclusive,  inclusive,  parseContext);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  return  new  GetAliasesRequest();  }  protected  AliasesExistResponse  newResponse()  {  return  new  AliasesExistResponse();  }  protected  void  masterOperation(GetAliasesRequest  request,  ClusterState  state,  ActionListener<AliasesExistResponse>  listener)  throws  ElasticsearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  request.indices(concreteIndices);  boolean  result  =  state.metaData().hasAliases(request.aliases(),  request.indices());  listener.onResponse(new  AliasesExistResponse(result));  }  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));  context:  String  key  =  entry.getKey();  String  value  =  entry.getValue();  if  (key.startsWith( "settings. "))  {  key  =  key.substring( "settings. ".length());  }  updateSettings.put(key,  value);  }  }  catch  (Exception  e)  {  try  {                      channel.sendResponse(new  XContentThrowableRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));                      channel.sendResponse(new  BytesRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));  }  catch  (IOException  e1)  {  }  return;  }  }  for  (Map.Entry<String,  String>  entry  :  request.params().entrySet())  {  if  (entry.getKey().equals( "pretty ")  ||  entry.getKey().equals( "timeout ")  ||  entry.getKey().equals( "master_timeout "))  {  	channel.sendResponse(new  BytesRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));  
elasticsearch_ef25ac2414be49fa3340f6a576ebbf555163bd10	buggy:  IgnoreIndices.fromString(request.param( "ignore_indices "));  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  MultiSearchRequest  multiSearchRequest  =  new  MultiSearchRequest();  multiSearchRequest.listenerThreaded(false);  String[]  indices  =  RestActions.splitIndices(request.param( "index "));  String[]  types  =  RestActions.splitTypes(request.param( "type "));  IgnoreIndices  ignoreIndices  =  null;  if  (request.hasParam( "ignore_indices "))  {              IgnoreIndices.fromString(request.param( "ignore_indices "));              ignoreIndices  =  IgnoreIndices.fromString(request.param( "ignore_indices "));  }  try  {  multiSearchRequest.add(request.content(),  request.contentUnsafe(),  indices,  types,  request.param( "search_type "),  ignoreIndices);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  	ignoreIndices  =  IgnoreIndices.fromString(request.param( "ignore_indices "));  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  collector  =  new  FilteredCollector(collector,  searchContext.parsedFilter());  context:  }  if  (currentState  ==  Stage.MAIN_QUERY)  {  if  (enableMainDocIdSetCollector)  {  collector  =  this.mainDocIdSetCollector  =  new  DocIdSetCollector(searchContext.docSetCache(),  collector);  }  if  (searchContext.parsedFilter()  !=  null)  {                  collector  =  new  FilteredCollector(collector,  searchContext.parsedFilter());                  collector  =  new  FilteredCollector(collector,  searchContext.parsedFilter().filter());  }  if  (queryCollectors  !=  null  &&  !queryCollectors.isEmpty())  {  collector  =  new  MultiCollector(collector,  queryCollectors.toArray(new  Collector[queryCollectors.size()]));  }  if  (searchContext.minimumScore()  !=  null)  {  collector  =  new  MinimumScoreCollector(collector,  searchContext.minimumScore());  	collector  =  new  FilteredCollector(collector,  searchContext.parsedFilter().filter());  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  aggregation  [ "  +  name  +   "] ");  context:  protected  List<Range>  ranges  =  Lists.newArrayList();  protected  AbstractRangeBuilder(String  name,  String  type)  {  super(name,  type);  }  protected  XContentBuilder  doInternalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (ranges.isEmpty())  {              throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  aggregation  [ "  +  getName()  +   "] ");  }  builder.startArray( "ranges ");  for  (Range  range  :  ranges)  {  range.toXContent(builder,  params);  }  return  builder.endArray();  }  }  	throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_3731362ca83e8a67979f484589110ab4f9c4f6a5	buggy:  listener.onFailure(new  BenchmarkNodeMissingException( "No  available  nodes  for  executing  benchmarks "));  context:  public  void  listBenchmarks(final  BenchmarkStatusRequest  request,  final  ActionListener<BenchmarkStatusResponse>  listener)  {  final  List<DiscoveryNode>  nodes  =  availableBenchmarkNodes();  if  (nodes.size()  ==  0)  {              listener.onFailure(new  BenchmarkNodeMissingException( "No  available  nodes  for  executing  benchmarks "));              listener.onResponse(new  BenchmarkStatusResponse());  }  else  {  BenchmarkStatusAsyncHandler  async  =  new  BenchmarkStatusAsyncHandler(nodes.size(),  request,  listener);  for  (DiscoveryNode  node  :  nodes)  {  assert  isBenchmarkNode(node);  transportService.sendRequest(node,  StatusExecutionHandler.ACTION,  new  NodeStatusRequest(request),  async);  }  }  }  	listener.onResponse(new  BenchmarkStatusResponse());  
elasticsearch_e70cf1849b97dc1e1a23432f576384410fd75b39	buggy:  if  (getResponse.source()  ==  null)  {  context:  }  public  String  executor()  {  return  ThreadPool.Names.SAME;  }  });  }  private  void  parseSource(GetResponse  getResponse,  final  BoolQueryBuilder  boolBuilder,  DocumentMapper  docMapper,  final  Set<String>  fields,  final  MoreLikeThisRequest  request)  {          if  (getResponse.source()  ==  null)  {          if  (getResponse.isSourceEmpty())  {  return;  }  docMapper.parse(SourceToParse.source(getResponse.sourceRef()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  public  boolean  beforeFieldAdded(FieldMapper  fieldMapper,  Field  field,  Object  parseContext)  {  if  (fieldMapper  instanceof  InternalMapper)  {  return  true;  }  	if  (getResponse.isSourceEmpty())  {  
libgdx_349ea157ebcaeb26afca1f252439b70a53fbbadd	buggy:  Gdx.audio.newSound(Gdx.files.internal( "data/chirp.ogg ")).play();  context:  package  com.badlogic.gdx.tests;  public  class  ShortSoundTest  extends  GdxTest  {  public  void  create  ()  {  Gdx.audio.newSound(Gdx.files.internal( "data/chirp.ogg ")).play();  Gdx.audio.newSound(Gdx.files.internal( "data/tic.ogg ")).play();  }  }  	Gdx.audio.newSound(Gdx.files.internal( "data/tic.ogg ")).play();  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage  =  new  Stage(480,  320,  true);  context:  public  class  GroupFadeTest  extends  GdxTest  {  Texture  texture;  Stage  stage;  public  void  create  ()  {  texture  =  new  Texture(Gdx.files.internal( "data/badlogicsmall.jpg "));  stage  =  new  Stage(480,  320,  true);  stage  =  new  Stage();  for  (int  i  =  0;  i  <  100;  i++)  {  Image  img  =  new  Image(new  TextureRegion(texture));  img.setX((float)Math.random()  *  480);  img.setY((float)Math.random()  *  320);  img.getColor().a  =  (float)Math.random()  *  0.5f  +  0.5f;  stage.addActor(img);  }  	stage  =  new  Stage();  
elasticsearch_f8e93fa2aa2b4a94928c95fb2cee30524d9b649c	buggy:  .addMapping( "article ")  context:  public  class  ChildrenTests  extends  ElasticsearchIntegrationTest  {  private  final  static  Map<String,  Control>  categoryToControl  =  new  HashMap<>();  public  void  setupSuiteScopeCluster()  throws  Exception  {  assertAcked(  prepareCreate( "test ")                      .addMapping( "article ")                      .addMapping( "article ",   "_id ",   "index=not_analyzed ")  .addMapping( "comment ",   "_parent ",   "type=article ",   "_id ",   "index=not_analyzed ")  );  List<IndexRequestBuilder>  requests  =  new  ArrayList<>();  String[]  uniqueCategories  =  new  String[randomIntBetween(1,  25)];  for  (int  i  =  0;  i  <  uniqueCategories.length;  i++)  {  uniqueCategories[i]  =  Integer.toString(i);  }  	.addMapping( "article ",   "_id ",   "index=not_analyzed ")  
elasticsearch_5804e9132a3d798b1b1df07e39cce7dcc5ab1dd1	buggy:  boolean  cache  =  false;  context:  super(index,  settings);  }  return  new  String[]{NAME};  }  XContentParser  parser  =  parseContext.parser();          boolean  cache  =  false;          boolean  cache  =  true;  //  since  usually  term  filter  is  on  repeating  terms,  cache  it  by  default  String  fieldName  =  null;  String  value  =  null;  String  filterName  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  	boolean  cache  =  true;  //  since  usually  term  filter  is  on  repeating  terms,  cache  it  by  default  
libgdx_b6b755419d5364d577171fe5c0a996616d7bc167	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.RotationTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.RotationTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.TextureDataTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.TextureDataTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_21f2b08de21c4d18c061687e559deeb1c3ec8725	buggy:  return  super.list();  context:  if  (count  <  relativePaths.length)  {  FileHandle[]  newHandles  =  new  FileHandle[count];  System.arraycopy(handles,  0,  newHandles,  0,  count);  handles  =  newHandles;  }  return  handles;  }  catch  (Exception  ex)  {  throw  new  GdxRuntimeException( "Error  listing  children:   "  +  file  +   "  ( "  +  type  +   ") ",  ex);  }  }  return  super.list();  return  super.list(suffix);  }  public  boolean  isDirectory  ()  {  if  (type  ==  FileType.Internal)  {  try  {  return  assets.list(file.getPath()).length  >  0;  }  catch  (IOException  ex)  {  return  false;  	return  super.list(suffix);  
elasticsearch_ac1e9856703960d953b81ba987f04596c925d153	buggy:  Query  childrenConstantScoreQuery  =  new  ChildrenConstantScoreQuery(query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  false);  context:  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  Type  [ "  +  childType  +   "]  points  to  a  non  existent  parent  type  [ "  +  parentType  +   "] ");  }  Filter  parentFilter  =  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null);          Query  childrenConstantScoreQuery  =  new  ChildrenConstantScoreQuery(query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  false);          Query  childrenConstantScoreQuery  =  new  ChildrenConstantScoreQuery(query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet);  if  (filterName  !=  null)  {  parseContext.addNamedQuery(filterName,  childrenConstantScoreQuery);  }  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  if  (deleteByQuery)  {  return  new  DeleteByQueryWrappingFilter(childrenConstantScoreQuery);  	Query  childrenConstantScoreQuery  =  new  ChildrenConstantScoreQuery(query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet);  
elasticsearch_c2f3eab7d3137f72595379fa6caa90410fc238d1	buggy:  return  loader.buildSingleValue(field,  new  int[0]);  //  Return  empty  field  data  if  field  doesn't  exists.  context:  loader.init();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  int  t  =  1;  //  current  term  number  Terms  terms  =  reader.terms(field);  if  (terms  ==  null)  {              return  loader.buildSingleValue(field,  new  int[0]);  //  Return  empty  field  data  if  field  doesn't  exists.              return  loader.buildSingleValue(field,  ordinals.get(0));  //  Return  empty  field  data  if  field  doesn't  exists.  }  TermsEnum  termsEnum  =  terms.iterator(null);  try  {  DocsEnum  docsEnum  =  null;  for  (BytesRef  term  =  termsEnum.next();  term  !=  null;  term  =  termsEnum.next())  {  loader.collectTerm(BytesRef.deepCopyOf(term));  docsEnum  =  termsEnum.docs(reader.getLiveDocs(),  docsEnum,  0);  	return    loader.buildSingleValue(field,  ordinals.get(0));  //  Return  empty  field  data  if  field  doesn't  exists.  
libgdx_11bbd67bc5e8b92add8a1cf89f042aea5632d104	buggy:  setScreen(new  GameScreen(this));  context:  public  class  SuperJumper  extends  Game  {  boolean  firstTimeCreate  =  true;  FPSLogger  fps;  public  void  create  ()  {  Settings.load();  Assets.load();  setScreen(new  GameScreen(this));  setScreen(new  MainMenuScreen(this));  fps  =  new  FPSLogger();  }  public  void  render()  {  super.render();  fps.log();  }  	setScreen(new  MainMenuScreen(this));  
elasticsearch_4bdae621f92beb226cf5873a9efe721b38c7e0c7	buggy:  new  ScriptModule(),  context:  private  PercolatorExecutor  percolatorExecutor;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),                  new  ScriptModule(),                  new  ScriptModule(settings),  new  MapperServiceModule(),  new  IndexSettingsModule(settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index),  	new  ScriptModule(settings),  
libgdx_16f45f74e50a10930e7679d3d132e8341ea0e4ba	buggy:  projection.setToOrtho(-viewportWidth  /  2,  viewportWidth  /  2,  -viewportHeight  /  2,  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  context:  public  OrthographicCamera(float  viewportWidth,  float  viewportHeight)  {  this.viewportWidth  =  viewportWidth;  this.viewportHeight  =  viewportHeight;  this.near  =  0;  }  private  final  Vector3  tmp  =  new  Vector3();  public  void  update()  {  projection.setToOrtho(-viewportWidth  /  2,  viewportWidth  /  2,  -viewportHeight  /  2,  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  viewportWidth  /  2,  zoom  *  -viewportHeight  /  2,  zoom  *  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  view.setToLookAt(position,  tmp.set(position).add(direction),  up);  combined.set(projection).mul(view);  invProjectionView.set(combined);  invProjectionView.inv();  frustum.update(combined);  }  }  	projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  viewportWidth  /  2,  zoom  *  -viewportHeight  /  2,  zoom  *  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  
elasticsearch_cdf1fc8981c99ed8af58a33bd2bba63fe192c26d	buggy:  if  (parentDocId  !=  -1  &&  !indexReader.getLiveDocs().get(parentDocId))  {  context:  HashedBytesArray  parentId  =  context.idCache().reader(subContext.reader()).parentIdByDoc(parentType,  subDoc);  if  (parentId  ==  null)  {  continue;  }  for  (AtomicReaderContext  atomicReaderContext  :  context.searcher().getIndexReader().leaves())  {  AtomicReader  indexReader  =  atomicReaderContext.reader();  int  parentDocId  =  context.idCache().reader(indexReader).docById(parentType,  parentId);                  if  (parentDocId  !=  -1  &&  !indexReader.getLiveDocs().get(parentDocId))  {                  if  (parentDocId  !=  -1  &&  indexReader.getLiveDocs().get(parentDocId))  {  TIntObjectHashMap<ParentDoc>  readerParentDocs  =  parentDocsPerReader.get(indexReader.getCoreCacheKey());  if  (readerParentDocs  ==  null)  {  readerParentDocs  =  new  TIntObjectHashMap<ParentDoc>();  parentDocsPerReader.put(indexReader.getCoreCacheKey(),  readerParentDocs);  }  	if  (parentDocId  !=  -1  &&  indexReader.getLiveDocs().get(parentDocId))  {  
elasticsearch_d2f91173b7b5979eccf98a508a5fcebd3cf72657	buggy:  clusterService.submitStateUpdateTask( "shard-started  ( "  +  shardRoutingEntry.shardRouting  +   "),  reason  [ "  +  shardRoutingEntry.reason  +   "] ",  Priority.HIGH,  context:  }  private  void  innerShardStarted(final  ShardRoutingEntry  shardRoutingEntry)  {  startedShardsQueue.add(shardRoutingEntry);          clusterService.submitStateUpdateTask( "shard-started  ( "  +  shardRoutingEntry.shardRouting  +   "),  reason  [ "  +  shardRoutingEntry.reason  +   "] ",  Priority.HIGH,          clusterService.submitStateUpdateTask( "shard-started  ( "  +  shardRoutingEntry.shardRouting  +   "),  reason  [ "  +  shardRoutingEntry.reason  +   "] ",  Priority.URGENT,  new  ClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  List<ShardRoutingEntry>  shardRoutingEntries  =  new  ArrayList<ShardRoutingEntry>();  startedShardsQueue.drainTo(shardRoutingEntries);  	clusterService.submitStateUpdateTask( "shard-started  ( "  +  shardRoutingEntry.shardRouting  +   "),  reason  [ "  +  shardRoutingEntry.reason  +   "] ",  Priority.URGENT,  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  numSearches  =  atLeast(50);  context:  .setTimeout(TimeValue.timeValueSeconds(1)).setSource( "test-str ",  randomUnicodeOfLengthBetween(5,  25),   "test-num ",  i).get();  }  catch  (ElasticsearchException  ex)  {  }  }  RefreshResponse  refreshResponse  =  client().admin().indices().prepareRefresh( "test ").execute().get();  //  don't  assert  on  failures  here  final  boolean  refreshFailed  =  refreshResponse.getShardFailures().length  !=  0  ||  refreshResponse.getFailedShards()  !=  0;  refreshFailed,  refreshResponse.getFailedShards(),  refreshResponse.getShardFailures().length,  refreshResponse.getSuccessfulShards(),  refreshResponse.getTotalShards());          final  int  numSearches  =  atLeast(50);          final  int  numSearches  =  scaledRandomIntBetween(50,  150);  NodesStatsResponse  resp  =  client().admin().cluster().prepareNodesStats()  .clear().setBreaker(true).execute().actionGet();  for  (NodeStats  stats  :  resp.getNodes())  {  assertThat( "Breaker  is  set  to  0 ",  stats.getBreaker().getEstimated(),  equalTo(0L));  }  for  (int  i  =  0;  i  <  numSearches;  i++)  {  SearchRequestBuilder  searchRequestBuilder  =  client().prepareSearch().setQuery(QueryBuilders.matchAllQuery());  	final  int  numSearches  =  scaledRandomIntBetween(50,  150);  
libgdx_893466e120e16638847491ebf92efffa03ff2b70	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.TextureDataTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.TextureDataTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.AnimationTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.AnimationTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_7d4f1327aac1dffe5bd71e616dd2a0f304faf7c6	buggy:  renderer  =  new  MD5Renderer(  app.getGraphics(),  model,  true,  true  );  context:  public  void  surfaceCreated(Application  app)  {  if(  model  ==  null  )  {  model  =  MD5Loader.loadModel(  app.getFiles().readFile(   "data/zfat.md5mesh ",  FileType.Internal)  );  anim  =  MD5Loader.loadAnimation(  app.getFiles().readFile(   "data/walk1.md5anim ",  FileType.Internal  )  );  skeleton  =  new  MD5Joints();  skeleton.joints  =  new  float[anim.frames[0].joints.length];  animInfo  =  new  MD5AnimationInfo(  anim.frames.length,  anim.secondsPerFrame  );  renderer  =  new  MD5Renderer(  app.getGraphics(),  model,  true,  true  );  renderer  =  new  MD5Renderer(  app.getGraphics(),  model,  false,  true  );  	renderer  =  new  MD5Renderer(  app.getGraphics(),  model,  false,  true  );  
elasticsearch_7beac4ddbfabc2e2cecc06708dc48783aed4b2a1	buggy:  if  (exp  instanceof  ConnectTransportException)  {  context:  public  void  handleException(TransportException  exp)  {  if  (!running)  {  return;  }  NodeFD  nodeFD  =  nodesFD.get(node);  if  (nodeFD  !=  null)  {  if  (!nodeFD.running)  {  return;  }                                  if  (exp  instanceof  ConnectTransportException)  {                                  if  (exp  instanceof  ConnectTransportException  ||  exp.getCause()  instanceof  ConnectTransportException)  {  handleTransportDisconnect(node);  return;  }  int  retryCount  =  ++nodeFD.retryCount;  if  (retryCount  >=  pingRetryCount)  {  	if  (exp  instanceof  ConnectTransportException  ||  exp.getCause()  instanceof  ConnectTransportException)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();  context:  InetAddress  hostAddressX;  try  {  hostAddressX  =  networkService.resolveBindHostAddress(bindHost);  }  catch  (IOException  e)  {  throw  new  BindHttpException( "Failed  to  resolve  host  [ "  +  bindHost  +   "] ",  e);  }  final  InetAddress  hostAddress  =  hostAddressX;  PortsRange  portsRange  =  new  PortsRange(port);          final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();          final  AtomicReference<Exception>  lastException  =  new  AtomicReference<>();  boolean  success  =  portsRange.iterate(new  PortsRange.PortCallback()  {  public  boolean  onPortNumber(int  portNumber)  {  try  {  serverChannel  =  serverBootstrap.bind(new  InetSocketAddress(hostAddress,  portNumber));  }  catch  (Exception  e)  {  lastException.set(e);  return  false;  	final  AtomicReference<Exception>  lastException  =  new  AtomicReference<>();  
elasticsearch_1114835de500230f14972f41aee2ae6be9b6aead	buggy:  return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  context:  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.flush(new  Engine.Flush().type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  return  new  ShardFlushResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  FlushRequest  request,  String[]  concreteIndices)  {          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true,  true);  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  FlushRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.METADATA);  }  	return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true,  true);  
libgdx_ba3a054b21bf3057e9bdee227c5681cb50f210f4	buggy:  font.draw(batch,  messageText,  x  +  bgLeftWidth,  y  +  textY  +  yOffset);  context:  float  yOffset  =  font.isFlipped()  ?  -textBounds.height  :  0;  if  (displayText.length()  ==  0)  {  if  (!focused  &&  messageText  !=  null)  {  if  (style.messageFontColor  !=  null)  {  font.setColor(style.messageFontColor.r,  style.messageFontColor.g,  style.messageFontColor.b,  style.messageFontColor.a  *  parentAlpha);  }  else  font.setColor(0.7f,  0.7f,  0.7f,  parentAlpha);  BitmapFont  messageFont  =  style.messageFont  !=  null  ?  style.messageFont  :  font;  font.draw(batch,  messageText,  x  +  bgLeftWidth,  y  +  textY  +  yOffset);  messageFont.draw(batch,  messageText,  x  +  bgLeftWidth,  y  +  textY  +  yOffset);  }  }  else  {  font.setColor(fontColor.r,  fontColor.g,  fontColor.b,  fontColor.a  *  parentAlpha);  font.draw(batch,  displayText,  x  +  bgLeftWidth  +  textOffset,  y  +  textY  +  yOffset,  visibleTextStart,  visibleTextEnd);  }  if  (focused  &&  !disabled)  {  blink();  if  (cursorOn  &&  cursorPatch  !=  null)  {  	messageFont.draw(batch,  messageText,  x  +  bgLeftWidth,  y  +  textY  +  yOffset);  
libgdx_6456ebb55f83346630a9c04cb6e0eeaed9107fae	buggy:  Actor  over  =  hit(stageCoords.x,  stageCoords.y,  false);  context:  if  (Gdx.app.getType()  ==  ApplicationType.Desktop)  mouseOverActor  =  fireEnterAndExit(mouseOverActor,  mouseScreenX,  mouseScreenY,  -1);  root.act(delta);  }  private  Actor  fireEnterAndExit  (Actor  overLast,  int  screenX,  int  screenY,  int  pointer)  {  screenToStageCoordinates(stageCoords.set(screenX,  screenY));  Actor  over  =  hit(stageCoords.x,  stageCoords.y,  false);  Actor  over  =  hit(stageCoords.x,  stageCoords.y,  true);  if  (over  ==  overLast)  return  overLast;  InputEvent  event  =  Pools.obtain(InputEvent.class);  event.setStage(this);  event.setStageX(stageCoords.x);  event.setStageY(stageCoords.y);  event.setPointer(pointer);  	Actor  over  =  hit(stageCoords.x,  stageCoords.y,  true);  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  clusterStateRequest.filterMetaData(true);  context:  void  documentation(StringBuilder  sb)  {  sb.append( "/_cat/recovery\n ");  sb.append( "/_cat/recovery/{index}\n ");  }  public  void  doRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  String[]  indices  =  Strings.splitStringByCommaToArray(request.param( "index "));  final  ClusterStateRequest  clusterStateRequest  =  new  ClusterStateRequest();          clusterStateRequest.filterMetaData(true);          clusterStateRequest.clear().nodes(true);  clusterStateRequest.local(request.paramAsBoolean( "local ",  clusterStateRequest.local()));  clusterStateRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterStateRequest.masterNodeTimeout()));  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  public  void  onResponse(final  ClusterStateResponse  clusterStateResponse)  {  IndicesStatusRequest  indicesStatusRequest  =  new  IndicesStatusRequest(indices);  indicesStatusRequest.recovery(true);  	clusterStateRequest.clear().nodes(true);  
elasticsearch_a0e9532dcaa79ad931c8dc18cb6dec2f00b19400	buggy:  return  settingsBuilder().put( "plugin.types ",  CustomScriptPlugin.class.getName()).put(super.nodeSettings(nodeOrdinal)).build();  context:  public  class  ScriptFieldTests  extends  ElasticsearchIntegrationTest  {  protected  Settings  nodeSettings(int  nodeOrdinal)  {          return  settingsBuilder().put( "plugin.types ",  CustomScriptPlugin.class.getName()).put(super.nodeSettings(nodeOrdinal)).build();          return  settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "plugin.types ",  CustomScriptPlugin.class.getName()).build();  }  static  int[]  intArray  =  {  Integer.MAX_VALUE,  Integer.MIN_VALUE,  3  };  static  long[]  longArray  =  {  Long.MAX_VALUE,  Long.MIN_VALUE,  9223372036854775807l  };  static  float[]  floatArray  =  {  Float.MAX_VALUE,  Float.MIN_VALUE,  3.3f  };  static  double[]  doubleArray  =  {  Double.MAX_VALUE,  Double.MIN_VALUE,  3.3d  };  public  void  testNativeScript()  throws  InterruptedException,  ExecutionException  {  	return  settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "plugin.types ",  CustomScriptPlugin.class.getName()).build();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<DumpContributionFailedException>  failedContributors  =  new  ArrayList<DumpContributionFailedException>();  context:  fileName  +=  localNode.id()  +   "- ";  }  File  file  =  new  File(dumpLocation,  fileName  +  cause  +   "- "  +  timestamp);  FileSystemUtils.mkdirs(file);  SimpleDump  dump;  try  {  dump  =  new  SimpleDump(System.currentTimeMillis(),  cause,  context,  file);  }  catch  (FileNotFoundException  e)  {  throw  new  DumpGenerationFailedException( "Failed  to  generate  dump ",  e);  }          ArrayList<DumpContributionFailedException>  failedContributors  =  new  ArrayList<DumpContributionFailedException>();          ArrayList<DumpContributionFailedException>  failedContributors  =  new  ArrayList<>();  for  (String  name  :  contributors)  {  DumpContributor  contributor  =  this.contributors.get(name);  if  (contributor  ==  null)  {  failedContributors.add(new  DumpContributionFailedException(name,   "No  contributor "));  continue;  }  try  {  contributor.contribute(dump);  	ArrayList<DumpContributionFailedException>  failedContributors  =  new  ArrayList<>();  
elasticsearch_f82ceb1e1eaf2568a85e59475d1cad2234de0cf5	buggy:  if  ((i  %  100)  ==  0)  {  context:  client( "server1 ").admin().indices().prepareRefresh().execute().actionGet();  assertThat(client( "server1 ").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),  equalTo(0l));  for  (long  i  =  0;  i  <  12345;  i++)  {  client( "server1 ").prepareIndex( "test ",   "type1 ",  Long.toString(i))  .setCreate(true)  //  make  sure  we  use  create,  so  if  we  recover  wrongly,  we  will  get  increments...  .setSource(MapBuilder.<String,  Object>newMapBuilder().put( "test ",   "value "  +  i).map()).execute().actionGet();              if  ((i  %  100)  ==  0)  {              if  ((i  %  11)  ==  0)  {  client( "server1 ").admin().indices().prepareGatewaySnapshot().execute().actionGet();  }  }  client( "server1 ").admin().indices().prepareRefresh().execute().actionGet();  assertThat(client( "server1 ").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),  equalTo(12345l));  	if  ((i  %  11)  ==  0)  {  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  .settings(settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).put( "routing.hash.type ",   "simple ")))  context:  private  Set<String>  fullExpectedIds  =  Sets.newHashSet();  public  void  createNodes()  throws  Exception  {  startNode( "server1 ");  startNode( "server2 ");  client  =  getClient();  client.admin().indices().create(createIndexRequest( "test ")                  .settings(settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).put( "routing.hash.type ",   "simple ")))                  .settings(settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).put( "routing.hash.type ",   "simple ")))  .actionGet();  client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();  for  (int  i  =  0;  i  <  100;  i++)  {  index(client( "server1 "),  Integer.toString(i),   "test ",  i);  fullExpectedIds.add(Integer.toString(i));  }  	.settings(settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).put( "routing.hash.type ",   "simple ")))  
elasticsearch_417c193cc3547e00d37bff4a8c760a4486057e61	buggy:  return  null;  context:  MultiDocs(MultiOrdinals  ordinals)  {  this.ordinals  =  ordinals;  this.endOffsets  =  ordinals.endOffsets;  this.ords  =  ordinals.ords;  this.longsScratch  =  new  LongsRef(16);  this.iter  =  new  MultiIter(ords);  }  public  Ordinals  ordinals()  {              return  null;              return  this.ordinals;  }  public  int  getNumDocs()  {  return  ordinals.getNumDocs();  }  	return  this.ordinals;  
elasticsearch_3c58176d29b3caa3ac32a696dd665a1568e64139	buggy:  }  else  if  ( "total ".equals(sScoreMode))  {  context:  }  else  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  else  if  ( "_scope ".equals(currentFieldName))  {  throw  new  QueryParsingException(parseContext.index(),   "the  [_scope]  support  in  [nested]  query  has  been  removed,  use  nested  filter  as  a  facet_filter  in  the  relevant  facet ");  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(currentFieldName))  {  String  sScoreMode  =  parser.text();  if  ( "avg ".equals(sScoreMode))  {  scoreMode  =  ScoreMode.Avg;  }  else  if  ( "max ".equals(sScoreMode))  {  scoreMode  =  ScoreMode.Max;                          }  else  if  ( "total ".equals(sScoreMode))  {                          }  else  if  ( "total ".equals(sScoreMode)  ||   "sum ".equals(sScoreMode))  {  scoreMode  =  ScoreMode.Total;  }  else  if  ( "none ".equals(sScoreMode))  {  scoreMode  =  ScoreMode.None;  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "illegal  score_mode  for  nested  query  [ "  +  sScoreMode  +   "] ");  }  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  	}  else  if  ( "total ".equals(sScoreMode)  ||   "sum ".equals(sScoreMode))  {  
elasticsearch_574c4552038e53ac292274efdfebb6320ebba764	buggy:  return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)));  context:  }  }  count++;  }          return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)));          return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  }  }  	return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  
elasticsearch_852a1103f38ea96d83f7cbae7cd8b8ce5705a53a	buggy:  clusterState  =  ClusterState.Builder.readFrom(in,  null);  context:  }  public  ClusterName  getClusterName()  {  return  this.clusterName;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  clusterName  =  ClusterName.readClusterName(in);          clusterState  =  ClusterState.Builder.readFrom(in,  null);          clusterState  =  ClusterState.Builder.readFrom(in,  null,  clusterName);  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  clusterName.writeTo(out);  ClusterState.Builder.writeTo(clusterState,  out);  }  	clusterState  =  ClusterState.Builder.readFrom(in,  null,  clusterName);  
libgdx_f47cd059f5a72414701390724555e6540ceda18d	buggy:  SoundManager.init(GWT.getModuleBaseURL(),  9,  true,  new  SoundManager.SoundManagerCallback(){  context:  panel.setWidth( " "  +  config.width  +   "px ");  panel.setHeight( " "  +  config.height  +   "px ");  panel.setHorizontalAlignment(HasHorizontalAlignment.ALIGN_CENTER);  panel.setVerticalAlignment(HasVerticalAlignment.ALIGN_MIDDLE);  element.appendChild(panel.getElement());  root  =  panel;  }  }  SoundManager.init(GWT.getModuleBaseURL(),  9,  true,  new  SoundManager.SoundManagerCallback(){  SoundManager.init(GWT.getModuleBaseURL(),  9,  config.preferFlash,  new  SoundManager.SoundManagerCallback(){  public  void  onready  ()  {  final  PreloaderCallback  callback  =  getPreloaderCallback();  preloader  =  createPreloader();  preloader.preload( "assets.txt ",  new  PreloaderCallback()  {  public  void  error  (String  file)  {  	SoundManager.init(GWT.getModuleBaseURL(),  9,  config.preferFlash,  new  SoundManager.SoundManagerCallback(){  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  public  void  onResponse(ClusterStateResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field(Fields.CLUSTER_NAME,  response.getClusterName().value());  response.getState().settingsFilter(settingsFilter).toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  if  (logger.isDebugEnabled())  {  	}  catch  (Throwable  e)  {  
elasticsearch_4c8978237fdb07ed81fc7cb0255f43cfe7c1f490	buggy:  GroupShardsIterator  group  =  indicesService.indexServiceSafe(request.index()).operationRouting().deleteByQueryShards(clusterService.state());  context:  indexShard(shardRequest).deleteByQuery(request.querySource(),  request.queryParserName(),  request.types());  return  new  ShardDeleteByQueryResponse();  }  ShardDeleteByQueryRequest  request  =  shardRequest.request;  indexShard(shardRequest).deleteByQuery(request.querySource(),  request.queryParserName(),  request.types());  }          GroupShardsIterator  group  =  indicesService.indexServiceSafe(request.index()).operationRouting().deleteByQueryShards(clusterService.state());          GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  for  (ShardsIterator  shards  :  group)  {  if  (shards.shardId().id()  ==  request.shardId())  {  return  shards;  }  }  throw  new  ElasticSearchIllegalStateException( "No  shards  iterator  found  for  shard  [ "  +  request.shardId()  +   "] ");  }  }  	GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  
elasticsearch_bcda6dfe54735f9a4b0252dbd8a8f43dd67f2c57	buggy:  mapper  =  MapperTestUtils.newParser().parse(null,  getRandom().nextBoolean()  ?  null  :   " ",  defaultMapping);  context:  public  void  testDefaultMappingAndNoMapping()  throws  Exception  {  String  defaultMapping  =  XContentFactory.jsonBuilder().startObject().startObject(MapperService.DEFAULT_MAPPING)  .startObject( "_source ").field( "enabled ",  false).endObject()  .endObject().endObject().string();  DocumentMapper  mapper  =  MapperTestUtils.newParser().parse( "my_type ",  null,  defaultMapping);  assertThat(mapper.type(),  equalTo( "my_type "));  assertThat(mapper.sourceMapper().enabled(),  equalTo(false));  try  {              mapper  =  MapperTestUtils.newParser().parse(null,  getRandom().nextBoolean()  ?  null  :   " ",  defaultMapping);              mapper  =  MapperTestUtils.newParser().parse(null,  null,  defaultMapping);  assertThat(mapper.type(),  equalTo( "my_type "));  assertThat(mapper.sourceMapper().enabled(),  equalTo(false));  assert  false;  }  catch  (MapperParsingException  e)  {  }  try  {  mapper  =  MapperTestUtils.newParser().parse(null,   "{} ",  defaultMapping);  	mapper  =  MapperTestUtils.newParser().parse(null,  null,  defaultMapping);  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  filter  =  parseContext.cacheFilter(filter);  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }          filter  =  parseContext.cacheFilter(filter);          filter  =  parseContext.cacheFilter(filter,  null);  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  return  filter;  }  }  	filter  =  parseContext.cacheFilter(filter,  null);  
libgdx_9b915fa50165aef03863b677fe5b47d615d76a09	buggy:  GdxTest  test  =  new  GleedTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  GleedTest();  GdxTest  test  =  new  TiledMapBench();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  TiledMapBench();  
libgdx_0cc5a2df18937254b2001c5d2cf1b8bb1cdbc825	buggy:  setScreen(new  MainMenuScreen(this));  context:  public  class  SuperJumper  extends  Game  {  boolean  firstTimeCreate  =  true;  FPSLogger  fps;  public  void  create  ()  {  Settings.load();  Assets.load();  setScreen(new  MainMenuScreen(this));  setScreen(new  GameScreen(this));  fps  =  new  FPSLogger();  }  public  void  render()  {  super.render();  fps.log();  }  	setScreen(new  GameScreen(this));  
libgdx_17a7ff5b86c1c0db55c16f4c97d531553b080b4f	buggy:  return  Integer.parseInt(android.os.Build.VERSION.SDK);  context:  return  net;  }  public  ApplicationType  getType  ()  {  return  ApplicationType.Android;  }  public  int  getVersion  ()  {  return  Integer.parseInt(android.os.Build.VERSION.SDK);  return  android.os.Build.VERSION.SDK_INT;  }  public  long  getJavaHeap  ()  {  return  Runtime.getRuntime().totalMemory()  -  Runtime.getRuntime().freeMemory();  }  	return  android.os.Build.VERSION.SDK_INT;  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  System.out.println( "Count:   "  +  client.client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().count());  context:  client1.prepareIndex( "test ",   "type1 ").setId(Integer.toString(i  %  ID_RANGE)).setSource(source(Integer.toString(i),   "test "  +  i))  .setCreate(false).execute().actionGet();  if  ((i  %  10000)  ==  0)  {  stopWatch.start();  }  }  client.client().admin().indices().prepareRefresh().execute().actionGet();          System.out.println( "Count:   "  +  client.client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().count());          System.out.println( "Count:   "  +  client.client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().getCount());  client.close();  for  (Node  node  :  nodes)  {  node.close();  }  }  	System.out.println( "Count:   "  +  client.client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().getCount());  
elasticsearch_d25c4cc91407a80a2b7052ea9e1a96bbcf7f1f5a	buggy:  String  data  =  settings.get( "data ");  context:  public  static  boolean  masterNode(Settings  settings)  {  String  master  =  settings.get( "node.master ");  if  (master  ==  null)  {  return  !clientNode(settings);  }  return  master.equals( "true ");  }  public  static  boolean  dataNode(Settings  settings)  {          String  data  =  settings.get( "data ");          String  data  =  settings.get( "node.data ");  if  (data  ==  null)  {  return  !clientNode(settings);  }  return  data.equals( "true ");  }  public  static  final  ImmutableList<DiscoveryNode>  EMPTY_LIST  =  ImmutableList.of();  	String  data  =  settings.get( "node.data ");  
libgdx_aa153c05af20461798e8acaa4931174c752caff6	buggy:  if  (scaleX  ==  0  &&  scaleY  ==  0  &&  rotation  ==  0)  context:  originX  =  width  /  2.0f;  originY  =  height  /  2.0f;  this.unpressedRegion  =  new  TextureRegion(unpressedRegion);  this.pressedRegion  =  new  TextureRegion(pressedRegion);  }  TextureRegion  region  =  pressed  ?  pressedRegion  :  unpressedRegion;  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  if  (region.getTexture()  !=  null)  {  if  (scaleX  ==  0  &&  scaleY  ==  0  &&  rotation  ==  0)  if  (scaleX  ==  1  &&  scaleY  ==  1  &&  rotation  ==  0)  batch.draw(region,  x,  y,  width,  height);  else  batch.draw(region,  x,  y,  originX,  originY,  width,  height,  scaleX,  scaleY,  rotation);  }  }  if(pressed)  return  false;  	if  (scaleX  ==  1  &&  scaleY  ==  1  &&  rotation  ==  0)  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  clusterState  =  ClusterState.Builder.readFrom(in,  settings,  nodesProvider.nodes().localNode());  context:  private  ClusterState  clusterState;  private  PublishClusterStateRequest()  {  }  private  PublishClusterStateRequest(ClusterState  clusterState)  {  this.clusterState  =  clusterState;  }              clusterState  =  ClusterState.Builder.readFrom(in,  settings,  nodesProvider.nodes().localNode());              clusterState  =  ClusterState.Builder.readFrom(in,  nodesProvider.nodes().localNode());  }  ClusterState.Builder.writeTo(clusterState,  out);  }  }  private  class  PublishClusterStateRequestHandler  extends  BaseTransportRequestHandler<PublishClusterStateRequest>  {  	clusterState  =  ClusterState.Builder.readFrom(in,  nodesProvider.nodes().localNode());  
elasticsearch_8260138e5975ebcb588933d792d22374168c48cf	buggy:  if  (formatter  !=  null)  {  context:  long  docCount  =  0;  for  (Bucket  bucket  :  buckets)  {  docCount  +=  bucket.docCount;  aggregations.add((InternalAggregations)  bucket.getAggregations());  }  InternalAggregations  aggs  =  InternalAggregations.reduce(aggregations,  bigArrays);  return  (B)  getFactory().createBucket(key,  docCount,  aggs,  formatter);  }  void  toXContent(XContentBuilder  builder,  Params  params,  boolean  keyed,  @Nullable  ValueFormatter  formatter)  throws  IOException  {              if  (formatter  !=  null)  {              if  (formatter  !=  null  &&  formatter  !=  ValueFormatter.RAW)  {  Text  keyTxt  =  new  StringText(formatter.format(key));  if  (keyed)  {  builder.startObject(keyTxt.string());  }  else  {  builder.startObject();  }  builder.field(CommonFields.KEY_AS_STRING,  keyTxt);  }  else  {  	if  (formatter  !=  null  &&  formatter  !=  ValueFormatter.RAW)  {  
elasticsearch_fad5e2d0e10e6c0ffb03a18bc38019e35bf05c6c	buggy:  ShardRouting  shardRouting  =  shardIterator.firstOrNull();  context:  public  void  onFailure(Throwable  e)  {  listener.onFailure(e);  }  });  }  private  void  redirect(MoreLikeThisRequest  request,  String  concreteIndex,  final  ActionListener<SearchResponse>  listener,  ClusterState  clusterState)  {  ShardIterator  shardIterator  =  clusterService.operationRouting().getShards(clusterState,  concreteIndex,  request.type(),  request.id(),  request.routing(),  null);          ShardRouting  shardRouting  =  shardIterator.firstOrNull();          ShardRouting  shardRouting  =  shardIterator.nextOrNull();  if  (shardRouting  ==  null)  {  throw  new  ElasticsearchException( "No  shards  for  index   "  +  request.index());  }  String  nodeId  =  shardRouting.currentNodeId();  DiscoveryNode  discoveryNode  =  clusterState.nodes().get(nodeId);  transportService.sendRequest(discoveryNode,  MoreLikeThisAction.NAME,  request,  new  TransportResponseHandler<SearchResponse>()  {  	ShardRouting  shardRouting  =  shardIterator.nextOrNull();  
libgdx_f824bf708cf4eca0f06fdd6fcf75cdbd891565f0	buggy:  map.setOwnedTextures(textures.values().toArray());  context:  public  TiledMap  load  (String  fileName)  {  try  {  FileHandle  tideFile  =  resolve(fileName);  root  =  xml.parse(tideFile);  ObjectMap<String,  Texture>  textures  =  new  ObjectMap<String,  Texture>();  for(FileHandle  textureFile:  loadTileSheets(root,  tideFile))  {  textures.put(textureFile.path(),  new  Texture(textureFile));  }  DirectImageResolver  imageResolver  =  new  DirectImageResolver(textures);  TiledMap  map  =  loadMap(root,  tideFile,  imageResolver);  map.setOwnedTextures(textures.values().toArray());  map.setOwnedResources(textures.values().toArray());  return  map;  }  catch(IOException  e)  {  throw  new  GdxRuntimeException( "Couldn't  load  tilemap  ' "  +  fileName  +   "' ",  e);  }  }  	map.setOwnedResources(textures.values().toArray());  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  updateSettingsService.updateSettings(request.settings(),  request.indices(),  new  MetaDataUpdateSettingsService.Listener()  {  context:  protected  UpdateSettingsResponse  newResponse()  {  return  new  UpdateSettingsResponse();  }  protected  UpdateSettingsResponse  masterOperation(UpdateSettingsRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          updateSettingsService.updateSettings(request.settings(),  request.indices(),  new  MetaDataUpdateSettingsService.Listener()  {          updateSettingsService.updateSettings(request.settings(),  request.indices(),  request.masterNodeTimeout(),  new  MetaDataUpdateSettingsService.Listener()  {  public  void  onSuccess()  {  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  failureRef.set(t);  	updateSettingsService.updateSettings(request.settings(),  request.indices(),  request.masterNodeTimeout(),  new  MetaDataUpdateSettingsService.Listener()  {  
elasticsearch_bc452dff84da86298b5234f81e90dd768244d70c	buggy:  GeoDistance  geoDistance  =  GeoDistance.ARC;  context:  CacheKeyFilter.Key  cacheKey  =  null;  String  filterName  =  null;  String  currentFieldName  =  null;  GeoPoint  point  =  new  GeoPoint();  String  fieldName  =  null;  Object  vFrom  =  null;  Object  vTo  =  null;  boolean  includeLower  =  true;  boolean  includeUpper  =  true;  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;  //  default  unit          GeoDistance  geoDistance  =  GeoDistance.ARC;          GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  String  optimizeBbox  =   "memory ";  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  GeoPoint.parse(parser,  point);  	GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  
libgdx_52eca501e35d1adbe360b83bfa9446fb72b7d0b1	buggy:  int  pointerIndex  =  (event.getAction()  &  MotionEvent.ACTION_POINTER_ID_MASK)  >>  MotionEvent.ACTION_POINTER_ID_SHIFT;  context:  public  class  AndroidMultiTouchHandler  implements  AndroidTouchHandler  {  public  void  onTouch  (MotionEvent  event,  AndroidInput  input)  {  final  int  action  =  event.getAction()  &  MotionEvent.ACTION_MASK;  int  pointerIndex  =  (event.getAction()  &  MotionEvent.ACTION_POINTER_ID_MASK)  >>  MotionEvent.ACTION_POINTER_ID_SHIFT;  int  pointerIndex  =  (event.getAction()  &  MotionEvent.ACTION_POINTER_INDEX_MASK)  >>  MotionEvent.ACTION_POINTER_INDEX_SHIFT;  int  pointerId  =  event.getPointerId(pointerIndex);  int  x  =  0,  y  =  0;  int  realPointerIndex  =  0;  long  timeStamp  =  System.nanoTime();  synchronized  (input)  {  switch  (action)  {  	int  pointerIndex  =  (event.getAction()  &  MotionEvent.ACTION_POINTER_INDEX_MASK)  >>  MotionEvent.ACTION_POINTER_INDEX_SHIFT;  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  aggregated.release();  context:  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  ordered.add(new  DoubleEntry(keys[i],  values[i]));  }  }  first.entries  =  ordered;  first.missing  =  missing;  first.total  =  total;          aggregated.release();          aggregated.close();  return  first;  }  private  void  trimExcessEntries()  {  if  (requiredSize  >=  entries.size())  {  return;  }  	aggregated.close();  
elasticsearch_76d042f3c5c4c4fcce91a09e1d10204ff7dace36	buggy:  if  (params  ==  null)  {  context:  public  ScriptFilterBuilder  addParam(String  name,  Object  value)  {  if  (params  ==  null)  {  params  =  newHashMap();  }  params.put(name,  value);  return  this;  }  public  ScriptFilterBuilder  params(Map<String,  Object>  params)  {          if  (params  ==  null)  {          if  (this.params  ==  null)  {  this.params  =  params;  }  else  {  this.params.putAll(params);  }  return  this;  }  	if  (this.params  ==  null)  {  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE).source( "refresh_flag_get "));  context:  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));  request.index(state.metaData().concreteIndex(request.index()));  }  protected  GetResponse  shardOperation(GetRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {              indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE).source( "refresh_flag_get "));              indexShard.refresh(new  Engine.Refresh( "refresh_flag_get ").force(REFRESH_FORCE));  }  GetResult  result  =  indexShard.getService().get(request.type(),  request.id(),  request.fields(),  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());  return  new  GetResponse(result);  }  	indexShard.refresh(new  Engine.Refresh( "refresh_flag_get ").force(REFRESH_FORCE));  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  return  new  InternalSearchRequest( "test ",  0).source(builder.buildAsBytes());  context:  try  {  searchService.executeFetchPhase(new  FetchSearchRequest(queryResult.id(),  docIdsToLoad.values().iterator().next()));  assert  true  :   "context  should  be  missing  since  it  timed  out ";  }  catch  (SearchContextMissingException  e)  {  }  }  private  InternalSearchRequest  searchRequest(SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest( "test ",  0).source(builder.buildAsBytes());          return  new  InternalSearchRequest( "test ",  0,  1).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  return   "{  type1  :  {  \ "id\ "  :  \ " "  +  id  +   "\ ",  \ "name\ "  :  \ " "  +  nameValue  +   "\ ",  age  :   "  +  age  +   "  }  } ";  	return  new  InternalSearchRequest( "test ",  0,  1).source(builder.buildAsBytes());  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  return  querySource(queryBuilder.build());  context:  public  CountRequest  minScore(float  minScore)  {  this.minScore  =  minScore;  return  this;  }  String  querySource()  {  return  querySource;  }          return  querySource(queryBuilder.build());          return  querySource(queryBuilder.buildAsString());  }  public  CountRequest  querySource(String  querySource)  {  this.querySource  =  querySource;  return  this;  }  String  queryParserName()  {  	return  querySource(queryBuilder.buildAsString());  
elasticsearch_5487c56c70663bb5fae6ddeb6e2fc8582396e792	buggy:  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false);  context:  protected  final  void  addShardFailure(final  int  shardIndex,  ShardSearchFailure  failure)  {  if  (shardFailures  ==  null)  {  shardFailures  =  new  AtomicArray<>(scrollId.getContext().length);  }  shardFailures.set(shardIndex,  failure);  }  public  void  start()  {  if  (scrollId.getContext().length  ==  0)  {                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false);                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false,  null);  listener.onResponse(new  SearchResponse(internalResponse,  request.scrollId(),  0,  0,  0l,  buildShardFailures()));  return;  }  Tuple<String,  Long>[]  context  =  scrollId.getContext();  for  (int  i  =  0;  i  <  context.length;  i++)  {  Tuple<String,  Long>  target  =  context[i];  DiscoveryNode  node  =  nodes.get(target.v1());  	final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false,  null);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {  context:  protected  ClusterBlockException  checkBlock(DeleteIndexTemplateRequest  request,  ClusterState  state)  {  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,   " ");  }  protected  DeleteIndexTemplateResponse  masterOperation(DeleteIndexTemplateRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<DeleteIndexTemplateResponse>  responseRef  =  new  AtomicReference<DeleteIndexTemplateResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {          indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.getName()),  new  MetaDataIndexTemplateService.RemoveListener()  {  public  void  onResponse(MetaDataIndexTemplateService.RemoveResponse  response)  {  responseRef.set(new  DeleteIndexTemplateResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.getName()),  new  MetaDataIndexTemplateService.RemoveListener()  {  
libgdx_b547d881eed01e5b932e5806133e30d04411e112	buggy:  this.world.fixtures.remove(fixture);  context:  public  void  destroyFixture(Fixture  fixture)  {  jniDestroyFixture(  addr,  fixture.addr  );  this.world.fixtures.remove(fixture);  this.world.fixtures.remove(fixture.addr);  this.fixtures.remove(fixture);  }  private  native  void  jniDestroyFixture(  long  addr,  long  fixtureAddr  );  	this.world.fixtures.remove(fixture.addr);  
elasticsearch_2b9bdc37961022c0f254f86fac083f5d2fdeca12	buggy:  entry  =  new  InternalFullHistogramFacet.FullEntry(bucket,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);  context:  final  ValueAggregator  valueAggregator  =  new  ValueAggregator();  public  HistogramProc(long  interval)  {  this.interval  =  interval;  }  long  bucket  =  FullHistogramFacetCollector.bucket(value,  interval);  InternalFullHistogramFacet.FullEntry  entry  =  entries.get(bucket);  if  (entry  ==  null)  {                  entry  =  new  InternalFullHistogramFacet.FullEntry(bucket,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);                  entry  =  new  InternalFullHistogramFacet.FullEntry(bucket,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  entries.put(bucket,  entry);  }  entry.count++;  valueAggregator.entry  =  entry;  valueFieldData.forEachValueInDoc(docId,  valueAggregator);  }  public  static  class  ValueAggregator  implements  NumericFieldData.DoubleValueInDocProc  {  	entry  =  new  InternalFullHistogramFacet.FullEntry(bucket,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  
elasticsearch_a9dd3c97568446a4c281c2ab72cbc838b52aeb76	buggy:  shardRequest.add(i,  item.type(),  item.id(),  item.fields());  context:  .getShards(clusterState,  item.index(),  item.type(),  item.id(),  item.routing(),  null).shardId();  MultiGetShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiGetShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequest.realtime(request.realtime);  shardRequest.refresh(request.refresh);  shardRequests.put(shardId,  shardRequest);  }              shardRequest.add(i,  item.type(),  item.id(),  item.fields());              shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType());  }  if  (shardRequests.size()  ==  0)  {  listener.onResponse(new  MultiGetResponse(responses.toArray(new  MultiGetItemResponse[responses.length()])));  }  final  AtomicInteger  counter  =  new  AtomicInteger(shardRequests.size());  	shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  context.cacheRecycler().longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector();  }  public  InternalFacet  buildFacet(String  facetName)  {          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }  	List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  
libgdx_6bef7431cf872bd0ef5b64fb374ea777afef5999	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (int[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (int[]  array,  int  offset,  int  length)  {  int[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  int  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length;  
elasticsearch_07c9b5b08d985a270e36f2cac790d7450d8a7905	buggy:  logger.error( "New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  context:  currentUsed  =  this.used.get();  newUsed  =  currentUsed  +  bytes;  long  newUsedWithOverhead  =  (long)(newUsed  *  overheadConstant);  if  (logger.isTraceEnabled())  {  new  ByteSizeValue(bytes),  label,  new  ByteSizeValue(newUsed),  memoryBytesLimit,  new  ByteSizeValue(memoryBytesLimit),  newUsedWithOverhead,  new  ByteSizeValue(newUsedWithOverhead));  }  if  (memoryBytesLimit  >  0  &&  newUsedWithOverhead  >  memoryBytesLimit)  {                  logger.error( "New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",                  logger.warn( "New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  newUsedWithOverhead,  new  ByteSizeValue(newUsedWithOverhead),  label,  memoryBytesLimit,  new  ByteSizeValue(memoryBytesLimit));  circuitBreak(label,  newUsedWithOverhead);  }  }  while  (!this.used.compareAndSet(currentUsed,  newUsed));  	logger.warn( "New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  
elasticsearch_f93efc360548e01480ca0f951b5001681bcd2901	buggy:  logger.debug( "Moving  to  second  phase,  based  on  results  from:  {} ",  sb);  context:  continue;  //  failure  }  if  (hadOne)  {  sb.append( ", ");  }  else  {  hadOne  =  true;  }  sb.append(result.shardTarget());  }                  logger.debug( "Moving  to  second  phase,  based  on  results  from:  {} ",  sb);                  logger.debug( "Moving  to  second  phase,  based  on  results  from:  {}  (cluster  state  version:  {}) ",  sb,  clusterState.version());  }  moveToSecondPhase();  }  protected  abstract  void  moveToSecondPhase()  throws  Exception;  protected  abstract  String  firstPhaseName();  }  	logger.debug( "Moving  to  second  phase,  based  on  results  from:  {}  (cluster  state  version:  {}) ",  sb,  clusterState.version());  
elasticsearch_167538ef0d8003e083af4f85da139c7020afcc57	buggy:  indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE));  context:  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));  request.index(state.metaData().concreteIndex(request.index()));  }  protected  GetResponse  shardOperation(GetRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {              indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE));              indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE).source( "refresh_flag_get "));  }  GetResult  result  =  indexShard.getService().get(request.type(),  request.id(),  request.fields(),  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());  return  new  GetResponse(result);  }  	indexShard.refresh(new  Engine.Refresh().force(REFRESH_FORCE).source( "refresh_flag_get "));  
libgdx_284c9990d9791c5d2fe48b3ed892bf25a52dd531	buggy:  if  (scaleValue  !=  1  ||  scale.length  !=  1)  {  context:  extension  =  packFileName.substring(dotIndex);  packFileName  =  packFileName.substring(0,  dotIndex);  }  if  (scaleSuffix[scaleIndex].length()  >  0)  packFileName  +=  scaleSuffix[scaleIndex];  else  {  float  scaleValue  =  scale[scaleIndex];  if  (scaleValue  !=  1  ||  scale.length  !=  1)  {  if  (scale.length  !=  1)  {  packFileName  =  (scaleValue  ==  (int)scaleValue  ?  Integer.toString((int)scaleValue)  :  Float.toString(scaleValue))   "/ "  +  packFileName;  }  }  packFileName  +=  extension;  if  (packFileName.indexOf('.')  ==  -1  ||  packFileName.endsWith( ".png ")  ||  packFileName.endsWith( ".jpg "))  packFileName  +=   ".atlas ";  	if  (scale.length  !=  1)  {  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  System.exit(0);  context:   "varying  vec2  v_texCoords;\n "  +   "uniform  sampler2D  u_texture;\n "  +   "void  main()                                  \n "  +   "{                                            \n "  +   "  gl_FragColor  =  v_color  *  texture2D(u_texture,  v_texCoords);\n "   "} ";  shader  =  new  ShaderProgram(vertexShader,  fragmentShader);  if  (shader.isCompiled()  ==  false)  {  Gdx.app.log( "ShaderTest ",  shader.getLog());  System.exit(0);  Gdx.app.exit();  }  mesh  =  new  Mesh(true,  4,  6,  VertexAttribute.Position(),  VertexAttribute.ColorUnpacked(),  VertexAttribute.TexCoords(0));  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  1,  1,  1,  1,  0,  1,  0.5f,  -0.5f,  0,  1,  1,  1,  1,  1,  1,  0.5f,  0.5f,  0,  1,  1,  1,  1,  1,  0,  0.5f,  0.5f,  0,  1,  1,  1,  1,  0,  0});  mesh.setIndices(new  short[]  {0,  1,  2,  2,  3,  0});  	Gdx.app.exit();  
libgdx_7bebe27c5851539183901ca4c64f356eca179734	buggy:  new  JoglApplication(new  KeyframedModelViewer(argv[0],  argv.length==2?argv[1]:null),   "KeframedModel  Viewer ",  320,  240,  false);  context:  }  }  public  static  void  main(String[]  argv)  {  if(argv.length  !=  1  &&  argv.length  !=  2)  {  System.exit(-1);  }  new  JoglApplication(new  KeyframedModelViewer(argv[0],  argv.length==2?argv[1]:null),   "KeframedModel  Viewer ",  320,  240,  false);  new  JoglApplication(new  KeyframedModelViewer( "data/boy.g3dt ",  argv.length==2?argv[1]:null),   "KeframedModel  Viewer ",  320,  240,  false);  }  }  	new  JoglApplication(new  KeyframedModelViewer( "data/boy.g3dt ",  argv.length==2?argv[1]:null),   "KeframedModel  Viewer ",  320,  240,  false);  
libgdx_e11396daad4d5c3efd948fa0a89a94395be4a6a3	buggy:  graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config.useGL20,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  context:  protected  final  Array<Runnable>  executedRunnables  =  new  Array<Runnable>();  protected  final  Array<LifecycleListener>  lifecycleListeners  =  new  Array<LifecycleListener>();  protected  int  logLevel  =  LOG_INFO;  public  AndroidLiveWallpaper(WallpaperService  service,  Engine  engine)  {  this.service  =  service;  this.engine  =  engine;  }  public  void  initialize(ApplicationListener  listener,  AndroidApplicationConfiguration  config)  {  graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config.useGL20,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  input  =  AndroidInputFactory.newAndroidInput(this,  this.getService(),  null,  config);  audio  =  new  AndroidAudio(this.getService(),  config);  files  =  new  AndroidFiles(this.getService().getAssets(),  this.getService().getFilesDir().getAbsolutePath());  this.listener  =  listener;  Gdx.app  =  this;  Gdx.input  =  this.getInput();  Gdx.audio  =  this.getAudio();  	graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  
libgdx_d0de5843edd4c9c4903188b203a9a3e098840b12	buggy:  return  new  GwtApplicationConfiguration(640,  640);  context:  public  class  GwtTestStarter  extends  GwtApplication  {  public  GwtApplicationConfiguration  getConfig  ()  {  return  new  GwtApplicationConfiguration(640,  640);  return  new  GwtApplicationConfiguration(480,  320);  }  public  ApplicationListener  getApplicationListener  ()  {  return  new  GwtTestWrapper();  }  }  	return  new  GwtApplicationConfiguration(480,  320);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  contentType  =  XContentFactory.xContentType(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  public  class  RestXContentBuilder  {  public  static  XContentBuilder  restContentBuilder(RestRequest  request)  throws  IOException  {  XContentType  contentType  =  XContentType.fromRestContentType(request.header( "Content-Type "));  if  (contentType  ==  null)  {  if  (request.hasContent())  {                  contentType  =  XContentFactory.xContentType(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  contentType  =  XContentFactory.xContentType(request.content());  }  }  if  (contentType  ==  null)  {  contentType  =  XContentType.JSON;  }  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  cachedEntry.bytes(),  cachedEntry);  	contentType  =  XContentFactory.xContentType(request.content());  
elasticsearch_4b2ff13833b9868c620b2943408d073f3042f526	buggy:  createIndexAction.execute(new  CreateIndexRequest(indexRequest.index()),  new  ActionListener<CreateIndexResponse>()  {  context:  if  (allowIdGeneration)  {  if  (indexRequest.id()  ==  null)  {  indexRequest.id(UUID.randomUUID().toString());  indexRequest.opType(IndexRequest.OpType.CREATE);  }  }  if  (autoCreateIndex  &&  !clusterService.state().metaData().hasConcreteIndex(indexRequest.index()))  {              createIndexAction.execute(new  CreateIndexRequest(indexRequest.index()),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(indexRequest.index()).cause( "auto(index  api) "),  new  ActionListener<CreateIndexResponse>()  {  TransportIndexAction.super.doExecute(indexRequest,  listener);  }  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  TransportIndexAction.super.doExecute(indexRequest,  listener);  	createIndexAction.execute(new  CreateIndexRequest(indexRequest.index()).cause( "auto(index  api) "),  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_836461e6de36c3218d9a7d90712370f1523057bb	buggy:  return  new  InternalSearchRequest(shardRouting,  builder.buildAsBytes());  context:  assertThat(searchResponse.facets().countFacet( "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().countFacet( "all ").count(),  equalTo(100l));  }  testSimpleFacets();  testSimpleFacets();  }  private  static  InternalSearchRequest  searchRequest(ShardRouting  shardRouting,  SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest(shardRouting,  builder.buildAsBytes());          return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  StringBuilder  multi  =  new  StringBuilder().append(nameValue);  	return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  afterIndexShardClosed(ShardId  shardId,  boolean  delete)  {  context:  public  void  afterIndexShardCreated(IndexShard  indexShard)  {  synchronized  (mutex)  {  calcAndSetShardIndexingBuffer( "created_shard[ "  +  indexShard.shardId().index().name()  +   "][ "  +  indexShard.shardId().id()  +   "] ");  shardsIndicesStatus.put(indexShard.shardId(),  new  ShardIndexingStatus());  }  }          public  void  afterIndexShardClosed(ShardId  shardId,  boolean  delete)  {          public  void  afterIndexShardClosed(ShardId  shardId)  {  synchronized  (mutex)  {  calcAndSetShardIndexingBuffer( "removed_shard[ "  +  shardId.index().name()  +   "][ "  +  shardId.id()  +   "] ");  shardsIndicesStatus.remove(shardId);  }  }  }  	public  void  afterIndexShardClosed(ShardId  shardId)  {  
elasticsearch_3268f5712536d5cbde55b1f467e90aabb7c8f907	buggy:  final  CountDownLatch  invoked2  =  new  CountDownLatch(8);  context:  return  currentState;  }  public  void  onFailure(String  source,  Throwable  t)  {  invoked1.countDown();  assert  false;  }  });  invoked1.await();          final  CountDownLatch  invoked2  =  new  CountDownLatch(8);          final  CountDownLatch  invoked2  =  new  CountDownLatch(9);  for  (int  i  =  2;  i  <=  10;  i++)  {  clusterService.submitStateUpdateTask(Integer.toString(i),  new  ClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  invoked2.countDown();  return  currentState;  }  	final  CountDownLatch  invoked2  =  new  CountDownLatch(9);  
elasticsearch_f96c1f1e10c0cb8f1854ecdb47a45275edde3816	buggy:  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).build());  context:  master.clusterService.submitStateUpdateTask( "local-disco-update ",  new  ClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  DiscoveryNodes  newNodes  =  currentState.nodes().removeDeadMembers(newMembers,  master.localNode.id());  DiscoveryNodes.Delta  delta  =  newNodes.delta(currentState.nodes());  if  (delta.added())  {  }  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState).nodes(newNodes).build();                          RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).build());                          RoutingAllocation.Result  routingResult  =  master.allocationService.reroute(newClusterStateBuilder().state(updatedState).build());  return  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  }  });  }  }  }  	RoutingAllocation.Result  routingResult  =  master.allocationService.reroute(newClusterStateBuilder().state(updatedState).build());  
libgdx_ed90a6a6f55568130589072cc621f61a63a75922	buggy:  new  AngleApplication(new  com.badlogic.gdx.tests.gles2.SimpleVertexShader(),   "Angle  Test ",  480,  320,  true);  context:  package  com.badlogic.gdx.tests.angle;  public  class  AngleDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  AngleApplication(new  com.badlogic.gdx.tests.gles2.SimpleVertexShader(),   "Angle  Test ",  480,  320,  true);  new  AngleApplication(new  com.badlogic.gdx.tests.InputTest(),   "Angle  Test ",  480,  320,  false);  }  }  	new  AngleApplication(new  com.badlogic.gdx.tests.InputTest(),   "Angle  Test ",  480,  320,  false);  
elasticsearch_f869951364ef1c5f437b65e4bb8004283cb69ecb	buggy:  DocumentMapper  docMapper  =  indexService.mapperService().type(request.type());  context:  }  state.blocks().indexBlockedRaiseException(ClusterBlockLevel.READ,  request.index());  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);          DocumentMapper  docMapper  =  indexService.mapperService().type(request.type());          DocumentMapper  docMapper  =  indexService.mapperService().documentMapper(request.type());  if  (docMapper  ==  null)  {  throw  new  DocumentMapperNotFoundException( "No  mapper  found  for  type  [ "  +  request.type()  +   "] ");  }  if  (request.refresh())  {  indexShard.refresh(new  Engine.Refresh(false));  }  	DocumentMapper  docMapper  =  indexService.mapperService().documentMapper(request.type());  
elasticsearch_dfdc183ba6e33061c8b4adaf094d98a0ebc102d8	buggy:  if  (snapshot.state()  ==  State.STARTED)  {  context:  MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  SnapshotMetaData  snapshots  =  metaData.custom(SnapshotMetaData.TYPE);  if  (snapshots  ==  null)  {  return  currentState;  }  boolean  changed  =  false;  ArrayList<SnapshotMetaData.Entry>  entries  =  newArrayList();  for  (final  SnapshotMetaData.Entry  snapshot  :  snapshots.entries())  {  SnapshotMetaData.Entry  updatedSnapshot  =  snapshot;  boolean  snapshotChanged  =  false;                          if  (snapshot.state()  ==  State.STARTED)  {                          if  (snapshot.state()  ==  State.STARTED  ||  snapshot.state()  ==  State.ABORTED)  {  ImmutableMap.Builder<ShardId,  ShardSnapshotStatus>  shards  =  ImmutableMap.builder();  for  (ImmutableMap.Entry<ShardId,  ShardSnapshotStatus>  shardEntry  :  snapshot.shards().entrySet())  {  ShardSnapshotStatus  shardStatus  =  shardEntry.getValue();  if  (!shardStatus.state().completed()  &&  shardStatus.nodeId()  !=  null)  {  if  (nodes.nodeExists(shardStatus.nodeId()))  {  shards.put(shardEntry);  }  else  {  	if  (snapshot.state()  ==  State.STARTED  ||  snapshot.state()  ==  State.ABORTED)  {  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  public  void  cancled()  {  context:  batch.end();  if(Gdx.input.justTouched())  {  Gdx.input.getTextInput(new  TextInputListener()  {  public  void  input(String  text)  {  message  =   "message:   "  +  text  +   ",  touch  screen  for  new  dialog ";  }  public  void  cancled()  {  public  void  canceled()  {  message  =   "cancled  by  user ";  }  },   "enter  something  funny ",   "funny ");  }  }  public  boolean  needsGL20()  {  	public  void  canceled()  {  
libgdx_015764fe472f9b7e2aee8ab616a883ad2996452d	buggy:  int  result  =  (int)type;  context:  this.value  =  value;  }  public  Attribute  copy  ()  {  return  new  FloatAttribute(type,  value);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  977  *  result  +  NumberUtils.floatToRawIntBits(value);  return  result;  }  }  	int  result  =  super.hashCode();  
libgdx_325aea4aff4f39868a270cb8ec909b4e0ede0374	buggy:  rotation.setFromAxes(tmp.x,  tmp.y,  tmp.z,  tmp2.x,  tmp2.y,  tmp2.z,  dir.x,  dir.y,  dir.z);  context:  rotation.mul(rotator);  updated  =  false;  }  public  void  setRotation  (Vector3  dir,  Vector3  up)  {  tmp.set(up).crs(dir).nor();  tmp2.set(dir).crs(tmp).nor();  rotation.setFromAxes(tmp.x,  tmp.y,  tmp.z,  tmp2.x,  tmp2.y,  tmp2.z,  dir.x,  dir.y,  dir.z);  rotation.setFromAxes(tmp.x,  tmp2.x,  dir.x,  tmp.y,  tmp2.y,  dir.y,  tmp.z,  tmp2.z,  dir.z);  updated  =  false;  }  public  Quaternion  getRotation  ()  {  return  rotation;  	rotation.setFromAxes(tmp.x,  tmp2.x,  dir.x,  tmp.y,  tmp2.y,  dir.y,  tmp.z,  tmp2.z,  dir.z);  
libgdx_70da7118c53c2c54a25e02258f628f04be03d2b9	buggy:  return  new  IOSApplication(new  BulletTestCollection(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  BulletTestCollection(),  config);  return  new  IOSApplication(new  MyGdxGame(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  MyGdxGame(),  config);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  HttpServerTransport  httpServerTransport  =  cluster().getDataNodeInstance(HttpServerTransport.class);  context:  .put(super.nodeSettings(nodeOrdinal))  .put( "path.plugins ",  pluginDir.getAbsolutePath())  .put( "force.http.enabled ",  true)  .build();  }  catch  (URISyntaxException  ex)  {  throw  new  RuntimeException(ex);  }  }  public  HttpClient  httpClient()  {          HttpServerTransport  httpServerTransport  =  cluster().getDataNodeInstance(HttpServerTransport.class);          HttpServerTransport  httpServerTransport  =  internalCluster().getDataNodeInstance(HttpServerTransport.class);  return  new  HttpClient(httpServerTransport.boundAddress().publishAddress());  }  public  void  testRedirectSitePlugin()  throws  Exception  {  HttpClientResponse  response  =  httpClient().request( "/_plugin/dummy ");  assertThat(response.errorCode(),  equalTo(RestStatus.MOVED_PERMANENTLY.getStatus()));  	HttpServerTransport  httpServerTransport  =  internalCluster().getDataNodeInstance(HttpServerTransport.class);  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  this.mesh  =  new  Mesh(false,  false,  6  *  4  *  rects.size(),  0,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,  context:  Pixmap  pixmap  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/badlogic.jpg ",  Files.FileType.Internal));  texture  =  Gdx.graphics.newUnmanagedTexture(pixmap,  Texture.TextureFilter.Linear,  Texture.TextureFilter.Linear,  Texture.TextureWrap.ClampToEdge,  Texture.TextureWrap.ClampToEdge);  float  invTexWidth  =  1.0f  /  texture.getWidth();  float  invTexHeight  =  1.0f  /  texture.getHeight();  rects  =  createRects();  if  (this.mesh  ==  null)  this.mesh  =  new  Mesh(false,  false,  6  *  4  *  rects.size(),  0,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,  this.mesh  =  new  Mesh(false,  6  *  4  *  rects.size(),  0,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,   "a_position "),  new  VertexAttribute(VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoord "));  final  float[]  vertices  =  new  float[rects.size()  *  6  *  4];  int  idx  =  0;  for  (int  i  =  0;  i  <  rects.size();  i++)  {  SimpleRect  rect  =  rects.get(i);  	this.mesh  =  new  Mesh(false,  6  *  4  *  rects.size(),  0,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,  
libgdx_e09da6c5aeffa9a6585099612f501ba4c141d181	buggy:  localTransform.set(translation,  rotation,  scale);  context:  public  final  Matrix4  globalTransform  =  new  Matrix4();  public  Array<NodePart>  parts  =  new  Array<NodePart>(2);  public  Matrix4  calculateLocalTransform()  {  if  (!isAnimated)  localTransform.set(translation,  rotation,  scale);  localTransform.idt().translate(translation).rotate(rotation).scale(scale.x,  scale.y,  scale.z);  return  localTransform;  }  	localTransform.idt().translate(translation).rotate(rotation).scale(scale.x,  scale.y,  scale.z);  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  deleteByQueryRequest.queryParserName(request.param( "queryParserName "));  context:  controller.registerHandler(DELETE,   "/{index}/_query ",  this);  controller.registerHandler(DELETE,   "/{index}/{type}/_query ",  this);  }  DeleteByQueryRequest  deleteByQueryRequest  =  new  DeleteByQueryRequest(splitIndices(request.param( "index ")));  deleteByQueryRequest.listenerThreaded(false);  try  {  deleteByQueryRequest.querySource(RestActions.parseQuerySource(request));              deleteByQueryRequest.queryParserName(request.param( "queryParserName "));              deleteByQueryRequest.queryParserName(request.param( "query_parser_name "));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  deleteByQueryRequest.types(RestActions.splitTypes(typesParam));  }  deleteByQueryRequest.timeout(request.paramAsTime( "timeout ",  ShardDeleteByQueryRequest.DEFAULT_TIMEOUT));  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  	deleteByQueryRequest.queryParserName(request.param( "query_parser_name "));  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  TokenStream  ts  =  field.tokenStream(null);  context:  private  static  void  assertPrecisionStepEquals(int  expected,  IndexableField  field)  throws  IOException  {  assertNotNull(field);  assertThat(field,  instanceOf(Field.class));  assertEquals(expected,  ((Field)field).fieldType().numericPrecisionStep());          TokenStream  ts  =  field.tokenStream(null);          TokenStream  ts  =  field.tokenStream(null,  null);  assertThat(ts,  instanceOf(NumericTokenStream.class));  assertEquals(expected,  ((NumericTokenStream)ts).getPrecisionStep());  }  }  	TokenStream  ts  =  field.tokenStream(null,  null);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.Cache.CLEAR;  }  return   "indices/cache/clear/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_b9ee9157631ee3ff3e19b7745886e5c004dbe134	buggy:  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0))  {  context:  throw  new  ElasticsearchIllegalArgumentException( "Doc  values  field  data  doesn't  support  filters  [ "  +  fieldNames.name()  +   "] ");  }  if  (BINARY_INDEX_FIELD_NAMES.contains(fieldNames.indexName()))  {  assert  numericType  ==  null;  return  new  BinaryDVIndexFieldData(index,  fieldNames,  mapper.fieldDataType());  }  else  if  (NUMERIC_INDEX_FIELD_NAMES.contains(fieldNames.indexName()))  {  assert  !numericType.isFloatingPoint();  return  new  NumericDVIndexFieldData(index,  fieldNames,  mapper.fieldDataType());  }  else  if  (numericType  !=  null)  {                  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0))  {                  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta))  {  return  new  SortedNumericDVIndexFieldData(index,  fieldNames,  numericType,  mapper.fieldDataType());  }  else  {  return  new  BinaryDVNumericIndexFieldData(index,  fieldNames,  numericType,  mapper.fieldDataType());  }  }  else  {  return  new  SortedSetDVOrdinalsIndexFieldData(index,  cache,  indexSettings,  fieldNames,  breakerService,  mapper.fieldDataType());  }  	if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta))  {  
libgdx_d809dc21eea9f0e7bf66a719670824f29a1adff1	buggy:  cache.draw(batch,  parentAlpha);  context:  if  (wrap)  cache.setWrappedText(text,  x,  y,  bounds.width,  lineAlign);  else  cache.setMultiLineText(text,  x,  y,  bounds.width,  lineAlign);  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  validate();  cache.setPosition(x,  y);  cache.draw(batch,  parentAlpha);  cache.draw(batch,  color.a  *  parentAlpha);  }  public  float  getPrefWidth  ()  {  if  (wrap)  return  wrapWidth  !=  0  ?  wrapWidth  :  100;  return  bounds.width;  }  public  float  getPrefHeight  ()  {  	cache.draw(batch,  color.a  *  parentAlpha);  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "normsField ",  normsField);  context:  this.boost  =  boost;  return  this;  }  builder.startObject(MatchAllJsonQueryParser.NAME);  if  (boost  !=  -1)  {  builder.field( "boost ",  boost);  }  if  (normsField  !=  null)  {              builder.field( "normsField ",  normsField);              builder.field( "norms_field ",  normsField);  }  builder.endObject();  }  }  	builder.field( "norms_field ",  normsField);  
elasticsearch_aac05e262905c58306a21cdadfecb13f6cd774be	buggy:  newMapperService(),  new  NoneFilterCache(index,  EMPTY_SETTINGS),  new  AnalysisService(index),  null,  null,   "test ",  null);  context:  assertThat(parsedQuery,  instanceOf(MoreLikeThisQuery.class));  MoreLikeThisQuery  mltQuery  =  (MoreLikeThisQuery)  parsedQuery;  assertThat(mltQuery.getMoreLikeFields()[0],  equalTo( "name.first "));  assertThat(mltQuery.getLikeText(),  equalTo( "something "));  assertThat(mltQuery.getMinTermFrequency(),  equalTo(1));  assertThat(mltQuery.getMaxQueryTerms(),  equalTo(12));  }  private  JsonIndexQueryParser  newQueryParser()  throws  IOException  {  return  new  JsonIndexQueryParser(new  Index( "test "),  EMPTY_SETTINGS,                  newMapperService(),  new  NoneFilterCache(index,  EMPTY_SETTINGS),  new  AnalysisService(index),  null,  null,   "test ",  null);                  newMapperService(),  new  NoneFilterCache(index,  EMPTY_SETTINGS),  new  AnalysisService(index),  null,  null,  null,   "test ",  null);  }  private  MapperService  newMapperService()  throws  IOException  {  Environment  environment  =  new  Environment();  MapperService  mapperService  =  new  MapperService(index,  EMPTY_SETTINGS,  environment,  new  AnalysisService(index));  mapperService.type( "person ").parse(copyToBytesFromClasspath( "/org/elasticsearch/index/query/json/data.json "));  return  mapperService;  	newMapperService(),  new  NoneFilterCache(index,  EMPTY_SETTINGS),  new  AnalysisService(index),  null,  null,  null,   "test ",  null);  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  bigArrays.ramBytesUsed.addAndGet(-sizeInBytes());  context:  public  final  boolean  clearOnResize;  private  boolean  released  =  false;  AbstractArray(BigArrays  bigArrays,  boolean  clearOnResize)  {  this.bigArrays  =  bigArrays;  this.clearOnResize  =  clearOnResize;  }  public  final  void  close()  {          bigArrays.ramBytesUsed.addAndGet(-sizeInBytes());          bigArrays.ramBytesUsed.addAndGet(-ramBytesUsed());  assert  !released  :   "double  release ";  released  =  true;  doClose();  }  protected  abstract  void  doClose();  }  	bigArrays.ramBytesUsed.addAndGet(-ramBytesUsed());  
elasticsearch_8f9693063820fb7417c53e7fbe8b10ddcd16c422	buggy:  getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);  getRequest.operationThreaded(true);  getRequest.refresh(request.paramAsBoolean( "refresh ",  getRequest.refresh()));  getRequest.routing(request.param( "routing "));  //  order  is  important,  set  it  after  routing,  so  it  will  set  the  routing  getRequest.parent(request.param( "parent "));  getRequest.preference(request.param( "preference "));          getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));          getRequest.realtime(request.paramAsBoolean( "realtime ",  null));  getRequest.fields(Strings.EMPTY_ARRAY);  client.get(getRequest,  new  ActionListener<GetResponse>()  {  public  void  onResponse(GetResponse  response)  {  try  {  	getRequest.realtime(request.paramAsBoolean( "realtime ",  null));  
elasticsearch_ee9beda3981c4b4acb5da85779f659bb27988767	buggy:  InternalSearchRequest  internalRequest  =  new  InternalSearchRequest(shardRouting,  numberOfShards);  context:  if  (shardFailures.isEmpty())  {  ret  =  ShardSearchFailure.EMPTY_ARRAY;  }  else  {  ret  =  shardFailures.toArray(ShardSearchFailure.EMPTY_ARRAY);  }  searchCache.releaseShardFailures(shardFailures);  return  ret;  }  public  static  InternalSearchRequest  internalSearchRequest(ShardRouting  shardRouting,  int  numberOfShards,  SearchRequest  request)  {          InternalSearchRequest  internalRequest  =  new  InternalSearchRequest(shardRouting,  numberOfShards);          InternalSearchRequest  internalRequest  =  new  InternalSearchRequest(shardRouting,  numberOfShards,  request.searchType());  internalRequest.source(request.source(),  request.sourceOffset(),  request.sourceLength());  internalRequest.extraSource(request.extraSource(),  request.extraSourceOffset(),  request.extraSourceLength());  internalRequest.scroll(request.scroll());  internalRequest.timeout(request.timeout());  internalRequest.types(request.types());  return  internalRequest;  }  	InternalSearchRequest  internalRequest  =  new  InternalSearchRequest(shardRouting,  numberOfShards,  request.searchType());  
elasticsearch_8a17222ff201d64225dd6c97028e07754447249e	buggy:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  context:  public  Query  parse(QueryParseContext  parseContext)  throws  IOException,  QueryParsingException  {  XContentParser  parser  =  parseContext.parser();  float  boost  =  1.0f;  String  normsField  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;          while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {          while  (((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT  &&  token  !=  XContentParser.Token.END_ARRAY))  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token.isValue())  {  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  else  if  ( "norms_field ".equals(currentFieldName)  ||   "normsField ".equals(currentFieldName))  {  normsField  =  parseContext.indexName(parser.text());  }  else  {  	while  (((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT  &&  token  !=  XContentParser.Token.END_ARRAY))  {  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  out.writeOptionalString(writtenBy  ==  null  ?  null  :  writtenBy.name());  context:  hash  =  new  BytesRef();  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeString(name);  out.writeVLong(length);  out.writeOptionalString(checksum);  if  (out.getVersion().onOrAfter(org.elasticsearch.Version.V_1_3_0))  {              out.writeOptionalString(writtenBy  ==  null  ?  null  :  writtenBy.name());              out.writeOptionalString(writtenBy  ==  null  ?  null  :  writtenBy.toString());  }  if  (out.getVersion().onOrAfter(org.elasticsearch.Version.V_1_4_0))  {  out.writeBytesRef(hash);  }  }  	out.writeOptionalString(writtenBy  ==  null  ?  null  :  writtenBy.toString());  
libgdx_bcd137f4ff4ebb60ee9e6ef822ede0f1e825e0a5	buggy:  return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  context:  }  public  float  getAngleAroundRad  (final  float  axisX,  final  float  axisY,  final  float  axisZ)  {  final  float  d  =  Vector3.dot(this.x,  this.y,  this.z,  axisX,  axisY,  axisZ);  final  float  l2  =  Quaternion.len2(axisX  *  d,  axisY  *  d,  axisZ  *  d,  this.w);  return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(MathUtils.clamp((float)  (this.w  /  Math.sqrt(l2)),  -1f,  1f)));  }  public  float  getAngleAroundRad  (final  Vector3  axis)  {  return  getAngleAroundRad(axis.x,  axis.y,  axis.z);  }  	return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(MathUtils.clamp((float)  (this.w  /  Math.sqrt(l2)),  -1f,  1f)));  
libgdx_0163fb14195573ccdeb114d935b42bb9c4a803e1	buggy:  return  false;  context:  public  class  StagePerformanceTest  extends  GdxTest  {  public  boolean  needsGL20  ()  {  return  false;  return  true;  }  TextureRegion[]  regions;  Stage  stage;  SpriteBatch  batch;  BitmapFont  font;  Sprite[]  sprites;  boolean  useStage  =  true;  	return  true;  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  checkIndex.fixIndex(status,  codecService.codec(indexSettings.get(Engine.INDEX_CODEC,   "default ")));  context:  if  (!status.clean)  {  if  (state  ==  IndexShardState.CLOSED)  {  return;  }  if  ( "fix ".equalsIgnoreCase(checkIndexOnStartup))  {  if  (logger.isDebugEnabled())  {  }                      checkIndex.fixIndex(status,  codecService.codec(indexSettings.get(Engine.INDEX_CODEC,   "default ")));                      checkIndex.fixIndex(status);  if  (logger.isDebugEnabled())  {  }  }  else  {  if  (throwException)  {  throw  new  IndexShardException(shardId,   "index  check  failure ");  }  	checkIndex.fixIndex(status);  
elasticsearch_e5737e305804da5f09b716e66fa1d5e17bddc07e	buggy:  transportServiceAdapter.received(size);  context:  transportServiceAdapter.sent(e.getWrittenAmount());  super.writeComplete(ctx,  e);  }  ChannelBuffer  buffer  =  (ChannelBuffer)  event.getMessage();  int  size  =  buffer.getInt(buffer.readerIndex()  -  4);          transportServiceAdapter.received(size);          transportServiceAdapter.received(size  +  4);  int  markedReaderIndex  =  buffer.readerIndex();  int  expectedIndexReader  =  markedReaderIndex  +  size;  StreamInput  streamIn  =  new  ChannelBufferStreamInput(buffer);  streamIn  =  HandlesStreamInput.Cached.cached(streamIn);  long  requestId  =  buffer.readLong();  	transportServiceAdapter.received(size  +  4);  
libgdx_497df197bb0f4400447116cb011d5b432c899d80	buggy:  return  false;  context:  mesh.unbind(shader);  shader.end();  }  else  {  mesh.unbind();  }  Gdx.app.log( "TextureBindTest ",   "fps:   "  +  Gdx.graphics.getFramesPerSecond());  }  public  boolean  needsGL20()  {  return  false;  return  true;  }  }  	return  true;  
elasticsearch_16fe44c7ec802fa6143630b3c2e30976d0f557a9	buggy:  return  fetchSource(include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{include},  include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{exclude});  context:  }  public  SearchSourceBuilder  fetchSource(@Nullable  String  include,  @Nullable  String  exclude)  {          return  fetchSource(include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{include},  include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{exclude});          return  fetchSource(include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{include},  exclude  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{exclude});  }  	return  fetchSource(include  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{include},  exclude  ==  null  ?  Strings.EMPTY_ARRAY  :  new  String[]{exclude});  
elasticsearch_df39016e58a05be51bc988154d10cbb6d96f2c18	buggy:  out.append( "   ");  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  boolean  helpWanted  =  request.paramAsBoolean( "h ",  false);  if  (helpWanted)  {  Table  table  =  getTableWithHeader(request);  int[]  width  =  buildHelpWidths(table,  request,  false);  StringBuilder  out  =  new  StringBuilder();  for  (Table.Cell  cell  :  table.getHeaders())  {  pad(new  Table.Cell(cell.value),  width[0],  request,  out);                  out.append( "   ");                  out.append( "  |   ");  pad(new  Table.Cell(cell.attr.containsKey( "desc ")  ?  cell.attr.get( "desc ")  :   "not  available "),  width[1],  request,  out);  out.append( "\n ");  }  channel.sendResponse(new  StringRestResponse(RestStatus.OK,  out.toString()));  }  else  {  doRequest(request,  channel);  }  }  	out.append( "  |   ");  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (parentFieldMapper  !=  null)  {  context:  }  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  Set<String>  parentTypes  =  new  HashSet<String>(5);  parentTypes.add(parentType);  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();              if  (parentFieldMapper  !=  null)  {              if  (parentFieldMapper.active())  {  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  }  }  	if  (parentFieldMapper.active())  {  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  threadPool.shutdown();  context:  assertThat( "failed  to  wait  for  all  nodes  to  connect ",  latch.await(5,  TimeUnit.SECONDS),  equalTo(true));  serviceA.removeConnectionListener(waitForConnection);  serviceB.removeConnectionListener(waitForConnection);  }  public  void  tearDown()  throws  Exception  {  super.tearDown();  serviceA.close();  serviceB.close();          threadPool.shutdown();          terminate(threadPool);  }  public  void  testHelloWorld()  {  serviceA.registerHandler( "sayHello ",  new  BaseTransportRequestHandler<StringMessageRequest>()  {  public  StringMessageRequest  newInstance()  {  return  new  StringMessageRequest();  	terminate(threadPool);  
libgdx_2a4ca185953f1a705d1e64103004c79bbe8fc89f	buggy:  TouchEvent  event  =  input.usedTouchEvents.add();  context:  input.touchX[pointerId]  =  x;  input.touchY[pointerId]  =  y;  }  break;  }  }  private  void  postTouchEvent  (AndroidInput  input,  int  type,  int  x,  int  y,  int  pointer)  {  long  timeStamp  =  System.nanoTime();  synchronized  (input)  {  TouchEvent  event  =  input.usedTouchEvents.add();  TouchEvent  event  =  input.usedTouchEvents.obtain();  event.timeStamp  =  timeStamp;  event.pointer  =  pointer;  event.x  =  x;  event.y  =  y;  event.type  =  type;  input.touchEvents.add(event);  }  }  	TouchEvent  event  =  input.usedTouchEvents.obtain();  
elasticsearch_2d94087f90f42cf3774a691640f1e7a527f14b0b	buggy:  engine.optimize(new  Engine.Optimize().maxNumSegments(-1).waitForMerge(false));  context:  }  catch  (Exception  e)  {  }  }  }  private  class  EngineOptimizer  implements  Runnable  {  try  {                  engine.optimize(new  Engine.Optimize().maxNumSegments(-1).waitForMerge(false));                  engine.optimize(new  Engine.Optimize().maxNumSegments(-1).waitForMerge(false).flush(false).refresh(false));  }  catch  (EngineClosedException  e)  {  }  catch  (OptimizeFailedEngineException  e)  {  if  (e.getCause()  instanceof  InterruptedException)  {  }  else  if  (e.getCause()  instanceof  ClosedByInterruptException)  {  }  else  if  (e.getCause()  instanceof  ThreadInterruptedException)  {  	engine.optimize(new  Engine.Optimize().maxNumSegments(-1).waitForMerge(false).flush(false).refresh(false));  
elasticsearch_e8b261c165495724573137e1705af385a51d9ffe	buggy:  result  =  t.getCause();  context:  return  result;  }  if  (result.getCause()  ==  result)  {  return  result;  }  if  (counter++  >  10)  {  return  result;  }              result  =  t.getCause();              result  =  result.getCause();  }  return  result;  }  public  static  String  detailedMessage(Throwable  t)  {  return  detailedMessage(t,  false,  0);  }  	result  =  result.getCause();  
elasticsearch_14237317fce4e365aa2e0a88ef59bafd43e73e4e	buggy:  return  documentMapper.sourceMapper().value(sourceField);  context:  searchHit.explanation(context.searcher().explain(context.query(),  docId));  }  catch  (IOException  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  explain  doc  [ "  +  docId  +   "] ",  e);  }  }  }  private  byte[]  extractSource(Document  doc,  DocumentMapper  documentMapper)  {  Fieldable  sourceField  =  doc.getFieldable(SourceFieldMapper.NAME);  if  (sourceField  !=  null)  {              return  documentMapper.sourceMapper().value(sourceField);              return  documentMapper.sourceMapper().nativeValue(sourceField);  }  return  null;  }  private  Uid  extractUid(SearchContext  context,  Document  doc)  {  String  sUid  =  doc.get(UidFieldMapper.NAME);  if  (sUid  !=  null)  {  	return  documentMapper.sourceMapper().nativeValue(sourceField);  
elasticsearch_2c67ba8f1a99336c52e1fc1e9b713471055cf508	buggy:  if  (fieldMappingMetaDataEntry.getValue()  ==  FieldMappingMetaData.NULL)  {  context:  private  boolean  isFieldMappingMissingField(ImmutableMap<String,  ImmutableMap<String,  ImmutableMap<String,  FieldMappingMetaData>>>  mappingsByIndex)  throws  IOException  {  if  (mappingsByIndex.size()  !=  1)  {  return  false;  }  for  (ImmutableMap<String,  ImmutableMap<String,  FieldMappingMetaData>>  value  :  mappingsByIndex.values())  {  for  (ImmutableMap<String,  FieldMappingMetaData>  fieldValue  :  value.values())  {  for  (Map.Entry<String,  FieldMappingMetaData>  fieldMappingMetaDataEntry  :  fieldValue.entrySet())  {                      if  (fieldMappingMetaDataEntry.getValue()  ==  FieldMappingMetaData.NULL)  {                      if  (fieldMappingMetaDataEntry.getValue().isNull())  {  return  true;  }  }  }  }  return  false;  }  }  	if  (fieldMappingMetaDataEntry.getValue().isNull())  {  
libgdx_1ef960314fab2b2748d0a4fa5c40712d0859aa62	buggy:  while(  decoder.readSamples(  decoder.handle,  stereoSamples,  stereoSamples.capacity()  )  >  0  )  context:  Mpg123Decoder  decoder  =  new  Mpg123Decoder(   "data/threeofaperfectpair.mp3 ");  JoglAudioDevice  device  =  new  JoglAudioDevice(  true  );  ShortBuffer  stereoSamples  =  AudioTools.allocateShortBuffer(  1024,  decoder.getNumChannels()  );  ShortBuffer  monoSamples  =  AudioTools.allocateShortBuffer(  1024,  1  );  FloatBuffer  floatSamples  =  AudioTools.allocateFloatBuffer(  1024,  1  );  float[]  samples  =  new  float[1024];  while(  decoder.readSamples(  decoder.handle,  stereoSamples,  stereoSamples.capacity()  )  >  0  )  while(  decoder.readSamples(  stereoSamples  )  >  0  )  {  AudioTools.convertToMono(  stereoSamples,  monoSamples,  stereoSamples.capacity()  );  AudioTools.convertToFloat(  monoSamples,  floatSamples,  1024  );  floatSamples.position(0);  floatSamples.get(samples);  device.writeSamples(samples,  0,  monoSamples.capacity());  }  	while(  decoder.readSamples(  stereoSamples  )  >  0  )  
libgdx_3b56a1234ba4895fd12b6851f69be46e69cfa5a3	buggy:  tick((lastTick  -  t)  *  nano2seconds);  context:  public  PerformanceCounter  add(final  String  name)  {  PerformanceCounter  result  =  new  PerformanceCounter(name);  counters.add(result);  return  result;  }  public  void  tick()  {  final  long  t  =  System.nanoTime();  if  (lastTick  >  0L)  tick((lastTick  -  t)  *  nano2seconds);  tick((t  -  lastTick)  *  nano2seconds);  lastTick  =  t;  }  public  void  tick(final  float  deltaTime)  {  for  (int  i  =  0;  i  <  counters.size;  i++)  counters.get(i).tick(deltaTime);  }  	tick((t  -  lastTick)  *  nano2seconds);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  error  =  new  AtomicReference<Throwable>();  context:  .setSource(jsonBuilder().startObject().field( "query ",  matchAllQuery()).endObject())  .execute().actionGet();  }  client.prepareIndex( "test ",   "type ",   "1 ")  .setSource(jsonBuilder().startObject().field( "field ",   "a "))  .execute().actionGet();  final  AtomicBoolean  run  =  new  AtomicBoolean(true);  final  CountDownLatch  done  =  new  CountDownLatch(1);          final  AtomicReference<Throwable>  error  =  new  AtomicReference<Throwable>();          final  AtomicReference<Throwable>  error  =  new  AtomicReference<>();  Runnable  r  =  new  Runnable()  {  public  void  run()  {  try  {  XContentBuilder  doc  =  jsonBuilder().startObject().field( "field ",   "a ").endObject();  while  (run.get())  {  NodesInfoResponse  nodesInfoResponse  =  client.admin().cluster().prepareNodesInfo()  .execute().actionGet();  	final  AtomicReference<Throwable>  error  =  new  AtomicReference<>();  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  queryResults.values());  context:  releaseIrrelevantSearchContexts(queryResults,  docIdsToLoad);  searchCache.releaseQueryResults(queryResults);  searchCache.releaseFetchResults(fetchResults);  }  }  private  void  innerFinishHim()  throws  Exception  {  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  queryResults.values());                  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  queryResults.values(),  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  queryResults.values(),  null);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  public  void  execute(DiscoveryNode  node,  final  Request  request,  final  ActionListener<Response>  listener)  {  transportService.sendRequest(node,  action.name(),  request,  action.options(),  new  BaseTransportResponseHandler<Response>()  {  public  Response  newInstance()  {  return  action.newResponse();  }  public  String  executor()  {  if  (request.listenerThreaded())  {                      return  ThreadPool.Names.CACHED;                      return  ThreadPool.Names.GENERIC;  }  return  ThreadPool.Names.SAME;  }  public  void  handleResponse(Response  response)  {  listener.onResponse(response);  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_d570d588a8fdfd7feca537d97f1455c6a5a52220	buggy:  final  int  numNodes  =  cluster().dataNodes();  context:  protected  int  numberOfReplicas()  {  return  0;  }  public  void  testSimpleStats()  throws  Exception  {  client().admin().indices().prepareStats().clear().execute().actionGet();          final  int  numNodes  =  cluster().dataNodes();          final  int  numNodes  =  immutableCluster().dataNodes();  assertThat(numNodes,  greaterThanOrEqualTo(2));  final  int  shardsIdx1  =  randomIntBetween(1,  10);  //  we  make  sure  each  node  gets  at  least  a  single  shard...  final  int  shardsIdx2  =  Math.max(numNodes  -  shardsIdx1,  randomIntBetween(1,  10));  final  int  totalShards  =  shardsIdx1  +  shardsIdx2;  assertThat(numNodes,  lessThanOrEqualTo(totalShards));  assertAcked(prepareCreate( "test1 ").setSettings(ImmutableSettings.builder()  .put(SETTING_NUMBER_OF_SHARDS,  shardsIdx1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)));  	final  int  numNodes  =  immutableCluster().dataNodes();  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  if  (getClass()  !=  o.getClass())  context:  }  public  String  toString(String  field)  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "function  score  ( ").append(subQuery.toString(field)).append( ",function= ").append(function).append(')');  sb.append(ToStringUtils.boost(getBoost()));  return  sb.toString();  }  public  boolean  equals(Object  o)  {          if  (getClass()  !=  o.getClass())          if  (o  ==  null  ||  getClass()  !=  o.getClass())  return  false;  FunctionScoreQuery  other  =  (FunctionScoreQuery)  o;  return  this.getBoost()  ==  other.getBoost()  &&  this.subQuery.equals(other.subQuery)  &&  this.function.equals(other.function)  &&  this.maxBoost  ==  other.maxBoost;  }  public  int  hashCode()  {  return  subQuery.hashCode()  +  31  *  function.hashCode()  ^  Float.floatToIntBits(getBoost());  	if  (o  ==  null  ||  getClass()  !=  o.getClass())  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InputStream>  dicStreams  =  new  ArrayList<InputStream>(dicFiles.length);  context:  boolean  ignoreCase  =  nodeSettings.getAsBoolean( "ignore_case ",  defaultIgnoreCase);  boolean  strictAffixParsing  =  nodeSettings.getAsBoolean( "strict_affix_parsing ",  defaultStrictAffixParsing);  File[]  affixFiles  =  dicDir.listFiles(AFFIX_FILE_FILTER);  if  (affixFiles.length  !=  1)  {  throw  new  ElasticsearchException(String.format(Locale.ROOT,   "Missing  affix  file  for  hunspell  dictionary  [%s] ",  locale));  }  InputStream  affixStream  =  null;  File[]  dicFiles  =  dicDir.listFiles(DIC_FILE_FILTER);          List<InputStream>  dicStreams  =  new  ArrayList<InputStream>(dicFiles.length);          List<InputStream>  dicStreams  =  new  ArrayList<>(dicFiles.length);  try  {  for  (int  i  =  0;  i  <  dicFiles.length;  i++)  {  dicStreams.add(new  FileInputStream(dicFiles[i]));  }  affixStream  =  new  FileInputStream(affixFiles[0]);  	List<InputStream>  dicStreams  =  new  ArrayList<>(dicFiles.length);  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  return  newPixmap(file.readFile());  context:  throw  new  GdxRuntimeException(   "Couldn't  load  Pixmap  from  InputStream ");  return  new  AndroidPixmap(bitmap);  }  public  Pixmap  newPixmap(FileHandle  file)  {  return  newPixmap(file.readFile());  return  newPixmap(file.read());  }  public  Pixmap  newPixmap(Object  nativePixmap)  {  return  new  AndroidPixmap((Bitmap)  nativePixmap);  	return  newPixmap(file.read());  
elasticsearch_7ed68a5c30e1a94d1938aef513e343f508eadf15	buggy:  return  ThreadPool.Names.MANAGEMENT;  context:  public  TransportGatewaySnapshotAction(Settings  settings,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }  protected  String  executor()  {          return  ThreadPool.Names.MANAGEMENT;          return  ThreadPool.Names.SNAPSHOT;  }  protected  String  transportAction()  {  return  GatewaySnapshotAction.NAME;  }  	return  ThreadPool.Names.SNAPSHOT;  
libgdx_bebea2bfef0963802073645fd78a72cadc495a4c	buggy:  emitter.getEmission().setHigh(particleCount  /  emitter.getLife().getHighMax());  context:  else  if  (keycode  ==  Input.Keys.KEYCODE_DPAD_DOWN)  particleCount  -=  5;  else  if  (keycode  ==  Input.Keys.KEYCODE_SPACE)  {  emitterIndex  =  (emitterIndex  +  1)  %  emitters.size();  emitter  =  emitters.get(emitterIndex);  particleCount  =  (int)(emitter.getEmission().getHighMax()  *  emitter.getLife().getHighMax());  }  else  return  false;  particleCount  =  Math.max(0,  particleCount);  if  (particleCount  >  emitter.getMaxParticleCount())  emitter.setMaxParticleCount(particleCount  *  2);  emitter.getEmission().setHigh(particleCount  /  emitter.getLife().getHighMax());  emitter.getEmission().setHigh(particleCount  /  emitter.getLife().getHighMax()  *  1000);  effect.getEmitters().clear();  effect.getEmitters().add(emitter);  return  false;  }  };  }  public  void  render  ()  {  	emitter.getEmission().setHigh(particleCount  /  emitter.getLife().getHighMax()  *  1000);  
elasticsearch_7d8726a5e81ba5c3d42182ffdb6b1d413a025b9f	buggy:  routingTable  =  strategy.applyFailedShards(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING)).routingTable();  context:  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).unassigned(),  equalTo(false));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).state(),  equalTo(INITIALIZING));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).currentNodeId(),  equalTo( "node1 "));  RoutingNodes  routingNodes  =  clusterState.routingNodes();  prevRoutingTable  =  routingTable;          routingTable  =  strategy.applyFailedShards(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING)).routingTable();          routingTable  =  strategy.applyFailedShard(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING).get(0)).routingTable();  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  assertThat(prevRoutingTable  !=  routingTable,  equalTo(true));  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).currentNodeId(),  nullValue());  	routingTable  =  strategy.applyFailedShard(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING).get(0)).routingTable();  
libgdx_fba1418dce932b1a33454b9024cfb4a2a79d5243	buggy:  new  LwjglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  context:  public  void  dispose  ()  {  }  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  new  LwjglApplication(new  SkeletonModelViewer( "data/models/robot-mesh.xml ",   "data/models/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  }  }  	new  LwjglApplication(new  SkeletonModelViewer( "data/models/robot-mesh.xml ",   "data/models/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  
elasticsearch_9addac830089e48bdcd77a5cc972d85808d863e5	buggy:  public  abstract  Explanation  explainScore(int  docId,  Explanation  subQueryExpl);  context:  public  abstract  class  ScoreFunction  {  private  final  CombineFunction  scoreCombiner;  public  abstract  void  setNextReader(AtomicReaderContext  context);  public  abstract  double  score(int  docId,  float  subQueryScore);      public  abstract  Explanation  explainScore(int  docId,  Explanation  subQueryExpl);      public  abstract  Explanation  explainScore(int  docId,  float  subQueryScore);  public  CombineFunction  getDefaultScoreCombiner()  {  return  scoreCombiner;  }  protected  ScoreFunction(CombineFunction  scoreCombiner)  {  this.scoreCombiner  =  scoreCombiner;  }  	public  abstract  Explanation  explainScore(int  docId,  float  subQueryScore);  
libgdx_52324f0400a8f4686f8982be6f4cf3e952f9485f	buggy:  String[]  lines  =  console.getItems().toArray();  context:  public  boolean  accelerometerMoved  (Controller  controller,  int  accelerometerIndex,  Vector3  value)  {  return  false;  }  });  }  void  print  (String  message)  {  String[]  lines  =  console.getItems().toArray();  String[]  lines  =  console.getItems().toArray(String.class);  String[]  newLines  =  new  String[lines.length  +  1];  System.arraycopy(lines,  0,  newLines,  0,  lines.length);  newLines[newLines.length  -  1]  =  message;  console.setItems(newLines);  scrollPane.invalidate();  scrollPane.validate();  scrollPane.setScrollPercentY(1.0f);  }  	String[]  lines  =  console.getItems().toArray(String.class);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  assertThat(healthResponse.isTimedOut(),  equalTo(false));  assertThat(healthResponse.getIndices().get( "test ").getActiveShards(),  equalTo(10));  client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "index.number_of_replicas ",  0)).execute().actionGet();  healthResponse  =  client().admin().cluster().prepareHealth( "test ").setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();  assertThat(healthResponse.isTimedOut(),  equalTo(false));  assertThat(healthResponse.getIndices().get( "test ").getActiveShards(),  equalTo(5));  try  {  client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "index.refresh_interval ",   " ")).execute().actionGet();              assert  false;              fail();  }  catch  (ElasticsearchIllegalArgumentException  ex)  {  }  }  }  	fail();  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  ExecutableScript  script  =  scriptService.executable(request.scriptLang,  request.script,  request.scriptParams);  context:  }  if  (indexRequest.parent()  !=  null)  {  parent  =  indexRequest.parent();  }  XContentHelper.update(updatedSourceAsMap,  indexRequest.sourceAsMap());  }  else  {  Map<String,  Object>  ctx  =  new  HashMap<>(2);  ctx.put( "_source ",  sourceAndContent.v2());  try  {                  ExecutableScript  script  =  scriptService.executable(request.scriptLang,  request.script,  request.scriptParams);                  ExecutableScript  script  =  scriptService.executable(request.scriptLang,  request.script,  request.scriptType,  request.scriptParams);  script.setNextVar( "ctx ",  ctx);  script.run();  ctx  =  (Map<String,  Object>)  script.unwrap(ctx);  }  catch  (Exception  e)  {  throw  new  ElasticsearchIllegalArgumentException( "failed  to  execute  script ",  e);  }  	ExecutableScript  script  =  scriptService.executable(request.scriptLang,  request.script,  request.scriptType,  request.scriptParams);  
elasticsearch_9b4bf4379a1e17556ed5155849c1bc4cbde7cc5f	buggy:  masterNode  =  null;  context:  public  void  testNodeNotReachableFromMaster()  throws  Exception  {  startCluster(3);  String  masterNode  =  internalCluster().getMasterName();  String  nonMasterNode  =  null;  while  (nonMasterNode  ==  null)  {  nonMasterNode  =  randomFrom(internalCluster().getNodeNames());  if  (nonMasterNode.equals(masterNode))  {                  masterNode  =  null;                  nonMasterNode  =  null;  }  }  MockTransportService  masterTransportService  =  (MockTransportService)  internalCluster().getInstance(TransportService.class,  masterNode);  if  (randomBoolean())  {  masterTransportService.addUnresponsiveRule(internalCluster().getInstance(ClusterService.class,  nonMasterNode).localNode());  }  else  {  	nonMasterNode  =  null;  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  return  parseContext.cacheFilter(filter);  context:  parser.nextToken();  Filter  filter;  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(type);  if  (documentMapper  ==  null)  {  filter  =  new  TermFilter(new  Term(TypeFieldMapper.NAME,  type));  }  else  {  filter  =  documentMapper.typeFilter();  }          return  parseContext.cacheFilter(filter);          return  parseContext.cacheFilter(filter,  null);  }  }  	return  parseContext.cacheFilter(filter,  null);  
libgdx_4279401a12b90b72315e40f6a339619cca70b067	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (char[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (char[]  array,  int  offset,  int  length)  {  char[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length  ;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  char  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length  ;  
libgdx_ae45ffe4ebe41482453af5e1245f4a93f57ae3b4	buggy:  font  =  new  BitmapFont();  context:  public  boolean  needsGL20  ()  {  return  false;  }  BitmapFont  font;  SpriteBatch  batch;  public  void  create  ()  {  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  batch  =  new  SpriteBatch();  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  font.drawMultiLine(batch,   "accel:  [ "  +  Gdx.input.getAccelerometerX()  +   ", "  +  Gdx.input.getAccelerometerY()  +   ", "  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);  context:  public  class  PreBuiltCharFilterFactoryFactory  implements  CharFilterFactoryFactory  {  private  final  CharFilterFactory  charFilterFactory;  public  PreBuiltCharFilterFactoryFactory(CharFilterFactory  charFilterFactory)  {  this.charFilterFactory  =  charFilterFactory;  }  public  CharFilterFactory  create(String  name,  Settings  settings)  {          Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);          Version  indexVersion  =  Version.indexCreated(settings);  if  (!Version.CURRENT.equals(indexVersion))  {  PreBuiltCharFilters  preBuiltCharFilters  =  PreBuiltCharFilters.getOrDefault(name,  null);  if  (preBuiltCharFilters  !=  null)  {  return  preBuiltCharFilters.getCharFilterFactory(indexVersion);  }  }  return  charFilterFactory;  	Version  indexVersion  =  Version.indexCreated(settings);  
elasticsearch_3b9da384c3e8f375ee604f7d1ff9932a8046623b	buggy:  return  new  CustomIntegerNumericField(this,  context.source().length);  context:  }  return  false;  }  if  (!enabled)  {  return  null;  }          return  new  CustomIntegerNumericField(this,  context.source().length);          return  new  CustomIntegerNumericField(this,  context.sourceLength());  }  if  (enabled  ==  Defaults.ENABLED  &&  store  ==  Defaults.STORE)  {  return  builder;  }  builder.startObject(contentType());  	return  new  CustomIntegerNumericField(this,  context.sourceLength());  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  LongArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  LongArrayAtomicFieldData.WithOrdinals(  values.toArray(new  long[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  LongValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_43a5cbe9bee92898056db7ba0db2d548514a16bd	buggy:  RecoveryStatus  recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard.shardId());  context:  if  (currentRoutingEntry.initializing()  &&  shardRouting.initializing()  &&  !currentRoutingEntry.equals(shardRouting))  {  recoveryTarget.cancelRecovery(indexShard);  indexService.removeShard(shardRouting.id(),   "removing  shard  (different  instance  of  it  allocated  on  this  node) ");  }  else  if  (isPeerRecovery(shardRouting))  {                      RecoveryStatus  recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard.shardId());                      RecoveryStatus  recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard);  if  (recoveryStatus  !=  null  &&  recoveryStatus.stage()  !=  RecoveryState.Stage.DONE)  {  DiscoveryNode  sourceNode  =  findSourceNodeForPeerRecovery(routingTable,  nodes,  shardRouting);  if  (!recoveryStatus.sourceNode().equals(sourceNode))  {  recoveryTarget.cancelRecovery(indexShard);  indexService.removeShard(shardRouting.id(),   "removing  shard  (recovery  source  node  changed) ");  }  	RecoveryStatus  recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard);  
libgdx_c966a7d92ca4c1b2bccb30958b51de6bc05c5361	buggy:  public  void  setIcon  (Pixmap  pixmap)  {  context:  while  (parent  !=  null)  {  if  (parent  instanceof  JFrame)  {  ((JFrame)parent).setTitle(title);  return;  }  parent  =  parent.getParent();  }  }  public  void  setIcon  (Pixmap  pixmap)  {  public  void  setIcon  (Pixmap[]  pixmap)  {  }  public  DisplayMode  getDesktopDisplayMode  ()  {  return  desktopMode;  }  	public  void  setIcon  (Pixmap[]  pixmap)  {  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  Engine.Searcher  searcher  =  shardToPurge.acquireSearcher();  context:  }  }  }  return  shardsToPurge;  }  }  private  void  purgeShards(List<IndexShard>  shardsToPurge)  {  for  (IndexShard  shardToPurge  :  shardsToPurge)  {  Query  query  =  NumericRangeQuery.newLongRange(TTLFieldMapper.NAME,  null,  System.currentTimeMillis(),  false,  true);              Engine.Searcher  searcher  =  shardToPurge.acquireSearcher();              Engine.Searcher  searcher  =  shardToPurge.acquireSearcher( "indices_ttl ");  try  {  ExpiredDocsCollector  expiredDocsCollector  =  new  ExpiredDocsCollector(shardToPurge.routingEntry().index());  searcher.searcher().search(query,  expiredDocsCollector);  List<DocToPurge>  docsToPurge  =  expiredDocsCollector.getDocsToPurge();  BulkRequestBuilder  bulkRequest  =  client.prepareBulk();  for  (DocToPurge  docToPurge  :  docsToPurge)  {  bulkRequest.add(new  DeleteRequest().index(shardToPurge.routingEntry().index()).type(docToPurge.type).id(docToPurge.id).version(docToPurge.version).routing(docToPurge.routing));  	Engine.Searcher  searcher  =  shardToPurge.acquireSearcher( "indices_ttl ");  
elasticsearch_bc0909b2325edb97ccb7254ce956469e3d678920	buggy:  serverTransport.dispatchRequest(new  NettyHttpRequest(request),  new  NettyHttpChannel(serverTransport,  e.getChannel(),  request));  context:  public  HttpRequestHandler(NettyHttpServerTransport  serverTransport)  {  this.serverTransport  =  serverTransport;  }  public  void  messageReceived(ChannelHandlerContext  ctx,  MessageEvent  e)  throws  Exception  {  HttpRequest  request  =  (HttpRequest)  e.getMessage();          serverTransport.dispatchRequest(new  NettyHttpRequest(request),  new  NettyHttpChannel(serverTransport,  e.getChannel(),  request));          serverTransport.dispatchRequest(new  NettyHttpRequest(request,  e.getChannel()),  new  NettyHttpChannel(serverTransport,  e.getChannel(),  request));  super.messageReceived(ctx,  e);  }  public  void  exceptionCaught(ChannelHandlerContext  ctx,  ExceptionEvent  e)  throws  Exception  {  serverTransport.exceptionCaught(ctx,  e);  }  }  	serverTransport.dispatchRequest(new  NettyHttpRequest(request,  e.getChannel()),  new  NettyHttpChannel(serverTransport,  e.getChannel(),  request));  
elasticsearch_54437c1bd3125c1e5cddbd1cad4a26fca03c002b	buggy:  return  new  ParsedQuery(query,  parseContext.copyNamedFilters());  context:  public  Query  parseInnerQuery(XContentParser  parser)  throws  IOException  {  QueryParseContext  context  =  cache.get().get();  context.reset(parser);  return  context.parseInnerQuery();  }  private  ParsedQuery  parse(QueryParseContext  parseContext,  XContentParser  parser)  throws  IOException,  QueryParsingException  {  parseContext.reset(parser);  Query  query  =  parseContext.parseInnerQuery();          return  new  ParsedQuery(query,  parseContext.copyNamedFilters());          return  new  ParsedQuery(query,  parseContext.copyNamedFilters(),  parseContext.copyScopePhases());  }  private  void  add(Map<String,  XContentFilterParser>  map,  XContentFilterParser  filterParser)  {  for  (String  name  :  filterParser.names())  {  map.put(name.intern(),  filterParser);  }  }  	return  new  ParsedQuery(query,  parseContext.copyNamedFilters(),  parseContext.copyScopePhases());  
elasticsearch_5d781961a07368ae458126e4fad0a8db566637da	buggy:  assertThat(indicesStatusResponse.index( "test ").docs().numDocs(),  equalTo(1));  context:  OptimizeResponse  optimizeResponse  =  client.admin().indices().optimize(optimizeRequest( "test ")).actionGet();  assertThat(optimizeResponse.successfulShards(),  equalTo(5));  assertThat(optimizeResponse.failedShards(),  equalTo(5));  //  5  are  not  active,  since  we  started  just  one  server  IndicesStatusResponse  indicesStatusResponse  =  client.admin().indices().status(indicesStatus()).actionGet();  assertThat(indicesStatusResponse.successfulShards(),  equalTo(5));  assertThat(indicesStatusResponse.failedShards(),  equalTo(5));  //  5  are  not  active,  since  we  started  just  one  server  assertThat(indicesStatusResponse.indices().size(),  equalTo(1));  assertThat(indicesStatusResponse.index( "test ").shards().size(),  equalTo(5));  //  5  index  shards  (1  with  1  backup)          assertThat(indicesStatusResponse.index( "test ").docs().numDocs(),  equalTo(1));          assertThat(indicesStatusResponse.index( "test ").docs().numDocs(),  equalTo(1l));  GetResponse  getResult;  for  (int  i  =  0;  i  <  5;  i++)  {  getResult  =  client.get(getRequest( "test ").type( "type1 ").id( "1 ").threadedOperation(false)).actionGet();  assertThat( "cycle  # "  +  i,  getResult.source(),  equalTo(source( "1 ",   "test ")));  getResult  =  client.get(getRequest( "test ").type( "type1 ").id( "1 ").threadedOperation(true)).actionGet();  assertThat( "cycle  # "  +  i,  getResult.source(),  equalTo(source( "1 ",   "test ")));  	assertThat(indicesStatusResponse.index( "test ").docs().numDocs(),  equalTo(1l));  
libgdx_7735e0d68d070b9ef45b1b1a45f72f859b32bb95	buggy:  lineEnd  =  nextStart;  //  If  no  characters  to  break,  show  all.  context:  }  int  lineEnd  =  start  +  font.computeVisibleGlyphs(str,  start,  newLine,  wrapWidth);  int  nextStart  =  lineEnd  +  1;  if  (lineEnd  <  newLine)  {  while  (lineEnd  >  start)  {  if  (BitmapFont.isWhitespace(str.charAt(lineEnd)))  break;  lineEnd--;  }  if  (lineEnd  ==  start)  lineEnd  =  nextStart;  //  If  no  characters  to  break,  show  all.  lineEnd  =  nextStart  -  1;  //  If  no  characters  to  break,  show  all.  else  {  nextStart  =  lineEnd;  while  (lineEnd  >  start)  {  if  (!BitmapFont.isWhitespace(str.charAt(lineEnd  -  1)))  break;  lineEnd--;  }  }  	lineEnd  =  nextStart  -  1;  //  If  no  characters  to  break,  show  all.  
elasticsearch_383945416866849139755c6761ad162faaadcbe0	buggy:  final  IntArray  hashes  =  BigArrays.newIntArray(1L  +  valueCount);  context:  final  SortedSetDocValues  values  =  getValuesNoException(reader,  field);  return  new  SortedSetValues(reader,  field,  values);  }  public  org.elasticsearch.index.fielddata.BytesValues.WithOrdinals  getHashedBytesValues()  {  final  SortedSetDocValues  values  =  getValuesNoException(reader,  field);  if  (hashes  ==  null)  {  synchronized  (this)  {  if  (hashes  ==  null)  {  final  long  valueCount  =  values.getValueCount();                      final  IntArray  hashes  =  BigArrays.newIntArray(1L  +  valueCount);                      final  IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(1L  +  valueCount);  BytesRef  scratch  =  new  BytesRef(16);  hashes.set(0,  scratch.hashCode());  for  (long  i  =  0;  i  <  valueCount;  ++i)  {  values.lookupOrd(i,  scratch);  hashes.set(1L  +  i,  scratch.hashCode());  }  this.hashes  =  hashes;  }  	final  IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(1L  +  valueCount);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  public  TransportClusterStateAction(Settings  settings,  TransportService  transportService,  ClusterService  clusterService,  ThreadPool  threadPool,  ClusterName  clusterName)  {  super(settings,  transportService,  clusterService,  threadPool);  this.clusterName  =  clusterName;  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return  ClusterStateAction.NAME;  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();  context:  public  class  GlobalTests  extends  ElasticsearchIntegrationTest  {  int  numDocs;  public  void  init()  throws  Exception  {  createIndex( "idx ");  createIndex( "idx2 ");          List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();          List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  numDocs  =  randomIntBetween(3,  20);  for  (int  i  =  0;  i  <  numDocs  /  2;  i++)  {  builders.add(client().prepareIndex( "idx ",   "type ",   " "+i+1).setSource(jsonBuilder()  .startObject()  .field( "value ",  i  +  1)  .field( "tag ",   "tag1 ")  .endObject()));  }  	List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  siBytes  =  new  BytesStreamInput(data);  context:  }  }  return  index;  }  private  MetaData  readMetaData(byte[]  data)  throws  IOException  {  XContentParser  parser  =  null;  try  {  if  (LZF.isCompressed(data))  {                  BytesStreamInput  siBytes  =  new  BytesStreamInput(data);                  BytesStreamInput  siBytes  =  new  BytesStreamInput(data,  false);  LZFStreamInput  siLzf  =  CachedStreamInput.cachedLzf(siBytes);  parser  =  XContentFactory.xContent(XContentType.JSON).createParser(siLzf);  }  else  {  parser  =  XContentFactory.xContent(XContentType.JSON).createParser(data);  }  return  MetaData.Builder.fromXContent(parser);  }  finally  {  if  (parser  !=  null)  {  	BytesStreamInput  siBytes  =  new  BytesStreamInput(data,  false);  
libgdx_eb314d8647757b263a405d5eacfcece01ba2ebc3	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (boolean[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (boolean[]  array,  int  offset,  int  length)  {  boolean[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  boolean  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length;  
libgdx_c9506ebf0aead4eb2a86a0bea1d5b7823056380e	buggy:  Runtime.getRuntime().exec(sdkLocation  +   "tools/android  sdk ");  context:  return;  }  if  (modules.contains(ProjectType.ANDROID))  {  if  (!GdxSetup.isSdkUpToDate(sdkLocation))  {  try  {  //give  them  a  poke  in  the  right  direction  if  (System.getProperty( "os.name ").contains( "Windows "))  {  String  replaced  =  sdkLocation.replace( "\\ ",   "\\\\ ");  Runtime.getRuntime().exec( "\ " "  +  replaced  +   "\\SDK  Manager.exe\ " ");  }  else  {  Runtime.getRuntime().exec(sdkLocation  +   "tools/android  sdk ");  Runtime.getRuntime().exec( "\ " "  +  sdkLocation  +   "tools/android  sdk\ " ");  }  }  catch  (IOException  e)  {  e.printStackTrace();  }  return;  }  }  	Runtime.getRuntime().exec( "\ " "  +  sdkLocation  +   "tools/android  sdk\ " ");  
libgdx_05a27f1a3b9c6ef471d9ecbf733955dacffb5c75	buggy:  initialize(new  SuperJumper(),  false);  context:  public  class  SuperJumperAndroid  extends  AndroidApplication  {  public  void  onCreate  (Bundle  savedInstanceState)  {  super.onCreate(savedInstanceState);  initialize(new  SuperJumper(),  false);  initialize(new  SuperJumper());  }  }  	initialize(new  SuperJumper());  
libgdx_7b41ab127c0b80c9ce3bf1cb4cd7ca56c2d9bdcd	buggy:  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_4444  );  context:  return  (int)(Math.ceil(width[0]));  }  public  Pixmap  getGlyphBitmap(char  character)  {  Rect  rect  =  new  Rect();  paint.getTextBounds(   " "  +  character,  0,  1,  rect  );  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_4444  );  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_8888  );  Canvas  g  =  new  Canvas(  bitmap  );  paint.setColor(0x00000000);  paint.setStyle(Style.FILL);  g.drawRect(  new  Rect(  0,  0,  rect.width()  +  5,  getLineHeight()),  paint);  paint.setColor(0xFFFFFFFF);  g.drawText(   " "  +  character,  0,  -metrics.ascent,  paint  );  return  new  AndroidPixmap(  bitmap  );  	Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_8888  );  
libgdx_ebc9a305a1015728cfb90fd73e05bc6c58748571	buggy:  btAxisSweep3  broadphase  =  new  btAxisSweep3(Vector3.tmp.set(-1000,  -1000,  -1000),  Vector3.tmp2.set(1000,  1000,  1000),  1024);  context:  Texture  texture;  Mesh  mesh;  Model  model;  ModelInstance  instance;  Matrix4  tmpM  =  new  Matrix4();  public  BulletWorld  createWorld  ()  {  btDefaultCollisionConfiguration  collisionConfiguration  =  new  btSoftBodyRigidBodyCollisionConfiguration();  btCollisionDispatcher  dispatcher  =  new  btCollisionDispatcher(collisionConfiguration);  btAxisSweep3  broadphase  =  new  btAxisSweep3(Vector3.tmp.set(-1000,  -1000,  -1000),  Vector3.tmp2.set(1000,  1000,  1000),  1024);  btAxisSweep3  broadphase  =  new  btAxisSweep3(tmpV1.set(-1000,  -1000,  -1000),  tmpV2.set(1000,  1000,  1000),  1024);  btSequentialImpulseConstraintSolver  solver  =  new  btSequentialImpulseConstraintSolver();  btSoftRigidDynamicsWorld  dynamicsWorld  =  new  btSoftRigidDynamicsWorld(dispatcher,  broadphase,  solver,  collisionConfiguration);  worldInfo  =  new  btSoftBodyWorldInfo();  worldInfo.setBroadphase(broadphase);  worldInfo.setDispatcher(dispatcher);  worldInfo.getSparsesdf().Initialize();  	btAxisSweep3  broadphase  =  new  btAxisSweep3(tmpV1.set(-1000,  -1000,  -1000),  tmpV2.set(1000,  1000,  1000),  1024);  
libgdx_1b98db20e5f6e192ba4efaa6317bcbfb49b6a18c	buggy:  float  projX  =  verts1[j  +  1]  -  verts1[i  +  1];  context:  static  boolean  separateConvexPolygons  (float[]  verts1,  float[]  verts2,  Vector2  separation)  {  final  int  length1  =  verts1.length;  final  int  length2  =  verts2.length;  for  (int  i  =  0;  i  <  length1;  i  +=  2)  {  final  int  j  =  (i  +  1)  %  length1;  float  projX  =  verts1[j  +  1]  -  verts1[i  +  1];  float  projX  =  verts1[(j  +  1)  %  length1]  -  verts1[i  +  1];  float  projY  =  verts1[i]  -  verts1[j];  final  float  length  =  (float)Math.sqrt(projX  *  projX  +  projY  *  projY);  projX  /=  length;  projY  /=  length;  	float  projX  =  verts1[(j  +  1)  %  length1]  -  verts1[i  +  1];  
elasticsearch_46088b9f8acc057414ba222809b1b6bc3e1a435e	buggy:  return  new  CountAndTotalHistogramFacetCollector(facetName,  keyField,  interval,  comparatorType,  context);  context:  if  (interval  <=  0)  {  throw  new  FacetPhaseExecutionException(facetName,   "[interval]  is  required  to  be  set  for  histogram  facet ");  }  if  (valueScript  !=  null)  {  return  new  KeyValueScriptHistogramFacetCollector(facetName,  keyField,  scriptLang,  valueScript,  params,  interval,  comparatorType,  context);  }  else  if  (valueField  ==  null)  {  return  new  CountHistogramFacetCollector(facetName,  keyField,  interval,  comparatorType,  context);  }  else  if  (keyField.equals(valueField))  {              return  new  CountAndTotalHistogramFacetCollector(facetName,  keyField,  interval,  comparatorType,  context);              return  new  FullHistogramFacetCollector(facetName,  keyField,  interval,  comparatorType,  context);  }  else  {  return  new  KeyValueHistogramFacetCollector(facetName,  keyField,  valueField,  interval,  comparatorType,  context);  }  }  InternalHistogramFacet  first  =  (InternalHistogramFacet)  facets.get(0);  	return  new  FullHistogramFacetCollector(facetName,  keyField,  interval,  comparatorType,  context);  
elasticsearch_f8a129961ea7fb71630e83d190b45e221e1dfd1a	buggy:  }  catch  (Exception  e)  {  context:  Translog.Operation  operation  =  TranslogStreams.readTranslogOperation(si);  if  ((si.position()  -  curPos)  !=  opSize)  {  }  recoveryStatus.translog().addTranslogOperations(1);  indexShard.performRecoveryOperation(operation);  if  (si.position()  >=  bos.size())  {  position  =  si.position();  break;  }                          }  catch  (Exception  e)  {                          }  catch  (Throwable  e)  {  ignore  =  true;  latch.countDown();  return;  }  }  BytesStreamOutput  newBos  =  new  BytesStreamOutput();  	}  catch  (Throwable  e)  {  
elasticsearch_ee585ad96c96040fccca79524e3c1f53d6294bd3	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  NodeService  nodeService;  ClusterService  clusterService,  TransportService  transportService,  NodeService  nodeService)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  this.nodeService  =  nodeService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Cluster.Node.INFO;  }  return   "/cluster/nodes/info/node ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_21a1021bdb7ff3877e9a030d86ad28bac9acf0c6	buggy:  throw  new  QueryPhaseExecutionException(searchContext);  context:  }  TopDocs  topDocs;  if  (searchContext.sort()  !=  null)  {  topDocs  =  searchContext.searcher().search(query,  null,  searchContext.from()  +  searchContext.size(),  searchContext.sort());  }  else  {  topDocs  =  searchContext.searcher().search(query,  searchContext.from()  +  searchContext.size());  }  searchContext.queryResult().topDocs(topDocs);  }  catch  (Exception  e)  {              throw  new  QueryPhaseExecutionException(searchContext);              throw  new  QueryPhaseExecutionException(searchContext,  e);  }  facetsPhase.execute(searchContext);  }  }  	throw  new  QueryPhaseExecutionException(searchContext,  e);  
elasticsearch_720b550a94467347cbfe0b697bd1a1bafa57705b	buggy:  public  float  factor(int  docId)  {  context:  public  void  setNextReader(AtomicReaderContext  context)  {  }  public  float  score(int  docId,  float  subQueryScore)  {  return  subQueryScore  *  boost;  }      public  float  factor(int  docId)  {      public  double  factor(int  docId)  {  return  boost;  }  public  Explanation  explainScore(int  docId,  Explanation  subQueryExpl)  {  Explanation  exp  =  new  Explanation(boost  *  subQueryExpl.getValue(),   "static  boost  function:  product  of: ");  exp.addDetail(subQueryExpl);  exp.addDetail(new  Explanation(boost,   "boostFactor "));  	public  double  factor(int  docId)  {  
elasticsearch_b75d1d885a4f56edf8d1b8cd393298588fbd0123	buggy:  if  (entry.getKey().equals( "pretty ")  ||  entry.getKey().equals( "timeout ")  ||  entry.getKey().equals( "master_timeout "))  {  context:  String  key  =  entry.getKey();  String  value  =  entry.getValue();  if  (key.startsWith( "settings. "))  {  key  =  key.substring( "settings. ".length());  }  updateSettings.put(key,  value);  }  }  for  (Map.Entry<String,  String>  entry  :  request.params().entrySet())  {              if  (entry.getKey().equals( "pretty ")  ||  entry.getKey().equals( "timeout ")  ||  entry.getKey().equals( "master_timeout "))  {              if  (entry.getKey().equals( "pretty ")  ||  entry.getKey().equals( "timeout ")  ||  entry.getKey().equals( "master_timeout ")  ||  entry.getKey().equals( "index "))  {  continue;  }  updateSettings.put(entry.getKey(),  entry.getValue());  }  updateSettingsRequest.settings(updateSettings);  client.admin().indices().updateSettings(updateSettingsRequest,  new  AcknowledgedRestListener<UpdateSettingsResponse>(channel));  }  	if  (entry.getKey().equals( "pretty ")  ||  entry.getKey().equals( "timeout ")  ||  entry.getKey().equals( "master_timeout ")  ||  entry.getKey().equals( "index "))  {  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  throw  new  IOException( "Expected  handle  header ");  context:  return  handles.get(in.readVInt());  }  else  if  (b  ==  2)  {  int  handle  =  in.readVInt();  String  s  =  in.readUTF();  identityHandles.put(handle,  s);  return  s;  }  else  if  (b  ==  3)  {  return  identityHandles.get(in.readVInt());  }  else  {              throw  new  IOException( "Expected  handle  header ");              throw  new  IOException( "Expected  handle  header,  got  [ "  +  b  +   "] ");  }  }  return  in.read();  }  	throw  new  IOException( "Expected  handle  header,  got  [ "  +  b  +   "] ");  
elasticsearch_c4bed91262394fcc26a2e8d20a5570fe70539fd2	buggy:  BytesRef  value  =  parser.bytesOrNull();  context:  String  currentFieldName  =  null;  XContentParser.Token  token;  boolean  idsProvided  =  false;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "values ".equals(currentFieldName))  {  idsProvided  =  true;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {                          BytesRef  value  =  parser.bytesOrNull();                          BytesRef  value  =  parser.utf8BytesOrNull();  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");  }  ids.add(value);  }  }  else  if  ( "types ".equals(currentFieldName)  ||   "type ".equals(currentFieldName))  {  types  =  new  ArrayList<>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  	BytesRef  value  =  parser.utf8BytesOrNull();  
libgdx_69925478def37cf08d50c9165af8fdaa2e926c96	buggy:  config.useGL20  =  true;  context:  public  class  GdxInvadersDesktop  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.title  =   "Gdx  Invaders ";  config.vSyncEnabled  =  true;  config.useGL20  =  true;  config.useGL20  =  false;  new  LwjglApplication(new  GdxInvaders(),  config);  }  }  	config.useGL20  =  false;  
libgdx_0c6a387f7b0b4f5180014459b3dafaac486d61d4	buggy:  nextIndex  =  currentIndex;  context:  hasNext  =  true;  break;  }  }  }  public  void  remove  ()  {  if  (currentIndex  <  0)  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  null;  map.valueTable[currentIndex]  =  null;  }  currentIndex  =  -1;  map.size--;  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_efc9e8fe7b21148095084c36d55cb2f218a3da88	buggy:  return  indexShard.primaryShardIt();  context:  preference  =  preference.substring(index  +  1);  }  }  if  (preference.startsWith( "_prefer_node: "))  {  return  indexShard.preferNodeActiveShardsIt(preference.substring( "_prefer_node: ".length()));  }  if  ( "_local ".equals(preference))  {  return  indexShard.preferNodeActiveShardsIt(localNodeId);  }  if  ( "_primary ".equals(preference))  {                  return  indexShard.primaryShardIt();                  return  indexShard.primaryActiveShardIt();  }  if  ( "_primary_first ".equals(preference)  ||   "_primaryFirst ".equals(preference))  {  return  indexShard.primaryFirstActiveShardsIt();  }  if  ( "_only_local ".equals(preference)  ||   "_onlyLocal ".equals(preference))  {  return  indexShard.onlyNodeActiveShardsIt(localNodeId);  }  if  (preference.startsWith( "_only_node: "))  {  	return  indexShard.primaryActiveShardIt();  
libgdx_1714ea76ecc275f8872e0494ce88a3885d48f143	buggy:  body.applyCentralImpulse(Vector3.tmp2.set(ray.direction).scl(20f));  context:  rayTestCB.getRayFromWorld().setValue(rayFrom.x,  rayFrom.y,  rayFrom.z);  rayTestCB.getRayToWorld().setValue(rayTo.x,  rayTo.y,  rayTo.z);  world.collisionWorld.rayTest(rayFrom,  rayTo,  rayTestCB);  if  (rayTestCB.hasHit())  {  final  btCollisionObject  obj  =  rayTestCB.getCollisionObject();  if  (!obj.isStaticOrKinematicObject())  {  final  btRigidBody  body  =  (btRigidBody)(obj);  body.activate();  body.applyCentralImpulse(Vector3.tmp2.set(ray.direction).scl(20f));  body.applyCentralImpulse(tmpV2.set(ray.direction).scl(20f));  }  }  return  true;  }  }  	body.applyCentralImpulse(tmpV2.set(ray.direction).scl(20f));  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  positions.add(new  Vector2(MathUtils.cos(i  /  n),  MathUtils.sin(i  /  n)).mul(200));  context:  stouchAreaP3.setPosition(touchAreaP3.max.x  -  170,  touchAreaP3.getCenter().y-40);  p3.setPosition(touchAreaP3.max.x-190,  touchAreaP3.getCenter().y-15);  stouchAreaP4.setPosition(touchAreaP4.max.x  -  170,  touchAreaP4.getCenter().y-40);  p4.setPosition(touchAreaP4.max.x-190,  touchAreaP4.getCenter().y-15);  }  }  public  Array<Vector2>  generatePositions(int  n)  {  Array<Vector2>  positions  =  new  Array<Vector2>();  for  (int  i  =  1;  i  <=  n;  ++i)  {  positions.add(new  Vector2(MathUtils.cos(i  /  n),  MathUtils.sin(i  /  n)).mul(200));  positions.add(new  Vector2(MathUtils.cos(i  /  n),  MathUtils.sin(i  /  n)).scl(200));  }  return  positions;  }  public  void  show()  {  }  	positions.add(new  Vector2(MathUtils.cos(i  /  n),  MathUtils.sin(i  /  n)).scl(200));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  putRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  PutIndexTemplateRequest  putRequest  =  new  PutIndexTemplateRequest(request.param( "name "));  putRequest.listenerThreaded(false);  putRequest.template(request.param( "template ",  putRequest.template()));  putRequest.order(request.paramAsInt( "order ",  putRequest.order()));  try  {  putRequest.create(request.paramAsBoolean( "create ",  false));  putRequest.cause(request.param( "cause ",   " "));  putRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));              putRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());              putRequest.source(request.content());  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  	putRequest.source(request.content());  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);  context:  return  ThreadPool.Names.SAME;  }  protected  final  boolean  localExecute(Request  request)  {  return  request.local();  }  protected  final  void  masterOperation(final  Request  request,  final  ClusterState  state,  final  ActionListener<Response>  listener)  throws  ElasticSearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  request.indices(concreteIndices);  doMasterOperation(request,  state,  listener);  }  protected  abstract  void  doMasterOperation(Request  request,  ClusterState  state,  final  ActionListener<Response>  listener)  throws  ElasticSearchException;  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_01b18ad219933679256753fa8639c37d11cac1ff	buggy:  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator());  context:  }  }  if  (reduced  ==  null)  {  return  (UnmappedTerms)  aggregations.get(0);  }  final  int  size  =  Math.min(requiredSize,  buckets.v().size());          BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator());          BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  Object[]  internalBuckets  =  buckets.v().values;  boolean[]  states  =  buckets.v().allocated;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  List<LongTerms.Bucket>  sameTermBuckets  =  (List<LongTerms.Bucket>)  internalBuckets[i];  ordered.insertWithOverflow(sameTermBuckets.get(0).reduce(sameTermBuckets,  reduceContext.cacheRecycler()));  }  }  	BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  
libgdx_6ddb43d249aac1cc668917670af2a170755f663e	buggy:  if  (type  ==  String.class)  return  (T)Float.toString(jsonData.asFloat());  context:  }  throw  new  SerializationException( "Unable  to  convert  value  to  required  type:   "  +  jsonData  +   "  ( "  +  type.getName()  +   ") ");  }  if  (jsonData.isNumber())  {  try  {  if  (type  ==  null  ||  type  ==  float.class  ||  type  ==  Float.class)  return  (T)(Float)jsonData.asFloat();  if  (type  ==  int.class  ||  type  ==  Integer.class)  return  (T)(Integer)jsonData.asInt();  if  (type  ==  long.class  ||  type  ==  Long.class)  return  (T)(Long)jsonData.asLong();  if  (type  ==  double.class  ||  type  ==  Double.class)  return  (T)(Double)jsonData.asDouble();  if  (type  ==  String.class)  return  (T)Float.toString(jsonData.asFloat());  if  (type  ==  String.class)  return  (T)jsonData.asString();  if  (type  ==  short.class  ||  type  ==  Short.class)  return  (T)(Short)jsonData.asShort();  if  (type  ==  byte.class  ||  type  ==  Byte.class)  return  (T)(Byte)jsonData.asByte();  }  catch  (NumberFormatException  ignored)  {  }  jsonData  =  new  JsonValue(jsonData.asString());  }  if  (jsonData.isBoolean())  {  	if  (type  ==  String.class)  return  (T)jsonData.asString();  
elasticsearch_a005dc2c1f0886466c15b4f834d21cb63b9a669a	buggy:  threadPool.info());  context:  }  return  new  NodeInfo();  }  return  new  NodeInfo(clusterService.state().nodes().localNode(),  nodeAttributes,  settings,  monitorService.osService().info(),  monitorService.processService().info(),  monitorService.jvmService().info(),  monitorService.networkService().info(),                  threadPool.info());                  threadPool.info(),  transportService.info());  }  return  false;  }  protected  static  class  NodeInfoRequest  extends  NodeOperationRequest  {  	threadPool.info(),  transportService.info());  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(immutableCluster().size()));  context:  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().clear().get();  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "foo "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "fuu "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "baz "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "non-existent "),  is(false));  }  public  void  testNodes()  throws  Exception  {  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().clear().setNodes(true).get();          assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(immutableCluster().size()));          assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(cluster().size()));  ClusterStateResponse  clusterStateResponseFiltered  =  client().admin().cluster().prepareState().clear().get();  assertThat(clusterStateResponseFiltered.getState().nodes().nodes().size(),  is(0));  }  public  void  testMetadata()  throws  Exception  {  ClusterStateResponse  clusterStateResponseUnfiltered  =  client().admin().cluster().prepareState().clear().setMetaData(true).get();  	assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(cluster().size()));  
elasticsearch_0236a77c0bbeb9117092a34cb4b6e16acdeef6c4	buggy:  String  rateLimitingType  =  indexSettings.get(INDEX_STORE_THROTTLE_TYPE,  AbstractIndexStore.this.rateLimitingType);  context:  public  abstract  class  AbstractIndexStore  extends  AbstractIndexComponent  implements  IndexStore  {  public  static  final  String  INDEX_STORE_THROTTLE_TYPE  =   "index.store.throttle.type ";  public  static  final  String  INDEX_STORE_THROTTLE_MAX_BYTES_PER_SEC  =   "index.store.throttle.max_bytes_per_sec ";  class  ApplySettings  implements  IndexSettingsService.Listener  {  public  void  onRefreshSettings(Settings  settings)  {              String  rateLimitingType  =  indexSettings.get(INDEX_STORE_THROTTLE_TYPE,  AbstractIndexStore.this.rateLimitingType);              String  rateLimitingType  =  settings.get(INDEX_STORE_THROTTLE_TYPE,  AbstractIndexStore.this.rateLimitingType);  if  (!rateLimitingType.equals(AbstractIndexStore.this.rateLimitingType))  {  if  (rateLimitingType.equalsIgnoreCase( "node "))  {  AbstractIndexStore.this.rateLimitingType  =  rateLimitingType;  AbstractIndexStore.this.nodeRateLimiting  =  true;  }  else  {  StoreRateLimiting.Type.fromString(rateLimitingType);  AbstractIndexStore.this.rateLimitingType  =  rateLimitingType;  	String  rateLimitingType  =  settings.get(INDEX_STORE_THROTTLE_TYPE,  AbstractIndexStore.this.rateLimitingType);  
elasticsearch_ee1d50f8d81a065b100f9efce8246729dc83d31e	buggy:  }  else  if  ( "comparator ".equals(fieldName))  {  context:  }  else  if  ( "value_field ".equals(fieldName)  ||   "valueField ".equals(fieldName))  {  valueField  =  parser.text();  }  else  if  ( "interval ".equals(fieldName))  {  interval  =  parser.longValue();  }  else  if  ( "time_interval ".equals(fieldName))  {  interval  =  TimeValue.parseTimeValue(parser.text(),  null).millis();  }  else  if  ( "key_script ".equals(fieldName)  ||   "keyScript ".equals(fieldName))  {  keyScript  =  parser.text();  }  else  if  ( "value_script ".equals(fieldName)  ||   "valueScript ".equals(fieldName))  {  valueScript  =  parser.text();                  }  else  if  ( "comparator ".equals(fieldName))  {                  }  else  if  ( "order ".equals(fieldName)  ||   "comparator ".equals(fieldName))  {  comparatorType  =  HistogramFacet.ComparatorType.fromString(parser.text());  }  }  }  if  (keyScript  !=  null  &&  valueScript  !=  null)  {  return  new  ScriptHistogramFacetCollector(facetName,  keyScript,  valueScript,  params,  interval,  comparatorType,  context.scriptService(),  context.fieldDataCache(),  context.mapperService());  }  	}  else  if  ( "order ".equals(fieldName)  ||   "comparator ".equals(fieldName))  {  
libgdx_7189250e1df3eee4d42d15cf44be0839242810b7	buggy:  partIndices[k]  =  (short)indices.getInt(k);  context:  String  type  =  meshPart.getString( "type ",  null);  if(type  ==  null)  {  throw  new  GdxRuntimeException( "No  primitive  type  given  for  mesh  part  ' "  +  partId  +   "' ");  }  jsonPart.primitiveType  =  parseType(type);  JsonValue  indices  =  meshPart.require( "indices ");  short[]  partIndices  =  new  short[indices.size()];  int  k  =  0;  for  (JsonValue  value  =  indices.child();  value  !=  null;  value  =  value.next(),  k++)  {  partIndices[k]  =  (short)indices.getInt(k);  partIndices[k]  =  (short)value.asInt();  }  jsonPart.indices  =  partIndices;  parts.add(jsonPart);  }  jsonMesh.parts  =  parts.toArray(ModelMeshPart.class);  model.meshes.add(jsonMesh);  }  }  	partIndices[k]  =  (short)value.asInt();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ObjectOpenHashSet<DiscoveryNode>  nodes  =  new  ObjectOpenHashSet<DiscoveryNode>();  context:  }  }  }  }  protected  void  masterOperation(final  NodesShutdownRequest  request,  final  ClusterState  state,  final  ActionListener<NodesShutdownResponse>  listener)  throws  ElasticsearchException  {  if  (disabled)  {  throw  new  ElasticsearchIllegalStateException( "Shutdown  is  disabled ");  }          final  ObjectOpenHashSet<DiscoveryNode>  nodes  =  new  ObjectOpenHashSet<DiscoveryNode>();          final  ObjectOpenHashSet<DiscoveryNode>  nodes  =  new  ObjectOpenHashSet<>();  if  (state.nodes().isAllNodes(request.nodesIds))  {  nodes.addAll(state.nodes().dataNodes().values());  nodes.addAll(state.nodes().masterNodes().values());  Thread  t  =  new  Thread(new  Runnable()  {  public  void  run()  {  try  {  	final  ObjectOpenHashSet<DiscoveryNode>  nodes  =  new  ObjectOpenHashSet<>();  
elasticsearch_9e2469e04f3cf7e2d94acdcd4bcef52b79d5dae5	buggy:  return  indexQueryParser.similarityService  !=  null  ?  indexQueryParser.similarityService.defaultSearchSimilarity()  :  null;  context:  public  IndexEngine  indexEngine()  {  return  indexQueryParser.indexEngine;  }  public  SimilarityService  similarityService()  {  return  indexQueryParser.similarityService;  }  public  Similarity  searchSimilarity()  {          return  indexQueryParser.similarityService  !=  null  ?  indexQueryParser.similarityService.defaultSearchSimilarity()  :  null;          return  indexQueryParser.similarityService  !=  null  ?  indexQueryParser.similarityService.similarity()  :  null;  }  public  IndexCache  indexCache()  {  return  indexQueryParser.indexCache;  }  public  String  defaultField()  {  return  indexQueryParser.defaultField();  	return  indexQueryParser.similarityService  !=  null  ?  indexQueryParser.similarityService.similarity()  :  null;  
libgdx_af119c8e5bbcabe99aafe25ac72b25bbf4542c7f	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleStageCullingTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleStageCullingTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_0a90444e5c0aeccbaef85408ffe41d7ac5430720	buggy:  File[]  relativePaths  =  file.listFiles(filter);  context:  return  handles;  }  public  FileHandle[]  list  (FilenameFilter  filter)  {  if  (type  ==  FileType.Classpath)  throw  new  GdxRuntimeException( "Cannot  list  a  classpath  directory:   "  +  file);  File[]  relativePaths  =  file.listFiles(filter);  File[]  relativePaths  =  file().listFiles(filter);  if(relativePaths  ==  null)  return  new  FileHandle[0];  FileHandle[]  handles  =  new  FileHandle[relativePaths.length];  for(int  i  =  0,  n  =  relativePaths.length;  i  <  n;  i++)  handles[i]  =  child(relativePaths[i].getPath());  return  handles;  }  	File[]  relativePaths  =  file().listFiles(filter);  
libgdx_184ea8f7a0270f3f5ce684a8cc0afe3cf569f68d	buggy:  return  new  GwtTestWrapper();  context:  public  class  GwtTestStarter  extends  GwtApplication  {  public  GwtApplicationConfiguration  getConfig  ()  {  return  new  GwtApplicationConfiguration(640,  640);  }  public  ApplicationListener  getApplicationListener  ()  {  return  new  GwtTestWrapper();  return  new  UITest();  }  }  	return  new  UITest();  
libgdx_0210c9c0183bbbc5e264c9ca17737cd74405b144	buggy:  touchEventPool.free(touchEvents);  context:  case  UITouchPhase.Cancelled:  case  UITouchPhase.Ended:  if(inputProcessor  !=  null)  inputProcessor.touchUp(event.x,  event.y,  event.pointer,  Buttons.LEFT);  break;  case  UITouchPhase.Moved:  case  UITouchPhase.Stationary:  if(inputProcessor  !=  null)  inputProcessor.touchDragged(event.x,  event.y,  event.pointer);  break;  }  }  touchEventPool.free(touchEvents);  touchEventPool.freeAll(touchEvents);  touchEvents.clear();  }  }  NSSetEnumerator  touchEnumerator  =  new  NSSetEnumerator(new  NSSetEnumerator.Method()  {  public  void  Invoke(NSObject  obj,  boolean[]  stop)  {  UITouch  touch  =  (UITouch)  obj;  PointF  loc  =  touch.LocationInView(touch.get_View());  	touchEventPool.freeAll(touchEvents);  
libgdx_8c1eb89354495c8efffe82f0e21ce339c881aa83	buggy:  gdxBulletJNI.ContactProcessedListenerByObject_onContactProcessed(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  match1);  context:  swigCMemOwn  =  false;  gdxBulletJNI.ContactProcessedListenerByObject_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  gdxBulletJNI.ContactProcessedListenerByObject_change_ownership(this,  swigCPtr,  true);  }  public  void  onContactProcessed(btManifoldPoint  cp,  btCollisionObject  colObj0,  boolean  match0,  btCollisionObject  colObj1,  boolean  match1)  {      gdxBulletJNI.ContactProcessedListenerByObject_onContactProcessed(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  match1);      gdxBulletJNI.ContactProcessedListenerByObject_onContactProcessed(swigCPtr,  this,  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  match1);  }  public  ContactProcessedListenerByObject()  {  this(gdxBulletJNI.new_ContactProcessedListenerByObject(),  true);  gdxBulletJNI.ContactProcessedListenerByObject_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	gdxBulletJNI.ContactProcessedListenerByObject_onContactProcessed(swigCPtr,  this,  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  match1);  
elasticsearch_3b21759bec0a668970de0ba0ef92af64dc9f866e	buggy:  query.add(new  BooleanClause(mapper.fieldQuery(value),  BooleanClause.Occur.SHOULD));  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  mapper  =  smartNameFieldMappers.mapper();  }  }  BooleanQuery  query  =  new  BooleanQuery(disableCoord);  for  (String  value  :  values)  {  if  (mapper  !=  null)  {                  query.add(new  BooleanClause(mapper.fieldQuery(value),  BooleanClause.Occur.SHOULD));                  query.add(new  BooleanClause(mapper.fieldQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));  }  else  {  query.add(new  TermQuery(new  Term(fieldName,  value)),  BooleanClause.Occur.SHOULD);  }  }  query.setBoost(boost);  if  (minimumNumberShouldMatch  !=  -1)  {  query.setMinimumNumberShouldMatch(minimumNumberShouldMatch);  }  	query.add(new  BooleanClause(mapper.fieldQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));  
libgdx_501eb16ea8fbe820d08692b5baf7d47b0e371f91	buggy:  SelectBox  dropdown  =  new  SelectBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX "},  skin);  context:  Table  t  =  new  Table();  t.row();  t.add(myLabel);  t.layout();  CheckBox  checkBox  =  new  CheckBox( "Check  me ",  skin);  final  Slider  slider  =  new  Slider(0,  10,  1,  false,  skin);  TextField  textfield  =  new  TextField( " ",  skin);  textfield.setMessageText( "Click  here! ");  SelectBox  dropdown  =  new  SelectBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX "},  skin);  SelectBox  dropdown  =  new  SelectBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX "},  skin);  Image  imageActor  =  new  Image(image2);  ScrollPane  scrollPane  =  new  ScrollPane(imageActor);  List  list  =  new  List(listEntries,  skin);  ScrollPane  scrollPane2  =  new  ScrollPane(list,  skin);  scrollPane2.setFlickScroll(false);  SplitPane  splitPane  =  new  SplitPane(scrollPane,  scrollPane2,  false,  skin,   "default-horizontal ");  fpsLabel  =  new  Label( "fps: ",  skin);  	SelectBox  dropdown  =  new  SelectBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX ", "Android ",   "Windows ",   "Linux ",   "OSX "},  skin);  
elasticsearch_f6beebf34c3b32570fdf937b26dc640e4a819aa2	buggy:  return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  context:  }  }  count++;  }          return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);          return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0,  count);  }  }  	return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0,  count);  
elasticsearch_2c2783875e1befec504247f8e843a7c031bba92f	buggy:  final  PageCacheRecycler  recycler  =  randomBoolean()  ?  null  :  new  MockPageCacheRecycler(ImmutableSettings.EMPTY,  new  ThreadPool());  context:  public  class  BigArraysTests  extends  ElasticsearchTestCase  {  public  static  BigArrays  randombigArrays()  {          final  PageCacheRecycler  recycler  =  randomBoolean()  ?  null  :  new  MockPageCacheRecycler(ImmutableSettings.EMPTY,  new  ThreadPool());          final  PageCacheRecycler  recycler  =  randomBoolean()  ?  null  :  new  MockPageCacheRecycler(ImmutableSettings.EMPTY,  new  ThreadPool( "BigArraysTests "));  return  new  MockBigArrays(ImmutableSettings.EMPTY,  recycler);  }  private  BigArrays  bigArrays;  public  void  init()  {  bigArrays  =  randombigArrays();  	final  PageCacheRecycler  recycler  =  randomBoolean()  ?  null  :  new  MockPageCacheRecycler(ImmutableSettings.EMPTY,  new  ThreadPool( "BigArraysTests "));  
libgdx_83c7f2fef080e49051c67073df8f953cfdef810d	buggy:  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-bullet "),  win32home,  android,  win32,  win64,  lin32,  lin64,  mac);  context:  lin64.headerDirs  =  headers;  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  mac.cExcludes  =  mac.cppExcludes  =  excludes;  mac.headerDirs  =  headers;  BuildTarget  android  =  BuildTarget.newDefaultTarget(TargetOs.Android,  false);  android.cExcludes  =  android.cppExcludes  =  excludes;  android.headerDirs  =  headers;  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-bullet "),  win32home,  android,  win32,  win64,  lin32,  lin64,  mac);  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-image "),  win32home,  android,  win32,  win64,  lin32,  lin64,  mac);  }  }  	new  AntScriptGenerator().generate(new  BuildConfig( "gdx-image "),  win32home,  android,  win32,  win64,  lin32,  lin64,  mac);  
libgdx_5385538d952eba4782810beadc3e3bceda332748	buggy:  +  (renderer.isJniUsed()  ?   ",  jni "  :   ",  java "),  10,  20,  context:  start  =  System.nanoTime();  renderer.render();  renderTime  =  (System.nanoTime()  -  start)  /  1000000000.0f;  }  gl.glDisable(GL10.GL_DEPTH_TEST);  batch.begin();  font.draw(batch,   "fps:   "  +  Gdx.graphics.getFramesPerSecond()  +  (renderer.isJniUsed()  ?   ",  jni "  :   ",  java "),  10,  20,  +  (renderer.isJniUsed()  ?   ",  jni "  :   ",  java ")  +   ",  render  time:   "  +  renderTime  +   ",  skin  time:   "  +  skinTime,  10,  20,  Color.WHITE);  batch.end();  Gdx.input.processEvents(this);  }  public  void  dispose()  {  	+  (renderer.isJniUsed()  ?   ",  jni "  :   ",  java ")  +   ",  render  time:   "  +  renderTime  +   ",  skin  time:   "  +  skinTime,  10,  20,  
libgdx_1d221eb563789ef7520a69ffc03fd2b7dbc271fb	buggy:  return  true;  context:  if  (!pressed)  return  false;  parent.focus(null);  pressed  =  false;  if  (clickListener  !=  null)  clickListener.clicked(this);  return  true;  }  return  true;  return  pressed;  }  public  Actor  hit  (float  x,  float  y)  {  return  x  >  0  &&  y  >  0  &&  x  <  width  &&  y  <  height  ?  this  :  null;  }  }  	return  pressed;  
libgdx_096ad73907d84bd82cae712a484ba5fbdb1473d5	buggy:  BuildExecutor.executeAnt( "jni/build-macosx32.xml ",   "clean  postcompile  -v ");  context:  android.cFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.cppFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.headerDirs  =  headerDirs;  android.cIncludes  =  cIncludes;  android.cppIncludes  =  cppIncludes;  android.cppExcludes  =  cppExcludes;  android.preCompileTask  =  precompileTask;  new  AntScriptGenerator().generate(buildConfig,  win32home,  win32,  win64,  lin32,  lin64,  mac,  android);  BuildExecutor.executeAnt( "jni/build-macosx32.xml ",   "clean  postcompile  -v ");  BuildExecutor.executeAnt( "jni/build-macosx32.xml ",   "-v ");  BuildExecutor.executeAnt( "jni/build.xml ",   "pack-natives  -v ");  }  }  	BuildExecutor.executeAnt( "jni/build-macosx32.xml ",   "-v ");  
libgdx_8acc495173f331d13730415858eef17c4a82af56	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_01b18ad219933679256753fa8639c37d11cac1ff	buggy:  .subAggregation(terms( "values ").order(Terms.Order.TERM_ASC)))  context:  assertThat(bucket,  notNullValue());  assertThat(bucket.getKey(),  equalTo((long)  i  *  interval));  assertThat(bucket.getDocCount(),  equalTo(counts[i]));  }  }  public  void  multiValuedField_WithValueScript_WithInheritedSubAggregator()  throws  Exception  {  SearchResponse  response  =  client().prepareSearch( "idx ")  .addAggregation(histogram( "histo ").field( "values ").script( "_value  +  1 ").interval(interval)                      .subAggregation(terms( "values ").order(Terms.Order.TERM_ASC)))                      .subAggregation(terms( "values ").order(Terms.Order.term(true))))  .execute().actionGet();  assertSearchResponse(response);  final  int  numBuckets  =  (numDocs  +  2)  /  interval  -  2  /  interval  +  1;  final  long[]  counts  =  new  long[(numDocs  +  2)  /  interval  +  1];  for  (int  i  =  0;  i  <  numDocs  ;  ++i)  {  	.subAggregation(terms( "values ").order(Terms.Order.term(true))))  
elasticsearch_c93ddd9b612ae32d2d59bcafec8e552e6877b033	buggy:  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(scoreMode))  {  context:  }  else  if  ( "filter ".equals(currentFieldName))  {  filter  =  parseContext.parseInnerFilter();  }  }  else  if  (token.isValue())  {  if  ( "path ".equals(currentFieldName))  {  path  =  parser.text();  }  else  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  else  if  ( "_scope ".equals(currentFieldName))  {  scope  =  parser.text();                  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(scoreMode))  {                  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(currentFieldName))  {  String  sScoreMode  =  parser.text();  if  ( "avg ".equals(sScoreMode))  {  scoreMode  =  BlockJoinQuery.ScoreMode.Avg;  }  else  if  ( "max ".equals(sScoreMode))  {  scoreMode  =  BlockJoinQuery.ScoreMode.Max;  }  else  if  ( "total ".equals(sScoreMode))  {  scoreMode  =  BlockJoinQuery.ScoreMode.Total;  }  else  if  ( "none ".equals(sScoreMode))  {  	}  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(currentFieldName))  {  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  AliasMetaData  aliasMetaData  =  cluster().clusterService().state().metaData().aliases().get( "alias1 ").get( "test ");  context:  stopWatch.start();  assertAcked((admin().indices().prepareAliases().addAlias( "test ",   "alias1 ",  termFilter( "name ",   "foo ")).setTimeout(timeout)));  assertThat(stopWatch.stop().lastTaskTime().millis(),  lessThan(timeout.millis()));  stopWatch.start();  assertAcked((admin().indices().prepareAliases().addAlias( "test ",   "alias1 ",  termFilter( "name ",   "bar ")).setTimeout(timeout)));  assertThat(stopWatch.stop().lastTaskTime().millis(),  lessThan(timeout.millis()));          AliasMetaData  aliasMetaData  =  cluster().clusterService().state().metaData().aliases().get( "alias1 ").get( "test ");          AliasMetaData  aliasMetaData  =  internalCluster().clusterService().state().metaData().aliases().get( "alias1 ").get( "test ");  assertThat(aliasMetaData.getFilter().toString(),  equalTo( "{\ "term\ ":{\ "name\ ":\ "bar\ "}} "));  stopWatch.start();  assertAcked((admin().indices().prepareAliases().removeAlias( "test ",   "alias1 ").setTimeout(timeout)));  assertThat(stopWatch.stop().lastTaskTime().millis(),  lessThan(timeout.millis()));  	AliasMetaData  aliasMetaData  =  internalCluster().clusterService().state().metaData().aliases().get( "alias1 ").get( "test ");  
libgdx_e167a69c58e51a796103b6124b63b7dce0631440	buggy:  return  false;  context:  return  tests[testIndex].touchDragged(x,  y,  pointer);  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer,  int  button)  {  return  tests[testIndex].touchUp(x,  y,  pointer,  button);  }  public  boolean  needsGL20  ()  {  return  false;  return  true;  }  public  boolean  mouseMoved  (int  x,  int  y)  {  return  tests[testIndex].mouseMoved  (x,  y);  }  	return  true;  
elasticsearch_3770924300a0c22f1db4d31e29bab702216edd79	buggy:  byte[]  buffer  =  new  byte[16  *  1024];  context:  File  file  =  new  File(path,  blobName);  RandomAccessFile  raf;  try  {  raf  =  new  RandomAccessFile(file,   "rw ");  }  catch  (FileNotFoundException  e)  {  listener.onFailure(e);  return;  }  try  {  try  {                          byte[]  buffer  =  new  byte[16  *  1024];                          byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  int  bytesRead;  while  ((bytesRead  =  is.read(buffer))  !=  -1)  {  raf.write(buffer,  0,  bytesRead);  }  }  finally  {  try  {  is.close();  }  catch  (IOException  ex)  {  	byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<NodeInfo>  nodesInfos  =  new  ArrayList<NodeInfo>();  context:  return  ThreadPool.Names.MANAGEMENT;  }  protected  String  transportAction()  {  return  NodesInfoAction.NAME;  }  protected  NodesInfoResponse  newResponse(NodesInfoRequest  nodesInfoRequest,  AtomicReferenceArray  responses)  {          final  List<NodeInfo>  nodesInfos  =  new  ArrayList<NodeInfo>();          final  List<NodeInfo>  nodesInfos  =  new  ArrayList<>();  for  (int  i  =  0;  i  <  responses.length();  i++)  {  Object  resp  =  responses.get(i);  if  (resp  instanceof  NodeInfo)  {  nodesInfos.add((NodeInfo)  resp);  }  }  return  new  NodesInfoResponse(clusterName,  nodesInfos.toArray(new  NodeInfo[nodesInfos.size()]));  }  	final  List<NodeInfo>  nodesInfos  =  new  ArrayList<>();  
libgdx_1c8122ee4f115b8afbcec748a20826d82995ad7a	buggy:  return  parse(new  InputStreamReader(input,   "ISO-8859-1 "));  context:  }  catch  (IOException  ex)  {  throw  new  SerializationException(ex);  }  finally  {  StreamUtils.closeQuietly(reader);  }  }  public  JsonValue  parse  (InputStream  input)  {  try  {  return  parse(new  InputStreamReader(input,   "ISO-8859-1 "));  return  parse(new  InputStreamReader(input,   "UTF-8 "));  }  catch  (IOException  ex)  {  throw  new  SerializationException(ex);  }  finally  {  StreamUtils.closeQuietly(input);  }  }  	return  parse(new  InputStreamReader(input,   "UTF-8 "));  
libgdx_bb452e3f906f19fc887101579fbe09f4085c2702	buggy:  FlickScrollPane  scroll  =  new  FlickScrollPane(null,  stage,  table,  0,  0);  context:  Gdx.input.setInputProcessor(stage);  Gdx.graphics.setVSync(false);  container  =  new  Table();  stage.addActor(container);  container.getTableLayout().debug();  Table  table  =  new  Table();  FlickScrollPane  scroll  =  new  FlickScrollPane(null,  stage,  table,  0,  0);  FlickScrollPane  scroll  =  new  FlickScrollPane(table,  stage);  container.add(scroll).expand().fill();  table.parse( "pad:10  *  expand:x  space:4 ");  for  (int  i  =  0;  i  <  100;  i++)  {  table.row();  table.add(new  Label(null,  i  +   "uno ",  new  LabelStyle(font,  Color.RED))).expandX().fillX();  table.add(new  Label(null,  i  +   "dos ",  new  LabelStyle(font,  Color.RED)));  table.add(new  Label(null,  i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9  long10  long11  long12 ",  new  LabelStyle(font,  	FlickScrollPane  scroll  =  new  FlickScrollPane(table,  stage);  
libgdx_8c1eb89354495c8efffe82f0e21ce339c881aa83	buggy:  return  gdxBulletJNI.ContactAddedListenerByWrapper_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObjectWrapper.getCPtr(colObj0Wrap),  colObj0Wrap,  partId0,  index0,  match0,  btCollisionObjectWrapper.getCPtr(colObj1Wrap),  colObj1Wrap,  partId1,  index1,  match1);  context:  swigCMemOwn  =  false;  gdxBulletJNI.ContactAddedListenerByWrapper_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  gdxBulletJNI.ContactAddedListenerByWrapper_change_ownership(this,  swigCPtr,  true);  }  public  boolean  onContactAdded(btManifoldPoint  cp,  btCollisionObjectWrapper  colObj0Wrap,  int  partId0,  int  index0,  boolean  match0,  btCollisionObjectWrapper  colObj1Wrap,  int  partId1,  int  index1,  boolean  match1)  {      return  gdxBulletJNI.ContactAddedListenerByWrapper_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObjectWrapper.getCPtr(colObj0Wrap),  colObj0Wrap,  partId0,  index0,  match0,  btCollisionObjectWrapper.getCPtr(colObj1Wrap),  colObj1Wrap,  partId1,  index1,  match1);      return  gdxBulletJNI.ContactAddedListenerByWrapper_onContactAdded(swigCPtr,  this,  cp,  btCollisionObjectWrapper.getCPtr(colObj0Wrap),  colObj0Wrap,  partId0,  index0,  match0,  btCollisionObjectWrapper.getCPtr(colObj1Wrap),  colObj1Wrap,  partId1,  index1,  match1);  }  public  ContactAddedListenerByWrapper()  {  this(gdxBulletJNI.new_ContactAddedListenerByWrapper(),  true);  gdxBulletJNI.ContactAddedListenerByWrapper_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	return  gdxBulletJNI.ContactAddedListenerByWrapper_onContactAdded(swigCPtr,  this,  cp,  btCollisionObjectWrapper.getCPtr(colObj0Wrap),  colObj0Wrap,  partId0,  index0,  match0,  btCollisionObjectWrapper.getCPtr(colObj1Wrap),  colObj1Wrap,  partId1,  index1,  match1);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataIndexTemplateService  indexTemplateService;  ThreadPool  threadPool,  MetaDataIndexTemplateService  indexTemplateService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.indexTemplateService  =  indexTemplateService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.PUT_INDEX_TEMPLATE;  }  return  new  PutIndexTemplateRequest();  	return  ThreadPool.Names.MANAGEMENT;  
libgdx_880cbf8d57403d0b765a5b140d2995165c8ae0ad	buggy:  shapes.rect(getX(),  getY(),  getWidth(),  getHeight(),  getOriginX(),  getOriginY(),  getScaleX(),  getScaleY(),  getRotation());  context:  public  void  drawDebug  (ShapeRenderer  shapes)  {  drawDebugBounds(shapes);  }  protected  void  drawDebugBounds  (ShapeRenderer  shapes)  {  if  (!getDebug())  return;  shapes.set(ShapeType.Line);  shapes.setColor(getStage().getDebugColor());  shapes.rect(getX(),  getY(),  getWidth(),  getHeight(),  getOriginX(),  getOriginY(),  getScaleX(),  getScaleY(),  getRotation());  shapes.rect(getX(),  getY(),  getOriginX(),  getOriginY(),  getWidth(),  getHeight(),  getScaleX(),  getScaleY(),  getRotation());  }  public  void  setDebug  (boolean  enabled)  {  debug  =  enabled;  if  (enabled)  Stage.debug  =  true;  }  	shapes.rect(getX(),  getY(),  getOriginX(),  getOriginY(),  getWidth(),  getHeight(),  getScaleX(),  getScaleY(),  getRotation());  
elasticsearch_12e2ba822f52bcab5a74603f41233a6d5cb423f6	buggy:  Query  parsedQuery  =  queryParser.parse(disMaxQuery().boost(1.2f).tieBreakerMultiplier(0.7f).add(termQuery( "age ",  34)).add(termQuery( "age ",  35)));  context:  IndexQueryParser  queryParser  =  newQueryParser();  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/json/matchAll.json ");  Query  parsedQuery  =  queryParser.parse(query);  assertThat(parsedQuery,  instanceOf(MatchAllDocsQuery.class));  MatchAllDocsQuery  matchAllDocsQuery  =  (MatchAllDocsQuery)  parsedQuery;  assertThat((double)  matchAllDocsQuery.getBoost(),  closeTo(1.2,  0.01));  }  IndexQueryParser  queryParser  =  newQueryParser();          Query  parsedQuery  =  queryParser.parse(disMaxQuery().boost(1.2f).tieBreakerMultiplier(0.7f).add(termQuery( "age ",  34)).add(termQuery( "age ",  35)));          Query  parsedQuery  =  queryParser.parse(disMaxQuery().boost(1.2f).tieBreaker(0.7f).add(termQuery( "age ",  34)).add(termQuery( "age ",  35)));  assertThat(parsedQuery,  instanceOf(DisjunctionMaxQuery.class));  DisjunctionMaxQuery  disjunctionMaxQuery  =  (DisjunctionMaxQuery)  parsedQuery;  assertThat((double)  disjunctionMaxQuery.getBoost(),  closeTo(1.2,  0.01));  List<Query>  disjuncts  =  Queries.disMaxClauses(disjunctionMaxQuery);  assertThat(disjuncts.size(),  equalTo(2));  Query  firstQ  =  disjuncts.get(0);  	Query  parsedQuery  =  queryParser.parse(disMaxQuery().boost(1.2f).tieBreaker(0.7f).add(termQuery( "age ",  34)).add(termQuery( "age ",  35)));  
elasticsearch_4e5ad568bb000a8026494fbc1e66752eeccc1826	buggy:  return  o2.order()  -  o1.order();  context:  public  synchronized  void  registerFilter(RestFilter  preProcessor)  {  RestFilter[]  copy  =  new  RestFilter[filters.length  +  1];  System.arraycopy(filters,  0,  copy,  0,  filters.length);  copy[filters.length]  =  preProcessor;  Arrays.sort(copy,  new  Comparator<RestFilter>()  {  public  int  compare(RestFilter  o1,  RestFilter  o2)  {                  return  o2.order()  -  o1.order();                  return  Integer.compare(o1.order(),  o2.order());  }  });  filters  =  copy;  }  	return  Integer.compare(o1.order(),  o2.order());  
elasticsearch_684e6986279ddbacdacd5470e27eddc25207427e	buggy:  for  (DocumentMapper  mapper  :  mapperService)  {  context:  }  }  for  (AliasMetaData  aliasMetaData  :  templatesAliases.values())  {  if  (aliasMetaData.filter()  !=  null)  {  aliasValidator.validateAliasFilter(aliasMetaData.alias(),  aliasMetaData.filter().uncompressed(),  indexQueryParserService);  }  }  Map<String,  MappingMetaData>  mappingsMetaData  =  Maps.newHashMap();                      for  (DocumentMapper  mapper  :  mapperService)  {                      for  (DocumentMapper  mapper  :  mapperService.docMappers(true))  {  MappingMetaData  mappingMd  =  new  MappingMetaData(mapper);  mappingsMetaData.put(mapper.type(),  mappingMd);  }  final  IndexMetaData.Builder  indexMetaDataBuilder  =  IndexMetaData.builder(request.index()).settings(actualIndexSettings);  for  (MappingMetaData  mappingMd  :  mappingsMetaData.values())  {  indexMetaDataBuilder.putMapping(mappingMd);  }  	for  (DocumentMapper  mapper  :  mapperService.docMappers(true))  {  
libgdx_501eb16ea8fbe820d08692b5baf7d47b0e371f91	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (short[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (short[]  array,  int  offset,  int  length)  {  short[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  short  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length;  
libgdx_e8a2f26f8b90144ba4247b9e769a3b32504c41e7	buggy:  public  CharSequence  getText  ()  {  context:  public  boolean  textEquals  (CharSequence  other)  {  int  length  =  text.length;  char[]  chars  =  text.chars;  if  (length  !=  other.length())  return  false;  for  (int  i  =  0;  i  <  length;  i++)  if  (chars[i]  !=  other.charAt(i))  return  false;  return  true;  }  public  CharSequence  getText  ()  {  public  StringBuilder  getText  ()  {  return  text;  }  public  void  invalidate  ()  {  super.invalidate();  sizeInvalid  =  true;  }  	public  StringBuilder  getText  ()  {  
elasticsearch_2c2783875e1befec504247f8e843a7c031bba92f	buggy:  final  ThreadPool  threadPool  =  new  ThreadPool();  context:  final  ByteSizeValue  payloadSize  =  new  ByteSizeValue(10,  ByteSizeUnit.MB);  final  int  NUMBER_OF_ITERATIONS  =  100000;  final  int  NUMBER_OF_CLIENTS  =  5;  final  byte[]  payload  =  new  byte[(int)  payloadSize.bytes()];  Settings  settings  =  ImmutableSettings.settingsBuilder()  .build();  NetworkService  networkService  =  new  NetworkService(settings);          final  ThreadPool  threadPool  =  new  ThreadPool();          final  ThreadPool  threadPool  =  new  ThreadPool( "BenchmarkNettyLargeMessages ");  final  TransportService  transportServiceServer  =  new  TransportService(new  NettyTransport(settings,  threadPool,  networkService,  BigArrays.NON_RECYCLING_INSTANCE,  Version.CURRENT),  threadPool).start();  final  TransportService  transportServiceClient  =  new  TransportService(new  NettyTransport(settings,  threadPool,  networkService,  BigArrays.NON_RECYCLING_INSTANCE,  Version.CURRENT),  threadPool).start();  final  DiscoveryNode  bigNode  =  new  DiscoveryNode( "big ",  new  InetSocketTransportAddress( "localhost ",  9300),  Version.CURRENT);  final  DiscoveryNode  smallNode  =  bigNode;  transportServiceClient.connectToNode(bigNode);  	final  ThreadPool  threadPool  =  new  ThreadPool( "BenchmarkNettyLargeMessages ");  
libgdx_a045d507fbe13a89587cf72c574c8ffd2e967260	buggy:  int  sdkVersion  =  Integer.parseInt(android.os.Build.VERSION.SDK);  context:  GLSurfaceView20  view  =  new  GLSurfaceView20(dream,  resolutionStrategy);  if  (configChooser  !=  null)  view.setEGLConfigChooser(configChooser);  else  view.setEGLConfigChooser(config.r,  config.g,  config.b,  config.a,  config.depth,  config.stencil);  view.setRenderer(this);  return  view;  }  else  {  config.useGL20  =  false;  configChooser  =  getEglConfigChooser();  int  sdkVersion  =  Integer.parseInt(android.os.Build.VERSION.SDK);  int  sdkVersion  =  android.os.Build.VERSION.SDK_INT;  if  (sdkVersion  >=  11)  {  GLSurfaceView  view  =  new  GLSurfaceView(dream)  {  protected  void  onMeasure  (int  widthMeasureSpec,  int  heightMeasureSpec)  {  ResolutionStrategy.MeasuredDimension  measures  =  resolutionStrategy.calcMeasures(widthMeasureSpec,  heightMeasureSpec);  setMeasuredDimension(measures.width,  measures.height);  	int  sdkVersion  =  android.os.Build.VERSION.SDK_INT;  
elasticsearch_edb3e5f0f48ead3ddc1bfbfecc78b7a49ea12285	buggy:  builder.field( "similariry ",  SimilarityLookupService.DEFAULT_SIMILARITY);  context:  builder.field( "index_analyzer ",  indexAnalyzer.name());  }  if  (includeDefaults  ||  !searchAnalyzer.name().startsWith( "_ "))  {  builder.field( "search_analyzer ",  searchAnalyzer.name());  }  }  if  (similarity()  !=  null)  {  builder.field( "similarity ",  similarity().name());  }  else  if  (includeDefaults)  {              builder.field( "similariry ",  SimilarityLookupService.DEFAULT_SIMILARITY);              builder.field( "similarity ",  SimilarityLookupService.DEFAULT_SIMILARITY);  }  if  (customFieldDataSettings  !=  null)  {  builder.field( "fielddata ",  (Map)  customFieldDataSettings.getAsMap());  }  else  if  (includeDefaults)  {  builder.field( "fielddata ",  (Map)  fieldDataType.getSettings().getAsMap());  }  }  	builder.field( "similarity ",  SimilarityLookupService.DEFAULT_SIMILARITY);  
libgdx_2b46aa85e6b2e6cc8738c25f12696ad5b904a6a6	buggy:  if  (unsafeBuffers.contains(buffer,  true))  context:  return  buffer;  }  public  static  long  getUnsafeByteBufferAddress(ByteBuffer  buffer)  {  synchronized(unsafeBuffers)  {  if  (unsafeBuffers.contains(buffer,  true))  if  (!unsafeBuffers.contains(buffer,  true))  return  0;  }  return  getByteBufferAddress(buffer);  }  	if  (!unsafeBuffers.contains(buffer,  true))  
elasticsearch_b5f3fc9ae1a68a9114acf1ef2bc9bc4d90ad1bea	buggy:  builder.startObject( "setting ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();  context:  builder.field( "successful ",  response.successfulShards());  builder.field( "failed ",  response.failedShards());  builder.endObject();  builder.startObject( "indices ");  for  (IndexStatus  indexStatus  :  response.indices().values())  {  builder.startObject(indexStatus.index());  builder.startObject( "settings ");  for  (Map.Entry<String,  String>  entry  :  indexStatus.settings().getAsMap().entrySet())  {                              builder.startObject( "setting ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();                              builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  builder.field( "storeSize ",  indexStatus.storeSize().toString());  builder.field( "storeSizeInBytes ",  indexStatus.storeSize().bytes());  builder.field( "estimatedFlushableMemorySize ",  indexStatus.estimatedFlushableMemorySize().toString());  builder.field( "estimatedFlushableMemorySizeInBytes ",  indexStatus.estimatedFlushableMemorySize().bytes());  builder.field( "translogOperations ",  indexStatus.translogOperations());  	builder.field(entry.getKey(),  entry.getValue());  
elasticsearch_c4bed91262394fcc26a2e8d20a5570fe70539fd2	buggy:  BytesRef  value  =  parser.bytesOrNull();  context:  String  queryName  =  null;  XContentParser.Token  token;  boolean  idsProvided  =  false;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "values ".equals(currentFieldName))  {  idsProvided  =  true;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {                          BytesRef  value  =  parser.bytesOrNull();                          BytesRef  value  =  parser.utf8BytesOrNull();  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");  }  ids.add(value);  }  }  else  if  ( "types ".equals(currentFieldName)  ||   "type ".equals(currentFieldName))  {  types  =  new  ArrayList<>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  	BytesRef  value  =  parser.utf8BytesOrNull();  
libgdx_69925478def37cf08d50c9165af8fdaa2e926c96	buggy:  config.useGL20  =  true;  context:  public  class  GdxInvadersAndroid  extends  AndroidApplication  {  public  void  onCreate  (Bundle  savedInstanceState)  {  super.onCreate(savedInstanceState);  setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);  AndroidApplicationConfiguration  config  =  new  AndroidApplicationConfiguration();  config.useWakelock  =  true;  config.useGL20  =  true;  config.useGL20  =  false;  initialize(new  GdxInvaders(),  config);  }  }  	config.useGL20  =  false;  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  public  class  FsImmutableBlobContainer  extends  AbstractFsBlobContainer  implements  ImmutableBlobContainer  {  public  FsImmutableBlobContainer(FsBlobStore  blobStore,  BlobPath  blobPath,  File  path)  {  super(blobStore,  blobPath,  path);  }          blobStore.executorService().execute(new  Runnable()  {          blobStore.executor().execute(new  Runnable()  {  File  file  =  new  File(path,  blobName);  RandomAccessFile  raf;  try  {  raf  =  new  RandomAccessFile(file,   "rw ");  raf.setLength(0);  }  catch  (Exception  e)  {  	blobStore.executor().execute(new  Runnable()  {  
elasticsearch_fdbcec8a84945626cc1db76e7c52c4bdb4c95b6a	buggy:  .put( "gateway.type ",   "fs ")  context:  }  }  public  static  void  main(String[]  args)  throws  Exception  {  System.setProperty( "es.logger.prefix ",   " ");  int  numberOfNodes  =  2;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.shard.check_index ",  true)                  .put( "gateway.type ",   "fs ")                  .put( "gateway.type ",   "local ")  .put( "gateway.recover_after_nodes ",  numberOfNodes)  .put( "index.number_of_shards ",  1)  .build();  FullRestartStressTest  test  =  new  FullRestartStressTest()  .settings(settings)  .period(TimeValue.timeValueMinutes(20))  .clearNodeWork(false)  //  only  applies  to  shared  gateway  	.put( "gateway.type ",   "local ")  
libgdx_9ef257986e7604c477b540bfca662845d114099c	buggy:  config.useGL20  =  false;  context:  public  class  GdxInvadersAndroid  extends  AndroidApplication  {  public  void  onCreate  (Bundle  savedInstanceState)  {  super.onCreate(savedInstanceState);  setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE);  AndroidApplicationConfiguration  config  =  new  AndroidApplicationConfiguration();  config.useWakelock  =  true;  config.useGL20  =  false;  config.useGL20  =  true;  initialize(new  GdxInvaders(),  config);  }  }  	config.useGL20  =  true;  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  context:  Settings  settings  =  EMPTY_SETTINGS;  Store  store  =  new  ByteBufferStore(shardId,  settings,  null,  new  ByteBufferCache(settings));  store.deleteContent();  ThreadPool  threadPool  =  new  ThreadPool();  SnapshotDeletionPolicy  deletionPolicy  =  new  SnapshotDeletionPolicy(new  KeepOnlyLastDeletionPolicy(shardId,  settings));          Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),          Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog ")),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  new  ConcurrentMergeSchedulerProvider(shardId,  settings),  new  AnalysisService(shardId.index()),  new  SimilarityService(shardId.index()),  new  NoneBloomCache(shardId.index()));  engine.start();  SimpleEngineBenchmark  benchmark  =  new  SimpleEngineBenchmark(store,  engine)  .numberOfContentItems(1000)  .searcherThreads(50).searcherIterations(10000)  .writerThreads(10).writerIterations(10000)  .refreshSchedule(new  TimeValue(1,  TimeUnit.SECONDS))  	Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog ")),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  
elasticsearch_35755cd8a4b4c5a829b47f9be07dfa64ccbfffe0	buggy:  return  new  InternalSearchResponse(new  InternalSearchHits(new  InternalSearchHit[0],  0,  0),  null,  null,  null,  false);  context:  public  class  InternalSearchResponse  implements  Streamable,  ToXContent  {  public  static  InternalSearchResponse  empty()  {          return  new  InternalSearchResponse(new  InternalSearchHits(new  InternalSearchHit[0],  0,  0),  null,  null,  null,  false);          return  new  InternalSearchResponse(InternalSearchHits.empty(),  null,  null,  null,  false);  }  private  InternalSearchHits  hits;  private  InternalFacets  facets;  private  InternalAggregations  aggregations;  	return  new  InternalSearchResponse(InternalSearchHits.empty(),  null,  null,  null,  false);  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  .put( "index.engine.robin.refreshInterval ",   "-1 ")  context:  public  class  NestedSearchBenchMark  {  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()                  .put( "index.engine.robin.refreshInterval ",   "-1 ")                  .put( "index.refresh_interval ",   "-1 ")  .put( "gateway.type ",   "local ")  .put(SETTING_NUMBER_OF_SHARDS,  1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)  .build();  Node  node1  =  nodeBuilder()  .settings(settingsBuilder().put(settings).put( "name ",   "node1 "))  .node();  	.put( "index.refresh_interval ",   "-1 ")  
elasticsearch_81fd17b03549ead9e2c7ca1a0a7f8addcc721182	buggy:  if  (map.containsKey( "delete ")  &&  map.get( "deleted ").equals( "true "))  {  context:  }  String  seq  =  map.get( "seq ").toString();  String  id  =  map.get( "id ").toString();  if  (id.startsWith( "_design/ "))  {  return  seq;  }          if  (map.containsKey( "delete ")  &&  map.get( "deleted ").equals( "true "))  {          if  (map.containsKey( "deleted ")  &&  map.get( "deleted ").equals(Boolean.TRUE))  {  bulk.add(deleteRequest(indexName).type(typeName).id(id));  }  else  if  (map.containsKey( "doc "))  {  Map<String,  Object>  doc  =  (Map<String,  Object>)  map.get( "doc ");  bulk.add(indexRequest(indexName).type(typeName).id(id).source(doc));  }  else  {  }  return  seq;  	if  (map.containsKey( "deleted ")  &&  map.get( "deleted ").equals(Boolean.TRUE))  {  
libgdx_b2502762d7f643c89a023de9c31a4ccddeaf5ad1	buggy:  }  else  if  (primitiveType  !=  GL10.GL_POINTS)  {  context:  final  short  i001  =  vertex(corner001);  final  short  i101  =  vertex(corner101);  final  short  i111  =  vertex(corner111);  final  short  i011  =  vertex(corner011);  if  (primitiveType  ==  GL10.GL_LINES)  {  ensureIndices(24);  rect(i000,  i100,  i110,  i010);  rect(i101,  i001,  i011,  i111);  index(i000,  i001,  i010,  i011,  i110,  i111,  i100,  i101);  }  else  if  (primitiveType  !=  GL10.GL_POINTS)  {  }  else  if  (primitiveType  ==  GL10.GL_POINTS)  {  ensureRectangleIndices(2);  rect(i000,  i100,  i110,  i010);  rect(i101,  i001,  i011,  i111);  }  else  {  //  GL10.GL_TRIANGLES  ensureRectangleIndices(6);  rect(i000,  i100,  i110,  i010);  rect(i101,  i001,  i011,  i111);  rect(i000,  i010,  i011,  i001);  	}  else  if  (primitiveType  ==  GL10.GL_POINTS)  {  
elasticsearch_01d8305af3dc277753eaee7c9c2c6d417fc9e01b	buggy:  throw  new  SettingsException( "Failed  to  load  settings  from  [ "  +  source  +   "] ");  context:  public  Builder  loadFromSource(String  source)  {  SettingsLoader  settingsLoader  =  SettingsLoaderFactory.loaderFromSource(source);  try  {  Map<String,  String>  loadedSettings  =  settingsLoader.load(source);  put(loadedSettings);  }  catch  (Exception  e)  {                  throw  new  SettingsException( "Failed  to  load  settings  from  [ "  +  source  +   "] ");                  throw  new  SettingsException( "Failed  to  load  settings  from  [ "  +  source  +   "] ",  e);  }  return  this;  }  	throw  new  SettingsException( "Failed  to  load  settings  from  [ "  +  source  +   "] ",  e);  
libgdx_1714ea76ecc275f8872e0494ce88a3885d48f143	buggy:  body.applyCentralForce(Vector3.tmp.set(0f,  8.0f  +  (float)(6.0  *  Math.random()),  0f));  context:  public  void  onInternalTick  (btDynamicsWorld  dynamicsWorld,  float  timeStep)  {  btCollisionObjectArray  objs  =  dynamicsWorld.getCollisionObjectArray();  dynamicsWorld.clearForces();  int  idx  =  0;  for  (int  i  =  0;  i  <  objs.size();  i++)  {  btRigidBody  body  =  (btRigidBody)(objs.at(i));  if  (body  ==  null  ||  body.isStaticOrKinematicObject())  continue;  body.applyGravity();  body.applyCentralForce(Vector3.tmp.set(0f,  8.0f  +  (float)(6.0  *  Math.random()),  0f));  body.applyCentralForce(tmpV1.set(0f,  8.0f  +  (float)(6.0  *  Math.random()),  0f));  idx++;  }  }  }  final  int  BOXCOUNT_X  =  5;  final  int  BOXCOUNT_Y  =  5;  final  int  BOXCOUNT_Z  =  1;  	body.applyCentralForce(tmpV1.set(0f,  8.0f  +  (float)(6.0  *  Math.random()),  0f));  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  position.add(facing.mul((SPEED  +  random_speed)  *  delta));  context:  public  void  draw(SpriteBatch  spriteBatch)  {  super.draw(spriteBatch);  delta  =  Math.min(0.06f,  Gdx.graphics.getDeltaTime());  since_alive  +=  delta;  facing.rotate((SPEED  +  random_speed)  *  delta).nor();  position.add(facing.mul((SPEED  +  random_speed)  *  delta));  position.add(facing.scl((SPEED  +  random_speed)  *  delta));  this.setPosition(position.x,  position.y);  if  (since_alive  <  FADE_TIME)  {  super.setColor(1,  1,  1,  Math.min((since_alive  /  FADE_TIME)  *  random_opacity,  random_opacity));  }  else  {  this.setColor(1,  1,  1,  Math.min(1  -  (since_alive  -  LIFETIME  +  FADE_TIME)  /  FADE_TIME,  1)  *  random_opacity);  }  if  (since_alive  >  LIFETIME)  {  	position.add(facing.scl((SPEED  +  random_speed)  *  delta));  
elasticsearch_cf51fbcdc6f7914ada4c4e70ea81f81bb33da178	buggy:  .put( "gateway.hdfs.path ",   "work/hdfs/gateway ")  context:  node.close();  node  =  buildNode().start();  }  private  Node  buildNode()  {  Settings  settings  =  settingsBuilder()  .put( "gateway.type ",   "hdfs ")  .put( "gateway.hdfs.uri ",   "file:/// ")                  .put( "gateway.hdfs.path ",   "work/hdfs/gateway ")                  .put( "gateway.hdfs.path ",   "data/hdfs/gateway ")  .build();  return  nodeBuilder().settings(settingsBuilder().put(settings).put( "node.name ",   "node1 ")).build();  }  node.stop();  ((InternalNode)  node).injector().getInstance(Gateway.class).reset();  node.close();  	.put( "gateway.hdfs.path ",   "data/hdfs/gateway ")  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  validateQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);  context:  ValidateQueryRequest  validateQueryRequest  =  new  ValidateQueryRequest(RestActions.splitIndices(request.param( "index ")));  validateQueryRequest.listenerThreaded(false);  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  validateQueryRequest.operationThreading(operationThreading);  if  (request.hasContent())  {                  validateQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);                  validateQueryRequest.query(request.content(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  validateQueryRequest.query(source);  }  else  {  BytesReference  querySource  =  RestActions.parseQuerySource(request);  if  (querySource  !=  null)  {  validateQueryRequest.query(querySource,  false);  	validateQueryRequest.query(request.content(),  request.contentUnsafe());  
libgdx_504d68c027e371fe01cf897125e2fd8c20339b39	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),  config);  context:  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),  config);  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  
elasticsearch_acf17b4e39ccfb28e1ac13ba48e37c4f4a96516a	buggy:  logger.debug( "Updating  cluster  state  version  {}:  {} ",  newClusterState.version(),  newClusterState);  context:  if  (newClusterState.nodes().localNodeMaster())  {  discoveryService.publish(newClusterState);  }                  logger.debug( "Updating  cluster  state  version  {}:  {} ",  newClusterState.version(),  newClusterState);                  logger.debug( "Updating  cluster  state  version  {} ",  newClusterState.version());  clusterState  =  newClusterState;  for  (ClusterStateListener  listener  :  priorityClusterStateListeners)  {  listener.clusterChanged(clusterChangedEvent);  }  for  (ClusterStateListener  listener  :  clusterStateListeners)  {  listener.clusterChanged(clusterChangedEvent);  }  	logger.debug( "Updating  cluster  state  version  {} ",  newClusterState.version());  
libgdx_fedd6a44fa6f0a2f141368b66981163f31ae15c7	buggy:  GL20  gl  =  Gdx.graphics.getGL20();  context:  int  coords[]  =  new  int[SPRITES  *  2];  int  coords2[]  =  new  int[SPRITES  *  2];  Color  col  =  new  Color(1,  1,  1,  0.6f);  Mesh  mesh;  float  vertices[]  =  new  float[SPRITES  *  6  *  (2  +  2  +  4)];  public  void  render  ()  {  GL20  gl  =  Gdx.graphics.getGL20();  GL20  gl  =  Gdx.gl20;  gl.glClearColor(0.7f,  0.7f,  0.7f,  1);  gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  float  begin  =  0;  float  end  =  0;  float  draw1  =  0;  float  draw2  =  0;  float  drawText  =  0;  	GL20  gl  =  Gdx.gl20;  
elasticsearch_6166911d8aa17ac098d251cc6e65109471c1df6f	buggy:  int  count  =  100;  context:  public  void  run()  {  uuidSet  =  verifyUUIDSet(count,  uuidSource);  }  }  public  void  testUUIDThreaded(UUIDGenerator  uuidSource)  {  HashSet<UUIDGenRunner>  runners  =  new  HashSet<>();  HashSet<Thread>  threads  =  new  HashSet<>();          int  count  =  100;          int  count  =  20;  int  uuids  =  10000;  for  (int  i  =  0;  i  <  count;  ++i)  {  UUIDGenRunner  runner  =  new  UUIDGenRunner(uuids,  uuidSource);  Thread  t  =  new  Thread(runner);  threads.add(t);  runners.add(runner);  }  for  (Thread  t  :  threads)  {  	int  count  =  20;  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  Array<Asset>  assets  =  new  Array<Asset>();  context:  public  void  onProgress  (double  amount)  {  }  public  void  onFailure  ()  {  callback.error(assetFileUrl);  }  public  void  onSuccess  (String  result)  {  String[]  lines  =  result.split( "\n ");  Array<Asset>  assets  =  new  Array<Asset>();  Array<Asset>  assets  =  new  Array<Asset>(lines.length);  for  (String  line  :  lines)  {  String[]  tokens  =  line.split( ": ");  if  (tokens.length  !=  4)  {  throw  new  GdxRuntimeException( "Invalid  assets  description  file. ");  }  AssetType  type  =  AssetType.Text;  if  (tokens[0].equals( "i "))  type  =  AssetType.Image;  if  (tokens[0].equals( "b "))  type  =  AssetType.Binary;  	Array<Asset>  assets  =  new  Array<Asset>(lines.length);  
elasticsearch_64358948eff4e3b75134dc9e2776e9dc5a39e156	buggy:  AsyncAction.this.shardFailures.add(new  ShardSearchFailure(t));  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  public  void  onFailure(Throwable  t)  {  if  (logger.isDebugEnabled())  {  }                      AsyncAction.this.shardFailures.add(new  ShardSearchFailure(t));                      AsyncAction.this.addShardFailure(new  ShardSearchFailure(t));  successulOps.decrementAndGet();  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  	AsyncAction.this.addShardFailure(new  ShardSearchFailure(t));  
elasticsearch_383945416866849139755c6761ad162faaadcbe0	buggy:  IntArray  hashes  =  BigArrays.newIntArray(numberOfValues);  context:  size  +=  termOrdToBytesOffset.ramBytesUsed();  this.size  =  size;  }  return  size;  }  private  final  IntArray  getHashes()  {  if  (hashes  ==  null)  {  long  numberOfValues  =  termOrdToBytesOffset.size();              IntArray  hashes  =  BigArrays.newIntArray(numberOfValues);              IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(numberOfValues);  BytesRef  scratch  =  new  BytesRef();  for  (long  i  =  0;  i  <  numberOfValues;  i++)  {  bytes.fill(scratch,  termOrdToBytesOffset.get(i));  hashes.set(i,  scratch.hashCode());  }  this.hashes  =  hashes;  }  return  hashes;  	IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(numberOfValues);  
elasticsearch_a414e4f2f3ce03c1cd80ca3ef7d01c370e49d5a7	buggy:  cluster().ensureAtLeastNumNodes(1  +  replica);  context:  assertThat(getResponse.isExists(),  equalTo(false));  }  }  }  public  void  testBulkIndexingWhileInitializing()  throws  Exception  {  int  replica  =  randomInt(2);          cluster().ensureAtLeastNumNodes(1  +  replica);          cluster().ensureAtLeastNumDataNodes(1  +  replica);  assertAcked(prepareCreate( "test ").setSettings(  ImmutableSettings.builder()  .put(indexSettings())  .put( "index.number_of_replicas ",  replica)  ));  int  numDocs  =  scaledRandomIntBetween(100,  5000);  	cluster().ensureAtLeastNumDataNodes(1  +  replica);  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  .add(updatedState.metaData().index(request.index),  true);  context:  }  }  if  (request.state  ==  State.CLOSE)  {  blocks.addIndexBlock(request.index,  MetaDataStateIndexService.INDEX_CLOSED_BLOCK);  }  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState).blocks(blocks).metaData(newMetaData).build();  if  (request.state  ==  State.OPEN)  {  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable())                                  .add(updatedState.metaData().index(request.index),  true);                                  .addAsNew(updatedState.metaData().index(request.index));  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());  updatedState  =  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  }  final  AtomicInteger  counter  =  new  AtomicInteger(currentState.nodes().size());  final  NodeIndexCreatedAction.Listener  nodeIndexCreatedListener  =  new  NodeIndexCreatedAction.Listener()  {  	.addAsNew(updatedState.metaData().index(request.index));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  this.listener  =  listener;  clusterState  =  clusterService.state();  String[]  nodesIds  =  clusterState.nodes().resolveNodes(request.nodesIds());  this.nodesIds  =  filterNodeIds(clusterState.nodes(),  nodesIds);  this.responses  =  new  AtomicReferenceArray<Object>(this.nodesIds.length);  }  private  void  start()  {  if  (nodesIds.length  ==  0)  {                  threadPool.cached().execute(new  Runnable()  {                  threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  listener.onResponse(newResponse(request,  responses));  }  });  return;  }  TransportRequestOptions  transportRequestOptions  =  TransportRequestOptions.options();  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();  context:  assertThat(bucket,  notNullValue());  assertThat(key(bucket),  equalTo( " "  +  (double)  i));  assertThat(bucket.getKeyAsNumber().intValue(),  equalTo(i));  assertThat(bucket.getDocCount(),  equalTo(1l));  }  }  public  void  emptyAggregation()  throws  Exception  {  prepareCreate( "empty_bucket_idx ").addMapping( "type ",  SINGLE_VALUED_FIELD_NAME,   "type=integer ").execute().actionGet();          List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();          List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field(SINGLE_VALUED_FIELD_NAME,  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  	List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  si  =  new  BytesStreamInput(bos.underlyingBytes(),  0,  bos.size());  context:  public  synchronized  void  onPartial(byte[]  data,  int  offset,  int  size)  throws  IOException  {  if  (ignore)  {  return;  }  bos.write(data,  offset,  size);  if  (bos.size()  <  4)  {  return;  }                      BytesStreamInput  si  =  new  BytesStreamInput(bos.underlyingBytes(),  0,  bos.size());                      BytesStreamInput  si  =  new  BytesStreamInput(bos.underlyingBytes(),  0,  bos.size(),  false);  int  position;  while  (true)  {  try  {  position  =  si.position();  if  (position  +  4  >  bos.size())  {  break;  }  int  opSize  =  si.readInt();  	BytesStreamInput  si  =  new  BytesStreamInput(bos.underlyingBytes(),  0,  bos.size(),  false);  
elasticsearch_64d42782a94395382b2dac4170f50830f5cfe7fa	buggy:  DocsEnum  docsEnum  =  termsEnum.docs(acceptDocs,  null);  context:  public  DocIdSet  getDocIdSet(AtomicReaderContext  context,  Bits  acceptDocs)  throws  IOException  {  Terms  terms  =  context.reader().terms(term.field());  if  (terms  ==  null)  {  return  null;  }  TermsEnum  termsEnum  =  terms.iterator(null);  if  (!termsEnum.seekExact(term.bytes(),  false))  {  return  null;  }          DocsEnum  docsEnum  =  termsEnum.docs(acceptDocs,  null);          DocsEnum  docsEnum  =  termsEnum.docs(acceptDocs,  null,  DocsEnum.FLAG_NONE);  int  docId  =  docsEnum.nextDoc();  if  (docId  ==  DocsEnum.NO_MORE_DOCS)  {  return  null;  }  final  FixedBitSet  result  =  new  FixedBitSet(context.reader().maxDoc());  for  (;  docId  <  DocsEnum.NO_MORE_DOCS;  docId  =  docsEnum.nextDoc())  {  result.set(docId);  	DocsEnum  docsEnum  =  termsEnum.docs(acceptDocs,  null,  DocsEnum.FLAG_NONE);  
elasticsearch_bb0199572271f464db9c671a553d79e7ef43f6c7	buggy:  Engine.DeleteByQuery  prepareDeleteByQuery(BytesReference  querySource,  @Nullable  String[]  filteringAliases,  String...  types)  throws  ElasticSearchException;  context:  ParsedDocument  create(Engine.Create  create)  throws  ElasticSearchException;  Engine.Index  prepareIndex(SourceToParse  source)  throws  ElasticSearchException;  ParsedDocument  index(Engine.Index  index)  throws  ElasticSearchException;  Engine.Delete  prepareDelete(String  type,  String  id,  long  version)  throws  ElasticSearchException;  void  delete(Engine.Delete  delete)  throws  ElasticSearchException;      Engine.DeleteByQuery  prepareDeleteByQuery(BytesReference  querySource,  @Nullable  String[]  filteringAliases,  String...  types)  throws  ElasticSearchException;      Engine.DeleteByQuery  prepareDeleteByQuery(BytesReference  source,  @Nullable  String[]  filteringAliases,  String...  types)  throws  ElasticSearchException;  void  deleteByQuery(Engine.DeleteByQuery  deleteByQuery)  throws  ElasticSearchException;  Engine.GetResult  get(Engine.Get  get)  throws  ElasticSearchException;  void  refresh(Engine.Refresh  refresh)  throws  ElasticSearchException;  void  flush(Engine.Flush  flush)  throws  ElasticSearchException;  	Engine.DeleteByQuery  prepareDeleteByQuery(BytesReference  source,  @Nullable  String[]  filteringAliases,  String...  types)  throws  ElasticSearchException;  
elasticsearch_228778ceedf4b9cc983971d07a55a3d595b6ee00	buggy:  posLefts  =  bigArrays.resize(posLefts,  tops.size());  context:  public  void  collect(int  docId,  long  owningBucketOrdinal)  throws  IOException  {  if  (owningBucketOrdinal  >=  tops.size())  {  long  from  =  tops.size();  tops  =  bigArrays.grow(tops,  owningBucketOrdinal  +  1);  tops.fill(from,  tops.size(),  Double.NEGATIVE_INFINITY);  bottoms  =  bigArrays.resize(bottoms,  tops.size());  bottoms.fill(from,  bottoms.size(),  Double.NEGATIVE_INFINITY);  posLefts  =  bigArrays.resize(posLefts,  tops.size());  posLefts.fill(from,  posLefts.size(),  Double.NEGATIVE_INFINITY);              posLefts  =  bigArrays.resize(posLefts,  tops.size());              posRights  =  bigArrays.resize(posRights,  tops.size());  posRights.fill(from,  posRights.size(),  Double.NEGATIVE_INFINITY);  negLefts  =  bigArrays.resize(negLefts,  tops.size());  negLefts.fill(from,  negLefts.size(),  Double.NEGATIVE_INFINITY);  negRights  =  bigArrays.resize(negRights,  tops.size());  negRights.fill(from,  negRights.size(),  Double.NEGATIVE_INFINITY);  }  values.setDocument(docId);  	posRights  =  bigArrays.resize(posRights,  tops.size());  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  return  new  ConstantScoreQuery(termFilter(value,  context));  context:  public  boolean  useTermQueryWithQueryString()  {  return  true;  }  public  Query  termQuery(Object  value,  @Nullable  QueryParseContext  context)  {  if  (fieldType.indexed()  ||  context  ==  null)  {  return  super.termQuery(value,  context);  }          return  new  ConstantScoreQuery(termFilter(value,  context));          return  new  XLuceneConstantScoreQuery(termFilter(value,  context));  }  public  Filter  termFilter(Object  value,  @Nullable  QueryParseContext  context)  {  if  (fieldType.indexed()  ||  context  ==  null)  {  return  super.termFilter(value,  context);  }  return  new  TermsFilter(UidFieldMapper.NAME,  Uid.createTypeUids(context.queryTypes(),  value));  	return  new  XLuceneConstantScoreQuery(termFilter(value,  context));  
libgdx_34c3074b5eb811cd46c8f61a0ec9d9caa9647a85	buggy:  nativesLoaded  =  loadLibrary( "gdx.dll ",   "gdx64.dll ");  context:  static  public  void  load  ()  {  if  (nativesLoaded)  return;  String  vm  =  System.getProperty( "java.vm.name ");  if  (vm  ==  null  ||  !vm.contains( "Dalvik "))  {  if  (isWindows)  {  nativesLoaded  =  loadLibrary( "gdx.dll ",   "gdx64.dll ");  nativesLoaded  =  loadLibrary( "gdx.dll ",   "gdx-64.dll ");  }  else  if  (isMac)  {  nativesLoaded  =  loadLibrary( "libgdx.dylib ",   "libgdx.dylib ");  }  else  if  (isLinux)  {  nativesLoaded  =  loadLibrary( "libgdx.so ",   "libgdx-64.so ");  }  if  (nativesLoaded)  return;  }  	nativesLoaded  =  loadLibrary( "gdx.dll ",   "gdx-64.dll ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<Throwable>();  context:  response.phase1TotalSize  =  totalSize;  response.phase1ExistingTotalSize  =  existingTotalSize;  RecoveryFilesInfoRequest  recoveryInfoFilesRequest  =  new  RecoveryFilesInfoRequest(request.recoveryId(),  request.shardId(),  response.phase1FileNames,  response.phase1FileSizes,  response.phase1ExistingFileNames,  response.phase1ExistingFileSizes,  response.phase1TotalSize,  response.phase1ExistingTotalSize);  transportService.submitRequest(request.targetNode(),  RecoveryTarget.Actions.FILES_INFO,  recoveryInfoFilesRequest,  TransportRequestOptions.options().withTimeout(internalActionTimeout),  EmptyTransportResponseHandler.INSTANCE_SAME).txGet();  final  CountDownLatch  latch  =  new  CountDownLatch(response.phase1FileNames.size());                      final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<Throwable>();                      final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<>();  int  fileIndex  =  0;  for  (final  String  name  :  response.phase1FileNames)  {  ThreadPoolExecutor  pool;  long  fileSize  =  response.phase1FileSizes.get(fileIndex);  if  (fileSize  >  recoverySettings.SMALL_FILE_CUTOFF_BYTES)  {  pool  =  recoverySettings.concurrentStreamPool();  }  else  {  pool  =  recoverySettings.concurrentSmallFileStreamPool();  	final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<>();  
elasticsearch_7ed68a5c30e1a94d1938aef513e343f508eadf15	buggy:  threadPool.executor(ThreadPool.Names.MANAGEMENT).execute(new  Runnable()  {  context:  }  reschedule();  }  private  void  reschedule()  {  future  =  threadPool.schedule(interval,  ThreadPool.Names.SAME,  this);  }  private  void  asyncFlushAndReschedule()  {              threadPool.executor(ThreadPool.Names.MANAGEMENT).execute(new  Runnable()  {              threadPool.executor(ThreadPool.Names.FLUSH).execute(new  Runnable()  {  public  void  run()  {  try  {  indexShard.flush(new  Engine.Flush());  }  catch  (IllegalIndexShardStateException  e)  {  }  catch  (FlushNotAllowedEngineException  e)  {  	threadPool.executor(ThreadPool.Names.FLUSH).execute(new  Runnable()  {  
libgdx_f9e38a6c2e320c8dd5ba2e97377830c7e8a56b3e	buggy:  cam.position.set(bounds.getCenter().cpy().add(len,  len,  len));  context:  if(fileName.endsWith( ".dae "))  model  =  ColladaLoader.loadStillModel(Gdx.files.internal(fileName));  else  throw  new  GdxRuntimeException( "Unknown  file  format  ' "  +  fileName  +   "' ");  if(textureFileName  !=  null)  texture  =  new  Texture(Gdx.files.internal(textureFileName));  hasNormals  =  hasNormals();  model.getBoundingBox(bounds);  float  len  =  bounds.getDimensions().len();  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(bounds.getCenter().cpy().add(len,  len,  len));  cam.position.set(bounds.getCenter().cpy().add(len*2,  len*2,  len*2));  cam.lookAt(bounds.getCenter().x,  bounds.getCenter().y,  bounds.getCenter().z);  cam.near  =  0.1f;  cam.far  =  1000;  renderer  =  new  ImmediateModeRenderer();  }  private  boolean  hasNormals()  {  	cam.position.set(bounds.getCenter().cpy().add(len*2,  len*2,  len*2));  
libgdx_89007d7e693effb9457dfb1b06d5de2427b78670	buggy:  protected  void  clicked  (Object  object)  {  context:  slider.addListener(new  ChangeListener()  {  public  void  changed  (ChangeEvent  event,  Actor  actor)  {  Gdx.app.log( "UITest ",   "slider:   "  +  slider.getValue());  }  });  iconButton.addListener(new  ChangeListener()  {  public  void  changed  (ChangeEvent  event,  Actor  actor)  {  new  Dialog( "Some  Dialog ",  skin,   "dialog ")  {  protected  void  clicked  (Object  object)  {  protected  void  result  (Object  object)  {  }  }.text( "Are  you  enjoying  this  demo? ").button( "Yes ",  true).button( "No ",  false).key(Keys.ENTER,  true)  .key(Keys.ESCAPE,  false).show(stage);  }  });  }  	protected  void  result  (Object  object)  {  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  listeners[0]  ==  null;  context:  ImmutableSettings.Builder  settings  =  settingsBuilder();  settings.put(BalancedShardsAllocator.SETTING_INDEX_BALANCE_FACTOR,  0.2);  settings.put(BalancedShardsAllocator.SETTING_SHARD_BALANCE_FACTOR,  0.3);  settings.put(BalancedShardsAllocator.SETTING_PRIMARY_BALANCE_FACTOR,  0.5);  settings.put(BalancedShardsAllocator.SETTING_THRESHOLD,  2.0);  final  NodeSettingsService.Listener[]  listeners  =  new  NodeSettingsService.Listener[1];  NodeSettingsService  service  =  new  NodeSettingsService(settingsBuilder().build())  {  public  void  addListener(Listener  listener)  {                  assert  listeners[0]  ==  null;                  assertNull( "addListener  was  called  twice  while  only  one  time  was  expected ",  listeners[0]);  listeners[0]  =  listener;  }  };  BalancedShardsAllocator  allocator  =  new  BalancedShardsAllocator(settings.build(),  service);  assertThat(allocator.getIndexBalance(),  Matchers.equalTo(0.2f));  assertThat(allocator.getShardBalance(),  Matchers.equalTo(0.3f));  assertThat(allocator.getPrimaryBalance(),  Matchers.equalTo(0.5f));  	assertNull( "addListener  was  called  twice  while  only  one  time  was  expected ",  listeners[0]);  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  request.opType(opType);  context:  public  IndexRequestBuilder  setOpType(IndexRequest.OpType  opType)  {  request.opType(opType);  return  this;  }  public  IndexRequestBuilder  setOpType(String  opType)  {          request.opType(opType);          request.opType(IndexRequest.OpType.fromString(opType));  return  this;  }  public  IndexRequestBuilder  setCreate(boolean  create)  {  request.create(create);  	request.opType(IndexRequest.OpType.fromString(opType));  
elasticsearch_6bc3a744a1a4d516a8839470e3c4a474b2d9999d	buggy:  final  Set<IntsRef>  ref  =  SpecialOperations.getFiniteStrings(automaton,  -1);  context:  }  public  TokenStreamToAutomaton  getTokenStreamToAutomaton()  {  final  TokenStreamToAutomaton  tsta  =  super.getTokenStreamToAutomaton();  tsta.setUnicodeArcs(unicodeAware);  return  tsta;  }  Automaton  toLevenshteinAutomata(Automaton  automaton)  {          final  Set<IntsRef>  ref  =  SpecialOperations.getFiniteStrings(automaton,  -1);          final  Set<IntsRef>  ref  =  XSpecialOperations.getFiniteStrings(automaton,  -1);  Automaton  subs[]  =  new  Automaton[ref.size()];  int  upto  =  0;  for  (IntsRef  path  :  ref)  {  if  (path.length  <=  nonFuzzyPrefix  ||  path.length  <  minFuzzyLength)  {  subs[upto]  =  BasicAutomata.makeString(path.ints,  path.offset,  path.length);  upto++;  }  else  {  Automaton  prefix  =  BasicAutomata.makeString(path.ints,  path.offset,  nonFuzzyPrefix);  	final  Set<IntsRef>  ref  =  XSpecialOperations.getFiniteStrings(automaton,  -1);  
libgdx_4279401a12b90b72315e40f6a339619cca70b067	buggy:  int  sizeNeeded  =  size  +  length  -  offset;  context:  throw  new  IllegalArgumentException( "offset  +  length  must  be  <=  size:   "  +  offset  +   "  +   "  +  length  +   "  <=   "  +  array.size);  addAll(array.items,  offset,  length);  }  public  void  addAll  (float[]  array)  {  addAll(array,  0,  array.length);  }  public  void  addAll  (float[]  array,  int  offset,  int  length)  {  float[]  items  =  this.items;  int  sizeNeeded  =  size  +  length  -  offset;  int  sizeNeeded  =  size  +  length;  if  (sizeNeeded  >=  items.length)  items  =  resize(Math.max(8,  (int)(sizeNeeded  *  1.75f)));  System.arraycopy(array,  offset,  items,  size,  length);  size  +=  length;  }  public  float  get  (int  index)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException(String.valueOf(index));  return  items[index];  	int  sizeNeeded  =  size  +  length;  
libgdx_ae45ffe4ebe41482453af5e1245f4a93f57ae3b4	buggy:  font  =  new  BitmapFont();  context:  float  TICK  =  1  /  60f;  public  void  create()  {  world  =  new  World(new  Vector2(0,  -40),  true);  renderer  =  new  Box2DDebugRenderer();  cam  =  new  OrthographicCamera(28,  20);  createWorld();  Gdx.input.setInputProcessor(this);  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  }  private  void  createWorld()  {  float  y1  =  1;  //(float)Math.random()  *  0.1f  +  1;  float  y2  =  y1;  for(int  i  =  0;  i  <  50;  i++)  {  Body  ground  =  createEdge(BodyType.StaticBody,  -50  +  i  *  2,  y1,  -50  +  i  *  2  +  2,  y2,  0);  y1  =  y2;  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_3b9da384c3e8f375ee604f7d1ff9932a8046623b	buggy:  docMapper.parse(SourceToParse.source(getResponse.source()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  context:  listener.onFailure(e);  }  });  }  private  void  parseSource(GetResponse  getResponse,  final  BoolQueryBuilder  boolBuilder,  DocumentMapper  docMapper,  final  Set<String>  fields,  final  MoreLikeThisRequest  request)  {  if  (getResponse.source()  ==  null)  {  return;  }          docMapper.parse(SourceToParse.source(getResponse.source()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {          docMapper.parse(SourceToParse.source(getResponse.sourceRef().bytes(),  getResponse.sourceRef().offset(),  getResponse.sourceRef().length()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  if  (fieldMapper  instanceof  InternalMapper)  {  return  true;  }  String  value  =  fieldMapper.valueAsString(field);  if  (value  ==  null)  {  return  false;  }  	docMapper.parse(SourceToParse.source(getResponse.sourceRef().bytes(),  getResponse.sourceRef().offset(),  getResponse.sourceRef().length()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  IntArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  IntArrayAtomicFieldData.WithOrdinals(  values.toArray(new  int[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  IntValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);  context:  public  class  PreBuiltAnalyzerProviderFactory  implements  AnalyzerProviderFactory  {  private  final  PreBuiltAnalyzerProvider  analyzerProvider;  public  PreBuiltAnalyzerProviderFactory(String  name,  AnalyzerScope  scope,  Analyzer  analyzer)  {  analyzerProvider  =  new  PreBuiltAnalyzerProvider(name,  scope,  analyzer);  }  public  AnalyzerProvider  create(String  name,  Settings  settings)  {          Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);          Version  indexVersion  =  Version.indexCreated(settings);  if  (!Version.CURRENT.equals(indexVersion))  {  PreBuiltAnalyzers  preBuiltAnalyzers  =  PreBuiltAnalyzers.getOrDefault(name,  null);  if  (preBuiltAnalyzers  !=  null)  {  Analyzer  analyzer  =  preBuiltAnalyzers.getAnalyzer(indexVersion);  return  new  PreBuiltAnalyzerProvider(name,  AnalyzerScope.INDICES,  analyzer);  }  }  	Version  indexVersion  =  Version.indexCreated(settings);  
elasticsearch_43a5cbe9bee92898056db7ba0db2d548514a16bd	buggy:  recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard.shardId());  context:  InternalIndexService  indexService  =  (InternalIndexService)  indicesService.indexServiceSafe(request.index());  InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shardSafe(request.shardId());  ShardRouting  shardRouting  =  indexShard.routingEntry();  ShardRecoveryResponse  shardRecoveryResponse  =  new  ShardRecoveryResponse(shardRouting.index(),  shardRouting.id());  RecoveryState  state;  RecoveryStatus  recoveryStatus  =  indexShard.recoveryStatus();  if  (recoveryStatus  ==  null)  {              recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard.shardId());              recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard);  }  if  (recoveryStatus  !=  null)  {  state  =  recoveryStatus.recoveryState();  }  else  {  IndexShardGatewayService  gatewayService  =  indexService.shardInjector(request.shardId()).getInstance(IndexShardGatewayService.class);  state  =  gatewayService.recoveryState();  	recoveryStatus  =  recoveryTarget.recoveryStatus(indexShard);  
libgdx_c966a7d92ca4c1b2bccb30958b51de6bc05c5361	buggy:  public  void  setIcon  (Pixmap  pixmap)  {  context:  public  boolean  setDisplayMode  (int  width,  int  height,  boolean  fullscreen)  {  return  false;  }  public  void  setTitle  (String  title)  {  }  public  void  setIcon  (Pixmap  pixmap)  {  public  void  setIcon  (Pixmap[]  pixmap)  {  }  private  class  AndroidDisplayMode  extends  DisplayMode  {  protected  AndroidDisplayMode  (int  width,  int  height,  int  refreshRate,  int  bitsPerPixel)  {  super(width,  height,  refreshRate,  bitsPerPixel);  }  }  	public  void  setIcon  (Pixmap[]  pixmap)  {  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher()  :  searcher;  context:  SearchContext  createContext(ShardSearchRequest  request)  throws  ElasticSearchException  {  return  createContext(request,  null);  }  SearchContext  createContext(ShardSearchRequest  request,  @Nullable  Engine.Searcher  searcher)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());          Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher()  :  searcher;          Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher( "search ")  :  searcher;  SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  cacheRecycler);  SearchContext.setCurrent(context);  try  {  context.scroll(request.scroll());  parseSource(context,  request.source());  parseSource(context,  request.extraSource());  	Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher( "search ")  :  searcher;  
elasticsearch_4cf1b3ed9ee2a77c393f7fc5770015c8531f892c	buggy:  Map<String,  String>  loadedSettings  =  settingsLoader.load(Streams.copyToString(new  InputStreamReader(is)));  context:  }  }  public  Builder  loadFromStream(String  resourceName,  InputStream  is)  throws  SettingsException  {  SettingsLoader  settingsLoader  =  SettingsLoaderFactory.loaderFromResource(resourceName);  try  {                  Map<String,  String>  loadedSettings  =  settingsLoader.load(Streams.copyToString(new  InputStreamReader(is)));                  Map<String,  String>  loadedSettings  =  settingsLoader.load(Streams.copyToString(new  InputStreamReader(is,   "UTF-8 ")));  putAll(loadedSettings);  }  catch  (IOException  e)  {  throw  new  SettingsException( "Failed  to  load  settings  from  [ "  +  resourceName  +   "] ");  }  return  this;  }  	Map<String,  String>  loadedSettings  =  settingsLoader.load(Streams.copyToString(new  InputStreamReader(is,   "UTF-8 ")));  
elasticsearch_0a3c941947bf95af24eeaf58a5b40d7b5d8e76bf	buggy:  return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  context:  }  protected  NodeStats  newNodeResponse()  {  return  new  NodeStats();  }  protected  NodeStats  nodeOperation(NodeStatsRequest  nodeStatsRequest)  throws  ElasticSearchException  {  NodesStatsRequest  request  =  nodeStatsRequest.request;          return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());          return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.fs(),  request.transport(),  request.http());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeStatsRequest  extends  NodeOperationRequest  {  	return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.fs(),  request.transport(),  request.http());  
libgdx_dcd37bd8e170019f20c808732ca4b1adbd8f2cca	buggy:  if  (TimeUtils.nanoTime()  -  startTime  >  1000000000  /*  1,000,000,000ns  ==  one  second*/  {  context:  public  class  FPSLogger  {  long  startTime;  public  FPSLogger  ()  {  startTime  =  TimeUtils.nanoTime();  }  public  void  log  ()  {  if  (TimeUtils.nanoTime()  -  startTime  >  1000000000  /*  1,000,000,000ns  ==  one  second*/  {  if  (TimeUtils.nanoTime()  -  startTime  >  1000000000)  /*  1,000,000,000ns  ==  one  second*/  {  Gdx.app.log( "FPSLogger ",   "fps:   "  +  Gdx.graphics.getFramesPerSecond());  startTime  =  TimeUtils.nanoTime();  }  }  }  	if  (TimeUtils.nanoTime()  -  startTime  >  1000000000)  /*  1,000,000,000ns  ==  one  second*/  {  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  initialize(new  Bouncy(),  false);  context:  public  class  BouncyAndroid  extends  AndroidApplication  {  public  void  onCreate  (Bundle  savedInstanceState)  {  super.onCreate(savedInstanceState);  initialize(new  Bouncy(),  false);  initialize(new  Bouncy());  }  }  	initialize(new  Bouncy());  
elasticsearch_1615aba114f8f5abd35e7a591865ef33ca81704f	buggy:  if  (parserContext.indexVersionCreated().onOrAfter(Version.V_1_0_0))  {  context:  final  String  propName2  =  Strings.toUnderscoreCase(entry2.getKey());  final  Object  propNode2  =  entry2.getValue();  if  (propName2.equals( "enabled "))  {  builder.omitNorms(!nodeBooleanValue(propNode2));  }  else  if  (propName2.equals(Loading.KEY))  {  builder.normsLoading(Loading.parse(nodeStringValue(propNode2,  null),  null));  }  }  }  else  if  (propName.equals( "omit_term_freq_and_positions "))  {  final  IndexOptions  op  =  nodeBooleanValue(propNode)  ?  IndexOptions.DOCS_ONLY  :  IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;                  if  (parserContext.indexVersionCreated().onOrAfter(Version.V_1_0_0))  {                  if  (parserContext.indexVersionCreated().onOrAfter(Version.V_1_0_0_RC2))  {  throw  new  ElasticsearchParseException( "'omit_term_freq_and_positions'  is  not  supported  anymore  -  use  ['index_options'  :  ' "  +  op.name()  +   "']  instead ");  }  builder.indexOptions(op);  }  else  if  (propName.equals( "index_options "))  {  builder.indexOptions(nodeIndexOptionValue(propNode));  }  else  if  (propName.equals( "analyzer "))  {  NamedAnalyzer  analyzer  =  parserContext.analysisService().analyzer(propNode.toString());  	if  (parserContext.indexVersionCreated().onOrAfter(Version.V_1_0_0_RC2))  {  
elasticsearch_14237317fce4e365aa2e0a88ef59bafd43e73e4e	buggy:  source  =  documentMapper.sourceMapper().value(sourceField);  context:  }  fieldSelector.add(x);  }  return  fieldSelector;  }  private  byte[]  extractSource(Document  doc,  DocumentMapper  documentMapper)  {  byte[]  source  =  null;  Fieldable  sourceField  =  doc.getFieldable(documentMapper.sourceMapper().names().indexName());  if  (sourceField  !=  null)  {              source  =  documentMapper.sourceMapper().value(sourceField);              source  =  documentMapper.sourceMapper().nativeValue(sourceField);  doc.removeField(documentMapper.sourceMapper().names().indexName());  }  return  source;  }  return  new  GetRequest();  }  	source  =  documentMapper.sourceMapper().nativeValue(sourceField);  
elasticsearch_927b4385a83f5cb8525812f415b83e9e6fa34d01	buggy:  mappingsToUpdate.add(Tuple.create(indexRequest.index(),  indexRequest.type()));  context:  op  =  create;  }  indexRequest.version(version);  if  (op.parsedDoc().mappersAdded())  {  if  (mappingsToUpdate  ==  null)  {  mappingsToUpdate  =  Sets.newHashSet();  }                          mappingsToUpdate.add(Tuple.create(indexRequest.index(),  indexRequest.type()));                          mappingsToUpdate.add(Tuple.tuple(indexRequest.index(),  indexRequest.type()));  }  if  (Strings.hasLength(indexRequest.percolate()))  {  if  (ops  ==  null)  {  ops  =  new  Engine.IndexingOperation[request.items().length];  }  ops[i]  =  op;  	mappingsToUpdate.add(Tuple.tuple(indexRequest.index(),  indexRequest.type()));  
libgdx_10e7e5fc9b6ac950684e3e4e2fed55fd944dfdba	buggy:  }  else  if  (Gdx.gl11  !=  null)  {  context:  buffer.flip();  byteBuffer.position(0);  byteBuffer.limit(count  <<  1);  if  (isBound)  {  if  (Gdx.gl11  !=  null)  {  GL11  gl  =  Gdx.gl11;  gl.glBufferSubData(GL11.GL_ELEMENT_ARRAY_BUFFER,  0,  byteBuffer.limit(),  byteBuffer);  }  else  if  (Gdx.gl11  !=  null)  {  }  else  if  (Gdx.gl20  !=  null)  {  GL20  gl  =  Gdx.gl20;  gl.glBufferSubData(GL20.GL_ELEMENT_ARRAY_BUFFER,  0,  byteBuffer.limit(),  byteBuffer);  }  isDirty  =  false;  }  	}  else  if  (Gdx.gl20  !=  null)  {  
libgdx_704b465d333389a1b6f3deb67695ffcaa1239a26	buggy:  return  false;  context:  if  (buffers  ==  null)  return;  if  (sourceID  !=  -1)  {  audio.freeSource(sourceID);  sourceID  =  -1;  }  alDeleteBuffers(buffers);  buffers  =  null;  }  public  boolean  isMono  ()  {  return  false;  return  channels  ==  1;  }  public  int  getLatency  ()  {  return  (int)(secondsPerBuffer  *  bufferCount  *  1000);  }  }  	return  channels  ==  1;  
elasticsearch_7209f9f40bc253adc7479a0ce276b5a4375aa2c4	buggy:  blocks.removeIndexBlock(index,  INDEX_CLOSED_BLOCK);  context:  if  (currentIndexMetaData.getNumberOfShards()  !=  snapshotIndexMetaData.getNumberOfShards())  {  throw  new  SnapshotRestoreException(snapshotId,   "cannot  restore  index  [ "  +  renamedIndex  +   "]  with  [ "  +  currentIndexMetaData.getNumberOfShards()  +   "]  shard  from  snapshot  with  [ "  +  snapshotIndexMetaData.getNumberOfShards()  +   "]  shards ");  }  IndexMetaData.Builder  indexMdBuilder  =  IndexMetaData.builder(snapshotIndexMetaData).state(IndexMetaData.State.OPEN);  indexMdBuilder.version(Math.max(snapshotIndexMetaData.version(),  currentIndexMetaData.version()  +  1));  IndexMetaData  updatedIndexMetaData  =  indexMdBuilder.index(renamedIndex).build();  rtBuilder.addAsRestore(updatedIndexMetaData,  restoreSource);                                  blocks.removeIndexBlock(index,  INDEX_CLOSED_BLOCK);                                  blocks.removeIndexBlock(renamedIndex,  INDEX_CLOSED_BLOCK);  mdBuilder.put(updatedIndexMetaData,  true);  }  for  (int  shard  =  0;  shard  <  snapshotIndexMetaData.getNumberOfShards();  shard++)  {  shards.put(new  ShardId(renamedIndex,  shard),  new  RestoreMetaData.ShardRestoreStatus(clusterService.state().nodes().localNodeId()));  }  }  RestoreMetaData.Entry  restoreEntry  =  new  RestoreMetaData.Entry(snapshotId,  RestoreMetaData.State.INIT,  ImmutableList.copyOf(renamedIndices.keySet()),  shards.build());  	blocks.removeIndexBlock(renamedIndex,  INDEX_CLOSED_BLOCK);  
elasticsearch_a96b294de0d77c945689f4f0101662fbca1174c8	buggy:  throw  new  ZenPingException( "Failed  to  send  ping  request  over  multicast ",  e);  context:  receivedResponses.remove(id);  throw  new  ZenPingException( "Failed  to  serialize  ping  request ",  e);  }  try  {  multicastSocket.send(datagramPacketSend);  if  (logger.isTraceEnabled())  {  }  }  catch  (IOException  e)  {  receivedResponses.remove(id);                  throw  new  ZenPingException( "Failed  to  send  ping  request  over  multicast ",  e);                  throw  new  ZenPingException( "Failed  to  send  ping  request  over  multicast  on   "  +  multicastSocket,  e);  }  }  }  class  MulticastPingResponseRequestHandler  extends  BaseTransportRequestHandler<MulticastPingResponse>  {  static  final  String  ACTION  =   "discovery/zen/multicast ";  	throw  new  ZenPingException( "Failed  to  send  ping  request  over  multicast  on   "  +  multicastSocket,  e);  
elasticsearch_64a01c28c31ba669a637fb497d4df034dc86b63a	buggy:  query.add(new  BooleanClause(mapper.fieldQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));  context:  mapper  =  smartNameFieldMappers.mapper();  if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  }  }  try  {  BooleanQuery  query  =  new  BooleanQuery(disableCoord);  for  (String  value  :  values)  {  if  (mapper  !=  null)  {                      query.add(new  BooleanClause(mapper.fieldQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));                      query.add(new  BooleanClause(mapper.termQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));  }  else  {  query.add(new  TermQuery(new  Term(fieldName,  value)),  BooleanClause.Occur.SHOULD);  }  }  query.setBoost(boost);  Queries.applyMinimumShouldMatch(query,  minimumShouldMatch);  return  wrapSmartNameQuery(optimizeQuery(fixNegativeQueryIfNeeded(query)),  smartNameFieldMappers,  parseContext);  }  finally  {  	query.add(new  BooleanClause(mapper.termQuery(value,  parseContext),  BooleanClause.Occur.SHOULD));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Terms.Bucket>  buckets  =  new  ArrayList<Terms.Bucket>(((Terms)  aggregations.get(0)).getBuckets());  context:  PercolateResponse  response  =  percolateRequestBuilder.execute().actionGet();  assertMatchCount(response,  expectedCount[i  %  numUniqueQueries]);  if  (!countOnly)  {  assertThat(response.getMatches(),  arrayWithSize(expectedCount[i  %  numUniqueQueries]));  }  if  (useAggs)  {  List<Aggregation>  aggregations  =  response.getAggregations().asList();  assertThat(aggregations.size(),  equalTo(1));  assertThat(aggregations.get(0).getName(),  equalTo( "a "));                  List<Terms.Bucket>  buckets  =  new  ArrayList<Terms.Bucket>(((Terms)  aggregations.get(0)).getBuckets());                  List<Terms.Bucket>  buckets  =  new  ArrayList<>(((Terms)  aggregations.get(0)).getBuckets());  assertThat(buckets.size(),  equalTo(1));  assertThat(buckets.get(0).getKeyAsText().string(),  equalTo( "b "));  assertThat(buckets.get(0).getDocCount(),  equalTo((long)  expectedCount[i  %  values.length]));  }  else  {  assertThat(response.getFacets().facets().size(),  equalTo(1));  assertThat(response.getFacets().facets().get(0).getName(),  equalTo( "a "));  assertThat(((TermsFacet)  response.getFacets().facets().get(0)).getEntries().size(),  equalTo(1));  assertThat(((TermsFacet)  response.getFacets().facets().get(0)).getEntries().get(0).getCount(),  equalTo(expectedCount[i  %  values.length]));  	List<Terms.Bucket>  buckets  =  new  ArrayList<>(((Terms)  aggregations.get(0)).getBuckets());  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());  context:  queryFetchResults.put(result.shardTarget(),  result);  }  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());                  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values(),  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  searchCache.releaseQueryFetchResults(queryFetchResults);  }  }  }  	scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values(),  null);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  public  TransportClusterHealthAction(Settings  settings,  TransportService  transportService,  ClusterService  clusterService,  ThreadPool  threadPool,  ClusterName  clusterName)  {  super(settings,  transportService,  clusterService,  threadPool);  this.clusterName  =  clusterName;  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return  ClusterHealthAction.NAME;  }  	return  ThreadPool.Names.GENERIC;  
libgdx_14eb562cf3d3c67b2d4e1b4f57a5bce0498ef44e	buggy:  MD5Jni.calculateVertices(skeleton.joints,  weights,  vertices,  verts,  numVertices);  context:  bbox.ext(finalX,  finalY,  finalZ);  verts[k++]  =  finalX;  verts[k++]  =  finalY;  verts[k++]  =  finalZ;  k  +=  2;  }  }  public  void  calculateVerticesJni  (MD5Joints  skeleton,  float[]  verts)  {  MD5Jni.calculateVertices(skeleton.joints,  weights,  vertices,  verts,  numVertices);  MD5Jni.calculateVertices(skeleton.joints,  weights,  vertices,  verts,  vertices.length,  floatsPerVertex,  floatsPerWeight);  }  public  void  calculateNormalsBind  (MD5Joints  bindPoseSkeleton,  float[]  verts)  {  calculateNormalsBind(bindPoseSkeleton,  weights,  vertices,  indices,  verts,  floatsPerVertex,  floatsPerWeight);  }  static  Vector3  _A  =  new  Vector3();  static  Vector3  _B  =  new  Vector3();  	MD5Jni.calculateVertices(skeleton.joints,  weights,  vertices,  verts,  vertices.length,  floatsPerVertex,  floatsPerWeight);  
libgdx_77c9f0ff01084270bb8c0764f43a07ccfa4cef61	buggy:  this.audio  =  new  IOSAudio();  context:  GL20  gl20  =  config.useMonotouchOpenTK  ?  new  IOSMonotouchGLES20()  :  new  IOSGLES20();  Gdx.gl  =  gl20;  Gdx.gl20  =  gl20;  this.input  =  new  IOSInput(this);  this.graphics  =  new  IOSGraphics(getBounds(uiViewController),  this,  input,  gl20);  this.files  =  new  IOSFiles();  this.audio  =  new  IOSAudio();  this.audio  =  new  IOSAudio(config.useObjectAL);  this.net  =  new  IOSNet(this);  Gdx.files  =  this.files;  Gdx.graphics  =  this.graphics;  Gdx.audio  =  this.audio;  Gdx.input  =  this.input;  Gdx.net  =  this.net;  	this.audio  =  new  IOSAudio(config.useObjectAL);  
elasticsearch_2e8b0464b65a2ca0d7db738637b151d586395b63	buggy:  MetaDataService.CreateIndexResult  createIndexResult  =  metaDataService.createIndex(request.index(),  request.settings(),  request.timeout());  context:  return  new  CreateIndexRequest();  }  return  new  CreateIndexResponse();  }          MetaDataService.CreateIndexResult  createIndexResult  =  metaDataService.createIndex(request.index(),  request.settings(),  request.timeout());          MetaDataService.CreateIndexResult  createIndexResult  =  metaDataService.createIndex(request.index(),  request.settings(),  request.mappings(),  request.timeout());  return  new  CreateIndexResponse(createIndexResult.acknowledged());  }  }  	MetaDataService.CreateIndexResult  createIndexResult  =  metaDataService.createIndex(request.index(),  request.settings(),  request.mappings(),  request.timeout());  
elasticsearch_d570d588a8fdfd7feca537d97f1455c6a5a52220	buggy:  assertAcked(prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().dataNodes()+2).put( "index.number_of_replicas ",  0)));  context:  public  class  SearchPreferenceTests  extends  ElasticsearchIntegrationTest  {  public  void  testStopOneNodePreferenceWithRedState()  throws  InterruptedException  {          assertAcked(prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().dataNodes()+2).put( "index.number_of_replicas ",  0)));          assertAcked(prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  immutableCluster().dataNodes()+2).put( "index.number_of_replicas ",  0)));  ensureGreen();  for  (int  i  =  0;  i  <  10;  i++)  {  client().prepareIndex( "test ",   "type1 ",   " "+i).setSource( "field1 ",   "value1 ").execute().actionGet();  }  refresh();  cluster().stopRandomNode();  client().admin().cluster().prepareHealth().setWaitForStatus(ClusterHealthStatus.RED).execute().actionGet();  String[]  preferences  =  new  String[]  { "_primary ",   "_local ",   "_primary_first ",   "_only_local ",   "_prefer_node:somenode ",   "_prefer_node:server2 "};  	assertAcked(prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  immutableCluster().dataNodes()+2).put( "index.number_of_replicas ",  0)));  
libgdx_5fd25ffb3dc8849230b693316e47670110b0928c	buggy:  new  LwjglApplication(new  SkeletonModelViewer( "data/models/robot-mesh.xml ",   "data/models/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  context:  public  void  dispose  ()  {  }  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  SkeletonModelViewer( "data/models/robot-mesh.xml ",   "data/models/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  new  LwjglApplication(new  SkeletonModelViewer( "data/models/ninja.mesh.xml ",   "data/models/ninja.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  }  }  	new  LwjglApplication(new  SkeletonModelViewer( "data/models/ninja.mesh.xml ",   "data/models/ninja.jpg "),   "SkeletonModel  Viewer ",  800,  480,  
libgdx_d17be9e903e740a312bb8d9183e9e1b0517dbedb	buggy:  this.graphics  =  new  IOSGraphics(getBounds(null),  this,  input,  gl20);  context:  }  }  GL20  gl20  =  new  IOSGLES20();  Gdx.gl  =  gl20;  Gdx.gl20  =  gl20;  this.input  =  new  IOSInput(this);  this.graphics  =  new  IOSGraphics(getBounds(null),  this,  input,  gl20);  this.graphics  =  new  IOSGraphics(getBounds(null),  this,  config,  input,  gl20);  this.files  =  new  IOSFiles();  this.audio  =  new  IOSAudio();  this.net  =  new  IOSNet(this);  Gdx.files  =  this.files;  Gdx.graphics  =  this.graphics;  Gdx.audio  =  this.audio;  Gdx.input  =  this.input;  	this.graphics  =  new  IOSGraphics(getBounds(null),  this,  config,  input,  gl20);  
libgdx_6510ddc07606f45340163b49e3265548621cecc7	buggy:  if(!MathUtils.isPowerOfTwo(width)  ||  !MathUtils.isPowerOfTwo(height))  context:  private  int  createGLHandle()  {  buffer.position(0);  buffer.limit(buffer.capacity());  Gdx.gl.glGenTextures(1,  buffer);  return  buffer.get(0);  }  private  void  uploadImageData(Pixmap  pixmap)  {  this.width  =  pixmap.getWidth();  this.height  =  pixmap.getHeight();  if(!MathUtils.isPowerOfTwo(width)  ||  !MathUtils.isPowerOfTwo(height))  if(Gdx.gl20  ==  null  &&  (!MathUtils.isPowerOfTwo(width)  ||  !MathUtils.isPowerOfTwo(height)))  throw  new  GdxRuntimeException( "texture  width  and  height  must  be  powers  of  two ");  Gdx.gl.glBindTexture(GL10.GL_TEXTURE_2D,  glHandle);  Gdx.gl.glTexImage2D(GL10.GL_TEXTURE_2D,  0,  pixmap.getGLInternalFormat(),  pixmap.getWidth(),  pixmap.getHeight(),  0,  pixmap.getGLFormat(),  pixmap.getGLType(),  pixmap.getPixels());  if(isMipMap)  {  if(!(Gdx.gl20==null)  &&  width  !=  height)  throw  new  GdxRuntimeException( "texture  width  and  height  must  be  square  when  using  mipmapping  in  OpenGL  ES  1.x ");  int  width  =  pixmap.getWidth()  /  2;  int  height  =  pixmap.getHeight()  /  2;  	if(Gdx.gl20  ==  null  &&  (!MathUtils.isPowerOfTwo(width)  ||  !MathUtils.isPowerOfTwo(height)))  
elasticsearch_8f9693063820fb7417c53e7fbe8b10ddcd16c422	buggy:  getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);  getRequest.operationThreaded(true);  getRequest.refresh(request.paramAsBoolean( "refresh ",  getRequest.refresh()));  getRequest.routing(request.param( "routing "));  //  order  is  important,  set  it  after  routing,  so  it  will  set  the  routing  getRequest.parent(request.param( "parent "));  getRequest.preference(request.param( "preference "));          getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));          getRequest.realtime(request.paramAsBoolean( "realtime ",  null));  getRequest.fetchSourceContext(FetchSourceContext.parseFromRestRequest(request));  if  (getRequest.fetchSourceContext()  !=  null  &&  !getRequest.fetchSourceContext().fetchSource())  {  try  {  ActionRequestValidationException  validationError  =  new  ActionRequestValidationException();  validationError.addValidationError( "fetching  source  can  not  be  disabled ");  channel.sendResponse(new  XContentThrowableRestResponse(request,  validationError));  	getRequest.realtime(request.paramAsBoolean( "realtime ",  null));  
libgdx_31b6f673fc5a826e1a649edaec147f2572d3dcf4	buggy:  if(isSdkLocationValid(sdkLocation))  {  context:  public  class  GdxSetup  {  public  static  boolean  isSdkLocationValid  (String  sdkLocation)  {  return  new  File(sdkLocation,   "tools ").exists()  &&  new  File(sdkLocation,   "platforms ").exists();  }  public  void  build  (String  outputDir,  String  appName,  String  packageName,  String  mainClass,  String  sdkLocation)  {  Project  project  =  new  Project();  String  packageDir  =  packageName.replace('.',  '/');  String  sdkPath  =  sdkLocation.replace('\\',  '/');  if(isSdkLocationValid(sdkLocation))  {  if(!isSdkLocationValid(sdkLocation))  {  }  project.files.add(new  ProjectFile( "gitignore ",   ".gitignore ",  false));  project.files.add(new  ProjectFile( "build.gradle ",  true));  project.files.add(new  ProjectFile( "settings.gradle "));  project.files.add(new  ProjectFile( "gradlew ",  false));  	if(!isSdkLocationValid(sdkLocation))  {  
elasticsearch_3ed848a495a494538a9071ccd447f23fa07fb7f2	buggy:  threadPool.execute(new  RoutingTableUpdater());  context:  routingTableDirty  =  true;  scheduledRoutingTableFuture  =  threadPool.scheduleWithFixedDelay(new  RoutingTableUpdater(),  schedule);  }  if  (event.nodesRemoved()  ||  event.routingTableChanged())  {  routingTableDirty  =  true;                  threadPool.execute(new  RoutingTableUpdater());                  threadPool.cached().execute(new  RoutingTableUpdater());  }  else  {  if  (event.nodesAdded())  {  routingTableDirty  =  true;  }  }  }  else  {  if  (scheduledRoutingTableFuture  !=  null)  {  scheduledRoutingTableFuture.cancel(true);  	threadPool.cached().execute(new  RoutingTableUpdater());  
libgdx_976ff5247ad463c87cd4621a1c2696ae2c87fe79	buggy:  float  angle  =  (float)Math.atan2(y,  x)  *  MathUtils.degreesToRadians;  context:  public  float  crs(float  x,  float  y)  {  return  this.x  *  y  -  this.y  *  x;  }  public  float  angle()  {        float  angle  =  (float)Math.atan2(y,  x)  *  MathUtils.degreesToRadians;        float  angle  =  (float)Math.atan2(y,  x)  *  MathUtils.radiansToDegrees;  if(angle  <  0)  angle  +=  360;  return  angle;  }  	float  angle  =  (float)Math.atan2(y,  x)  *  MathUtils.radiansToDegrees;  
elasticsearch_8a17222ff201d64225dd6c97028e07754447249e	buggy:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  context:  public  String[]  names()  {  return  new  String[]{NAME,  Strings.toCamelCase(NAME)};  }  public  Filter  parse(QueryParseContext  parseContext)  throws  IOException,  QueryParsingException  {  XContentParser  parser  =  parseContext.parser();  XContentParser.Token  token;          while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {          while  (((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT  &&  token  !=  XContentParser.Token.END_ARRAY))  {  }  return  Queries.MATCH_ALL_FILTER;  }  }  	while  (((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT  &&  token  !=  XContentParser.Token.END_ARRAY))  {  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  out.writeOptionalString(metaData.writtenBy()  ==  null  ?  null  :  metaData.writtenBy().name());  context:  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeLong(recoveryId);  shardId.writeTo(out);  out.writeString(metaData.name());  out.writeVLong(position);  out.writeVLong(metaData.length());  out.writeOptionalString(metaData.checksum());  out.writeBytesReference(content);  if  (out.getVersion().onOrAfter(org.elasticsearch.Version.V_1_3_0))  {              out.writeOptionalString(metaData.writtenBy()  ==  null  ?  null  :  metaData.writtenBy().name());              out.writeOptionalString(metaData.writtenBy()  ==  null  ?  null  :  metaData.writtenBy().toString());  }  }  public  String  toString()  {  return  shardId  +   ":  name=' "  +  name()  +  '\''  +   ",  position= "  +  position  +   ",  length= "  +  length();  	out.writeOptionalString(metaData.writtenBy()  ==  null  ?  null  :  metaData.writtenBy().toString());  
libgdx_8a2912c4841b8b9f5fe7acd83c935b0fd1fe00ec	buggy:  if  (velocityValue.active  &&  velocityValue.active)  updateFlags  |=  UPDATE_VELOCITY;  context:  spawnWidth  =  spawnWidthValue.newLowValue();  spawnWidthDiff  =  spawnWidthValue.newHighValue();  if  (!spawnWidthValue.isRelative())  spawnWidthDiff  -=  spawnWidth;  spawnHeight  =  spawnHeightValue.newLowValue();  spawnHeightDiff  =  spawnHeightValue.newHighValue();  if  (!spawnHeightValue.isRelative())  spawnHeightDiff  -=  spawnHeight;  updateFlags  =  0;  if  (angleValue.active  &&  angleValue.timeline.length  >  1)  updateFlags  |=  UPDATE_ANGLE;  if  (velocityValue.active  &&  velocityValue.active)  updateFlags  |=  UPDATE_VELOCITY;  if  (velocityValue.active)  updateFlags  |=  UPDATE_VELOCITY;  if  (scaleValue.timeline.length  >  1)  updateFlags  |=  UPDATE_SCALE;  if  (rotationValue.active  &&  rotationValue.timeline.length  >  1)  updateFlags  |=  UPDATE_ROTATION;  if  (windValue.active)  updateFlags  |=  UPDATE_WIND;  if  (gravityValue.active)  updateFlags  |=  UPDATE_GRAVITY;  if  (tintValue.timeline.length  >  1)  updateFlags  |=  UPDATE_TINT;  }  protected  Particle  newParticle  (Sprite  sprite)  {  	if  (velocityValue.active)  updateFlags  |=  UPDATE_VELOCITY;  
elasticsearch_e5737e305804da5f09b716e66fa1d5e17bddc07e	buggy:  logger.trace( "Recovery  [phase1]  to  {}:  recovering  [{}]  files  with  total  size  of  [{}] ",  new  Object[]{node,  snapshot.getFiles().length,  new  SizeValue(totalSize)});  context:  for  (String  name  :  snapshot.getFiles())  {  IndexInput  indexInput  =  store.directory().openInput(name);  recoveryStatus.phase1FileNames.add(name);  recoveryStatus.phase1FileSizes.add(indexInput.length());  totalSize  +=  indexInput.length();  indexInput.close();  }  recoveryStatus.phase1TotalSize  =  totalSize;                          logger.trace( "Recovery  [phase1]  to  {}:  recovering  [{}]  files  with  total  size  of  [{}] ",  new  Object[]{node,  snapshot.getFiles().length,  new  SizeValue(totalSize)});                          logger.trace( "Recovery  [phase1]  to  {}:  recovering  [{}]  files  with  total  size  of  [{}] ",  node,  snapshot.getFiles().length,  new  SizeValue(totalSize));  final  CountDownLatch  latch  =  new  CountDownLatch(snapshot.getFiles().length);  final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();  for  (final  String  name  :  snapshot.getFiles())  {  sendFileChunksRecoveryFutures.add(threadPool.submit(new  Runnable()  {  IndexInput  indexInput  =  null;  try  {  	logger.trace( "Recovery  [phase1]  to  {}:  recovering  [{}]  files  with  total  size  of  [{}] ",  node,  snapshot.getFiles().length,  new  SizeValue(totalSize));  
elasticsearch_efb3e97ce4fe8edbd3fec9bb217fe6e42bde6dba	buggy:  assertThat(UidField.loadDocIdAndVersion(reader,  new  Term( "_uid ",   "1 ")).version,  equalTo(-1l));  context:  doc  =  new  Document();  doc.add(new  UidField( "_uid ",   "1 ",  2));  writer.updateDocument(new  Term( "_uid ",   "1 "),  doc);  reader  =  reader.reopen();  assertThat(UidField.loadVersion(reader,  new  Term( "_uid ",   "1 ")),  equalTo(2l));  assertThat(UidField.loadDocIdAndVersion(reader,  new  Term( "_uid ",   "1 ")).version,  equalTo(2l));  writer.deleteDocuments(new  Term( "_uid ",   "1 "));  reader  =  reader.reopen();  assertThat(UidField.loadVersion(reader,  new  Term( "_uid ",   "1 ")),  equalTo(-1l));          assertThat(UidField.loadDocIdAndVersion(reader,  new  Term( "_uid ",   "1 ")).version,  equalTo(-1l));          assertThat(UidField.loadDocIdAndVersion(reader,  new  Term( "_uid ",   "1 ")),  nullValue());  }  }  	assertThat(UidField.loadDocIdAndVersion(reader,  new  Term( "_uid ",   "1 ")),  nullValue());  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  if  (termsEnum.seekExact(uidSpare,  false))  {  context:  DocsEnum  docsEnum  =  null;  FixedBitSet  result  =  null;  for  (int  i  =  0;  i  <  allocated.length;  i++)  {  if  (!allocated[i])  {  continue;  }  idSpare.bytes  =  ((HashedBytesArray)  keys[i]).toBytes();  idSpare.length  =  idSpare.bytes.length;  Uid.createUidAsBytes(parentTypeBr,  idSpare,  uidSpare);              if  (termsEnum.seekExact(uidSpare,  false))  {              if  (termsEnum.seekExact(uidSpare))  {  int  docId;  docsEnum  =  termsEnum.docs(acceptDocs,  docsEnum,  DocsEnum.FLAG_NONE);  if  (result  ==  null)  {  docId  =  docsEnum.nextDoc();  if  (docId  !=  DocIdSetIterator.NO_MORE_DOCS)  {  result  =  new  FixedBitSet(context.reader().maxDoc());  result.set(docId);  }  else  {  	if  (termsEnum.seekExact(uidSpare))  {  
libgdx_9d40ad3d7a82d55c5827a977b425380da1c3f71f	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.MusicTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.MusicTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_df3fa9c067f2accdf39e0add07900eace19f9d07	buggy:  return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  context:  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.refresh(new  Engine.Refresh(request.waitForOperations()));  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);          return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true);  
libgdx_497df197bb0f4400447116cb011d5b432c899d80	buggy:  GdxTest  test  =  new  TextButtonTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  GdxTest  test  =  new  TextButtonTest();  GdxTest  test  =  new  TextureBindTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  TextureBindTest();  
libgdx_2a4ca185953f1a705d1e64103004c79bbe8fc89f	buggy:  TouchEvent  event  =  input.usedTouchEvents.add();  context:  }else  if  (event.getAction()  ==  MotionEvent.ACTION_CANCEL)  {  postTouchEvent(input,  TouchEvent.TOUCH_UP,  x,  y,  0);  input.touched[0]  =  false;  }  }  private  void  postTouchEvent  (AndroidInput  input,  int  type,  int  x,  int  y,  int  pointer)  {  long  timeStamp  =  System.nanoTime();  synchronized  (input)  {  TouchEvent  event  =  input.usedTouchEvents.add();  TouchEvent  event  =  input.usedTouchEvents.obtain();  event.timeStamp  =  timeStamp;  event.pointer  =  0;  event.x  =  x;  event.y  =  y;  event.type  =  type;  input.touchEvents.add(event);  }  }  	TouchEvent  event  =  input.usedTouchEvents.obtain();  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  context:  }  if  ( "delete_by_query ".equals(SearchContext.current().source()))  {  throw  new  QueryParsingException(parseContext.index(),   "[top_children]  unsupported  in  delete_by_query  api ");  }  DocumentMapper  childDocMapper  =  parseContext.mapperService().documentMapper(childType);  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  mapping  for  for  type  [ "  +  childType  +   "] ");  }          if  (childDocMapper.parentFieldMapper()  ==  null)  {          if  (!childDocMapper.parentFieldMapper().active())  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  parseContext.cacheRecycler());  	if  (!childDocMapper.parentFieldMapper().active())  {  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  threadPool.shutdownNow();  context:  latch.countDown();  Thread.currentThread().interrupt();  }  }  });  threadPool.updateSettings(settingsBuilder().put( "threadpool.search.type ",   "fixed ").build());  assertThat(threadPool.executor(Names.SEARCH),  not(sameInstance(oldExecutor)));  assertThat(((ThreadPoolExecutor)  oldExecutor).isShutdown(),  equalTo(true));  assertThat(((ThreadPoolExecutor)  oldExecutor).isTerminating(),  equalTo(true));  assertThat(((ThreadPoolExecutor)  oldExecutor).isTerminated(),  equalTo(false));          threadPool.shutdownNow();          terminate(threadPool);  latch.await();  }  }  	terminate(threadPool);  
elasticsearch_02cb2976917e3a6edb5e0caf5a65a95e3bff5f3a	buggy:  MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreConflicts(),  request.timeout());  context:  return  new  PutMappingResponse();  }  ClusterState  clusterState  =  clusterService.state();  request.indices(clusterState.metaData().concreteIndices(request.indices()));  final  String[]  indices  =  request.indices();          MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreConflicts(),  request.timeout());          MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.source(),  request.ignoreConflicts(),  request.timeout());  return  new  PutMappingResponse(result.acknowledged());  }  }  	MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.source(),  request.ignoreConflicts(),  request.timeout());  
libgdx_78bed2c6254daac8057dd18d56728a295f3bd00f	buggy:  draw(region,  x,  y,  Math.abs(region.getRegionWidth()),  Math.abs(region.getRegionHeight()));  context:  renderMesh();  vertexCount  =  Math.min(vertices.length,  length  -  offset);  System.arraycopy(spriteVertices,  offset,  vertices,  0,  vertexCount);  offset  +=  vertexCount;  idx  +=  vertexCount;  }  }  public  void  draw  (TextureRegion  region,  float  x,  float  y)  {  draw(region,  x,  y,  Math.abs(region.getRegionWidth()),  Math.abs(region.getRegionHeight()));  draw(region,  x,  y,  region.getRegionWidth(),  region.getRegionHeight());  }  public  void  draw  (TextureRegion  region,  float  x,  float  y,  float  width,  float  height)  {  if  (!drawing)  throw  new  IllegalStateException( "SpriteBatch.begin  must  be  called  before  draw. ");  Texture  texture  =  region.texture;  if  (texture  !=  lastTexture)  {  	draw(region,  x,  y,  region.getRegionWidth(),  region.getRegionHeight());  
elasticsearch_fdd5e53aa779cb9f7d3e765583f23ce04cac709d	buggy:  }  catch  (Exception  e)  {  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  void  finishHim()  {  try  {  innerFinishHim();              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  ReduceSearchPhaseException  failure  =  new  ReduceSearchPhaseException( "query_fetch ",   " ",  e,  buildShardFailures());  if  (logger.isDebugEnabled())  {  }  listener.onFailure(failure);  }  finally  {  }  	}  catch  (Throwable  e)  {  
elasticsearch_40d86a630b0436a1a33a8b9ba059910a41b3367a	buggy:  ensureGreen();  context:  ids[i]  =  id;  }  indexRandom(true,  indexBuilders);  checkFunctionScoreStillWorks(ids);  logClusterState();  boolean  upgraded;  int  upgradedNodesCounter  =  1;  do  {  upgraded  =  backwardsCluster().upgradeOneNode();              ensureGreen();              ensureYellow();  logClusterState();  checkFunctionScoreStillWorks(ids);  }  while  (upgraded);  }  private  void  checkFunctionScoreStillWorks(String...  ids)  throws  ExecutionException,  InterruptedException,  IOException  {  SearchResponse  response  =  client().search(  	ensureYellow();  
elasticsearch_76e92ffbea1bf6663e075ad50baaad64b3c6e659	buggy:  boolean  defaultIsolation  =  settings.getAsBoolean( "plugins.isolation ",  Boolean.TRUE);  context:  }  private  List<Tuple<PluginInfo,Plugin>>  loadPlugins()  {  File  pluginsFile  =  environment.pluginsFile();  if  (!isAccessibleDirectory(pluginsFile,  logger))  {  return  Collections.emptyList();  }  List<Tuple<PluginInfo,  Plugin>>  pluginData  =  Lists.newArrayList();          boolean  defaultIsolation  =  settings.getAsBoolean( "plugins.isolation ",  Boolean.TRUE);          boolean  defaultIsolation  =  settings.getAsBoolean( "plugins.isolation ",  Boolean.FALSE);  ClassLoader  esClassLoader  =  settings.getClassLoader();  Method  addURL  =  null;  boolean  discoveredAddUrl  =  false;  File[]  pluginsFiles  =  pluginsFile.listFiles();  if  (pluginsFiles  !=  null)  {  for  (File  pluginRoot  :  pluginsFiles)  {  	boolean  defaultIsolation  =  settings.getAsBoolean( "plugins.isolation ",  Boolean.FALSE);  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Float.NaN;  context:  this.nullValue  =  nullValue;  }  return  32;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Float.NaN;              return  null;  }  return  Numbers.bytesToFloat(value);  }  return  indexedValue(Float.parseFloat(value));  }  	return  null;  
elasticsearch_8eed6cdcaefa07980230fafdf2945adc32c76611	buggy:  bind(MetaDataStateIndexService.class).asEagerSingleton();  context:  }  protected  void  configure()  {  bind(DiscoveryNodeService.class).asEagerSingleton();  bind(ClusterService.class).to(InternalClusterService.class).asEagerSingleton();  bind(MetaDataService.class).asEagerSingleton();  bind(MetaDataCreateIndexService.class).asEagerSingleton();  bind(MetaDataDeleteIndexService.class).asEagerSingleton();          bind(MetaDataStateIndexService.class).asEagerSingleton();          bind(MetaDataIndexStateService.class).asEagerSingleton();  bind(MetaDataMappingService.class).asEagerSingleton();  bind(MetaDataIndexAliasesService.class).asEagerSingleton();  bind(MetaDataUpdateSettingsService.class).asEagerSingleton();  bind(MetaDataIndexTemplateService.class).asEagerSingleton();  bind(RoutingService.class).asEagerSingleton();  bind(ShardStateAction.class).asEagerSingleton();  	bind(MetaDataIndexStateService.class).asEagerSingleton();  
elasticsearch_b4940d258cc16193df07a2b57da83bb3d753cff5	buggy:  logger.info(summary);  context:  }  else  if  (logger.isDebugEnabled())  {  }  ClusterChangedEvent  clusterChangedEvent  =  new  ClusterChangedEvent(source,  clusterState,  previousClusterState,  discoveryService.firstMaster());  final  DiscoveryNodes.Delta  nodesDelta  =  clusterChangedEvent.nodesDelta();  if  (nodesDelta.hasChanges()  &&  logger.isInfoEnabled())  {  String  summary  =  nodesDelta.shortSummary();  if  (summary.length()  >  0)  {                              logger.info(summary);                              logger.info( "{},  Reason:  {} ",  summary,  source);  }  }  for  (DiscoveryNode  node  :  nodesDelta.addedNodes())  {  try  {  transportService.connectToNode(node);  }  catch  (Exception  e)  {  	logger.info( "{},  Reason:  {} ",  summary,  source);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  HttpServerTransport  httpServerTransport  =  cluster().getDataNodeInstance(HttpServerTransport.class);  context:  assertThat(response.getHeader( "Secret "),  equalTo( "required "));  Map<String,  String>  headers  =  Maps.newHashMap();  headers.put( "Secret ",   "password ");  HttpClientResponse  authResponse  =  httpClient().request( "GET ",   "_protected ",  headers);  assertThat(authResponse.errorCode(),  equalTo(RestStatus.OK.getStatus()));  assertThat(authResponse.getHeader( "Secret "),  equalTo( "granted "));  }  private  HttpClient  httpClient()  {          HttpServerTransport  httpServerTransport  =  cluster().getDataNodeInstance(HttpServerTransport.class);          HttpServerTransport  httpServerTransport  =  internalCluster().getDataNodeInstance(HttpServerTransport.class);  return  new  HttpClient(httpServerTransport.boundAddress().publishAddress());  }  }  	HttpServerTransport  httpServerTransport  =  internalCluster().getDataNodeInstance(HttpServerTransport.class);  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  final  Engine.Searcher  searcher  =  indexShard.searcher();  context:  super(shardId,  indexSettings);  }  public  ShardTermVectorService  setIndexShard(IndexShard  indexShard)  {  this.indexShard  =  indexShard;  return  this;  }  public  TermVectorResponse  getTermVector(TermVectorRequest  request)  {          final  Engine.Searcher  searcher  =  indexShard.searcher();          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  IndexReader  topLevelReader  =  searcher.reader();  final  TermVectorResponse  termVectorResponse  =  new  TermVectorResponse(request.index(),  request.type(),  request.id());  final  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  try  {  Fields  topLevelFields  =  MultiFields.getFields(topLevelReader);  Versions.DocIdAndVersion  docIdAndVersion  =  Versions.loadDocIdAndVersion(topLevelReader,  uidTerm);  if  (docIdAndVersion  !=  null)  {  	final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  
elasticsearch_d2493ea48a284cbb2fb41eecf201c5e9dfa09fa3	buggy:  final  Version  version  =  Version.parseLeniently(info.info.getVersion());  context:  try  {  segmentCommitInfos  =  Store.readLastCommittedSegmentsInfo(directory);  }  catch  (FileNotFoundException  |  NoSuchFileException  ex)  {  return  ImmutableMap.of();  }  Version  maxVersion  =  Version.LUCENE_3_0;  //  we  don't  know  which  version  was  used  to  write  so  we  take  the  max  version.  Set<String>  added  =  new  HashSet<>();  for  (SegmentCommitInfo  info  :  segmentCommitInfos)  {                      final  Version  version  =  Version.parseLeniently(info.info.getVersion());                      final  Version  version  =  Lucene.parseVersionLenient(info.info.getVersion(),  Version.LUCENE_3_0);  if  (version.onOrAfter(maxVersion))  {  maxVersion  =  version;  }  for  (String  file  :  Iterables.concat(info.info.files(),  info.files()))  {  if  (!added.contains(file))  {  String  legacyChecksum  =  checksumMap.get(file);  if  (version.onOrAfter(Version.LUCENE_4_8)  &&  legacyChecksum  ==  null)  {  checksumFromLuceneFile(directory,  file,  builder,  logger,  version);  	final  Version  version  =  Lucene.parseVersionLenient(info.info.getVersion(),  Version.LUCENE_3_0);  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(false,  false,  (WIDTH  +  1)  *  (HEIGHT  +  1),  WIDTH  *  HEIGHT  *  6,  new  VertexAttribute(  context:  camera  =  new  PerspectiveCamera();  camera.getPosition().set((WIDTH)  /  2.0f,  (HEIGHT)  /  2.0f,  WIDTH  /  2.0f);  camera.setViewport(Gdx.graphics.getWidth(),  Gdx.graphics.getWidth());  camera.setFov(90);  camera.setNear(0.1f);  camera.setFar(1000);  last  =  new  float[WIDTH  +  1][HEIGHT  +  1];  curr  =  new  float[WIDTH  +  1][HEIGHT  +  1];  intp  =  new  float[WIDTH  +  1][HEIGHT  +  1];  vertices  =  new  float[(WIDTH  +  1)  *  (HEIGHT  +  1)  *  5];  mesh  =  new  Mesh(false,  false,  (WIDTH  +  1)  *  (HEIGHT  +  1),  WIDTH  *  HEIGHT  *  6,  new  VertexAttribute(  mesh  =  new  Mesh(false,  (WIDTH  +  1)  *  (HEIGHT  +  1),  WIDTH  *  HEIGHT  *  6,  new  VertexAttribute(  VertexAttributes.Usage.Position,  3,   "a_Position "),  new  VertexAttribute(VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoords "));  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/stones.jpg ",  FileType.Internal),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  createIndices();  updateVertices(curr);  initialized  =  true;  	mesh  =  new  Mesh(false,  (WIDTH  +  1)  *  (HEIGHT  +  1),  WIDTH  *  HEIGHT  *  6,  new  VertexAttribute(  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  String  sOpType  =  request.param( "opType ");  context:  super(settings,  client);  controller.registerHandler(POST,   "/{index}/{type} ",  this);  //  auto  id  creation  controller.registerHandler(PUT,   "/{index}/{type}/{id} ",  this);  }  IndexRequest  indexRequest  =  new  IndexRequest(request.param( "index "),  request.param( "type "),  request.param( "id "),  request.contentAsBytes());  indexRequest.timeout(request.paramAsTime( "timeout ",  IndexRequest.DEFAULT_TIMEOUT));          String  sOpType  =  request.param( "opType ");          String  sOpType  =  request.param( "op_type ");  if  (sOpType  !=  null)  {  if  ( "index ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.INDEX);  }  else  if  ( "create ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.CREATE);  }  else  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  	String  sOpType  =  request.param( "op_type ");  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  assertThat(fieldData.getMemorySizeInBytes(),  greaterThan(0l));  context:  d  =  new  Document();  d.add(new  StringField(UidFieldMapper.NAME,  Uid.createUid( "other-type ",   "1 "),  Field.Store.NO));  writer.addDocument(d);  }  public  void  testGetBytesValues()  throws  Exception  {  IndexFieldData  indexFieldData  =  getForField(childType);  AtomicFieldData  fieldData  =  indexFieldData.load(refreshReader());          assertThat(fieldData.getMemorySizeInBytes(),  greaterThan(0l));          assertThat(fieldData.ramBytesUsed(),  greaterThan(0l));  BytesValues  bytesValues  =  fieldData.getBytesValues();  assertThat(bytesValues.setDocument(0),  equalTo(1));  assertThat(bytesValues.nextValue().utf8ToString(),  equalTo( "1 "));  assertThat(bytesValues.setDocument(1),  equalTo(2));  assertThat(bytesValues.nextValue().utf8ToString(),  equalTo( "1 "));  assertThat(bytesValues.nextValue().utf8ToString(),  equalTo( "2 "));  	assertThat(fieldData.ramBytesUsed(),  greaterThan(0l));  
libgdx_a40f81c3a8983a66b6d967d42895321f7eb80122	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_a18021c77859c477d03ebc5fe7d13bf036ea0946	buggy:  return  combine(ImmutableSet.of(modules));  context:  public  static  OverriddenModuleBuilder  override(Iterable<?  extends  Module>  modules)  {  return  new  RealOverriddenModuleBuilder(modules);  }  public  static  Module  combine(Module...  modules)  {          return  combine(ImmutableSet.of(modules));          return  combine(ImmutableSet.copyOf(modules));  }  public  static  Module  combine(Iterable<?  extends  Module>  modules)  {  final  Set<Module>  modulesSet  =  ImmutableSet.copyOf(modules);  return  new  Module()  {  	return  combine(ImmutableSet.copyOf(modules));  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.INDEX;  }  return  new  AnalyzeRequest();  }  return  new  AnalyzeResponse();  	return  ThreadPool.Names.INDEX;  
libgdx_ff7b713f3735ffac9135c6898d9707aa2892d432	buggy:  String  scaledPackFileName  =  rootSettings.scaledPackFileName(packFileName,  i);  context:  }  for  (int  i  =  0,  n  =  rootSettings.scale.length;  i  <  n;  i++)  {  FileProcessor  deleteProcessor  =  new  FileProcessor()  {  protected  void  processFile  (Entry  inputFile)  throws  Exception  {  inputFile.inputFile.delete();  }  };  deleteProcessor.setRecursive(false);  String  scaledPackFileName  =  rootSettings.scaledPackFileName(packFileName,  i);  String  scaledPackFileName  =  rootSettings.getScaledPackFileName(packFileName,  i);  File  packFile  =  new  File(scaledPackFileName);  String  prefix  =  packFile.getName();  int  dotIndex  =  prefix.lastIndexOf('.');  if  (dotIndex  !=  -1)  prefix  =  prefix.substring(0,  dotIndex);  deleteProcessor.addInputRegex( "(?i) "  +  prefix  +   "\\d*\\.(png|jpg) ");  deleteProcessor.addInputRegex( "(?i) "  +  prefix  +   "\\.atlas ");  	String  scaledPackFileName  =  rootSettings.getScaledPackFileName(packFileName,  i);  
libgdx_d809dc21eea9f0e7bf66a719670824f29a1adff1	buggy:  touchFocusedChild  =  stage  !=  null  ?  stage.getTouchFocus(0)  :  null;  context:  ScissorStack.popScissors();  }  resetTransform(batch);  }  public  boolean  touchDown  (float  x,  float  y,  int  pointer)  {  if  (pointer  !=  0)  return  false;  super.touchDown(x,  y,  pointer);  touchFocusedChild  =  stage  !=  null  ?  stage.getTouchFocus(0)  :  null;  touchFocusedChild  =  stage.getTouchFocus(0)  !=  this  ?  stage.getTouchFocus(0)  :  null;  gestureDetector.touchDown((int)x,  (int)y,  pointer,  0);  if  (stage  !=  null)  stage.setTouchFocus(this,  0);  //  Always  take  the  touch  focus.  return  true;  }  public  void  touchUp  (float  x,  float  y,  int  pointer)  {  clamp();  	touchFocusedChild  =  stage.getTouchFocus(0)  !=  this  ?  stage.getTouchFocus(0)  :  null;  
elasticsearch_7f32e8c70772e582f0dcec8495c5bfd9591fa95a	buggy:  ThreadPool.Names.SNAPSHOT_DATA,  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  context:  builder.put(SearchService.KEEPALIVE_INTERVAL_KEY,  TimeValue.timeValueSeconds(10  +  random.nextInt(5  *  60)));  }  if  (random.nextBoolean())  {  //  sometimes  set  a  builder.put(SearchService.DEFAUTL_KEEPALIVE_KEY,  TimeValue.timeValueSeconds(100  +  random.nextInt(5  *  60)));  }  if  (random.nextBoolean())  {  for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GET,  ThreadPool.Names.INDEX,  ThreadPool.Names.MANAGEMENT,  ThreadPool.Names.MERGE,  ThreadPool.Names.OPTIMIZE,  ThreadPool.Names.PERCOLATE,  ThreadPool.Names.REFRESH,  ThreadPool.Names.SEARCH,  ThreadPool.Names.SNAPSHOT,                      ThreadPool.Names.SNAPSHOT_DATA,  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {                      ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  if  (random.nextBoolean())  {  final  String  type  =  RandomPicks.randomFrom(random,  Arrays.asList( "fixed ",   "cached ",   "scaling "));  builder.put(ThreadPool.THREADPOOL_GROUP  +  name  +   ".type ",  type);  }  }  }  if  (random.nextInt(10)  ==  0)  {  builder.put(EsExecutors.PROCESSORS,  1  +  random.nextInt(AbstractRandomizedTest.TESTS_PROCESSORS));  	ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  
elasticsearch_f285ffc61088f72be9790c80db55b2d69f05f461	buggy:  ce.setDescription( "exp(-  abs( "  +  valueExpl  +   ")  *   "  +  -1  *  scale  +   ") ");  context:  public  double  evaluate(double  value,  double  scale)  {  return  Math.exp(scale  *  value);  }  public  Explanation  explainFunction(String  valueExpl,  double  value,  double  scale)  {  ComplexExplanation  ce  =  new  ComplexExplanation();  ce.setValue((float)  evaluate(value,  scale));              ce.setDescription( "exp(-  abs( "  +  valueExpl  +   ")  *   "  +  -1  *  scale  +   ") ");              ce.setDescription( "exp(-   "  +  valueExpl  +   "  *   "  +  -1  *  scale  +   ") ");  return  ce;  }  public  double  processScale(double  scale,  double  decay)  {  return  Math.log(decay)  /  scale;  }  	ce.setDescription( "exp(-   "  +  valueExpl  +   "  *   "  +  -1  *  scale  +   ") ");  
libgdx_6bef7431cf872bd0ef5b64fb374ea777afef5999	buggy:  if  (knownType  !=  null  &&  actualType  !=  knownType)  context:  return;  }  Serializer  serializer  =  classToSerializer.get(actualType);  if  (serializer  !=  null)  {  serializer.write(this,  value,  knownType);  return;  }  if  (value  instanceof  Array)  {  if  (knownType  !=  null  &&  actualType  !=  knownType)  if  (knownType  !=  null  &&  actualType  !=  knownType  &&  actualType  !=  Array.class)  throw  new  SerializationException( "Serialization  of  an  Array  other  than  the  known  type  is  not  supported.\n "   "Known  type:   "  +  knownType  +   "\nActual  type:   "  +  actualType);  writeArrayStart();  Array  array  =  (Array)value;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  writeValue(array.get(i),  elementType,  null);  writeArrayEnd();  return;  	if  (knownType  !=  null  &&  actualType  !=  knownType  &&  actualType  !=  Array.class)  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  context.cacheRecycler().longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector();  }  public  InternalFacet  buildFacet(String  facetName)  {          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean  []  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  	List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  
elasticsearch_03cd2f3772183d1421069d45738d472549612842	buggy:  }  else  if  (request.waitForNodes().startsWith( "M= "))  {  context:  }  if  (request.waitForActiveShards()  !=  -1  &&  response.activeShards()  >=  request.waitForActiveShards())  {  waitForCounter++;  }  if  (!request.waitForNodes().isEmpty())  {  if  (request.waitForNodes().startsWith( ">= "))  {  int  expected  =  Integer.parseInt(request.waitForNodes().substring(2));  if  (response.numberOfNodes()  >=  expected)  {  waitForCounter++;  }                  }  else  if  (request.waitForNodes().startsWith( "M= "))  {                  }  else  if  (request.waitForNodes().startsWith( "<= "))  {  int  expected  =  Integer.parseInt(request.waitForNodes().substring(2));  if  (response.numberOfNodes()  <=  expected)  {  waitForCounter++;  }  }  else  if  (request.waitForNodes().startsWith( "> "))  {  int  expected  =  Integer.parseInt(request.waitForNodes().substring(1));  if  (response.numberOfNodes()  >  expected)  {  waitForCounter++;  	}  else  if  (request.waitForNodes().startsWith( "<= "))  {  
libgdx_e42e328c2f0629cc317dca82fc57cf7ce21bc650	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.AssetManagerTest(),  config);  context:  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  config.useGL20  =  true;  config.vSyncEnabled  =  false;  new  JoglApplication(new  com.badlogic.gdx.tests.AssetManagerTest(),  config);  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  
elasticsearch_c9b7bec3cca1889da4b37d50bbce040114c903d5	buggy:  return  COMPATIBILITY_VERSION.onOrAfter(Version.V_1_2_0);  context:  if  (skipSection.isVersionCheck())  {  messageBuilder.append( "[ ").append(description).append( "]  skipped,  reason:  [ ").append(skipSection.getReason()).append( "]   ");  }  else  {  messageBuilder.append( "[ ").append(description).append( "]  skipped,  reason:  features   ").append(skipSection.getFeatures()).append( "  not  supported ");  }  return  messageBuilder.toString();  }  protected  boolean  randomizeNumberOfShardsAndReplicas()  {          return  COMPATIBILITY_VERSION.onOrAfter(Version.V_1_2_0);          return  compatibilityVersion().onOrAfter(Version.V_1_2_0);  }  public  void  test()  throws  IOException  {  if  (testCandidate.getTestSection().getExecutableSections().size()  ==  0)  {  throw  new  IllegalArgumentException( "No  executable  sections  loaded  for  [ "  +  testCandidate.getTestPath()  +   "] ");  }  	return  compatibilityVersion().onOrAfter(Version.V_1_2_0);  
elasticsearch_167538ef0d8003e083af4f85da139c7020afcc57	buggy:  indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE));  context:  }  protected  MultiGetShardResponse  shardOperation(MultiGetShardRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {              indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE));              indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE).source( "refresh_flag_mget "));  }  MultiGetShardResponse  response  =  new  MultiGetShardResponse();  for  (int  i  =  0;  i  <  request.locations.size();  i++)  {  String  type  =  request.types.get(i);  String  id  =  request.ids.get(i);  String[]  fields  =  request.fields.get(i);  	indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE).source( "refresh_flag_mget "));  
libgdx_59b03495a1faa930c6a8c5786c969f57bad44b57	buggy:  return  currAction  ==  actions.size();  context:  }  actions.get(currAction).act(delta);  if  (actions.get(currAction).isDone())  {  currAction++;  if  (currAction  <  actions.size())  actions.get(currAction).setTarget(target);  }  }  return  currAction  ==  actions.size();  return  currAction  >=  actions.size();  }  pool.free(this);  int  len  =  0;  for  (int  i  =  0;  i  <  len;  i++)  actions.get(i).finish();  }  	return  currAction  >=  actions.size();  
libgdx_2330e1fecb57bb166c70ecf7f540be719be8e7e3	buggy:  }  catch  (IOException  e)  {  context:  return  w.toString();  }  finally  {  StreamUtils.closeQuietly(reader);  }  }  public  static  void  closeQuietly  (Closeable  c)  {  if  (c  !=  null)  try  {  c.close();  }  catch  (IOException  e)  {  }  catch  (Exception  e)  {  }  }  private  static  class  OptimizedByteArrayOutputStream  extends  ByteArrayOutputStream  {  OptimizedByteArrayOutputStream  (int  initialSize)  {  super(initialSize);  	}  catch  (Exception  e)  {  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  music[i]  =  Gdx.audio.newMusic(Gdx.files.internal( "data/music.mp3 "));  context:  static  final  int  NUM_STREAMS  =  1;  Music[]  music  =  new  Music[NUM_STREAMS];  TextureRegion  buttons;  SpriteBatch  batch;  BitmapFont  font;  public  void  create  ()  {  for  (int  i  =  0;  i  <  music.length;  i++)  {  music[i]  =  Gdx.audio.newMusic(Gdx.files.internal( "data/music.mp3 "));  music[i]  =  Gdx.audio.newMusic(Gdx.files.internal( "data/cloudconnected.ogg "));  }  buttons  =  new  TextureRegion(new  Texture(Gdx.files.internal( "data/playback.png ")));  batch  =  new  SpriteBatch();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  }  	music[i]  =  Gdx.audio.newMusic(Gdx.files.internal( "data/cloudconnected.ogg "));  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  throws  ElasticSearchException  {  context:  }  this.rateLimitingThrottle  =  indexSettings.getAsBytesSize(INDEX_STORE_THROTTLE_MAX_BYTES_PER_SEC,  new  ByteSizeValue(0));  rateLimiting.setMaxRate(rateLimitingThrottle);  indexService.settingsService().addListener(applySettings);  }      public  void  close(boolean  delete)  throws  ElasticSearchException  {      public  void  close()  throws  ElasticSearchException  {  indexService.settingsService().removeListener(applySettings);  }  public  boolean  canDeleteUnallocated(ShardId  shardId)  {  return  false;  }  	public  void  close()  throws  ElasticSearchException  {  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  updateRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  String[]  sFields  =  Strings.splitStringByCommaToArray(sField);  if  (sFields  !=  null)  {  updateRequest.fields(sFields);  }  }  updateRequest.retryOnConflict(request.paramAsInt( "retry_on_conflict ",  updateRequest.retryOnConflict()));  if  (request.hasContent())  {  try  {                  updateRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  updateRequest.source(request.content());  IndexRequest  upsertRequest  =  updateRequest.upsertRequest();  if  (upsertRequest  !=  null)  {  upsertRequest.routing(request.param( "routing "));  upsertRequest.parent(request.param( "parent "));  //  order  is  important,  set  it  after  routing,  so  it  will  set  the  routing  upsertRequest.timestamp(request.param( "timestamp "));  if  (request.hasParam( "ttl "))  {  upsertRequest.ttl(request.paramAsTime( "ttl ",  null).millis());  }  	updateRequest.source(request.content());  
elasticsearch_836461e6de36c3218d9a7d90712370f1523057bb	buggy:  return  new  InternalSearchRequest(shardRouting,  builder.buildAsBytes());  context:  assertThat(searchResponse.facets().countFacet( "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().countFacet( "all ").count(),  equalTo(100l));  }  testSimpleFacets();  testSimpleFacets();  }  private  InternalSearchRequest  searchRequest(ShardRouting  shardRouting,  SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest(shardRouting,  builder.buildAsBytes());          return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  StringBuilder  multi  =  new  StringBuilder().append(nameValue);  	return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  
elasticsearch_4b2ff13833b9868c620b2943408d073f3042f526	buggy:  metaDataService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  indexMetaData.mappings(),  timeValueMillis(10));  context:  clusterService.submitStateUpdateTask( "gateway  (recovered  meta-data) ",  new  ClusterStateUpdateTask()  {  MetaData.Builder  metaDataBuilder  =  newMetaDataBuilder()  .metaData(currentState.metaData()).maxNumberOfShardsPerNode(fMetaData.maxNumberOfShardsPerNode());  for  (final  IndexMetaData  indexMetaData  :  fMetaData)  {  threadPool.execute(new  Runnable()  {  try  {                                          metaDataService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  indexMetaData.mappings(),  timeValueMillis(10));                                          metaDataService.createIndex( "gateway ",  indexMetaData.index(),  indexMetaData.settings(),  indexMetaData.mappings(),  timeValueMillis(10));  }  catch  (Exception  e)  {  }  }  });  }  return  newClusterStateBuilder().state(currentState).metaData(metaDataBuilder).build();  }  	metaDataService.createIndex( "gateway ",  indexMetaData.index(),  indexMetaData.settings(),  indexMetaData.mappings(),  timeValueMillis(10));  
libgdx_7e95896aae1ad85511c46aed3c554586db157ec8	buggy:  while  (vertices.size()  >=  3)  {  context:  final  ArrayList<Vector2>  vertices  =  new  ArrayList<Vector2>(  polygon.size());  vertices.addAll(polygon);  while  (vertices.size()  >=  3)  {  while  (vertices.size()  >  3)  {  final  int  vertexTypes[]  =  this.classifyVertices(vertices);  final  int  vertexCount  =  vertices.size();  for  (int  index  =  0;  index  <  vertexCount;  index++)  {  if  (this.isEarTip(vertices,  index,  vertexTypes))  {  this.cutEarTip(vertices,  index,  triangles);  	while  (vertices.size()  >  3)  {  
elasticsearch_73e5eb9e145ce20d375f4db7880762b32aa08c89	buggy:  .setQuery(filtered(matchAllQuery(),  orFilter(rangeFilter( "number ").lte(2).filterName( "test1 "),  rangeFilter( "number ").gt(2).filterName( "test2 "))))  context:  client.admin().indices().prepareFlush().execute().actionGet();  client.prepareIndex( "test ",   "type1 ",   "3 ").setSource(jsonBuilder().startObject()  .field( "name ",   "test3 ")  .field( "number ",  3)  .endObject()).execute().actionGet();  client.admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  searchResponse  =  client.prepareSearch()                  .setQuery(filtered(matchAllQuery(),  orFilter(rangeFilter( "number ").lte(2).filterName( "test1 "),  rangeFilter( "number ").gt(2).filterName( "test2 "))))                  .setQuery(filteredQuery(matchAllQuery(),  orFilter(rangeFilter( "number ").lte(2).filterName( "test1 "),  rangeFilter( "number ").gt(2).filterName( "test2 "))))  .execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(3l));  for  (SearchHit  hit  :  searchResponse.hits())  {  if  (hit.id().equals( "1 ")  ||  hit.id().equals( "2 "))  {  assertThat(hit.matchedFilters().length,  equalTo(1));  assertThat(hit.matchedFilters(),  hasItemInArray( "test1 "));  }  else  if  (hit.id().equals( "3 "))  {  	.setQuery(filteredQuery(matchAllQuery(),  orFilter(rangeFilter( "number ").lte(2).filterName( "test1 "),  rangeFilter( "number ").gt(2).filterName( "test2 "))))  
elasticsearch_00665663575b3d42bd3beeb6b3b558ffdb9e7306	buggy:  Filter  filter  =  lookup.getFieldMapper().termsFilter(values,  null);  context:  public  TermsFilterValue  call()  throws  Exception  {  GetResponse  getResponse  =  client.get(new  GetRequest(lookup.getIndex(),  lookup.getType(),  lookup.getId()).preference( "_local ")).actionGet();  if  (!getResponse.isExists())  {  return  NO_TERMS;  }  List<Object>  values  =  XContentMapValues.extractRawValues(lookup.getPath(),  getResponse.getSourceAsMap());  if  (values.isEmpty())  {  return  NO_TERMS;  }                      Filter  filter  =  lookup.getFieldMapper().termsFilter(values,  null);                      Filter  filter  =  lookup.getFieldMapper().termsFilter(values,  lookup.getQueryParseContext());  return  new  TermsFilterValue(estimateSizeInBytes(values),  filter);  }  }).filter;  }  catch  (ExecutionException  e)  {  if  (e.getCause()  instanceof  RuntimeException)  {  throw  (RuntimeException)  e.getCause();  }  throw  new  ElasticSearchException(e.getMessage(),  e.getCause());  	Filter  filter  =  lookup.getFieldMapper().termsFilter(values,  lookup.getQueryParseContext());  
libgdx_ebfd2fac3157b88107476429145ed8aaa4208452	buggy:  return  getBounds(str,  0,  str.length());  context:  public  TextBounds  drawWrapped  (Batch  batch,  CharSequence  str,  float  x,  float  y,  float  wrapWidth,  HAlignment  alignment)  {  cache.clear();  TextBounds  bounds  =  cache.addWrappedText(str,  x,  y,  wrapWidth,  alignment);  cache.draw(batch);  return  bounds;  }  public  TextBounds  getBounds  (CharSequence  str)  {  return  getBounds(str,  0,  str.length());  return  getBounds(str,  0,  str.length(),  cache.getBounds());  }  public  TextBounds  getBounds  (CharSequence  str,  TextBounds  textBounds)  {  return  getBounds(str,  0,  str.length(),  textBounds);  }  	return  getBounds(str,  0,  str.length(),  cache.getBounds());  
elasticsearch_565dd9086069ef26aa1121b05c60c56e667fe0d0	buggy:  IndexService  indexService  =  indicesService.indexService(request.index());  context:  request.filteringAlias(state.metaData().filteringAliases(concreteIndex,  request.index()));  request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  }  protected  ExplainResponse  shardOperation(ExplainRequest  request,  int  shardId)  throws  ElasticsearchException  {          IndexService  indexService  =  indicesService.indexService(request.index());          IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  Engine.GetResult  result  =  indexShard.get(new  Engine.Get(false,  uidTerm));  if  (!result.exists())  {  return  new  ExplainResponse(request.index(),  request.type(),  request.id(),  false);  }  SearchContext  context  =  new  DefaultSearchContext(  	IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  
elasticsearch_763f986a30b859d62d23c8cde9a748a6b75975e0	buggy:  Engine  engine  =  new  RobinEngine(shardId,  settings,  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  context:  Settings  settings  =  EMPTY_SETTINGS;  Store  store  =  new  ByteBufferStore(shardId,  settings,  null,  new  ByteBufferCache(settings));  store.deleteContent();  ThreadPool  threadPool  =  new  ThreadPool();  SnapshotDeletionPolicy  deletionPolicy  =  new  SnapshotDeletionPolicy(new  KeepOnlyLastDeletionPolicy(shardId,  settings));          Engine  engine  =  new  RobinEngine(shardId,  settings,  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),          Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  new  ConcurrentMergeSchedulerProvider(shardId,  settings),  new  AnalysisService(shardId.index()),  new  SimilarityService(shardId.index()),  new  NoneBloomCache(shardId.index()));  engine.start();  SimpleEngineBenchmark  benchmark  =  new  SimpleEngineBenchmark(store,  engine)  .numberOfContentItems(1000)  .searcherThreads(50).searcherIterations(10000)  .writerThreads(10).writerIterations(10000)  .refreshSchedule(new  TimeValue(1,  TimeUnit.SECONDS))  	Engine  engine  =  new  RobinEngine(shardId,  settings,  new  ThreadPool(),  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  
elasticsearch_0f23485a3c628ad947496ceb53bf05592ed0c2c7	buggy:  client().admin().indices().prepareRefresh( "grandissue ").get();  context:  .addMapping( "child_type_two ",   "_parent ",   "type=parent "));  client().prepareIndex( "grandissue ",   "grandparent ",   "1 ").setSource( "name ",   "Grandpa ").get();  client().prepareIndex( "grandissue ",   "parent ",   "2 ").setParent( "1 ").setSource( "name ",   "Dana ").get();  client().prepareIndex( "grandissue ",   "child_type_one ",   "3 ").setParent( "2 ").setRouting( "1 ")  .setSource( "name ",   "William ")  .get();  client().prepareIndex( "grandissue ",   "child_type_two ",   "4 ").setParent( "2 ").setRouting( "1 ")  .setSource( "name ",   "Kate ")  .get();          client().admin().indices().prepareRefresh( "grandissue ").get();          refresh();  SearchResponse  searchResponse  =  client().prepareSearch( "grandissue ").setQuery(  boolQuery().must(  hasChildQuery(   "parent ",  boolQuery().must(  hasChildQuery(   "child_type_one ",  	refresh();  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  return  translog.numberOfOperations();  context:  }  }  public  long  getTranslogId()  {  return  translog.currentId();  }  public  long  getTranslogNumberOfOperations()  {          return  translog.numberOfOperations();          return  translog.estimatedNumberOfOperations();  }  public  String  getTranslogSize()  {  return  new  ByteSizeValue(translog.memorySizeInBytes()).toString();  }  	return  translog.estimatedNumberOfOperations();  
elasticsearch_4d40a1e77c7db688727aa600322ed6f5f4e4d9df	buggy:  Node[]  nodes  =  new  Node[2];  context:  public  class  PercolatorStressBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "cluster.routing.schedule ",  200,  TimeUnit.MILLISECONDS)  .put( "gateway.type ",   "none ")  .put(SETTING_NUMBER_OF_SHARDS,  4)  .put(SETTING_NUMBER_OF_REPLICAS,  0)  .build();          Node[]  nodes  =  new  Node[2];          Node[]  nodes  =  new  Node[1];  for  (int  i  =  0;  i  <  nodes.length;  i++)  {  nodes[i]  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "node "  +  i)).node();  }  Node  clientNode  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "client ")).client(true).node();  Client  client  =  clientNode.client();  client.admin().indices().create(createIndexRequest( "test ")).actionGet();  	Node[]  nodes  =  new  Node[1];  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  .state().blocks().global(ClusterBlockLevel.METADATA);  context:  }  }  while  (!activeNodes.isEmpty()  &&  (System.currentTimeMillis()  -  start)  <  timeout.millis());  return  activeNodes.isEmpty();  }  public  ImmutableSet<ClusterBlock>  waitForNoBlocks(TimeValue  timeout,  String  node)  throws  InterruptedException  {  long  start  =  System.currentTimeMillis();  ImmutableSet<ClusterBlock>  blocks;  do  {  blocks  =  client(node).admin().cluster().prepareState().setLocal(true).execute().actionGet()                      .state().blocks().global(ClusterBlockLevel.METADATA);                      .getState().blocks().global(ClusterBlockLevel.METADATA);  }  while  (!blocks.isEmpty()  &&  (System.currentTimeMillis()  -  start)  <  timeout.millis());  return  blocks;  }  }  	.getState().blocks().global(ClusterBlockLevel.METADATA);  
elasticsearch_c75a56ca1747ec9a29074b37514c17be46f217df	buggy:  canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  poolSize.get()  >  corePoolSize);  context:  private  boolean  workerCanExit()  {  final  ReentrantLock  mainLock  =  this.mainLock;  mainLock.lock();  boolean  canExit;  try  {              canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  poolSize.get()  >  corePoolSize);              canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  (runState  >=  SHUTDOWN  ||  poolSize.get()  >  corePoolSize));  }  finally  {  mainLock.unlock();  }  return  canExit;  }  	canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  (runState  >=  SHUTDOWN  ||  poolSize.get()  >  corePoolSize));  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  wipeIndex( "test ");  context:  ensureGreen();  SearchResponse  searchResponseAfterGreen  =  client.prepareSearch( "test ").setPreference(preference).setQuery(QueryBuilders.termQuery( "field ",   "test ")).execute().actionGet();  assertHitCount(searchResponse,  1);  }  assertHitCount(searchResponse,  1);  status  =  client().admin().cluster().prepareHealth( "test ").get().getStatus();  cluster().ensureAtLeastNumNodes(numberOfReplicas  +  1);  }              wipeIndex( "test ");              wipeIndices( "test ");  }  }  }  	wipeIndices( "test ");  
elasticsearch_8d3347bb5c4a508db16028d9764e74119fa815ab	buggy:  logger.debug( "ThreadLocal  with  key  of  type  [{0}]  (value  [{1}])  and  a  value  of  type  [{2}]  (value  [{3}]):  The  ThreadLocal  has  been  forcibly  removed. ",  args);  context:  }  if  (remove)  {  Object[]  args  =  new  Object[4];  if  (key  !=  null)  {  args[0]  =  key.getClass().getCanonicalName();  args[1]  =  key.toString();  }  args[2]  =  value.getClass().getCanonicalName();  args[3]  =  value.toString();  if  (logger.isDebugEnabled())  {                                  logger.debug( "ThreadLocal  with  key  of  type  [{0}]  (value  [{1}])  and  a  value  of  type  [{2}]  (value  [{3}]):  The  ThreadLocal  has  been  forcibly  removed. ",  args);                                  logger.trace( "ThreadLocal  with  key  of  type  [{0}]  (value  [{1}])  and  a  value  of  type  [{2}]  (value  [{3}]):  The  ThreadLocal  has  been  forcibly  removed. ",  args);  }  if  (key  ==  null)  {  staleEntriesCount++;  }  else  {  mapRemove.invoke(map,  key);  }  }  }  	logger.trace( "ThreadLocal  with  key  of  type  [{0}]  (value  [{1}])  and  a  value  of  type  [{2}]  (value  [{3}]):    The  ThreadLocal  has  been  forcibly  removed. ",  args);  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  clusterState  =  ClusterState.Builder.readFrom(in,  settings,  nodesProvider.nodes().localNode());  context:  ClusterState  clusterState;  JoinResponse()  {  }  JoinResponse(ClusterState  clusterState)  {  this.clusterState  =  clusterState;  }              clusterState  =  ClusterState.Builder.readFrom(in,  settings,  nodesProvider.nodes().localNode());              clusterState  =  ClusterState.Builder.readFrom(in,  nodesProvider.nodes().localNode());  }  ClusterState.Builder.writeTo(clusterState,  out);  }  }  private  class  JoinRequestRequestHandler  extends  BaseTransportRequestHandler<JoinRequest>  {  	clusterState  =  ClusterState.Builder.readFrom(in,  nodesProvider.nodes().localNode());  
elasticsearch_c29f5afa790990f3826a0aa9923047e9e2486e8f	buggy:  return  new  IndexNameFacetExecutor(context.shardTarget().index(),  comparatorType,  size,  shardSize);  context:  script  =  parser.text();  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "execution_hint ".equals(currentFieldName)  ||   "executionHint ".equals(currentFieldName))  {  executionHint  =  parser.textOrNull();  }  }  }  if  ( "_index ".equals(field))  {              return  new  IndexNameFacetExecutor(context.shardTarget().index(),  comparatorType,  size,  shardSize);              return  new  IndexNameFacetExecutor(context.shardTarget().index(),  comparatorType,  size);  }  if  (fieldsNames  !=  null  &&  fieldsNames.length  ==  1)  {  field  =  fieldsNames[0];  fieldsNames  =  null;  }  Pattern  pattern  =  null;  	return  new  IndexNameFacetExecutor(context.shardTarget().index(),  comparatorType,  size);  
libgdx_0db3797720e11fa7f267cad4246afbc06b717656	buggy:  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/><div>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.</div><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  context:  public  class  TextAreaTest  implements  RenderListener  {  GUI  gui;  public  void  surfaceCreated  ()  {  if  (gui  !=  null)  return;  final  HTMLTextAreaModel  htmlText  =  new  HTMLTextAreaModel();  TextArea  textArea  =  new  TextArea(htmlText);  htmlText  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/><div>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.</div><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  ScrollPane  scrollPane  =  new  ScrollPane(textArea);  scrollPane.setFixed(ScrollPane.Fixed.HORIZONTAL);  FPSCounter  fpsCounter  =  new  FPSCounter(4,  2);  DialogLayout  layout  =  new  DialogLayout();  layout.setTheme( " ");  layout.setHorizontalGroup(layout.createParallelGroup().addWidgets(scrollPane,  fpsCounter));  layout.setVerticalGroup(layout.createSequentialGroup().addWidget(scrollPane).addGap(5).addWidget(fpsCounter).addGap(5));  	.setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.<br/><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  
elasticsearch_dbe2f53a0082bd5c90e8b4d1b8e6eb3cae91e5e8	buggy:  XContentType  contentType  =  XContentType.fromRestContentType(request.header( "Content-Type "));  context:  public  class  RestXContentBuilder  {  public  static  XContentBuilder  restContentBuilder(RestRequest  request)  throws  IOException  {          XContentType  contentType  =  XContentType.fromRestContentType(request.header( "Content-Type "));          XContentType  contentType  =  XContentType.fromRestContentType(request.param( "format ",  request.header( "Content-Type ")));  if  (contentType  ==  null)  {  if  (request.hasContent())  {  contentType  =  XContentFactory.xContentType(request.content());  }  }  if  (contentType  ==  null)  {  	XContentType  contentType  =  XContentType.fromRestContentType(request.param( "format ",  request.header( "Content-Type ")));  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {  context:  protected  ClusterBlockException  checkBlock(DeleteIndexTemplateRequest  request,  ClusterState  state)  {  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,   " ");  }  protected  DeleteIndexTemplateResponse  masterOperation(DeleteIndexTemplateRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<DeleteIndexTemplateResponse>  responseRef  =  new  AtomicReference<DeleteIndexTemplateResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {          indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataIndexTemplateService.RemoveListener()  {  public  void  onResponse(MetaDataIndexTemplateService.RemoveResponse  response)  {  responseRef.set(new  DeleteIndexTemplateResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataIndexTemplateService.RemoveListener()  {  
elasticsearch_b6cdb1d8fb68a747686c2a8cf35e32124b60e544	buggy:  assertThat(e.getMessage(),  equalTo( "Merge  failed  with  failures  {[The  _parent  field  can't  be  added  or  updated]} "));  context:  assertThat(mapping.size(),  greaterThanOrEqualTo(1));  //  there  are  potentially  some  meta  fields  configured  randomly  assertThat(mapping.get( "properties "),  notNullValue());  try  {  client().admin().indices().preparePutMapping( "test ").setType( "child ").setSource(jsonBuilder().startObject().startObject( "child ")  .startObject( "_parent ").field( "type ",   "parent ").endObject()  .endObject().endObject()).get();  fail();  }  catch  (MergeMappingException  e)  {              assertThat(e.getMessage(),  equalTo( "Merge  failed  with  failures  {[The  _parent  field  can't  be  added  or  updated]} "));              assertThat(e.getMessage(),  equalTo( "Merge  failed  with  failures  {[The  _parent  field's  type  option  can't  be  changed]} "));  }  }  public  void  testTopChildrenBug_concurrencyIssue()  throws  Exception  {  assertAcked(prepareCreate( "test ")  .addMapping( "parent ")  	assertThat(e.getMessage(),  equalTo( "Merge  failed  with  failures  {[The  _parent  field's  type  option  can't  be  changed]} "));  
elasticsearch_ed281fbfd5d620a568afcb7399232c008da9616d	buggy:  return  getLogger(parentLogger.getName()  +  s,  parentLogger.getPrefix());  context:  if  (name  !=  null)  {  prefixesList.add(name);  }  if  (prefixes  !=  null  &&  prefixes.length  >  0)  {  prefixesList.addAll(asList(prefixes));  }  return  getLogger(getLoggerName(loggerName),  prefixesList.toArray(new  String[prefixesList.size()]));  }  public  static  ESLogger  getLogger(ESLogger  parentLogger,  String  s)  {          return  getLogger(parentLogger.getName()  +  s,  parentLogger.getPrefix());          return  ESLoggerFactory.getLogger(parentLogger.getPrefix(),  getLoggerName(parentLogger.getName()  +  s));  }  public  static  ESLogger  getLogger(String  s)  {  return  ESLoggerFactory.getLogger(s);  }  public  static  ESLogger  getLogger(Class  clazz)  {  return  ESLoggerFactory.getLogger(getLoggerName(buildClassLoggerName(clazz)));  	return  ESLoggerFactory.getLogger(parentLogger.getPrefix(),  getLoggerName(parentLogger.getName()  +  s));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  aggregated.release();  context:  final  int[]  values  =  aggregated.v().values;  for  (int  i  =  0;  i  <  entries.allocated.length;  i++)  {  if  (states[i])  {  ordered.add(new  LongEntry(keys[i],  values[i]));  }  }  first.entries  =  ordered;  first.missing  =  missing;  first.total  =  total;          aggregated.release();          aggregated.close();  return  first;  }  private  void  trimExcessEntries()  {  if  (requiredSize  >=  entries.size())  {  return;  }  	aggregated.close();  
elasticsearch_76d042f3c5c4c4fcce91a09e1d10204ff7dace36	buggy:  throw  new  ConnectTransportException(node,   "Can't  connect  to  a  null  node ");  context:  return  connectedNodes.containsKey(node);  }  if  (!lifecycle.started())  {  throw  new  ElasticSearchIllegalStateException( "Can't  add  nodes  to  a  stopped  transport ");  }  if  (node  ==  null)  {              throw  new  ConnectTransportException(node,   "Can't  connect  to  a  null  node ");              throw  new  ConnectTransportException(null,   "Can't  connect  to  a  null  node ");  }  try  {  NodeChannels  nodeChannels  =  connectedNodes.get(node);  if  (nodeChannels  !=  null)  {  return;  }  synchronized  (this)  {  	throw  new  ConnectTransportException(null,   "Can't  connect  to  a  null  node ");  
elasticsearch_e4244268faac78abda4ac5adabc1ea4dbcc1e575	buggy:  IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContentStandalone(parser);  context:  File  templatesDir  =  new  File(environment.configFile(),   "templates ");  if  (templatesDir.exists()  &&  templatesDir.isDirectory())  {  File[]  templatesFiles  =  templatesDir.listFiles();  if  (templatesFiles  !=  null)  {  for  (File  templatesFile  :  templatesFiles)  {  XContentParser  parser  =  null;  try  {  byte[]  templatesData  =  Streams.copyToByteArray(templatesFile);  parser  =  XContentHelper.createParser(templatesData,  0,  templatesData.length);                          IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContentStandalone(parser);                          IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContent(parser);  if  (Regex.simpleMatch(template.template(),  request.index))  {  templates.add(template);  }  }  catch  (Exception  e)  {  }  finally  {  IOUtils.closeWhileHandlingException(parser);  }  	IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContent(parser);  
elasticsearch_bc452dff84da86298b5234f81e90dd768244d70c	buggy:  GeoDistance  geoDistance  =  GeoDistance.ARC;  context:  boolean  cache  =  false;  CacheKeyFilter.Key  cacheKey  =  null;  String  filterName  =  null;  String  currentFieldName  =  null;  GeoPoint  point  =  new  GeoPoint();  String  fieldName  =  null;  double  distance  =  0;  Object  vDistance  =  null;  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;  //  default  unit          GeoDistance  geoDistance  =  GeoDistance.ARC;          GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  String  optimizeBbox  =   "memory ";  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  fieldName  =  currentFieldName;  	GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  indexShard.refresh(new  Engine.Refresh().force(request.force()).source( "api "));  context:  }  protected  ShardRefreshResponse  newShardResponse()  {  return  new  ShardRefreshResponse();  }  protected  ShardRefreshResponse  shardOperation(ShardRefreshRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          indexShard.refresh(new  Engine.Refresh().force(request.force()).source( "api "));          indexShard.refresh(new  Engine.Refresh( "api ").force(request.force()));  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }  	indexShard.refresh(new  Engine.Refresh( "api ").force(request.force()));  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  return  new  TermsFacetCollector(facetName,  field,  size,  context.fieldDataCache(),  context.mapperService(),  excluded);  context:  excluded  =  builder.build();  }  }  else  if  (token.isValue())  {  if  ( "field ".equals(fieldName))  {  field  =  parser.text();  }  else  if  ( "size ".equals(fieldName))  {  size  =  parser.intValue();  }  }  }          return  new  TermsFacetCollector(facetName,  field,  size,  context.fieldDataCache(),  context.mapperService(),  excluded);          return  new  TermsFacetCollector(facetName,  field,  size,  context.numberOfShards(),  context.fieldDataCache(),  context.mapperService(),  excluded);  }  }  	return  new  TermsFacetCollector(facetName,  field,  size,  context.numberOfShards(),  context.fieldDataCache(),  context.mapperService(),  excluded);  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  return  querySource(queryBuilder.build());  context:  super.listenerThreaded(threadedListener);  return  this;  }  String  querySource()  {  return  querySource;  }          return  querySource(queryBuilder.build());          return  querySource(queryBuilder.buildAsString());  }  this.querySource  =  querySource;  return  this;  }  String  queryParserName()  {  	return  querySource(queryBuilder.buildAsString());  
libgdx_b8f451a6dee64a2bc6d9da450f042a82ff4729c8	buggy:  sound.play();  context:  return  false;  }  return  false;  }  sound.play();  sound.play(0.5f);  return  false;  }  return  false;  }  	sound.play(0.5f);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  updateSettingsService.updateSettings(request.settings(),  request.indices(),  new  MetaDataUpdateSettingsService.Listener()  {  context:  protected  UpdateSettingsResponse  newResponse()  {  return  new  UpdateSettingsResponse();  }  protected  UpdateSettingsResponse  masterOperation(UpdateSettingsRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          updateSettingsService.updateSettings(request.settings(),  request.indices(),  new  MetaDataUpdateSettingsService.Listener()  {          updateSettingsService.updateSettings(request.getSettings(),  request.getIndices(),  new  MetaDataUpdateSettingsService.Listener()  {  public  void  onSuccess()  {  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  failureRef.set(t);  	updateSettingsService.updateSettings(request.getSettings(),  request.getIndices(),  new  MetaDataUpdateSettingsService.Listener()  {  
elasticsearch_22cbdd930cd0b5f274289c97b951b8dedca8bd4b	buggy:  assertThat(docs.getOrd(i),  equalTo(0L));  context:  for  (int  i  =  0;  i  <  numOrds;  i++)  {  assertThat(docs.nextOrd(),  equalTo(docOrds.get(i)));  }  final  long[]  array  =  new  long[docOrds.size()];  for  (int  i  =  0;  i  <  array.length;  i++)  {  array[i]  =  docOrds.get(i);  }  assertIter(docs,  docId,  array);  }  for  (int  i  =  docId  +  1;  i  <  ordAndId.id;  i++)  {                      assertThat(docs.getOrd(i),  equalTo(0L));                      assertThat(docs.getOrd(i),  equalTo(Ordinals.MISSING_ORDINAL));  }  docId  =  ordAndId.id;  docOrds.clear();  docOrds.add(ordAndId.ord);  }  }  	assertThat(docs.getOrd(i),  equalTo(Ordinals.MISSING_ORDINAL));  
elasticsearch_cdf1fc8981c99ed8af58a33bd2bba63fe192c26d	buggy:  return  !acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));  context:  ParentDocSet(IndexReader  reader,  THashSet<HashedBytesArray>  parents,  IdReaderTypeCache  typeCache,  Bits  acceptDocs)  {  super(reader.maxDoc());  this.reader  =  reader;  this.parents  =  parents;  this.typeCache  =  typeCache;  this.acceptDocs  =  acceptDocs;  }  public  boolean  get(int  doc)  {                  return  !acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));                  return  acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));  }  }  static  class  UidCollector  extends  NoopCollector  {  final  String  parentType;  final  SearchContext  context;  final  THashSet<HashedBytesArray>  collectedUids;  	return  acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iters  =  atLeast(5);  context:  }  catch  (ElasticsearchException  ex)  {  }  String[]  queries  =  new  String[]  {   "{\ "flt\ ":  {\ "fields\ ":  [\ "comment\ "],  \ "like_text\ ":  \ "FFFdfds\ ",\ "fuzziness\ ":  \ "4\ "}} ",   "{\ "flt\ ":  {\ "fields\ ":  [\ "comment\ "],  \ "like_text\ ":  \ "FFFdfds\ ",\ "fuzziness\ ":  \ "4.00000000\ "}} ",   "{\ "flt\ ":  {\ "fields\ ":  [\ "comment\ "],  \ "like_text\ ":  \ "FFFdfds\ ",\ "fuzziness\ ":  \ "4.\ "}} ",   "{\ "flt\ ":  {\ "fields\ ":  [\ "comment\ "],  \ "like_text\ ":  \ "FFFdfds\ ",\ "fuzziness\ ":  4}} ",   "{\ "flt\ ":  {\ "fields\ ":  [\ "comment\ "],  \ "like_text\ ":  \ "FFFdfds\ ",\ "fuzziness\ ":  4.0}} "  };          int  iters  =  atLeast(5);          int  iters  =  scaledRandomIntBetween(5,  100);  for  (int  i  =  0;  i  <  iters;  i++)  {  parsedQuery  =  queryParser.parse(new  BytesArray((String)  randomFrom(queries))).query();  parsedQuery1  =  queryParser.parse(new  BytesArray((String)  randomFrom(queries))).query();  assertThat(parsedQuery1,  instanceOf(FuzzyLikeThisQuery.class));  assertThat(parsedQuery,  instanceOf(FuzzyLikeThisQuery.class));  assertThat(parsedQuery,  equalTo(parsedQuery1));  }  }  	int  iters  =  scaledRandomIntBetween(5,  100);  
libgdx_eeb19856c8e6cb547f80700cd8b968bda3f480cb	buggy:  data.lineHeight  =  data.lineHeight  *  x;  context:  public  Color  getColor  ()  {  return  cache.getColor();  }  public  void  setScale  (float  scaleX,  float  scaleY)  {  BitmapFontData  data  =  this.data;  float  x  =  scaleX  /  data.scaleX;  float  y  =  scaleY  /  data.scaleY;  data.lineHeight  =  data.lineHeight  *  x;  data.lineHeight  =  data.lineHeight  *  y;  data.spaceWidth  =  data.spaceWidth  *  x;  data.xHeight  =  data.xHeight  *  y;  data.capHeight  =  data.capHeight  *  y;  data.ascent  =  data.ascent  *  y;  data.descent  =  data.descent  *  y;  data.down  =  data.down  *  y;  data.scaleX  =  scaleX;  data.scaleY  =  scaleY;  	data.lineHeight  =  data.lineHeight  *  y;  
elasticsearch_8d1e04a973a1d104251fead938c9f85f36ba6694	buggy:  ClusterHealthResponse  clusterHealthResponse  =  client.client().admin().cluster().prepareHealth().setWaitForGreenStatus().setTimeout( "10m ").execute().actionGet();  context:  int  nodeId  =  ThreadLocalRandom.current().nextInt();  for  (int  i  =  0;  i  <  nodes.length;  i++)  {  int  nodeIdx  =  Math.abs(nodeId++)  %  nodes.length;  nodes[nodeIdx].close();  nodes[nodeIdx]  =  NodeBuilder.nodeBuilder().settings(settings).node();  }              ClusterHealthResponse  clusterHealthResponse  =  client.client().admin().cluster().prepareHealth().setWaitForGreenStatus().setTimeout( "10m ").execute().actionGet();              ClusterHealthResponse  clusterHealthResponse  =  client.client().admin().cluster().prepareHealth().setWaitForGreenStatus().setWaitForRelocatingShards(0).setTimeout( "10m ").execute().actionGet();  if  (clusterHealthResponse.timedOut())  {  System.err.println( "-->  timed  out  waiting  for  green  state... ");  ClusterState  state  =  client.client().admin().cluster().prepareState().execute().actionGet().state();  throw  new  ElasticSearchException( "timed  out  waiting  for  green  state ");  }  else  {  	ClusterHealthResponse  clusterHealthResponse  =  client.client().admin().cluster().prepareHealth().setWaitForGreenStatus().setWaitForRelocatingShards(0).setTimeout( "10m ").execute().actionGet();  
elasticsearch_5cdba0383b08b24e6d829975b308e60bc81fc459	buggy:  int  COUNT  =  200000;  context:  Node  node1  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "server1 ")).node();  Node  node2  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "server2 ")).node();  Client  client1  =  node1.client();  Thread.sleep(1000);  client1.admin().indices().create(createIndexRequest( "test ")).actionGet();  Thread.sleep(5000);  StopWatch  stopWatch  =  new  StopWatch().start();          int  COUNT  =  200000;          int  COUNT  =  2000000;  for  (int  i  =  0;  i  <  COUNT;  i++)  {  client1.index(  indexRequest( "test ")  .type( "type1 ")  .id(Integer.toString(i))  .source(source(Integer.toString(i),   "test "  +  i))  .opType(IndexRequest.OpType.INDEX)  	int  COUNT  =  2000000;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  seenDevices  =  new  HashSet<String>(infos.length);  context:  public  Info  getTotal()  {  return  total();  }  public  Info  total()  {  if  (total  !=  null)  {  return  total;  }  Info  res  =  new  Info();          Set<String>  seenDevices  =  new  HashSet<String>(infos.length);          Set<String>  seenDevices  =  new  HashSet<>(infos.length);  for  (Info  subInfo  :  infos)  {  if  (subInfo.dev  !=  null)  {  if  (!seenDevices.add(subInfo.dev))  {  continue;  //  already  added  numbers  for  this  device;  }  }  res.add(subInfo);  }  	Set<String>  seenDevices  =  new  HashSet<>(infos.length);  
elasticsearch_a0e9532dcaa79ad931c8dc18cb6dec2f00b19400	buggy:  return  ImmutableSettings.settingsBuilder().put( "plugin.types ",  CustomSuggesterPlugin.class.getName()).put(super.nodeSettings(nodeOrdinal)).build();  context:  public  class  CustomSuggesterSearchTests  extends  ElasticsearchIntegrationTest  {  protected  Settings  nodeSettings(int  nodeOrdinal)  {          return  ImmutableSettings.settingsBuilder().put( "plugin.types ",  CustomSuggesterPlugin.class.getName()).put(super.nodeSettings(nodeOrdinal)).build();          return  ImmutableSettings.settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "plugin.types ",  CustomSuggesterPlugin.class.getName()).build();  }  public  void  testThatCustomSuggestersCanBeRegisteredAndWork()  throws  Exception  {  createIndex( "test ");  client().prepareIndex( "test ",   "test ",   "1 ").setSource(jsonBuilder()  .startObject()  .field( "name ",   "arbitrary  content ")  	return  ImmutableSettings.settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "plugin.types ",  CustomSuggesterPlugin.class.getName()).build();  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  clusterStateRequest.filterMetaData(true);  context:  void  documentation(StringBuilder  sb)  {  sb.append( "/_cat/allocation\n ");  }  public  void  doRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  String[]  nodes  =  Strings.splitStringByCommaToArray(request.param( "nodes "));  final  ClusterStateRequest  clusterStateRequest  =  new  ClusterStateRequest();          clusterStateRequest.filterMetaData(true);          clusterStateRequest.clear().routingTable(true);  clusterStateRequest.local(request.paramAsBoolean( "local ",  clusterStateRequest.local()));  clusterStateRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterStateRequest.masterNodeTimeout()));  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  public  void  onResponse(final  ClusterStateResponse  state)  {  NodesStatsRequest  statsRequest  =  new  NodesStatsRequest(nodes);  statsRequest.clear().fs(true);  	clusterStateRequest.clear().routingTable(true);  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  Settings  settings  =  settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).build();  context:  public  class  SimpleMultiSearchTests  extends  AbstractNodesTests  {  private  Client  client;  public  void  createNodes()  throws  Exception  {          Settings  settings  =  settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).build();          Settings  settings  =  settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).build();  startNode( "node1 ",  settings);  startNode( "node2 ",  settings);  client  =  getClient();  }  public  void  closeNodes()  {  client.close();  	Settings  settings  =  settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).build();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.admin().cluster().searchShards(clusterSearchShardsRequest,  new  ActionListener<ClusterSearchShardsResponse>()  {  public  void  onResponse(ClusterSearchShardsResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_167538ef0d8003e083af4f85da139c7020afcc57	buggy:  shard.refresh(new  Engine.Refresh().force(true));  context:  }  }  private  boolean  hasPercolatorType(IndexShard  indexShard)  {  ShardId  otherShardId  =  indexShard.shardId();  return  shardId.equals(otherShardId)  &&  mapperService.hasMapping(PercolatorService.Constants.TYPE_NAME);  }  private  void  loadQueries(IndexShard  shard)  {  try  {                  shard.refresh(new  Engine.Refresh().force(true));                  shard.refresh(new  Engine.Refresh().force(true).source( "percolator_load_queries "));  Engine.Searcher  searcher  =  shard.acquireSearcher();  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.Constants.TYPE_NAME))  )  );  QueriesLoaderCollector  queries  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  	shard.refresh(new  Engine.Refresh().force(true).source( "percolator_load_queries "));  
elasticsearch_7c04ef6cbccf472a80426a0eddb1679e5e6071a5	buggy:  return  bottom  -  currentFieldData.shortValue(doc);  context:  return  FieldDataType.DefaultTypes.BYTE;  }  return  values[slot1]  -  values[slot2];  }          return  bottom  -  currentFieldData.shortValue(doc);          return  bottom  -  currentFieldData.byteValue(doc);  }  values[slot]  =  currentFieldData.byteValue(doc);  }  this.bottom  =  values[bottom];  	return  bottom  -  currentFieldData.byteValue(doc);  
libgdx_f47cd059f5a72414701390724555e6540ceda18d	buggy:  switch  (type)  {  context:  }  public  String[]  asStringArray  ()  {  if  (type  !=  ValueType.array)  throw  new  IllegalStateException( "Value  is  not  an  array:   "  +  type);  String[]  array  =  new  String[size];  int  i  =  0;  for  (JsonValue  value  =  child;  value  !=  null;  value  =  value.next,  i++)  {  String  v;  switch  (type)  {  switch  (value.type)  {  case  stringValue:  v  =  value.stringValue;  break;  case  doubleValue:  v  =  Double.toString(value.doubleValue);  break;  case  longValue:  v  =  Long.toString(value.longValue);  	switch  (value.type)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  ImmutableList<String>  indices  =  ImmutableList.copyOf(metaData.concreteIndices(request.indices(),  request.indicesOptions()));  context:  public  ClusterState  execute(ClusterState  currentState)  {  validate(request,  currentState);  MetaData  metaData  =  currentState.metaData();  MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  SnapshotMetaData  snapshots  =  metaData.custom(SnapshotMetaData.TYPE);  if  (snapshots  ==  null  ||  snapshots.entries().isEmpty())  {                      ImmutableList<String>  indices  =  ImmutableList.copyOf(metaData.concreteIndices(request.indices(),  request.indicesOptions()));                      ImmutableList<String>  indices  =  ImmutableList.copyOf(metaData.concreteIndices(request.indicesOptions(),  request.indices()));  newSnapshot  =  new  SnapshotMetaData.Entry(snapshotId,  request.includeGlobalState(),  State.INIT,  indices,  null);  snapshots  =  new  SnapshotMetaData(newSnapshot);  }  else  {  throw  new  ConcurrentSnapshotExecutionException(snapshotId,   "a  snapshot  is  already  running ");  }  mdBuilder.putCustom(SnapshotMetaData.TYPE,  snapshots);  	ImmutableList<String>  indices  =  ImmutableList.copyOf(metaData.concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_852a1103f38ea96d83f7cbae7cd8b8ce5705a53a	buggy:  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);  context:  private  void  publish(LocalDiscovery[]  members,  ClusterState  clusterState,  final  ClusterStatePublishResponseHandler  publishResponseHandler)  {  try  {  final  byte[]  clusterStateBytes  =  Builder.toBytes(clusterState);  for  (final  LocalDiscovery  discovery  :  members)  {  if  (discovery.master)  {  continue;  }                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode,  clusterName);  nodeSpecificClusterState.status(ClusterState.ClusterStateStatus.RECEIVED);  if  (nodeSpecificClusterState.nodes().localNode()  !=  null)  {  discovery.clusterService.submitStateUpdateTask( "local-disco-receive(from  master) ",  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  if  (nodeSpecificClusterState.version()  <  currentState.version()  &&  Objects.equal(nodeSpecificClusterState.nodes().masterNodeId(),  currentState.nodes().masterNodeId()))  {  return  currentState;  	final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode,  clusterName);  
elasticsearch_c4be4975d6c0f88a6e2783f372594efa1ab8b3af	buggy:  logger.info( "recovered  [{}]  indices  into  cluster_state,  allocating ",  clusterState.metaData().indices().size());  context:  }  }  RoutingAllocation.Result  routingResult  =  shardsAllocation.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());  return  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  }                      logger.info( "recovered  [{}]  indices  into  cluster_state,  allocating ",  clusterState.metaData().indices().size());                      logger.info( "recovered  [{}]  indices  into  cluster_state ",  clusterState.metaData().indices().size());  latch.countDown();  }  });  }  	logger.info( "recovered  [{}]  indices  into  cluster_state ",  clusterState.metaData().indices().size());  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));  context:  DocumentMapper  childDocMapper  =  parseContext.mapperService().documentMapper(childType);  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  mapping  for  for  type  [ "  +  childType  +   "] ");  }  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  HasChildFilter  childFilter  =  new  HasChildFilter(query,  scope,  childType,  parentType,  searchContext);  searchContext.addScopePhase(childFilter);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  childFilter);  	query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  
elasticsearch_7ea490dfd15ea9f969d41e00fd452c0144c804dc	buggy:  return  new  DoubleTerms(terms.getName(),  terms.order,  terms.formatter,  terms.requiredSize,  terms.shardSize,  terms.minDocCount,  Arrays.asList(buckets),  terms.showTermDocCountError,  terms.docCountError);  context:  final  long  term  =  bucket.getKeyAsNumber().longValue();  final  double  value  =  NumericUtils.sortableLongToDouble(term);  return  new  DoubleTerms.Bucket(value,  bucket.docCount,  bucket.aggregations,  bucket.showDocCountError,  bucket.docCountError,  bucket.formatter);  }  private  static  DoubleTerms  convertToDouble(LongTerms  terms)  {  final  InternalTerms.Bucket[]  buckets  =  terms.getBuckets().toArray(new  InternalTerms.Bucket[0]);  for  (int  i  =  0;  i  <  buckets.length;  ++i)  {  buckets[i]  =  convertToDouble(buckets[i]);  }          return  new  DoubleTerms(terms.getName(),  terms.order,  terms.formatter,  terms.requiredSize,  terms.shardSize,  terms.minDocCount,  Arrays.asList(buckets),  terms.showTermDocCountError,  terms.docCountError);          return  new  DoubleTerms(terms.getName(),  terms.order,  terms.formatter,  terms.requiredSize,  terms.shardSize,  terms.minDocCount,  Arrays.asList(buckets),  terms.showTermDocCountError,  terms.docCountError,  terms.otherDocCount);  }  }  	return  new  DoubleTerms(terms.getName(),  terms.order,  terms.formatter,  terms.requiredSize,  terms.shardSize,  terms.minDocCount,  Arrays.asList(buckets),  terms.showTermDocCountError,  terms.docCountError,  terms.otherDocCount);  
elasticsearch_4c8978237fdb07ed81fc7cb0255f43cfe7c1f490	buggy:  return  indicesService.indexServiceSafe(request.index()).operationRouting().deleteByQueryShards(clusterService.state());  context:  return   "indices/index/deleteByQuery ";  }  state.blocks().indexBlockedRaiseException(ClusterBlockLevel.WRITE,  request.index());  }          return  indicesService.indexServiceSafe(request.index()).operationRouting().deleteByQueryShards(clusterService.state());          return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  }  return  new  ShardDeleteByQueryRequest(request,  shardId);  }  }  	return  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  
elasticsearch_fe86c8bc88a321bf587dd8eb4df52aaed9ed2156	buggy:  distanceValues  =  GeoDistance.distanceValues(distance,  geoValues);  context:  this.metaData  =  MetaData.builder(source.metaData()).uniqueness(MetaData.Uniqueness.UNKNOWN).build();  this.distanceType  =  distanceType;  this.unit  =  unit;  this.origin  =  origin;  }  public  void  setNextReader(AtomicReaderContext  reader)  {  final  MultiGeoPointValues  geoValues  =  source.geoPointValues();  final  FixedSourceDistance  distance  =  distanceType.fixedSourceDistance(origin.getLat(),  origin.getLon(),  unit);                  distanceValues  =  GeoDistance.distanceValues(distance,  geoValues);                  distanceValues  =  GeoDistance.distanceValues(geoValues,  distance);  }  public  MetaData  metaData()  {  return  metaData;  }  	distanceValues  =  GeoDistance.distanceValues(geoValues,  distance);  
libgdx_1f8a06a327e6c2e149705a4da4a5cddd7cde7a24	buggy:  generate( "src ",   "bin ",   "jni ",  new  String[0],  new  String[0]);  context:  CMethodParser  cMethodParser  =  new  JniHeaderCMethodParser();  CMethodParserResult  cResult;  public  void  generate()  throws  Exception  {  generate( "src ",   "bin ",   "jni ",  new  String[0],  new  String[0]);  generate( "src ",   "bin ",   "jni ",  null,  null);  }  	generate( "src ",   "bin ",   "jni ",  null,  null);  
elasticsearch_265b386fa75f9446378e65002d9fc16766e67892	buggy:  int  numberOfUpdates  =  scaledRandomIntBetween(1,  25);  context:  Filter  filterMe;  if  (random().nextBoolean())  {  filterMe  =  SearchContext.current().filterCache().cache(rawFilterMe);  }  else  {  filterMe  =  rawFilterMe;  }  if  (random().nextBoolean())  {                  int  numberOfUpdates  =  scaledRandomIntBetween(1,  25);                  int  numberOfUpdates  =  childIdToParentId.isEmpty()  ?  0  :  scaledRandomIntBetween(1,  25);  int[]  childIds  =  childIdToParentId.keys().toArray();  for  (int  j  =  0;  j  <  numberOfUpdates;  j++)  {  int  childId  =  childIds[random().nextInt(childIds.length)];  String  childUid  =  Uid.createUid( "child ",  Integer.toString(childId));  indexWriter.deleteDocuments(new  Term(UidFieldMapper.NAME,  childUid));  Document  document  =  new  Document();  document.add(new  StringField(UidFieldMapper.NAME,  childUid,  Field.Store.YES));  	int  numberOfUpdates  =  childIdToParentId.isEmpty()  ?  0  :  scaledRandomIntBetween(1,  25);  
elasticsearch_70bbcb4c489108aed2d87d91c23194c7a8b2d9b9	buggy:  System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version()  +   "( "  +  JvmInfo.jvmInfo().vmVersion()  +   ") ");  context:  sb.append(major).append('.').append(minor).append('.').append(revision);  if  (build  <  50)  {  sb.append( ".Beta ").append(build);  }  else  if  (build  <  99)  {  sb.append( ".RC ").append(build  -  50);  }  return  sb.toString();  }  public  static  void  main(String[]  args)  {          System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version()  +   "( "  +  JvmInfo.jvmInfo().vmVersion()  +   ") ");          System.out.println( "Version:   "  +  Version.CURRENT  +   ",  Build:   "  +  Build.CURRENT.hashShort()  +   "/ "  +  Build.CURRENT.timestamp()  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version());  }  public  String  toString()  {  StringBuilder  sb  =  new  StringBuilder();  sb.append(number());  if  (snapshot())  {  sb.append( "-SNAPSHOT ");  	System.out.println( "Version:   "  +  Version.CURRENT  +   ",  Build:   "  +  Build.CURRENT.hashShort()  +   "/ "  +  Build.CURRENT.timestamp()  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version());  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "nested  path  must  be  set  on  nested  aggregation  [ "  +  name  +   "] ");  context:  public  NestedBuilder  path(String  path)  {  this.path  =  path;  return  this;  }  protected  XContentBuilder  internalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject();  if  (path  ==  null)  {              throw  new  SearchSourceBuilderException( "nested  path  must  be  set  on  nested  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "nested  path  must  be  set  on  nested  aggregation  [ "  +  getName()  +   "] ");  }  builder.field( "path ",  path);  return  builder.endObject();  }  }  	throw  new  SearchSourceBuilderException( "nested  path  must  be  set  on  nested  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  Filter  facetFilter  =  context.queryParserService().parseInnerFilter(parser);  context:  return  FacetExecutor.Mode.COLLECTOR;  }  public  FacetExecutor.Mode  defaultGlobalMode()  {  return  FacetExecutor.Mode.POST;  }  public  FacetExecutor  parse(String  facetName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          Filter  facetFilter  =  context.queryParserService().parseInnerFilter(parser);          Filter  facetFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  return  new  FilterFacetExecutor(facetFilter);  }  }  	Filter  facetFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  
libgdx_0de363981a44cd72e72c824dc0f3798f1c9afb52	buggy:  new  JoglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  false);  context:  ++  libgdx_0de363981a44cd72e72c824dc0f3798f1c9afb52_6202.java  package  com.dozingcatsoftware.bouncy;  public  class  BouncyDesktop  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  false);  new  JoglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  true);  }  }  	new  JoglApplication(new  Bouncy(),   "Bouncy ",  320,  480,  true);  
elasticsearch_94a77b69d66df3a8289dba05748cf84c2147a45a	buggy:  bind(String.class).annotatedWith(IndexerIndexName.class).toInstance(settings.get( "indexer.index_name ",   "indexer "));  context:  public  class  IndexersModule  extends  AbstractModule  {  private  final  Settings  settings;  public  IndexersModule(Settings  settings)  {  this.settings  =  settings;  }          bind(String.class).annotatedWith(IndexerIndexName.class).toInstance(settings.get( "indexer.index_name ",   "indexer "));          bind(String.class).annotatedWith(IndexerIndexName.class).toInstance(IndexerIndexName.Conf.indexName(settings));  bind(IndexersService.class).asEagerSingleton();  bind(IndexerClusterService.class).asEagerSingleton();  bind(IndexersRouter.class).asEagerSingleton();  bind(IndexerManager.class).asEagerSingleton();  }  }  	bind(String.class).annotatedWith(IndexerIndexName.class).toInstance(IndexerIndexName.Conf.indexName(settings));  
libgdx_349ea157ebcaeb26afca1f252439b70a53fbbadd	buggy:  GdxTest  test  =  new  TimerTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  TimerTest();  GdxTest  test  =  new  MusicTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.r  =  config.g  =  config.b  =  config.a  =  8;  config.width  =  960;  config.height  =  600;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  MusicTest();  
elasticsearch_7c5a954b93ee2c3b65222aee35266f3ca479512a	buggy:  }  else  {  context:  if(out.intersect  !=  out.next.coordinate)  {  Edge  e2  =  new  Edge(out.intersect,  out.next);  in.next  =  new  Edge(in.intersect,  e2,  in.intersect);  }  else  {  in.next  =  new  Edge(in.intersect,  out.next,  in.intersect);  }  out.next  =  new  Edge(out.intersect,  e1,  out.intersect);          }  else  {          }  else  if  (in.next  !=  out){  Edge  e2  =  new  Edge(out.intersect,  in.next,  out.intersect);  if(out.intersect  !=  out.next.coordinate)  {  Edge  e1  =  new  Edge(out.intersect,  out.next);  in.next  =  new  Edge(in.intersect,  e1,  in.intersect);  	}  else  if  (in.next  !=  out){  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  context:  createUI();  multiplexer  =  new  InputMultiplexer();  Gdx.input.setInputProcessor(multiplexer);  multiplexer.addProcessor(ui);  multiplexer.addProcessor(controller);  }  private  void  createUI  ()  {  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  ui  =  new  Stage();  String[]  filters  =  new  String[TextureFilter.values().length];  int  idx  =  0;  for  (TextureFilter  filter  :  TextureFilter.values())  {  filters[idx++]  =  filter.toString();  }  hwMipMap  =  new  CheckBox( "Hardware  Mips ",  skin);  minFilter  =  new  SelectBox(skin);  	ui  =  new  Stage();  
libgdx_ff63cc965b1111792cf3dbd9758ccd9bfb197aca	buggy:  return  file.exists();  context:  public  boolean  exists  ()  {  return  file.exists();  return  file().exists();  }  public  File  file  ()  {  if  (type  ==  FileType.External)  return  new  File(IOSFiles.externalPath,  file.getPath());  if  (type  ==  FileType.Local)  return  new  File(IOSFiles.localPath,  file.getPath());  return  file;  }  }  	return  file().exists();  
elasticsearch_ac1e9856703960d953b81ba987f04596c925d153	buggy:  query  =  new  ChildrenConstantScoreQuery(innerQuery,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  true);  context:  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  Query  query;  Filter  parentFilter  =  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null);  if  (!deleteByQuery  &&  scoreType  !=  null)  {  query  =  new  ChildrenQuery(parentType,  childType,  parentFilter,  innerQuery,  scoreType,  shortCircuitParentDocSet);  }  else  {              query  =  new  ChildrenConstantScoreQuery(innerQuery,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  true);              query  =  new  ChildrenConstantScoreQuery(innerQuery,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet);  if  (deleteByQuery)  {  query  =  new  XConstantScoreQuery(new  DeleteByQueryWrappingFilter(query));  }  }  if  (queryName  !=  null)  {  parseContext.addNamedQuery(queryName,  query);  }  query.setBoost(boost);  	query  =  new  ChildrenConstantScoreQuery(innerQuery,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  mapper  =  context.mapperService().smartNameFieldMapper(keyField);  context:  }  if  (entries.isEmpty())  {  throw  new  FacetPhaseExecutionException(facetName,   "no  ranges  defined  for  range  facet ");  }  RangeFacet.Entry[]  rangeEntries  =  entries.toArray(new  RangeFacet.Entry[entries.size()]);  if  (keyField  !=  null)  {              FieldMapper  mapper  =  context.mapperService().smartNameFieldMapper(keyField);              FieldMapper  mapper  =  context.smartNameFieldMapper(keyField);  if  (mapper  ==  null)  {  throw  new  FacetPhaseExecutionException(facetName,   "No  mapping  found  for  key_field  [ "  +  keyField  +   "] ");  }  for  (RangeFacet.Entry  entry  :  rangeEntries)  {  if  (entry.fromAsString  !=  null)  {  entry.from  =  ((Number)  mapper.valueFromString(entry.fromAsString)).doubleValue();  }  if  (entry.toAsString  !=  null)  {  	FieldMapper  mapper  =  context.smartNameFieldMapper(keyField);  
elasticsearch_4bdae621f92beb226cf5873a9efe721b38c7e0c7	buggy:  new  ScriptModule(),  context:  private  IndexQueryParserService  queryParser;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),                  new  ScriptModule(),                  new  ScriptModule(settings),  new  MapperServiceModule(),  new  IndexSettingsModule(settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index)  	new  ScriptModule(settings),  
libgdx_d661aac56fe4dbc87c95bba23eccb4a828e49297	buggy:  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  context:  font.dispose();  }  public  boolean  isDone  ()  {  return  isDone;  }  public  void  draw  (float  delta)  {  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  viewMatrix.setToOrtho2D(0,  0,  480,  320);  spriteBatch.setProjectionMatrix(viewMatrix);  spriteBatch.setTransformMatrix(transformMatrix);  spriteBatch.begin();  spriteBatch.disableBlending();  spriteBatch.setColor(Color.WHITE);  spriteBatch.draw(background,  0,  0,  480,  320,  0,  0,  512,  512,  false,  false);  	Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  
libgdx_db17325d71bec6c0769d0a7bc20060d617360000	buggy:  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.xml "),  Gdx.files.internal( "data/uiskin.png "));  context:  projector  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  projector.position.set(2,  3,  2);  projector.lookAt(0,  0,  0);  projector.normalizeUp();  projector.update();  }  public  void  setupUI  ()  {  ui  =  new  Stage(480,  320,  false);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.xml "),  Gdx.files.internal( "data/uiskin.png "));  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  Button  reload  =  skin.newButton( "reload ",   "Reload  Shaders ");  ComboBox  camera  =  skin.newComboBox( "camera ",  new  String[]  { "Camera ",   "Light "},  ui);  Label  fps  =  skin.newLabel( "fps ",   "fps:   ");  Table  table  =  new  Table( "container ",  (int)ui.width(),  (int)ui.height());  table.add(reload).spaceRight(5);  table.add(camera).spaceRight(5);  table.add(fps);  	Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  
libgdx_4ad8fd08c0c903e0d844f4efe3a20f9e56f398f6	buggy:  if  (index  >=  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >=  size:   "  +  index  +   "  >=   "  +  size);  context:  if  (index  >=  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >=  size:   "  +  index  +   "  >=   "  +  size);  items[index]  +=  value;  }  public  void  mul  (int  index,  short  value)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >=  size:   "  +  index  +   "  >=   "  +  size);  items[index]  *=  value;  }  public  void  insert  (int  index,  short  value)  {  if  (index  >=  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >=  size:   "  +  index  +   "  >=   "  +  size);  if  (index  >  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >  size:   "  +  index  +   "  >   "  +  size);  short[]  items  =  this.items;  if  (size  ==  items.length)  items  =  resize(Math.max(8,  (int)(size  *  1.75f)));  if  (ordered)  System.arraycopy(items,  index,  items,  index  +  1,  size  -  index);  else  items[size]  =  items[index];  size++;  items[index]  =  value;  	if  (index  >  size)  throw  new  IndexOutOfBoundsException( "index  can't  be  >  size:   "  +  index  +   "  >   "  +  size);  
elasticsearch_b0caf0d761df94f6213742c36d899d7c9857d96b	buggy:  if  (file.getName().startsWith( "_checksums "))  {  context:  FSDirectory  directory  =  FSDirectory.open(indexFile);  Map<String,  String>  checksums  =  null;  try  {  checksums  =  AbstractStore.readChecksums(directory);  for  (File  file  :  indexFile.listFiles())  {  if  (file.getName().endsWith( ".cks "))  {  continue;  }                  if  (file.getName().startsWith( "_checksums "))  {                  if  (AbstractStore.isChecksum(file.getName()))  {  continue;  }  files.put(file.getName(),  new  StoreFileMetaData(file.getName(),  file.length(),  file.lastModified(),  checksums.get(file.getName())));  }  }  finally  {  directory.close();  }  	if  (AbstractStore.isChecksum(file.getName()))  {  
elasticsearch_f6509930c7253c41009290474f61e807fdf46b0f	buggy:  return  HttpResponseStatus.UNUATHORIZED;  context:  return  HttpResponseStatus.SEE_OTHER;  case  NOT_MODIFIED:  return  HttpResponseStatus.NOT_MODIFIED;  case  USE_PROXY:  return  HttpResponseStatus.USE_PROXY;  case  TEMPORARY_REDIRECT:  return  HttpResponseStatus.TEMPORARY_REDIRECT;  case  BAD_REQUEST:  return  HttpResponseStatus.BAD_REQUEST;  case  UNAUTHORIZED:                  return  HttpResponseStatus.UNUATHORIZED;                  return  HttpResponseStatus.UNAUTHORIZED;  case  PAYMENT_REQUIRED:  return  HttpResponseStatus.PAYMENT_REQUIRED;  case  FORBIDDEN:  return  HttpResponseStatus.FORBIDDEN;  case  NOT_FOUND:  return  HttpResponseStatus.NOT_FOUND;  case  METHOD_NOT_ALLOWED:  return  HttpResponseStatus.METHOD_NOT_ALLOWED;  	return  HttpResponseStatus.UNAUTHORIZED;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<Coordinate[]>  parts  =  new  ArrayList<Coordinate[]>();  context:  protected  static  Coordinate[][]  decompose(double  dateline,  Coordinate[]  coordinates)  {  int  offset  =  0;          ArrayList<Coordinate[]>  parts  =  new  ArrayList<Coordinate[]>();          ArrayList<Coordinate[]>  parts  =  new  ArrayList<>();  double  shift  =  coordinates[0].x  >  DATELINE  ?  DATELINE  :  (coordinates[0].x  <  -DATELINE  ?  -DATELINE  :  0);  for  (int  i  =  1;  i  <  coordinates.length;  i++)  {  double  t  =  intersection(coordinates[i-1],  coordinates[i],  dateline);  if(!Double.isNaN(t))  {  Coordinate[]  part;  if(t<1)  {  	ArrayList<Coordinate[]>  parts  =  new  ArrayList<>();  
elasticsearch_eb63bb259d393354d4875c4e41dfed97edd142d1	buggy:  DeleteIndexResponse  deleteIndexResponse  =  client().admin().indices().prepareDelete().execute().actionGet();  context:  assertThat(matches[2].getScore(),  equalTo(5.5f));  assertThat(matches[2].getHighlightFields().get( "field1 ").fragments()[0].string(),  equalTo( "The  quick  brown  fox  <em>jumps</em>  over  the  lazy  dog "));  assertThat(matches[3].getScore(),  equalTo(5.5f));  assertThat(matches[3].getHighlightFields().get( "field1 ").fragments()[0].string(),  equalTo( "The  quick  brown  fox  jumps  over  the  lazy  <em>dog</em> "));  assertThat(matches[4].getScore(),  equalTo(5.5f));  assertThat(matches[4].getHighlightFields().get( "field1 ").fragments()[0].string(),  equalTo( "The  quick  brown  <em>fox</em>  jumps  over  the  lazy  dog "));  }  public  void  testDeletePercolatorType()  throws  Exception  {          DeleteIndexResponse  deleteIndexResponse  =  client().admin().indices().prepareDelete().execute().actionGet();          DeleteIndexResponse  deleteIndexResponse  =  client().admin().indices().prepareDelete( "_all ").execute().actionGet();  assertThat( "Delete  Index  failed  -  not  acked ",  deleteIndexResponse.isAcknowledged(),  equalTo(true));  ensureGreen();  client().admin().indices().prepareCreate( "test1 ").execute().actionGet();  client().admin().indices().prepareCreate( "test2 ").execute().actionGet();  ensureGreen();  client().prepareIndex( "test1 ",  PercolatorService.TYPE_NAME,   "1 ")  	DeleteIndexResponse  deleteIndexResponse  =  client().admin().indices().prepareDelete( "_all ").execute().actionGet();  
libgdx_a799a6fe9002591c640f9996abe8a91afd04ba97	buggy:  ui  =  new  Stage(480,  320,  true);  context:  controller  =  new  PerspectiveCamController(cam);  projector  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  projector.position.set(2,  3,  2);  projector.lookAt(0,  0,  0);  projector.normalizeUp();  projector.update();  }  public  void  setupUI()  {  ui  =  new  Stage(480,  320,  true);  ui  =  new  Stage(480,  320,  false);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.xml "),  Gdx.files.internal( "data/uiskin.png "));  Button  reload  =  skin.newButton( "reload ",   "Reload  Shaders ");  ComboBox  camera  =  skin.newComboBox( "camera ",  new  String[]  {   "Camera ",   "Light "  },  ui);  Label  fps  =  skin.newLabel( "fps ",   "fps:   ");  Container  container  =  new  Container( "container ",  (int)ui.width(),  (int)ui.height());  container.add(reload).spacingRight(5);  container.add(camera).spacingRight(5);  	ui  =  new  Stage(480,  320,  false);  
elasticsearch_9c9cd01854d4343b11314d58b82c00f1de335f8a	buggy:  if  (token  ==  XContentParser.Token.START_OBJECT  &&  !parser.hasTextCharacters())  {  context:   "suggester[phrase][highlight]  doesn't  support  field  [ "  +  fieldName  +   "] ");  }  }  }  }  else  if  ( "collate ".equals(fieldName))  {  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  fieldName  =  parser.currentName();  }  else  if  ( "query ".equals(fieldName)  ||   "filter ".equals(fieldName))  {  String  templateNameOrTemplateContent;                              if  (token  ==  XContentParser.Token.START_OBJECT  &&  !parser.hasTextCharacters())  {                              if  (token  ==  XContentParser.Token.START_OBJECT)  {  XContentBuilder  builder  =  XContentBuilder.builder(parser.contentType().xContent());  builder.copyCurrentStructure(parser);  templateNameOrTemplateContent  =  builder.string();  }  else  {  templateNameOrTemplateContent  =  parser.text();  }  if  (templateNameOrTemplateContent  ==  null)  {  throw  new  ElasticsearchIllegalArgumentException( "suggester[phrase][collate]  no  query/filter  found  in  collate  object ");  	if  (token  ==  XContentParser.Token.START_OBJECT)  {  
libgdx_4cb20f69e6398c5bb5cbbf3b4319c1dd42009411	buggy:  public  void  fillTriangle  (int  x1,  int  y1,  int  x2,  int  y2,  int  x3,  int  y3,  int  radius)  {  context:  }  public  void  fillTriangle  (int  x1,  int  y1,  int  x2,  int  y2,  int  x3,  int  y3,  int  radius)  {  public  void  fillTriangle  (int  x1,  int  y1,  int  x2,  int  y2,  int  x3,  int  y3)  {  context.beginPath();  context.moveTo(x1,y1);  context.lineTo(x2,y2);  context.lineTo(x3,y3);  context.lineTo(x1,y1);  context.fill();  context.closePath();  }  	public  void  fillTriangle  (int  x1,  int  y1,  int  x2,  int  y2,  int  x3,  int  y3)  {  
libgdx_8c0773e24e8fa3c93b7e261f8c79cdb3ee34d4f4	buggy:  return  new  BuildTarget(TargetOs.Linux,  false,  context:  return  new  BuildTarget(TargetOs.Linux,  false,  new  String[]  {   "**/*.c "  },  new  String[0],  new  String[]  {   "**/*.cpp "  },  new  String[0],  new  String[0],   " ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m32  -fPIC ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m32  -fPIC ",   "-shared  -m32 ");  }  if(type  ==  TargetOs.Linux  &&  is64Bit)  {  return  new  BuildTarget(TargetOs.Linux,  false,  return  new  BuildTarget(TargetOs.Linux,  true,  new  String[]  {   "**/*.c "  },  new  String[0],  new  String[]  {   "**/*.cpp "  },  new  String[0],  new  String[0],   " ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-shared  -m64 ");  }  if(type  ==  TargetOs.MacOsX)  {  	return  new  BuildTarget(TargetOs.Linux,  true,  
elasticsearch_016e2e7288aed5a96d4ca3a9f5972ae4e892d3d8	buggy:  StreamInput  streamIn  =  new  ChannelBufferStreamInput(buffer,  size);  context:  }  private  void  process(ChannelHandlerContext  ctx,  Channel  channel,  ChannelBuffer  buffer,  int  size)  throws  Exception  {  transportServiceAdapter.received(size  +  4);  int  markedReaderIndex  =  buffer.readerIndex();  int  expectedIndexReader  =  markedReaderIndex  +  size;          StreamInput  streamIn  =  new  ChannelBufferStreamInput(buffer,  size);          StreamInput  streamIn  =  ChannelBufferStreamInputFactory.create(buffer,  size);  long  requestId  =  buffer.readLong();  byte  status  =  buffer.readByte();  boolean  isRequest  =  TransportStreams.statusIsRequest(status);  StreamInput  wrappedStream;  if  (TransportStreams.statusIsCompress(status)  &&  buffer.readable())  {  Compressor  compressor  =  CompressorFactory.compressor(buffer);  	StreamInput  streamIn  =  ChannelBufferStreamInputFactory.create(buffer,  size);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  createIndexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  controller.registerHandler(RestRequest.Method.POST,   "/{index} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  CreateIndexRequest  createIndexRequest  =  new  CreateIndexRequest(request.param( "index "));  createIndexRequest.listenerThreaded(false);  if  (request.hasContent())  {  try  {                  createIndexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  createIndexRequest.source(request.content());  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  	createIndexRequest.source(request.content());  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  map.release();  context:  Arrays.sort(values,  (Comparator)  comparatorType.comparator());  List<FullEntry>  ordered  =  new  ArrayList<>(map.v().size());  for  (int  i  =  0;  i  <  map.v().size();  i++)  {  FullEntry  value  =  (FullEntry)  values[i];  if  (value  ==  null)  {  break;  }  ordered.add(value);  }          map.release();          map.close();  InternalFullDateHistogramFacet  ret  =  new  InternalFullDateHistogramFacet(getName());  ret.comparatorType  =  comparatorType;  ret.entries  =  ordered;  return  ret;  }  	map.close();  
elasticsearch_e7baf30bd290e04fd225f750543f4a5f094ece5e	buggy:  primaries().toXContent(builder,  params);  context:  }  builder.startObject( "_all ");  builder.startObject( "primaries ");  primaries().toXContent(builder,  params);  builder.endObject();  builder.startObject( "total ");          primaries().toXContent(builder,  params);          total().toXContent(builder,  params);  builder.endObject();  builder.startObject(Fields.INDICES);  for  (IndexStats  indexStats  :  indices().values())  {  builder.startObject(indexStats.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.startObject( "primaries ");  indexStats.primaries().toXContent(builder,  params);  	total().toXContent(builder,  params);  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  context:  public  static  final  String  NAME  =   "_missing_ ";  public  Query  query(QueryParseContext  parseContext,  String  queryText)  {  String  fieldName  =  queryText;  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);                  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }  filter  =  parseContext.cacheFilter(filter,  null);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  
libgdx_eeecfec20e63d74e2a77c496bcece5249073cce0	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamTest(),   "Debug  Test ",  600,  320,  false  );  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamTest(),   "Debug  Test ",  600,  320,  false  );  new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamBorderTest(),   "Debug  Test ",  800,  480,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.OrthoCamBorderTest(),   "Debug  Test ",  800,  480,  false  );  
libgdx_31c5b74028f0be7430fd668e08d8d012c9d2bdad	buggy:  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.MeshRendererTest()  );  context:  public  class  MeshRendererTest  extends  AndroidApplication  {  public  void  onCreate(  Bundle  bundle  )  {  super.onCreate(  bundle  );  setRequestedOrientation(  ActivityInfo.SCREEN_ORIENTATION_LANDSCAPE  );  initialize(false);  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.MeshRendererTest()  );  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.MeshTest()  );  }  }  	getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.MeshTest()  );  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  return  new  GetAliasesRequest();  }  protected  GetAliasesResponse  newResponse()  {  return  new  GetAliasesResponse();  }  protected  void  masterOperation(GetAliasesRequest  request,  ClusterState  state,  ActionListener<GetAliasesResponse>  listener)  throws  ElasticsearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  request.indices(concreteIndices);  ImmutableOpenMap<String,  List<AliasMetaData>>  result  =  (ImmutableOpenMap)  state.metaData().findAliases(request.aliases(),  request.indices());  listener.onResponse(new  GetAliasesResponse(result));  }  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
libgdx_89a681e7fd0bf7ae3279c52869d5da7a7e05c942	buggy:  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY)  {  context:  button.addListener(new  ActorGestureListener()  {  public  boolean  longPress  (Actor  actor,  float  x,  float  y)  {  return  true;  }  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY)  {  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  pointer,  int  button)  {  }  public  void  zoom  (InputEvent  event,  float  initialDistance,  float  distance)  {  }  public  void  pan  (InputEvent  event,  float  x,  float  y,  float  deltaX,  float  deltaY)  {  	public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  pointer,  int  button)  {  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  putRequest.template(request.param( "template ",  putRequest.template()));  putRequest.order(request.paramAsInt( "order ",  putRequest.order()));  putRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  putRequest.masterNodeTimeout()));  try  {  putRequest.create(request.paramAsBoolean( "create ",  false));  putRequest.cause(request.param( "cause ",   " "));  putRequest.source(request.content());  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                  channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  client.admin().indices().putTemplate(putRequest,  new  AcknowledgedRestResponseActionListener<PutIndexTemplateResponse>(request,  channel,  logger));  }  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  values  =  new  ArrayList<Object>(size);  context:  public  static  InternalSearchHitField  readSearchHitField(StreamInput  in)  throws  IOException  {  InternalSearchHitField  result  =  new  InternalSearchHitField();  result.readFrom(in);  return  result;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  name  =  in.readSharedString();  int  size  =  in.readVInt();          values  =  new  ArrayList<Object>(size);          values  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  values.add(in.readGenericValue());  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeSharedString(name);  	values  =  new  ArrayList<>(size);  
elasticsearch_f1916d16dc1193a14d4ea87e8e11f0963a03d543	buggy:  boundsMinKey  =  baseKey.plus(addedBucketsLeft  *  interval);  context:  DateTime  lastDataBucketKey  =  baseKey.plusDays((numOfBuckets  -  1)  *  interval);  int  addedBucketsLeft  =  randomIntBetween(0,  numOfBuckets);  DateTime  boundsMinKey;  if  (frequently())  {  boundsMinKey  =  baseKey.minusDays(addedBucketsLeft  *  interval);  }  else  {              boundsMinKey  =  baseKey.plus(addedBucketsLeft  *  interval);              boundsMinKey  =  baseKey.plusDays(addedBucketsLeft  *  interval);  addedBucketsLeft  =  0;  }  DateTime  boundsMin  =  boundsMinKey.plusDays(randomIntBetween(0,  interval  -  1));  int  addedBucketsRight  =  randomIntBetween(0,  numOfBuckets);  int  boundsMaxKeyDelta  =  addedBucketsRight  *  interval;  	boundsMinKey  =  baseKey.plusDays(addedBucketsLeft  *  interval);  
libgdx_f7ee4f123d2131f1a645f4e043a7a02e9b05713e	buggy:  GdxTest  test  =  new  SpriteCacheTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  SpriteCacheTest();  GdxTest  test  =  new  TiledMapDirectLoaderTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  TiledMapDirectLoaderTest();  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  return  new  StoreFilesMetaData(true,  shardId,  indexShard.store().listWithMd5());  context:  }  InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shard(shardId.id());  if  (indexShard  ==  null)  {  return  listUnallocatedStoreMetaData(shardId);  }  else  {              return  new  StoreFilesMetaData(true,  shardId,  indexShard.store().listWithMd5());              return  new  StoreFilesMetaData(true,  shardId,  indexShard.store().list());  }  }  protected  StoreFilesMetaData  listUnallocatedStoreMetaData(ShardId  shardId)  throws  IOException  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }  }  	return  new  StoreFilesMetaData(true,  shardId,  indexShard.store().list());  
libgdx_6cc53e2279ec82085265a200ee7cb71e52206682	buggy:  TouchEvent  event  =  input.freeTouchEvents.newObject();  context:  input.touchX[pointerId]  =  x;  input.touchY[pointerId]  =  y;  }  break;  }  }  private  void  postTouchEvent  (AndroidInput  input,  int  type,  int  x,  int  y,  int  pointer)  {  long  timeStamp  =  System.nanoTime();  synchronized  (input)  {  TouchEvent  event  =  input.freeTouchEvents.newObject();  TouchEvent  event  =  input.usedTouchEvents.add();  event.timeStamp  =  timeStamp;  event.pointer  =  pointer;  event.x  =  x;  event.y  =  y;  event.type  =  type;  input.touchEvents.add(event);  }  }  	TouchEvent  event  =  input.usedTouchEvents.add();  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  siBytes  =  new  BytesStreamInput(source,  offset,  length);  context:  }  return  builder;  }  public  static  void  restDocumentSource(byte[]  source,  XContentBuilder  builder,  ToXContent.Params  params)  throws  IOException  {  restDocumentSource(source,  0,  source.length,  builder,  params);  }  public  static  void  restDocumentSource(byte[]  source,  int  offset,  int  length,  XContentBuilder  builder,  ToXContent.Params  params)  throws  IOException  {  if  (LZF.isCompressed(source,  offset,  length))  {              BytesStreamInput  siBytes  =  new  BytesStreamInput(source,  offset,  length);              BytesStreamInput  siBytes  =  new  BytesStreamInput(source,  offset,  length,  false);  LZFStreamInput  siLzf  =  CachedStreamInput.cachedLzf(siBytes);  XContentType  contentType  =  XContentFactory.xContentType(siLzf);  siLzf.resetToBufferStart();  if  (contentType  ==  builder.contentType())  {  builder.rawField( "_source ",  siLzf);  }  else  {  XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(siLzf);  try  {  	BytesStreamInput  siBytes  =  new  BytesStreamInput(source,  offset,  length,  false);  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  .setIndicesOptions(IndicesOptions.lenient())  context:  response  =  client().preparePercolate()  .setIndices( "test1 ",   "test2 ").setDocumentType( "type ")  .setSource(jsonBuilder().startObject().startObject( "doc ").field( "field1 ",   "value ").endObject().endObject())  .execute().actionGet();  assertMatchCount(response,  10l);  assertThat(response.getMatches(),  arrayWithSize(10));  response  =  client().preparePercolate()  .setIndices( "test1 ",   "test3 ").setDocumentType( "type ")                  .setIndicesOptions(IndicesOptions.lenient())                  .setIndicesOptions(IndicesOptions.lenientExpandOpen())  .setSource(jsonBuilder().startObject().startObject( "doc ").field( "field1 ",   "value ").endObject().endObject())  .execute().actionGet();  assertMatchCount(response,  5l);  assertThat(response.getMatches(),  arrayWithSize(5));  IndicesAliasesResponse  aliasesResponse  =  client().admin().indices().prepareAliases()  .addAlias( "test1 ",   "my-alias1 ")  	.setIndicesOptions(IndicesOptions.lenientExpandOpen())  
elasticsearch_051beb51a3847c457324ecc07db708538e34d15c	buggy:  assert  request.versionType().validateVersion(request.version());  context:  protected  PrimaryResponse<DeleteResponse,  DeleteRequest>  shardOperationOnPrimary(ClusterState  clusterState,  PrimaryOperationRequest  shardRequest)  {  DeleteRequest  request  =  shardRequest.request;  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  Engine.Delete  delete  =  indexShard.prepareDelete(request.type(),  request.id(),  request.version(),  request.versionType(),  Engine.Operation.Origin.PRIMARY);  indexShard.delete(delete);  request.versionType(delete.versionType().versionTypeForReplicationAndRecovery());  request.version(delete.version());          assert  request.versionType().validateVersion(request.version());          assert  request.versionType().validateVersionForWrites(request.version());  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_delete ").force(false));  }  catch  (Exception  e)  {  }  }  	assert  request.versionType().validateVersionForWrites(request.version());  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  docTerms  =  indexFieldData.load(context).getBytesValues(false);  context:  }  else  {  if  (values[slot]  ==  null  ||  values[slot]  ==  missingValue)  {  values[slot]  =  new  BytesRef();  }  values[slot].copyBytes(relevantValue);  }  }  public  FieldComparator<BytesRef>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          docTerms  =  indexFieldData.load(context).getBytesValues(false);          docTerms  =  indexFieldData.load(context).getBytesValues();  return  this;  }  public  void  setBottom(final  int  bottom)  {  this.bottom  =  values[bottom];  }  	docTerms  =  indexFieldData.load(context).getBytesValues();  
elasticsearch_4aa59aff0058b05e822592431eda4a469a6b9eef	buggy:  Query  query  =  highlighterContext.highlightQuery;  context:  Encoder  encoder  =  field.encoder().equals( "html ")  ?  HighlightUtils.Encoders.HTML  :  HighlightUtils.Encoders.DEFAULT;  if  (!hitContext.cache().containsKey(CACHE_KEY))  {  Map<FieldMapper<?>,  org.apache.lucene.search.highlight.Highlighter>  mappers  =  Maps.newHashMap();  hitContext.cache().put(CACHE_KEY,  mappers);  }  Map<FieldMapper<?>,  org.apache.lucene.search.highlight.Highlighter>  cache  =  (Map<FieldMapper<?>,  org.apache.lucene.search.highlight.Highlighter>)  hitContext.cache().get(CACHE_KEY);  org.apache.lucene.search.highlight.Highlighter  entry  =  cache.get(mapper);  if  (entry  ==  null)  {              Query  query  =  highlighterContext.highlightQuery;              Query  query  =  highlighterContext.query.originalQuery();  QueryScorer  queryScorer  =  new  CustomQueryScorer(query,  field.requireFieldMatch()  ?  mapper.names().indexName()  :  null);  queryScorer.setExpandMultiTermQuery(true);  Fragmenter  fragmenter;  if  (field.numberOfFragments()  ==  0)  {  fragmenter  =  new  NullFragmenter();  }  else  if  (field.fragmenter()  ==  null)  {  fragmenter  =  new  SimpleSpanFragmenter(queryScorer,  field.fragmentCharSize());  }  else  if  ( "simple ".equals(field.fragmenter()))  {  	Query  query  =  highlighterContext.query.originalQuery();  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  return  new  String(buf,  0,  count);  context:  public  String  toString()  {          return  new  String(buf,  0,  count);          return  new  String(buf,  0,  count,  Streams.UTF8);  }  	return  new  String(buf,  0,  count,  Streams.UTF8);  
libgdx_188925733482957172efa9a594964d21696b025b	buggy:  throw  new  IllegalStateException(String.format( "frame  buffer  couldn't  be  constructed:  unknown  error  0x%04x ",  result));  context:  gl.glDeleteFramebuffers(1,  handle);  if  (result  ==  GL20.GL_FRAMEBUFFER_INCOMPLETE_ATTACHMENT)  throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  incomplete  attachment ");  if  (result  ==  GL20.GL_FRAMEBUFFER_INCOMPLETE_DIMENSIONS)  throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  incomplete  dimensions ");  if  (result  ==  GL20.GL_FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT)  throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  missing  attachment ");  if  (result  ==  GL20.GL_FRAMEBUFFER_UNSUPPORTED)  throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  unsupported  combination  of  formats ");        throw  new  IllegalStateException(String.format( "frame  buffer  couldn't  be  constructed:  unknown  error  0x%04x ",  result));  throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  unknown  error   "  +  result);  }  }  public  void  dispose  ()  {  GL20  gl  =  Gdx.graphics.getGL20();  IntBuffer  handle  =  BufferUtils.newIntBuffer(1);  	throw  new  IllegalStateException( "frame  buffer  couldn't  be  constructed:  unknown  error   "  +  result);  
elasticsearch_0492d9b8cb60e188703bcb2c1c416dc85cbb5971	buggy:  logger.error( "==>  Test  Success  [{}] ",  extractTestName(result));  context:  }  public  void  onTestSuccess(ITestResult  result)  {  }  public  void  onTestFailure(ITestResult  result)  {          logger.error( "==>  Test  Success  [{}] ",  extractTestName(result));          logger.error( "==>  Test  Failure  [{}] ",  extractTestName(result));  }  public  void  onTestSkipped(ITestResult  result)  {  }  	logger.error( "==>  Test  Failure  [{}] ",  extractTestName(result));  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (IntFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();  context:  public  class  BlobStores  {  public  static  void  syncWriteBlob(ImmutableBlobContainer  blobContainer,  String  blobName,  InputStream  is,  long  sizeInBytes)  throws  IOException  {  final  CountDownLatch  latch  =  new  CountDownLatch(1);          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();          final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  blobContainer.writeBlob(blobName,  is,  sizeInBytes,  new  ImmutableBlobContainer.WriterListener()  {  public  void  onCompleted()  {  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	final  AtomicReference<Throwable>  failure  =  new  AtomicReference<>();  
libgdx_61a644025318b4de08386a63162ca5eae8303b0b	buggy:  System.out.println( "dispose  intro ");  context:  time  +=  delta;  if  (time  >  1)  {  if  (Gdx.input.isKeyPressed(Keys.ANY_KEY)  ||  Gdx.input.justTouched())  {  game.setScreen(new  GameScreen(game));  }  }  }  public  void  hide  ()  {  System.out.println( "dispose  intro ");  Gdx.app.debug( "Cubocy ",   "dispose  intro ");  batch.dispose();  intro.getTexture().dispose();  }  }  	Gdx.app.debug( "Cubocy ",   "dispose  intro ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>  ordered  =  new  BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>(comparatorType.comparator(),  shardSize);  context:  ordered.insertWithOverflow(new  InternalDoubleTermsFacet.DoubleEntry(keys[i],  values[i]));  }  }  InternalDoubleTermsFacet.DoubleEntry[]  list  =  new  InternalDoubleTermsFacet.DoubleEntry[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  (InternalDoubleTermsFacet.DoubleEntry)  ordered.pop();  }  facets.release();  return  new  InternalDoubleTermsFacet(facetName,  comparatorType,  size,  Arrays.asList(list),  missing,  total);  }  else  {                  BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>  ordered  =  new  BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>(comparatorType.comparator(),  shardSize);                  BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  ordered.add(new  InternalDoubleTermsFacet.DoubleEntry(keys[i],  values[i]));  }  }  facets.release();  return  new  InternalDoubleTermsFacet(facetName,  comparatorType,  size,  ordered,  missing,  total);  }  	BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  
elasticsearch_e3a9271000128121c056ac59dfe6c7fede80f0d1	buggy:  long  count  =  Lucene.count(searcher,  mltQuery,  -1);  context:  indexWriter.addDocument(doc().add(field( "_id ",   "1 ")).add(field( "text ",   "lucene ")).build());  indexWriter.addDocument(doc().add(field( "_id ",   "2 ")).add(field( "text ",   "lucene  release ")).build());  IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  MoreLikeThisQuery  mltQuery  =  new  MoreLikeThisQuery( "lucene ",  new  String[]{ "text "},  Lucene.STANDARD_ANALYZER);  mltQuery.setLikeText( "lucene ");  mltQuery.setMinTermFrequency(1);  mltQuery.setMinDocFreq(1);          long  count  =  Lucene.count(searcher,  mltQuery,  -1);          long  count  =  Lucene.count(searcher,  mltQuery);  assertThat(count,  equalTo(2l));  reader.close();  indexWriter.close();  }  }  	long  count  =  Lucene.count(searcher,  mltQuery);  
elasticsearch_d2fea5378ad8beff6e2eb566c9d573f93771e2ef	buggy:  return  actionName  +   "/replica ";  context:  protected  boolean  ignoreReplicas()  {  return  false;  }  private  String  transportReplicaAction()  {          return  actionName  +   "/replica ";          return  actionName  +   "[r] ";  }  protected  boolean  retryPrimaryException(Throwable  e)  {  return  TransportActions.isShardNotAvailableException(e);  }  	return  actionName  +   "[r] ";  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  }  protected  ClusterSearchShardsResponse  newResponse()  {  return  new  ClusterSearchShardsResponse();  }  protected  void  masterOperation(final  ClusterSearchShardsRequest  request,  final  ClusterState  state,  final  ActionListener<ClusterSearchShardsResponse>  listener)  throws  ElasticsearchException  {  ClusterState  clusterState  =  clusterService.state();          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(request.routing(),  request.indices());  Set<String>  nodeIds  =  newHashSet();  GroupShardsIterator  groupShardsIterator  =  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  request.preference());  ShardRouting  shard;  ClusterSearchShardsGroup[]  groupResponses  =  new  ClusterSearchShardsGroup[groupShardsIterator.size()];  int  currentGroup  =  0;  for  (ShardIterator  shardIt  :  groupShardsIterator)  {  String  index  =  shardIt.shardId().getIndex();  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_73383e201431cff19a278925eef630a2db2d6f51	buggy:  assert  rewriteIndexReader  ==  searcher.getIndexReader();  context:  public  Weight  createWeight(IndexSearcher  searcher)  throws  IOException  {  SearchContext  searchContext  =  SearchContext.current();  BytesRefHash  parentIds  =  new  BytesRefHash(512,  searchContext.bigArrays());  ParentIdsCollector  collector  =  new  ParentIdsCollector(parentType,  parentChildIndexFieldData,  parentIds);  final  Query  parentQuery;  if  (rewrittenParentQuery  !=  null)  {  parentQuery  =  rewrittenParentQuery;  }  else  {              assert  rewriteIndexReader  ==  searcher.getIndexReader();              assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  parentQuery  =  rewrittenParentQuery  =  originalParentQuery.rewrite(searcher.getIndexReader());  }  IndexSearcher  indexSearcher  =  new  IndexSearcher(searcher.getIndexReader());  indexSearcher.setSimilarity(searcher.getSimilarity());  indexSearcher.search(parentQuery,  collector);  if  (parentIds.size()  ==  0)  {  Releasables.release(parentIds);  	assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  
libgdx_0e0658329f06583b642c9f2d8f8e9466947a0bad	buggy:  this.audio  =  new  IOSAudio();  context:  GL20  gl20  =  new  IOSGLES20();  Gdx.gl  =  gl20;  Gdx.gl20  =  gl20;  this.input  =  new  IOSInput(this);  this.graphics  =  new  IOSGraphics(getBounds(null),  this,  config,  input,  gl20);  this.files  =  new  IOSFiles();  this.audio  =  new  IOSAudio();  this.audio  =  new  IOSAudio(config);  this.net  =  new  IOSNet(this);  Gdx.files  =  this.files;  Gdx.graphics  =  this.graphics;  Gdx.audio  =  this.audio;  Gdx.input  =  this.input;  Gdx.net  =  this.net;  	this.audio  =  new  IOSAudio(config);  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  fields.add(toDocValues((int)  value));  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomByteNumericField  field  =  new  CustomByteNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              fields.add(toDocValues((int)  value));              addDocValue(context,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  value);  
elasticsearch_e4b739502670bdcd20259a3ca03189971b1eef53	buggy:  if  (randomBoolean())  {  context:  logClusterState();  CountResponse  countResponse  =  client().prepareCount().get();  assertHitCount(countResponse,  numDocs);  upgraded  =  backwardsCluster().upgradeOneNode();  ensureYellow();  countResponse  =  client().prepareCount().get();  assertHitCount(countResponse,  numDocs);  }  while  (upgraded);  client().admin().indices().prepareUpdateSettings( "test ").setSettings(ImmutableSettings.builder().put(EnableAllocationDecider.INDEX_ROUTING_ALLOCATION_ENABLE,   "all ")).get();  }          if  (randomBoolean())  {          if  (cluster().numDataNodes()  >  1  &&  randomBoolean())  {  //  only  bump  the  replicas  if  we  have  enough  nodes  client().admin().indices().prepareUpdateSettings( "test ").setSettings(ImmutableSettings.builder().put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS,  randomIntBetween(1,2))).get();  }  CreateSnapshotResponse  createSnapshotResponseSecond  =  client.admin().cluster().prepareCreateSnapshot( "test-repo ",   "test-1 ").setWaitForCompletion(true).setIndices( "test ").get();  assertThat(createSnapshotResponseSecond.getSnapshotInfo().successfulShards(),  greaterThan(0));  assertThat(createSnapshotResponseSecond.getSnapshotInfo().successfulShards(),  equalTo(createSnapshotResponseSecond.getSnapshotInfo().totalShards()));  assertThat(client.admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test-1 ").get().getSnapshots().get(0).state(),  equalTo(SnapshotState.SUCCESS));  {  	if  (cluster().numDataNodes()  >  1  &&  randomBoolean())  {  //  only  bump  the  replicas  if  we  have  enough  nodes  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  new  ShardSearchRequest().types(new  String[]{request.type()})  context:  IndexService  indexService  =  indicesService.indexServiceSafe(shardId.getIndex());  IndexShard  indexShard  =  indexService.shardSafe(shardId.id());  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  Engine.GetResult  result  =  indexShard.get(new  Engine.Get(false,  uidTerm));  if  (!result.exists())  {  return  new  ExplainResponse(shardId.getIndex(),  request.type(),  request.id(),  false);  }  SearchContext  context  =  new  DefaultSearchContext(  0,                  new  ShardSearchRequest().types(new  String[]{request.type()})                  new  ShardSearchRequest(request).types(new  String[]{request.type()})  .filteringAliases(request.filteringAlias())  .nowInMillis(request.nowInMillis),  null,  result.searcher(),  indexService,  indexShard,  scriptService,  cacheRecycler,  pageCacheRecycler,  bigArrays  );  SearchContext.setCurrent(context);  	new  ShardSearchRequest(request).types(new  String[]{request.type()})  
elasticsearch_4d05d1d7b0725e5e0836b5182ae34ccf906c7249	buggy:  SnapshotIndexShardStatus  shardStatus  =  new  SnapshotIndexShardStatus(shardEntry.getKey().getIndex(),  shardEntry.getKey().getId(),  stage);  context:  case  WAITING:  case  STARTED:  stage  =  SnapshotIndexShardStage.STARTED;  break;  case  SUCCESS:  stage  =  SnapshotIndexShardStage.DONE;  break;  default:  throw  new  ElasticsearchIllegalArgumentException( "Unknown  snapshot  state   "  +  shardEntry.getValue().state());  }                      SnapshotIndexShardStatus  shardStatus  =  new  SnapshotIndexShardStatus(shardEntry.getKey().getIndex(),  shardEntry.getKey().getId(),  stage);                      SnapshotIndexShardStatus  shardStatus  =  new  SnapshotIndexShardStatus(shardEntry.getKey(),  stage);  shardStatusBuilder.add(shardStatus);  }  builder.add(new  SnapshotStatus(entry.snapshotId(),  entry.state(),  shardStatusBuilder.build()));  }  }  if  (Strings.hasText(request.repository()))  {  if  (request.snapshots()  !=  null  &&  request.snapshots().length  >  0)  {  	SnapshotIndexShardStatus  shardStatus  =  new  SnapshotIndexShardStatus(shardEntry.getKey(),  stage);  
elasticsearch_55cad3208e19104c8bb213302ad8f5ca00662563	buggy:  public  SearchSourceBuilder  explain(boolean  explain)  {  context:  public  SearchSourceBuilder  queryParserName(String  queryParserName)  {  this.queryParserName  =  queryParserName;  return  this;  }      public  SearchSourceBuilder  explain(boolean  explain)  {      public  SearchSourceBuilder  explain(Boolean  explain)  {  this.explain  =  explain;  return  this;  }  	public  SearchSourceBuilder  explain(Boolean  explain)  {  
elasticsearch_5014158d6be2ec827f4fc220b8b018b970b11b48	buggy:  mltQuery.setPercentTermsToMatch(1.0f);  context:  IndexQueryParserService  queryParser  =  queryParser();  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/mlt-items.json ");  BooleanQuery  parsedQuery  =  (BooleanQuery)  queryParser.parse(query).query();  MoreLikeThisQuery  mltQuery  =  (MoreLikeThisQuery)  parsedQuery.getClauses()[0].getQuery();          mltQuery.setPercentTermsToMatch(1.0f);          mltQuery.setMinimumShouldMatch( "100% ");  mltQuery.setMinWordLen(0);  mltQuery.setMinDocFreq(0);  MemoryIndex  index  =  new  MemoryIndex();  index.addField( "name.first ",   "apache  lucene ",  new  WhitespaceAnalyzer());  index.addField( "name.last ",   "1  2  3  4 ",  new  WhitespaceAnalyzer());  	mltQuery.setMinimumShouldMatch( "100% ");  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(5).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(5));  for  (int  i  =  0;  i  <  routingTable.index( "test ").shards().size();  i++)  {  assertThat(routingTable.index( "test ").shard(i).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).currentNodeId(),  nullValue());  assertThat(routingTable.index( "test ").shard(i).shards().get(1).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
libgdx_77ca91b2233d4a482e6dc086d1827d508a46e639	buggy:   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-shared  -m64 ");  context:  return  new  BuildTarget(TargetOs.Linux,  false,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   " ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m32  -fPIC ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m32  -fPIC ",   "-shared  -m32 ");  }  if  (type  ==  TargetOs.Linux  &&  is64Bit)  {  return  new  BuildTarget(TargetOs.Linux,  true,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   " ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-shared  -m64 ");   "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-shared  -m64  -Wl,-wrap,memcpy ");  }  if  (type  ==  TargetOs.MacOsX)  {  BuildTarget  mac  =  new  BuildTarget(TargetOs.MacOsX,  false,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   " ",   "-c  -Wall  -O2  -arch  i386  -arch  x86_64  -DFIXED_POINT  -fmessage-length=0  -fPIC  -mmacosx-version-min=10.5 ",   "-c  -Wall  -O2  -arch  i386  -arch  x86_64  -DFIXED_POINT  -fmessage-length=0  -fPIC  -mmacosx-version-min=10.5 ",  	 "-c  -Wall  -O2  -mfpmath=sse  -msse  -fmessage-length=0  -m64  -fPIC ",   "-shared  -m64  -Wl,-wrap,memcpy ");  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  TermVectorResponse  response  =  run(request);  context:  TestConfig[]  testConfigs  =  generateTestConfigs(20,  testDocs,  testFieldSettings);  for  (TestConfig  test  :  testConfigs)  {  try  {  TermVectorRequestBuilder  request  =  getRequestForConfig(test);  if  (test.expectedException  !=  null)  {  assertThrows(request,  test.expectedException);  continue;  }                  TermVectorResponse  response  =  run(request);                  TermVectorResponse  response  =  request.get();  Fields  luceneTermVectors  =  getTermVectorsFromLucene(directoryReader,  test.doc);  validateResponse(response,  luceneTermVectors,  test);  }  catch  (Throwable  t)  {  throw  new  Exception( "Test  exception  while  running   "  +  test.toString(),  t);  }  }  }  	TermVectorResponse  response  =  request.get();  
elasticsearch_de3cde3e1eb1984b86ba9320e6662b8bf63e1fcb	buggy:  return  engine.searcher();  context:  public  void  recover(Engine.RecoveryHandler  recoveryHandler)  throws  EngineException  {  verifyStarted();  engine.recover(recoveryHandler);  }  public  Engine.Searcher  acquireSearcher()  {  readAllowed();          return  engine.searcher();          return  engine.acquireSearcher();  }  public  void  close(String  reason)  {  synchronized  (mutex)  {  indexSettingsService.removeListener(applyRefreshSettings);  if  (state  !=  IndexShardState.CLOSED)  {  if  (refreshScheduledFuture  !=  null)  {  refreshScheduledFuture.cancel(true);  	return  engine.acquireSearcher();  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  assertThat(searchResponse.timedOut(),  equalTo(true));  context:  for  (int  i  =  0;  i  <  10;  i++)  {  client.prepareIndex( "test ",   "type ",  Integer.toString(i)).setSource( "field ",   "value ").execute().actionGet();  }  client.admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  searchResponse  =  client.prepareSearch( "test ")  .setTimeout( "10ms ")  .setQuery(filteredQuery(matchAllQuery(),  scriptFilter( "Thread.sleep(100);  return  true; ")))  .execute().actionGet();          assertThat(searchResponse.timedOut(),  equalTo(true));          assertThat(searchResponse.isTimedOut(),  equalTo(true));  }  }  	assertThat(searchResponse.isTimedOut(),  equalTo(true));  
elasticsearch_ef56c68f67925948fee6065c5e5b754a1ca2040e	buggy:  final  IndexMetaData.Builder  indexMetaDataBuilder  =  newIndexMetaDataBuilder(request.index).settings(actualIndexSettings);  context:  throw  new  MapperParsingException( "mapping  [ "  +  entry.getKey()  +   "] ",  e);  }  }  Map<String,  MappingMetaData>  mappingsMetaData  =  Maps.newHashMap();  for  (DocumentMapper  mapper  :  mapperService)  {  MappingMetaData  mappingMd  =  new  MappingMetaData(mapper);  mappingsMetaData.put(mapper.type(),  mappingMd);  }                      final  IndexMetaData.Builder  indexMetaDataBuilder  =  newIndexMetaDataBuilder(request.index).settings(actualIndexSettings);                      final  IndexMetaData.Builder  indexMetaDataBuilder  =  IndexMetaData.builder(request.index).settings(actualIndexSettings);  for  (MappingMetaData  mappingMd  :  mappingsMetaData.values())  {  indexMetaDataBuilder.putMapping(mappingMd);  }  for  (Map.Entry<String,  Custom>  customEntry  :  customs.entrySet())  {  indexMetaDataBuilder.putCustom(customEntry.getKey(),  customEntry.getValue());  }  indexMetaDataBuilder.state(request.state);  final  IndexMetaData  indexMetaData;  	final  IndexMetaData.Builder  indexMetaDataBuilder  =  IndexMetaData.builder(request.index).settings(actualIndexSettings);  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  DeleteRequest  deleteRequest  =  new  DeleteRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  deleteRequest.timeout(request.paramAsTime( "timeout ",  DeleteRequest.DEFAULT_TIMEOUT));  deleteRequest.listenerThreaded(false);  deleteRequest.operationThreaded(true);  client.execDelete(deleteRequest,  new  ActionListener<DeleteResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "_index ",  result.index())  .field( "_type ",  result.type())  .field( "_id ",  result.id())  .endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  ShortArrayAtomicFieldData.SingleFixedSet(new  short[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  ShortArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  ShortArrayAtomicFieldData.SingleFixedSet(new  short[1],  0,  new  FixedBitSet(1));              return  ShortArrayAtomicFieldData.EMPTY;  }  final  TShortArrayList  values  =  new  TShortArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  ShortArrayAtomicFieldData.EMPTY;  
elasticsearch_a836496e57fa08ef80b0a858ffe52f58c892923b	buggy:  assertThat(statsResponse.getIndex( "test ").getTotal().getFilterCache().getMemorySizeInBytes(),  greaterThan(initialCacheSize));  context:  matchAllQuery(),  FilterBuilders.boolFilter().cache(true)  .must(FilterBuilders.termFilter( "field ",   "value ").cache(true))  .must(FilterBuilders.hasParentFilter( "parent ",  matchAllQuery()).cache(true))  ))  .get();  assertHitCount(searchResponse,  1l);  statsResponse  =  client().admin().indices().prepareStats( "test ").clear().setFilterCache(true).get();          assertThat(statsResponse.getIndex( "test ").getTotal().getFilterCache().getMemorySizeInBytes(),  greaterThan(initialCacheSize));          assertThat(statsResponse.getIndex( "test ").getTotal().getFilterCache().getMemorySizeInBytes(),  cluster().hasFilterCache()  ?  greaterThan(initialCacheSize)  :  is(initialCacheSize));  }  public  void  testQueryBeforeChildType()  throws  Exception  {  assertAcked(prepareCreate( "test ")  .addMapping( "features ")  .addMapping( "posts ",   "_parent ",   "type=features ")  	assertThat(statsResponse.getIndex( "test ").getTotal().getFilterCache().getMemorySizeInBytes(),  cluster().hasFilterCache()  ?  greaterThan(initialCacheSize)  :  is(initialCacheSize));  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(terms( "terms ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_bf13f3f81e437f3057a16b32d04ed158cd3736a1	buggy:  NumericUtils.longToPrefixCoded(val,  0,  bytesRef);  context:  public  void  close()  {  injector.getInstance(ThreadPool.class).shutdownNow();  }  private  IndexQueryParserService  queryParser()  throws  IOException  {  return  this.queryParser;  }  private  BytesRef  longToPrefixCoded(long  val)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.longToPrefixCoded(val,  0,  bytesRef);          NumericUtils.longToPrefixCoded(val,  NumericUtils.PRECISION_STEP_DEFAULT,  bytesRef);  return  bytesRef;  }  public  void  testQueryStringBuilder()  throws  Exception  {  IndexQueryParserService  queryParser  =  queryParser();  Query  parsedQuery  =  queryParser.parse(queryString( "test ").defaultField( "content ").phraseSlop(1)).query();  	NumericUtils.longToPrefixCoded(val,  NumericUtils.PRECISION_STEP_DEFAULT,  bytesRef);  
elasticsearch_01ca81e2a37c9cd38c6dc44ae567d427c059dbe0	buggy:  final  RecoveryStatus  recoveryStatus  =  new  RecoveryStatus(request.recoveryId(),  indexShard);  context:  public  void  startRecovery(final  StartRecoveryRequest  request,  final  InternalIndexShard  indexShard,  final  RecoveryListener  listener)  {  try  {  indexShard.recovering( "from   "  +  request.sourceNode());  }  catch  (IllegalIndexShardStateException  e)  {  listener.onIgnoreRecovery(false,   "already  in  recovering  process,   "  +  e.getMessage());  return;  }          final  RecoveryStatus  recoveryStatus  =  new  RecoveryStatus(request.recoveryId(),  indexShard);          final  RecoveryStatus  recoveryStatus  =  new  RecoveryStatus(request.recoveryId(),  indexShard,  request.sourceNode());  recoveryStatus.recoveryState.setType(request.recoveryType());  recoveryStatus.recoveryState.setSourceNode(request.sourceNode());  recoveryStatus.recoveryState.setTargetNode(request.targetNode());  recoveryStatus.recoveryState.setPrimary(indexShard.routingEntry().primary());  onGoingRecoveries.put(recoveryStatus.recoveryId,  recoveryStatus);  threadPool.generic().execute(new  Runnable()  {  	final  RecoveryStatus  recoveryStatus  =  new  RecoveryStatus(request.recoveryId(),  indexShard,  request.sourceNode());  
libgdx_1ab6849614157115963e631247b28b6cf2120db2	buggy:  parameterTypes[i]  =  parameters[i].getType();  context:  public  Class  getReturnType  ()  {  return  method.getReturnType();  }  public  Class[]  getParameterTypes  ()  {  Parameter[]  parameters  =  method.getParameters();  Class[]  parameterTypes  =  new  Class[parameters.length];  for  (int  i  =  0,  j  =  parameters.length;  i  <  j;  i++)  {  parameterTypes[i]  =  parameters[i].getType();  parameterTypes[i]  =  parameters[i].getClazz();  }  return  parameterTypes;  }  public  Class  getDeclaringClass  ()  {  return  method.getEnclosingType();  }  	parameterTypes[i]  =  parameters[i].getClazz();  
libgdx_cb553906a6e25ef0073f29ba1bad66a1cca01cb1	buggy:  Table  table  =  new  Table( "container ");  context:  String[]  filters  =  new  String[TextureFilter.values().length];  int  idx  =  0;  for  (TextureFilter  filter  :  TextureFilter.values())  {  filters[idx++]  =  filter.toString();  }  hwMipMap  =  new  CheckBox( "Hardware  Mips ",  skin.getStyle(CheckBoxStyle.class),   "hardware ");  minFilter  =  new  ComboBox(filters,  ui,  skin.getStyle(ComboBoxStyle.class),   "minfilter ");  magFilter  =  new  ComboBox(new  String[]  { "Nearest ",   "Linear "},  ui,  skin.getStyle(ComboBoxStyle.class),   "magfilter ");  Table  table  =  new  Table( "container ");  Table  table  =  new  Table();  table.width  =  ui.width();  table.height  =  30;  table.y  =  ui.height()  -  30;  table.add(hwMipMap).spaceRight(5);  table.add(new  Label( "Min  Filter ",  skin.getStyle(LabelStyle.class))).spaceRight(5);  table.add(minFilter).spaceRight(5);  table.add(new  Label( "Mag  Filter ",  skin.getStyle(LabelStyle.class))).spaceRight(5);  table.add(magFilter);  	Table  table  =  new  Table();  
libgdx_b899ed685a7e491bd375ae87bd9757dc0491c34e	buggy:  localTransform.idt().translate(translation).rotate(rotation).scale(scale.x,  scale.y,  scale.z);  context:  public  final  Matrix4  globalTransform  =  new  Matrix4();  public  Array<NodePart>  parts  =  new  Array<NodePart>(2);  public  Matrix4  calculateLocalTransform()  {  if  (!isAnimated)  localTransform.idt().translate(translation).rotate(rotation).scale(scale.x,  scale.y,  scale.z);  localTransform.set(translation,  rotation,  scale);  return  localTransform;  }  	localTransform.set(translation,  rotation,  scale);  
libgdx_0848219adf20ce3599755144d1b86181b038cc50	buggy:  GdxTest  test  =  new  ProgressiveJPEGTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  ProgressiveJPEGTest();  GdxTest  test  =  new  Box2DTestCollection();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.r  =  config.g  =  config.b  =  config.a  =  8;  config.width  =  960;  config.height  =  600;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  Box2DTestCollection();  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  deleteIndexService.deleteIndex(new  MetaDataDeleteIndexService.Request(index).timeout(request.timeout()),  new  MetaDataDeleteIndexService.Listener()  {  context:  protected  DeleteIndexResponse  masterOperation(DeleteIndexRequest  request,  final  ClusterState  state)  throws  ElasticSearchException  {  if  (request.indices().length  ==  0)  {  return  new  DeleteIndexResponse(true);  }  final  AtomicReference<DeleteIndexResponse>  responseRef  =  new  AtomicReference<DeleteIndexResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(request.indices().length);  for  (final  String  index  :  request.indices())  {              deleteIndexService.deleteIndex(new  MetaDataDeleteIndexService.Request(index).timeout(request.timeout()),  new  MetaDataDeleteIndexService.Listener()  {              deleteIndexService.deleteIndex(new  MetaDataDeleteIndexService.Request(index).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataDeleteIndexService.Listener()  {  public  void  onResponse(MetaDataDeleteIndexService.Response  response)  {  responseRef.set(new  DeleteIndexResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	deleteIndexService.deleteIndex(new  MetaDataDeleteIndexService.Request(index).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataDeleteIndexService.Listener()  {  
elasticsearch_a62f1f3e0dc0716918945d5d9ff48503c90ccb2c	buggy:  GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());  context:  indexShard(shardRequest).deleteByQuery(request.querySource(),  request.queryParserName(),  request.types());  return  new  ShardDeleteByQueryResponse();  }  ShardDeleteByQueryRequest  request  =  shardRequest.request;  indexShard(shardRequest).deleteByQuery(request.querySource(),  request.queryParserName(),  request.types());  }          GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index());          GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index(),  request.routing());  for  (ShardsIterator  shards  :  group)  {  if  (shards.shardId().id()  ==  request.shardId())  {  return  shards;  }  }  throw  new  ElasticSearchIllegalStateException( "No  shards  iterator  found  for  shard  [ "  +  request.shardId()  +   "] ");  }  }  	GroupShardsIterator  group  =  clusterService.operationRouting().deleteByQueryShards(clusterService.state(),  request.index(),  request.routing());  
libgdx_db919295a059e1c9748b5628a6aa1e090fbe1294	buggy:  out.x  =  x  /  child.scaleX  -  (child.x  -  child.originX);  context:  if  (child.rotation  ==  0)  {  if  (child.scaleX  ==  1  &&  child.scaleY  ==  1)  {  out.x  =  x  -  child.x;  out.y  =  y  -  child.y;  }  else  {  if  (child.originX  ==  0  &&  child.originY  ==  0)  {  out.x  =  (x  -  child.x)  /  child.scaleX;  out.y  =  (y  -  child.y)  /  child.scaleY;  }  else  {  out.x  =  x  /  child.scaleX  -  (child.x  -  child.originX);  out.x  =  x  /  child.scaleX  -  (child.x  -  child.originX);  out.y  =  x  /  child.scaleY  -  (child.y  -  child.originY);  }  }  }  else  {  final  float  cos  =  (float)Math.cos((float)Math.toRadians(child.rotation));  final  float  sin  =  (float)Math.sin((float)Math.toRadians(child.rotation));  if  (child.scaleX  ==  1  &&  child.scaleY  ==  1)  {  if  (child.originX  ==  0  &&  child.originY  ==  0)  {  	out.y  =  x  /  child.scaleY  -  (child.y  -  child.originY);  
libgdx_0807a456831b3d6c0310c52aff28128aba040d15	buggy:  FreeTypeBitmapFontData  fontData  =  generator.generateData(22,  FreeTypeFontGenerator.DEFAULT_CHARS,  flip);  context:  batch  =  new  SpriteBatch();  if(flip)  {  OrthographicCamera  cam  =  new  OrthographicCamera();  cam.setToOrtho(flip);  cam.update();  batch.setProjectionMatrix(cam.combined);  }  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  flip);  FileHandle  fontFile  =  Gdx.files.internal( "data/arial.ttf ");  FreeTypeFontGenerator  generator  =  new  FreeTypeFontGenerator(fontFile);  FreeTypeBitmapFontData  fontData  =  generator.generateData(22,  FreeTypeFontGenerator.DEFAULT_CHARS,  flip);  FreeTypeBitmapFontData  fontData  =  generator.generateData(15,  FreeTypeFontGenerator.DEFAULT_CHARS,  flip);  generator.dispose();  ftFont  =  new  BitmapFont(fontData,  fontData.getTextureRegion(),  false);  }  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	FreeTypeBitmapFontData  fontData  =  generator.generateData(15,  FreeTypeFontGenerator.DEFAULT_CHARS,  flip);  
libgdx_c113aa3e4b1aa0142457bc1cd225ad878db41bb3	buggy:  if  (visualPressedTime  >  TimeUtils.nanoTime())  return  true;  context:  public  boolean  isPressed  ()  {  return  pressed;  }  public  boolean  isVisualPressed  ()  {  if  (pressed)  return  true;  if  (visualPressedTime  <=  0)  return  false;  if  (visualPressedTime  >  TimeUtils.nanoTime())  return  true;  if  (visualPressedTime  >  TimeUtils.nanoTime()  &&  Gdx.graphics.isContinuousRendering())  return  true;  visualPressedTime  =  0;  return  false;  }  public  boolean  isOver  ()  {  return  over  ||  pressed;  }  	if  (visualPressedTime  >  TimeUtils.nanoTime()  &&  Gdx.graphics.isContinuousRendering())  return  true;  
libgdx_38e65331c71f092470a2c193adcbf2a75f05251d	buggy:  initialize(new  Metagun(),  false);  context:  public  class  MetagunAndroid  extends  AndroidApplication  {  public  void  onCreate  (Bundle  savedInstanceState)  {  super.onCreate(savedInstanceState);  initialize(new  Metagun(),  false);  initialize(new  Metagun());  }  }  	initialize(new  Metagun());  
elasticsearch_0156bcbf3203e656901a3d587b5b5cdf1601735e	buggy:  logger.warn( "failed  engine  [{}] ",  reason,  failure);  context:  }  }  }  finally  {  assert  !readLock.assertLockIsHeld()  :   "readLock  is  held  by  a  thread  that  tries  to  fail  the  engine ";  if  (failedEngine  !=  null)  {  return;  }  try  {                      logger.warn( "failed  engine  [{}] ",  reason,  failure);                      logger.warn( "failed  engine  [{}] ",  failure,  reason);  failedEngine  =  failure;  for  (FailedEngineListener  listener  :  failedEngineListeners)  {  listener.onFailedEngine(shardId,  reason,  failure);  }  }  finally  {  close();  }  	logger.warn( "failed  engine  [{}] ",  failure,  reason);  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  mltQuery.setMinimumShouldMatch((int)  (parser.floatValue()  *  100)  +   "% ");  context:  mltQuery.setMaxWordLen(parser.intValue());  }  else  if  (MoreLikeThisQueryParser.Fields.BOOST_TERMS.match(currentFieldName,parseContext.parseFlags()))  {  float  boostFactor  =  parser.floatValue();  if  (boostFactor  !=  0)  {  mltQuery.setBoostTerms(true);  mltQuery.setBoostTermsFactor(boostFactor);  }  }  else  if  (MoreLikeThisQueryParser.Fields.MINIMUM_SHOULD_MATCH.match(currentFieldName,parseContext.parseFlags()))  {  mltQuery.setMinimumShouldMatch(parser.text());  }  else  if  (MoreLikeThisQueryParser.Fields.PERCENT_TERMS_TO_MATCH.match(currentFieldName,parseContext.parseFlags()))  {                      mltQuery.setMinimumShouldMatch((int)  (parser.floatValue()  *  100)  +   "% ");                      mltQuery.setMinimumShouldMatch(Math.round(parser.floatValue()  *  100)  +   "% ");  }  else  if  ( "analyzer ".equals(currentFieldName))  {  analyzer  =  parseContext.analysisService().analyzer(parser.text());  }  else  if  ( "boost ".equals(currentFieldName))  {  mltQuery.setBoost(parser.floatValue());  }  else  if  (MoreLikeThisQueryParser.Fields.FAIL_ON_UNSUPPORTED_FIELD.match(currentFieldName,parseContext.parseFlags()))  {  failOnUnsupportedField  =  parser.booleanValue();  }  else  if  ( "_name ".equals(currentFieldName))  {  queryName  =  parser.text();  	mltQuery.setMinimumShouldMatch(Math.round(parser.floatValue()  *  100)  +   "% ");  
elasticsearch_9539661d40d5eb219f68e1298feddb9359b4a14d	buggy:  public  Facet  reduce(String  name,  List<Facet>  facets)  {  context:  }  private  void  releaseCache()  {  if  (cachedEntries)  {  cachedEntries  =  false;  CacheRecycler.pushObjectArray(entries);  }  }      public  Facet  reduce(String  name,  List<Facet>  facets)  {      public  Facet  reduce(List<Facet>  facets)  {  if  (facets.size()  ==  1)  {  InternalBoundedFullHistogramFacet  internalFacet  =  (InternalBoundedFullHistogramFacet)  facets.get(0);  if  (comparatorType  !=  ComparatorType.KEY)  {  Arrays.sort(internalFacet.entries,  (Comparator)  comparatorType.comparator());  }  return  internalFacet;  }  	public  Facet  reduce(List<Facet>  facets)  {  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(10000);  context:  public  class  LongObjectHashMapTests  extends  ElasticsearchTestCase  {  public  void  duel()  {  final  LongObjectOpenHashMap<Object>  map1  =  new  LongObjectOpenHashMap<Object>();  final  LongObjectPagedHashMap<Object>  map2  =  new  LongObjectPagedHashMap<Object>(randomInt(42),  0.6f  +  randomFloat()  *  0.39f,  BigArraysTests.randombigArrays());  final  int  maxKey  =  randomIntBetween(1,  10000);          final  int  iters  =  atLeast(10000);          final  int  iters  =  scaledRandomIntBetween(10000,  100000);  for  (int  i  =  0;  i  <  iters;  ++i)  {  final  boolean  put  =  randomBoolean();  final  int  iters2  =  randomIntBetween(1,  100);  for  (int  j  =  0;  j  <  iters2;  ++j)  {  final  long  key  =  randomInt(maxKey);  if  (put)  {  final  Object  value  =  new  Object();  assertSame(map1.put(key,  value),  map2.put(key,  value));  	final  int  iters  =  scaledRandomIntBetween(10000,  100000);  
libgdx_c9af856df9a4698a44f8f2ed62132f3b00d0f151	buggy:  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  context:  }  public  boolean  removeAll  (IntArray  array)  {  int  size  =  this.size;  int  startSize  =  size;  int[]  items  =  this.items;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  {  int  item  =  array.get(i);  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  for  (int  ii  =  0;  ii  <  size;  ii++)  {  if  (item  ==  items[ii])  {  removeIndex(ii);  size--;  break;  }  }  }  return  size  !=  startSize;  	for  (int  ii  =  0;  ii  <  size;  ii++)  {  
libgdx_a6a27eb6f7fedc3421e3ea42ca8ea3dddfc9df0f	buggy:  renderer.begin(ShapeType.Rectangle);  context:  }  public  void  render  ()  {  time  +=  Gdx.graphics.getDeltaTime();  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  badlogicSmall.draw(batch);  renderer.begin(ShapeType.Rectangle);  renderer.begin(ShapeType.Line);  renderer.rect(10,  10,  256,  256);  renderer.end();  batch.end();  }  public  void  dispose  ()  {  atlas.dispose();  	renderer.begin(ShapeType.Line);  
elasticsearch_8b7620f9de67794e48c762a81ccd8997bee34d75	buggy:  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class))  context:  }  private  final  Settings  settings;  public  MergeSchedulerModule(Settings  settings)  {  this.settings  =  settings;  }  bind(MergeSchedulerProvider.class)                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class))                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler ",   "MergeSchedulerProvider "))  .asEagerSingleton();  }  }  	.to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler ",   "MergeSchedulerProvider "))  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  analyzeRequest.tokenFilters(request.paramAsStringArray( "token_filters ",  request.paramAsStringArray( "filters ",  null)));  client.admin().indices().analyze(analyzeRequest,  new  ActionListener<AnalyzeResponse>()  {  public  void  onResponse(AnalyzeResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request,  false);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  GL10  gl  =  Gdx.graphics.getGL10();  context:  gl.glDisableClientState(GL11.GL_TEXTURE_COORD_ARRAY);  textureUnit--;  }  }  gl.glBindBuffer(GL20.GL_ARRAY_BUFFER,  0);  if  (maxIndices  >  0)  gl.glBindBuffer(GL20.GL_ELEMENT_ARRAY_BUFFER,  0);  }  private  void  renderVA  (int  primitiveType,  int  offset,  int  count)  {  GL10  gl  =  Gdx.graphics.getGL10();  GL10  gl  =  Gdx.gl10;  int  numAttributes  =  attributes.size();  int  type  =  useFixedPoint  ?  GL11.GL_FIXED  :  GL11.GL_FLOAT;  int  textureUnit  =  0;  for  (int  i  =  0;  i  <  numAttributes;  i++)  {  VertexAttribute  attribute  =  attributes.get(i);  if  (attribute.usage  ==  Usage.Position)  {  	GL10  gl  =  Gdx.gl10;  
libgdx_330d43c0bd77c975fcadc5ef442bd3ca1bfd25c5	buggy:  return  false;  context:  this.shader.begin();  setupMatrices();  }  }  public  boolean  isBlendingEnabled  ()  {  return  !blendingDisabled;  }  public  boolean  isDrawing  ()  {  return  false;  return  drawing;  }  }  	return  drawing;  
elasticsearch_6b672e29f5efac913621deae118575fc7f51f2a6	buggy:  return  this.levels();  context:  public  int  id()  {  return  this.id;  }  public  String  description()  {  return  this.description;  }  public  ClusterBlockLevel[]  levels()  {          return  this.levels();          return  this.levels;  }  public  boolean  contains(ClusterBlockLevel  level)  {  for  (ClusterBlockLevel  testLevel  :  levels)  {  if  (testLevel  ==  level)  {  return  true;  }  }  	return  this.levels;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Tuple<String,  String>(scriptName,  ext);  context:  }  private  class  ScriptChangesListener  extends  FileChangesListener  {  private  Tuple<String,  String>  scriptNameExt(File  file)  {  String  scriptPath  =  scriptsDirectory.toURI().relativize(file.toURI()).getPath();  int  extIndex  =  scriptPath.lastIndexOf('.');  if  (extIndex  !=  -1)  {  String  ext  =  scriptPath.substring(extIndex  +  1);  String  scriptName  =  scriptPath.substring(0,  extIndex).replace(File.separatorChar,  '_');                  return  new  Tuple<String,  String>(scriptName,  ext);                  return  new  Tuple<>(scriptName,  ext);  }  else  {  return  null;  }  }  public  void  onFileInit(File  file)  {  Tuple<String,  String>  scriptNameExt  =  scriptNameExt(file);  	return  new  Tuple<>(scriptName,  ext);  
elasticsearch_74464f9f99ad4da88d41fb94c87eca5f8da8da22	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(from.utf8ToString(),  to.utf8ToString(),  includeLower,  includeUpper,  parseContext);  context:  if  (fieldName  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  field  specified  for  range  filter ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  filter  =  smartNameFieldMappers.mapper().rangeFilter(from.utf8ToString(),  to.utf8ToString(),  includeLower,  includeUpper,  parseContext);                  filter  =  smartNameFieldMappers.mapper().rangeFilter(from  !=  null  ?  from.utf8ToString()  :  null,  to  !=  null  ?  to.utf8ToString()  :  null,  includeLower,  includeUpper,  parseContext);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  from,  to,  includeLower,  includeUpper);  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(from  !=  null  ?  from.utf8ToString()  :  null,  to  !=  null  ?  to.utf8ToString()  :  null,  includeLower,  includeUpper,  parseContext);  
libgdx_3c78cb6a40b150b6690f1a6680af81d4fecc6e3a	buggy:  tmpV.set(cb.getHitPointWorld().getFloats());  context:  Ray  ray  =  camera.getPickRay(screenX,  screenY);  tmpV1.set(ray.direction).scl(10f).add(ray.origin);  ClosestRayResultCallback  cb  =  new  ClosestRayResultCallback(ray.origin,  tmpV1);  world.collisionWorld.rayTest(ray.origin,  tmpV1,  cb);  if  (cb.hasHit())  {  btRigidBody  body  =  (btRigidBody)(cb.getCollisionObject());  if  (body  !=  null  &&  !body.isStaticObject()  &&  !body.isKinematicObject())  {  pickedBody  =  body;  body.setActivationState(Collision.DISABLE_DEACTIVATION);  tmpV.set(cb.getHitPointWorld().getFloats());  cb.getHitPointWorld(tmpV);  tmpV.mul(body.getCenterOfMassTransform().inv());  pickConstraint  =  new  btPoint2PointConstraint(body,  tmpV);  btConstraintSetting  setting  =  pickConstraint.getSetting();  setting.setImpulseClamp(30f);  setting.setTau(0.001f);  pickConstraint.setSetting(setting);  	cb.getHitPointWorld(tmpV);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);  context:  static  final  ParseField  EXTENDED_BOUNDS  =  new  ParseField( "extended_bounds ");  public  String  type()  {  return  InternalHistogram.TYPE.name();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  String  field  =  null;  String  script  =  null;  String  scriptLang  =  null;  Map<String,  Object>  scriptParams  =  null;  boolean  keyed  =  false;  long  minDocCount  =  1;  InternalOrder  order  =  (InternalOrder)  InternalOrder.KEY_ASC;  	ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  
elasticsearch_943b62634c1ca798a0a8b47918f2b23f707d8b06	buggy:  public  void  fieldMappers(FieldMapper...  fieldMappers)  {  context:  public  final  List<FieldMapper>  mappers  =  new  ArrayList<FieldMapper>();  public  void  fieldMapper(FieldMapper  fieldMapper)  {  mappers.add(fieldMapper);  }  }  public  abstract  void  fieldMapper(FieldMapper  fieldMapper);      public  void  fieldMappers(FieldMapper...  fieldMappers)  {      public  void  fieldMappers(Iterable<FieldMapper>  fieldMappers)  {  for  (FieldMapper  mapper  :  fieldMappers)  {  fieldMapper(mapper);  }  }  }  	public  void  fieldMappers(Iterable<FieldMapper>    fieldMappers)  {  
elasticsearch_ee585ad96c96040fccca79524e3c1f53d6294bd3	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  RecoveryTarget  peerRecoveryTarget;  IndicesService  indicesService,  RecoveryTarget  peerRecoveryTarget)  {  super(settings,  threadPool,  clusterService,  transportService);  this.peerRecoveryTarget  =  peerRecoveryTarget;  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.STATUS;  }  return   "indices/status/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_eef3610e120a1dbf6c10d5fc95f75b9ff7fa12c9	buggy:  if  (!(command  instanceof  PrioritizedRunnable))  {  context:  public  PrioritizedEsThreadPoolExecutor(int  corePoolSize,  int  maximumPoolSize,  long  keepAliveTime,  TimeUnit  unit,  ThreadFactory  threadFactory,  RejectedExecutionHandler  handler)  {  super(corePoolSize,  maximumPoolSize,  keepAliveTime,  unit,  new  PriorityBlockingQueue<Runnable>(),  threadFactory,  handler);  }  public  PrioritizedEsThreadPoolExecutor(int  corePoolSize,  int  initialWorkQueuSize,  int  maximumPoolSize,  long  keepAliveTime,  TimeUnit  unit,  ThreadFactory  threadFactory,  RejectedExecutionHandler  handler)  {  super(corePoolSize,  maximumPoolSize,  keepAliveTime,  unit,  new  PriorityBlockingQueue<Runnable>(initialWorkQueuSize),  threadFactory,  handler);  }  public  void  execute(Runnable  command)  {          if  (!(command  instanceof  PrioritizedRunnable))  {          if  (!(command  instanceof  Comparable))  {  command  =  PrioritizedRunnable.wrap(command,  Priority.NORMAL);  }  super.execute(command);  }  protected  <T>  RunnableFuture<T>  newTaskFor(Runnable  runnable,  T  value)  {  if  (!(runnable  instanceof  PrioritizedRunnable))  {  	if  (!(command  instanceof  Comparable))  {  
libgdx_9a4dbd27c6593357b47827a632727f61c0d45e99	buggy:  for  (int  i  =  0,  n  =  actions.size;  i  <  n;  i++)  context:  addAction(action2);  addAction(action3);  addAction(action4);  addAction(action5);  }  public  boolean  act  (float  delta)  {  if  (complete)  return  true;  complete  =  true;  Array<Action>  actions  =  this.actions;  for  (int  i  =  0,  n  =  actions.size;  i  <  n;  i++)  for  (int  i  =  0,  n  =  actions.size;  i  <  n  &&  actor  !=  null;  i++)  if  (!actions.get(i).act(delta))  complete  =  false;  return  complete;  }  public  void  restart  ()  {  complete  =  false;  Array<Action>  actions  =  this.actions;  for  (int  i  =  0,  n  =  actions.size;  i  <  n;  i++)  	for  (int  i  =  0,  n  =  actions.size;  i  <  n  &&  actor  !=  null;  i++)  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardRefreshRequest(shard.index(),  shard.id(),  request);  context:  return  new  RefreshResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardRefreshRequest  newShardRequest()  {  return  new  ShardRefreshRequest();  }  protected  ShardRefreshRequest  newShardRequest(int  numShards,  ShardRouting  shard,  RefreshRequest  request)  {          return  new  ShardRefreshRequest(shard.index(),  shard.id(),  request);          return  new  ShardRefreshRequest(shard.shardId(),  request);  }  protected  ShardRefreshResponse  newShardResponse()  {  return  new  ShardRefreshResponse();  }  	return  new  ShardRefreshRequest(shard.shardId(),  request);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(metaData.concreteIndex(request.index()));  context:  });  }  else  {  innerExecute(request,  listener);  }  }  protected  boolean  resolveRequest(ClusterState  state,  IndexRequest  request,  ActionListener<IndexResponse>  indexResponseActionListener)  {  MetaData  metaData  =  clusterService.state().metaData();  String  aliasOrIndex  =  request.index();          request.index(metaData.concreteIndex(request.index()));          request.index(metaData.concreteSingleIndex(request.index()));  MappingMetaData  mappingMd  =  null;  if  (metaData.hasIndex(request.index()))  {  mappingMd  =  metaData.index(request.index()).mappingOrDefault(request.type());  }  request.process(metaData,  aliasOrIndex,  mappingMd,  allowIdGeneration);  return  true;  }  	request.index(metaData.concreteSingleIndex(request.index()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  finishHim();  }  }  });  }  }  private  void  finishHim()  {  try  {  innerFinishHim();              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures()));  }  }  private  void  innerFinishHim()  {  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  	}  catch  (Throwable  e)  {  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  verifySameTokens(XContentFactory.xContent(XContentType.JSON).createParser(jsonOs.copiedByteArray()),  XContentFactory.xContent(XContentType.SMILE).createParser(xsonOs.copiedByteArray()));  context:  jsonGen.writeNull();  xsonGen.writeEndArray();  jsonGen.writeEndArray();  xsonGen.writeEndObject();  jsonGen.writeEndObject();  xsonGen.close();  jsonGen.close();          verifySameTokens(XContentFactory.xContent(XContentType.JSON).createParser(jsonOs.copiedByteArray()),  XContentFactory.xContent(XContentType.SMILE).createParser(xsonOs.copiedByteArray()));          verifySameTokens(XContentFactory.xContent(XContentType.JSON).createParser(jsonOs.bytes().toBytes()),  XContentFactory.xContent(XContentType.SMILE).createParser(xsonOs.bytes().toBytes()));  }  private  void  verifySameTokens(XContentParser  parser1,  XContentParser  parser2)  throws  IOException  {  while  (true)  {  XContentParser.Token  token1  =  parser1.nextToken();  XContentParser.Token  token2  =  parser2.nextToken();  if  (token1  ==  null)  {  assertThat(token2,  nullValue());  	verifySameTokens(XContentFactory.xContent(XContentType.JSON).createParser(jsonOs.bytes().toBytes()),  XContentFactory.xContent(XContentType.SMILE).createParser(xsonOs.bytes().toBytes()));  
libgdx_5805f36ea1b29a185ded3305590df0872c3abb44	buggy:  direction.set(0,  0,  1);  context:  public  void  setToOrtho  (boolean  yDown,  float  viewportWidth,  float  viewportHeight)  {  if  (yDown)  {  up.set(0,  -1,  0);  direction.set(0,  0,  1);  }  else  {  up.set(0,  1,  0);  direction.set(0,  0,  1);  direction.set(0,  0,  -1);  }  position.set(zoom  *  viewportWidth  /  2.0f,  zoom  *  viewportHeight  /  2.0f,  0);  this.viewportWidth  =  viewportWidth;  this.viewportHeight  =  viewportHeight;  update();  }  	direction.set(0,  0,  -1);  
elasticsearch_d9979f8dfeceb3ef31e38fa74f928514c17c44c7	buggy:  translog.close();  context:  protected  final  ShardId  shardId  =  new  ShardId(new  Index( "index "),  1);  protected  Translog  translog;  translog  =  create();  translog.newTranslog();  }          translog.close();          translog.close(true);  }  protected  abstract  Translog  create();  Translog.Snapshot  snapshot  =  translog.snapshot();  assertThat(snapshot,  translogSize(0));  snapshot.release();  	translog.close(true);  
libgdx_03f73bc55e672144c4439bcce798025207b5023d	buggy:  internalTickCallback  =  new  TestInternalTickCallback(world.dynamicsWorld);  context:  final  float  BOXOFFSET_X  =  -2.5f;  final  float  BOXOFFSET_Y  =  0.5f;  final  float  BOXOFFSET_Z  =  0f;  TestInternalTickCallback  internalTickCallback;  public  void  create  ()  {  super.create();  internalTickCallback  =  new  TestInternalTickCallback(world.dynamicsWorld);  internalTickCallback  =  new  TestInternalTickCallback((btDynamicsWorld)world.collisionWorld);  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  for  (int  x  =  0;  x  <  BOXCOUNT_X;  x++)  {  for  (int  y  =  0;  y  <  BOXCOUNT_Y;  y++)  {  for  (int  z  =  0;  z  <  BOXCOUNT_Z;  z++)  {  	internalTickCallback  =  new  TestInternalTickCallback((btDynamicsWorld)world.collisionWorld);  
libgdx_9aca2b9e86926c43e68e5611de574c2198bd21fb	buggy:  *  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  context:  private  final  Vector3  tmp  =  new  Vector3();  public  void  update  ()  {  update(true);  }  public  void  update  (boolean  updateFrustum)  {  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  (viewportWidth  /  2),  zoom  *  -(viewportHeight  /  2),  zoom  *  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  *  viewportHeight  /  2,  near,  far);  view.setToLookAt(position,  tmp.set(position).add(direction),  up);  combined.set(projection);  Matrix4.mul(combined.val,  view.val);  if  (updateFrustum)  {  invProjectionView.set(combined);  Matrix4.inv(invProjectionView.val);  frustum.update(invProjectionView);  	*  viewportHeight  /  2,  near,  far);  
libgdx_a2ab2a01b2928767dd0ca759e48e9678911bb517	buggy:  new  JoglApplication(new  StillModelViewer( "data/boy_static.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  context:  }  public  static  void  main(String[]  argv)  {  new  JoglApplication(new  StillModelViewer( "data/boy_static.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  new  JoglApplication(new  StillModelViewer( "data/test_section_02.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  }  }  	new  JoglApplication(new  StillModelViewer( "data/test_section_02.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  
libgdx_9b5059f682757f9c6bf0ac781db3d132e22da043	buggy:  return  camera.getPickRay(screenX,  screenY,  screenX,  screenY,  screenWidth,  screenHeight);  context:  public  Vector3  project  (Vector3  worldCoords)  {  camera.project(worldCoords,  screenX,  screenY,  screenWidth,  screenHeight);  return  worldCoords;  }  public  Ray  getPickRay  (float  screenX,  float  screenY)  {  return  camera.getPickRay(screenX,  screenY,  screenX,  screenY,  screenWidth,  screenHeight);  return  camera.getPickRay(screenX,  screenY,  this.screenX,  this.screenY,  screenWidth,  screenHeight);  }  public  void  calculateScissors  (Matrix4  batchTransform,  Rectangle  area,  Rectangle  scissor)  {  ScissorStack.calculateScissors(camera,  screenX,  screenY,  screenWidth,  screenHeight,  batchTransform,  area,  scissor);  }  	return  camera.getPickRay(screenX,  screenY,  this.screenX,  this.screenY,  screenWidth,  screenHeight);  
elasticsearch_c30d790609a932acfcd38a072a4e7662a87b85fa	buggy:  .put( "queryBoost ",  new  QueryBoostParseElement())  context:  private  final  FacetsPhase  facetsPhase;  this.facetsPhase  =  facetsPhase;  }  ImmutableMap.Builder<String,  SearchParseElement>  parseElements  =  ImmutableMap.builder();  parseElements.put( "from ",  new  FromParseElement()).put( "size ",  new  SizeParseElement())  .put( "queryParserName ",  new  QueryParserNameParseElement())                  .put( "queryBoost ",  new  QueryBoostParseElement())                  .put( "indicesBoost ",  new  IndicesBoostParseElement())  .put( "query ",  new  QueryParseElement())  .put( "sort ",  new  SortParseElement())  .putAll(facetsPhase.parseElements());  return  parseElements.build();  }  context.query().setBoost(context.query().getBoost()  *  context.queryBoost());  	.put( "indicesBoost ",  new  IndicesBoostParseElement())  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  AnalyzeRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.READ);  }  protected  ClusterBlockException  checkRequestBlock(ClusterState  state,  AnalyzeRequest  request)  {  if  (request.index()  !=  null)  {              request.index(state.metaData().concreteSingleIndex(request.index()));              request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  return  state.blocks().indexBlockedException(ClusterBlockLevel.READ,  request.index());  }  return  null;  }  protected  ShardsIterator  shards(ClusterState  state,  AnalyzeRequest  request)  {  if  (request.index()  ==  null)  {  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_2eb09e6b1abceb316c789f173988ac733a55dc8b	buggy:  }  catch  (Exception  e)  {  context:  listener.future  =  threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {  public  void  run()  {  listener.onResponse(new  Response(false,  indexMetaData));  nodeIndexCreatedAction.remove(nodeIndexCreatedListener);  }  });  return  updatedState;                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  listener.onFailure(e);  return  currentState;  }  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  	}  catch  (Throwable  e)  {  
elasticsearch_5448477c54bd8f25edc2c46dede7a97ca02b8fff	buggy:  RoutingAllocation.Result  routingResult  =  allocationService.reroute(currentState,  request.commands);  context:  }  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {                  RoutingAllocation.Result  routingResult  =  allocationService.reroute(currentState,  request.commands);                  RoutingAllocation.Result  routingResult  =  allocationService.reroute(currentState,  request.commands,  true);  ClusterState  newState  =  ClusterState.builder(currentState).routingResult(routingResult).build();  clusterStateToSend  =  newState;  if  (request.dryRun)  {  return  currentState;  }  return  newState;  }  	RoutingAllocation.Result  routingResult  =  allocationService.reroute(currentState,  request.commands,  true);  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  public  abstract  class  FutureTransportResponseHandler<T  extends  Streamable>  extends  BaseTransportResponseHandler<T>  {  }      @Override  public  void  handleException(RemoteTransportException  exp)  {      @Override  public  void  handleException(TransportException  exp)  {  }  }  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_24e3c41afad4e6c89c0c1b6b2cf5fed60abbbef3	buggy:  assertThat(((InterceptingTransportService)transportService).requests.isEmpty(),  equalTo(true));  context:  int  i  =  0;  for  (String  index  :  uniqueIndices)  {  indices[i++]  =  randomBoolean()  ?  index  +   "-alias "  :  index;  }  return  indices;  }  private  static  void  assertAllRequestsHaveBeenConsumed()  {  Iterable<TransportService>  transportServices  =  internalCluster().getInstances(TransportService.class);  for  (TransportService  transportService  :  transportServices)  {              assertThat(((InterceptingTransportService)transportService).requests.isEmpty(),  equalTo(true));              assertThat(((InterceptingTransportService)transportService).requests.entrySet(),  emptyIterable());  }  }  private  static  void  clearInterceptedActions()  {  Iterable<TransportService>  transportServices  =  internalCluster().getInstances(TransportService.class);  for  (TransportService  transportService  :  transportServices)  {  ((InterceptingTransportService)  transportService).clearInterceptedActions();  }  	assertThat(((InterceptingTransportService)transportService).requests.entrySet(),  emptyIterable());  
elasticsearch_1eee7f381ae98744f1017ce3997798728e34c752	buggy:  builder.startObject(indexStatus.index());  context:  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.startObject( "indices ");  for  (IndexStatus  indexStatus  :  response.indices().values())  {                          builder.startObject(indexStatus.index());                          builder.startObject(indexStatus.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.array( "aliases ",  indexStatus.settings().getAsArray( "index.aliases "));  builder.startObject( "settings ");  Settings  settings  =  settingsFilter.filterSettings(indexStatus.settings());  for  (Map.Entry<String,  String>  entry  :  settings.getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  	builder.startObject(indexStatus.index(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  boolean  indexShouldExists  =  indexShardRouting.allocatedPostApi();  context:  handleRecoveryFailure(indexService,  shardRouting,  true,  e);  break;  }  break;  }  }  }  else  {  if  (shardRouting.relocatingNodeId()  ==  null)  {                  boolean  indexShouldExists  =  indexShardRouting.allocatedPostApi();                  boolean  indexShouldExists  =  indexShardRouting.primaryAllocatedPostApi();  IndexShardGatewayService  shardGatewayService  =  indexService.shardInjector(shardId).getInstance(IndexShardGatewayService.class);  shardGatewayService.recover(indexShouldExists,  new  IndexShardGatewayService.RecoveryListener()  {  public  void  onRecoveryDone()  {  shardStateAction.shardStarted(shardRouting,   "after  recovery  from  gateway ");  }  	boolean  indexShouldExists  =  indexShardRouting.primaryAllocatedPostApi();  
libgdx_dd0f133c661723db1f88115562288e950ce2c419	buggy:  return  track.isPlaying();  context:  }  }  public  void  stop  ()  {  track.stop();  }  public  boolean  isPlaying  ()  {  return  track.isPlaying();  return  track.isPlaying()  &&  !track.isPaused();  }  public  void  setLooping  (boolean  isLooping)  {  track.setNumberOfLoops(isLooping  ?  -1  :  0);  }  	return  track.isPlaying()  &&  !track.isPaused();  
libgdx_d3cf1e5dbb63ee6e35ef5d76e9f74ee06a83681c	buggy:  spriteBatch.draw(region,  x,  y,  width,  -region.getRegionHeight());  context:  spriteBatch.setProjectionMatrix(projection);  }  protected  void  setScreen  (Screen  screen)  {  metagun.setScreen(screen);  }  public  void  draw  (TextureRegion  region,  int  x,  int  y)  {  int  width  =  region.getRegionWidth();  if  (width  <  0)  width  =  -width;  spriteBatch.draw(region,  x,  y,  width,  -region.getRegionHeight());  spriteBatch.draw(region,  x,  y,  width,  region.getRegionHeight());  }  public  void  drawString  (String  string,  int  x,  int  y)  {  string  =  string.toUpperCase();  for  (int  i  =  0;  i  <  string.length();  i++)  {  char  ch  =  string.charAt(i);  for  (int  ys  =  0;  ys  <  chars.length;  ys++)  {  int  xs  =  chars[ys].indexOf(ch);  	spriteBatch.draw(region,  x,  y,  width,  region.getRegionHeight());  
libgdx_d922799e8bc22745f37a9a28d498630a77788289	buggy:  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  pointer,  int  button)  {  context:  button.addListener(new  ActorGestureListener()  {  public  boolean  longPress  (Actor  actor,  float  x,  float  y)  {  return  true;  }  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  pointer,  int  button)  {  public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  button)  {  }  public  void  zoom  (InputEvent  event,  float  initialDistance,  float  distance)  {  }  public  void  pan  (InputEvent  event,  float  x,  float  y,  float  deltaX,  float  deltaY)  {  	public  void  fling  (InputEvent  event,  float  velocityX,  float  velocityY,  int  button)  {  
libgdx_e5d281500ceea711d0f8e2cbfa2ad2f48852a33b	buggy:  this.joints.remove(body.getJointList().get(i).joint.addr);  context:  public  void  destroyBody  (Body  body)  {  body.setUserData(null);  this.bodies.remove(body.addr);  for  (int  i  =  0;  i  <  body.getFixtureList().size();  i++)  {  this.fixtures.remove(body.getFixtureList().get(i).addr).setUserData(null);  }  for  (int  i  =  0;  i  <  body.getJointList().size();  i++)  this.joints.remove(body.getJointList().get(i).joint.addr);  destroyJoint(body.getJointList().get(i).joint);  jniDestroyBody(addr,  body.addr);  freeBodies.free(body);  }  private  native  void  jniDestroyBody  (long  addr,  long  bodyAddr);  	destroyJoint(body.getJointList().get(i).joint);  
elasticsearch_4dddeeb30cdb78d22356a1cdccb93a81071256ee	buggy:  public  class  XMMapFSDirectory  extends  NIOFSDirectory  {  context:  package  org.apache.lucene.store;  public  class  XMMapFSDirectory  extends  NIOFSDirectory  {  public  class  XMMapFSDirectory  extends  MMapDirectory  {  private  final  StoreRateLimiting.Provider  rateLimitingProvider;  private  final  StoreRateLimiting.Listener  rateListener;  public  XMMapFSDirectory(File  path,  LockFactory  lockFactory,  StoreRateLimiting.Provider  rateLimitingProvider,  StoreRateLimiting.Listener  rateListener)  throws  IOException  {  super(path,  lockFactory);  this.rateLimitingProvider  =  rateLimitingProvider;  	public  class  XMMapFSDirectory  extends  MMapDirectory  {  
libgdx_c9e39568b42bfe05307f5bdb7ed717536dde9033	buggy:  internalTickCallback.delete();  context:  }  }  }  }  public  void  dispose  ()  {  super.dispose();  if  (internalTickCallback  !=  null)  internalTickCallback.delete();  internalTickCallback.dispose();  internalTickCallback  =  null;  }  float  toggleTime  =  0f;  boolean  toggleAttach  =  false;  public  void  render  ()  {  super.render();  	internalTickCallback.dispose();  
libgdx_b3f21b0cbae25aaff918658955dac3baf89e2160	buggy:  TextureAttribute.createDiffuse(null));  context:  renderable.mesh.dispose();  renderable.mesh  =  new  Mesh(false,  capacity,  0,  CPU_ATTRIBUTES);  }  protected  void  allocRenderable(){  renderable  =  new  Renderable();  renderable.primitiveType  =  GL20.GL_POINTS;  renderable.meshPartOffset  =  0;  renderable.material  =  new  Material(new  BlendingAttribute(GL20.GL_ONE,  GL20.GL_ONE_MINUS_SRC_ALPHA,  1f),  new  DepthTestAttribute(GL20.GL_LEQUAL,  false),  TextureAttribute.createDiffuse(null));  TextureAttribute.createDiffuse((Texture)null));  }  public  void  setTexture(Texture  texture){  TextureAttribute  attribute  =  (TextureAttribute)  renderable.material.get(TextureAttribute.Diffuse);  attribute.textureDescription.texture  =  texture;  }  public  Texture  getTexture  ()  {  	TextureAttribute.createDiffuse((Texture)null));  
elasticsearch_5d6e84f206c85476d25e4b26e7998db2067e3bac	buggy:  return  new  HyphenationCompoundWordTokenFilter(tokenStream,  context:  }  try  {  hyphenationTree  =  HyphenationCompoundWordTokenFilter.getHyphenationTree(hyphenationPatternsFile);  }  catch  (Exception  e)  {  throw  new  ElasticSearchIllegalArgumentException( "Exception  while  reading  hyphenation_patterns_path:   "  +  e.getMessage());  }  }          return  new  HyphenationCompoundWordTokenFilter(tokenStream,          return  new  HyphenationCompoundWordTokenFilter(version,  tokenStream,  hyphenationTree,  wordList,  minWordSize,  minSubwordSize,  maxSubwordSize,  onlyLongestMatch);  }  }  	return  new  HyphenationCompoundWordTokenFilter(version,  tokenStream,  
elasticsearch_2c2783875e1befec504247f8e843a7c031bba92f	buggy:  threadPool  =  new  ThreadPool();  context:  protected  static  final  Version  version1  =  Version.fromId(199);  protected  DiscoveryNode  nodeB;  protected  MockTransportService  serviceB;  protected  abstract  MockTransportService  build(Settings  settings,  Version  version);  public  void  setUp()  throws  Exception  {  super.setUp();          threadPool  =  new  ThreadPool();          threadPool  =  new  ThreadPool(getClass().getName());  serviceA  =  build(ImmutableSettings.builder().put( "name ",   "TS_A ").build(),  version0);  nodeA  =  new  DiscoveryNode( "TS_A ",   "TS_A ",  serviceA.boundAddress().publishAddress(),  ImmutableMap.<String,  String>of(),  version0);  serviceB  =  build(ImmutableSettings.builder().put( "name ",   "TS_B ").build(),  version1);  nodeB  =  new  DiscoveryNode( "TS_B ",   "TS_B ",  serviceB.boundAddress().publishAddress(),  ImmutableMap.<String,  String>of(),  version1);  final  CountDownLatch  latch  =  new  CountDownLatch(4);  	threadPool  =  new  ThreadPool(getClass().getName());  
elasticsearch_98d2e7c031f628161218a944a321a5d76ce5a183	buggy:  builder.field(Fields.SIZE,  gatewayRecoveryStatus.indexSize().bytes());  context:  GatewayRecoveryStatus  gatewayRecoveryStatus  =  shardStatus.gatewayRecoveryStatus();  builder.startObject(Fields.GATEWAY_RECOVERY);  builder.field(Fields.STAGE,  gatewayRecoveryStatus.stage());  builder.field(Fields.START_TIME_IN_MILLIS,  gatewayRecoveryStatus.startTime());  builder.field(Fields.TIME,  gatewayRecoveryStatus.time());  builder.field(Fields.TIME_IN_MILLIS,  gatewayRecoveryStatus.time().millis());  builder.startObject(Fields.INDEX);  builder.field(Fields.PROGRESS,  gatewayRecoveryStatus.indexRecoveryProgress());  builder.field(Fields.SIZE,  gatewayRecoveryStatus.indexSize());                          builder.field(Fields.SIZE,  gatewayRecoveryStatus.indexSize().bytes());                          builder.field(Fields.SIZE_IN_BYTES,  gatewayRecoveryStatus.indexSize().bytes());  builder.field(Fields.REUSED_SIZE,  gatewayRecoveryStatus.reusedIndexSize());  builder.field(Fields.REUSED_SIZE_IN_BYTES,  gatewayRecoveryStatus.reusedIndexSize().bytes());  builder.field(Fields.EXPECTED_RECOVERED_SIZE,  gatewayRecoveryStatus.expectedRecoveredIndexSize());  builder.field(Fields.EXPECTED_RECOVERED_SIZE_IN_BYTES,  gatewayRecoveryStatus.expectedRecoveredIndexSize().bytes());  builder.field(Fields.RECOVERED_SIZE,  gatewayRecoveryStatus.recoveredIndexSize());  builder.field(Fields.RECOVERED_SIZE_IN_BYTES,  gatewayRecoveryStatus.recoveredIndexSize().bytes());  builder.endObject();  	builder.field(Fields.SIZE_IN_BYTES,  gatewayRecoveryStatus.indexSize().bytes());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  PrimaryResponse<IndexResponse,  IndexRequest>(shardRequest.request,  response,  op);  context:  }  }  request.version(version);  request.versionType(request.versionType().versionTypeForReplicationAndRecovery());  assert  request.versionType().validateVersion(request.version());  IndexResponse  response  =  new  IndexResponse(request.index(),  request.type(),  request.id(),  version,  created);          return  new  PrimaryResponse<IndexResponse,  IndexRequest>(shardRequest.request,  response,  op);          return  new  PrimaryResponse<>(shardRequest.request,  response,  op);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  IndexRequest  request  =  shardRequest.request;  SourceToParse  sourceToParse  =  SourceToParse.source(SourceToParse.Origin.REPLICA,  request.source()).type(request.type()).id(request.id())  .routing(request.routing()).parent(request.parent()).timestamp(request.timestamp()).ttl(request.ttl());  	return  new  PrimaryResponse<>(shardRequest.request,  response,  op);  
elasticsearch_99ef3408fb8c3777b385f4b73506ca39c75da6ed	buggy:  metadata  =  store.getMetadata();  context:  shard.recover(new  Engine.RecoveryHandler()  {  public  void  phase1(final  SnapshotIndexCommit  snapshot)  throws  ElasticsearchException  {  long  totalSize  =  0;  long  existingTotalSize  =  0;  final  Store  store  =  shard.store();  store.incRef();  try  {  StopWatch  stopWatch  =  new  StopWatch().start();  final  Store.MetadataSnapshot  metadata;                      metadata  =  store.getMetadata();                      metadata  =  store.getMetadata(snapshot);  for  (String  name  :  snapshot.getFiles())  {  final  StoreFileMetaData  md  =  metadata.get(name);  if  (md  ==  null)  {  throw  new  CorruptIndexException( "Snapshot  differs  from  actual  index  -  maybe  index  was  removed  metadata  has   "  +  metadata.asMap().size()  +   "  files ");  }  boolean  useExisting  =  false;  if  (request.existingFiles().containsKey(name))  {  	metadata  =  store.getMetadata(snapshot);  
libgdx_6e2abfb38e6f991315751ae796fbcd3b54946457	buggy:  return  new  GwtFileHandle(preloader,  file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ "))  +  name,  FileType.Internal);  context:  public  boolean  isDirectory  ()  {  return  preloader.isDirectory(file);  }  public  FileHandle  child  (String  name)  {  return  new  GwtFileHandle(preloader,  file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ "))  +  name,  FileType.Internal);  return  new  GwtFileHandle(preloader,  (file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ ")))  +  name,  FileType.Internal);  }  public  FileHandle  parent  ()  {  int  index  =  file.lastIndexOf( "/ ");  String  dir  =   " ";  if  (index  >  0)  dir  =  file.substring(0,  index  +  1);  return  new  GwtFileHandle(preloader,  dir,  type);  }  	return  new  GwtFileHandle(preloader,  (file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ ")))  +  name,  FileType.Internal);  
elasticsearch_b9ee9157631ee3ff3e19b7745886e5c004dbe134	buggy:  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0).build();  context:  public  class  DateHistogramOffsetTests  extends  ElasticsearchIntegrationTest  {  private  DateTime  date(String  date)  {  return  DateFieldMapper.Defaults.DATE_TIME_FORMATTER.parser().parseDateTime(date);  }  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.builder()  .put(super.nodeSettings(nodeOrdinal))                  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0).build();                  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta).build();  }  public  void  afterEachTest()  throws  IOException  {  internalCluster().wipeIndices( "idx2 ");  }  	.put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta).build();  
elasticsearch_8f2b8ec8a74da02b4201e7ea5fc9a807c386288f	buggy:  t.printStackTrace();  context:  public  JvmMonitor()  {  }  public  void  run()  {  try  {  monitorLongGc();  }  catch  (Throwable  t)  {                  t.printStackTrace();                  logger.debug( "failed  to  monitor ",  t);  }  }  private  synchronized  void  monitorLongGc()  {  seq++;  JvmStats  currentJvmStats  =  jvmStats();  for  (int  i  =  0;  i  <  currentJvmStats.gc().collectors().length;  i++)  {  	logger.debug( "failed  to  monitor ",  t);  
libgdx_8a4e2517a1caa6472add58ae3f74233060c18f33	buggy:  glTexEnvf(target,  pname,  params[offset]);  context:  public  final  void  glMaterialfv  (int  face,  int  pname,  float[]  params,  int  offset)  {  GL11.glMaterial(face,  pname,  toBuffer(params,  offset));  }  public  final  void  glMultMatrixf  (float[]  m,  int  offset)  {  GL11.glMultMatrix(toBuffer(m,  offset));  }  public  final  void  glTexEnvfv  (int  target,  int  pname,  float[]  params,  int  offset)  {  glTexEnvf(target,  pname,  params[offset]);  GL11.glTexEnv(target,  pname,  toBuffer(params,  offset));  }  public  void  glPolygonMode  (int  face,  int  mode)  {  GL11.glPolygonMode(face,  mode);  }  }  	GL11.glTexEnv(target,  pname,  toBuffer(params,  offset));  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices( "test ");  context:  ensureGreen();  SearchResponse  searchResponseAfterGreen  =  client.prepareSearch( "test ").setPreference(preference).setQuery(QueryBuilders.termQuery( "field ",   "test ")).execute().actionGet();  assertHitCount(searchResponse,  1);  }  assertHitCount(searchResponse,  1);  status  =  client().admin().cluster().prepareHealth( "test ").get().getStatus();  cluster().ensureAtLeastNumNodes(numberOfReplicas  +  1);  }              cluster().wipeIndices( "test ");              immutableCluster().wipeIndices( "test ");  }  }  }  	immutableCluster().wipeIndices( "test ");  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.field( "successful ",  indexDeleteByQueryResponse.getSuccessfulShards());  builder.field( "failed ",  indexDeleteByQueryResponse.getFailedShards());  builder.endObject();  builder.endObject();  }  builder.endObject();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_7b030b35b3ba43b2f47b2c65efa92086c40f8e92	buggy:   "varying  vec3  v_color; "  +  context:  Texture  texture;  Matrix  matrix  =  new  Matrix();  public  void  surfaceCreated(Application  app)  {  String  vertexShader  =   "attribute  vec4  a_position;    \n "  +   "attribute  vec4  a_color;\n "  +   "attribute  vec2  a_texCoords;\n "  +   "uniform  mat4  u_worldView;\n "  +     "varying  vec3  v_color; "  +     "varying  vec4  v_color; "  +   "varying  vec2  v_texCoords; "  +   "void  main()                  \n "  +   "{                            \n "  +   "    v_color  =  vec4(a_color.x,  a_color.y,  a_color.z,  1);  \n "  +   "    v_texCoords  =  a_texCoords;  \n "  +   "    gl_Position  =  u_worldView  *  a_position;  \n "  +   "}                            \n ";  String  fragmentShader  =   "precision  mediump  float;\n "  +  	 "varying  vec4  v_color; "  +  
libgdx_0341d8c3eaa93fb2c2c8df4b8a352c3cbf356d23	buggy:  add(name,  region,  Texture.class);  context:  public  TextureRegion  getRegion  (String  name)  {  TextureRegion  region  =  optional(name,  TextureRegion.class);  if  (region  !=  null)  return  region;  Texture  texture  =  optional(name,  Texture.class);  if  (texture  ==  null)  throw  new  GdxRuntimeException( "No  TextureRegion  or  Texture  registered  with  name:   "  +  name);  region  =  new  TextureRegion(texture);  add(name,  region,  Texture.class);  add(name,  region,  TextureRegion.class);  return  region;  }  public  TiledDrawable  getTiledDrawable  (String  name)  {  TiledDrawable  tiled  =  optional(name,  TiledDrawable.class);  if  (tiled  !=  null)  return  tiled;  	add(name,  region,  TextureRegion.class);  
elasticsearch_1867ef50845dcc19aac3dd8a6027d44931691326	buggy:  doc.add(new  Field( "_uid ",   "1 ",  UidFieldMapper.Defaults.UID_FIELD_TYPE));  context:  public  void  testUidField()  throws  Exception  {  IndexWriter  writer  =  new  IndexWriter(new  RAMDirectory(),  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  DirectoryReader  directoryReader  =  DirectoryReader.open(writer,  true);  AtomicReader  atomicReader  =  SlowCompositeReaderWrapper.wrap(directoryReader);  MatcherAssert.assertThat(UidField.loadVersion(atomicReader.getContext(),  new  Term( "_uid ",   "1 ")),  equalTo(-1l));  Document  doc  =  new  Document();          doc.add(new  Field( "_uid ",   "1 ",  UidFieldMapper.Defaults.UID_FIELD_TYPE));          doc.add(new  Field( "_uid ",   "1 ",  UidFieldMapper.Defaults.FIELD_TYPE));  writer.addDocument(doc);  directoryReader  =  DirectoryReader.openIfChanged(directoryReader);  atomicReader  =  SlowCompositeReaderWrapper.wrap(directoryReader);  assertThat(UidField.loadVersion(atomicReader.getContext(),  new  Term( "_uid ",   "1 ")),  equalTo(-2l));  assertThat(UidField.loadDocIdAndVersion(atomicReader.getContext(),  new  Term( "_uid ",   "1 ")).version,  equalTo(-2l));  doc  =  new  Document();  doc.add(new  UidField( "_uid ",   "1 ",  1));  	doc.add(new  Field( "_uid ",   "1 ",  UidFieldMapper.Defaults.FIELD_TYPE));  
elasticsearch_d487d809ea2e99a853cd7c845db1b14d8a160e72	buggy:  boolean  cache  =  false;  context:  }  return  new  String[]{NAME};  }  XContentParser  parser  =  parseContext.parser();  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  null;          boolean  cache  =  false;          boolean  cache  =  true;  TermsFilter  termsFilter  =  new  PublicTermsFilter();  String  filterName  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  	boolean  cache  =  true;  
libgdx_f29eeb49ac8df19ab1fb4430b8275a62e320e4c8	buggy:  layout.debugRects.add(new  DebugRect(type,  x,  y,  w,  h));  context:  if  (actor  instanceof  Layout)  return  (int)((Layout)actor).getMaxHeight();  return  0;  }  public  void  clearDebugRectangles  (TableLayout  layout)  {  if  (layout.debugRects  !=  null)  layout.debugRects.clear();  }  public  void  addDebugRectangle  (TableLayout  layout,  int  type,  int  x,  int  y,  int  w,  int  h)  {  if  (layout.debugRects  ==  null)  layout.debugRects  =  new  Array();  layout.debugRects.add(new  DebugRect(type,  x,  y,  w,  h));  layout.debugRects.add(new  DebugRect(type,  x,  (int)(layout.getTable().height  -  y),  w,  h));  }  static  public  void  registerFont  (String  name,  BitmapFont  font)  {  fonts.put(name,  font);  if  (defaultFont  ==  null)  defaultFont  =  font;  }  	layout.debugRects.add(new  DebugRect(type,  x,  (int)(layout.getTable().height  -  y),  w,  h));  
libgdx_075da3adeb013bfeb6c92e1d72a9360735341657	buggy:  return  new  AssetManagerTest();  context:  public  class  GwtTestStarter  extends  GwtApplication  {  public  GwtApplicationConfiguration  getConfig  ()  {  return  new  GwtApplicationConfiguration(480,  320);  }  public  ApplicationListener  getApplicationListener  ()  {  return  new  AssetManagerTest();  return  new  GwtTestWrapper();  }  }  	return  new  GwtTestWrapper();  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  context:  }  }  return  new  SuggestResponse(new  Suggest(Suggest.reduce(groupedSuggestions)),  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardSuggestResponse  shardOperation(ShardSuggestRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher( "suggest ");  XContentParser  parser  =  null;  try  {  BytesReference  suggest  =  request.suggest();  if  (suggest  !=  null  &&  suggest.length()  >  0)  {  parser  =  XContentFactory.xContent(suggest).createParser(suggest);  if  (parser.nextToken()  !=  XContentParser.Token.START_OBJECT)  {  throw  new  ElasticSearchIllegalArgumentException( "suggest  content  missing ");  }  	final  Engine.Searcher  searcher  =  indexShard.acquireSearcher( "suggest ");  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  }  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(RangeFacetCollectorParser.NAME);  context:  if  (valueScript  ==  null)  {  throw  new  SearchSourceBuilderException( "value_script  must  be  set  on  range  script  facet  for  facet  [ "  +  name  +   "] ");  }  if  (entries.isEmpty())  {  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(RangeFacetCollectorParser.NAME);          builder.startObject(RangeFacet.TYPE);  builder.field( "key_script ",  keyScript);  builder.field( "value_script ",  valueScript);  if  (lang  !=  null)  {  builder.field( "lang ",  lang);  }  builder.startArray( "ranges ");  for  (Entry  entry  :  entries)  {  	builder.startObject(RangeFacet.TYPE);  
elasticsearch_c05df433c6ff92b69a2acaa411c1b66e537e0811	buggy:  return  new  AllTermQuery(new  Term(names.indexName(),  value));  context:  public  boolean  enabled()  {  return  this.enabled;  }  return  new  AllTermQuery(term);  }          return  new  AllTermQuery(new  Term(names.indexName(),  value));          return  new  AllTermQuery(termFactory.createTerm(value));  }  if  (!enabled)  {  return  null;  }  context.allEntries().reset();  	return  new  AllTermQuery(termFactory.createTerm(value));  
elasticsearch_b5a0ae2fbeca2f6449d67556f134bd51634ffd29	buggy:  scoreFunction  =  new  CustomScoreQueryParser.ScriptScoreFunction(searchScript);  context:  SearchContext  context  =  SearchContext.current();  if  (context  ==  null)  {  throw  new  ElasticSearchIllegalStateException( "No  search  context  on  going... ");  }  FiltersFunctionScoreQuery.FilterFunction[]  filterFunctions  =  new  FiltersFunctionScoreQuery.FilterFunction[filters.size()];  for  (int  i  =  0;  i  <  filterFunctions.length;  i++)  {  ScoreFunction  scoreFunction;  String  script  =  scripts.get(i);  if  (script  !=  null)  {  SearchScript  searchScript  =  context.scriptService().search(context.lookup(),  scriptLang,  script,  vars);                  scoreFunction  =  new  CustomScoreQueryParser.ScriptScoreFunction(searchScript);                  scoreFunction  =  new  CustomScoreQueryParser.ScriptScoreFunction(script,  vars,  searchScript);  }  else  {  scoreFunction  =  new  BoostScoreFunction(boosts.get(i));  }  filterFunctions[i]  =  new  FiltersFunctionScoreQuery.FilterFunction(filters.get(i),  scoreFunction);  }  FiltersFunctionScoreQuery  functionScoreQuery  =  new  FiltersFunctionScoreQuery(query,  scoreMode,  filterFunctions);  functionScoreQuery.setBoost(boost);  return  functionScoreQuery;  	scoreFunction  =  new  CustomScoreQueryParser.ScriptScoreFunction(script,  vars,  searchScript);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  int  startPort  =  11000  +  randomIntBetween(0,  255);  int  endPort  =  startPort  +  10;  settings  =  ImmutableSettings.builder().put(settings).put( "transport.tcp.port ",  startPort  +   "- "  +  endPort).build();  return  new  TransportService(settings,  new  NettyTransport(settings,  threadPool,  new  NetworkService(settings),  version),  threadPool).start();  }  public  void  testConnectException()  {  try  {  serviceA.connectToNode(new  DiscoveryNode( "C ",  new  InetSocketTransportAddress( "localhost ",  9876),  Version.CURRENT));              assert  false;              fail();  }  catch  (ConnectTransportException  e)  {  }  }  }  	fail();  
elasticsearch_6bf19fcd930bcfdee25003a62f1c2d1098575eaf	buggy:  .startObject( "allField ").field( "store ",   "yes ").field( "termVector ",   "with_positions_offsets ").endObject()  context:  assertThat( "id[ "  +  hit.id()  +   "] ",  hit.id(),  equalTo(Integer.toString(100  -  60  -  1  -  i)));  }  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  throws  IOException  {  client.index(Requests.indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  public  JsonBuilder  mapping()  throws  IOException  {  return  binaryJsonBuilder().startObject().startObject( "type1 ")                  .startObject( "allField ").field( "store ",   "yes ").field( "termVector ",   "with_positions_offsets ").endObject()                  .startObject( "_all ").field( "store ",   "yes ").field( "termVector ",   "with_positions_offsets ").endObject()  .endObject().endObject();  }  private  JsonBuilder  source(String  id,  String  nameValue,  int  age)  throws  IOException  {  StringBuilder  multi  =  new  StringBuilder().append(nameValue);  for  (int  i  =  0;  i  <  age;  i++)  {  multi.append( "   ").append(nameValue);  }  	.startObject( "_all ").field( "store ",   "yes ").field( "termVector ",   "with_positions_offsets ").endObject()  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  IntValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  int  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Integer.MIN_VALUE  :  Integer.MAX_VALUE;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Integer.MAX_VALUE  :  Integer.MIN_VALUE;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).intValue()  :  Integer.parseInt(missingValue.toString());  }          return  new  IntValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  IntValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  IntValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
elasticsearch_5d781961a07368ae458126e4fad0a8db566637da	buggy:  countRequest.minScore(paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));  context:  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);  countRequest.querySource(HttpActions.parseQuerySource(request));  countRequest.queryParserName(request.param( "queryParserName "));  countRequest.queryHint(request.param( "queryHint "));              countRequest.minScore(paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));              countRequest.minScore(request.paramAsFloat( "minScore ",  DEFAULT_MIN_SCORE));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  countRequest.types(splitTypes(typesParam));  }  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  	countRequest.minScore(request.paramAsFloat( "minScore ",  DEFAULT_MIN_SCORE));  
elasticsearch_07480846c328c62ffed2bd2fb91036c7c0516890	buggy:  logger.warn( "[{}][{}]  master  [{}]  marked  shard  as  started,  but  shard  have  not  been  created,  mark  shard  as  failed ");  context:  DiscoveryNodes  nodes  =  event.state().nodes();  for  (final  ShardRouting  shardRouting  :  routingNodes)  {  final  IndexService  indexService  =  indicesService.indexServiceSafe(shardRouting.index());  final  int  shardId  =  shardRouting.id();  if  (!indexService.hasShard(shardId)  &&  shardRouting.started())  {                  logger.warn( "[{}][{}]  master  [{}]  marked  shard  as  started,  but  shard  have  not  been  created,  mark  shard  as  failed ");                  logger.warn( "[{}][{}]  master  [{}]  marked  shard  as  started,  but  shard  have  not  been  created,  mark  shard  as  failed ",  shardRouting.index(),  shardId,  nodes.masterNode());  shardStateAction.shardFailed(shardRouting,   "master   "  +  nodes.masterNode()  +   "  marked  shard  as  started,  but  shard  have  not  been  created,  mark  shard  as  failed ");  continue;  }  if  (indexService.hasShard(shardId))  {  InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shard(shardId);  if  (!shardRouting.equals(indexShard.routingEntry()))  {  indexShard.routingEntry(shardRouting);  	logger.warn( "[{}][{}]  master  [{}]  marked  shard  as  started,  but  shard  have  not  been  created,  mark  shard  as  failed ",  shardRouting.index(),  shardId,  nodes.masterNode());  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  }  else  if  ( "scope ".equals(currentFieldName))  {  context:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "query ".equals(currentFieldName))  {  query  =  parseContext.parseInnerQuery();  }  }  else  if  (token.isValue())  {  if  ( "type ".equals(currentFieldName))  {  childType  =  parser.text();                  }  else  if  ( "scope ".equals(currentFieldName))  {                  }  else  if  ( "_scope ".equals(currentFieldName))  {  scope  =  parser.text();  }  else  if  ( "_name ".equals(currentFieldName))  {  filterName  =  parser.text();  }  }  }  if  (query  ==  null)  {  throw  new  QueryParsingException(index,   "[child]  filter  requires  'query'  field ");  	}  else  if  ( "_scope ".equals(currentFieldName))  {  
libgdx_f2df52d349558defe29c001c3a84a153dcc06c44	buggy:  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  context:  public  Matrix4  setToLookAt  (Vector3  position,  Vector3  target,  Vector3  up)  {  tmpVec.set(target).sub(position);  setToLookAt(tmpVec,  up);  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  this.mul(tmpMat.setToTranslation(-position.x,  -position.y,  -position.z));  return  this;  }  static  final  Vector3  right  =  new  Vector3();  static  final  Vector3  tmpForward  =  new  Vector3();  static  final  Vector3  tmpUp  =  new  Vector3();  	this.mul(tmpMat.setToTranslation(-position.x,  -position.y,  -position.z));  
elasticsearch_08b4ca66c31162323bcb0fb8403052b003f01a13	buggy:  int  numUniqueQueries  =  randomInt(numQueries  /  2);  context:  public  class  PercolatorFacetsTests  extends  AbstractIntegrationTest  {  public  void  testFacets()  throws  Exception  {  client().admin().indices().prepareCreate( "test ").execute().actionGet();  ensureGreen();  int  numQueries  =  atLeast(250);          int  numUniqueQueries  =  randomInt(numQueries  /  2);          int  numUniqueQueries  =  between(1,  numQueries  /  2);  String[]  values  =  new  String[numUniqueQueries];  for  (int  i  =  0;  i  <  values.length;  i++)  {  values[i]  =   "value "  +  i;  }  int[]  expectedCount  =  new  int[numUniqueQueries];  for  (int  i  =  0;  i  <  numQueries;  i++)  {  	int  numUniqueQueries  =  between(1,  numQueries  /  2);  
libgdx_f5d0f1f3dd77f08d995859d3899992106c8b3627	buggy:  model.getBoundingBox(bbox);  context:  float[]  lightPosition  =  {2,  5,  10,  0};  float  touchStartX  =  0;  float  touchStartY  =  0;  public  void  create  ()  {  ObjLoader  objLoader  =  new  ObjLoader();  model  =  objLoader.loadModel(Gdx.files.internal( "data/cube.obj "));  BoundingBox  bbox  =  new  BoundingBox();  model.getBoundingBox(bbox);  model.calculateBoundingBox(bbox);  Gdx.app.log( "ObjTest ",   "obj  bounds:   "  +  bbox);  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  true);  texture.setFilter(TextureFilter.MipMap,  TextureFilter.Linear);  cam  =  new  PerspectiveCamera(45,  4,  4);  cam.position.set(3,  3,  3);  cam.direction.set(-1,  -1,  -1);  	model.calculateBoundingBox(bbox);  
libgdx_633ee79f66365887d4699e8aa6b6131793f41fbb	buggy:  logoSprite.getRegion().flip(false,  true);  context:  pixS1  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/test4.png ",  Files.FileType.Internal));  pixS2  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/test3.png ",  Files.FileType.Internal));  pixD  =  Gdx.graphics.newPixmap(64,  128,  Pixmap.Format.RGBA8888);  pixD.drawPixmap(pixS1,  0,  0,  0,  0,  76,  76);  pixD.drawPixmap(pixS2,  0,  0,  0,  0,  76,  76);  logoSprite  =  new  Sprite(Gdx.graphics.newUnmanagedTexture(pixD,  TextureFilter.Nearest,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge));  logoSprite.getRegion().flip(false,  true);  logoSprite.flip(false,  true);  }  GL10  gl  =  Gdx.graphics.getGL10();  gl.glClearColor(0,  1,  0,  1);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	logoSprite.flip(false,  true);  
elasticsearch_ebcc1e0bf5b0afcf76d7889bea94e9c8ff165535	buggy:  }  else  if  ( "id ".equals(currentFieldName))  {  context:  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  params  =  parser.map();  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[script]  filter  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INLINE;                  }  else  if  ( "id ".equals(currentFieldName))  {                  }  else  if  ( "script_id ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INDEXED;  }  else  if  ( "file ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.FILE;  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "_name ".equals(currentFieldName))  {  	}  else  if  ( "script_id ".equals(currentFieldName))  {  
libgdx_13d4acfee2429725e8b271de16083dde4057f4a8	buggy:  spriteCache  =  new  SpriteCache(1000);  context:  if  (System.nanoTime()  -  startTime  >  1000000000)  {  frames  =  0;  startTime  =  System.nanoTime();  }  frames++;  }  spriteCache  =  new  SpriteCache(1000);  spriteCache  =  new  SpriteCache(1000,  true);  Pixmap  pixmap  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/badlogicsmall.jpg ",  FileType.Internal));  texture  =  Gdx.graphics.newUnmanagedTexture(32,  32,  Format.RGB565,  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  texture.draw(pixmap,  0,  0);  pixmap.dispose();  pixmap  =  Gdx.graphics.newPixmap(32,  32,  Format.RGBA8888);  	spriteCache  =  new  SpriteCache(1000,  true);  
libgdx_bd9a38f6b0830368eed1959ee8b10f95da20c478	buggy:  GdxTest  test  =  new  SpriteBatchTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  GdxTest  test  =  new  SpriteBatchTest();  GdxTest  test  =  new  SoundTouchTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  SoundTouchTest();  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execState(new  ClusterStateRequest(),  new  ActionListener<ClusterStateResponse>()  {  context:  public  class  RestClusterStateAction  extends  BaseRestHandler  {  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/state ",  this);  }          client.admin().cluster().execState(new  ClusterStateRequest(),  new  ActionListener<ClusterStateResponse>()  {          client.admin().cluster().state(new  ClusterStateRequest(),  new  ActionListener<ClusterStateResponse>()  {  try  {  ClusterState  state  =  response.state();  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.startObject( "metadata ");  	client.admin().cluster().state(new  ClusterStateRequest(),  new  ActionListener<ClusterStateResponse>()  {  
libgdx_14ccbf9e7c5fa7184fcb6db5405edf4f547794c5	buggy:  fileName.endsWith( ".obj "))  {  context:  for(FileHandle  file:  directory.list())  {  if(file.isDirectory())  {  traverse(file,  base,  list);  }  else  {  String  fileName  =  file.toString().replace( "\\ ",   "/ ").replace(base,   " ");  if(fileName.endsWith( ".png ")  ||  fileName.endsWith( ".jpg ")  ||  fileName.endsWith( ".jpeg "))  {  list.append( "i: "  +  fileName  +   "\n ");  }  if(fileName.endsWith( ".glsl ")  ||  fileName.endsWith( ".fnt ")  ||  fileName.endsWith( ".pack ")  ||  fileName.endsWith( ".obj "))  {  fileName.endsWith( ".obj ")  ||  file.extension().equals( " "))  {  list.append( "t: "  +  fileName  +   "\n ");  }  }  }  }  }  	fileName.endsWith( ".obj ")  ||  file.extension().equals( " "))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  fieldsBoosts  =  new  ObjectFloatOpenHashMap<String>();  context:  fields.add(field);  return  this;  }  public  MultiMatchQueryBuilder  field(String  field,  float  boost)  {  fields.add(field);  if  (fieldsBoosts  ==  null)  {              fieldsBoosts  =  new  ObjectFloatOpenHashMap<String>();              fieldsBoosts  =  new  ObjectFloatOpenHashMap<>();  }  fieldsBoosts.put(field,  boost);  return  this;  }  	fieldsBoosts  =  new  ObjectFloatOpenHashMap<>();  
elasticsearch_ce2e65f6e7c0fb671b9d3c8a99ce0291d13ed6ab	buggy:   "tests.bwc ",   "tests.bwc.path ",   "tests.bwc.version ");  context:  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TESTS_CLUSTER,  InternalTestCluster.TESTS_ENABLE_MOCK_MODULES,   "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nightly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ",                       "tests.bwc ",   "tests.bwc.path ",   "tests.bwc.version ");                       "tests.bwc ",   "tests.bwc.version ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  appendOpt(AbstractRandomizedTest.SYSPROP_PROCESSORS,  Integer.toString(AbstractRandomizedTest.TESTS_PROCESSORS));  return  this;  }  public  ReproduceErrorMessageBuilder  appendRestTestsProperties()  {  	 "tests.bwc ",   "tests.bwc.version ");  
elasticsearch_b275e6f798c563d32a7731388a013492f238a5f9	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices());  context:  this.optimizeSingleShard  =  componentSettings.getAsBoolean( "optimize_single_shard ",  true);  transportService.registerHandler(TransportActions.SEARCH,  new  TransportHandler());  }  if  (optimizeSingleShard  &&  searchRequest.searchType()  !=  SCAN  &&  searchRequest.searchType()  !=  COUNT)  {  try  {  ClusterState  clusterState  =  clusterService.state();                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices());                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  false,  true);  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(searchRequest.routing(),  searchRequest.indices());  int  shardCount  =  clusterService.operationRouting().searchShardsCount(clusterState,  searchRequest.indices(),  concreteIndices,  searchRequest.queryHint(),  routingMap,  searchRequest.preference());  if  (shardCount  ==  1)  {  searchRequest.searchType(QUERY_AND_FETCH);  }  }  catch  (IndexMissingException  e)  {  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  false,  true);  
libgdx_1c809af770701b4168872837ea91994c39591ad4	buggy:  applyTransform(batch);  context:  }  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  if  (widget  ==  null)  return;  validate();  applyTransform(batch);  applyTransform(batch,  computeTransform());  if  (scrollX)  hKnobBounds.x  =  hScrollBounds.x  +  (int)((hScrollBounds.width  -  hKnobBounds.width)  *  getScrollPercentX());  if  (scrollY)  vKnobBounds.y  =  vScrollBounds.y  +  (int)((vScrollBounds.height  -  vKnobBounds.height)  *  (1  -  getScrollPercentY()));  float  y  =  widgetAreaBounds.y;  if  (!scrollY)  	applyTransform(batch,  computeTransform());  
libgdx_71c8a1e9aa6bf754b12bf368f2d14e388c675166	buggy:  color  =  Float.intBitsToFloat(intBits);  context:  }  return  index  -  start;  }  public  void  setColor  (Color  tint)  {  this.color  =  tint.toFloatBits();  }  public  void  setColor  (float  r,  float  g,  float  b,  float  a)  {  int  intBits  =  (int)(255  *  a)  <<  24  |  (int)(255  *  b)  <<  16  |  (int)(255  *  g)  <<  8  |  (int)(255  *  r);  color  =  Float.intBitsToFloat(intBits);  color  =  Float.intBitsToFloat((intBits  &  0xfeffffff));  }  public  Color  getColor  ()  {  int  intBits  =  Float.floatToRawIntBits(color);  	color  =  Float.intBitsToFloat((intBits  &  0xfeffffff));  
libgdx_bd87f700288b5887225d7bddc5d3e2b7c3ce7dbc	buggy:  return  new  UITest();  context:  public  class  GwtTestStarter  extends  GwtApplication  {  public  GwtApplicationConfiguration  getConfig  ()  {  return  new  GwtApplicationConfiguration(640,  640);  }  public  ApplicationListener  getApplicationListener  ()  {  return  new  UITest();  return  new  GwtTestWrapper();  }  }  	return  new  GwtTestWrapper();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.endObject();  if  (!wroteOne  &&  name  !=  null)  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  new  IndexWarmerMissingException(name)));  return;  }  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_f6bbc894cf332c17e5f0add676973adde2dd94dd	buggy:   "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");  context:  return  this;  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TESTS_CLUSTER,  TestCluster.TESTS_ENABLE_MOCK_MODULES,                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nightly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  return  this;  }  protected  ReproduceErrorMessageBuilder  appendProperties(String...  properties)  {  for  (String  sysPropName  :  properties)  {  	 "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nightly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");  
elasticsearch_d73a459f1e87ee67d1e513812cbe607c40ae1661	buggy:  this.required  =  required;  context:  }  protected  RoutingFieldMapper(Field.Store  store,  Field.Index  index,  boolean  required,  String  path)  {  super(new  Names(Defaults.NAME,  Defaults.NAME,  Defaults.NAME,  Defaults.NAME),  index,  store,  Defaults.TERM_VECTOR,  1.0f,  Defaults.OMIT_NORMS,  Defaults.OMIT_TERM_FREQ_AND_POSITIONS,  Lucene.KEYWORD_ANALYZER,  Lucene.KEYWORD_ANALYZER);  this.required  =  required;  this.path  =  path;  }  public  void  markAsRequired()  {          this.required  =  required;          this.required  =  true;  }  return  this.required;  }  return  this.path;  	this.required  =  true;  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "shardId ",  shardFailure.shard().shardId());  context:  builder.field( "total ",  totalShards());  builder.field( "successful ",  successfulShards());  builder.field( "failed ",  failedShards());  if  (shardFailures.length  >  0)  {  builder.startArray( "failures ");  for  (ShardSearchFailure  shardFailure  :  shardFailures)  {  builder.startObject();  if  (shardFailure.shard()  !=  null)  {  builder.field( "index ",  shardFailure.shard().index());                      builder.field( "shardId ",  shardFailure.shard().shardId());                      builder.field( "shard ",  shardFailure.shard().shardId());  }  builder.field( "reason ",  shardFailure.reason());  builder.endObject();  }  builder.endArray();  }  builder.endObject();  	builder.field( "shard ",  shardFailure.shard().shardId());  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  public  void  testUnknownAliasFilter()  throws  Exception  {  IndexAliasesService  indexAliasesService  =  newIndexAliasesService();  indexAliasesService.add( "cats ",  filter(termFilter( "animal ",   "cat ")));  indexAliasesService.add( "dogs ",  filter(termFilter( "animal ",   "dog ")));  try  {  indexAliasesService.aliasFilter( "unknown ");              assert  false;              fail();  }  catch  (InvalidAliasNameException  e)  {  }  }  }  	fail();  
elasticsearch_6a5d2bf76724c4f9388eaed6a55e93eaae6a4046	buggy:  return  false;  context:  return  this.builder;  }  public  String  contentType()  {  return  builder.contentType().restContentType();  }  public  boolean  contentThreadSafe()  {          return  false;          return  true;  }  public  byte[]  content()  throws  IOException  {  return  builder.bytes().array();  }  	return  true;  
libgdx_1fdf27a1fbe845e8317b5a05b4394d194f634f19	buggy:  MapLayer  layer  =  map.getLayers().getLayer(layerIdx);  context:  }  }  }  spriteBatch.end();  }  public  void  render  (int[]  layers)  {  spriteBatch.begin();  for  (int  layerIdx  :  layers)  {  MapLayer  layer  =  map.getLayers().getLayer(layerIdx);  MapLayer  layer  =  map.getLayers().get(layerIdx);  if  (layer.isVisible())  {  if  (layer  instanceof  TiledMapTileLayer)  {  renderTileLayer((TiledMapTileLayer)  layer);  }  else  {  for  (MapObject  object  :  layer.getObjects())  {  renderObject(object);  }  }  	MapLayer  layer  =  map.getLayers().get(layerIdx);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<RandomAccessFile>  files  =  new  ArrayList<RandomAccessFile>();  context:  mkdirsThread1.interrupt();  //  try  and  interrupt  it...  }  }  public  static  int  maxOpenFiles(File  testDir)  {  boolean  dirCreated  =  false;  if  (!testDir.exists())  {  dirCreated  =  true;  testDir.mkdirs();  }          List<RandomAccessFile>  files  =  new  ArrayList<RandomAccessFile>();          List<RandomAccessFile>  files  =  new  ArrayList<>();  try  {  while  (true)  {  files.add(new  RandomAccessFile(new  File(testDir,   "tmp "  +  files.size()),   "rw "));  }  }  catch  (IOException  ioe)  {  int  i  =  0;  for  (RandomAccessFile  raf  :  files)  {  try  {  	List<RandomAccessFile>  files  =  new  ArrayList<>();  
elasticsearch_aa851225e5d544a870c08810b67a919859a7790c	buggy:  if  (response.getVersion()  ==  1)  {  context:  if  (response.getMatches()  !=  null)  {  builder.startArray(Fields.MATCHES);  for  (String  match  :  response.getMatches())  {  builder.value(match);  }  builder.endArray();  }  builder.endObject();  RestStatus  status  =  OK;                      if  (response.getVersion()  ==  1)  {                      if  (response.isCreated())  {  status  =  CREATED;  }  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));  }  catch  (Throwable  e)  {  onFailure(e);  }  }  	if  (response.isCreated())  {  
libgdx_64ca274676f5015154232c7437475ad088a935a2	buggy:  FileHandle  src  =  Gdx.files.internal( "data/8.12.mp3 ");  context:  public  class  ExternalMusicTest  extends  GdxTest  {  public  void  create  ()  {  FileHandle  src  =  Gdx.files.internal( "data/8.12.mp3 ");  FileHandle  src  =  Gdx.files.internal( "data/iron.mp3 ");  FileHandle  dst  =  Gdx.files.external( "8.12.mp3 ");  src.copyTo(dst);  Music  music  =  Gdx.audio.newMusic(dst);  music.play();  }  	FileHandle  src  =  Gdx.files.internal( "data/iron.mp3 ");  
elasticsearch_10183c744087ac1fd46dc04e0e8118b11cf16198	buggy:  logger.warn( "Caught  exception  while  handling  client  http  trafic ",  e.getCause());  context:  if  (logger.isTraceEnabled())  {  }  ctx.getChannel().close();  }  else  {  if  (!lifecycle.started())  {  return;  }  if  (!NetworkExceptionHelper.isCloseConnectionException(e.getCause()))  {                  logger.warn( "Caught  exception  while  handling  client  http  trafic ",  e.getCause());                  logger.warn( "Caught  exception  while  handling  client  http  traffic ",  e.getCause());  }  }  }  }  	logger.warn( "Caught  exception  while  handling  client  http  traffic ",  e.getCause());  
libgdx_ad4ba1c7473f6d64a1cb52eb5cefbff49eb20142	buggy:  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true);  context:  mesh.render(meshShader,  GL20.GL_TRIANGLES);  meshShader.end();  frameBuffer.end();  Gdx.graphics.getGL20().glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.graphics.getGL20().glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.graphics.getGL20().glClear(GL20.GL_COLOR_BUFFER_BIT);  spriteBatch.begin();  spriteBatch.draw(frameBuffer.getColorBufferTexture(),  0,  0,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true);  frameBuffer.getColorBufferTexture().getHeight(),  false,  true);  spriteBatch.end();  }  mesh  =  new  Mesh(true,  3,  0,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(  Usage.ColorPacked,  4,   "a_Color "),  new  VertexAttribute(Usage.TextureCoordinates,  2,   "a_texCoords "));  float  c1  =  Color.toFloatBits(255,  0,  0,  255);  float  c2  =  Color.toFloatBits(255,  0,  0,  255);  	frameBuffer.getColorBufferTexture().getHeight(),  false,  true);  
libgdx_a24c2ab03a479256f9cd25798c2c22c58688ce17	buggy:  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-stbtruetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac,  android);  context:  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  BuildTarget  win32  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  BuildTarget  win64  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  true);  BuildTarget  lin32  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  false);  BuildTarget  lin64  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  true);  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  BuildTarget  android  =  BuildTarget.newDefaultTarget(TargetOs.Android,  false);  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-stbtruetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac,  android);  new  AntScriptGenerator().generate(new  BuildConfig( "gdx-stb-truetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac,  android);  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-v ");  }  }  	new  AntScriptGenerator().generate(new  BuildConfig( "gdx-stb-truetype "),  win32home,  win32,  win64,  lin32,  lin64,  mac,  android);  
libgdx_05a27f1a3b9c6ef471d9ecbf733955dacffb5c75	buggy:  new  LwjglApplication(new  VeryAngryRobotsGame(),   "Very  Angry  Robots ",  WINDOW_WIDTH,  WINDOW_HEIGHT,  false);  context:  package  com.badlydrawngames.veryangryrobots;  public  class  DesktopStarter  {  private  final  static  int  WINDOW_WIDTH  =  800;  private  final  static  int  WINDOW_HEIGHT  =  480;  public  static  void  main  (String[]  args)  {  new  LwjglApplication(new  VeryAngryRobotsGame(),   "Very  Angry  Robots ",  WINDOW_WIDTH,  WINDOW_HEIGHT,  false);  new  LwjglApplication(new  VeryAngryRobotsGame(),   "Very  Angry  Robots ",  WINDOW_WIDTH,  WINDOW_HEIGHT);  }  }  	new  LwjglApplication(new  VeryAngryRobotsGame(),   "Very  Angry  Robots ",  WINDOW_WIDTH,  WINDOW_HEIGHT);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  protected  void  doStart()  throws  ElasticSearchException  {  }  protected  void  doStop()  throws  ElasticSearchException  {  ImmutableSet<RiverName>  indices  =  ImmutableSet.copyOf(this.rivers.keySet());  final  CountDownLatch  latch  =  new  CountDownLatch(indices.size());  for  (final  RiverName  riverName  :  indices)  {              threadPool.cached().execute(new  Runnable()  {              threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  try  {  closeRiver(riverName);  }  catch  (Exception  e)  {  }  finally  {  latch.countDown();  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(stats( "stats ")))  context:  public  class  StatsTests  extends  AbstractNumericTests  {  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(stats( "stats ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(stats( "stats ")))  .execute().actionGet();  assertShardExecutionState(searchResponse,  0);  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(stats( "stats ")))  
elasticsearch_28b9e250536f8a554abb26b49d6a80a0d4fb4f03	buggy:  builder.field( "index ",  fieldType.indexed());  context:  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (fieldType.indexed()  ==  Defaults.FIELD_TYPE.indexed()  &&  fieldType.stored()  ==  Defaults.FIELD_TYPE.stored()  &&  required  ==  Defaults.REQUIRED  &&  path  ==  Defaults.PATH)  {  return  builder;  }  builder.startObject(CONTENT_TYPE);  if  (fieldType.indexed()  !=  Defaults.FIELD_TYPE.indexed())  {              builder.field( "index ",  fieldType.indexed());              builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  }  if  (fieldType.stored()  !=  Defaults.FIELD_TYPE.stored())  {  builder.field( "store ",  fieldType.stored());  }  if  (required  !=  Defaults.REQUIRED)  {  builder.field( "required ",  required);  }  if  (path  !=  Defaults.PATH)  {  	builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(settings),  context:  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),  new  ScriptModule(settings),  new  MapperServiceModule(),                  new  IndexSettingsModule(settings),                  new  IndexSettingsModule(index,  settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index),  new  AbstractModule()  {  	new  IndexSettingsModule(index,  settings),  
elasticsearch_2dfb1d98f4c5e5309a326301476094cd5af6df73	buggy:  return  ensureYellow(indices);  context:  return  actionGet.getStatus();  }  protected  ClusterHealthStatus  ensureSearchable(String...indices)  {          return  ensureYellow(indices);          return  ensureGreen(indices);  }  	return  ensureGreen(indices);  
libgdx_d69f047ed13a15d17432d37f97e315a4dfa49f8d	buggy:  ui.render();  context:  ui.addActor(linearh);  Gdx.input.setInputProcessor(this);  }  GL10  gl  =  Gdx.graphics.getGL10();  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  ui.act(Gdx.graphics.getDeltaTime());  ui.render();  ui.draw();  }  return  false;  }  return  false;  	ui.draw();  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execNodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  context:  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/nodes ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/nodes/{nodeId} ",  this);  }  String[]  nodesIds  =  RestActions.splitNodes(request.param( "nodeId "));  final  boolean  includeSettings  =  request.paramAsBoolean( "settings ",  false);  NodesInfoRequest  nodesInfoRequest  =  new  NodesInfoRequest(nodesIds);  nodesInfoRequest.listenerThreaded(false);          client.admin().cluster().execNodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {          client.admin().cluster().nodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "clusterName ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeInfo  nodeInfo  :  result)  {  	client.admin().cluster().nodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  
libgdx_f9afe97454a11eef13597c6400881c5c20015263	buggy:  String[]  headers  =  { "src/bullet/ ",   "src/custom/ "};  context:  cppFlags  +=   "  -fno-rtti ";  cppFlags  +=   "  -DBT_NO_PROFILE ";  String[]  excludes  =  { "src/bullet/BulletMultiThreaded/GpuSoftBodySolvers/** "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize "};  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  win32home.cExcludes  =  win32home.cppExcludes  =  excludes;  win32home.headerDirs  =  headers;  win32home.cppFlags  +=  cppFlags;  	String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize "};  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  builder.field( "scope ",  scope);  context:  this.filterName  =  filterName;  return  this;  }  builder.startObject(HasChildFilterParser.NAME);  builder.field( "query ");  queryBuilder.toXContent(builder,  params);  builder.field( "type ",  childType);  if  (scope  !=  null)  {              builder.field( "scope ",  scope);              builder.field( "_scope ",  scope);  }  if  (filterName  !=  null)  {  builder.field( "_name ",  filterName);  }  builder.endObject();  }  }  	builder.field( "_scope ",  scope);  
elasticsearch_5e0f67b5163b697b29de9c15ba4b7c8f042d7ca4	buggy:  ce.setDescription( "-exp(-0.5*pow( "  +  valueExpl  +   ",2.0)/ "  +  -1  *  scale  +   ") ");  context:  public  double  evaluate(double  value,  double  scale)  {  return  (float)  Math.exp(0.5  *  Math.pow(value,  2.0)  /  scale);  }  public  Explanation  explainFunction(String  valueExpl,  double  value,  double  scale)  {  ComplexExplanation  ce  =  new  ComplexExplanation();  ce.setValue((float)  evaluate(value,  scale));              ce.setDescription( "-exp(-0.5*pow( "  +  valueExpl  +   ",2.0)/ "  +  -1  *  scale  +   ") ");              ce.setDescription( "exp(-0.5*pow( "  +  valueExpl  +   ",2.0)/ "  +  -1  *  scale  +   ") ");  return  ce;  }  public  double  processScale(double  scale,  double  decay)  {  return  0.5  *  Math.pow(scale,  2.0)  /  Math.log(decay);  }  }  	ce.setDescription( "exp(-0.5*pow( "  +  valueExpl  +   ",2.0)/ "  +  -1  *  scale  +   ") ");  
elasticsearch_3e405c3ec76235145f81507f1189e92824d06b92	buggy:  stats.cpu.percent  =  cpu.getPercent();  context:  }  Sigar  sigar  =  sigarService.sigar();  ProcessStats  stats  =  new  ProcessStats();  stats.timestamp  =  System.currentTimeMillis();  try  {  ProcCpu  cpu  =  sigar.getProcCpu(sigar.getPid());  stats.cpu  =  new  ProcessStats.Cpu();              stats.cpu.percent  =  cpu.getPercent();              stats.cpu.percent  =  (short)  (cpu.getPercent()  *  100);  stats.cpu.sys  =  cpu.getSys();  stats.cpu.user  =  cpu.getUser();  }  catch  (SigarException  e)  {  }  try  {  ProcMem  mem  =  sigar.getProcMem(sigar.getPid());  	stats.cpu.percent  =  (short)  (cpu.getPercent()  *  100);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  long  count  =  indexShard.count(request.minScore(),  request.querySource(),  request.querySourceOffset(),  request.querySourceLength(),  context:  count  +=  ((ShardCountResponse)  shardResponse).count();  successfulShards++;  }  }  return  new  CountResponse(count,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardCountResponse  shardOperation(ShardCountRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          long  count  =  indexShard.count(request.minScore(),  request.querySource(),  request.querySourceOffset(),  request.querySourceLength(),          long  count  =  indexShard.count(request.minScore(),  request.querySource(),  request.filteringAliases(),  request.types());  return  new  ShardCountResponse(request.index(),  request.shardId(),  count);  }  }  	long  count  =  indexShard.count(request.minScore(),  request.querySource(),  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e1)  {  context:  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  ConnectTransportException)  {  int  i  =  ++this.i;  if  (i  ==  nodes.size())  {  listener.onFailure(new  NoNodeAvailableException());  }  else  {  try  {  callback.doWithNode(nodes.get((index  +  i)  %  nodes.size()),  this);                      }  catch  (Exception  e1)  {                      }  catch  (Throwable  e1)  {  onFailure(e);  }  }  }  else  {  listener.onFailure(e);  }  }  	}  catch  (Throwable  e1)  {  
libgdx_d825792ac494dd0257e0c2ec7acd60100ecfe700	buggy:  bytes[j]  =  (byte)(value  |  0xff);  context:  }  public  void  writeSamples  (float[]  samples,  int  offset,  int  numSamples)  {  if  (bytes.length  <  samples.length  *  2)  bytes  =  new  byte[samples.length  *  2];  for  (int  i  =  offset,  j  =  0;  i  <  offset  +  numSamples;  i++,  j  +=  2)  {  float  fValue  =  samples[i];  if  (fValue  >  1)  fValue  =  1;  if  (fValue  <  -1)  fValue  =  -1;  short  value  =  (short)(fValue  *  Short.MAX_VALUE);  bytes[j]  =  (byte)(value  |  0xff);  bytes[j]  =  (byte)(value  &  0xff);  bytes[j  +  1]  =  (byte)(value  >>  8);  }  int  writtenBytes  =  line.write(bytes,  0,  numSamples  *  2);  while  (writtenBytes  !=  numSamples  *  2)  writtenBytes  +=  line.write(bytes,  writtenBytes,  numSamples  *  2  -  writtenBytes);  }  }  	bytes[j]  =  (byte)(value  &  0xff);  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices( "test ");  context:  client().prepareIndex( "test ",   "test ",   "1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "my-queries-index ",  PercolatorService.TYPE_NAME,   "kuku ")  .setSource(jsonBuilder().startObject()  .field( "color ",   "blue ")  .field( "query ",  termQuery( "field1 ",   "value1 "))  .endObject())  .setRefresh(true)  .execute().actionGet();          wipeIndices( "test ");          cluster().wipeIndices( "test ");  createIndex( "test ");  ensureGreen();  client().prepareIndex( "test ",   "test ",   "1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "my-queries-index ",  PercolatorService.TYPE_NAME,   "kuku ")  .setSource(jsonBuilder().startObject()  .field( "color ",   "blue ")  	cluster().wipeIndices( "test ");  
elasticsearch_6e0180db6a725d17cdc051fe0786d87008aa5305	buggy:  File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeDataLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");  context:  }  IndexMetaData  metaData  =  clusterService.state().metaData().index(shardId.index().name());  if  (metaData  ==  null)  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }  String  storeType  =  metaData.settings().get( "index.store.type ",   "fs ");  if  (!storeType.contains( "fs "))  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }          File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeDataLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");          File  indexFile  =  new  File(nodeEnv.shardLocation(shardId),   "index ");  if  (!indexFile.exists())  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }  Map<String,  StoreFileMetaData>  files  =  Maps.newHashMap();  for  (File  file  :  indexFile.listFiles())  {  if  (file.getName().endsWith( ".cks "))  {  continue;  }  	File  indexFile  =  new  File(nodeEnv.shardLocation(shardId),   "index ");  
elasticsearch_6af80d501797903e3a3b627cd7cc331e6806bc38	buggy:  lastNodeMatched.add(shard);  context:  }  unassignedIterator.remove();  routingNodes.ignoredUnassigned().add(shard);  }  else  {  if  (logger.isDebugEnabled())  {  }  changed  =  true;                      lastNodeMatched.add(shard);                      allocation.routingNodes().assignShardToNode(  shard,  lastNodeMatched.nodeId()  );  unassignedIterator.remove();  }  }  }  return  changed;  }  	allocation.routingNodes().assignShardToNode(  shard,  lastNodeMatched.nodeId()  );  
libgdx_3921b4761e32964f15705f0de5a40f080119d40e	buggy:  if  (scaleX  ==  0  &&  scaleY  ==  0  &&  rotation  ==  0)  context:  width  =  Math.abs(region.getRegionWidth());  height  =  Math.abs(region.getRegionHeight());  originX  =  width  /  2.0f;  originY  =  height  /  2.0f;  this.region  =  new  TextureRegion(region);  }  if  (region.getTexture()  !=  null)  {  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  if  (scaleX  ==  0  &&  scaleY  ==  0  &&  rotation  ==  0)  if  (scaleX  ==  1  &&  scaleY  ==  1  &&  rotation  ==  0)  batch.draw(region,  x,  y,  width,  height);  else  batch.draw(region,  x,  y,  originX,  originY,  width,  height,  scaleX,  scaleY,  rotation);  }  }  return  x  >  0  &&  y  >  0  &&  x  <  width  &&  y  <  height;  	if  (scaleX  ==  1  &&  scaleY  ==  1  &&  rotation  ==  0)  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullDateHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  cacheRecycler.longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector();  }  public  InternalFacet  buildFacet(String  facetName)  {          ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullDateHistogramFacet.FullEntry>(entries.v().size());          ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullDateHistogramFacet.FullEntry  value  =  (InternalFullDateHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }  	ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  
elasticsearch_8d2123a4522906397f22016e97ddcc97e864ad41	buggy:  root  =  xContentParser.map();  context:  parseField(builder,  builder.name,  idNode,  parserContext);  return  builder;  }  private  Tuple<String,  Map<String,  Object>>  extractMapping(String  type,  String  source)  throws  MapperParsingException  {  Map<String,  Object>  root;  XContentParser  xContentParser  =  null;  try  {  xContentParser  =  XContentFactory.xContent(source).createParser(source);              root  =  xContentParser.map();              root  =  xContentParser.mapOrdered();  }  catch  (IOException  e)  {  throw  new  MapperParsingException( "Failed  to  parse  mapping  definition ",  e);  }  finally  {  if  (xContentParser  !=  null)  {  xContentParser.close();  }  }  	root  =  xContentParser.mapOrdered();  
elasticsearch_5396d8e1498dca2904764f75f04c6977a6adb9bf	buggy:  assertThat( "Expected  id:   "  +  hit.getId()  +   "  at  position   "  +  i  +   "  but  wasn't. "  +  shardStatus,  hit.getId(),  equalTo(ids[i]));  context:  assertThat( "Expected  id:   "  +  hit.getId()  +   "  in  the  result  but  wasn't. "  +  shardStatus,  idsSet.remove(hit.getId()),  equalTo(true));  }  assertThat( "Expected  ids:   "  +  Arrays.toString(idsSet.toArray(new  String[0]))  +   "  in  the  result  -  result  size  differs. "  +  shardStatus,  idsSet.size(),  equalTo(0));  }  public  static  void  assertOrderedSearchHits(SearchResponse  searchResponse,  String...  ids)  {  String  shardStatus  =  formatShardStatus(searchResponse);  assertThat( "Expected  different  hit  count.   "  +  shardStatus,  searchResponse.getHits().hits().length,  equalTo(ids.length));  for  (int  i=0;  i<ids.length;  i++)  {  SearchHit  hit  =  searchResponse.getHits().hits()[i];              assertThat( "Expected  id:   "  +  hit.getId()  +   "  at  position   "  +  i  +   "  but  wasn't. "  +  shardStatus,  hit.getId(),  equalTo(ids[i]));              assertThat( "Expected  id:   "  +  ids[i]  +   "  at  position   "  +  i  +   "  but  wasn't. "  +  shardStatus,  hit.getId(),  equalTo(ids[i]));  }  }  public  static  void  assertHitCount(CountResponse  countResponse,  long  expectedHitCount)  {  if  (countResponse.getCount()  !=  expectedHitCount)  {  fail( "Count  is   "  +  countResponse.getCount()  +   "  but   "  +  expectedHitCount  +   "  was  expected.   "  +  formatShardStatus(countResponse));  }  	assertThat( "Expected  id:   "  +  ids[i]  +   "  at  position   "  +  i  +   "  but  wasn't. "  +  shardStatus,  hit.getId(),  equalTo(ids[i]));  
libgdx_777834757f63b7171f81abd206b1b316a39528ff	buggy:  if  (keycode  ==  Keys.KEYCODE_SPACE)  {  context:  if  (this.app  ==  null)  {  this.app  =  Gdx.app;  Box2DTest  test  =  tests[testIndex];  test.create();  }  Gdx.input.setInputProcessor(this);  }  if  (keycode  ==  Keys.KEYCODE_SPACE)  {  if  (keycode  ==  Keys.SPACE)  {  app.log( "TestCollection ",   "disposing  test  ' "  +  tests[testIndex].getClass().getName());  tests[testIndex].dispose();  testIndex++;  if  (testIndex  >=  tests.length)  testIndex  =  0;  Box2DTest  test  =  tests[testIndex];  test.create();  app.log( "TestCollection ",   "created  test  ' "  +  tests[testIndex].getClass().getName());  }  else  {  	if  (keycode  ==  Keys.SPACE)  {  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  return  new  Vector2(target.collisionCenter).sub(relativeVel.mul(Math.max(0,  time_to_target)));  context:  missile.alive  =  false;  GameInstance.getInstance().explosionParticles.addTinyExplosion(missile.collisionCenter);  }  public  Vector2  predict()  {  relativeVel.set(missile.velocity).sub(target.velocity);  toTarget.set(target.collisionCenter).sub(missile.collisionCenter);  if  (missile.velocity.dot(toTarget)  !=  0)  {  float  time_to_target  =  toTarget.dot(toTarget)  /  relativeVel.dot(toTarget);  return  new  Vector2(target.collisionCenter).sub(relativeVel.mul(Math.max(0,  time_to_target)));  return  new  Vector2(target.collisionCenter).sub(relativeVel.scl(Math.max(0,  time_to_target)));  }  else  {  return  target.collisionCenter;  }  }  public  void  update()  {  if  (target  ==  null  ||  missile.aliveTime  >  MAX_LIFETIME)  {  selfDestruct();  	return  new  Vector2(target.collisionCenter).sub(relativeVel.scl(Math.max(0,  time_to_target)));  
libgdx_bc6a63aa7f5a377f13c7d48731326b6f5f840a15	buggy:  pad(null);  context:  public  void  setBackground  (Drawable  background,  boolean  adjustPadding)  {  if  (this.background  ==  background)  return;  this.background  =  background;  if  (adjustPadding)  {  if  (background  ==  null)  pad(null);  pad(Value.zero);  else  pad(background.getTopHeight(),  background.getLeftWidth(),  background.getBottomHeight(),  background.getRightWidth());  invalidate();  }  }  public  Container<T>  background  (Drawable  background)  {  	pad(Value.zero);  
elasticsearch_22ea5e660888f363969d444e4fc8b6adfcfd7a27	buggy:  if  (indexShard.backupsShards().isEmpty())  {  context:  public  Builder  addReplica()  {  for  (int  shardId  :  shards.keySet())  {  addShard(shardId,  null,  false,  ShardRoutingState.UNASSIGNED);  }  return  this;  }  public  Builder  removeReplica()  {  for  (int  shardId  :  shards.keySet())  {  IndexShardRoutingTable  indexShard  =  shards.get(shardId);                  if  (indexShard.backupsShards().isEmpty())  {                  if  (indexShard.replicaShards().isEmpty())  {  return  this;  }  IndexShardRoutingTable.Builder  builder  =  new  IndexShardRoutingTable.Builder(indexShard.shardId());  for  (ShardRouting  shardRouting  :  indexShard)  {  builder.addShard(new  ImmutableShardRouting(shardRouting));  }  	if  (indexShard.replicaShards().isEmpty())  {  
libgdx_335bbf4ff4b0a346f7e63fb40586e5ed33857e84	buggy:  final  long  t  =  System.nanoTime();  context:  return  result;  }  public  PerformanceCounter  add(final  String  name)  {  PerformanceCounter  result  =  new  PerformanceCounter(name);  counters.add(result);  return  result;  }  public  void  tick()  {  final  long  t  =  System.nanoTime();  final  long  t  =  TimeUtils.nanoTime();  if  (lastTick  >  0L)  tick((t  -  lastTick)  *  nano2seconds);  lastTick  =  t;  }  public  void  tick(final  float  deltaTime)  {  for  (int  i  =  0;  i  <  counters.size;  i++)  counters.get(i).tick(deltaTime);  	final  long  t  =  TimeUtils.nanoTime();  
libgdx_34ed5fbfe5d918ed411939d351930b0ab1457dd2	buggy:  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  numTexCoords,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +  k));  context:  switch(k)  {  case  0:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions0());  break;  case  1:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions1());  break;  case  2:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions2());  break;  case  3:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions3());  break;  case  4:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions4());  break;  case  5:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions5());  break;  case  6:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions6());  break;  case  7:  numTexCoords  =  Integer.valueOf(buffer.getTextureCoordDimensions7());  break;  }  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  numTexCoords,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +  k));  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  numTexCoords,  ShaderProgram.TEXCOORD_ATTRIBUTE  +  k));  offset  +=  numTexCoords;  }  catch(NumberFormatException  e)  {  throw  new  GdxRuntimeException( "Can't  process  texture  coords  with  dimensions  !=  1,  2,  3,  4  (e.g.  float1) ");  }  }  }  VertexAttributes  attribs  =  new  VertexAttributes(attributes.toArray(new  VertexAttribute[0]));  	attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  numTexCoords,  ShaderProgram.TEXCOORD_ATTRIBUTE  +  k));  
libgdx_0a1224177f1a907c6524dcaedc2cc24585773dae	buggy:  System.arraycopy(sprite.vertices,  0,  vertices,  idx,  20);  context:  if(  sprite.texture  !=  lastTexture  )  {  renderMesh(  );  lastTexture  =  sprite.texture;  invTexWidth  =  1.0f  /  sprite.texture.getWidth();  invTexHeight  =  1.0f  /  sprite.texture.getHeight();  }  useTextBlend  =  false;  System.arraycopy(sprite.vertices,  0,  vertices,  idx,  20);  sprite.computeVertices(  vertices,  idx  );  idx  +=  20;  if(  idx  ==  vertices.length  )  renderMesh();  }  public  void  draw(  Sprite2  sprite  )  {  	sprite.computeVertices(  vertices,  idx  );  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  assertThat(scriptCounter.get(),  equalTo(cluster().hasFilterCache()  ?  3  :  1));  context:  String  script  =   "org.elasticsearch.search.scriptfilter.ScriptFilterSearchTests.incrementScriptCounter()  >  0 ";  scriptCounter.set(0);  SearchResponse  response  =  client().prepareSearch()  .setQuery(filteredQuery(termQuery( "test ",   "1 "),  scriptFilter(script).cache(true)))  .execute().actionGet();  assertThat(response.getHits().totalHits(),  equalTo(1l));          assertThat(scriptCounter.get(),  equalTo(cluster().hasFilterCache()  ?  3  :  1));          assertThat(scriptCounter.get(),  equalTo(internalCluster().hasFilterCache()  ?  3  :  1));  scriptCounter.set(0);  response  =  client().prepareSearch()  .setQuery(filteredQuery(termQuery( "test ",   "2 "),  scriptFilter(script).cache(true)))  .execute().actionGet();  assertThat(response.getHits().totalHits(),  equalTo(1l));  	assertThat(scriptCounter.get(),  equalTo(internalCluster().hasFilterCache()  ?  3  :  1));  
libgdx_015764fe472f9b7e2aee8ab616a883ad2996452d	buggy:  SnapshotArray<Actor>  children  =  getChildren();  context:  return  0;  }  public  void  setLayoutEnabled  (boolean  enabled)  {  if  (layoutEnabled  ==  enabled)  return;  layoutEnabled  =  enabled;  setLayoutEnabled(this,  enabled);  }  private  void  setLayoutEnabled  (Group  parent,  boolean  enabled)  {  SnapshotArray<Actor>  children  =  getChildren();  SnapshotArray<Actor>  children  =  parent.getChildren();  for  (int  i  =  0,  n  =  children.size;  i  <  n;  i++)  {  Actor  actor  =  children.get(i);  if  (actor  instanceof  Layout)  ((Layout)actor).setLayoutEnabled(enabled);  else  if  (actor  instanceof  Group)  //  setLayoutEnabled((Group)actor,  enabled);  }  }  	SnapshotArray<Actor>  children  =  parent.getChildren();  
libgdx_226527bf6c5daf0274cf4d557d86253dcfeffd12	buggy:  logoSprite.flip(false,  true);  context:  renderMode  =  (renderMode  +  1)  %  2;  return  false;  }  });  spriteBatch  =  new  SpriteBatch();  spriteBatch.setProjectionMatrix(new  Matrix4().setToOrtho(0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  0,  0,  1));  logoSprite  =  new  Sprite(Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge));  logoSprite.flip(false,  true);  logoSprite.getTextureRegion().flip(false,  true);  logoSprite.setPosition(0,  320  -  256);  logoSprite.setColor(1,  1,  1,  0.5f);  font  =  new  BitmapFont(Gdx.files.getFileHandle( "data/verdana39.fnt ",  FileType.Internal),  Gdx.files.getFileHandle(   "data/verdana39.png ",  FileType.Internal),  true);  cache1  =  new  BitmapFontCache(font);  cache2  =  new  BitmapFontCache(font);  	logoSprite.getTextureRegion().flip(false,  true);  
elasticsearch_91e78dcbe8f9f1c278f01f0f983b8028b898ed04	buggy:  index( "test ",   "type ",   " "  +  docCount,  jsonBuilder().startObject().endObject());  context:  }  public  void  consistentHitsWithSameSeed()  throws  Exception  {  prepareCreate( "test ").execute().actionGet();  ensureGreen();  int  docCount  =  atLeast(100);  for  (int  i  =  0;  i  <  docCount;  i++)  {              index( "test ",   "type ",   " "  +  docCount,  jsonBuilder().startObject().endObject());              index( "test ",   "type ",   " "  +  i,  jsonBuilder().startObject().endObject());  }  flush();  long  seed  =  System.nanoTime();  String  preference  =  _TestUtil.randomRealisticUnicodeString(getRandom());  float[]  scores  =  null;  	index( "test ",   "type ",   " "  +  i,  jsonBuilder().startObject().endObject());  
libgdx_bc152a10931c8c3fb3b734a91d9aba94ad7f214b	buggy:  SelectBox  camera  =  new  SelectBox(new  String[]  { "Camera ",   "Light "},  ui,  skin.getStyle(SelectBoxStyle.class),   "camera ");  context:  projector.position.set(2,  3,  2);  projector.lookAt(0,  0,  0);  projector.normalizeUp();  projector.update();  }  public  void  setupUI  ()  {  ui  =  new  Stage(480,  320,  true);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  TextButton  reload  =  new  TextButton( "Reload  Shaders ",  skin.getStyle(TextButtonStyle.class),   "reload ");  SelectBox  camera  =  new  SelectBox(new  String[]  { "Camera ",   "Light "},  ui,  skin.getStyle(SelectBoxStyle.class),   "camera ");  SelectBox  camera  =  new  SelectBox(new  String[]  { "Camera ",   "Light "},  skin.getStyle(SelectBoxStyle.class),   "camera ");  Label  fps  =  new  Label( "fps:   ",  skin.getStyle(LabelStyle.class),   "fps ");  Table  table  =  new  Table();  table.width  =  ui.width();  table.height  =  ui.height();  table.top().padTop(15);  table.add(reload).spaceRight(5);  table.add(camera).spaceRight(5);  	SelectBox  camera  =  new  SelectBox(new  String[]  { "Camera ",   "Light "},  skin.getStyle(SelectBoxStyle.class),   "camera ");  
elasticsearch_89e6b9cfc49a34e944abb0a7834ce1a3c9be4731	buggy:  SearchResponse  result  =  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).setFilter(filter).execute().actionGet();  context:  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource(o1).execute().actionGet();  client().admin().indices().prepareRefresh( "test ").execute().actionGet();  String  filter  =   "{\ "geo_shape\ ":  {\ "location2\ ":  {\ "indexed_shape\ ":  { "   "\ "id\ ":  \ "1\ ", "   "\ "type\ ":  \ "type1\ ", "   "\ "index\ ":  \ "test\ ", "   "\ "shape_field_name\ ":  \ "location2\ " "   "}}}} ";          SearchResponse  result  =  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).setFilter(filter).execute().actionGet();          SearchResponse  result  =  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();  assertHitCount(result,  1);  }  public  void  testThatShapeIsReturnedEvenWhenExclusionsAreSet()  throws  Exception  {  String  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type1 ")  .startObject( "properties ").startObject( "location ")  .field( "type ",   "geo_shape ")  	SearchResponse  result  =  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();  
libgdx_0c8e6d5d7433db555180bd39f7eb4b9d2a7f3466	buggy:  return  super.needsGL20();  context:  ++  libgdx_0c8e6d5d7433db555180bd39f7eb4b9d2a7f3466_485.java  package  com.badlogic.gdx.tests;  public  class  TextButtonTestGL2  extends  TextButtonTest  {  public  boolean  needsGL20()  {  return  super.needsGL20();  return  true;  }  }  	return  true;  
elasticsearch_747ce36915b3cd1f3d868d778db42ee811c97a04	buggy:  return   "bloom_default ";  context:  return  Defaults.FIELD_TYPE;  }  public  FieldDataType  defaultFieldDataType()  {  return  new  FieldDataType( "string ");  }  protected  String  defaultPostingFormat()  {          return   "bloom_default ";          return   "default ";  }  public  void  preParse(ParseContext  context)  throws  IOException  {  if  (context.sourceToParse().id()  !=  null)  {  context.id(context.sourceToParse().id());  super.parse(context);  	return   "default ";  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  ignoreMalformed);  context:  public  Builder  nullValue(float  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  FloatFieldMapper  build(BuilderContext  context)  {  FloatFieldMapper  fieldMapper  =  new  FloatFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,                      ignoreMalformed);                      ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	ignoreMalformed(context));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  PrimaryResponse<ShardDeleteResponse,  ShardDeleteRequest>(shardRequest.request,  response,  null);  context:  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_delete ").force(false));  }  catch  (Exception  e)  {  }  }  ShardDeleteResponse  response  =  new  ShardDeleteResponse(delete.version(),  delete.found());          return  new  PrimaryResponse<ShardDeleteResponse,  ShardDeleteRequest>(shardRequest.request,  response,  null);          return  new  PrimaryResponse<>(shardRequest.request,  response,  null);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  ShardDeleteRequest  request  =  shardRequest.request;  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  Engine.Delete  delete  =  indexShard.prepareDelete(request.type(),  request.id(),  request.version())  .origin(Engine.Operation.Origin.REPLICA);  	return  new  PrimaryResponse<>(shardRequest.request,  response,  null);  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();  context:  protected  Client  getClient2()  {  return  client( "server2 ");  }  client1.admin().indices().create(createIndexRequest( "test ")).actionGet();          ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();          ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  client1.index(indexRequest( "test ").type( "type1 ").id( "1 ").source(jsonBuilder().startObject().field( "text ",   "lucene ").endObject())).actionGet();  client1.index(indexRequest( "test ").type( "type1 ").id( "2 ").source(jsonBuilder().startObject().field( "text ",   "lucene  release ").endObject())).actionGet();  client1.admin().indices().refresh(refreshRequest()).actionGet();  	ClusterHealthResponse  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  request.indices(state.metaData().concreteIndices(request.indices()));  context:  protected  DeleteIndexResponse  newResponse()  {  return  new  DeleteIndexResponse();  }  protected  void  doExecute(DeleteIndexRequest  request,  ActionListener<DeleteIndexResponse>  listener)  {  ClusterState  state  =  clusterService.state();  String[]  indicesOrAliases  =  request.indices();          request.indices(state.metaData().concreteIndices(request.indices()));          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  if  (disableDeleteAllIndices)  {  if  (state.metaData().isAllIndices(indicesOrAliases)  ||  state.metaData().isPatternMatchingAllIndices(indicesOrAliases,  request.indices()))  {  throw  new  ElasticSearchIllegalArgumentException( "deleting  all  indices  is  disabled ");  }  }  super.doExecute(request,  listener);  	request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  context:  mesh.render(GL10.GL_TRIANGLES,  0,  3);  }  }  if  (mesh  ==  null)  {  mesh  =  new  Mesh(true,  false,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  mesh  =  new  Mesh(true,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  Usage.ColorPacked,  4,   "a_color "),  new  VertexAttribute(Usage.TextureCoordinates,  2,   "a_texCoords "));  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  Color.toFloatBits(255,  0,  0,  255),  0,  0,  0.5f,  -0.5f,  0,  Color.toFloatBits(0,  255,  0,  255),  1,  0,  0,  0.5f,  0,  Color.toFloatBits(0,  0,  255,  255),  0.5f,  1});  mesh.setIndices(new  short[]  {0,  1,  2});  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  	mesh  =  new  Mesh(true,  3,  3,  new  VertexAttribute(Usage.Position,  3,   "a_position "),  new  VertexAttribute(  
elasticsearch_a7dde8dd80d1a5430b832b88fca196c87b79c9a5	buggy:  indexRandom(false,  false,  builders);  context:  ));  ensureYellow();  int  numDocs  =  scaledRandomIntBetween(100,  1000);  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[numDocs];  for  (int  i  =  0;  i  <  builders.length;  i++)  {  builders[i]  =  client().prepareIndex( "test ",   "type ").setSource( "foo ",   "bar ");  }  disableTranslogFlush( "test ");          indexRandom(false,  false,  builders);          indexRandom(false,  false,  false,  Arrays.asList(builders));  //  this  one  corruptRandomTranslogFiles();  internalCluster().fullRestart();  sleep(1000);  	indexRandom(false,  false,  false,  Arrays.asList(builders));    //  this  one  
elasticsearch_e33dbcd93e3b1d0beac7e1629a790a28e5cab749	buggy:  return  new  AllTermQuery(termFactory.createTerm(value));  context:  public  boolean  enabled()  {  return  this.enabled;  }  return  new  AllTermQuery(term);  }          return  new  AllTermQuery(termFactory.createTerm(value));          return  new  AllTermQuery(names().createIndexNameTerm(value));  }  }  super.parse(context);  }  	return  new  AllTermQuery(names().createIndexNameTerm(value));  
elasticsearch_66825ac851a2578686eefca08f1900bf86f3d443	buggy:  addDocValue(context,  value);  context:  addIntegerFields(context,  fields,  value,  boost);  }  protected  void  addIntegerFields(ParseContext  context,  List<Field>  fields,  int  value,  float  boost)  {  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomIntegerNumericField  field  =  new  CustomIntegerNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              addDocValue(context,  value);              addDocValue(context,  fields,  value);  }  }  protected  Integer  nullValue()  {  return  nullValue;  }  	addDocValue(context,  fields,  value);  
libgdx_5860df981ce3025aabc1e129435203f11213dd15	buggy:  Mouse.setCursorPosition(x,  y  -  1);  context:  public  int  getDeltaY  (int  pointer)  {  if  (pointer  ==  0)  return  -deltaY;  else  return  0;  }  public  void  setCursorPosition  (int  x,  int  y)  {  Mouse.setCursorPosition(x,  y  -  1);  Mouse.setCursorPosition(x,  Gdx.graphics.getHeight()  -  1  -  y);  }  public  void  setCursorImage(Pixmap  pixmap,  int  xHotspot,  int  yHotspot)  {  try  {  if  (pixmap  ==  null)  {  Mouse.setNativeCursor  (null);  return;  	Mouse.setCursorPosition(x,  Gdx.graphics.getHeight()  -  1  -  y);  
libgdx_eeaea8a5dad98864dd80eab1ed34ddf7875c9ccb	buggy:  if  (!dirty)  return  localVertices;  context:  this.localVertices  =  vertices;  }  public  float[]  getLocalVertices  ()  {  return  localVertices;  }  public  float[]  getWorldVertices  ()  {  if  (!dirty)  return  localVertices;  if  (!dirty)  return  worldVertices;  dirty  =  false;  final  float[]  localVertices  =  this.localVertices;  if  (worldVertices  ==  null  ||  worldVertices.length  <  localVertices.length)  worldVertices  =  new  float[localVertices.length];  final  float[]  worldVertices  =  this.worldVertices;  final  float  positionX  =  x;  final  float  positionY  =  y;  	if  (!dirty)  return  worldVertices;  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  field.setBoost(context.fieldBoost(this));  context:  ShapeBuilder  shape  =  ShapeBuilder.parse(context.parser());  if  (shape  ==  null)  {  return;  }  Field[]  fields  =  defaultStrategy.createIndexableFields(shape.build());  if  (fields  ==  null  ||  fields.length  ==  0)  {  return;  }  for  (Field  field  :  fields)  {  if  (!customBoost())  {                      field.setBoost(context.fieldBoost(this));                      field.setBoost(boost);  }  if  (context.listener().beforeFieldAdded(this,  field,  context))  {  context.doc().add(field);  }  }  }  catch  (Exception  e)  {  throw  new  MapperParsingException( "failed  to  parse  [ "  +  names.fullName()  +   "] ",  e);  }  	field.setBoost(boost);  
elasticsearch_f94ff19f33db48235fa79af012ba96da42c5d015	buggy:  if  (fields()  !=  null)  {  context:  builder.startObject();  builder.field( "_index ",  shard.index());  builder.field( "_type ",  type());  builder.field( "_id ",  id());  if  (source()  !=  null)  {  builder.raw( ",  \ "_source\ "  :   ");  builder.raw(source());  }          if  (fields()  !=  null)  {          if  (fields()  !=  null  &&  !fields().isEmpty())  {  builder.startObject( "fields ");  for  (SearchHitField  field  :  fields().values())  {  if  (field.values().isEmpty())  {  continue;  }  if  (field.values().size()  ==  1)  {  builder.field(field.name(),  field.values().get(0));  }  else  {  	if  (fields()  !=  null  &&  !fields().isEmpty())  {  
libgdx_67b527fbb442dda91442ca6bac8e0c76a40bf37f	buggy:  GdxTest  test  =  new  ModelTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  ModelTest();  GdxTest  test  =  new  Basic3DTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.width  =  480;  config.height  =  320;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  Basic3DTest();  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  BytesStreamOutput  out  =  CachedStreamOutput.popEntry().cachedBytes();  context:  public  class  BytesStreamsTests  {  public  void  testSimpleStreams()  throws  Exception  {          BytesStreamOutput  out  =  CachedStreamOutput.popEntry().cachedBytes();          BytesStreamOutput  out  =  CachedStreamOutput.popEntry().bytes();  out.writeBoolean(false);  out.writeByte((byte)  1);  out.writeShort((short)  -1);  out.writeInt(-1);  out.writeVInt(2);  out.writeLong(-3);  out.writeVLong(4);  out.writeFloat(1.1f);  	BytesStreamOutput  out  =  CachedStreamOutput.popEntry().bytes();  
elasticsearch_772ee9db54c26bd154a837c7ea02b5a7316c92f1	buggy:  return  numDocs  +  1;  context:  return  false;  }  public  int  getNumDocs()  {  return  this.numDocs;  }  public  int  getNumOrds()  {          return  numDocs  +  1;          return  1;  }  public  Docs  ordinals()  {  return  new  Docs(this);  }  public  static  class  Docs  implements  Ordinals.Docs  {  	return  1;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<FieldMapper>  tempMappers  =  new  ArrayList<FieldMapper>(this.mappers);  context:  this.mappers  =  ImmutableList.<FieldMapper>builder().addAll(this.mappers).addAll(newMappers).build();  this.name  =  tempName.build();  this.indexName  =  tempIndexName.build();  this.fullName  =  tempFullName.build();  }  public  void  removeMappers(Iterable<FieldMapper>  mappersToRemove)  {          List<FieldMapper>  tempMappers  =  new  ArrayList<FieldMapper>(this.mappers);          List<FieldMapper>  tempMappers  =  new  ArrayList<>(this.mappers);  ImmutableOpenMap.Builder<String,  FieldMappers>  tempName  =  ImmutableOpenMap.builder(this.name);  ImmutableOpenMap.Builder<String,  FieldMappers>  tempIndexName  =  ImmutableOpenMap.builder(this.indexName);  ImmutableOpenMap.Builder<String,  FieldMappers>  tempFullName  =  ImmutableOpenMap.builder(this.fullName);  for  (FieldMapper  mapper  :  mappersToRemove)  {  FieldMappers  mappers  =  tempName.get(mapper.names().name());  if  (mappers  !=  null)  {  mappers  =  mappers.remove(mapper);  	List<FieldMapper>  tempMappers  =  new  ArrayList<>(this.mappers);  
libgdx_d7d6da12b772cf256d66208dfbb1a0de8dc5d6e9	buggy:  onModelClicked( "g3d/teapot.g3db ");  context:  );  public  void  create  ()  {  super.create();  showAxes  =  true;  onModelClicked( "g3d/teapot.g3db ");  onModelClicked( "g3d/knight.g3dj ");  }  private  final  static  Vector3  tmpV  =  new  Vector3();  private  final  static  Quaternion  tmpQ  =  new  Quaternion();  float  counter;  String  currentAsset;  protected  void  render  (ModelBatch  batch,  Array<ModelInstance>  instances)  {  	onModelClicked( "g3d/knight.g3dj ");  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  ClusterStateResponse  stateResponse  =  client().admin().cluster().prepareState().setFilterIndices(indexName).get();  context:  Set<String>  indices  =  new  HashSet<String>();  for  (int  i  =  0;  i  <  iters;  i++)  {  String  indexName  =   "foo "  +  randomRealisticUnicodeOfLengthBetween(0,  5);  if  (indices.contains(indexName))  {  continue;  }  indices.add(indexName);  createIndex(indexName);  ensureYellow();  //  ensuring  yellow  so  the  test  fails  faster  if  the  template  cannot  be  loaded              ClusterStateResponse  stateResponse  =  client().admin().cluster().prepareState().setFilterIndices(indexName).get();              ClusterStateResponse  stateResponse  =  client().admin().cluster().prepareState().setIndices(indexName).get();  assertThat(stateResponse.getState().getMetaData().indices().get(indexName).getNumberOfShards(),  is(10));  assertThat(stateResponse.getState().getMetaData().indices().get(indexName).getNumberOfReplicas(),  is(0));  }  }  }  	ClusterStateResponse  stateResponse  =  client().admin().cluster().prepareState().setIndices(indexName).get();  
libgdx	buggy:  listener.destroy();  context:  Gdx.input.processEvents(null);  }  public  void  displayChanged(GLAutoDrawable  arg0,  boolean  arg1,  boolean  arg2)  {  }  public  void  destroy()  {  canvas.getContext().makeCurrent();  listener.destroy();  listener.dispose();  }  }  	listener.dispose();  
elasticsearch_da938a659d3f5459167ea7f39eade00e004b66b4	buggy:  clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  Priority.URGENT,  new  AckedClusterStateUpdateTask()  {  context:  return  new  ClusterRerouteRequest();  }  protected  ClusterRerouteResponse  newResponse()  {  return  new  ClusterRerouteResponse();  }  protected  void  masterOperation(final  ClusterRerouteRequest  request,  final  ClusterState  state,  final  ActionListener<ClusterRerouteResponse>  listener)  throws  ElasticsearchException  {          clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  Priority.URGENT,  new  AckedClusterStateUpdateTask()  {          clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  Priority.IMMEDIATE,  new  AckedClusterStateUpdateTask()  {  private  volatile  ClusterState  clusterStateToSend;  private  volatile  RoutingExplanations  explanations;  public  boolean  mustAck(DiscoveryNode  discoveryNode)  {  return  true;  }  	clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  Priority.IMMEDIATE,  new  AckedClusterStateUpdateTask()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Document>  docs  =  new  ArrayList<Document>();  context:  directoryReader.close();  writer.close();  dir.close();  }  public  void  testNestedDocuments()  throws  IOException  {  Directory  dir  =  newDirectory();  IndexWriter  writer  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));          List<Document>  docs  =  new  ArrayList<Document>();          List<Document>  docs  =  new  ArrayList<>();  for  (int  i  =  0;  i  <  4;  ++i)  {  Document  doc  =  new  Document();  doc.add(new  Field(UidFieldMapper.NAME,   "1 ",  UidFieldMapper.Defaults.NESTED_FIELD_TYPE));  docs.add(doc);  }  Document  doc  =  new  Document();  	List<Document>  docs  =  new  ArrayList<>();  
elasticsearch_82072fc47fd37b9c1fff457b66f2112d88e4a396	buggy:  if  (method.isAnnotationPresent(Provides.class))  {  context:  public  synchronized  void  configure(Binder  binder)  {  for  (ProviderMethod<?>  providerMethod  :  getProviderMethods(binder))  {  providerMethod.configure(binder);  }  }  public  List<ProviderMethod<?>>  getProviderMethods(Binder  binder)  {  List<ProviderMethod<?>>  result  =  Lists.newArrayList();  for  (Class<?>  c  =  delegate.getClass();  c  !=  Object.class;  c  =  c.getSuperclass())  {  for  (Method  method  :  c.getDeclaredMethods())  {                  if  (method.isAnnotationPresent(Provides.class))  {                  if  (method.getAnnotation(Provides.class)  !=  null)  {  result.add(createProviderMethod(binder,  method));  }  }  }  return  result;  }  <T>  ProviderMethod<T>  createProviderMethod(Binder  binder,  final  Method  method)  {  	if  (method.getAnnotation(Provides.class)  !=  null)  {  
libgdx_01e254477052a47b350799df638f6e65f77e1799	buggy:  final  Slider  slider  =  new  Slider(0,  10,  1,  skin);  context:  ImageButtonStyle  style  =  new  ImageButtonStyle(skin.get(ButtonStyle.class));  style.imageUp  =  new  TextureRegionDrawable(image);  style.imageDown  =  new  TextureRegionDrawable(imageFlipped);  ImageButton  iconButton  =  new  ImageButton(style);  Button  buttonMulti  =  new  TextButton( "Multi\nLine\nToggle ",  skin,   "toggle ");  Button  imgButton  =  new  Button(new  Image(image),  skin);  Button  imgToggleButton  =  new  Button(new  Image(image),  skin,   "toggle ");  CheckBox  checkBox  =  new  CheckBox( "Check  me ",  skin);  final  Slider  slider  =  new  Slider(0,  10,  1,  skin);  final  Slider  slider  =  new  Slider(0,  10,  1,  false,  skin);  TextField  textfield  =  new  TextField( " ",  skin);  textfield.setMessageText( "Click  here! ");  SelectBox  dropdown  =  new  SelectBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX "},  skin);  Image  imageActor  =  new  Image(image2);  ScrollPane  scrollPane  =  new  ScrollPane(imageActor);  List  list  =  new  List(listEntries,  skin);  ScrollPane  scrollPane2  =  new  ScrollPane(list,  skin);  scrollPane2.setFlickScroll(false);  	final  Slider  slider  =  new  Slider(0,  10,  1,  false,  skin);  
libgdx_da1a17844e73ae33fafc932462e8d1eb8b022405	buggy:  GdxTest  test  =  new  UITest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-stb-truetype/libs/gdx-stb-truetype-natives.jar ").load( "gdx-stb-truetype ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  GdxTest  test  =  new  UITest();  GdxTest  test  =  new  FreeTypeTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.width  =  800;  config.height  =  480;  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  FreeTypeTest();  
elasticsearch_f5e55b7cb901843a4e1441cb16276e66c3c042f6	buggy:  System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().vmVersion());  context:  sb.append(major).append('.').append(minor).append('.').append(revision);  if  (build  <  50)  {  sb.append( ".Beta ").append(build);  }  else  if  (build  <  99)  {  sb.append( ".RC ").append(build  -  50);  }  return  sb.toString();  }  public  static  void  main(String[]  args)  {          System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().vmVersion());          System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version()  +   "( "  +  JvmInfo.jvmInfo().vmVersion()  +   ") ");  }  public  String  toString()  {  StringBuilder  sb  =  new  StringBuilder();  sb.append(number());  if  (snapshot())  {  sb.append( "-SNAPSHOT ");  	System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().version()  +   "( "  +  JvmInfo.jvmInfo().vmVersion()  +   ") ");  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  request.source(source);  context:  public  ClusterRerouteRequestBuilder  setDryRun(boolean  dryRun)  {  request.dryRun(dryRun);  return  this;  }  public  ClusterRerouteRequestBuilder  setSource(BytesReference  source)  throws  Exception  {          request.source(source);          request.setSource(source);  return  this;  }  protected  void  doExecute(ActionListener<ClusterRerouteResponse>  listener)  {  ((ClusterAdminClient)  client).reroute(request,  listener);  }  }  	request.setSource(source);  
elasticsearch_7f5befd95e19badf8b911df5c28a08613b0a9cd0	buggy:  if  (snapshot.state()  !=  SnapshotState.SUCCESS)  {  context:  public  void  restoreSnapshot(final  RestoreRequest  request,  final  RestoreSnapshotListener  listener)  {  try  {  Repository  repository  =  repositoriesService.repository(request.repository());  final  SnapshotId  snapshotId  =  new  SnapshotId(request.repository(),  request.name());  final  Snapshot  snapshot  =  repository.readSnapshot(snapshotId);  ImmutableList<String>  filteredIndices  =  SnapshotUtils.filterIndices(snapshot.indices(),  request.indices(),  request.indicesOptions());  final  MetaData  metaData  =  repository.readSnapshotMetaData(snapshotId,  filteredIndices);              if  (snapshot.state()  !=  SnapshotState.SUCCESS)  {              if  (!snapshot.state().restorable())  {  throw  new  SnapshotRestoreException(snapshotId,   "unsupported  snapshot  state  [ "  +  snapshot.state()  +   "] ");  }  if  (Version.CURRENT.before(snapshot.version()))  {  throw  new  SnapshotRestoreException(snapshotId,   "incompatible  snapshot  version  [ "  +  snapshot.version()  +   "] ");  }  final  Map<String,  String>  renamedIndices  =  newHashMap();  	if  (!snapshot.state().restorable())  {  
libgdx_7add388bafb5d965fe1f249bbe2f4253055407e6	buggy:  for  (int  i  =  size;  i  <  newSize;  i++)  context:  public  Iterator<T>  iterator  ()  {  if  (iterator  ==  null)  iterator  =  new  ArrayIterator(this);  iterator.index  =  0;  return  iterator;  }  public  void  truncate  (int  newSize)  {  if  (size  <=  newSize)  return;  for  (int  i  =  size;  i  <  newSize;  i++)  for  (int  i  =  newSize;  i  <  size;  i++)  items[i]  =  null;  size  =  newSize;  }  public  T[]  toArray  ()  {  return  (T[])toArray(items.getClass().getComponentType());  }  	for  (int  i  =  newSize;  i  <  size;  i++)  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  for  (int  i  =  0;  i  <  (immutableCluster().size()  *  5);  i++)  {  context:  }  latch.await();  assertThat(failure.get(),  nullValue());  client().admin().indices().prepareRefresh().execute().actionGet();  Map  masterSource  =  client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet().getSourceAsMap();          for  (int  i  =  0;  i  <  (immutableCluster().size()  *  5);  i++)  {          for  (int  i  =  0;  i  <  (cluster().size()  *  5);  i++)  {  assertThat(client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet().getSourceAsMap(),  equalTo(masterSource));  }  }  }  	for  (int  i  =  0;  i  <  (cluster().size()  *  5);  i++)  {  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "format ".equals(currentFieldName))  {  format  =  parser.text();  }  }  else  if  (token  ==  XContentParser.Token.VALUE_NUMBER)  {  if  ( "interval ".equals(currentFieldName))  {  interval  =  parser.longValue();  }  	}  else  if  ( "lang ".equals(currentFieldName))  {  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  indexShard.refresh(new  Engine.Refresh().force(true).source( "post_gateway "));  context:  lastIndexVersion  =  recoveryStatus.index().version();  lastTranslogId  =  -1;  lastTranslogLength  =  0;  lastTotalTranslogOperations  =  recoveryStatus.translog().currentTranslogOperations();  if  (indexShard.state()  !=  IndexShardState.STARTED)  {  indexShard.start( "post  recovery  from  gateway ");  }                      indexShard.refresh(new  Engine.Refresh().force(true).source( "post_gateway "));                      indexShard.refresh(new  Engine.Refresh( "post_gateway ").force(true));  recoveryStatus.time(System.currentTimeMillis()  -  recoveryStatus.startTime());  recoveryStatus.updateStage(RecoveryStatus.Stage.DONE);  if  (logger.isDebugEnabled())  {  }  else  if  (logger.isTraceEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  	indexShard.refresh(new  Engine.Refresh( "post_gateway ").force(true));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }          entries.release();          entries.close();  return  new  InternalFullHistogramFacet(facetName,  comparatorType,  entries1);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  class  Collector  extends  FacetExecutor.Collector  {  	entries.close();  
elasticsearch_942b427940f8dbc3695e391e2912969ded5625d8	buggy:  void  onFailure(Throwable  t);  context:  void  performStateRecovery(GatewayStateRecoveredListener  listener)  throws  GatewayException;  Class<?  extends  Module>  suggestIndexGateway();  void  reset()  throws  Exception;  interface  GatewayStateRecoveredListener  {  void  onSuccess(ClusterState  recoveredState);          void  onFailure(Throwable  t);          void  onFailure(String  message);  }  }  	void  onFailure(String  message);  
libgdx_3acb4cfe293cec597a89678bf92cf1ecbe96ce00	buggy:  return  2  *  this.width  *  this.height;  context:  public  String  toString  ()  {  return  x  +   ", "  +  y  +   ", "  +  width  +   ", "  +  height;  }  public  float  area  ()  {  return  this.width  *  this.height;  }  public  float  perimeter  ()  {  return  2  *  this.width  *  this.height;  return  2  *  (this.width  +  this.height);  }  public  int  hashCode  ()  {  final  int  prime  =  31;  int  result  =  1;  result  =  prime  *  result  +  NumberUtils.floatToRawIntBits(height);  result  =  prime  *  result  +  NumberUtils.floatToRawIntBits(width);  result  =  prime  *  result  +  NumberUtils.floatToRawIntBits(x);  	return  2  *  (this.width  +  this.height);  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(avg( "avg ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  Avg  avg  =  bucket.getAggregations().get( "avg ");  assertThat(avg,  notNullValue());  assertThat(avg.getName(),  equalTo( "avg "));  assertThat(Double.isNaN(avg.getValue()),  is(true));  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_32c5471d330a62363dc5d1fe4703d211fd229129	buggy:  sourceBuilder().setScore(score);  context:  public  PercolateRequestBuilder  setSort(boolean  sort)  {  sourceBuilder().setSort(sort);  return  this;  }  public  PercolateRequestBuilder  setScore(boolean  score)  {          sourceBuilder().setScore(score);          sourceBuilder().setTrackScores(score);  return  this;  }  public  PercolateRequestBuilder  setPercolateDoc(PercolateSourceBuilder.DocBuilder  docBuilder)  {  	sourceBuilder().setTrackScores(score);  
libgdx_439c26c0838e48d228ecb7a1f747c9209c8b15f2	buggy:  renderer  =  new  MD5Renderer(model,  false,  true);  context:  BitmapFont  font;  public  void  create  ()  {  Gdx.app.log( "MD5  Test ",   "created ");  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  anim  =  MD5Loader.loadAnimation(Gdx.files.internal( "data/walk1.md5anim ").read());  skeleton  =  new  MD5Joints();  skeleton.joints  =  new  float[anim.frames[0].joints.length];  animInfo  =  new  MD5AnimationInfo(anim.frames.length,  anim.secondsPerFrame);  renderer  =  new  MD5Renderer(model,  false,  true);  renderer  =  new  MD5Renderer(model,  true,  false);  renderer.setSkeleton(model.baseSkeleton);  	renderer  =  new  MD5Renderer(model,  true,  false);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(source,  true);  context:  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeUTF(index);  out.writeOptionalUTF(type);  out.writeUTF(id);  out.writeLong(version);  out.writeBoolean(exists);  if  (exists)  {              out.writeBytesReference(source,  true);              out.writeBytesReference(source);  if  (fields  ==  null)  {  out.writeVInt(0);  }  else  {  out.writeVInt(fields.size());  for  (GetField  field  :  fields.values())  {  field.writeTo(out);  }  }  	out.writeBytesReference(source);  
elasticsearch_6950c38a0436ec937797f01fba8d7d95e6d6225f	buggy:  final  Aggregator  aggregator  =  path.resolveAggregator(termsAggregator,  false);  context:  OrderPath  path  =  path();              final  Aggregator  aggregator  =  path.resolveAggregator(termsAggregator,  false);              final  Aggregator  aggregator  =  path.resolveAggregator(termsAggregator);  final  String  key  =  path.tokens[path.tokens.length  -  1].key;  if  (aggregator  instanceof  SingleBucketAggregator)  {  assert  key  ==  null  :   "this  should  be  picked  up  before  the  aggregation  is  executed  -  on  validate ";  return  new  Comparator<Terms.Bucket>()  {  public  int  compare(Terms.Bucket  o1,  Terms.Bucket  o2)  {  int  mul  =  asc  ?  1  :  -1;  	final  Aggregator  aggregator  =  path.resolveAggregator(termsAggregator);  
elasticsearch_9f10547f4b60e2e55318a955f4ace6496ef32cf3	buggy:  +   "]  while  using  version_type  [ "  +  request.versionType());  context:  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));  request.index(state.metaData().concreteSingleIndex(request.index()));  if  (state.metaData().hasIndex(request.index()))  {  MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mappingOrDefault(request.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required())  {  if  (request.routing()  ==  null)  {  if  (request.versionType()  !=  VersionType.INTERNAL)  {  throw  new  ElasticsearchIllegalArgumentException( "routing  value  is  required  for  deleting  documents  of  type  [ "  +  request.type()                                  +   "]  while  using  version_type  [ "  +  request.versionType());                                  +   "]  while  using  version_type  [ "  +  request.versionType()  +   "] ");  }  indexDeleteAction.execute(new  IndexDeleteRequest(request),  new  ActionListener<IndexDeleteResponse>()  {  public  void  onResponse(IndexDeleteResponse  indexDeleteResponse)  {  long  version  =  Versions.MATCH_ANY;  boolean  found  =  false;  for  (ShardDeleteResponse  deleteResponse  :  indexDeleteResponse.getResponses())  {  	+   "]  while  using  version_type  [ "  +  request.versionType()  +   "] ");  
libgdx_9d37f4a93e68875c1b6c0dc84dfbfc5764b74e9a	buggy:  textures[i].texture  =  null;  context:  if  (Gdx.graphics.isGL20Available())  Gdx.gl.glGetIntegerv(GL20.GL_MAX_TEXTURE_IMAGE_UNITS,  buffer);  else  Gdx.gl.glGetIntegerv(GL10.GL_MAX_TEXTURE_UNITS,  buffer);  return  buffer.get(0);  }  public  void  begin  ()  {  for(int  i  =  0;  i  <  count;  i++)  {  textures[i].texture  =  null;  textures[i].reset();  if(weights  !=  null)  weights[i]  =  0;  }  }  public  void  end  ()  {  for(int  i  =  0;  i  <  count;  i++)  {  if  (textures[i].texture  !=  null)  {  	textures[i].reset();  
elasticsearch_bd0b68080b513d6ef735e9a1c25ff7b110029a26	buggy:  System.out.println( "AGG  COLLECTION  MODE:   "  +  aggCollectionMode);  context:  public  void  setupSuiteScopeCluster()  throws  Exception  {  assertAcked(prepareCreate( "idx ")  .addMapping( "type ",   "nested ",   "type=nested "));  List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  numParents  =  randomIntBetween(3,  10);  numChildren  =  new  int[numParents];  aggCollectionMode  =  randomFrom(SubAggCollectionMode.values());          System.out.println( "AGG  COLLECTION  MODE:   "  +  aggCollectionMode);          logger.info( "AGG  COLLECTION  MODE:   "  +  aggCollectionMode);  int  totalChildren  =  0;  for  (int  i  =  0;  i  <  numParents;  ++i)  {  if  (i  ==  numParents  -  1  &&  totalChildren  ==  0)  {  numChildren[i]  =  randomIntBetween(1,  5);  }  else  {  numChildren[i]  =  randomInt(5);  }  	logger.info( "AGG  COLLECTION  MODE:   "  +  aggCollectionMode);  
libgdx_e8018318e45e948cbc746b54fa7f1f8c658d8439	buggy:  if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL)  {  context:  }  public  static  void  generateMipMap  (int  target,  Pixmap  pixmap,  int  textureWidth,  int  textureHeight)  {  if  (!useHWMipMap)  {  generateMipMapCPU(target,  pixmap,  textureWidth,  textureHeight);  return;  }  if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL)  {  if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL  ||  Gdx.app.getType()  ==  ApplicationType.iOS)  {  if  (Gdx.graphics.isGL20Available())  generateMipMapGLES20(target,  pixmap);  else  generateMipMapCPU(target,  pixmap,  textureWidth,  textureHeight);  }  else  {  generateMipMapDesktop(target,  pixmap,  textureWidth,  textureHeight);  }  }  	if  (Gdx.app.getType()  ==  ApplicationType.Android  ||  Gdx.app.getType()  ==  ApplicationType.WebGL  ||  Gdx.app.getType()  ==  ApplicationType.iOS)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();  context:  public  class  ScriptsConstantScoreBenchmark  extends  BasicScriptBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {  int  minTerms  =  49;  int  maxTerms  =  50;  int  maxIter  =  1000;  int  warmerIter  =  1000;  init(maxTerms);          List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();          List<Results>  allResults  =  new  ArrayList<>();  Settings  settings  =  settingsBuilder().put( "plugin.types ",  NativeScriptExamplesPlugin.class.getName()).build();  String  clusterName  =  ScriptsConstantScoreBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().clusterName(clusterName).settings(settingsBuilder().put(settings).put( "name ",   "node1 ")).node();  Client  client  =  node1.client();  client.admin().cluster().prepareHealth( "test ").setWaitForGreenStatus().setTimeout( "10s ").execute().actionGet();  indexData(10000,  client,  true);  	List<Results>  allResults  =  new  ArrayList<>();  
libgdx_a96276ab5c62a694fd8cb0630aba97e903f1d719	buggy:  cam.near  =  0.1f;  context:  model.setMaterial(material);  anim  =  (SkeletonAnimation)model.getAnimations()[0];  model.getBoundingBox(bounds);  float  len  =  bounds.getDimensions().len();  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(bounds.getCenter().cpy().add(len,  len,  len));  cam.lookAt(bounds.getCenter().x,  bounds.getCenter().y,  bounds.getCenter().z);  cam.near  =  0.1f;  cam.near  =  1f;  cam.far  =  1000;  renderer  =  new  ImmediateModeRenderer10();  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  }  private  boolean  hasNormals  ()  {  	cam.near  =  1f;  
elasticsearch_89e6b9cfc49a34e944abb0a7834ce1a3c9be4731	buggy:  return  request.getHeader(name);  context:  return  false;  }  public  BytesReference  content()  {  return  content;  }  public  String  header(String  name)  {          return  request.getHeader(name);          return  request.headers().get(name);  }  public  boolean  hasParam(String  key)  {  return  params.containsKey(key);  }  	return  request.headers().get(name);  
elasticsearch_c40935ae1473326783e2e15b85077c5b22720997	buggy:  String  builtMapping  =  docMapper.buildSource();  context:  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/xcontent/test-mapping.json ");  XContentDocumentMapper  docMapper  =  mapperParser.parse(mapping);  byte[]  json  =  jsonBuilder().startObject().field( "_id ",  1).field( "file ",  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/testXHTML.html ")).endObject().copiedBytes();  Document  doc  =  docMapper.parse(json).doc();  assertThat(doc.get(docMapper.mappers().smartName( "file.title ").mapper().names().indexName()),  equalTo( "XHTML  test  document "));  assertThat(doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()),  containsString( "This  document  tests  the  ability  of  Apache  Tika  to  extract  content "));          String  builtMapping  =  docMapper.buildSource();          String  builtMapping  =  docMapper.mappingSource().string();  docMapper  =  mapperParser.parse(builtMapping);  json  =  jsonBuilder().startObject().field( "_id ",  1).field( "file ",  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/testXHTML.html ")).endObject().copiedBytes();  doc  =  docMapper.parse(json).doc();  assertThat(doc.get(docMapper.mappers().smartName( "file.title ").mapper().names().indexName()),  equalTo( "XHTML  test  document "));  assertThat(doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()),  containsString( "This  document  tests  the  ability  of  Apache  Tika  to  extract  content "));  	String  builtMapping  =  docMapper.mappingSource().string();  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().primaryShardsGrouped(concreteIndices);  context:  IndexShardGatewayService  shardGatewayService  =  indicesService.indexServiceSafe(request.index())  .shardInjectorSafe(request.shardId()).getInstance(IndexShardGatewayService.class);  shardGatewayService.snapshot( "api ");  return  new  ShardGatewaySnapshotResponse(request.index(),  request.shardId());  }          return  clusterState.routingTable().primaryShardsGrouped(concreteIndices);          return  clusterState.routingTable().activePrimaryShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().activePrimaryShardsGrouped(concreteIndices,  true);  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(String  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  IpFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  IpFieldMapper  fieldMapper  =  new  IpFieldMapper(buildNames(context),  precisionStep,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  keyFieldData  =  (NumericFieldData)  fieldDataCache.cache(keyFieldDataType,  context.reader(),  keyFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  else  {  aggregator.valueFieldData  =  (NumericFieldData)  fieldDataCache.cache(valueFieldDataType,  context.reader(),  valueFieldName);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  keyFieldData.forEachValueInDoc(doc,  aggregator);  	script.setNextReader(context);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  buckets.release();  context:  final  int  size  =  (int)  Math.min(requiredSize,  buckets.size());  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  for  (DoubleObjectPagedHashMap.Cursor<List<DoubleTerms.Bucket>>  cursor  :  buckets)  {  List<DoubleTerms.Bucket>  sameTermBuckets  =  cursor.value;  final  InternalTerms.Bucket  b  =  sameTermBuckets.get(0).reduce(sameTermBuckets,  reduceContext.bigArrays());  if  (b.getDocCount()  >=  minDocCount)  {  ordered.insertWithOverflow(b);  }  }          buckets.release();          buckets.close();  InternalTerms.Bucket[]  list  =  new  InternalTerms.Bucket[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  (Bucket)  ordered.pop();  }  reduced.buckets  =  Arrays.asList(list);  return  reduced;  }  	buckets.close();  
elasticsearch_f8f8cac0ed52ebde54006b395c0cf7111d2dfc37	buggy:  assertThat(ttl0,  greaterThan(0L));  context:  client().prepareIndex( "test ",   "type1 ",   "with_routing ").setSource( "field1 ",   "value1 ").setTTL(providedTTLValue).setRouting( "routing ").setRefresh(true).execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "no_ttl ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "test ",   "type2 ",   "default_ttl ").setSource( "field1 ",   "value1 ").execute().actionGet();  long  currentTime  =  System.currentTimeMillis();  GetResponse  getResponse  =  client().prepareGet( "test ",   "type1 ",   "1 ").setFields( "_ttl ").setRealtime(true).execute().actionGet();  long  ttl0;  if  (getResponse.isExists())  {  ttl0  =  ((Number)  getResponse.getField( "_ttl ").getValue()).longValue();              assertThat(ttl0,  greaterThan(0L));              assertThat(ttl0,  greaterThan(-purgeInterval));  assertThat(ttl0,  lessThan(providedTTLValue  -  (currentTime  -  now)));  }  else  {  assertTrue((providedTTLValue  -  (currentTime  -  now))  <  0);  }  currentTime  =  System.currentTimeMillis();  getResponse  =  client().prepareGet( "test ",   "type1 ",   "1 ").setFields( "_ttl ").setRealtime(true).execute().actionGet();  if  (getResponse.isExists())  {  	assertThat(ttl0,  greaterThan(-purgeInterval));  
libgdx_c9dee0fd6eef21391c31d3298ba38159f8e28123	buggy:  buffers[offset]  =  GL15.glGenBuffers();  context:  public  void  glDeleteBuffers  (int  n,  int[]  buffers,  int  offset)  {  GL15.glDeleteBuffers(toBuffer(n,  buffers,  offset));  }  public  void  glDeleteBuffers  (int  n,  IntBuffer  buffers)  {  GL15.glDeleteBuffers(buffers);  }  public  void  glGenBuffers  (int  n,  int[]  buffers,  int  offset)  {  for  (int  i  =  offset;  i  <  offset  +  n;  i++)  buffers[offset]  =  GL15.glGenBuffers();  buffers[i]  =  GL15.glGenBuffers();  }  public  void  glGenBuffers  (int  n,  IntBuffer  buffers)  {  GL15.glGenBuffers(buffers);  }  public  void  glGetBooleanv  (int  pname,  boolean[]  params,  int  offset)  {  throw  new  UnsupportedOperationException( "not  implemented ");  	buffers[i]  =  GL15.glGenBuffers();  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  name  +   "]  must  be  in  the  [0,  100]  range ");  context:  private  Double  compression;  public  PercentilesBuilder(String  name)  {  super(name,  InternalPercentiles.TYPE.name());  }  public  PercentilesBuilder  percentiles(double...  percentiles)  {  for  (int  i  =  0;  i  <  percentiles.length;  i++)  {  if  (percentiles[i]  <  0  ||  percentiles[i]  >  100)  {  throw  new  IllegalArgumentException( "the  percents  in  the  percentiles  aggregation  [ "  +                          name  +   "]  must  be  in  the  [0,  100]  range ");                          getName()  +   "]  must  be  in  the  [0,  100]  range ");  }  }  this.percentiles  =  percentiles;  return  this;  }  public  PercentilesBuilder  compression(double  compression)  {  this.compression  =  compression;  	getName()  +   "]  must  be  in  the  [0,  100]  range ");  
libgdx_56a0df7d79084e12da5280ec64e0260796feb2e4	buggy:  buf.append(xmlTab).append(xmlOpen).append( "char  id= ").append(quote(String.format( "%-5s ",  g.id),  true)).append( "x= ")  context:  glyphs.add(fontData.glyphs[i][j]);  }  }  }  buf.append(xmlOpen).append( "chars  count= ").append(quote(glyphs.size)).append(xmlClose).append( "\n ");  for  (int  i  =  0;  i  <  glyphs.size;  i++)  {  Glyph  g  =  glyphs.get(i);  buf.append(xmlTab).append(xmlOpen).append( "char  id= ").append(quote(String.format( "%-5s ",  g.id),  true)).append( "x= ")  buf.append(xmlTab).append(xmlOpen).append( "char  id= ").append(quote(String.format( "%-6s ",  g.id),  true)).append( "x= ")  .append(quote(String.format( "%-5s ",  g.srcX),  true)).append( "y= ").append(quote(String.format( "%-5s ",  g.srcY),  true))  .append( "width= ").append(quote(String.format( "%-5s ",  g.width),  true)).append( "height= ")  .append(quote(String.format( "%-5s ",  g.height),  true)).append( "xoffset= ")  .append(quote(String.format( "%-5s ",  g.xoffset),  true)).append( "yoffset= ")  .append(quote(String.format( "%-5s ",  fontData.flipped  ?  g.yoffset  :  -(g.height  +  g.yoffset)),  true))  .append( "xadvance= ").append(quote(String.format( "%-5s ",  g.xadvance),  true)).append( "page= ")  .append(quote(String.format( "%-5s ",  g.page),  true)).append( "chnl= ").append(quote(0,  true)).append(xmlCloseSelf)  .append( "\n ");  	buf.append(xmlTab).append(xmlOpen).append( "char  id= ").append(quote(String.format( "%-6s ",  g.id),  true)).append( "x= ")  
elasticsearch_21c4530aaf5cd14c6880185b14d2b155286ff9b8	buggy:  return  shards.get((index  +  1)  %  size);  context:  }  return  limit  -  counter;  }  if  (size  ==  0)  {  return  null;  }          return  shards.get((index  +  1)  %  size);          return  shards.get(index);  }  if  (size  ==  0)  {  return  null;  }  int  counter  =  (this.counter);  if  (counter  >=  size)  {  	return  shards.get(index);  
elasticsearch_b5b1960a2bbc719411fa490b82e13490df808aff	buggy:  Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  SearchContext.current().cacheRecycler(),  NonNestedDocsFilter.INSTANCE);  context:  SearchContext.removeCurrent();  Releasables.close(current);  }  public  void  testBasicQuerySanities()  {  Query  childQuery  =  new  TermQuery(new  Term( "field ",   "value "));  ScoreType  scoreType  =  ScoreType.values()[random().nextInt(ScoreType.values().length)];  ParentFieldMapper  parentFieldMapper  =  SearchContext.current().mapperService().documentMapper( "child ").parentFieldMapper();  ParentChildIndexFieldData  parentChildIndexFieldData  =  SearchContext.current().fieldData().getForField(parentFieldMapper);          Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  SearchContext.current().cacheRecycler(),  NonNestedDocsFilter.INSTANCE);          Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  NonNestedDocsFilter.INSTANCE);  QueryUtils.check(query);  }  }  	Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  NonNestedDocsFilter.INSTANCE);  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  keyValues  =  keyIndexFieldData.load(context).getBytesValues();  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {              keyValues  =  keyIndexFieldData.load(context).getBytesValues();              keyValues  =  keyIndexFieldData.load(context).getBytesValues(true);  if  (script  !=  null)  {  script.setNextReader(context);  }  else  {  aggregator.valueValues  =  valueIndexFieldData.load(context).getDoubleValues();  }  }  	keyValues  =  keyIndexFieldData.load(context).getBytesValues(true);  
libgdx_5d379423cb8f460bf7e84ec0f6c290dba044fb23	buggy:  recorder  =  app.getAudio().newAudioRecoder(  22050,  true  );  context:  public  void  pause(Application  app)  {  device.dispose();  recorder.dispose();  }  public  void  resume(Application  app)  {  device  =  app.getAudio().newAudioDevice(true);  recorder  =  app.getAudio().newAudioRecoder(  22050,  true  );  recorder  =  app.getAudio().newAudioRecoder(  44100,  true  );  }  }  	recorder  =  app.getAudio().newAudioRecoder(  44100,  true  );  
elasticsearch_4634ca5cb8c8ad0a3c725363f3705a4078c04c9c	buggy:  if  (includeInAll  ==  null  ||  includeInAll)  {  context:  }  else  {  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  value  =  nullValue;  }  else  {  value  =  context.parser().text();  }  }  if  (value  ==  null)  {  return  null;  }          if  (includeInAll  ==  null  ||  includeInAll)  {          if  (context.includeInAll(includeInAll))  {  context.allEntries().addText(names.fullName(),  value,  boost);  }  if  (!indexed()  &&  !stored())  {  context.ignoredValue(names.indexName(),  value);  return  null;  }  return  new  Field(names.indexName(),  value,  store,  index,  termVector);  }  	if  (context.includeInAll(includeInAll))  {  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  context:  if  (maxChildren  >  0  &&  maxChildren  <  minChildren)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  'max_children'  is  less  than  'min_children' ");  }  Filter  nonNestedDocsFilter  =  null;  if  (parentDocMapper.hasNestedObjects())  {  nonNestedDocsFilter  =  parseContext.cacheFilter(NonNestedDocsFilter.INSTANCE,  null);  }  Filter  parentFilter  =  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null);          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  Query  childrenQuery;  if  (minChildren  >  1  ||  maxChildren  >  0)  {  childrenQuery  =  new  ChildrenQuery(parentChildIndexFieldData,  parentType,  childType,  parentFilter,query,ScoreType.NONE,minChildren,  maxChildren,  shortCircuitParentDocSet,  nonNestedDocsFilter);  }  else  {  childrenQuery  =  new  ChildrenConstantScoreQuery(parentChildIndexFieldData,  query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  nonNestedDocsFilter);  }  	ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  
elasticsearch_61aba891107fe77877e43a8e3379c498a57b429d	buggy:  result.matches(),  result.count(),  tookInMillis,  result.reducedFacets()  context:  }  if  (shardResults  ==  null)  {  long  tookInMillis  =  System.currentTimeMillis()  -  request.startTime;  return  new  PercolateResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,  tookInMillis);  }  else  {  PercolatorService.ReduceResult  result  =  percolatorService.reduce(percolatorTypeId,  shardResults);  long  tookInMillis  =  System.currentTimeMillis()  -  request.startTime;  return  new  PercolateResponse(  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,                      result.matches(),  result.count(),  tookInMillis,  result.reducedFacets()                      result.matches(),  result.count(),  tookInMillis,  result.reducedFacets(),  result.reducedAggregations()  );  }  }  protected  PercolateShardRequest  newShardRequest()  {  return  new  PercolateShardRequest();  }  	result.matches(),  result.count(),  tookInMillis,  result.reducedFacets(),  result.reducedAggregations()  
elasticsearch_82298d890c3549c9d62ed8cec39eeb068bc7b7b0	buggy:  BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(InternalStringTermsFacet.ComparatorType.COUNT.comparator(),  size  *  numberOfShards);  context:  }  }  TObjectIntHashMap<String>  facets  =  aggregator.facets();  if  (facets.isEmpty())  {  TermsStringFacetCollector.pushFacets(facets);  return  new  InternalStringTermsFacet(facetName,  arrayToCommaDelimitedString(fieldsNames),  comparatorType,  size,  ImmutableList.<InternalStringTermsFacet.StringEntry>of());  }  else  {              BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(InternalStringTermsFacet.ComparatorType.COUNT.comparator(),  size  *  numberOfShards);              BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(comparatorType.comparator(),  size  *  numberOfShards);  for  (TObjectIntIterator<String>  it  =  facets.iterator();  it.hasNext();)  {  it.advance();  ordered.add(new  InternalStringTermsFacet.StringEntry(it.key(),  it.value()));  }  TermsStringFacetCollector.pushFacets(facets);  return  new  InternalStringTermsFacet(facetName,  arrayToCommaDelimitedString(fieldsNames),  comparatorType,  size,  ordered);  }  }  	BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(comparatorType.comparator(),  size  *  numberOfShards);  
elasticsearch_7437acfcea49a66d938e26897af8f7b29e1654b9	buggy:  InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shard(request.shardId());  context:  return  new  IndexShardStatusRequest(shard.index(),  shard.id());  }  return  new  ShardStatus();  }  InternalIndexService  indexService  =  (InternalIndexService)  indicesService.indexServiceSafe(request.index());          InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shard(request.shardId());          InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shardSafe(request.shardId());  ShardStatus  shardStatus  =  new  ShardStatus(indexShard.routingEntry());  shardStatus.state  =  indexShard.state();  try  {  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  	InternalIndexShard  indexShard  =  (InternalIndexShard)  indexService.shardSafe(request.shardId());  
elasticsearch_1bcd3b67ee9f3462d6cac310b3be9a952f154b48	buggy:  GroupShardsIterator  groupIt  =  clusterService.operationRouting().searchShards(clusterState,  searchRequest.indices(),  searchRequest.queryHint(),  searchRequest.routing());  context:  transportService.registerHandler(TransportActions.SEARCH,  new  TransportHandler());  }  if  (optimizeSingleShard  &&  searchRequest.searchType()  !=  SCAN  &&  searchRequest.searchType()  !=  COUNT)  {  try  {  ClusterState  clusterState  =  clusterService.state();  searchRequest.indices(clusterState.metaData().concreteIndices(searchRequest.indices()));                  GroupShardsIterator  groupIt  =  clusterService.operationRouting().searchShards(clusterState,  searchRequest.indices(),  searchRequest.queryHint(),  searchRequest.routing());                  GroupShardsIterator  groupIt  =  clusterService.operationRouting().searchShards(clusterState,  searchRequest.indices(),  searchRequest.queryHint(),  searchRequest.routing(),  searchRequest.preference());  if  (groupIt.size()  ==  1)  {  searchRequest.searchType(QUERY_AND_FETCH);  }  }  catch  (IndexMissingException  e)  {  }  catch  (Exception  e)  {  	GroupShardsIterator  groupIt  =  clusterService.operationRouting().searchShards(clusterState,  searchRequest.indices(),  searchRequest.queryHint(),  searchRequest.routing(),  searchRequest.preference());  
libgdx_2ec8565f5e5380e98cded288111be2f21b1c9c5a	buggy:  ball.applyLinearImpulse(impulse,  ball.getWorldCenter());  context:  float  iy  =  ballpos.y  -  this.cy;  float  mag  =  (float)Math.sqrt(ix  *  ix  +  iy  *  iy);  float  scale  =  this.kick  /  mag;  return  new  Vector2(ix  *  scale,  iy  *  scale);  }  public  void  handleCollision  (Body  ball,  Body  bodyHit,  Field  field)  {  Vector2  impulse  =  this.impulseForBall(ball);  if  (impulse  !=  null)  {  ball.applyLinearImpulse(impulse,  ball.getWorldCenter());  ball.applyLinearImpulse(impulse,  ball.getWorldCenter(),  true);  flashForFrames(3);  }  }  public  void  draw  (IFieldRenderer  renderer)  {  renderer.fillCircle(cx,  cy,  radius,  redColorComponent(0),  greenColorComponent(0),  blueColorComponent(255));  }  	ball.applyLinearImpulse(impulse,  ball.getWorldCenter(),  true);  
libgdx_862db50e4239a7f86ef79fa7f9af53feb707d6f5	buggy:  multiplier  +=  0.1f;  context:  private  void  checkNextLevel  ()  {  if  (invaders.size()  ==  0  &&  ship.lives  >  0)  {  blocks.clear();  shots.clear();  shipShot  =  null;  Vector3  shipPosition  =  ship.position;  int  lives  =  ship.lives;  populate();  ship.position.set(shipPosition);  ship.lives  =  lives;  multiplier  +=  0.1f;  multiplier  +=  0.2f;  wave++;  }  }  public  void  moveShipLeft  (float  delta,  float  scale)  {  if  (ship.isExploding)  return;  ship.position.x  -=  delta  *  Ship.SHIP_VELOCITY  *  scale;  	multiplier  +=  0.2f;  
elasticsearch_8dedbd01df14c76fc8f1ac9060facc053fa2be9b	buggy:  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  context:  return  new  TypesExistsRequest();  }  protected  TypesExistsResponse  newResponse()  {  return  new  TypesExistsResponse();  }  protected  ClusterBlockException  checkBlock(TypesExistsRequest  request,  ClusterState  state)  {          return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());          return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  }  protected  void  masterOperation(final  TypesExistsRequest  request,  final  ClusterState  state,  final  ActionListener<TypesExistsResponse>  listener)  throws  ElasticsearchException  {  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  if  (concreteIndices.length  ==  0)  {  listener.onResponse(new  TypesExistsResponse(false));  return;  	return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
libgdx_c52ce6dcf5eec304a77e310fda357386a3863079	buggy:  throw  new  GdxRuntimeException( "Using  null  for  the  data  not  possible,  blame  LWJGL ");  context:  public  void  glBlendFunc  (int  sfactor,  int  dfactor)  {  GL11.glBlendFunc(sfactor,  dfactor);  }  public  void  glBlendFuncSeparate  (int  srcRGB,  int  dstRGB,  int  srcAlpha,  int  dstAlpha)  {  GL14.glBlendFuncSeparate(srcRGB,  dstRGB,  srcAlpha,  dstAlpha);  }  public  void  glBufferData  (int  target,  int  size,  Buffer  data,  int  usage)  {  if(data  ==  null)  throw  new  GdxRuntimeException( "Using  null  for  the  data  not  possible,  blame  LWJGL ");  GL15.glBufferData(target,  size,  usage);  else  if  (data  instanceof  ByteBuffer)  GL15.glBufferData(target,  (ByteBuffer)data,  usage);  else  if  (data  instanceof  IntBuffer)  GL15.glBufferData(target,  (IntBuffer)data,  usage);  else  if  (data  instanceof  FloatBuffer)  GL15.glBufferData(target,  (FloatBuffer)data,  usage);  else  if  (data  instanceof  DoubleBuffer)  GL15.glBufferData(target,  (DoubleBuffer)data,  usage);  	GL15.glBufferData(target,  size,  usage);  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  context:  public  class  SingleShardOneReplicaRoutingTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(SingleShardOneReplicaRoutingTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  
elasticsearch_06da379f5045e0c1d7436a7757400f9ba5b7f993	buggy:  if  (smartNameFieldMappers.hasDocMapper())  {  context:  parser.nextToken();  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  query ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              if  (smartNameFieldMappers.hasDocMapper())  {              if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  query  =  smartNameFieldMappers.mapper().fieldQuery(value,  parseContext);  }  finally  {  QueryParseContext.setTypes(previousTypes);  }  }  else  {  query  =  smartNameFieldMappers.mapper().fieldQuery(value,  parseContext);  	if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  
libgdx_2d9bdfa52c4b495ef6c5543c6a8faadba452eafe	buggy:  if  (particle  ==  null)  break;  context:  }  public  void  setSprite  (Sprite  sprite)  {  this.sprite  =  sprite;  if  (sprite  ==  null)  return;  float  originX  =  sprite.getOriginX();  float  originY  =  sprite.getOriginY();  Texture  texture  =  sprite.getTexture();  for  (int  i  =  0,  n  =  particles.length;  i  <  n;  i++)  {  Particle  particle  =  particles[i];  if  (particle  ==  null)  break;  if  (particle  ==  null)  continue;  particle.setTexture(texture);  particle.setOrigin(originX,  originY);  }  }  	if  (particle  ==  null)  continue;  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  addIntegerFields(fields,  count,  valueAndBoost.boost());  context:  return;  }  if  (fieldType.indexed()  ||  fieldType.stored()  ||  hasDocValues())  {  int  count;  if  (valueAndBoost.value()  ==  null)  {  count  =  nullValue();  }  else  {  count  =  countPositions(analyzer.analyzer().tokenStream(name(),  valueAndBoost.value()));  }              addIntegerFields(fields,  count,  valueAndBoost.boost());              addIntegerFields(context,  fields,  count,  valueAndBoost.boost());  }  if  (fields.isEmpty())  {  context.ignoredValue(names.indexName(),  valueAndBoost.value());  }  }  	addIntegerFields(context,  fields,  count,  valueAndBoost.boost());  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  context.release();  context:  }  context.preProcess();  try  {  long  count  =  Lucene.count(context.searcher(),  context.query());  return  new  ShardCountResponse(request.index(),  request.shardId(),  count);  }  catch  (Exception  e)  {  throw  new  QueryPhaseExecutionException(context,   "failed  to  execute  count ",  e);  }  }  finally  {              context.release();              context.close();  SearchContext.removeCurrent();  }  }  }  	context.close();  
elasticsearch_445db1e5592beaa036155c2573351d2f65a94d0a	buggy:  return  false;  context:  MetaData  metaData;  try  {  metaData  =  gateway.read();  }  catch  (Exception  e)  {  return  false;  }  if  (metaData  ==  null)  {              return  false;              return  true;  }  final  MetaData  fMetaData  =  metaData;  final  CountDownLatch  latch  =  new  CountDownLatch(fMetaData.indices().size());  clusterService.submitStateUpdateTask( "gateway  (recovered  meta-data) ",  new  ClusterStateUpdateTask()  {  MetaData.Builder  metaDataBuilder  =  newMetaDataBuilder()  .metaData(currentState.metaData()).maxNumberOfShardsPerNode(fMetaData.maxNumberOfShardsPerNode());  	return  true;  
elasticsearch_81c6b9075c6c6e584c8029b52fa73f71b4597939	buggy:  mltRequest.fields(request.paramAsStringArray( "fields ",  null));  context:  super(settings,  client);  controller.registerHandler(GET,   "/{index}/{type}/{id}/_moreLikeThis ",  this);  controller.registerHandler(POST,   "/{index}/{type}/{id}/_moreLikeThis ",  this);  controller.registerHandler(GET,   "/{index}/{type}/{id}/_mlt ",  this);  controller.registerHandler(POST,   "/{index}/{type}/{id}/_mlt ",  this);  }  MoreLikeThisRequest  mltRequest  =  moreLikeThisRequest(request.param( "index ")).type(request.param( "type ")).id(request.param( "id "));  try  {              mltRequest.fields(request.paramAsStringArray( "fields ",  null));              mltRequest.fields(request.paramAsStringArray( "mltFields ",  null));  mltRequest.percentTermsToMatch(request.paramAsFloat( "percentTermsToMatch ",  -1));  mltRequest.minTermFrequency(request.paramAsInt( "minTermFrequency ",  -1));  mltRequest.maxQueryTerms(request.paramAsInt( "maxQueryTerms ",  -1));  mltRequest.stopWords(request.paramAsStringArray( "stopWords ",  null));  mltRequest.minDocFreq(request.paramAsInt( "minDocFreq ",  -1));  mltRequest.maxDocFreq(request.paramAsInt( "maxDocFreq ",  -1));  mltRequest.minWordLen(request.paramAsInt( "minWordLen ",  -1));  mltRequest.maxWordLen(request.paramAsInt( "maxWordLen ",  -1));  	mltRequest.fields(request.paramAsStringArray( "mltFields ",  null));  
libgdx_f603e57ab8f4e0cc5c154da2a53292ddbb4d7356	buggy:  scrollPane.setOverscroll(false);  context:  }));  root  =  new  Table();  stage.addActor(root);  root.pad(10).top().left();  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  list  =  new  List(interpolators,  skin);  ScrollPane  scrollPane  =  new  ScrollPane(list,  skin);  scrollPane.setOverscroll(false);  scrollPane.setOverscroll(false,  false);  scrollPane.setFadeScrollBars(false);  root.add(scrollPane).expandY().fillY().prefWidth(110);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  root.setSize(width,  height);  root.invalidate();  	scrollPane.setOverscroll(false,  false);  
libgdx_81faef6516a91d603e10263bd026035634b215b9	buggy:  final  Mesh  mesh  =  new  Mesh(true,  vertices.size,  indices.size,  attributes);  context:  return  part;  }  public  Mesh  end()  {  if  (this.attributes  ==  null)  throw  new  RuntimeException( "Call  begin()  first ");  endpart();  final  Mesh  mesh  =  new  Mesh(true,  vertices.size,  indices.size,  attributes);  final  Mesh  mesh  =  new  Mesh(true,  vertices.size  /  stride,  indices.size,  attributes);  mesh.setVertices(vertices.items,  0,  vertices.size);  mesh.setIndices(indices.items,  0,  indices.size);  for  (MeshPart  p  :  parts)  p.mesh  =  mesh;  parts.clear();  attributes  =  null;  	final  Mesh  mesh  =  new  Mesh(true,  vertices.size  /  stride,  indices.size,  attributes);  
libgdx_a3ecc8c17b142ed979ec0e6a97e2ae3e104d2fe8	buggy:  if  (len  !=  0.f  &&  (Math.abs(len  -  1.0f)  >  MathUtils.FLOAT_ROUNDING_ERROR))  {  context:  public  float  len2  ()  {  return  x  *  x  +  y  *  y  +  z  *  z  +  w  *  w;  }  public  Quaternion  nor  ()  {  float  len  =  len2();  if  (len  !=  0.f  &&  (Math.abs(len  -  1.0f)  >  MathUtils.FLOAT_ROUNDING_ERROR))  {  if  (len  !=  0.f  &&  !MathUtils.isEqual(len,  1f))  {  len  =  (float)Math.sqrt(len);  w  /=  len;  x  /=  len;  y  /=  len;  z  /=  len;  }  return  this;  }  	if  (len  !=  0.f  &&  !MathUtils.isEqual(len,  1f))  {  
libgdx_bd4e401abdb51c5aba4e09e2c8f6ebbc355f4b03	buggy:  if  (layer.getVisible())  {  context:  }  }  public  void  render  ()  {  begin();  if  (cached)  {  spriteCache.draw(0);  }  else  {  for  (MapLayer  layer  :  map.getLayers())  {  if  (layer.getVisible())  {  if  (layer.isVisible())  {  if  (layer  instanceof  TiledMapTileLayer)  {  renderTileLayer((TiledMapTileLayer)  layer);  }  else  {  for  (MapObject  object  :  layer.getObjects())  {  renderObject(object);  }  }  }  	if  (layer.isVisible())  {  
elasticsearch_9c45fe8f9b37500ccd36d5bdd5052f29cb84b432	buggy:  if  (fieldType.indexOptions()  ==  IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)  {  context:  public  FieldDataType  defaultFieldDataType()  {  return  new  FieldDataType( "string ");  }  public  Query  queryStringTermQuery(Term  term)  {  if  (!autoBoost)  {  return  new  TermQuery(term);  }          if  (fieldType.indexOptions()  ==  IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)  {          if  (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)  >=  0)  {  return  new  AllTermQuery(term);  }  return  new  TermQuery(term);  }  public  Query  termQuery(Object  value,  QueryParseContext  context)  {  return  queryStringTermQuery(names().createIndexNameTerm(indexedValueForSearch(value)));  	if  (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)  >=  0)  {  
libgdx_c64a9d86f2a70f4e9cc4715927afadb7c96b7ba6	buggy:  modelBatch.render(lights,  instance);  context:  texture  =  null;  }  protected  void  renderWorld  ()  {  softBody.getVertices(mesh.getVerticesBuffer(),  softBody.getNodeCount(),  mesh.getVertexSize(),  0);  softBody.getWorldTransform(instance.transform);  modelBatch.begin(camera);  world.render(modelBatch,  lights);  modelBatch.render(lights,  instance);  modelBatch.render(instance,  lights);  modelBatch.end();  }  public  void  render  ()  {  super.render();  if  (world.renderMeshes)  {  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  	modelBatch.render(instance,  lights);  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (!indexed()  &&  !stored())  {  context:  public  Filter  nullValueFilter()  {  if  (nullValue  ==  null)  {  return  null;  }  return  new  TermFilter(names().createIndexNameTerm(nullValue  ?   "T "  :   "F "));  }  protected  Field  parseCreateField(ParseContext  context)  throws  IOException  {          if  (!indexed()  &&  !stored())  {          if  (!fieldType().indexed()  &&  !fieldType().stored())  {  return  null;  }  XContentParser.Token  token  =  context.parser().currentToken();  String  value  =  null;  if  (token  ==  XContentParser.Token.VALUE_NULL)  {  if  (nullValue  !=  null)  {  value  =  nullValue  ?   "T "  :   "F ";  }  	if  (!fieldType().indexed()  &&  !fieldType().stored())  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  HashMap<String,Object>  newSettings  =  new  HashMap<String,  Object>();  context:  indexResponse  =  client().prepareIndex( "test ",   "type ",   "1 ").setSource( "field1 ",   "value1_1 ").setVersion(19).setVersionType(VersionType.EXTERNAL).execute().actionGet();  assertThat(indexResponse.getVersion(),  equalTo(19l));  deleteResponse  =  client().prepareDelete( "test ",   "type ",   "1 ").setVersion(20).setVersionType(VersionType.EXTERNAL).execute().actionGet();  assertThat(deleteResponse.isFound(),  equalTo(true));  assertThat(deleteResponse.getVersion(),  equalTo(20l));          HashMap<String,Object>  newSettings  =  new  HashMap<String,  Object>();          HashMap<String,Object>  newSettings  =  new  HashMap<>();  newSettings.put( "index.gc_deletes ",-1);  client().admin().indices().prepareUpdateSettings( "test ").setSettings(newSettings).execute().actionGet();  Thread.sleep(300);  //  gc  works  based  on  estimated  sampled  time.  Give  it  a  chance...  indexResponse  =  client().prepareIndex( "test ",   "type ",   "1 ").setSource( "field1 ",   "value1_1 ").setVersion(20).setVersionType(VersionType.EXTERNAL).execute().actionGet();  assertThat(indexResponse.getVersion(),  equalTo(20l));  	HashMap<String,Object>  newSettings  =  new  HashMap<>();  
libgdx_36a4ac8ffe5f7c2bcbf1ff6678778c8e5ddcc1f0	buggy:  protected  void  processDir  (InputFile  inputDir,  ArrayList<InputFile>  value)  throws  Exception  {  context:  inputFiles.add(inputFile);  }  if  (recursive  &&  file.isDirectory())  process(file.listFiles(inputFilter),  outputRoot,  new  File(outputDir,  file.getName()),  dirToEntries,  depth  +  1);  }  }  protected  void  processFile  (InputFile  inputFile)  throws  Exception  {  }  protected  void  processDir  (InputFile  inputDir,  ArrayList<InputFile>  value)  throws  Exception  {  protected  void  processDir  (InputFile  inputDir,  ArrayList<InputFile>  files)  throws  Exception  {  }  protected  void  addProcessedFile  (InputFile  inputFile)  {  outputFiles.add(inputFile);  }  static  public  class  InputFile  {  public  File  inputFile;  	protected  void  processDir  (InputFile  inputDir,  ArrayList<InputFile>  files)  throws  Exception  {  
libgdx_41cadccfaa7b7767c664f473826aefc2bf042d9d	buggy:  spriteBatch.draw(font.texture,  vertices,  0,  idx);  context:  }  public  void  draw(SpriteBatch  spriteBatch)  {  spriteBatch.draw(font.texture,  vertices,  0,  idx);  spriteBatch.draw(font.getSprite().getTexture(),  vertices,  0,  idx);  }  void  reset(int  glyphCount)  {  x  =  0;  y  =  0;  idx  =  0;  int  vertexCount  =  glyphCount  *  20;  	spriteBatch.draw(font.getSprite().getTexture(),  vertices,  0,  idx);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  true);  context:  }  public  void  render  ()  {  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  Table.drawDebug(stage);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  ByteValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  byte  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Byte.MIN_VALUE  :  Byte.MAX_VALUE;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Byte.MAX_VALUE  :  Byte.MIN_VALUE;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).byteValue()  :  Byte.parseByte(missingValue.toString());  }          return  new  ByteValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  ByteValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  ByteValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);  context:  FieldMapper<?>  mapper  =  smartMappers.mapper();  if  (!(mapper  instanceof  GeoPointFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "field  [ "  +  fieldName  +   "]  is  not  a  geo_point  field ");  }  GeoPointFieldMapper  geoMapper  =  ((GeoPointFieldMapper)  mapper);  Filter  filter;  if  ( "indexed ".equals(type))  {  filter  =  IndexedGeoBoundingBoxFilter.create(topLeft,  bottomRight,  geoMapper);  }  else  if  ( "memory ".equals(type))  {              IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);              IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  filter  =  new  InMemoryGeoBoundingBoxFilter(topLeft,  bottomRight,  indexFieldData);  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "geo  bounding  box  type  [ "  +  type  +   "]  not  supported,  either  'indexed'  or  'memory'  are  allowed ");  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  	IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  
libgdx_af10a54d1c2d40cfe9686c7fe88c74a398d9693a	buggy:  if  (Gdx.input.isTouched())  {  context:  font  =  new  BitmapFont(Gdx.files.internal( "data/font16.fnt "),  Gdx.files.internal( "data/font16.png "),  false);  }  public  boolean  isDone  ()  {  return  isDone;  }  public  void  update  (float  delta)  {  if  (Gdx.input.isTouched())  {  if  (Gdx.input.justTouched())  {  isDone  =  true;  }  }  public  void  draw  (float  delta)  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	if  (Gdx.input.justTouched())  {  
libgdx_8afd0b7ab3c7036593210e95fd1b6cedac263be7	buggy:  jsonTexture.fileName  =  materialDir  +   "/ "  +  fileName;  context:  ModelTexture  jsonTexture  =  new  ModelTexture();  String  textureId  =  texture.getString( "id ",  null);  if(textureId  ==  null)  throw  new  GdxRuntimeException( "Texture  has  no  id. ");  jsonTexture.id  =  textureId;  String  fileName  =  texture.getString( "filename ",  null);  if(fileName  ==  null)  throw  new  GdxRuntimeException( "Texture  needs  filename. ");  jsonTexture.fileName  =  materialDir  +   "/ "  +  fileName;  jsonTexture.fileName  =  materialDir  +  (materialDir.endsWith( "/ ")  ?   " "  :   "/ ")  +  fileName;  jsonTexture.uvTranslation  =  readVector2(texture.get( "uvTranslation "),  0f,  0f);  jsonTexture.uvScaling  =  readVector2(texture.get( "uvScaling "),  1f,  1f);  String  textureType  =  texture.getString( "type ",  null);  if(textureType  ==  null)  throw  new  GdxRuntimeException( "Texture  needs  type. ");  	jsonTexture.fileName  =  materialDir  +  (materialDir.endsWith( "/ ")  ?   " "  :   "/ ")  +  fileName;  
libgdx_b190af77f97df7c52873e5fc53f9ed29f0c8122d	buggy:  new  JoglApplication(new  StillModelViewer( "data/multipleuvs.g3dt ",   "data/multipleuvs_1.png ",   "data/multipleuvs_2.png "),  context:  }  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  StillModelViewer( "data/multipleuvs.g3dt ",   "data/multipleuvs_1.png ",   "data/multipleuvs_2.png "),  new  JoglApplication(new  StillModelViewer( "data/models/multipleuvs.g3d ",   "data/multipleuvs_1.png ",   "data/multipleuvs_2.png "),   "StillModel  Viewer ",  800,  480,  false);  }  }  	new  JoglApplication(new  StillModelViewer( "data/models/multipleuvs.g3d ",   "data/multipleuvs_1.png ",   "data/multipleuvs_2.png "),  
elasticsearch_694bf287d682d1bd7dcafe7289e4a5f2bb5830da	buggy:  @TestLogging( "cluster.service:TRACE,discovery:TRACE ")  context:  ensureGreen();  for  (int  i  =  0;  i  <  10;  i++)  {  assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(),  equalTo(100l));  }  }      @TestLogging( "cluster.service:TRACE,discovery:TRACE ")      @TestLogging( "cluster.service:TRACE,discovery:TRACE,indices.cluster:TRACE ")  public  void  multipleNodesShutdownNonMasterNodes()  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "discovery.type ",   "zen ")  .put( "discovery.zen.minimum_master_nodes ",  3)  .put( "discovery.zen.ping_timeout ",   "200ms ")  .put( "discovery.initial_state_timeout ",   "500ms ")  .put( "gateway.type ",   "local ")  .build();  	@TestLogging( "cluster.service:TRACE,discovery:TRACE,indices.cluster:TRACE ")  
libgdx_dd897f20887ee94f02c3122419dd7777ae748988	buggy:  return  new  IOSApplication(new  EmptyDownloadTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  class  InnerClass  {  }  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  EmptyDownloadTest(),  config);  return  new  IOSApplication(new  DownloadTest(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.drain();  }  }  	return  new  IOSApplication(new  DownloadTest(),  config);  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  String  reason  =  String.format( "query:  [%s]  field:  [%s]  size:  [%d]  order:  [%s]  all_terms:  [%s]  fields:  [%s]  regex:  [%s]  excludes:  [%s] ",  queryVal,  facetField,  size,  compType,  allTerms,  useFields,  regex,  excludes);  context:  boolean  allTerms  =  random.nextInt(10)  ==  3;  termsFacetBuilder.allTerms(allTerms);  SearchResponse  response  =  client.prepareSearch( "test ")  .setQuery(QueryBuilders.termQuery( "q_field ",  queryVal))  .addFacet(termsFacetBuilder)  .execute().actionGet();  TermsFacet  actualFacetEntries  =  response.getFacets().facet( "facet1 ");  List<Tuple<Text,  Integer>>  expectedFacetEntries  =  getExpectedFacetEntries(allFieldValues,  queryControlFacets,  size,  compType,  excludes,  regex,  allTerms);                      String  reason  =  String.format( "query:  [%s]  field:  [%s]  size:  [%d]  order:  [%s]  all_terms:  [%s]  fields:  [%s]  regex:  [%s]  excludes:  [%s] ",  queryVal,  facetField,  size,  compType,  allTerms,  useFields,  regex,  excludes);                      String  reason  =  String.format(Locale.ROOT,   "query:  [%s]  field:  [%s]  size:  [%d]  order:  [%s]  all_terms:  [%s]  fields:  [%s]  regex:  [%s]  excludes:  [%s] ",  queryVal,  facetField,  size,  compType,  allTerms,  useFields,  regex,  excludes);  assertThat(reason,  actualFacetEntries.getEntries().size(),  equalTo(expectedFacetEntries.size()));  for  (int  i  =  0;  i  <  expectedFacetEntries.size();  i++)  {  assertThat(reason,  actualFacetEntries.getEntries().get(i).getTerm(),  equalTo(expectedFacetEntries.get(i).v1()));  assertThat(reason,  actualFacetEntries.getEntries().get(i).getCount(),  equalTo(expectedFacetEntries.get(i).v2()));  }  }  }  }  catch  (Throwable  t)  {  	String  reason  =  String.format(Locale.ROOT,   "query:  [%s]  field:  [%s]  size:  [%d]  order:  [%s]  all_terms:  [%s]  fields:  [%s]  regex:  [%s]  excludes:  [%s] ",  queryVal,  facetField,  size,  compType,  allTerms,  useFields,  regex,  excludes);  
elasticsearch_02cb2976917e3a6edb5e0caf5a65a95e3bff5f3a	buggy:  client.admin().indices().putMapping(putMappingRequest( "test ").mappingSource(mapping())).actionGet();  context:  private  Client  client;  startNode( "server1 ");  startNode( "server2 ");  client  =  getClient();  client.admin().indices().create(createIndexRequest( "test ")).actionGet();          client.admin().indices().putMapping(putMappingRequest( "test ").mappingSource(mapping())).actionGet();          client.admin().indices().putMapping(putMappingRequest( "test ").source(mapping())).actionGet();  for  (int  i  =  0;  i  <  100;  i++)  {  index(client( "server1 "),  Integer.toString(i),   "test ",  i);  }  client.admin().indices().refresh(refreshRequest( "test ")).actionGet();  }  	client.admin().indices().putMapping(putMappingRequest( "test ").source(mapping())).actionGet();  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  pageCacheRecycler,  bigArrays);  context:  }  }  final  SearchContext  createContext(ShardSearchRequest  request,  @Nullable  Engine.Searcher  searcher)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());  Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher( "search ")  :  searcher;          SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  pageCacheRecycler,  bigArrays);          SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  SearchContext.setCurrent(context);  try  {  context.scroll(request.scroll());  context.useSlowScroll(request.useSlowScroll());  parseTemplate(request);  parseSource(context,  request.source());  parseSource(context,  request.extraSource());  	SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  
libgdx_6238b7716f375dea84022fe13f67d6be2c554004	buggy:  if  (parameter  ==  null  ||  (parameter  !=  null  &&  parameter.textureData  ==  null))  {  context:  };  TextureLoaderInfo  info  =  new  TextureLoaderInfo();  public  TextureLoader  (FileHandleResolver  resolver)  {  super(resolver);  }  public  void  loadAsync  (AssetManager  manager,  String  fileName,  FileHandle  file,  TextureParameter  parameter)  {  info.filename  =  fileName;  if  (parameter  ==  null  ||  (parameter  !=  null  &&  parameter.textureData  ==  null))  {  if  (parameter  ==  null  ||  parameter.textureData  ==  null)  {  Pixmap  pixmap  =  null;  Format  format  =  null;  boolean  genMipMaps  =  false;  info.texture  =  null;  if  (parameter  !=  null)  {  format  =  parameter.format;  genMipMaps  =  parameter.genMipMaps;  	if  (parameter  ==  null  ||  parameter.textureData  ==  null)  {  
elasticsearch_9539661d40d5eb219f68e1298feddb9359b4a14d	buggy:  public  Facet  reduce(String  name,  List<Facet>  facets)  {  context:  }  return  other;  }  public  long  getOtherCount()  {  return  otherCount();  }      public  Facet  reduce(String  name,  List<Facet>  facets)  {      public  Facet  reduce(List<Facet>  facets)  {  if  (facets.size()  ==  1)  {  return  facets.get(0);  }  InternalLongTermsFacet  first  =  (InternalLongTermsFacet)  facets.get(0);  TLongIntHashMap  aggregated  =  CacheRecycler.popLongIntMap();  long  missing  =  0;  long  total  =  0;  for  (Facet  facet  :  facets)  {  	public  Facet  reduce(List<Facet>  facets)  {  
elasticsearch_6aa9be238c7ae3a7168ea0271df6006779b15504	buggy:  return  operations.size();  context:  super(shardId,  indexSettings);  }  return  this.id;  }          return  operations.size();          return  operationCounter.get();  }  return  new  ByteSizeValue(estimatedMemorySize.get(),  ByteSizeUnit.BYTES);  }  synchronized  (mutex)  {  	return  operationCounter.get();  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  if  (termsEnum.seekExact(term,  true))  {  context:  this.vocabluarySize  =  vocSize  ==  -1  ?  reader.maxDoc()  :  vocSize;  this.useTotalTermFreq  =  vocSize  !=  -1;  this.numTerms  =  terms.size();  this.termsEnum  =  terms.iterator(null);  this.reader  =  reader;  this.realWordLikelyhood  =  realWordLikelyHood;  this.separator  =  separator;  }  public  long  frequency(BytesRef  term)  throws  IOException  {        if  (termsEnum.seekExact(term,  true))  {        if  (termsEnum.seekExact(term))  {  return  useTotalTermFreq  ?  termsEnum.totalTermFreq()  :  termsEnum.docFreq();  }  return  0;  }  protected  double  channelScore(Candidate  candidate,  Candidate  original)  throws  IOException  {  if  (candidate.stringDistance  ==  1.0d)  {  return  realWordLikelyhood;  	if  (termsEnum.seekExact(term))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<GeoPointValuesSource>  config  =  new  ValuesSourceConfig<GeoPointValuesSource>(GeoPointValuesSource.class);  context:  if  (shardSize  <  0)  {  shardSize  =  BucketUtils.suggestShardSideQueueSize(requiredSize,  context.numberOfShards());  }  if  (shardSize  <  requiredSize)  {  shardSize  =  requiredSize;  }          ValuesSourceConfig<GeoPointValuesSource>  config  =  new  ValuesSourceConfig<GeoPointValuesSource>(GeoPointValuesSource.class);          ValuesSourceConfig<GeoPointValuesSource>  config  =  new  ValuesSourceConfig<>(GeoPointValuesSource.class);  if  (field  ==  null)  {  return  new  GeoGridFactory(aggregationName,  config,  precision,  requiredSize,  shardSize);  }  FieldMapper<?>  mapper  =  context.smartNameFieldMapper(field);  if  (mapper  ==  null)  {  config.unmapped(true);  return  new  GeoGridFactory(aggregationName,  config,  precision,  requiredSize,  shardSize);  	ValuesSourceConfig<GeoPointValuesSource>  config  =  new  ValuesSourceConfig<>(GeoPointValuesSource.class);  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  StreamOutput  streamOutput  =  cachedEntry.cachedBytes(CompressorFactory.defaultCompressor());  context:  return  null;  }  byte[]  value;  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  return  null;  }  else  {  value  =  context.parser().binaryValue();  if  (compress  !=  null  &&  compress  &&  !CompressorFactory.isCompressed(value,  0,  value.length))  {  if  (compressThreshold  ==  -1  ||  value.length  >  compressThreshold)  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();                      StreamOutput  streamOutput  =  cachedEntry.cachedBytes(CompressorFactory.defaultCompressor());                      StreamOutput  streamOutput  =  cachedEntry.bytes(CompressorFactory.defaultCompressor());  streamOutput.writeBytes(value,  0,  value.length);  streamOutput.close();  value  =  cachedEntry.bytes().copiedByteArray();  CachedStreamOutput.pushEntry(cachedEntry);  }  }  	StreamOutput  streamOutput  =  cachedEntry.bytes(CompressorFactory.defaultCompressor());  
elasticsearch_5f538b1ba39f939e6b596defd333d556295777c6	buggy:  clusterState  =  new  ClusterState(clusterState.version()  +  1,  clusterState.metaData(),  clusterState.routingTable(),  clusterState.nodes());  context:  StringBuilder  sb  =  new  StringBuilder( "failed  to  execute  cluster  state  update,  state:\nversion  [ ").append(clusterState.version()).append( "],  source  [ ").append(source).append( "]\n ");  sb.append(clusterState.nodes().prettyPrint());  sb.append(clusterState.routingTable().prettyPrint());  sb.append(clusterState.readOnlyRoutingNodes().prettyPrint());  return;  }  if  (previousClusterState  !=  clusterState)  {  if  (clusterState.nodes().localNodeMaster())  {                          clusterState  =  new  ClusterState(clusterState.version()  +  1,  clusterState.metaData(),  clusterState.routingTable(),  clusterState.nodes());                          clusterState  =  new  ClusterState(clusterState.version()  +  1,  clusterState);  }  else  {  if  (clusterState.version()  <  previousClusterState.version())  {  return;  }  }  	clusterState  =  new  ClusterState(clusterState.version()  +  1,  clusterState);  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  }  }  if  (factor  >  maxBoost)  {  factor  =  maxBoost;  }  float  score  =  scorer.score();  return  subQueryBoost  *  score  *  factor;  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  scorer.freq();  }  }  public  String  toString(String  field)  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "custom  score  ( ").append(subQuery.toString(field)).append( ",  functions:  [ ");  	public  int  freq()  throws  IOException  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<String>  terms  =  new  ArrayList<String>();  context:  Analyzer  analyzer  =  analysisService.analyzer(analyzerName).analyzer();  AllEntries  allEntries  =  new  AllEntries();  allEntries.addText( "field1 ",  text,  1.0f);  allEntries.reset();  TokenStream  stream  =  AllTokenStream.allTokenStream( "_all ",  allEntries,  analyzer);  stream.reset();  CharTermAttribute  termAtt  =  stream.addAttribute(CharTermAttribute.class);          List<String>  terms  =  new  ArrayList<String>();          List<String>  terms  =  new  ArrayList<>();  while  (stream.incrementToken())  {  String  tokText  =  termAtt.toString();  terms.add(tokText);  }  return  terms;  }  private  Settings  getJsonSettings()  {  	List<String>  terms  =  new  ArrayList<>();  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "format ".equals(currentFieldName))  {  format  =  parser.text();  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "ranges ".equals(currentFieldName))  {  ranges  =  new  ArrayList<RangeAggregator.Range>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  	}  else  if  ( "lang ".equals(currentFieldName))  {  
elasticsearch_d6b613ac8c6e3ddee6d8e1604db208721f03cb75	buggy:  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.queryString( "_id:XXX* ")).execute().actionGet();  context:  SearchResponse  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.termQuery( "_id ",   "XXX1 ")).execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.queryString( "_id:XXX1 ")).execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.prefixQuery( "_id ",   "XXX ")).execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));          searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.queryString( "_id:XXX* ")).execute().actionGet();          searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.queryString( "_id:XXX* ").lowercaseExpandedTerms(false)).execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  }  public  void  simpleDateRangeWithUpperInclusiveEnabledTests()  throws  Exception  {  client.admin().indices().prepareDelete().execute().actionGet();  client.admin().indices().prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder()).execute().actionGet();  client.prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field ",   "2010-01-05T02:00 ").execute().actionGet();  	searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.queryString( "_id:XXX* ").lowercaseExpandedTerms(false)).execute().actionGet();  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).currentNodeId(),  nullValue());  assertThat(routingTable.index( "test ").shard(0).shards().get(1).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
libgdx_9c68e1f28a8dd7068fbc3842308382e668192a53	buggy:  if  (list.getParent()  ==  null)  return;  context:  public  float  getPrefWidth  ()  {  return  prefWidth;  }  public  float  getPrefHeight  ()  {  return  prefHeight;  }  public  void  hideList  ()  {  if  (list.getParent()  ==  null)  return;  if  (list  ==  null  ||  list.getParent()  ==  null)  return;  getStage().removeCaptureListener(list.stageListener);  list.addAction(sequence(fadeOut(0.15f,  Interpolation.fade),  removeActor()));  }  class  SelectList  extends  Actor  {  Vector2  oldScreenCoords  =  new  Vector2();  float  itemHeight;  	if  (list  ==  null  ||  list.getParent()  ==  null)  return;  
elasticsearch_942b427940f8dbc3695e391e2912969ded5625d8	buggy:  .put(indexMetaData)  context:  final  IndexMetaData.Builder  indexMetaDataBuilder  =  newIndexMetaDataBuilder(request.index).settings(actualIndexSettings);  for  (MappingMetaData  mappingMd  :  mappingsMetaData.values())  {  indexMetaDataBuilder.putMapping(mappingMd);  }  indexMetaDataBuilder.state(request.state);  final  IndexMetaData  indexMetaData  =  indexMetaDataBuilder.build();  MetaData  newMetaData  =  newMetaDataBuilder()  .metaData(currentState.metaData())                              .put(indexMetaData)                              .put(indexMetaData,  false)  .build();  ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks());  if  (!request.blocks.isEmpty())  {  for  (ClusterBlock  block  :  request.blocks)  {  blocks.addIndexBlock(request.index,  block);  	.put(indexMetaData,  false)  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  smartNameFieldMappers.mapper().indexName();  context:  jp.nextToken();  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  fieldName  =  smartNameFieldMappers.mapper().indexName();                  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  SpanTermQuery  query  =  new  SpanTermQuery(new  Term(fieldName,  value));  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  }  	fieldName  =  smartNameFieldMappers.mapper().names().indexName();  
elasticsearch_5dd18acd0e338f9b01e68cf39cd263f22d03ef50	buggy:  clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  request.waitForEvents(),  new  ProcessedClusterStateUpdateTask()  {  context:  protected  ClusterHealthResponse  newResponse()  {  return  new  ClusterHealthResponse();  }  protected  ClusterHealthResponse  masterOperation(ClusterHealthRequest  request,  ClusterState  unusedState)  throws  ElasticSearchException  {  long  endTime  =  System.currentTimeMillis()  +  request.timeout().millis();  if  (request.waitForEvents()  !=  null)  {  final  CountDownLatch  latch  =  new  CountDownLatch(1);              clusterService.submitStateUpdateTask( "cluster_reroute  (api) ",  request.waitForEvents(),  new  ProcessedClusterStateUpdateTask()  {              clusterService.submitStateUpdateTask( "cluster_health  (wait_for_events  [ "  +  request.waitForEvents()  +   "]) ",  request.waitForEvents(),  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  return  currentState;  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  latch.countDown();  	clusterService.submitStateUpdateTask( "cluster_health  (wait_for_events  [ "  +  request.waitForEvents()  +   "]) ",  request.waitForEvents(),  new  ProcessedClusterStateUpdateTask()  {  
libgdx_91cd849f495d62ec6693eff9193661852204c6f4	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.SoundTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.SoundTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(stats( "stats ")))  .execute().actionGet();  assertShardExecutionState(searchResponse,  0);  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  Stats  stats  =  bucket.getAggregations().get( "stats ");  assertThat(stats,  notNullValue());  assertThat(stats.getName(),  equalTo( "stats "));  assertThat(stats.getCount(),  equalTo(0l));  assertThat(stats.getSum(),  equalTo(0.0));  assertThat(stats.getMin(),  equalTo(Double.POSITIVE_INFINITY));  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  indexService.filterCache();  context:  public  IndexQueryParserService  queryParserService()  {  return  indexService.queryParserService();  }  public  SimilarityService  similarityService()  {  return  indexService.similarityService();  }  public  FilterCache  filterCache()  {          return  indexService.filterCache();          return  indexService.cache().filter();  }  public  TimeValue  timeout()  {  return  timeout;  }  public  SearchContext  sort(Sort  sort)  {  this.sort  =  sort;  	return  indexService.cache().filter();  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  map2.release();  context:  assertEquals(map1.size(),  map2.size());  }  }  for  (int  i  =  0;  i  <=  maxKey;  ++i)  {  assertSame(map1.get(i),  map2.get(i));  }  final  DoubleObjectOpenHashMap<Object>  copy  =  new  DoubleObjectOpenHashMap<>();  for  (DoubleObjectPagedHashMap.Cursor<Object>  cursor  :  map2)  {  copy.put(cursor.key,  cursor.value);  }          map2.release();          map2.close();  assertEquals(map1,  copy);  }  }  	map2.close();  
elasticsearch_6b497589cee759594086ea33627029e2a03f2e28	buggy:  throw  new  ElasticSearchIllegalArgumentException( "No  query  to  execute,  not  in  body,  and  not  bounded  to  'q'  parameter ");  context:  builder.endObject();  }  builder.endArray();  }  builder.endObject();  }  public  static  byte[]  parseQuerySource(RestRequest  request)  {  String  queryString  =  request.param( "q ");  if  (queryString  ==  null)  {              throw  new  ElasticSearchIllegalArgumentException( "No  query  to  execute,  not  in  body,  and  not  bounded  to  'q'  parameter ");              return  null;  }  QueryStringQueryBuilder  queryBuilder  =  QueryBuilders.queryString(queryString);  queryBuilder.defaultField(request.param( "df "));  queryBuilder.analyzer(request.param( "analyzer "));  String  defaultOperator  =  request.param( "default_operator ");  if  (defaultOperator  !=  null)  {  if  ( "OR ".equals(defaultOperator))  {  queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);  	return  null;  
libgdx_0e0eda76dc2dbe9c200da4fc8782e55914aa6a50	buggy:  new  JoglApplication(new  GdxInvaders(), "Gdx  Invaders ",  480,  320,  false);  context:  public  class  GdxInvadersDesktop  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  GdxInvaders(), "Gdx  Invaders ",  480,  320,  false);  new  JoglApplication(new  GdxInvaders(), "Gdx  Invaders ",  800,  480,  false);  }  }  	new  JoglApplication(new  GdxInvaders(), "Gdx  Invaders ",  800,  480,  false);  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  Query  query  =  indexQueryParser.parse(jp,  context.source());  context:  public  class  QueryParseElement  implements  SearchParseElement  {  JsonIndexQueryParser  indexQueryParser  =  (JsonIndexQueryParser)  context.queryParser();          Query  query  =  indexQueryParser.parse(jp,  context.source());          Query  query  =  indexQueryParser.parse(jp);  query.setBoost(query.getBoost()  *  context.queryBoost());  context.query(query);  }  }  	Query  query  =  indexQueryParser.parse(jp);  
elasticsearch_c8285739d28c6f363e123266e4dc0e1e788c5c69	buggy:  if  ( "_all ".equals(actualField))  {  context:  if  (termStr.equals( "* "))  {  if  ( "* ".equals(field)  ||  Objects.equal(field,  this.field))  {  String  actualField  =  field;  if  (actualField  ==  null)  {  actualField  =  this.field;  }  if  (actualField  ==  null)  {  return  newMatchAllDocsQuery();  }                  if  ( "_all ".equals(actualField))  {                  if  ( "* ".equals(actualField)  ||   "_all ".equals(actualField))  {  return  newMatchAllDocsQuery();  }  return  fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(parseContext,  actualField);  }  }  Collection<String>  fields  =  extractMultiFields(field);  if  (fields  !=  null)  {  	if  ( "* ".equals(actualField)  ||   "_all ".equals(actualField))  {  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(avg( "avg ")))  context:  public  class  AvgTests  extends  AbstractNumericTests  {  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(avg( "avg ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(avg( "avg ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(avg( "avg ")))  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  int  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
libgdx_bb5ec2d9cf5bcd9c23c4bdbac1fd651f6725e1a8	buggy:  shader  =  new  ShaderProgram(  app.getGraphics().getGL20(),  vertexShader,  fragmentShader);  context:   "}                            \n ";  String  fragmentShader  =   "precision  mediump  float;\n "  +   "varying  vec4  v_color;\n "  +   "varying  vec2  v_texCoords;\n "  +   "uniform  sampler2D  u_texture;\n "  +   "void  main()                                  \n "  +   "{                                            \n "  +   "  gl_FragColor  =  v_color  *  texture2D(u_texture,  v_texCoords);\n "  +   "} ";  shader  =  new  ShaderProgram(  app.getGraphics().getGL20(),  vertexShader,  fragmentShader);  shader  =  new  ShaderProgram(  app.getGraphics().getGL20(),  vertexShader,  fragmentShader,  true);  if(  shader.isCompiled()  ==  false  )  {  app.log(   "ShaderTest ",  shader.getLog()  );  System.exit(0);  }  mesh  =  new  Mesh(  app.getGraphics(),  true,  true,  false,  3,  3,  new  VertexAttribute(  Usage.Position,  3,   "a_position "  ),  	shader  =  new  ShaderProgram(  app.getGraphics().getGL20(),  vertexShader,  fragmentShader,  true);  
elasticsearch_2372f481aa3763779d7b06d30155eec68c2e9c07	buggy:  translogSnapshot.seekForward(snapshot.lastTranslogPosition());  context:  for  (CommitPoint.FileInfo  fileInfo  :  commitPoint.translogFiles())  {  if  (!commitPointFileExistsInBlobs(fileInfo,  blobs))  {  allTranslogFilesExists  =  false;  break;  }  }  if  (allTranslogFilesExists)  {  translogCommitPointFiles.addAll(commitPoint.translogFiles());  if  (snapshot.sameTranslogNewOperations())  {                          translogSnapshot.seekForward(snapshot.lastTranslogPosition());                          translogSnapshot.seekForward(snapshot.lastTranslogLength());  if  (translogSnapshot.lengthInBytes()  >  0)  {  snapshotRequired  =  true;  expectedNumberOfOperations  =  translogSnapshot.totalOperations()  -  snapshot.lastTotalTranslogOperations();  }  }  }  else  {  if  (translogSnapshot.lengthInBytes()  >  0)  {  	translogSnapshot.seekForward(snapshot.lastTranslogLength());  
elasticsearch_745b8cbefe56c0f68040339095d6327a81d78161	buggy:  sortFields.add(new  SortField(fieldName,  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  context:  if  (reverse)  {  sortFields.add(SORT_DOC_REVERSE);  }  else  {  sortFields.add(SORT_DOC);  }  }  else  {  FieldMapper  fieldMapper  =  context.mapperService().smartNameFieldMapper(fieldName);  if  (fieldMapper  ==  null)  {  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "] ");  }              sortFields.add(new  SortField(fieldName,  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));              sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  }  }  }  	sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  
elasticsearch_15bdba30e5901361a0408d8e8b4068bef66169ec	buggy:  if  (propName.equals( "nullValue "))  {  context:  public  static  class  TypeParser  implements  JsonTypeParser  {  ObjectNode  booleanNode  =  (ObjectNode)  node;  JsonBooleanFieldMapper.Builder  builder  =  booleanField(name);  parseJsonField(builder,  name,  booleanNode,  parserContext);  for  (Iterator<Map.Entry<String,  JsonNode>>  propsIt  =  booleanNode.getFields();  propsIt.hasNext();)  {  Map.Entry<String,  JsonNode>  entry  =  propsIt.next();  String  propName  =  entry.getKey();  JsonNode  propNode  =  entry.getValue();                  if  (propName.equals( "nullValue "))  {                  if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  builder.nullValue(nodeBooleanValue(propNode));  }  }  return  builder;  }  }  private  Boolean  nullValue;  	if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  
libgdx_c9af856df9a4698a44f8f2ed62132f3b00d0f151	buggy:  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  context:  }  public  boolean  removeAll  (LongArray  array)  {  int  size  =  this.size;  int  startSize  =  size;  long[]  items  =  this.items;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  {  long  item  =  array.get(i);  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  for  (int  ii  =  0;  ii  <  size;  ii++)  {  if  (item  ==  items[ii])  {  removeIndex(ii);  size--;  break;  }  }  }  return  size  !=  startSize;  	for  (int  ii  =  0;  ii  <  size;  ii++)  {  
elasticsearch_a26b4f31e10d5457913399d9a9fd51acf081c694	buggy:  logger.warn( "[{}]  failed  to  add  mapping  [{}],  source  [{}] ",  index,  mappingType,  mappingSource);  context:  if  (!mappingSource.equals(existingMapper.mappingSource()))  {  if  (logger.isDebugEnabled())  {  }  mapperService.add(mappingType,  mappingSource);  nodeMappingCreatedAction.nodeMappingCreated(new  NodeMappingCreatedAction.NodeMappingCreatedResponse(index,  mappingType,  event.state().nodes().localNodeId()));  }  }  }  catch  (Exception  e)  {                      logger.warn( "[{}]  failed  to  add  mapping  [{}],  source  [{}] ",  index,  mappingType,  mappingSource);                      logger.warn( "[{}]  failed  to  add  mapping  [{}],  source  [{}] ",  e,  index,  mappingType,  mappingSource);  }  }  }  }  private  void  applyNewOrUpdatedShards(final  ClusterChangedEvent  event)  throws  ElasticSearchException  {  if  (!indicesService.changesAllowed())  return;  	logger.warn( "[{}]  failed  to  add  mapping  [{}],  source  [{}] ",  e,  index,  mappingType,  mappingSource);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(2);  context:  public  class  HotThreadsTest  extends  ElasticsearchIntegrationTest  {  public  void  testHotThreadsDontFail()  throws  ExecutionException,  InterruptedException  {  createIndex( "test ");          final  int  iters  =  atLeast(2);          final  int  iters  =  scaledRandomIntBetween(2,  20);  final  AtomicBoolean  hasErrors  =  new  AtomicBoolean(false);  for  (int  i  =  0;  i  <  iters;  i++)  {  final  String  type;  NodesHotThreadsRequestBuilder  nodesHotThreadsRequestBuilder  =  client().admin().cluster().prepareNodesHotThreads();  if  (randomBoolean())  {  TimeValue  timeValue  =  new  TimeValue(rarely()  ?  randomIntBetween(500,  5000)  :  randomIntBetween(20,  500));  nodesHotThreadsRequestBuilder.setInterval(timeValue);  }  	final  int  iters  =  scaledRandomIntBetween(2,  20);  
libgdx_38e65331c71f092470a2c193adcbf2a75f05251d	buggy:  new  LwjglApplication(new  Metagun(),   "Metagun ",  320,  240,  false);  context:  ++  libgdx_38e65331c71f092470a2c193adcbf2a75f05251d_344.java  package  com.mojang.metagun;  public  class  MetagunDesktop  {  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  Metagun(),   "Metagun ",  320,  240,  false);  new  LwjglApplication(new  Metagun(),   "Metagun ",  320,  240);  }  }  	new  LwjglApplication(new  Metagun(),   "Metagun ",  320,  240);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  fieldTotals  =  new  ObjectLongOpenHashMap<String>();  context:  public  ShardFieldData(ShardId  shardId,  @IndexSettings  Settings  indexSettings,  CircuitBreakerService  breakerService)  {  super(shardId,  indexSettings);  this.breakerService  =  breakerService;  }  public  FieldDataStats  stats(String...  fields)  {  ObjectLongOpenHashMap<String>  fieldTotals  =  null;  if  (fields  !=  null  &&  fields.length  >  0)  {              fieldTotals  =  new  ObjectLongOpenHashMap<String>();              fieldTotals  =  new  ObjectLongOpenHashMap<>();  for  (Map.Entry<String,  CounterMetric>  entry  :  perFieldTotals.entrySet())  {  for  (String  field  :  fields)  {  if  (Regex.simpleMatch(field,  entry.getKey()))  {  fieldTotals.put(entry.getKey(),  entry.getValue().count());  }  }  }  }  	fieldTotals  =  new  ObjectLongOpenHashMap<>();  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");  context:  public  MoreLikeThisFieldQueryBuilder  minimumShouldMatch(String  minimumShouldMatch)  {  this.minimumShouldMatch  =  minimumShouldMatch;  return  this;  }  public  MoreLikeThisFieldQueryBuilder  percentTermsToMatch(float  percentTermsToMatch)  {          return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");          return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  }  public  MoreLikeThisFieldQueryBuilder  minTermFreq(int  minTermFreqy)  {  this.minTermFreq  =  minTermFreqy;  	return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  
libgdx_e2d8370eaf12f29bcf3365ad5e46ed2df382982f	buggy:  if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getCurrentTarget(),  x,  y))  clicked(event,  x,  y);  context:  package  com.badlogic.gdx.scenes.scene2d.utils;  abstract  public  class  ClickListener  extends  PressedListener  {  public  void  touchUp  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getCurrentTarget(),  x,  y))  clicked(event,  x,  y);  if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getListenerActor(),  x,  y))  clicked(event,  x,  y);  super.touchUp(event,  x,  y,  pointer,  button);  }  abstract  public  void  clicked  (ActorEvent  event,  float  x,  float  y);  }  	if  (pointer  ==  0  &&  button  ==  getButton()  &&  isOver(event.getListenerActor(),  x,  y))  clicked(event,  x,  y);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  parentTypes  =  new  HashSet<String>(5);  context:  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  query  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;          Set<String>  parentTypes  =  new  HashSet<String>(5);          Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  if  (parentTypeDocumentMapper  ==  null)  {  	Set<String>  parentTypes  =  new  HashSet<>(5);  
elasticsearch_68de46ff05ed75987997eba1b836d076bc281fed	buggy:  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  context:  public  class  FetchSourceParseElement  implements  SearchParseElement  {  public  void  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  XContentParser.Token  token;  List<String>  includes  =  null,  excludes  =  null;  String  currentFieldName  =  null;  token  =  parser.currentToken();  //  we  get  it  on  the  value          if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {          if  (parser.isBooleanValue())  {  context.fetchSourceContext(new  FetchSourceContext(parser.booleanValue()));  return;  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  context.fetchSourceContext(new  FetchSourceContext(new  String[]{parser.text()}));  return;  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  includes  =  new  ArrayList<String>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  	if  (parser.isBooleanValue())  {  
libgdx_d9063ff99c431fabc8fe570d1f13d288220316ab	buggy:  .getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  context:  return  new  BulletWorld(collisionConfiguration,  dispatcher,  broadphase,  solver,  dynamicsWorld);  }  public  void  create  ()  {  super.create();  world.maxSubSteps  =  20;  world.add( "ground ",  0f,  0f,  0f)  .getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  .setColor(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  final  StillModel  model  =  ModelLoaderRegistry.loadStillModel(Gdx.files.internal( "data/wheel.obj "));  mesh  =  model.subMeshes[0].getMesh().copy(false,  true,  new  int[]  {Usage.Position});  mesh.scale(6f,  6f,  6f);  softBody  =  new  btSoftBody(worldInfo,  mesh.getVerticesBuffer(),  mesh.getNumVertices(),  mesh.getVertexSize(),  mesh.getVertexAttribute(Usage.Position).offset,  mesh.getIndicesBuffer(),  mesh.getNumIndices()/3);  	.setColor(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<DisplayHeader>  display  =  new  ArrayList<DisplayHeader>();  context:  out.append( "   ");  }  out.append( "\n ");  }  return  new  StringRestResponse(RestStatus.OK,  out.toString());  }  private  static  List<DisplayHeader>  buildDisplayHeaders(Table  table,  RestRequest  request)  {  String  pHeaders  =  request.param( "h ");          List<DisplayHeader>  display  =  new  ArrayList<DisplayHeader>();          List<DisplayHeader>  display  =  new  ArrayList<>();  if  (pHeaders  !=  null)  {  for  (String  possibility  :  Strings.splitStringByCommaToArray(pHeaders))  {  DisplayHeader  dispHeader  =  null;  if  (table.getAsMap().containsKey(possibility))  {  dispHeader  =  new  DisplayHeader(possibility,  possibility);  }  else  {  for  (Table.Cell  headerCell  :  table.getHeaders())  {  	List<DisplayHeader>  display  =  new  ArrayList<>();  
elasticsearch_1d8b5458545c5de5bf2fc165da346107440d1f88	buggy:  if  (state.metaData().aliases().contains(request.index))  {  context:  }  if  (!request.index.equals(riverIndexName)  &&  !request.index.equals(PercolatorService.INDEX_NAME)  &&  request.index.charAt(0)  ==  '_')  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  not  start  with  '_' ");  }  if  (!request.index.toLowerCase().equals(request.index))  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  be  lowercase ");  }  if  (!Strings.validFileName(request.index))  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  not  contain  the  following  characters   "  +  Strings.INVALID_FILENAME_CHARS);  }          if  (state.metaData().aliases().contains(request.index))  {          if  (state.metaData().aliases().containsKey(request.index))  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "an  alias  with  the  same  name  already  exists ");  }  }  public  static  interface  Listener  {  void  onResponse(Response  response);  	if  (state.metaData().aliases().containsKey(request.index))  {  
elasticsearch_70c089de0adc866326a6804c556c2c91647a3860	buggy:  StringBuffer  sb  =  new  StringBuffer();  context:  throw  new  Exception( "failed  test,  count  does  not  match... ");  }  }  int  numberOfBulks  =  numberOfDocsPerRound  /  bulkSize;  for  (int  b  =  0;  b  <  numberOfBulks;  b++)  {  BulkRequestBuilder  bulk  =  client.client().prepareBulk();  for  (int  k  =  0;  k  <  bulkSize;  k++)  {                      StringBuffer  sb  =  new  StringBuffer();                      StringBuilder  sb  =  new  StringBuilder();  XContentBuilder  json  =  XContentFactory.jsonBuilder().startObject()  .field( "field ",   "value "  +  ThreadLocalRandom.current().nextInt());  int  fields  =  ThreadLocalRandom.current().nextInt()  %  numberOfFields;  for  (int  i  =  0;  i  <  fields;  i++)  {  json.field( "num_ "  +  i,  ThreadLocalRandom.current().nextDouble());  int  tokens  =  ThreadLocalRandom.current().nextInt()  %  textTokens;  sb.setLength(0);  	StringBuilder  sb  =  new  StringBuilder();  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  }  if  (value  instanceof  BytesRef)  {  return  Numbers.bytesToInt((BytesRef)  value);  }  return  Integer.parseInt(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  int  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).intValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  
libgdx_00f729f162a35591f669ffc8c42dc108dcc0753b	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.MatrixJNITest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.MatrixJNITest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_709ff47a136b8cc1a7e178b77e3afbf5939a6b5d	buggy:  return  listener.pan(tracker.lastX,  tracker.lastY,  tracker.deltaX,  tracker.deltaY);  context:  if  (inTapSquare  &&  (Math.abs(x  -  tapSquareCenterX)  >=  tapSquareSize  ||  Math.abs(y  -  tapSquareCenterY)  >=  tapSquareSize))  {  longPressTask.cancel();  inTapSquare  =  false;  }  if  (!inTapSquare)  {  inTapSquare  =  false;  panning  =  true;  return  listener.pan(tracker.lastX,  tracker.lastY,  tracker.deltaX,  tracker.deltaY);  return  listener.pan(x,  y,  tracker.deltaX,  tracker.deltaY);  }  return  false;  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer,  int  button)  {  return  touchUp((float)x,  (float)y,  pointer,  button);  	return  listener.pan(x,  y,  tracker.deltaX,  tracker.deltaY);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  foundAny  =  true;  }  builder.endObject();  }  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  foundAny  ||  indices.length  ==  0  ?  OK  :  NOT_FOUND,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  GL10  gl  =  Gdx.graphics.getGL10();  context:  idxNors  +=  3;  idxTexCoords  +=  2;  }  public  void  end  ()  {  if  (idxPos  ==  0)  return;  GL10  gl  =  Gdx.graphics.getGL10();  GL10  gl  =  Gdx.gl10;  gl.glEnableClientState(GL10.GL_VERTEX_ARRAY);  positionsBuffer.clear();  positionsBuffer.put(positions,  0,  idxPos);  positionsBuffer.flip();  gl.glVertexPointer(3,  GL10.GL_FLOAT,  0,  positionsBuffer);  if  (colorsDefined)  {  gl.glEnableClientState(GL10.GL_COLOR_ARRAY);  	GL10  gl  =  Gdx.gl10;  
elasticsearch_4631df9d0111f20116a8f2d631ca67f368d33d33	buggy:  add(new  DeleteRequest(index,  type,  id).routing(routing));  context:  opType  =  parser.text();  }  else  if  ( "_version ".equals(currentFieldName))  {  version  =  parser.longValue();  }  else  if  ( "percolate ".equals(currentFieldName))  {  percolate  =  parser.textOrNull();  }  }  }  if  ( "delete ".equals(action))  {                  add(new  DeleteRequest(index,  type,  id).routing(routing));                  add(new  DeleteRequest(index,  type,  id).parent(parent).routing(routing));  }  else  {  nextMarker  =  findNextMarker(marker,  from,  data,  length);  if  (nextMarker  ==  -1)  {  break;  }  if  ( "index ".equals(action))  {  if  (opType  ==  null)  {  	add(new  DeleteRequest(index,  type,  id).parent(parent).routing(routing));  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  currentDoc  =  currentChildPointer++;  }  return  currentDoc;  }  public  float  score()  throws  IOException  {  return  parentScorer.score();  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  parentScorer.freq();  }  public  int  docID()  {  return  currentDoc;  }  }  	public  int  freq()  throws  IOException  {  
elasticsearch_9eaa50ce62215990275ade77a164190aa6341e7a	buggy:  boolean  escape  =  true;  context:  String  queryString  =  null;  String  defaultField  =  null;  MapperQueryParser.Operator  defaultOperator  =  QueryParser.Operator.OR;  boolean  allowLeadingWildcard  =  true;  boolean  lowercaseExpandedTerms  =  true;  boolean  enablePositionIncrements  =  true;  float  fuzzyMinSim  =  FuzzyQuery.defaultMinSimilarity;  int  fuzzyPrefixLength  =  FuzzyQuery.defaultPrefixLength;  int  phraseSlop  =  0;  float  boost  =  1.0f;          boolean  escape  =  true;          boolean  escape  =  false;  Analyzer  analyzer  =  null;  String  currentFieldName  =  null;  JsonToken  token;  while  ((token  =  jp.nextToken())  !=  JsonToken.END_OBJECT)  {  if  (token  ==  JsonToken.FIELD_NAME)  {  currentFieldName  =  jp.getCurrentName();  }  else  if  (token  ==  JsonToken.VALUE_STRING)  {  	boolean  escape  =  false;  
elasticsearch_c3cb5a3e349e36d4cd0f948331253032051a623a	buggy:  String  nodeId  =  UUID.randomUUID().toString();  context:  this.nodesFD.addListener(new  NodeFailureListener());  this.publishClusterState  =  new  PublishClusterStateAction(settings,  transportService,  this,  new  NewClusterStateListener());  this.pingService.setNodesProvider(this);  this.membership  =  new  MembershipAction(settings,  transportService,  this,  new  MembershipListener());  }  Map<String,  String>  nodeAttributes  =  buildCommonNodesAttributes(settings);          String  nodeId  =  UUID.randomUUID().toString();          String  nodeId  =  UUID.randomBase64UUID();  localNode  =  new  DiscoveryNode(settings.get( "name "),  nodeId,  transportService.boundAddress().publishAddress(),  nodeAttributes);  latestDiscoNodes  =  new  DiscoveryNodes.Builder().put(localNode).localNodeId(localNode.id()).build();  nodesFD.updateNodes(latestDiscoNodes);  pingService.start();  threadPool.cached().execute(new  Runnable()  {  	String  nodeId  =  UUID.randomBase64UUID();  
elasticsearch_fef647cb92926c97107f506831bfbdc0b838e80c	buggy:  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable())  context:  blocks.addIndexBlock(request.index,  block);  }  }  if  (request.state  ==  State.CLOSE)  {  blocks.addIndexBlock(request.index,  MetaDataIndexStateService.INDEX_CLOSED_BLOCK);  }  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState).blocks(blocks).metaData(newMetaData).build();  if  (request.state  ==  State.OPEN)  {                          RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable())                          RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(updatedState.routingTable())  .addAsNew(updatedState.metaData().index(request.index));  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());  updatedState  =  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  }  final  AtomicInteger  counter  =  new  AtomicInteger(currentState.nodes().size());  	RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(updatedState.routingTable())  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  .indexShards(clusterService.state(),  request.index(),  request.type,  request.id,  null);  context:  return  TransportActions.Admin.Cluster.Ping.SINGLE;  }  return   "/cluster/ping/single/shard ";  }  return  clusterService.operationRouting()                  .indexShards(clusterService.state(),  request.index(),  request.type,  request.id,  null);                  .getShards(clusterService.state(),  request.index(),  request.type,  request.id,  null,  null);  }  return  new  SinglePingResponse();  }  return  new  SinglePingRequest();  	.getShards(clusterService.state(),  request.index(),  request.type,  request.id,  null,  null);  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  metaBuilder.put(IndexMetaData.builder( "INDEX_ "  +  i).numberOfShards(numShards).numberOfReplicas(replicas));  }  MetaData  metaData  =  metaBuilder.build();  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder();  for  (int  i  =  0;  i  <  indices;  i++)  {  routingTableBuilder.addAsNew(metaData.index( "INDEX_ "  +  i));  }  RoutingTable  routingTable  =  routingTableBuilder.build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  int  numIters  =  scaledRandomIntBetween(10,  30);  int  nodeIdCounter  =  0;  int  atMostNodes  =  between(Math.max(1,  maxNumReplicas),  numIters);  final  boolean  frequentNodes  =  randomBoolean();  for  (int  i  =  0;  i  <  numIters;  i++)  {  ClusterState.Builder  stateBuilder  =  ClusterState.builder(clusterState);  DiscoveryNodes.Builder  newNodesBuilder  =  DiscoveryNodes.builder(clusterState.nodes());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_123b21f4ae2034b2fb42aae335ce8d7010a55c11	buggy:  builder.field( "text ",  text);  context:  public  TextQueryBuilder  maxExpansions(int  maxExpansions)  {  this.maxExpansions  =  maxExpansions;  return  this;  }  builder.startObject(TextQueryParser.NAME);  builder.startObject(name);          builder.field( "text ",  text);          builder.field( "query ",  text);  if  (type  !=  null)  {  builder.field( "type ",  type.toString().toLowerCase());  }  if  (operator  !=  null)  {  builder.field( "operator ",  operator.toString());  }  if  (analyzer  !=  null)  {  builder.field( "analyzer ",  analyzer);  	builder.field( "query ",  text);  
elasticsearch_da953700f47924f4948ec3775eb1f42f3109aac7	buggy:  terms.trimExcessEntries();  context:  public  Type  type()  {  return  TYPE;  }  public  InternalTerms  reduce(ReduceContext  reduceContext)  {  List<InternalAggregation>  aggregations  =  reduceContext.aggregations();  if  (aggregations.size()  ==  1)  {  InternalTerms  terms  =  (InternalTerms)  aggregations.get(0);              terms.trimExcessEntries();              terms.trimExcessEntries(reduceContext.cacheRecycler());  return  terms;  }  InternalTerms  reduced  =  null;  Recycler.V<LongObjectOpenHashMap<List<Bucket>>>  buckets  =  null;  for  (InternalAggregation  aggregation  :  aggregations)  {  InternalTerms  terms  =  (InternalTerms)  aggregation;  if  (terms  instanceof  UnmappedTerms)  {  	terms.trimExcessEntries(reduceContext.cacheRecycler());  
elasticsearch_ee5221bd220b5e23d77a02d217909c4b527b860f	buggy:  XContentBuilder  updateMappingBuilder  =  jsonBuilder().startObject().startObject( "_timestamp ").field( "enabled ",  false).endObject().endObject();  context:  String  index  =   "foo ";  String  type  =   "mytype ";  XContentBuilder  builder  =  jsonBuilder().startObject().startObject( "_timestamp ").field( "enabled ",  true).field( "store ",  true).endObject().endObject();  assertAcked(client().admin().indices().prepareCreate(index).addMapping(type,  builder));  assertTimestampMappingEnabled(index,  type,  true);          XContentBuilder  updateMappingBuilder  =  jsonBuilder().startObject().startObject( "_timestamp ").field( "enabled ",  false).endObject().endObject();          XContentBuilder  updateMappingBuilder  =  jsonBuilder().startObject().startObject( "_timestamp ").field( "enabled ",  false).field( "store ",  true).endObject().endObject();  PutMappingResponse  putMappingResponse  =  client().admin().indices().preparePutMapping(index).setType(type).setSource(updateMappingBuilder).get();  assertAcked(putMappingResponse);  assertTimestampMappingEnabled(index,  type,  false);  }  private  void  assertTimestampMappingEnabled(String  index,  String  type,  boolean  enabled)  {  	XContentBuilder  updateMappingBuilder  =  jsonBuilder().startObject().startObject( "_timestamp ").field( "enabled ",  false).field( "store ",  true).endObject().endObject();  
libgdx_80be7e7c75693536b6fb9a8f2ae071b70be5f421	buggy:  return  new  GwtFileHandle(preloader,  file  +  (file.endsWith( "/ ")  ?   " "  :   "/ ")  +  name,  FileType.Internal);  context:  public  boolean  isDirectory  ()  {  return  preloader.isDirectory(file);  }  public  FileHandle  child  (String  name)  {  return  new  GwtFileHandle(preloader,  file  +  (file.endsWith( "/ ")  ?   " "  :   "/ ")  +  name,  FileType.Internal);  return  new  GwtFileHandle(preloader,  file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ "))  +  name,  FileType.Internal);  }  public  FileHandle  parent  ()  {  int  index  =  file.lastIndexOf( "/ ");  String  dir  =   " ";  if  (index  >  0)  dir  =  file.substring(0,  index  +  1);  return  new  GwtFileHandle(preloader,  dir,  type);  }  	return  new  GwtFileHandle(preloader,  file.isEmpty()  ?   " "  :  (file  +  (file.endsWith( "/ ")  ?   " "  :   "/ "))  +  name,  FileType.Internal);  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  controller.registerHandler(POST,   "/{index}/_gateway/snapshot ",  this);  }  GatewaySnapshotRequest  gatewaySnapshotRequest  =  new  GatewaySnapshotRequest(RestActions.splitIndices(request.param( "index ")));  gatewaySnapshotRequest.timeout(request.paramAsTime( "timeout ",  DEFAULT_TIMEOUT));  gatewaySnapshotRequest.listenerThreaded(false);  client.admin().indices().execGatewaySnapshot(gatewaySnapshotRequest,  new  ActionListener<GatewaySnapshotResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  builder.startObject( "indices ");  for  (IndexGatewaySnapshotResponse  indexResponse  :  result.indices().values())  {  builder.startObject(indexResponse.index())  .field( "ok ",  true)  .field( "totalShards ",  indexResponse.totalShards())  .field( "successfulShards ",  indexResponse.successfulShards())  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "  +  i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i  *  2)  .field( "ip ",   "10.0.0.5 ")  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(ipRange( "ip_range ").field( "ip ").addRange( "r1 ",   "10.0.0.1 ",   "10.0.0.10 ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  bulkRequest.add(new  DeleteRequest().index(shardToPurge.routingEntry().index()).type(docToPurge.type).id(docToPurge.id).version(docToPurge.version).routing(docToPurge.routing));  context:  for  (IndexShard  shardToPurge  :  shardsToPurge)  {  Query  query  =  NumericRangeQuery.newLongRange(TTLFieldMapper.NAME,  null,  System.currentTimeMillis(),  false,  true);  Engine.Searcher  searcher  =  shardToPurge.searcher();  try  {  ExpiredDocsCollector  expiredDocsCollector  =  new  ExpiredDocsCollector(shardToPurge.routingEntry().index());  searcher.searcher().search(query,  expiredDocsCollector);  List<DocToPurge>  docsToPurge  =  expiredDocsCollector.getDocsToPurge();  BulkRequestBuilder  bulkRequest  =  client.prepareBulk();  for  (DocToPurge  docToPurge  :  docsToPurge)  {                      bulkRequest.add(new  DeleteRequest().index(shardToPurge.routingEntry().index()).type(docToPurge.type).id(docToPurge.id).version(docToPurge.version).routing(docToPurge.routing));                      bulkRequest.add(new  DeleteRequest().setIndex(shardToPurge.routingEntry().index()).setType(docToPurge.type).setId(docToPurge.id).setVersion(docToPurge.version).setRouting(docToPurge.routing));  bulkRequest  =  processBulkIfNeeded(bulkRequest,  false);  }  processBulkIfNeeded(bulkRequest,  true);  }  catch  (Exception  e)  {  }  finally  {  searcher.release();  }  	bulkRequest.add(new  DeleteRequest().setIndex(shardToPurge.routingEntry().index()).setType(docToPurge.type).setId(docToPurge.id).setVersion(docToPurge.version).setRouting(docToPurge.routing));  
elasticsearch_2f835621aeb69f108a0beeb7be780760c40e3bb8	buggy:  client().admin().cluster().prepareHealth( "idx_unmapped ").setWaitForYellowStatus().execute().actionGet();  context:  assertThat(bucket,  notNullValue());  assertThat(bucket.getKey(),  equalTo(key));  assertThat(bucket.getDocCount(),  equalTo(3l));  max  =  bucket.getAggregations().get( "max ");  assertThat(max,  notNullValue());  assertThat((long)  max.getValue(),  equalTo(new  DateTime(2012,  4,  24,  0,  0,  DateTimeZone.UTC).getMillis()));  }  public  void  unmapped()  throws  Exception  {          client().admin().cluster().prepareHealth( "idx_unmapped ").setWaitForYellowStatus().execute().actionGet();          client().admin().cluster().prepareHealth( "idx_unmapped ").setWaitForGreenStatus().execute().actionGet();  SearchResponse  response  =  client().prepareSearch( "idx_unmapped ")  .addAggregation(dateHistogram( "histo ").field( "date ").interval(DateHistogram.Interval.MONTH))  .execute().actionGet();  assertThat(response.getFailedShards(),  equalTo(0));  DateHistogram  histo  =  response.getAggregations().get( "histo ");  	client().admin().cluster().prepareHealth( "idx_unmapped ").setWaitForGreenStatus().execute().actionGet();  
libgdx_cb553906a6e25ef0073f29ba1bad66a1cca01cb1	buggy:  Table  table  =  new  Table( "container ");  context:  projector.update();  }  public  void  setupUI  ()  {  ui  =  new  Stage(480,  320,  true);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  Button  reload  =  new  Button( "Reload  Shaders ",  skin.getStyle(ButtonStyle.class),   "reload ");  ComboBox  camera  =  new  ComboBox(new  String[]  { "Camera ",   "Light "},  ui,  skin.getStyle(ComboBoxStyle.class),   "camera ");  Label  fps  =  new  Label( "fps:   ",  skin.getStyle(LabelStyle.class),   "fps ");  Table  table  =  new  Table( "container ");  Table  table  =  new  Table();  table.width  =  ui.width();  table.height  =  ui.height();  table.top().padTop(15);  table.add(reload).spaceRight(5);  table.add(camera).spaceRight(5);  table.add(fps);  ui.addActor(table);  	Table  table  =  new  Table();  
libgdx_34f318992d8f07056290ec419aeb4c11f6022875	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_388fddb3d959eb642499892bf680032447ebc070	buggy:  addUrl(urls,   "https://github.com/ "  +  user  +   "/ "  +  repo  +   "/archive/v "  +  version  +   ".zip ");  context:  List<URL>  urls()  {  List<URL>  urls  =  new  ArrayList<>();  if  (version  !=  null)  {  addUrl(urls,   "http://download.elasticsearch.org/ "  +  user  +   "/ "  +  repo  +   "/ "  +  repo  +   "- "  +  version  +   ".zip ");  addUrl(urls,   "http://search.maven.org/remotecontent?filepath= "  +  user.replace('.',  '/')  +   "/ "  +  repo  +   "/ "  +  version  +   "/ "  +  repo  +   "- "  +  version  +   ".zip ");  addUrl(urls,   "https://oss.sonatype.org/service/local/repositories/releases/content/ "  +  user.replace('.',  '/')  +   "/ "  +  repo  +   "/ "  +  version  +   "/ "  +  repo  +   "- "  +  version  +   ".zip ");                  addUrl(urls,   "https://github.com/ "  +  user  +   "/ "  +  repo  +   "/archive/v "  +  version  +   ".zip ");                  addUrl(urls,   "https://github.com/ "  +  user  +   "/ "  +  repo  +   "/archive/ "  +  version  +   ".zip ");  }  addUrl(urls,   "https://github.com/ "  +  user  +   "/ "  +  repo  +   "/archive/master.zip ");  return  urls;  }  private  static  void  addUrl(List<URL>  urls,  String  url)  {  try  {  	addUrl(urls,   "https://github.com/ "  +  user  +   "/ "  +  repo  +   "/archive/ "  +  version  +   ".zip ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  ArrayList<MutableShardRouting>(shards);  context:  sb.append( "-------- ").append(entry.shortSummary()).append('\n');  }  return  sb.toString();  }  public  MutableShardRouting  get(int  i)  {  return  shards.get(i)  ;  }  public  Collection<MutableShardRouting>  copyShards()  {          return  new  ArrayList<MutableShardRouting>(shards);          return  new  ArrayList<>(shards);  }  public  boolean  isEmpty()  {  return  shards.isEmpty();  }  }  	return  new  ArrayList<>(shards);  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  valueScript.setNextReader(context.reader());  context:  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  valueScript.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (NumericFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);          valueScript.setNextReader(context.reader());          valueScript.setNextReader(context);  }  public  Facet  facet()  {  return  new  InternalFullHistogramFacet(facetName,  comparatorType,  histoProc.entries,  true);  }  public  static  long  bucket(double  value,  long  interval)  {  	valueScript.setNextReader(context);  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  temp.mul(getInterpolation().apply(Math.min(1,  timer  /  1f)));  context:  renderer.rect(current.x,  current.y,  20,  20);  renderer.end();  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  }  Vector2  getCurrentPosition  ()  {  temp.set(targetPosition);  temp.sub(position);  temp.mul(getInterpolation().apply(Math.min(1,  timer  /  1f)));  temp.scl(getInterpolation().apply(Math.min(1,  timer  /  1f)));  temp.add(position);  return  temp;  }  private  Interpolation  getInterpolation  ()  {  try  {  return  (Interpolation)Interpolation.class.getField(list.getSelection()).get(null);  }  catch  (Exception  ex)  {  	temp.scl(getInterpolation().apply(Math.min(1,  timer  /  1f)));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  types  =  new  String[size];  for  (int  i  =  0;  i  <  size;  i++)  {  types[i]  =  in.readUTF();  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  if  (routing  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  out.writeUTF(routing);  }  	out.writeBytesReference(querySource);  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  if  ( "interval ".equals(currentFieldName))  {  interval  =  parser.longValue();  }  else  if  ( "min_doc_count ".equals(currentFieldName)  ||   "minDocCount ".equals(currentFieldName))  {  minDocCount  =  parser.longValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  aggregation  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "keyed ".equals(currentFieldName))  {  keyed  =  parser.booleanValue();                  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {                  }  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  aggregation  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  else  if  ( "order ".equals(currentFieldName))  {  	}  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
elasticsearch_bf071222ed161410722b79f8cdf623c53ea3daf6	buggy:  if  (terms.size()  >  maxExpansions)  {  context:  try  {  do  {  Term  term  =  enumerator.term();  if  (term  !=  null  &&  term.text().startsWith(prefix.text())  &&  term.field().equals(field))  {  terms.add(term);  }  else  {  break;  }                  if  (terms.size()  >  maxExpansions)  {                  if  (terms.size()  >=  maxExpansions)  {  break;  }  }  while  (enumerator.next());  }  finally  {  enumerator.close();  }  }  	if  (terms.size()  >=  maxExpansions)  {  
libgdx_43ac8a91cf08bb5a3e71b94fbd7f410fae4d7743	buggy:  writer.write(header  +   "\n "  +  content);  context:  setRecursive(true);  }  protected  void  processFile  (Entry  inputFile)  throws  Exception  {  String  content  =  new  FileHandle(inputFile.inputFile).readString();  content  =  content.trim();  if  (content.startsWith( "package "))  {  BufferedWriter  writer  =  new  BufferedWriter(new  OutputStreamWriter(new  FileHandle(inputFile.outputFile).write(false)));  writer.write(header  +   "\n "  +  content);  writer.write(header  +   "\n\n "  +  content);  writer.close();  }  }  protected  void  processDir  (Entry  inputDir,  ArrayList<Entry>  value)  throws  Exception  {  }  }  	writer.write(header  +   "\n\n "  +  content);  
elasticsearch_78e73259a08d10fb6b95e7707c8573ff698c921a	buggy:  String  builtMapping  =  docMapper.toJson();  context:  doc  =  docMapper.parse(json).doc();  }  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/json/simple/test-mapping.json ");  JsonDocumentMapper  docMapper  =  (JsonDocumentMapper)  new  JsonDocumentMapperParser(new  AnalysisService(new  Index( "test "))).parse(mapping);          String  builtMapping  =  docMapper.toJson();          String  builtMapping  =  docMapper.buildSource();  JsonDocumentMapper  builtDocMapper  =  (JsonDocumentMapper)  new  JsonDocumentMapperParser(new  AnalysisService(new  Index( "test "))).parse(builtMapping);  String  json  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/json/simple/test1.json ");  Document  doc  =  builtDocMapper.parse(json).doc();  assertThat(doc.get(docMapper.uidMapper().names().indexName()),  equalTo(Uid.createUid( "person ",   "1 ")));  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().names().indexName()),  equalTo( "shay "));  	String  builtMapping  =  docMapper.buildSource();  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(byte  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  ByteFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  ByteFieldMapper  fieldMapper  =  new  ByteFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
libgdx_4ee959bea723f2964d533e3a5c4b93ee55ee47fe	buggy:  diffuse  =  new  Texture(Gdx.files.internal( "data/world_blobbie_blocks_512.png "),  true);  context:  model[0]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/test_section_01.dae.g3d "));  lightMaps[0]  =  new  Texture(Gdx.files.internal( "data/world_blobbie_lm_01.jpg "),  true);  model[1]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/test_section_02.dae.g3d "));  lightMaps[1]  =  new  Texture(Gdx.files.internal( "data/world_blobbie_lm_02.jpg "),  true);  model[2]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/test_section_03.dae.g3d "));  lightMaps[2]  =  new  Texture(Gdx.files.internal( "data/world_blobbie_lm_03.jpg "),  true);  model[3]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/test_section_04.dae.g3d "));  lightMaps[3]  =  new  Texture(Gdx.files.internal( "data/world_blobbie_lm_04.jpg "),  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/world_blobbie_blocks_512.png "),  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/world_blobbie_blocks.png "),  true);  cam  =  new  PerspectiveCamera(60,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(30,  10,  85f);  cam.direction.set(0,0,-1);  cam.up.set(0,1,0);  cam.near  =  0.1f;  	diffuse  =  new  Texture(Gdx.files.internal( "data/world_blobbie_blocks.png "),  true);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  searcher.release();  context:  Fields  termVectorsByField  =  docIdAndVersion.context.reader().getTermVectors(docIdAndVersion.docId);  termVectorResponse.setFields(termVectorsByField,  request.selectedFields(),  request.getFlags(),  topLevelFields);  termVectorResponse.setExists(true);  termVectorResponse.setDocVersion(docIdAndVersion.version);  }  else  {  termVectorResponse.setExists(false);  }  }  catch  (Throwable  ex)  {  throw  new  ElasticsearchException( "failed  to  execute  term  vector  request ",  ex);  }  finally  {              searcher.release();              searcher.close();  }  return  termVectorResponse;  }  }  	searcher.close();  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  IndexService  indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  currentState.nodes().localNode().id());  context:  throw  new  IndexMissingException(new  Index(index));  }  }  for  (String  index  :  request.indices)  {  if  (indicesService.hasIndex(index))  {  continue;  }  final  IndexMetaData  indexMetaData  =  currentState.metaData().index(index);                          IndexService  indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  currentState.nodes().localNode().id());                          IndexService  indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  clusterService.localNode().id());  indicesToClose.add(indexMetaData.index());  if  (indexMetaData.mappings().containsKey(request.mappingType))  {  indexService.mapperService().merge(request.mappingType,  indexMetaData.mappings().get(request.mappingType).source().string(),  false);  }  }  Map<String,  DocumentMapper>  newMappers  =  newHashMap();  	IndexService  indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  clusterService.localNode().id());  
elasticsearch_a3978402e577410137db27d8476598e0410a7bbe	buggy:  SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.nowInMillis(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  indexShard,  scriptService);  context:  return  context;  }  private  SearchContext  createContext(InternalSearchRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());  Engine.Searcher  engineSearcher  =  indexShard.searcher();          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.nowInMillis(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  indexShard,  scriptService);          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService);  SearchContext.setCurrent(context);  try  {  context.scroll(request.scroll());  parseSource(context,  request.source(),  request.sourceOffset(),  request.sourceLength());  parseSource(context,  request.extraSource(),  request.extraSourceOffset(),  request.extraSourceLength());  	SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalTermsStatsDoubleFacet.DoubleEntry>  doubleEntries  =  new  ArrayList<InternalTermsStatsDoubleFacet.DoubleEntry>(entries.v().size());  context:  }  public  InternalFacet  buildFacet(String  facetName)  {  if  (entries.v().isEmpty())  {  entries.release();  return  new  InternalTermsStatsDoubleFacet(facetName,  comparatorType,  size,  ImmutableList.<InternalTermsStatsDoubleFacet.DoubleEntry>of(),  missing);  }  if  (size  ==  0)  {  //  all  terms              List<InternalTermsStatsDoubleFacet.DoubleEntry>  doubleEntries  =  new  ArrayList<InternalTermsStatsDoubleFacet.DoubleEntry>(entries.v().size());              List<InternalTermsStatsDoubleFacet.DoubleEntry>  doubleEntries  =  new  ArrayList<>(entries.v().size());  boolean[]  states  =  entries.v().allocated;  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  doubleEntries.add((InternalTermsStatsDoubleFacet.DoubleEntry)  values[i]);  }  }  entries.release();  	List<InternalTermsStatsDoubleFacet.DoubleEntry>  doubleEntries  =  new  ArrayList<>(entries.v().size());  
elasticsearch_ed996c3e850b047d52e36e7e865e3f39ccfd7ab6	buggy:  String[]  indices  =  currentState.metaData().concreteIndices(request.filteredIndices(),  true);  context:  if  (!request.filterBlocks())  {  builder.blocks(currentState.blocks());  }  if  (!request.filterMetaData())  {  MetaData.Builder  mdBuilder  =  newMetaDataBuilder();  if  (request.filteredIndices().length  ==  0  &&  request.filteredIndexTemplates().length  ==  0)  {  mdBuilder.metaData(currentState.metaData());  }  if  (request.filteredIndices().length  >  0)  {                  String[]  indices  =  currentState.metaData().concreteIndices(request.filteredIndices(),  true);                  String[]  indices  =  currentState.metaData().concreteIndicesIgnoreMissing(request.filteredIndices());  for  (String  filteredIndex  :  indices)  {  IndexMetaData  indexMetaData  =  currentState.metaData().index(filteredIndex);  if  (indexMetaData  !=  null)  {  mdBuilder.put(indexMetaData);  }  }  }  	String[]  indices  =  currentState.metaData().concreteIndicesIgnoreMissing(request.filteredIndices());  
libgdx_4dabe51de177f458dc40b3bff5449a07ea59973f	buggy:  CGPoint  loc  =  touch.getLocation(touch.getView());  context:  public  static  native  @MachineSizedUInt  long  count  (@Pointer  long  thiz);  }  private  void  toTouchEvents  (long  touches,  UIEvent  uiEvent)  {  long  array  =  NSSetExtensions.allObjects(touches);  int  length  =  (int)NSArrayExtensions.count(array);  for  (int  i  =  0;  i  <  length;  i++)  {  long  touchHandle  =  NSArrayExtensions.objectAtIndex$(array,  i);  UITouch  touch  =  UI_TOUCH_WRAPPER.wrap(touchHandle);  CGPoint  loc  =  touch.getLocation(touch.getView());  CGPoint  loc  =  touch.getLocationInView(touch.getView());  synchronized  (touchEvents)  {  UITouchPhase  phase  =  touch.getPhase();  TouchEvent  event  =  touchEventPool.obtain();  event.x  =  (int)(loc.x()  *  app.displayScaleFactor);  event.y  =  (int)(loc.y()  *  app.displayScaleFactor);  event.phase  =  phase;  event.timestamp  =  (long)(touch.getTimestamp()  *  1000000000);  touchEvents.add(event);  	CGPoint  loc  =  touch.getLocationInView(touch.getView());  
libgdx_fc4382fdc46e18cf64a63c59faff03967a57f4ba	buggy:  String  command  =  ant  +   "  -f   "  +  build.file().getAbsolutePath()  +   "   "  +  params;  context:  public  class  BuildExecutor  {  public  static  boolean  executeAnt  (String  buildFile,  String  params)  {  FileDescriptor  build  =  new  FileDescriptor(buildFile);  String  ant  =  System.getProperty( "os.name ").contains( "Windows ")  ?   "ant.bat "  :   "ant ";  String  command  =  ant  +   "  -f   "  +  build.file().getAbsolutePath()  +   "   "  +  params;  String  command  =  ant  +   "  -f  \ " "  +  build.file().getAbsolutePath()  +   "\ "   "  +  params;  return  startProcess(command,  build.parent().file());  }  public  static  void  executeNdk  (String  directory)  {  FileDescriptor  build  =  new  FileDescriptor(directory);  	String  command  =  ant  +   "  -f  \ " "  +  build.file().getAbsolutePath()  +   "\ "   "  +  params;  
elasticsearch_3f6ed7e1def9b0a3e5d4119f7e11457cb1c8c8f2	buggy:  }  catch  (IOException  e)  {  context:  return  new  MappingUpdatedRequest();  }  return  new  MappingUpdatedResponse();  }  try  {  metaDataMappingService.updateMapping(request.index(),  request.type(),  request.mappingSource());          }  catch  (IOException  e)  {          }  catch  (Exception  e)  {  throw  new  ElasticSearchParseException( "failed  to  parse  mapping  form  compressed  string ",  e);  }  return  new  MappingUpdatedResponse();  }  public  static  class  MappingUpdatedResponse  implements  ActionResponse  {  }  	}  catch  (Exception  e)  {  
elasticsearch_4ff3e1926b0b0a092a9fcb70f47fb49977ec2d70	buggy:  return  ScriptDocValues.EMPTY;  context:  return  0;  }  public  BytesValues  getBytesValues(boolean  needsHashes)  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {              return  ScriptDocValues.EMPTY;              return  ScriptDocValues.EMPTY_DOUBLES;  }  }  public  static  class  WithOrdinals  extends  FloatArrayAtomicFieldData  {  private  final  Ordinals  ordinals;  private  final  BigFloatArrayList  values;  	return  ScriptDocValues.EMPTY_DOUBLES;  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  termsIndex  =  indexFieldData.load(context).getBytesValues();  context:  }  else  {  ord  =  ((-2  -  docOrd)  <<  2)  +  2;  }  assert  (ord  &  1)  ==  0;  return  ord;  }  public  FieldComparator<BytesRef>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          termsIndex  =  indexFieldData.load(context).getBytesValues();          termsIndex  =  indexFieldData.load(context).getBytesValues(false);  assert  termsIndex.ordinals()  !=  null  &&  termsIndex.ordinals().ordinals()  !=  null;  if  (missingValue  ==  null)  {  missingOrd  =  Ordinals.MISSING_ORDINAL;  }  else  {  missingOrd  =  ordInCurrentReader(termsIndex,  missingValue);  assert  consistentInsertedOrd(termsIndex,  missingOrd,  missingValue);  }  FieldComparator<BytesRef>  perSegComp  =  null;  	termsIndex  =  indexFieldData.load(context).getBytesValues(false);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  public  BytesValues  getBytesValues(boolean  needsHashes)  {  context:  public  long  getNumberUniqueValues()  {  return  0;  }  public  long  getMemorySizeInBytes()  {  return  0;  }          public  BytesValues  getBytesValues(boolean  needsHashes)  {          public  BytesValues  getBytesValues()  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {  return  ScriptDocValues.EMPTY_DOUBLES;  }  }  	public  BytesValues  getBytesValues()  {  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  snapshotStatus.index().totalSize(),  snapshotStatus.translog().currentTranslogOperations());  context:  stage  =  GatewaySnapshotStatus.Stage.FINALIZE;  break;  case  INDEX:  stage  =  GatewaySnapshotStatus.Stage.INDEX;  break;  default:  stage  =  GatewaySnapshotStatus.Stage.NONE;  break;  }  shardStatus.gatewaySnapshotStatus  =  new  GatewaySnapshotStatus(stage,  snapshotStatus.startTime(),  snapshotStatus.time(),                      snapshotStatus.index().totalSize(),  snapshotStatus.translog().currentTranslogOperations());                      snapshotStatus.index().totalSize());  }  return  shardStatus;  }  public  static  class  IndexShardStatusRequest  extends  BroadcastShardOperationRequest  {  IndexShardStatusRequest()  {  	snapshotStatus.index().totalSize());  
libgdx_6cc53e2279ec82085265a200ee7cb71e52206682	buggy:  sprite  =  atlas.getSprite( "map ");  context:  public  class  AtlasIssueTest  extends  GdxTest  {  SpriteBatch  batch;  Sprite  sprite;  TextureAtlas  atlas;  BitmapFont  font;  public  void  create  ()  {  batch  =  new  SpriteBatch();  batch.setProjectionMatrix(new  Matrix4().setToOrtho2D(0,  0,  855,  480));  atlas  =  new  TextureAtlas(Gdx.files.internal( "data/issue_pack "),  Gdx.files.internal( "data/ "));  sprite  =  atlas.getSprite( "map ");  sprite  =  atlas.createSprite( "map ");  font  =  new  BitmapFont(Gdx.files.internal( "data/font.fnt "),  Gdx.files.internal( "data/font.png "),  false);  Gdx.gl.glClearColor(0,  1,  0,  1);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  sprite.draw(batch);  	sprite    =  atlas.createSprite( "map ");  
libgdx_f99ce494cce69d685a3670d46e70e7deaf0d17b6	buggy:  if  (file.exists())  return  true;  context:  if  (type  ==  FileType.Classpath)  throw  new  GdxRuntimeException( "Cannot  mkdirs  with  a  classpath  file:   "  +  file);  if  (type  ==  FileType.Internal)  throw  new  GdxRuntimeException( "Cannot  mkdirs  with  an  internal  file:   "  +  file);  file().mkdirs();  }  public  boolean  exists  ()  {  switch  (type)  {  case  Internal:  if  (file.exists())  return  true;  if  (file().exists())  return  true;  case  Classpath:  return  FileHandle.class.getResource( "/ "  +  file.getPath().replace('\\',  '/'))  !=  null;  }  return  file().exists();  }  	if  (file().exists())  return  true;  
libgdx_58ae7e94a5e662e1cbbc65226a2d9ac9b1482bae	buggy:  GdxTest  test  =  new  IssueTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  IssueTest();  GdxTest  test  =  new  TimerTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.r  =  config.g  =  config.b  =  config.a  =  8;  config.width  =  960;  config.height  =  600;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  TimerTest();  
elasticsearch_f57efcf6c868c107edde6bb087dab2280acd86d3	buggy:  public  Object  clone()  {  context:  protected  int  uncompress(IndexInput  in,  byte[]  out)  throws  IOException  {  return  decoder.decodeChunk(new  InputStreamIndexInput(in,  Long.MAX_VALUE),  inputBuffer,  out);  }  protected  void  doClose()  throws  IOException  {  }      public  Object  clone()  {      public  IndexInput  clone()  {  LZFCompressedIndexInput  cloned  =  (LZFCompressedIndexInput)  super.clone();  cloned.inputBuffer  =  new  byte[LZFChunk.MAX_CHUNK_LEN];  return  cloned;  }  }  	public  IndexInput  clone()  {  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.ERROR_UNAVAILABLE_EXPAND_OPEN_CLOSE);  context:  return  request.masterNodeTimeout();  }  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {                  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.ERROR_UNAVAILABLE_EXPAND_OPEN_CLOSE);                  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.strictExpand());  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  MetaData.Builder  metaDataBuilder  =  MetaData.builder(currentState.metaData());  Set<String>  openIndices  =  Sets.newHashSet();  Set<String>  closeIndices  =  Sets.newHashSet();  for  (String  index  :  actualIndices)  {  	String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.strictExpand());  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray());  context:  out.writeShort((short)  -1);  out.writeInt(-1);  out.writeVInt(2);  out.writeLong(-3);  out.writeVLong(4);  out.writeFloat(1.1f);  out.writeDouble(2.2);  out.writeUTF( "hello ");  out.writeUTF( "goodbye ");          BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray());          BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray(),  false);  assertThat(in.readBoolean(),  equalTo(false));  assertThat(in.readByte(),  equalTo((byte)  1));  assertThat(in.readShort(),  equalTo((short)  -1));  assertThat(in.readInt(),  equalTo(-1));  assertThat(in.readVInt(),  equalTo(2));  assertThat(in.readLong(),  equalTo((long)  -3));  assertThat(in.readVLong(),  equalTo((long)  4));  assertThat((double)  in.readFloat(),  closeTo(1.1,  0.0001));  	BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray(),  false);  
elasticsearch_475564449f924cfa8df839f5e23c21a9e4fbcf28	buggy:  builder.rawField( "_source ",  source);  context:  parser.nextToken();  builder.field( "_source ");  builder.copyCurrentStructure(parser);  }  finally  {  parser.close();  }  }  }  else  {  XContentType  contentType  =  XContentFactory.xContentType(source,  offset,  length);  if  (contentType  ==  builder.contentType())  {                  builder.rawField( "_source ",  source);                  builder.rawField( "_source ",  source,  offset,  length);  }  else  {  XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(source);  try  {  parser.nextToken();  builder.field( "_source ");  builder.copyCurrentStructure(parser);  }  finally  {  parser.close();  	builder.rawField( "_source ",  source,  offset,  length);  
elasticsearch_31231531e117e257d7a2dcdccf89b5f179cde8a6	buggy:  fragments  =  highlighter.getBestFragments(fieldQuery,  context.searcher().getIndexReader(),  docId,  mapper.names().indexName(),  field.fragmentCharSize(),  numberOfFragments);  context:  HighlightField  highlightField  =  new  HighlightField(field.field(),  fragments);  highlightFields.put(highlightField.name(),  highlightField);  }  else  {  FastVectorHighlighter  highlighter  =  buildHighlighter(context,  mapper,  field);  FieldQuery  fieldQuery  =  buildFieldQuery(highlighter,  context.query(),  reader,  field);  String[]  fragments;  try  {  int  numberOfFragments  =  field.numberOfFragments()  ==  0  ?  1  :  field.numberOfFragments();                          fragments  =  highlighter.getBestFragments(fieldQuery,  context.searcher().getIndexReader(),  docId,  mapper.names().indexName(),  field.fragmentCharSize(),  numberOfFragments);                          fragments  =  highlighter.getBestFragments(fieldQuery,  reader,  docId,  mapper.names().indexName(),  field.fragmentCharSize(),  numberOfFragments);  }  catch  (IOException  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  highlight  field  [ "  +  field.field()  +   "] ",  e);  }  HighlightField  highlightField  =  new  HighlightField(field.field(),  fragments);  highlightFields.put(highlightField.name(),  highlightField);  }  }  	fragments  =  highlighter.getBestFragments(fieldQuery,  reader,  docId,  mapper.names().indexName(),  field.fragmentCharSize(),  numberOfFragments);  
libgdx_4aaa53af08724e317a87ea1b162cc2ef0e37c289	buggy:  unload(dependency);  context:  assetTypes.remove(fileName);  assets.get(type).remove(fileName);  }  else  {  log.debug( "Unload  (decrement):   "  +  fileName);  }  Array<String>  dependencies  =  assetDependencies.get(fileName);  if  (dependencies  !=  null)  {  for  (String  dependency  :  dependencies)  {  unload(dependency);  if  (isLoaded(dependency))  unload(dependency);  }  }  if  (assetRef.getRefCount()  <=  0)  {  assetDependencies.remove(fileName);  }  }  	if  (isLoaded(dependency))  unload(dependency);  
libgdx_77b2fdf93d86f5bea77636305a974f542bf537d4	buggy:  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_blocks.png "),  true);  context:  model[0]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_01.dae.g3d "));  lightMaps[0]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_01.jpg "),  true);  model[1]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_02.dae.g3d "));  lightMaps[1]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_02.jpg "),  true);  model[2]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_03.dae.g3d "));  lightMaps[2]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_03.jpg "),  true);  model[3]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_04.dae.g3d "));  lightMaps[3]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_04.jpg "),  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_blocks.png "),  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/World_blobbie_blocks.png "),  true);  cam  =  new  PerspectiveCamera(60,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(30,  10,  85f);  cam.direction.set(0,0,-1);  cam.up.set(0,1,0);  cam.near  =  10f;  cam.far  =  1000;  	diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/World_blobbie_blocks.png "),  true);  
elasticsearch_10e2528cceb404165822862602eb1326ccb1fba5	buggy:  textsToHighlight  =  HighlightUtils.loadFieldValues(mapper,  context,  hitContext);  context:  cache.put(mapper,  entry);  }  int  numberOfFragments  =  field.numberOfFragments()  ==  0  ?  1  :  field.numberOfFragments();  ArrayList<TextFragment>  fragsList  =  new  ArrayList<TextFragment>();  List<Object>  textsToHighlight;  try  {              textsToHighlight  =  HighlightUtils.loadFieldValues(mapper,  context,  hitContext);              textsToHighlight  =  HighlightUtils.loadFieldValues(mapper,  context,  hitContext,  field.forceSource());  for  (Object  textToHighlight  :  textsToHighlight)  {  String  text  =  textToHighlight.toString();  Analyzer  analyzer  =  context.mapperService().documentMapper(hitContext.hit().type()).mappers().indexAnalyzer();  TokenStream  tokenStream  =  analyzer.tokenStream(mapper.names().indexName(),  text);  if  (!tokenStream.hasAttribute(CharTermAttribute.class)  ||  !tokenStream.hasAttribute(OffsetAttribute.class))  {  continue;  	textsToHighlight  =  HighlightUtils.loadFieldValues(mapper,  context,  hitContext,  field.forceSource());  
elasticsearch_b454f64c5756f31c6b1c7b33dd2b373edb1df589	buggy:  if  (setResponseFailureIfIndexMatches(responses,  i,  request,  index,  e))  {  context:  executeBulk(bulkRequest,  startTime,  listener,  responses);  }  }  public  void  onFailure(Throwable  e)  {  if  (!(ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException))  {  for  (int  i  =  0;  i  <  bulkRequest.requests.size();  i++)  {  ActionRequest  request  =  bulkRequest.requests.get(i);                                      if  (setResponseFailureIfIndexMatches(responses,  i,  request,  index,  e))  {                                      if  (request  !=  null  &&  setResponseFailureIfIndexMatches(responses,  i,  request,  index,  e))  {  bulkRequest.requests.set(i,  null);  }  }  }  if  (counter.decrementAndGet()  ==  0)  {  executeBulk(bulkRequest,  startTime,  listener,  responses);  }  }  	if  (request  !=  null  &&  setResponseFailureIfIndexMatches(responses,  i,  request,  index,  e))  {  
libgdx_0da85515db522e8b91e41ddcc1caf26e5f0fdce6	buggy:  System.out.println( "Not  handled  by  TWL! ");  context:  public  boolean  keyUp  (int  keycode)  {  return  false;  }  public  boolean  keyTyped  (char  character)  {  return  false;  }  public  boolean  touchDown  (int  x,  int  y,  int  pointer)  {  System.out.println( "Not  handled  by  TWL! ");  System.out.println( "This  touch  made  it  through  and  was  not  handled  by  TWL. ");  return  false;  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer)  {  return  false;  }  public  boolean  touchDragged  (int  x,  int  y,  int  pointer)  {  	System.out.println( "This  touch  made  it  through  and  was  not  handled  by  TWL. ");  
elasticsearch_e59b41398046371c7c2712d62098f8ed6ef02ef7	buggy:  client( "server1 ").admin().indices().create(createIndexRequest( "test ")).actionGet(5000);  context:  public  class  BroadcastActionsTests  extends  AbstractNodesTests  {  closeAllNodes();  }  startNode( "server1 ");          client( "server1 ").admin().indices().create(createIndexRequest( "test ")).actionGet(5000);          client( "server1 ").admin().indices().prepareCreate( "test ").execute().actionGet(5000);  ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealth().waitForYellowStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  client( "server1 ").index(indexRequest( "test ").type( "type1 ").id( "1 ").source(source( "1 ",   "test "))).actionGet();  	client( "server1 ").admin().indices().prepareCreate( "test ").execute().actionGet(5000);  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  if  ( "script_values_unique ".equals(currentFieldName))  {  context:  }  else  if  ( "include ".equals(currentFieldName))  {  include  =  parser.text();  }  else  if  ( "exclude ".equals(currentFieldName))  {  exclude  =  parser.text();  }  else  if  ( "execution_hint ".equals(currentFieldName)  ||   "executionHint ".equals(currentFieldName))  {  executionHint  =  parser.text();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {                  if  ( "script_values_unique ".equals(currentFieldName))  {                  if  ( "script_values_unique ".equals(currentFieldName)  ||   "scriptValuesUnique ".equals(currentFieldName))  {  assumeUnique  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_NUMBER)  {  if  ( "size ".equals(currentFieldName))  {  requiredSize  =  parser.intValue();  }  else  if  ( "shard_size ".equals(currentFieldName)  ||   "shardSize ".equals(currentFieldName))  {  	if  ( "script_values_unique ".equals(currentFieldName)  ||   "scriptValuesUnique ".equals(currentFieldName))  {  
elasticsearch_0c72bb2125971c015059c861613b6b0fffaa542f	buggy:  throw  new  IndexShardGatewayRecoveryException(shardId,   "Failed  to  recovery  index ",  failures.get(0));  context:  }  }  try  {  latch.await();  }  catch  (InterruptedException  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId,   "Interrupted  while  recovering  index ",  e);  }  if  (!failures.isEmpty())  {              throw  new  IndexShardGatewayRecoveryException(shardId,   "Failed  to  recovery  index ",  failures.get(0));              throw  new  IndexShardGatewayRecoveryException(shardId,   "Failed  to  recover  index ",  failures.get(0));  }  long  version  =  -1;  try  {  if  (IndexReader.indexExists(store.directory()))  {  version  =  IndexReader.getCurrentVersion(store.directory());  }  	throw  new  IndexShardGatewayRecoveryException(shardId,   "Failed  to  recover  index ",  failures.get(0));  
libgdx_cf561c803b7e431654bacd7c2d0c139e926b80b1	buggy:  cubemap  =  new  Cubemap(root.child(name  +   "_PX.png "),  null,//  root.child(name+ "_NX.png "),  context:  cubemap.dispose();  cubemap  =  null;  }  if  (name.equals( "<none> "))  {  if  (lights.has(CubemapAttribute.EnvironmentMap))  {  lights.remove(CubemapAttribute.EnvironmentMap);  shaderProvider.clear();  }  }  else  {  FileHandle  root  =  Gdx.files.internal( "data/g3d/environment ");  cubemap  =  new  Cubemap(root.child(name  +   "_PX.png "),  null,//  root.child(name+ "_NX.png "),  cubemap  =  new  Cubemap(root.child(name  +   "_PX.png "),  root.child(name+ "_NX.png "),  root.child(name  +   "_PY.png "),  root.child(name  +   "_NY.png "),  root.child(name  +   "_PZ.png "),  root.child(name  +   "_NZ.png "),  false);  //  FIXME  mipmapping  on  desktop  cubemap.load(CubemapSide.NegativeX,  root.child(name  +   "_NX.png "));  if  (!lights.has(CubemapAttribute.EnvironmentMap))  shaderProvider.clear();  lights.set(new  CubemapAttribute(CubemapAttribute.EnvironmentMap,  cubemap));  }  }  	cubemap  =  new  Cubemap(root.child(name  +   "_PX.png "),  root.child(name+ "_NX.png "),  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  private  String  bottom;  public  StringFieldsFunctionDataComparator(int  numHits,  SearchScript  script)  {  this.script  =  script;  values  =  new  String[numHits];  }  public  FieldComparator<String>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          script.setNextReader(context.reader());          script.setNextReader(context);  return  this;  }  public  void  setScorer(Scorer  scorer)  {  script.setScorer(scorer);  }  	script.setNextReader(context);  
elasticsearch_8c25be6dee4f4c33ed5d737b1be14b31e3de319f	buggy:  return   "[ "  +  index  +   "][ "  +  shardId  +   "] ";  context:  super.readFrom(in);  shardId  =  in.readVInt();  }  super.writeTo(out);  out.writeVInt(shardId);  }          return   "[ "  +  index  +   "][ "  +  shardId  +   "] ";          return   "gateway_snapshot  {[ "  +  index  +   "][ "  +  shardId  +   "]} ";  }  }  	return   "gateway_snapshot  {[ "  +  index  +   "][ "  +  shardId  +   "]} ";  
elasticsearch_eb63bb259d393354d4875c4e41dfed97edd142d1	buggy:  client.admin().indices().prepareDelete().execute().actionGet();  context:  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  settingsBuilder()  .put(super.nodeSettings(nodeOrdinal))  .put( "indices.ttl.interval ",  PURGE_INTERVAL)  .build();  }  public  void  testPercolatingWithTimeToLive()  throws  Exception  {  Client  client  =  client();          client.admin().indices().prepareDelete().execute().actionGet();          client.admin().indices().prepareDelete( "_all ").execute().actionGet();  ensureGreen();  String  precolatorMapping  =  XContentFactory.jsonBuilder().startObject().startObject(PercolatorService.TYPE_NAME)  .startObject( "_ttl ").field( "enabled ",  true).endObject()  .startObject( "_timestamp ").field( "enabled ",  true).endObject()  .endObject().endObject().string();  String  typeMapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type1 ")  	client.admin().indices().prepareDelete( "_all ").execute().actionGet();  
libgdx_aa57782a2a89cc71a8f6b255a758ea5ff4bcc3bf	buggy:  jniDestroyBody(  body.addr,  body.addr  );  context:  float  intertiaScale  );  public  void  destroyBody(Body  body)  {  jniDestroyBody(  body.addr,  body.addr  );  jniDestroyBody(  addr,  body.addr  );  this.bodies.remove(  body.addr  );  for(  int  i  =  0;  i  <  body.getFixtureList().size();  i++  )  this.fixtures.remove(body.getFixtureList().get(i).addr);  for(  int  i  =  0;  i  <  body.getJointList().size();  i++  )  this.joints.remove(body.getJointList().get(i).joint.addr);  }  private  native  void  jniDestroyBody(  long  addr,  long  bodyAddr  );  	jniDestroyBody(  addr,  body.addr  );  
elasticsearch_7709c68f6312703b60b40f9ded1bd6121daa1d58	buggy:  return  fixNegativeQueryIfNeeded(query);  context:  queryParser.setFuzzyPrefixLength(fuzzyPrefixLength);  queryParser.setPhraseSlop(phraseSlop);  if  (escape)  {  queryString  =  QueryParser.escape(queryString);  }  try  {  Query  query  =  queryParser.parse(queryString);  query.setBoost(boost);              return  fixNegativeQueryIfNeeded(query);              return  optimizeQuery(fixNegativeQueryIfNeeded(query));  }  catch  (ParseException  e)  {  throw  new  QueryParsingException(index,   "Failed  to  parse  query  [ "  +  queryString  +   "] ",  e);  }  }  }  	return  optimizeQuery(fixNegativeQueryIfNeeded(query));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  TypeLiteral<T>(type);  context:  public  static  TypeLiteral<?>  get(Type  type)  {  return  new  TypeLiteral<Object>(type);  }  public  static  <T>  TypeLiteral<T>  get(Class<T>  type)  {          return  new  TypeLiteral<T>(type);          return  new  TypeLiteral<>(type);  }  private  List<TypeLiteral<?>>  resolveAll(Type[]  types)  {  TypeLiteral<?>[]  result  =  new  TypeLiteral<?>[types.length];  	return  new  TypeLiteral<>(type);  
libgdx_b6021a23bbcf5b41d830905505367d49356decf6	buggy:  return  newPixmap(file.readFile());  context:  BufferedImage  img  =  (BufferedImage)  ImageIO.read(in);  return  new  JoglPixmap(img);  }  catch  (Exception  ex)  {  throw  new  GdxRuntimeException(   "Couldn't  load  Pixmap  from  InputStream ",  ex);  }  }  public  Pixmap  newPixmap(FileHandle  file)  {  return  newPixmap(file.readFile());  return  newPixmap(file.read());  }  public  Pixmap  newPixmap(Object  nativePixmap)  {  return  new  JoglPixmap((BufferedImage)  nativePixmap);  }  private  static  boolean  isPowerOfTwo(int  value)  {  	return  newPixmap(file.read());  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  Distance  precision  =  Distance.parseDistance(pinFieldData.get( "precision ").toString(),  DistanceUnit.METERS);  context:  assertPrecision(new  Distance(11,  DistanceUnit.METERS));  }  private  void  assertPrecision(Distance  expected)  throws  Exception  {  ImmutableOpenMap<String,  ImmutableOpenMap<String,  MappingMetaData>>  mappings  =  client().admin().indices().getMappings(new  GetMappingsRequest().indices( "test ").types( "type1 ")).actionGet().getMappings();  assertNotNull(mappings);  Map<String,  ?>  properties  =  (Map<String,  ?>)  mappings.get( "test ").get( "type1 ").getSourceAsMap().get( "properties ");  Map<String,  ?>  pinProperties  =  (Map<String,  ?>)  properties.get( "pin ");  Map<String,  ?>  pinFieldData  =  (Map<String,  ?>)  pinProperties.get( "fielddata ");          Distance  precision  =  Distance.parseDistance(pinFieldData.get( "precision ").toString(),  DistanceUnit.METERS);          Distance  precision  =  Distance.parseDistance(pinFieldData.get( "precision ").toString());  assertEquals(expected,  precision);  }  }  	Distance  precision  =  Distance.parseDistance(pinFieldData.get( "precision ").toString());  
elasticsearch_22c27e4ff8f977a005d0bb0e1d9c6611e5ac8fd6	buggy:  order  =  fieldData.order();  context:  readerGen[slot]  =  currentReaderGen;  }  FieldData  cleanFieldData  =  fieldDataCache.cache(FieldDataType.DefaultTypes.STRING,  reader,  field);  if  (cleanFieldData  instanceof  MultiValueStringFieldData)  {  throw  new  IOException( "Can't  sort  on  string  types  with  more  than  one  value  per  doc,  or  more  than  one  token  per  field ");  }  SingleValueStringFieldData  fieldData  =  (SingleValueStringFieldData)  cleanFieldData;  currentReaderGen++;          order  =  fieldData.order();          order  =  fieldData.ordinals();  lookup  =  fieldData.values();  assert  lookup.length  >  0;  if  (bottomSlot  !=  -1)  {  convert(bottomSlot);  bottomOrd  =  ords[bottomSlot];  }  }  	order  =  fieldData.ordinals();  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  searchRouting  =  parser.textOrNull();  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "filter ".equals(currentFieldName))  {  filter  =  parser.mapOrdered();  }  }  }  }  catch  (Throwable  e)  {  try  {                      channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                      channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  finally  {  if  (parser  !=  null)  {  parser.close();  }  	channel.sendResponse(new  BytesRestResponse(request,  e));  
libgdx_6807f577418a46f4ec299ccc1f3d86998976f7a0	buggy:  GdxTest  test  =  new  TiledMapDirectLoaderTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  TiledMapDirectLoaderTest();  GdxTest  test  =  new  SuperKoalio();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  SuperKoalio();  
elasticsearch_7c032f6af69c33dd2f985b4b6d54b3d0f04aa6d4	buggy:  out.writeStringArray(indices);  context:  for  (int  i  =  0;  i  <  size;  i++)  {  PercolateRequest  request  =  new  PercolateRequest();  request.readFrom(in);  requests.add(request);  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeStringArray(indices);          out.writeStringArrayNullable(indices);  out.writeOptionalString(documentType);  out.writeByte(ignoreIndices.id());  out.writeVInt(requests.size());  for  (PercolateRequest  request  :  requests)  {  request.writeTo(out);  }  }  }  	out.writeStringArrayNullable(indices);  
elasticsearch_38894632c39e4ac0b8f6cc3faf53c6fc79bfb06a	buggy:  boolean  helpWanted  =  request.paramAsBoolean( "h ",  false);  context:  public  AbstractCatAction(Settings  settings,  Client  client)  {  super(settings,  client);  }  abstract  void  doRequest(final  RestRequest  request,  final  RestChannel  channel);  abstract  void  documentation(StringBuilder  sb);  abstract  Table  getTableWithHeader(final  RestRequest  request);  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {          boolean  helpWanted  =  request.paramAsBoolean( "h ",  false);          boolean  helpWanted  =  request.paramAsBoolean( "help ",  false);  if  (helpWanted)  {  Table  table  =  getTableWithHeader(request);  int[]  width  =  buildHelpWidths(table,  request,  false);  StringBuilder  out  =  new  StringBuilder();  for  (Table.Cell  cell  :  table.getHeaders())  {  pad(new  Table.Cell(cell.value),  width[0],  request,  out);  out.append( "  |   ");  	boolean  helpWanted  =  request.paramAsBoolean( "help ",  false);  
elasticsearch_135404fffc21d6e9d6f3982ca1e6ca38099755c9	buggy:  ensureYellow();  context:  .startObject( "pin ")  .field( "type ",   "geo_point ")  .startObject( "fielddata ")  .field( "format ",   "compressed ")  .field( "precision ",   "2mm ")  .endObject()  .endObject()  .endObject()  .endObject()  .endObject()).execute().actionGet();          ensureYellow();          ensureGreen();  assertPrecision(new  Distance(2,  DistanceUnit.MILLIMETERS));  client().admin().indices().preparePutMapping( "test ").setType( "type1 ").setSource(XContentFactory.jsonBuilder().startObject()  .startObject( "type1 ")  .startObject( "properties ")  .startObject( "pin ")  .field( "type ",   "geo_point ")  .startObject( "fielddata ")  	ensureGreen();  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  context:  }  }  if  (fieldName  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "exists  must  be  provided  with  a  [field] ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);              filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }  filter  =  parseContext.cacheFilter(filter,  null);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  
elasticsearch_d1d3f8c4ca39471ff551330eea508d31d9aea2ea	buggy:  channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));  context:  }  if  (nodeInfo.transport()  !=  null)  {  nodeInfo.transport().toXContent(builder,  request);  }  builder.endObject();  }  builder.endObject();  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  
elasticsearch_d150ac2da418d30c5cfbabe47f27cc31e6f5b397	buggy:  invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));  context:  queryFetchResults.put(result.shardTarget(),  result);  }  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());  }              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  searchCache.releaseQueryFetchResults(queryFetchResults);  }  }  }  	invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_d2fea5378ad8beff6e2eb566c9d573f93771e2ef	buggy:  final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action);  context:  public  ChannelPipeline  getPipeline()  throws  Exception  {  ChannelPipeline  pipeline  =  super.getPipeline();  pipeline.replace( "dispatcher ",   "dispatcher ",  new  MessageChannelHandler(nettyTransport,  logger)  {  protected  String  handleRequest(Channel  channel,  StreamInput  buffer,  long  requestId,  Version  version)  throws  IOException  {  final  String  action  =  buffer.readString();  final  NettyTransportChannel  transportChannel  =  new  NettyTransportChannel(transport,  action,  channel,  requestId,  version);  try  {                              final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action);                              final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action,  version);  if  (handler  ==  null)  {  throw  new  ActionNotFoundTransportException(action);  }  final  TransportRequest  request  =  handler.newInstance();  request.remoteAddress(new  InetSocketTransportAddress((InetSocketAddress)  channel.getRemoteAddress()));  request.readFrom(buffer);  if  (request.getHeaders()  !=  null  &&  request.getHeaders().containsKey( "ERROR "))  {  throw  new  ElasticsearchException((String)  request.getHeaders().get( "ERROR "));  	final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action,  version);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  return  new  TypesExistsResponse();  }  protected  ClusterBlockException  checkBlock(TypesExistsRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  TypesExistsRequest  request,  final  ClusterState  state,  final  ActionListener<TypesExistsResponse>  listener)  throws  ElasticsearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  if  (concreteIndices.length  ==  0)  {  listener.onResponse(new  TypesExistsResponse(false));  return;  }  for  (String  concreteIndex  :  concreteIndices)  {  if  (!state.metaData().hasConcreteIndex(concreteIndex))  {  listener.onResponse(new  TypesExistsResponse(false));  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage  =  new  Stage(480,  320,  true);  context:  public  class  ActionSequenceTest  extends  GdxTest  implements  Runnable  {  Image  img;  Image  img2;  Image  img3;  Stage  stage;  Texture  texture;  public  void  create  ()  {  stage  =  new  Stage(480,  320,  true);  stage  =  new  Stage();  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  false);  texture.setFilter(TextureFilter.Linear,  TextureFilter.Linear);  img  =  new  Image(new  TextureRegion(texture));  img.setSize(100,  100);  img.setOrigin(50,  50);  img.setPosition(100,  100);  img2  =  new  Image(new  TextureRegion(texture));  	stage  =  new  Stage();  
elasticsearch_cfafb52bebbd5bb50b4fc74b1aebc121a9e91548	buggy:  indexShard.refresh(false);  context:  }  stopWatch.stop();  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "Recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(stopWatch.totalTime()).append( "]\n ");  sb.append( "    Index    :  numberOfFiles      [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  totalSize  [ ").append(recoveryStatus.index().totalSize()).append( "]\n ");  sb.append( "    Translog  :  numberOfOperations  [ ").append(recoveryStatus.translog().numberOfOperations()).append( "]  with  totalSize  [ ").append(recoveryStatus.translog().totalSize()).append( "] ");  }              indexShard.refresh(false);              indexShard.refresh(new  Engine.Refresh(false));  scheduleSnapshotIfNeeded();  }  else  {  throw  new  IgnoreGatewayRecoveryException(shardId,   "Already  recovered ");  }  }  	indexShard.refresh(new  Engine.Refresh(false));  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  nestedFilter  =  context.queryParserService().parseInnerFilter(parser);  context:  ignoreUnmapped  =  parser.booleanValue();  }  else  if  ( "mode ".equals(innerJsonName))  {  sortMode  =  SortMode.fromString(parser.text());  }  else  if  ( "nested_path ".equals(innerJsonName)  ||   "nestedPath ".equals(innerJsonName))  {  nestedPath  =  parser.text();  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "sort  option  [ "  +  innerJsonName  +   "]  not  supported ");  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "nested_filter ".equals(innerJsonName)  ||   "nestedFilter ".equals(innerJsonName))  {                                      nestedFilter  =  context.queryParserService().parseInnerFilter(parser);                                      nestedFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "sort  option  [ "  +  innerJsonName  +   "]  not  supported ");  }  }  }  addSortField(context,  sortFields,  fieldName,  reverse,  ignoreUnmapped,  missing,  sortMode,  nestedPath,  nestedFilter);  }  }  	nestedFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  
libgdx_b1d974e23ed2130b201acefee70d661183836bc9	buggy:  project.files.add(new  ProjectFile( "android/res/values/strings.xml ",  false));  context:  project.files.add(new  ProjectFile( "core/src/MainClass ",   "core/src/ "  +  packageDir  +   "/ "  +  mainClass  +   ".java ",  true));  project.files.add(new  ProjectFile( "core/CoreGdxDefinition ",   "core/src/ "  +  packageDir  +   "/ "  +  mainClass  +   ".gwt.xml ",  true));  project.files.add(new  ProjectFile( "desktop/build.gradle "));  project.files.add(new  ProjectFile( "desktop/src/DesktopLauncher ",   "desktop/src/ "  +  packageDir  +   "/desktop/DesktopLauncher.java ",  true));  project.files.add(new  ProjectFile( "android/assets/badlogic.jpg ",  false));  project.files.add(new  ProjectFile( "android/res/values/strings.xml ",  false));  project.files.add(new  ProjectFile( "android/res/values/strings.xml "));  project.files.add(new  ProjectFile( "android/res/values/styles.xml ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-hdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-mdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-xhdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/res/drawable-xxhdpi/ic_launcher.png ",  false));  project.files.add(new  ProjectFile( "android/src/AndroidLauncher ",   "android/src/ "  +  packageDir  +   "/android/AndroidLauncher.java ",  true));  project.files.add(new  ProjectFile( "android/AndroidManifest.xml "));  project.files.add(new  ProjectFile( "android/build.gradle "));  	project.files.add(new  ProjectFile( "android/res/values/strings.xml "));  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  name  +   "] ");  context:  }  public  HistogramBuilder  postOffset(long  postOffset)  {  this.postOffset  =  postOffset;  return  this;  }  protected  XContentBuilder  doInternalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (interval  ==  null)  {              throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  getName()  +   "] ");  }  builder.field( "interval ",  interval);  if  (order  !=  null)  {  builder.field( "order ");  order.toXContent(builder,  params);  }  	throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  getName()  +   "] ");  
libgdx_00d1104f15561c9a7ff1060ce19f623b930f37f3	buggy:  if  (node.actor.getY()  <=  high)  selectedNodes.add(node);  context:  }  }  return  rowY;  }  void  selectNodes  (Array<Node>  nodes,  float  low,  float  high)  {  for  (int  i  =  0,  n  =  nodes.size;  i  <  n;  i++)  {  Node  node  =  nodes.get(i);  if  (node.actor.getY()  <  low)  break;  if  (!node.isSelectable())  continue;  if  (node.actor.getY()  <=  high)  selectedNodes.add(node);  if  (node.actor.getY()  <=  high  &&  !selectedNodes.contains(node,  true))  selectedNodes.add(node);  if  (node.expanded)  selectNodes(node.children,  low,  high);  }  }  public  Array<Node>  getSelection  ()  {  return  selectedNodes;  }  	if  (node.actor.getY()  <=  high  &&  !selectedNodes.contains(node,  true))  selectedNodes.add(node);  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  PRECONDITION_FAILED,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));  context:  try  {  deleteByQueryRequest.querySource(HttpActions.parseQuerySource(request));  deleteByQueryRequest.queryParserName(request.param( "queryParserName "));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  deleteByQueryRequest.types(HttpActions.splitTypes(typesParam));  }  deleteByQueryRequest.timeout(TimeValue.parseTimeValue(request.param( "timeout "),  ShardDeleteByQueryRequest.DEFAULT_TIMEOUT));  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  JsonHttpResponse(request,  PRECONDITION_FAILED,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));                  channel.sendResponse(new  JsonHttpResponse(request,  PRECONDITION_FAILED,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }  client.execDeleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {  try  {  	channel.sendResponse(new  JsonHttpResponse(request,  PRECONDITION_FAILED,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  
libgdx_52eca501e35d1adbe360b83bfa9446fb72b7d0b1	buggy:  actor.rotate(amount  *  percentDelta);  context:  package  com.badlogic.gdx.scenes.scene2d.actions;  public  class  RotateByAction  extends  RelativeTemporalAction  {  private  float  amount;  protected  void  updateRelative  (float  percentDelta)  {  actor.rotate(amount  *  percentDelta);  actor.rotateBy(amount  *  percentDelta);  }  public  float  getAmount  ()  {  return  amount;  }  public  void  setAmount  (float  rotationAmount)  {  amount  =  rotationAmount;  	actor.rotateBy(amount  *  percentDelta);  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  return  builder.startObject(name)  context:  .addAggregation(dateHistogram( "histo ").field( "date ").interval(DateHistogram.Interval.DAY).postZone( "-01:00 "))  .execute().actionGet();  }  else  {  response  =  client().prepareSearch( "idx ")  .addAggregation(new  AbstractAggregationBuilder( "histo ",   "date_histogram ")  {  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {                          return  builder.startObject(name)                          return  builder.startObject(getName())  .startObject(type)  .field( "field ",   "date ")  .field( "interval ",   "1d ")  .field( "post_zone ",  -1)  .endObject()  .endObject();  }  })  	return  builder.startObject(getName())  
elasticsearch_4b9fcdb9000f7f42b9ff841f142d7a540d466c68	buggy:  assertThat((Integer)  getResponse.field( "int ").getValue(),  equalTo(42));  context:  assertThat((Integer)  getResponse.field( "int ").getValue(),  equalTo(42));  assertThat((String)  getResponse.field( "date ").getValue(),  equalTo( "2012-11-13T15:26:14.000Z "));  client.admin().indices().prepareFlush().execute().actionGet();  getResponse  =  client.prepareGet( "test ",   "type1 ",   "1 ").setFields( "str ",   "int ",   "date ").execute().actionGet();  assertThat(getResponse.exists(),  equalTo(true));  assertThat((String)  getResponse.field( "str ").getValue(),  equalTo( "test "));          assertThat((Integer)  getResponse.field( "int ").getValue(),  equalTo(42));          assertThat((Long)  getResponse.field( "int ").getValue(),  equalTo(42l));  assertThat((String)  getResponse.field( "date ").getValue(),  equalTo( "2012-11-13T15:26:14.000Z "));  getResponse  =  client.prepareGet( "test ",   "type2 ",   "1 ").setFields( "str ",   "int ",   "date ").execute().actionGet();  assertThat(getResponse.exists(),  equalTo(true));  assertThat((String)  getResponse.field( "str ").getValue(),  equalTo( "test "));  assertThat((Integer)  getResponse.field( "int ").getValue(),  equalTo(42));  assertThat((String)  getResponse.field( "date ").getValue(),  equalTo( "2012-11-13T15:26:14.000Z "));  	assertThat((Long)  getResponse.field( "int ").getValue(),  equalTo(42l));  
elasticsearch_12cbb3223a540399164734a188460a343eec4068	buggy:  clusterService.submitStateUpdateTask( "zen-disco-receive(join  from  node[ "  +  node  +   "]) ",  Priority.IMMEDIATE,  new  ProcessedClusterStateUpdateTask()  {  context:  }  else  {  transportService.connectToNode(node);  membership.sendValidateJoinRequestBlocking(node,  joinTimeout);  processJoinRequests.add(new  Tuple<>(node,  callback));              clusterService.submitStateUpdateTask( "zen-disco-receive(join  from  node[ "  +  node  +   "]) ",  Priority.IMMEDIATE,  new  ProcessedClusterStateUpdateTask()  {              clusterService.submitStateUpdateTask( "zen-disco-receive(join  from  node[ "  +  node  +   "]) ",  Priority.URGENT,  new  ProcessedClusterStateUpdateTask()  {  private  final  List<Tuple<DiscoveryNode,  MembershipAction.JoinCallback>>  drainedTasks  =  new  ArrayList<>();  public  ClusterState  execute(ClusterState  currentState)  {  processJoinRequests.drainTo(drainedTasks);  if  (drainedTasks.isEmpty())  {  return  currentState;  	clusterService.submitStateUpdateTask( "zen-disco-receive(join  from  node[ "  +  node  +   "]) ",  Priority.URGENT,  new  ProcessedClusterStateUpdateTask()  {  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<PingResponse[]>();  context:  }  protected  void  doClose()  throws  ElasticsearchException  {  for  (ZenPing  zenPing  :  zenPings)  {  zenPing.close();  }  }  public  PingResponse[]  pingAndWait(TimeValue  timeout)  {          final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<PingResponse[]>();          final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);  ping(new  PingListener()  {  public  void  onPing(PingResponse[]  pings)  {  response.set(pings);  latch.countDown();  }  },  timeout);  	final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<>();  
libgdx_c97148fb6b77cef3eed2165c3c0fa5d96640b383	buggy:  return  new  IOSApplication(new  BulletTestCollection(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  config.useAccelerometer  =  false;  return  new  IOSApplication(new  BulletTestCollection(),  config);  return  new  IOSApplication(new  InputTest(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  InputTest(),  config);  
libgdx_d5229e09e8bc160de8fb8988bea48ba170d3139d	buggy:  world.step(  1  /  60.0f,  8,  3  );  context:  protected  abstract  void  createWorld(  World  world  );  protected  Vector2  tmp  =  new  Vector2();  public  void  render(Application  app)  {  world.step(  1  /  60.0f,  8,  3  );  world.step(  app.getGraphics().getDeltaTime(),  8,  3  );  GL10  gl  =  app.getGraphics().getGL10();  gl.glClear(  GL10.GL_COLOR_BUFFER_BIT  );  camera.setMatrices(  );  renderer.render(  world  );  	world.step(  app.getGraphics().getDeltaTime(),  8,  3  );  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  numRuns  =  atLeast(3);  context:  public  class  SimpleFacetsTests  extends  ElasticsearchIntegrationTest  {  private  int  numRuns  =  -1;  protected  int  numberOfRuns()  {  if  (numRuns  ==  -1)  {              numRuns  =  atLeast(3);              numRuns  =  scaledRandomIntBetween(3,  10);  }  return  numRuns;  }  public  void  testSimpleFacetEmptyFacetFilter()  throws  Exception  {  createIndex( "test ");  ensureGreen();  	numRuns  =  scaledRandomIntBetween(3,  10);  
libgdx_a52d449d0330348fbafd9ebcceeddeec901b78fc	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.EdgeDetectionTest(),   "Debug  Test ",  480,  320,  true);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.EdgeDetectionTest(),   "Debug  Test ",  480,  320,  true);  new  JoglApplication(new  com.badlogic.gdx.tests.KinematicBodyTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.KinematicBodyTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(metaData.concreteIndex(request.index()));  context:  protected  boolean  retryOnFailure(Throwable  e)  {  return  TransportActions.isShardNotAvailableException(e);  }  protected  boolean  resolveRequest(ClusterState  state,  UpdateRequest  request,  ActionListener<UpdateResponse>  listener)  {  MetaData  metaData  =  clusterService.state().metaData();  String  aliasOrIndex  =  request.index();  request.routing((metaData.resolveIndexRouting(request.routing(),  aliasOrIndex)));          request.index(metaData.concreteIndex(request.index()));          request.index(metaData.concreteSingleIndex(request.index()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  return  true;  }  	request.index(metaData.concreteSingleIndex(request.index()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.startObject( "nodes ");  for  (DiscoveryNode  node  :  response.getNodes())  {  builder.startObject(node.id(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "name ",  node.name(),  XContentBuilder.FieldCaseConversion.NONE);  builder.endObject();  }  builder.endObject();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_e1625e8c41e8950317462dd783f9cd0541c9fb99	buggy:  arrayPool.free(usedArrays);  context:  }  materialGroup.add(decal);  }  contents.clear();  for  (Array<Decal>  materialGroup  :  materialGroups.values())  {  contents.addAll(materialGroup);  }  materialGroups.clear();  arrayPool.free(usedArrays);  arrayPool.freeAll(usedArrays);  usedArrays.clear();  }  }  public  void  afterGroup  (int  group)  {  if  (group  ==  GROUP_BLEND)  {  Gdx.gl.glDisable(GL10.GL_BLEND);  	arrayPool.freeAll(usedArrays);  
libgdx_935f499cb48f96d29e4395d09458d86b9f80bc9a	buggy:  root.add(image).minWidth(600).minHeight(400);  context:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  TextureRegion  image2  =  new  TextureRegion(new  Texture(Gdx.files.internal( "data/badlogic.jpg ")));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  Gdx.input.setInputProcessor(ui);  root  =  new  Table();  ui.addActor(root);  root.debug();  Image  image  =  new  Image(image2,  Scaling.stretch);  root.add(image).minWidth(600).minHeight(400);  root.add(image).minWidth(16).minHeight(14);  }  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  ui.act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30f));  ui.draw();  	root.add(image).minWidth(16).minHeight(14);  
elasticsearch_0a459f7cebb0ecf2a7330619bdf4b9da51142b22	buggy:  ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(settings,   "[ "  +  name  +   "] ");  context:  }  }  return  result;  }  private  ExecutorHolder  build(String  name,  String  defaultType,  @Nullable  Settings  settings,  Settings  defaultSettings)  {  if  (settings  ==  null)  {  settings  =  ImmutableSettings.Builder.EMPTY_SETTINGS;  }  String  type  =  settings.get( "type ",  defaultType);          ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(settings,   "[ "  +  name  +   "] ");          ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(this.settings,   "[ "  +  name  +   "] ");  if  ( "same ".equals(type))  {  return  new  ExecutorHolder(MoreExecutors.sameThreadExecutor(),  new  Info(name,  type));  }  else  if  ( "cached ".equals(type))  {  TimeValue  keepAlive  =  settings.getAsTime( "keep_alive ",  defaultSettings.getAsTime( "keep_alive ",  timeValueMinutes(5)));  Executor  executor  =  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAlive.millis(),  TimeUnit.MILLISECONDS,  	ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(this.settings,   "[ "  +  name  +   "] ");  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  .filterAll().filterNodes(false).local(true),  context:  transportService.connectToNodeLight(listedNode);  }  }  catch  (Exception  e)  {  latch.countDown();  return;  }  }  transportService.sendRequest(listedNode,  ClusterStateAction.NAME,  Requests.clusterStateRequest()                                              .filterAll().filterNodes(false).local(true),                                              .clear().nodes(true).local(true),  TransportRequestOptions.options().withType(TransportRequestOptions.Type.STATE).withTimeout(pingTimeout),  new  BaseTransportResponseHandler<ClusterStateResponse>()  {  public  ClusterStateResponse  newInstance()  {  return  new  ClusterStateResponse();  }  	.clear().nodes(true).local(true),  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  systemProperties  =  new  HashMap<String,  String>();  context:  vmName  =  in.readString();  vmVersion  =  in.readString();  vmVendor  =  in.readString();  startTime  =  in.readLong();  inputArguments  =  new  String[in.readInt()];  for  (int  i  =  0;  i  <  inputArguments.length;  i++)  {  inputArguments[i]  =  in.readString();  }  bootClassPath  =  in.readString();  classPath  =  in.readString();          systemProperties  =  new  HashMap<String,  String>();          systemProperties  =  new  HashMap<>();  int  size  =  in.readInt();  for  (int  i  =  0;  i  <  size;  i++)  {  systemProperties.put(in.readString(),  in.readString());  }  mem  =  new  Mem();  mem.readFrom(in);  gcCollectors  =  in.readStringArray();  memoryPools  =  in.readStringArray();  	systemProperties  =  new  HashMap<>();  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  FloatArrayAtomicFieldData.Single(new  float[0],  0);  context:  }  }  }  public  FloatArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  FloatArrayAtomicFieldData.Single(new  float[0],  0);              return  new  FloatArrayAtomicFieldData.SingleFixedSet(new  float[1],  0,  new  FixedBitSet(1));  }  final  TFloatArrayList  values  =  new  TFloatArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  FloatArrayAtomicFieldData.SingleFixedSet(new  float[1],  0,  new  FixedBitSet(1));  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  node.client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "number_of_shards ",  10)).execute().actionGet();  context:  public  void  searchWhileCreatingIndex()  {  Node  node  =  startNode( "node1 ");  try  {  node.client().admin().indices().prepareDelete( "test ").execute().actionGet();  }  catch  (Exception  e)  {  }  for  (int  i  =  0;  i  <  20;  i++)  {              node.client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "number_of_shards ",  10)).execute().actionGet();              node.client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  10)).execute().actionGet();  node.client().prepareIndex( "test ",   "type1 ").setSource( "field ",   "test ").execute().actionGet();  node.client().admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  searchResponse  =  node.client().prepareSearch( "test ").setQuery(QueryBuilders.termQuery( "field ",   "test ")).execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  node.client().admin().indices().prepareDelete( "test ").execute().actionGet();  	node.client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  10)).execute().actionGet();  
libgdx_b432442fda59f17f4c481c8cab34cf0b49e3aa6e	buggy:  renderBatch.render(instances.get(i),  lights);  context:  gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.gl.glClearColor(0,  0,  0,  0);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  Gdx.gl.glDisable(GL20.GL_CULL_FACE);  renderBatch.begin(cam);  for  (int  i  =  0;  i  <  instances.size;  i++)  {  if  (instances.get(i).model  ==  null)  Gdx.app.log( "Test ",   "Model   "+i+ "  is  null ");  else  renderBatch.render(instances.get(i),  lights);  renderBatch.render(lights,  instances.get(i));  }  renderBatch.end();  }  public  boolean  touchDown  (int  x,  int  y,  int  pointer,  int  newParam)  {  touchStartX  =  x;  touchStartY  =  y;  	renderBatch.render(lights,  instances.get(i));  
elasticsearch_af39f07213ccce2419688191b47fbac5fbd4de40	buggy:  .setQuery(termQuery( "child._id ",   "c1 "))  context:  client.prepareIndex( "test ",   "child ",   "c1 ").setSource( "c_field ",   "red ").setParent( "p1 ").execute().actionGet();  client.prepareIndex( "test ",   "child ",   "c2 ").setSource( "c_field ",   "yellow ").setParent( "p1 ").execute().actionGet();  client.prepareIndex( "test ",   "parent ",   "p2 ").setSource( "p_field ",   "p_value2 ").execute().actionGet();  client.prepareIndex( "test ",   "child ",   "c3 ").setSource( "c_field ",   "blue ").setParent( "p2 ").execute().actionGet();  client.prepareIndex( "test ",   "child ",   "c4 ").setSource( "c_field ",   "red ").setParent( "p2 ").execute().actionGet();  client.admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  searchResponse  =  client.prepareSearch( "test ")                  .setQuery(termQuery( "child._id ",   "c1 "))                  .setQuery(idsQuery( "child ").ids( "c1 "))  .addFields( "_parent ")  .execute().actionGet();  if  (searchResponse.failedShards()  >  0)  {  for  (ShardSearchFailure  shardSearchFailure  :  searchResponse.shardFailures())  {  }  }  	.setQuery(idsQuery( "child ").ids( "c1 "))  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  PrefixQuery  query  =  new  PrefixQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  
libgdx_fe85dabde8abe742c21873c8bfd0a160fb2b5aad	buggy:  nextStart--;  context:  }  int  lineEnd  =  start  +  font.computeVisibleGlyphs(str,  start,  newLine,  wrapWidth);  int  nextStart  =  lineEnd  +  1;  if  (lineEnd  <  newLine)  {  while  (lineEnd  >  start)  {  if  (BitmapFont.isWhitespace(str.charAt(lineEnd)))  break;  lineEnd--;  }  if  (lineEnd  ==  start)  {  nextStart--;  if  (nextStart  >  start  +  1)  nextStart--;  lineEnd  =  nextStart;  //  If  no  characters  to  break,  show  all.  }  else  {  nextStart  =  lineEnd;  while  (lineEnd  >  start)  {  if  (!BitmapFont.isWhitespace(str.charAt(lineEnd  -  1)))  break;  lineEnd--;  }  	if  (nextStart  >  start  +  1)  nextStart--;  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  if  ((System.currentTimeMillis()  -  cachedStats.timestamp())  >  refreshInterval.millis())  {  context:  super(settings);  this.probe  =  probe;  this.cachedStats  =  probe.stats();  this.refreshInterval  =  componentSettings.getAsTime( "refresh_interval ",  TimeValue.timeValueSeconds(1));  }  public  synchronized  FsStats  stats()  {          if  ((System.currentTimeMillis()  -  cachedStats.timestamp())  >  refreshInterval.millis())  {          if  ((System.currentTimeMillis()  -  cachedStats.getTimestamp())  >  refreshInterval.millis())  {  cachedStats  =  probe.stats();  }  return  cachedStats;  }  }  	if  ((System.currentTimeMillis()  -  cachedStats.getTimestamp())  >  refreshInterval.millis())  {  
elasticsearch_3ca0239668187c535f36a5da6473d73315f42679	buggy:  assertThat(response.getMatches()[0].id().string(),  equalTo( "100 "));  context:  ensureGreen(client);  client.admin().indices().prepareOpen( "test ").execute().actionGet();  ensureGreen(client);  response  =  client.preparePercolate()  .setIndices( "test ").setDocumentType( "type1 ")  .setSource(jsonBuilder().startObject().startObject( "doc ").field( "field1 ",  100).endObject().endObject())  .execute().actionGet();  assertThat(response.getMatches(),  arrayWithSize(1));          assertThat(response.getMatches()[0].id().string(),  equalTo( "100 "));          assertThat(response.getMatches()[0].getId().string(),  equalTo( "100 "));  }  public  void  testSinglePercolator_recovery()  throws  Exception  {  percolatorRecovery(false);  }  	assertThat(response.getMatches()[0].getId().string(),  equalTo( "100 "));  
elasticsearch_19c8d18b1489bcebafb4d5fcb022e03ece749550	buggy:  return  distance  /  10000.0;  context:  assertThat(GeoDistance.ARC.calculate(-86.9,  53.738,  -86.9,  53.741,  DistanceUnit.METERS),  closeTo(18.03998,  maxError(18.03998)));  assertThat(GeoDistance.ARC.calculate(89.041,  115.93,  89.04,  115.946,  DistanceUnit.METERS),  closeTo(115.11711,  maxError(115.11711)));  testSloppyMath(DistanceUnit.METERS,  0.01,  5,  45,  90);  testSloppyMath(DistanceUnit.KILOMETERS,  0.01,  5,  45,  90);  testSloppyMath(DistanceUnit.INCH,  0.01,  5,  45,  90);  testSloppyMath(DistanceUnit.MILES,  0.01,  5,  45,  90);  }  private  static  double  maxError(double  distance)  {          return  distance  /  10000.0;          return  distance  /  1000.0;  }  private  void  testSloppyMath(DistanceUnit  unit,  double...deltaDeg)  {  final  double  lat1  =  randomLatitude();  final  double  lon1  =  randomLongitude();  GeoDistance.ArcFixedSourceDistance  src  =  new  GeoDistance.ArcFixedSourceDistance(lat1,  lon1,  unit);  	return  distance  /  1000.0;  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  while  (cluster().numNodes()  !=  0)  {  context:  public  void  testLoadByClassNameShardsAllocator()  {  Settings  build  =  settingsBuilder().put(ShardsAllocatorModule.TYPE_KEY,   "EvenShardsCount ").build();  assertAllocatorInstance(build,  EvenShardsCountAllocator.class);  build  =  settingsBuilder().put(ShardsAllocatorModule.TYPE_KEY,   "org.elasticsearch.cluster.routing.allocation.allocator.EvenShardsCountAllocator ").build();  assertAllocatorInstance(build,  EvenShardsCountAllocator.class);  }  private  void  assertAllocatorInstance(Settings  settings,  Class<?  extends  ShardsAllocator>  clazz)  {          while  (cluster().numNodes()  !=  0)  {          while  (cluster().size()  !=  0)  {  cluster().stopRandomNode();  }  cluster().startNode(settings);  ShardsAllocator  instance  =  cluster().getInstance(ShardsAllocator.class);  assertThat(instance,  instanceOf(clazz));  }  }  	while  (cluster().size()  !=  0)  {  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execDeleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {  context:  deleteByQueryRequest.timeout(request.paramAsTime( "timeout ",  ShardDeleteByQueryRequest.DEFAULT_TIMEOUT));  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  PRECONDITION_FAILED,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }          client.execDeleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {          client.deleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject().field( "ok ",  true);  builder.startObject( "_indices ");  for  (IndexDeleteByQueryResponse  indexDeleteByQueryResponse  :  result.indices().values())  {  builder.startObject(indexDeleteByQueryResponse.index());  	client.deleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  context:  assertThat(searchResponse.facets().facet(QueryFacet.class,   "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().facet(QueryFacet.class,   "all ").count(),  equalTo(100l));  }  testSimpleFacets();  testSimpleFacets();  }  private  static  InternalSearchRequest  searchRequest(ShardRouting  shardRouting,  SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());          return  new  InternalSearchRequest(shardRouting,  3).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  StringBuilder  multi  =  new  StringBuilder().append(nameValue);  	return  new  InternalSearchRequest(shardRouting,  3).source(builder.buildAsBytes());  
elasticsearch_333e7df3bca643cc3852ff3784eb4ff65fe56096	buggy:  if  (w.closeException()  ==  null)  {  context:  public  boolean  apply(Object  input)  {  return  !w.isOpen();  }  });  }  catch  (InterruptedException  e)  {  Thread.interrupted();  }  if  (!w.successfullyClosed())  {  if  (w.closeException()  ==  null)  {  w.close();                          if  (w.closeException()  ==  null)  {                          if  (w.closeException()  !=  null)  {  throw  w.closeException();  }  }  else  {  throw  w.closeException();  }  }  assertThat(w.isOpen(),  is(false));  }  	if  (w.closeException()  !=  null)  {  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  return  querySource(queryBuilder.build());  context:  ActionRequestValidationException  validationException  =  super.validate();  if  (querySource  ==  null)  {  validationException  =  addValidationError( "querySource  is  missing ",  validationException);  }  return  validationException;  }          return  querySource(queryBuilder.build());          return  querySource(queryBuilder.buildAsString());  }  this.querySource  =  querySource;  return  this;  }  String  queryParserName()  {  	return  querySource(queryBuilder.buildAsString());  
elasticsearch_036febe110f0ea87d96bfe2dce71f97469d5f317	buggy:  assertThat(clusterState.metaData().index( "test ").mappings(),  hasKey( "type1 "));  context:  client().admin().indices().prepareRefresh().execute().actionGet();  for  (int  i  =  0;  i  <  10;  i++)  {  CountResponse  countResponse  =  client().prepareCount().setQuery(matchAllQuery()).execute().actionGet();  assertThat(countResponse.getCount(),  equalTo(10l));  }  ClusterState  clusterState  =  client().admin().cluster().prepareState().execute().actionGet().getState();  for  (int  i  =  0;  i  <  10  &&  !clusterState.metaData().index( "test ").mappings().containsKey( "type1 ");  i++,  Thread.sleep(100))  ;          assertThat(clusterState.metaData().index( "test ").mappings(),  hasKey( "type1 "));          assertThat(clusterState.metaData().index( "test ").mappings().containsKey( "type1 "),  equalTo(true));  GetMappingsResponse  mappingsResponse  =  client().admin().indices().prepareGetMappings( "test ").setTypes( "type1 ").execute().actionGet();  assertThat(mappingsResponse.getMappings().get( "test ").get( "type1 "),  notNullValue());  client().admin().indices().prepareDeleteMapping().setType( "type1 ").execute().actionGet();  Thread.sleep(500);  //  for  now,  we  don't  have  ack  logic,  so  just  wait  for  (int  i  =  0;  i  <  10;  i++)  {  	assertThat(clusterState.metaData().index( "test ").mappings().containsKey( "type1 "),  equalTo(true));  
elasticsearch_2a79ffdc002ebaad07b62c9ee6e0ba47bafe27b0	buggy:  logger.info( "Creating  Index  [{}],  cause  [{}],  shards  [{}]/[{}],  mappings  {} ",  new  Object[]{index,  cause,  indexMetaData.numberOfShards(),  indexMetaData.numberOfReplicas(),  fMappings.keySet()});  context:  }  MetaData  newMetaData  =  newMetaDataBuilder()  .metaData(currentState.metaData())  .put(indexMetaData)  .build();  IndexRoutingTable.Builder  indexRoutingBuilder  =  new  IndexRoutingTable.Builder(index)  .initializeEmpty(newMetaData.index(index));  routingTableBuilder.add(indexRoutingBuilder);                  logger.info( "Creating  Index  [{}],  cause  [{}],  shards  [{}]/[{}],  mappings  {} ",  new  Object[]{index,  cause,  indexMetaData.numberOfShards(),  indexMetaData.numberOfReplicas(),  fMappings.keySet()});                  logger.info( "Creating  Index  [{}],  cause  [{}],  shards  [{}]/[{}],  mappings  {} ",  index,  cause,  indexMetaData.numberOfShards(),  indexMetaData.numberOfReplicas(),  fMappings.keySet());  RoutingTable  newRoutingTable  =  shardsRoutingStrategy.reroute(newClusterStateBuilder().state(currentState).routingTable(routingTableBuilder).metaData(newMetaData).build());  return  newClusterStateBuilder().state(currentState).routingTable(newRoutingTable).metaData(newMetaData).build();  }  });  boolean  acknowledged;  try  {  acknowledged  =  latch.await(timeout.millis(),  TimeUnit.MILLISECONDS);  	logger.info( "Creating  Index  [{}],  cause  [{}],  shards  [{}]/[{}],  mappings  {} ",  index,  cause,  indexMetaData.numberOfShards(),  indexMetaData.numberOfReplicas(),  fMappings.keySet());  
elasticsearch_932215d6fac6519706d9542721d9f18913f9a80d	buggy:  .put( "index.shard.check_index ",  true)  context:  .setCreate(true)  .setSource(json)  .execute().actionGet();  indexCounter.incrementAndGet();  }  public  static  void  main(String[]  args)  throws  Exception  {  System.setProperty( "es.logger.prefix ",   " ");  Settings  settings  =  settingsBuilder()                  .put( "index.shard.check_index ",  true)                  .put( "index.shard.check_on_startup ",  true)  .put( "gateway.type ",   "none ")  .put( "path.data ",   "data/data1,data/data2 ")  .build();  RollingRestartStressTest  test  =  new  RollingRestartStressTest()  .settings(settings)  .numberOfNodes(4)  .numberOfShards(5)  	.put( "index.shard.check_on_startup ",  true)  
elasticsearch_4824f05369e7445cc25de3c72e799a8fbbe34a40	buggy:  ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks()).removeGlobalBlock(Discovery.NO_MASTER_BLOCK);  context:  final  LocalDiscovery  master  =  firstMaster;  clusterService.submitStateUpdateTask( "local-disco-initial_connect(master) ",  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  DiscoveryNodes.Builder  nodesBuilder  =  DiscoveryNodes.builder();  for  (LocalDiscovery  discovery  :  clusterGroups.get(clusterName).members())  {  nodesBuilder.put(discovery.localNode);  }  nodesBuilder.localNodeId(master.localNode().id()).masterNodeId(master.localNode().id());                          ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks()).removeGlobalBlock(Discovery.NO_MASTER_BLOCK);                          ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks()).removeGlobalBlock(discoverySettings.getNoMasterBlock());  return  ClusterState.builder(currentState).nodes(nodesBuilder).blocks(blocks).build();  }  public  void  onFailure(String  source,  Throwable  t)  {  }  	ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks()).removeGlobalBlock(discoverySettings.getNoMasterBlock());  
elasticsearch_80fa91d873a838e12379037e27ce5656a7e8db95	buggy:  AsyncAction.this.addShardFailure(shardIndex,  t);  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  public  void  onFailure(Throwable  t)  {  if  (logger.isDebugEnabled())  {  }                      AsyncAction.this.addShardFailure(shardIndex,  t);                      AsyncAction.this.addShardFailure(shardIndex,  shardTarget,  t);  successulOps.decrementAndGet();  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  	AsyncAction.this.addShardFailure(shardIndex,  shardTarget,  t);  
libgdx_31ff891183b1faf5c2e1735f42b9e067fea335d2	buggy:  if  (!handle.parent().exists())  fail();  context:  private  void  testLocal  ()  throws  IOException  {  String  path  =   "meow ";  FileHandle  handle  =  Gdx.files.local(path);  handle.delete();  if  (handle.exists())  fail();  if  (handle.isDirectory())  fail();  if  (handle.delete())  fail();  if  (handle.list().length  !=  0)  fail();  if  (handle.child( "meow ").exists())  fail();  if  (!handle.parent().exists())  fail();  if  (handle.parent().exists())  fail();  try  {  handle.read().close();  fail();  }  catch  (Exception  ignored)  {  }  handle.mkdirs();  if  (!handle.exists())  fail();  if  (!handle.isDirectory())  fail();  	if  (handle.parent().exists())  fail();  
libgdx_3462817917f66952dd99872a1f36b290161ffd46	buggy:  return  buttons.contains(  button  );  context:  public  boolean  isButtonDown(  int  button  )  {  return  buttons.contains(  button  );  return  buttons.size()  >  0;  }  	return  buttons.size()  >  0;  
libgdx_6bd78bbd5ddb3905dc4c47abdd76fe3d2a6c59f3	buggy:  prefHeight  =  background.getTotalHeight();  context:  layout();  this.width  =  prefWidth;  this.height  =  prefHeight;  }  public  void  layout  ()  {  final  NinePatch  background  =  style.background;  final  BitmapFont  font  =  style.font;  prefHeight  =  background.getTotalHeight();  prefHeight  =  Math.max(font.getLineHeight()  -  font.getDescent(),  background.getTotalHeight());  float  max  =  0;  for  (int  i  =  0;  i  <  entries.length;  i++)  {  max  =  Math.max(font.getBounds(entries[i]).width,  max);  }  prefWidth  =  background.getLeftWidth()  +  background.getRightWidth()  +  max;  invalidated  =  false;  }  	prefHeight  =  Math.max(font.getLineHeight()  -  font.getDescent(),  background.getTotalHeight());  
elasticsearch_fd5719b2324367e73df6e09fa8a592381a3f8b44	buggy:  valueBytes  =  smartNameFieldMappers.mapper().indexedValue(value);  context:  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  query ");  }  BytesRef  valueBytes  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();                  valueBytes  =  smartNameFieldMappers.mapper().indexedValue(value);                  valueBytes  =  smartNameFieldMappers.mapper().indexedValueForSearch(value);  }  }  if  (valueBytes  ==  null)  {  valueBytes  =  new  BytesRef(value);  }  SpanTermQuery  query  =  new  SpanTermQuery(new  Term(fieldName,  valueBytes));  query.setBoost(boost);  	valueBytes  =  smartNameFieldMappers.mapper().indexedValueForSearch(value);  
elasticsearch_314a3343f93a4af884c117113e23b70f347ae534	buggy:  SearchResponse  searchResponse  =  client().prepareSearch()  context:  for  (int  i  =  10;  i  <  20;  i++)  {  client().prepareIndex( "unmapped_idx ",   "type ",   " "+i).setSource(jsonBuilder().startObject()  .field( "mapped ",   " "+i)  .endObject()).execute().actionGet();  }  client().admin().indices().prepareFlush().setRefresh(true).execute().actionGet();          SearchResponse  searchResponse  =  client().prepareSearch()          SearchResponse  searchResponse  =  client().prepareSearch( "mapped_idx ",   "unmapped_idx ")  .setQuery(matchAllQuery())  .addFacet(termsFacet( "mapped ").field( "mapped ").size(10))  .addFacet(termsFacet( "partially_mapped_str ").field( "partially_mapped_str ").size(10))  .addFacet(termsFacet( "partially_mapped_bool ").field( "partially_mapped_bool ").size(10))  .addFacet(termsFacet( "partially_mapped_byte ").field( "partially_mapped_byte ").size(10))  .addFacet(termsFacet( "partially_mapped_short ").field( "partially_mapped_short ").size(10))  .addFacet(termsFacet( "partially_mapped_int ").field( "partially_mapped_int ").size(10))  .addFacet(termsFacet( "partially_mapped_long ").field( "partially_mapped_long ").size(10))  	SearchResponse  searchResponse  =  client().prepareSearch( "mapped_idx ",   "unmapped_idx ")  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  font  =  new  BitmapFont();  context:  Texture  texture  =  new  Texture(Gdx.files.internal( "data/layers.png "));  layers  =  new  TextureRegion[3];  layers[0]  =  new  TextureRegion(texture,  0,  0,  542,  363);  layers[1]  =  new  TextureRegion(texture,  0,  363,  1024,  149);  layers[2]  =  new  TextureRegion(texture,  547,  0,  224,  51);  camera  =  new  ParallaxCamera(480,  320);  controller  =  new  OrthoCamController(camera);  Gdx.input.setInputProcessor(controller);  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  }  public  void  render  ()  {  Gdx.gl.glClearColor(242  /  255.0f,  210  /  255.0f,  111  /  255.0f,  1);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_8ecf71ffb8a73a4b16f5b5c29b752fd094fa787a	buggy:  return   "boundAddress  [ "  +  boundAddress  +   "],  publishAddress  [ "  +  publishAddress  +   "] ";  context:  public  TransportAddress  boundAddress()  {  return  boundAddress;  }  public  TransportAddress  publishAddress()  {  return  publishAddress;  }          return   "boundAddress  [ "  +  boundAddress  +   "],  publishAddress  [ "  +  publishAddress  +   "] ";          return   "bound_address[ "  +  boundAddress  +   "],  publish_address[ "  +  publishAddress  +   "] ";  }  }  	return   "bound_address[ "  +  boundAddress  +   "],  publish_address[ "  +  publishAddress  +   "] ";  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  context:  sortFields.add(SORT_DOC);  }  }  else  {  FieldMapper  fieldMapper  =  context.smartNameFieldMapper(fieldName);  if  (fieldMapper  ==  null)  {  if  (ignoreUnmapped)  {  return;  }  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "]  in  order  to  sort  on ");  }              sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));              sortFields.add(new  SortField(fieldMapper.names().indexName(),  context.fieldData().getForField(fieldMapper).comparatorSource(missing),  reverse));  }  }  }  	sortFields.add(new  SortField(fieldMapper.names().indexName(),  context.fieldData().getForField(fieldMapper).comparatorSource(missing),  reverse));  
elasticsearch_27a84afe24a6768d1e8253ad8b8016699bd53641	buggy:  .addCell( "p/r ",   "default:true;desc:primary  or  replica ")  context:  }  });  }  Table  getTableWithHeader(final  RestRequest  request)  {  Table  table  =  new  Table();  table.startHeaders()  .addCell( "index ",   "default:true;desc:index  name ")  .addCell( "shard ",   "default:true;desc:shard  name ")                  .addCell( "p/r ",   "default:true;desc:primary  or  replica ")                  .addCell( "prirep ",   "alias:pr,primaryOrReplica;default:true;desc:primary  or  replica ")  .addCell( "state ",   "default:true;desc:shard  state ")  .addCell( "docs ",   "text-align:right;desc:number  of  docs  in  shard ")  .addCell( "store ",   "text-align:right;desc:store  size  of  shard  (how  much  disk  it  uses) ")  .addCell( "ip ",   "default:true;desc:ip  of  node  where  it  lives ")  .addCell( "node ",   "default:true;desc:name  of  node  where  it  lives ");  table.addCell( "total.completion.size ",   "alias:tcs,totalCompletionSize;default:false;text-align:right;desc:size  of  completion ");  	.addCell( "prirep ",   "alias:pr,primaryOrReplica;default:true;desc:primary  or  replica ")  
libgdx_9cda1aa96cdefd0476707c92a4fa97337e731a51	buggy:  GdxTest  test  =  new  Bresenham2Test();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  Bresenham2Test();  GdxTest  test  =  new  VoxelTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.width  =  1024;  config.height  =  768;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  VoxelTest();  
elasticsearch_8a62619fb94d862b16687087b869cadf5bf9849c	buggy:  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "an  alias  with  the  same  name  already  exists ");  context:  if  (!request.index.equals(riverIndexName)  &&  request.index.charAt(0)  ==  '_')  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  not  start  with  '_' ");  }  if  (!request.index.toLowerCase(Locale.ROOT).equals(request.index))  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  be  lowercase ");  }  if  (!Strings.validFileName(request.index))  {  throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "must  not  contain  the  following  characters   "  +  Strings.INVALID_FILENAME_CHARS);  }  if  (state.metaData().aliases().containsKey(request.index))  {              throw  new  InvalidIndexNameException(new  Index(request.index),  request.index,   "an  alias  with  the  same  name  already  exists ");              throw  new  IndexAlreadyExistsException(new  Index(request.index),   "already  exists  as  alias ");  }  }  public  static  interface  Listener  {  void  onResponse(Response  response);  void  onFailure(Throwable  t);  	throw  new  IndexAlreadyExistsException(new  Index(request.index),   "already  exists  as  alias ");  
elasticsearch_2cb40fcb1741ce1bf4c770aeec8b85717f2b5d98	buggy:  ShardDeleteResponse  response  =  new  ShardDeleteResponse(delete.version(),  delete.notFound());  context:  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_delete ").force(false));  }  catch  (Exception  e)  {  }  }          ShardDeleteResponse  response  =  new  ShardDeleteResponse(delete.version(),  delete.notFound());          ShardDeleteResponse  response  =  new  ShardDeleteResponse(delete.version(),  delete.found());  return  new  PrimaryResponse<ShardDeleteResponse,  ShardDeleteRequest>(shardRequest.request,  response,  null);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  ShardDeleteRequest  request  =  shardRequest.request;  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  Engine.Delete  delete  =  indexShard.prepareDelete(request.type(),  request.id(),  request.version())  	ShardDeleteResponse  response  =  new  ShardDeleteResponse(delete.version(),  delete.found());  
libgdx_1010849a882df4e5458e4b3cd24038ae03d790a1	buggy:  boolean  is64Bit  =  System.getProperty( "os.arch ").equals( "amd64 ");  context:  public  synchronized  void  load  (String  sharedLibName)  {  if  (loadedLibraries.contains(sharedLibName))  return;  boolean  isWindows  =  System.getProperty( "os.name ").contains( "Windows ");  boolean  isLinux  =  System.getProperty( "os.name ").contains( "Linux ");  boolean  isMac  =  System.getProperty( "os.name ").contains( "Mac ");  boolean  isAndroid  =  false;  boolean  is64Bit  =  System.getProperty( "os.arch ").equals( "amd64 ");  boolean  is64Bit  =  System.getProperty( "os.arch ").equals( "amd64 ")  ||  System.getProperty( "os.arch ").equals( "x86_64 ");  String  vm  =  System.getProperty( "java.vm.name ");  if  (vm  !=  null  &&  vm.contains( "Dalvik "))  {  isAndroid  =  true;  isWindows  =  false;  isLinux  =  false;  isMac  =  false;  is64Bit  =  false;  }  	boolean  is64Bit  =  System.getProperty( "os.arch ").equals( "amd64 ")  ||  System.getProperty( "os.arch ").equals( "x86_64 ");  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  cnt.set(min).add(max).mul(0.5f);  context:  public  BoundingBox  set  (Vector3  minimum,  Vector3  maximum)  {  min.set(minimum.x  <  maximum.x  ?  minimum.x  :  maximum.x,  minimum.y  <  maximum.y  ?  minimum.y  :  maximum.y,  minimum.z  <  maximum.z  ?  minimum.z  :  maximum.z);  max.set(minimum.x  >  maximum.x  ?  minimum.x  :  maximum.x,  minimum.y  >  maximum.y  ?  minimum.y  :  maximum.y,  minimum.z  >  maximum.z  ?  minimum.z  :  maximum.z);  cnt.set(min).add(max).mul(0.5f);  cnt.set(min).add(max).scl(0.5f);  dim.set(max).sub(min);  crn_dirty  =  true;  return  this;  }  	cnt.set(min).add(max).scl(0.5f);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  }  }  });  }  private  SearchRequest  parseSearchRequest(RestRequest  request)  {  String[]  indices  =  RestActions.splitIndices(request.param( "index "));  SearchRequest  searchRequest  =  new  SearchRequest(indices);  if  (request.hasContent())  {              searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());              searchRequest.source(request.content(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  searchRequest.source(source);  }  }  searchRequest.extraSource(parseSearchSource(request));  	searchRequest.source(request.content(),  request.contentUnsafe());  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  translog.close(true);  context:  protected  Translog  translog;  public  void  setUp()  {  translog  =  create();  translog.newTranslog(1);  }  public  void  tearDown()  {          translog.close(true);          translog.closeWithDelete();  }  protected  abstract  Translog  create();  public  void  testRead()  throws  IOException  {  Translog.Location  loc1  =  translog.add(new  Translog.Create( "test ",   "1 ",  new  byte[]{1}));  Translog.Location  loc2  =  translog.add(new  Translog.Create( "test ",   "2 ",  new  byte[]{2}));  	translog.closeWithDelete();  
libgdx_ebfd2fac3157b88107476429145ed8aaa4208452	buggy:  Color  color  =  this.tempColor;  context:  }  public  void  setColor  (float  color)  {  this.color  =  color;  }  public  Color  getColor  ()  {  int  intBits  =  NumberUtils.floatToIntColor(color);  Color  color  =  this.tempColor;  Color  color  =  tempColor;  color.r  =  (intBits  &  0xff)  /  255f;  color.g  =  ((intBits  >>>  8)  &  0xff)  /  255f;  color.b  =  ((intBits  >>>  16)  &  0xff)  /  255f;  color.a  =  ((intBits  >>>  24)  &  0xff)  /  255f;  return  color;  }  	Color  color  =  tempColor;  
elasticsearch_00665663575b3d42bd3beeb6b3b558ffdb9e7306	buggy:  TermsLookup  termsLookup  =  new  TermsLookup(fieldMapper,  lookupIndex,  lookupType,  lookupId,  lookupPath);  context:  fieldName  =  fieldMapper.names().indexName();  }  if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  }  }  if  (lookupId  !=  null)  {              TermsLookup  termsLookup  =  new  TermsLookup(fieldMapper,  lookupIndex,  lookupType,  lookupId,  lookupPath);              TermsLookup  termsLookup  =  new  TermsLookup(fieldMapper,  lookupIndex,  lookupType,  lookupId,  lookupPath,  parseContext);  if  (cacheKey  ==  null)  {  cacheKey  =  new  CacheKeyFilter.Key(termsLookup.toString());  }  Filter  filter  =  termsFilterCache.lookupTermsFilter(cacheKey,  termsLookup);  filter  =  parseContext.cacheFilter(filter,  null);  //  cacheKey  is  passed  as  null,  so  we  don't  double  cache  the  key  return  filter;  }  	TermsLookup  termsLookup  =  new  TermsLookup(fieldMapper,  lookupIndex,  lookupType,  lookupId,  lookupPath,  parseContext);  
libgdx_015764fe472f9b7e2aee8ab616a883ad2996452d	buggy:  int  result  =  (int)type;  context:  this(copyFrom.type,  copyFrom.textureDescription);  }  public  Attribute  copy  ()  {  return  new  CubemapAttribute(this);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  967  *  result  +  textureDescription.hashCode();  return  result;  }  }  	int  result  =  super.hashCode();  
libgdx_a80a00bddd5ff73ddfc8c64e70ba3e12218da5dd	buggy:  BitmapFont  font  =  skin.getResource( "default-font ",  BitmapFont.class);  context:  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  stage.act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30f));  stage.draw();  Table.drawDebug(stage);  float  x  =  40,  y  =  40;  BitmapFont  font  =  skin.getResource( "default-font ",  BitmapFont.class);  BitmapFont  font  =  skin.getFont( "default-font ");  batch.begin();  font.draw(batch,   "The  quick  brown  fox  jumped  over  the  lazy  cow. ",  x,  y);  batch.end();  drawLine(x,  y  -  font.getDescent(),  x  +  1000,  y  -  font.getDescent());  drawLine(x,  y  -  font.getCapHeight()  +  font.getDescent(),  x  +  1000,  y  -  font.getCapHeight()  +  font.getDescent());  }  	BitmapFont  font  =  skin.getFont( "default-font ");  
libgdx_08522762e746b0e4388d2d92f16741a5d5ba5ef7	buggy:  if  (parent  instanceof  Group)  {  context:  if  (Gdx.graphics.isGL20Available())  debugRenderer  =  new  ImmediateModeRenderer20(64,  false,  true,  0);  else  debugRenderer  =  new  ImmediateModeRenderer10(64);  }  Table  table  =  getTable();  Actor  parent  =  table.parent;  float  x  =  table.x,  y  =  0;  while  (parent  !=  null)  {  if  (parent  instanceof  Group)  {  if  (parent  instanceof  Group  &&  ((Group)parent).transform)  {  x  +=  parent.x;  y  =  parent.y  +  parent.height  -  y;  }  parent  =  parent.parent;  }  y  =  table.y  +  table.height  -  y;  int  viewHeight  =  Gdx.graphics.getHeight();  	if  (parent  instanceof  Group  &&  ((Group)parent).transform)  {  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Long.MIN_VALUE;  context:  this.nullValue  =  nullValue;  }  return  64;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Long.MIN_VALUE;              return  null;  }  return  Numbers.bytesToLong(value);  }  	return  null;  
libgdx_9679f9fafb06ce0f80b6d4458f3b1095421fac61	buggy:  return  current  >  count;  context:  public  class  CountdownEventAction<T  extends  Event>  extends  EventAction<T>  {  int  count,  current;  public  CountdownEventAction  (Class<?  extends  T>  eventClass,  int  count)  {  super(eventClass);  this.count  =  count;  }  public  boolean  handle  (T  event)  {  current++;  return  current  >  count;  return  current  >=  count;  }  }  	return  current  >=  count;  
libgdx_9844f1f930c6a1154871f9cc8489873f16063868	buggy:  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/uiTexture.png ",  FileType.Internal  ),  context:  Group  group  =  new  Group(   "group "  +  i  );  group.x  =  (float)Math.random()  *  (stage.width()  -  NUM_SPRITES  *  (32  +  SPACING));  group.y  =  (float)Math.random()  *  (stage.height()  -  NUM_SPRITES  *  (32  +  SPACING));  group.originX  =  loc;  group.originY  =  loc;  fillGroup(  group,  texture  );  stage.addActor(  group  );  }  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/uiTexture.png ",  FileType.Internal  ),  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/ui.png ",  FileType.Internal  ),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge  );  ui  =  new  Stage(  480,  320,  false  );  Image  blend  =  new  Image(   "blend  button ",  new  TextureRegion(  uiTexture,  0,  0,  64,  32  )  );  blend.y  =  ui.height()  -  32;  Image  rotate  =  new  Image(   "rotate  button ",  new  TextureRegion(  uiTexture,  64,  0,  64,  32  )  );  rotate.y  =  blend.y;  rotate.x  =  64;  Image  scale  =  new  Image(   "scale  button ",  new  TextureRegion(  uiTexture,  64,  32,  64,  32  )  );  	uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/ui.png ",  FileType.Internal  ),  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  cluster().wipeIndices( "test ");  context:  refresh();  assertThat(awaitBusy(new  Predicate<Object>()  {  public  boolean  apply(Object  input)  {  IndicesStatsResponse  indicesStatsResponse  =  client().admin().indices().prepareStats( "test ").clear().setIndexing(true).get();  return  indicesStatsResponse.getIndices().get( "test ").getTotal().getIndexing().getTotal().getDeleteCount()  !=  0;  }  },  5,  TimeUnit.SECONDS),  equalTo(true));          cluster().wipeIndices( "test ");          internalCluster().wipeIndices( "test ");  client().admin().indices().prepareCreate( "test ")  .addMapping( "type1 ",  typeMapping)  .execute().actionGet();  }  }  	internalCluster().wipeIndices( "test ");  
elasticsearch_4194ab31c8d92edc10b88411fffc779a8706d515	buggy:  flush(new  Flush().type(Flush.Type.NEW_WRITER));  context:  if  (indexWriter  !=  null)  {  indexWriter.getConfig().setRAMBufferSizeMB(this.indexingBufferSize.mbFrac());  }  }  if  (preValue.bytes()  !=  indexingBufferSize.bytes())  {  if  (indexingBufferSize  ==  Engine.INACTIVE_SHARD_INDEXING_BUFFER  &&  preValue  !=  Engine.INACTIVE_SHARD_INDEXING_BUFFER)  {  try  {                      flush(new  Flush().type(Flush.Type.NEW_WRITER));                      flush(new  Flush().type(Flush.Type.COMMIT));  }  catch  (EngineClosedException  e)  {  }  catch  (FlushNotAllowedEngineException  e)  {  }  catch  (Throwable  e)  {  }  }  else  {  	flush(new  Flush().type(Flush.Type.COMMIT));  
libgdx_989e66f74ee1797beacdba45b068b4c4e16dedb2	buggy:  input  =  new  AndroidInput(this,  this.getService(),  null,  config);  context:  protected  final  Array<Runnable>  executedRunnables  =  new  Array<Runnable>();  protected  int  logLevel  =  LOG_INFO;  public  AndroidLiveWallpaper(WallpaperService  service,  Engine  engine)  {  this.service  =  service;  this.engine  =  engine;  }  public  void  initialize(ApplicationListener  listener,  AndroidApplicationConfiguration  config)  {  graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config.useGL20,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  input  =  new  AndroidInput(this,  this.getService(),  null,  config);  input  =  AndroidInputFactory.newAndroidInput(this,  this.getService(),  null,  config);  audio  =  new  AndroidAudio(this.getService(),  config);  files  =  new  AndroidFiles(this.getService().getAssets());  this.listener  =  listener;  Gdx.app  =  this;  Gdx.input  =  this.getInput();  Gdx.audio  =  this.getAudio();  Gdx.files  =  this.getFiles();  	input  =  AndroidInputFactory.newAndroidInput(this,  this.getService(),  null,  config);  
libgdx_78bed2c6254daac8057dd18d56728a295f3bd00f	buggy:  draw(region,  x,  y,  Math.abs(region.getRegion().getRegionWidth()),  Math.abs(region.getRegion().getRegionHeight()));  context:  Color  color  =  this.tempColor;  color.r  =  (intBits  &  0xff)  /  255f;  color.g  =  ((intBits  >>>  8)  &  0xff)  /  255f;  color.b  =  ((intBits  >>>  16)  &  0xff)  /  255f;  color.a  =  ((intBits  >>>  24)  &  0xff)  /  255f;  return  color;  }  public  void  draw  (PolygonRegion  region,  float  x,  float  y)  {  draw(region,  x,  y,  Math.abs(region.getRegion().getRegionWidth()),  Math.abs(region.getRegion().getRegionHeight()));  draw(region,  x,  y,  region.getRegion().getRegionWidth(),  region.getRegion().getRegionHeight());  }  public  void  draw  (PolygonRegion  region,  float  x,  float  y,  float  width,  float  height)  {  if  (!drawing)  throw  new  IllegalStateException( "PolygonSpriteBatch.begin  must  be  called  before  draw. ");  Texture  texture  =  region.getRegion().texture;  if  (texture  !=  lastTexture)  {  	draw(region,  x,  y,  region.getRegion().getRegionWidth(),  region.getRegion().getRegionHeight());  
elasticsearch_f869951364ef1c5f437b65e4bb8004283cb69ecb	buggy:  DocumentMapper  documentMapper  =  context.mapperService().type(hit.type());  context:  return  ImmutableMap.of( "highlight ",  new  HighlighterParseElement());  }  return  context.highlight()  !=  null;  }  try  {              DocumentMapper  documentMapper  =  context.mapperService().type(hit.type());              DocumentMapper  documentMapper  =  context.mapperService().documentMapper(hit.type());  Map<String,  HighlightField>  highlightFields  =  newHashMap();  for  (SearchContextHighlight.Field  field  :  context.highlight().fields())  {  FieldMapper  mapper  =  documentMapper.mappers().smartNameFieldMapper(field.field());  if  (mapper  ==  null)  {  throw  new  SearchException(context.shardTarget(),   "No  mapping  found  for  [ "  +  field.field()  +   "] ");  }  	DocumentMapper  documentMapper  =  context.mapperService().documentMapper(hit.type());  
elasticsearch_b078c9206a71d639ee76fa5b6a8b44344e797d98	buggy:  return  BlobStoreIndexShardGateway.aggregateParts(indexContainer.listBlobs());  context:  this.gateway  =  (BlobStoreGateway)  gateway;  this.blobStore  =  this.gateway.blobStore();  this.chunkSize  =  componentSettings.getAsBytesSize( "chunk_size ",  this.gateway.chunkSize());  this.indexPath  =  this.gateway.basePath().add( "indices ").add(index.name());  }  public  ImmutableMap<String,  BlobMetaData>  listIndexBlobs(int  shardId)  throws  IOException  {  ImmutableBlobContainer  indexContainer  =  blobStore.immutableBlobContainer(shardIndexPath(shardId));          return  BlobStoreIndexShardGateway.aggregateParts(indexContainer.listBlobs());          return  BlobStoreIndexShardGateway.buildVirtualBlobs(indexContainer,  indexContainer.listBlobs(),  null);  }  return  type()  +   ":// "  +  blobStore  +   "/ "  +  indexPath;  }  public  BlobStore  blobStore()  {  return  blobStore;  	return  BlobStoreIndexShardGateway.buildVirtualBlobs(indexContainer,  indexContainer.listBlobs(),  null);  
libgdx_db3b817cbcd5c9551fdfbb99567b754e336018be	buggy:  if(new  FileWrapper(token).exists())  {  context:  return  null;  }  String  paths  =  assetPathProperty.getValues().get(0);  if(paths  ==  null)  {  return  null;  }  else  {  ArrayList<String>  existingPaths  =  new  ArrayList<String>();  String[]  tokens  =  paths.split( ", ");  String  path  =  null;  for(String  token:  tokens)  {  if(new  FileWrapper(token).exists())  {  if  (new  FileWrapper(token).exists()  ||  new  FileWrapper(token).mkdirs())  {  path  =  token;  }  }  if  (path  !=  null  &&  !path.endsWith( "/ ")){  path  +=   "/ ";  }  return  path;  }  	if  (new  FileWrapper(token).exists()  ||  new  FileWrapper(token).mkdirs())  {  
elasticsearch_82cc227da32b35b96e49a4a684e251be6c904539	buggy:  if  (script  !=  null)  {  context:  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeByte(replicationType.id());  out.writeByte(consistencyLevel.id());  out.writeSharedString(type);  out.writeString(id);  out.writeOptionalString(routing);  out.writeOptionalString(script);          if  (script  !=  null)  {          if  (script  !=  null  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {  ScriptService.ScriptType.writeTo(scriptType,  out);  }  out.writeOptionalString(scriptLang);  out.writeMap(scriptParams);  out.writeVInt(retryOnConflict);  out.writeBoolean(refresh);  if  (doc  ==  null)  {  out.writeBoolean(false);  	if  (script  !=  null  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {  
elasticsearch_9d979dfc015ee8de43a1080d817f48a1583b8ae9	buggy:  return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.network(),  request.transport(),  request.http());  context:  }  protected  NodeInfo  newNodeResponse()  {  return  new  NodeInfo();  }  protected  NodeInfo  nodeOperation(NodeInfoRequest  nodeRequest)  throws  ElasticSearchException  {  NodesInfoRequest  request  =  nodeRequest.request;          return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.network(),  request.transport(),  request.http());          return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeInfoRequest  extends  NodeOperationRequest  {  	return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.Gateway.SNAPSHOT;  }  return   "indices/gateway/snapshot/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_48ca7b874d8e1838764823e2f6a9fa837f1ceab4	buggy:  nodeIndexDeletedAction.nodeIndexStoreDeleted(current.index(),  event.state().nodes().masterNodeId());  context:  if  (currentMetaData  !=  null)  {  for  (IndexMetaData  current  :  currentMetaData)  {  if  (!newMetaData.hasIndex(current.index()))  {  if  (nodeEnv.hasNodeFile())  {  FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(current.index())));  }  try  {                          nodeIndexDeletedAction.nodeIndexStoreDeleted(current.index(),  event.state().nodes().masterNodeId());                          nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  current.index(),  event.state().nodes().localNodeId());  }  catch  (Exception  e)  {  }  }  }  }  currentMetaData  =  newMetaData;  	nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  current.index(),  event.state().nodes().localNodeId());  
elasticsearch_ed2196f5a58c75ea0268ac039544c123c730fbdc	buggy:  return  ThreadPool.Names.CACHE;  context:  public  class  TransportNodesHotThreadsAction  extends  TransportNodesOperationAction<NodesHotThreadsRequest,  NodesHotThreadsResponse,  TransportNodesHotThreadsAction.NodeRequest,  NodeHotThreads>  {  public  TransportNodesHotThreadsAction(Settings  settings,  ClusterName  clusterName,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  }  protected  String  executor()  {          return  ThreadPool.Names.CACHE;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return  NodesHotThreadsAction.NAME;  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_5ae12368574b33a8fad215ef104108fbf5435eb3	buggy:  return  sums.get(owningBucketOrd)  /  counts.get(owningBucketOrd);  context:  counts.increment(owningBucketOrdinal,  valueCount);  double  sum  =  0;  for  (int  i  =  0;  i  <  valueCount;  i++)  {  sum  +=  values.nextValue();  }  sums.increment(owningBucketOrdinal,  sum);  }  public  double  metric(long  owningBucketOrd)  {          return  sums.get(owningBucketOrd)  /  counts.get(owningBucketOrd);          return  valuesSource  ==  null  ?  Double.NaN  :  sums.get(owningBucketOrd)  /  counts.get(owningBucketOrd);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  if  (valuesSource  ==  null  ||  owningBucketOrdinal  >=  counts.size())  {  return  new  InternalAvg(name,  0l,  0);  }  return  new  InternalAvg(name,  sums.get(owningBucketOrdinal),  counts.get(owningBucketOrdinal));  	return  valuesSource  ==  null  ?  Double.NaN  :  sums.get(owningBucketOrd)  /  counts.get(owningBucketOrd);  
elasticsearch_8b295b53d0ec023e3a71448bf33050f60c00f123	buggy:  indexShard.refresh(new  Engine.Refresh(request.waitForOperations()));  context:  }  protected  ShardRefreshResponse  newShardResponse()  {  return  new  ShardRefreshResponse();  }  protected  ShardRefreshResponse  shardOperation(ShardRefreshRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          indexShard.refresh(new  Engine.Refresh(request.waitForOperations()));          indexShard.refresh(new  Engine.Refresh().force(request.force()));  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  RefreshRequest  request,  String[]  concreteIndices)  {  	indexShard.refresh(new  Engine.Refresh().force(request.force()));  
elasticsearch_cd4aea841a906dbe7aa877b23e8c35871ca0b9ad	buggy:  if  (nx  >=  0  &&  nx  <=  xLimit  &&  ny  >=  0  &&  ny  <  yLimit)  {  context:  final  int  ny  =  ((level  %  2)  ==  1)  ?  (y  +  dy)  :  (y  +  dx);  final  int  xLimit  =  ((level  %  2)  ==  0)  ?  7  :  3;  final  int  yLimit  =  ((level  %  2)  ==  0)  ?  3  :  7;              if  (nx  >=  0  &&  nx  <=  xLimit  &&  ny  >=  0  &&  ny  <  yLimit)  {              if  (nx  >=  0  &&  nx  <=  xLimit  &&  ny  >=  0  &&  ny  <=  yLimit)  {  return  geohash.substring(0,  level  -  1)  +  encode(nx,  ny);  }  else  {  String  neighbor  =  neighbor(geohash,  level  -  1,  dx,  dy);  if(neighbor  !=  null)  {  return  neighbor  +  encode(nx,  ny);  }  else  {  return  null;  }  	if  (nx  >=  0  &&  nx  <=  xLimit  &&  ny  >=  0  &&  ny  <=  yLimit)  {  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  try  {  Map<String,  Object>  source  =  XContentFactory.xContent(request.content()).createParser(request.content()).mapAndClose();  if  (source.containsKey( "transient "))  {  clusterUpdateSettingsRequest.transientSettings((Map)  source.get( "transient "));  }  if  (source.containsKey( "persistent "))  {  clusterUpdateSettingsRequest.persistentSettings((Map)  source.get( "persistent "));  }  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                  channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  client.admin().cluster().updateSettings(clusterUpdateSettingsRequest,  new  AcknowledgedRestResponseActionListener<ClusterUpdateSettingsResponse>(request,  channel,  logger)  {  	channel.sendResponse(new  BytesRestResponse(request,  e));  
libgdx_4bfa5a9a87603d026360aaedfc7771a07d77845a	buggy:  int  lineEnd  =  start  +  font.computeVisibleGlpyhs(str,  start,  BitmapFont.indexOf(str,  '\n',  start),  wrapWidth);  context:  int  length  =  str.length();  reset(length);  y  +=  font.ascent;  float  down  =  font.down;  int  maxWidth  =  0;  int  start  =  0;  int  numLines  =  0;  while  (start  <  length)  {  int  lineEnd  =  start  +  font.computeVisibleGlpyhs(str,  start,  BitmapFont.indexOf(str,  '\n',  start),  wrapWidth);  int  lineEnd  =  start  +  font.computeVisibleGlyphs(str,  start,  BitmapFont.indexOf(str,  '\n',  start),  wrapWidth);  if  (lineEnd  <  length)  {  while  (lineEnd  >  start)  {  char  ch  =  str.charAt(lineEnd);  if  (ch  ==  '  '  ||  ch  ==  '\n')  break;  lineEnd--;  }  }  if  (lineEnd  ==  start)  lineEnd++;  	int  lineEnd  =  start  +  font.computeVisibleGlyphs(str,  start,  BitmapFont.indexOf(str,  '\n',  start),  wrapWidth);  
elasticsearch_86a883b4bfd5b8a08c849da4a312fb7a6cec7356	buggy:  boolean  helpWanted  =  request.paramAsBoolean( "h ",  false);  context:  sb.append(CAT).append( "  try:\n ");  for  (AbstractCatAction  catAction  :  catActions)  {  catAction.documentation(sb);  }  HELP  =  sb.toString();  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  try  {              boolean  helpWanted  =  request.paramAsBoolean( "h ",  false);              boolean  helpWanted  =  request.paramAsBoolean( "h ",  request.paramAsBoolean( "help ",  false));  if  (helpWanted)  {  channel.sendResponse(new  StringRestResponse(RestStatus.OK,  HELP));  }  else  {  channel.sendResponse(new  StringRestResponse(RestStatus.OK,  CAT_NL));  }  }  catch  (Throwable  t)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  t));  	boolean  helpWanted  =  request.paramAsBoolean( "h ",  request.paramAsBoolean( "help ",  false));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  fieldsAndWeights  =  new  HashMap<String,  Float>();  context:  fField  =  new  String(text,  parser.textOffset(),  relativeLocation);  fBoost  =  Float.parseFloat(new  String(text,  i  +  1,  parser.textLength()  -  relativeLocation  -  1));  break;  }  }  if  (fField  ==  null)  {  fField  =  parser.text();  }  if  (fieldsAndWeights  ==  null)  {                              fieldsAndWeights  =  new  HashMap<String,  Float>();                              fieldsAndWeights  =  new  HashMap<>();  }  if  (Regex.isSimpleMatchPattern(fField))  {  for  (String  fieldName  :  parseContext.mapperService().simpleMatchToIndexNames(fField))  {  fieldsAndWeights.put(fieldName,  fBoost);  }  }  else  {  MapperService.SmartNameFieldMappers  mappers  =  parseContext.smartFieldMappers(fField);  	fieldsAndWeights  =  new  HashMap<>();  
elasticsearch_49c74e08859736d09add31436554dfa76e395dd8	buggy:  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  context:  searchService.sendExecuteScan(node,  request,  listener);  }  protected  void  moveToSecondPhase()  throws  Exception  {  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(SearchPhaseController.EMPTY_DOCS,  firstResults,  (AtomicArray<?  extends  FetchSearchResultProvider>)  AtomicArray.empty());  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  firstResults,  ImmutableMap.of( "total_hits ",  Long.toString(internalResponse.hits().totalHits())));  }              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "indexName ",  names.indexNameClean());  context:  return  new  Field(names.indexName(),  value,  Field.Store.YES);  }  return  JSON_TYPE;  }  builder.startObject(names.name());  builder.field( "type ",  jsonType());          builder.field( "indexName ",  names.indexNameClean());          builder.field( "index_name ",  names.indexNameClean());  builder.endObject();  }  }  	builder.field( "index_name ",  names.indexNameClean());  
elasticsearch_85065f9c8e9d06df37054f5c556dfdb00ee18f8d	buggy:  public  void  rescore(TopDocs  topDocs,  SearchContext  context,  RescoreSearchContext  rescoreContext)  throws  IOException;  context:      public  void  rescore(TopDocs  topDocs,  SearchContext  context,  RescoreSearchContext  rescoreContext)  throws  IOException;      public  TopDocs  rescore(TopDocs  topDocs,  SearchContext  context,  RescoreSearchContext  rescoreContext)  throws  IOException;  	public  TopDocs  rescore(TopDocs  topDocs,  SearchContext  context,  RescoreSearchContext  rescoreContext)  throws  IOException;  
elasticsearch_2cbe9371d289f85219ed1d6e1f0ee121cde2f5b7	buggy:  +   "  Increase  RLIMIT_MEMLOCK  or  run  elasticsearch  as  root. ");  context:  }  }  catch  (UnsatisfiedLinkError  e)  {  return;  }  if  (errno  !=  Integer.MIN_VALUE)  {  if  (errno  ==  CLibrary.ENOMEM  &&  System.getProperty( "os.name ").toLowerCase(Locale.ROOT).contains( "linux "))  {   "  This  can  result  in  part  of  the  JVM  being  swapped  out. "                          +   "  Increase  RLIMIT_MEMLOCK  or  run  elasticsearch  as  root. ");                          +   "  Increase  RLIMIT_MEMLOCK  (ulimit). ");  }  else  if  (!System.getProperty( "os.name ").toLowerCase(Locale.ROOT).contains( "mac "))  {  }  }  }  }  	+   "  Increase  RLIMIT_MEMLOCK  (ulimit). ");  
libgdx_076c3def06e696ae3c0c2bdd9c1fbe814b132f90	buggy:  renderer.begin(ShapeType.Triangle);  context:  renderer.setColor(1,  1,  1,  1);  renderer.begin(ShapeType.Line);  for  (int  j  =  0;  j  <  coords.length  -  2;  j  +=  2)  {  renderer.line(coords[j],  coords[j  +  1],  coords[j  +  2],  coords[j  +  3]);  }  renderer.line(coords[0],  coords[1],  coords[coords.length  -  2],  coords[coords.length  -  1]);  renderer.end();  renderer.setColor(1,  0,  0,  1);  renderer.translate(0,  -4,  0);  renderer.begin(ShapeType.Triangle);  renderer.begin(ShapeType.Filled);  for  (int  i  =  0;  i  <  triangles.size();  i  +=  3)  {  Vector2  v1  =  triangles.get(i);  Vector2  v2  =  triangles.get(i  +  1);  Vector2  v3  =  triangles.get(i  +  2);  renderer.triangle(v1.x,  v1.y,  v2.x,  v2.y,  v3.x,  v3.y);  }  renderer.end();  renderer.identity();  	renderer.begin(ShapeType.Filled);  
elasticsearch_8f9693063820fb7417c53e7fbe8b10ddcd16c422	buggy:  getRequest.realtime(restRequest.paramAsBooleanOptional( "realtime ",  null));  context:  String  index  =  restRequest.param( "index ");  String  type  =  restRequest.param( "type ");  percolateRequest.indices(Strings.splitStringByCommaToArray(restRequest.param( "percolate_index ",  index)));  percolateRequest.documentType(restRequest.param( "percolate_type ",  type));  GetRequest  getRequest  =  new  GetRequest(index,  type,  restRequest.param( "id "));  getRequest.routing(restRequest.param( "routing "));  getRequest.preference(restRequest.param( "preference "));  getRequest.refresh(restRequest.paramAsBoolean( "refresh ",  getRequest.refresh()));          getRequest.realtime(restRequest.paramAsBooleanOptional( "realtime ",  null));          getRequest.realtime(restRequest.paramAsBoolean( "realtime ",  null));  getRequest.version(RestActions.parseVersion(restRequest));  getRequest.versionType(VersionType.fromString(restRequest.param( "version_type "),  getRequest.versionType()));  percolateRequest.getRequest(getRequest);  percolateRequest.routing(restRequest.param( "percolate_routing "));  percolateRequest.preference(restRequest.param( "percolate_preference "));  percolateRequest.source(restRequest.content(),  restRequest.contentUnsafe());  	getRequest.realtime(restRequest.paramAsBoolean( "realtime ",  null));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.value(match);  }  builder.endArray();  }  builder.endObject();  RestStatus  status  =  OK;  if  (response.getVersion()  ==  1)  {  status  =  CREATED;  }  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_c5edc0976145a61a5551053dfda8a8c3394100ee	buggy:  Preferences  prefs  =  new  LwjglPreferences(name);  context:  return  getJavaHeap();  }  Map<String,  Preferences>  preferences  =  new  HashMap<String,  Preferences>();  public  Preferences  getPreferences  (String  name)  {  if  (preferences.containsKey(name))  {  return  preferences.get(name);  }  else  {  Preferences  prefs  =  new  LwjglPreferences(name);  Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  preferences.put(name,  prefs);  return  prefs;  }  }  public  Clipboard  getClipboard  ()  {  return  new  LwjglClipboard();  	Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  
elasticsearch_96655d2505760083befd2352941337e13fbe3ef8	buggy:  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  context:  String  routing  =  null;  boolean  routingSet  =  false;  String  indexRouting  =  null;  boolean  indexRoutingSet  =  false;  String  searchRouting  =  null;  boolean  searchRoutingSet  =  false;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();                                  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {                                  }  else  if  (token.isValue())  {  if  ( "index ".equals(currentFieldName))  {  index  =  parser.text();  }  else  if  ( "alias ".equals(currentFieldName))  {  alias  =  parser.text();  }  else  if  ( "routing ".equals(currentFieldName))  {  routing  =  parser.textOrNull();  routingSet  =  true;  }  else  if  ( "indexRouting ".equals(currentFieldName)  ||   "index-routing ".equals(currentFieldName)  ||   "index_routing ".equals(currentFieldName))  {  	}  else  if  (token.isValue())  {  
libgdx_18f86a162b089e0d85a53d63abdf62155d8eea3b	buggy:  if  (config.getTouchEventsForLiveWallpaper  &&  Integer.parseInt(android.os.Build.VERSION.SDK)  <  9)  context:  public  void  initialize  (ApplicationListener  listener,  AndroidApplicationConfiguration  config)  {  if  (DEBUG)  Log.d(TAG,   "  >  AndroidLiveWallpaperService  -  initialize() ");  app.initialize(listener,  config);  if  (config.getTouchEventsForLiveWallpaper  &&  Integer.parseInt(android.os.Build.VERSION.SDK)  <  9)  if  (config.getTouchEventsForLiveWallpaper  &&  Integer.parseInt(android.os.Build.VERSION.SDK)  >=  7)  linkedEngine.setTouchEventsEnabled(true);  }  	if  (config.getTouchEventsForLiveWallpaper  &&  Integer.parseInt(android.os.Build.VERSION.SDK)  >=  7)  
elasticsearch_7340d6973dfec457fa3f325ef9725afa64227360	buggy:  clusterHealth  =  client1.admin().cluster().prepareHealth().setWaitForYellowStatus().execute().actionGet();  context:  for  (int  i  =  0;  i  <  10;  i++)  {  CountResponse  countResponse  =  client1.prepareCount().setQuery(matchAllQuery()).execute().actionGet();  assertThat(countResponse.count(),  equalTo(10l));  }  client1.admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "index.number_of_replicas ",  2)).execute().actionGet();  Thread.sleep(200);          clusterHealth  =  client1.admin().cluster().prepareHealth().setWaitForYellowStatus().execute().actionGet();          clusterHealth  =  client1.admin().cluster().prepareHealth().setWaitForYellowStatus().setWaitForActiveShards(10).execute().actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  assertThat(clusterHealth.indices().get( "test ").activePrimaryShards(),  equalTo(5));  assertThat(clusterHealth.indices().get( "test ").numberOfReplicas(),  equalTo(2));  assertThat(clusterHealth.indices().get( "test ").activeShards(),  equalTo(10));  	clusterHealth  =  client1.admin().cluster().prepareHealth().setWaitForYellowStatus().setWaitForActiveShards(10).execute().actionGet();  
elasticsearch_45a1b447599909a294ba63887bd91789c2e9b772	buggy:  return  InternalSearchResponse.EMPTY;  context:  list.add(shardDoc.doc);  }  }  public  InternalSearchResponse  merge(ScoreDoc[]  sortedDocs,  AtomicArray<?  extends  QuerySearchResultProvider>  queryResultsArr,  AtomicArray<?  extends  FetchSearchResultProvider>  fetchResultsArr)  {  List<?  extends  AtomicArray.Entry<?  extends  QuerySearchResultProvider>>  queryResults  =  queryResultsArr.asList();  List<?  extends  AtomicArray.Entry<?  extends  FetchSearchResultProvider>>  fetchResults  =  fetchResultsArr.asList();  if  (queryResults.isEmpty())  {              return  InternalSearchResponse.EMPTY;              return  InternalSearchResponse.empty();  }  QuerySearchResult  firstResult  =  queryResults.get(0).value.queryResult();  boolean  sorted  =  false;  int  sortScoreIndex  =  -1;  if  (firstResult.topDocs()  instanceof  TopFieldDocs)  {  sorted  =  true;  	return  InternalSearchResponse.empty();  
elasticsearch_683be6fc645fe3e917caeb883d3f29c63a6763a2	buggy:  boolean  transpositions  =  true;  context:  throw  new  QueryParsingException(parseContext.index(),   "[fuzzy]  query  malformed,  no  field ");  }  String  fieldName  =  parser.currentName();  String  value  =  null;  float  boost  =  1.0f;  String  minSimilarity  =   "0.5 ";  int  prefixLength  =  FuzzyQuery.defaultPrefixLength;  int  maxExpansions  =  FuzzyQuery.defaultMaxExpansions;          boolean  transpositions  =  true;          boolean  transpositions  =  false;  MultiTermQuery.RewriteMethod  rewriteMethod  =  null;  token  =  parser.nextToken();  if  (token  ==  XContentParser.Token.START_OBJECT)  {  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  {  	boolean  transpositions  =  false;  
libgdx_42229f95ed8f071850aa8b69ba2cc49b65a791fc	buggy:  world.step(Gdx.graphics.getDeltaTime(),  3,  3);  context:  boxPoly.dispose();  }  public  void  render  ()  {  long  start  =  System.nanoTime();  world.step(Gdx.graphics.getDeltaTime(),  3,  3);  world.step(Gdx.graphics.getDeltaTime(),  8,  3);  float  updateTime  =  (System.nanoTime()  -  start)  /  1000000000.0f;  GL10  gl  =  Gdx.graphics.getGL10();  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  camera.update();  camera.apply(gl);  	world.step(Gdx.graphics.getDeltaTime(),  8,  3);  
elasticsearch_6804c02e97628700e589498dbf56fde2f41aa617	buggy:  File  nodeWork  =  ((InternalNode)  node).injector().getInstance(NodeEnvironment.class).nodeLocation();  context:  bulk.add(Requests.indexRequest( "test "  +  (Math.abs(ThreadLocalRandom.current().nextInt())  %  numberOfIndices)).type( "type1 ").source(json));  indexCounter.incrementAndGet();  }  bulk.execute().actionGet();  }  client.client().admin().indices().prepareGatewaySnapshot().execute().actionGet();  client.close();  for  (Node  node  :  nodes)  {                  File  nodeWork  =  ((InternalNode)  node).injector().getInstance(NodeEnvironment.class).nodeLocation();                  File  nodeWork  =  ((InternalNode)  node).injector().getInstance(NodeEnvironment.class).nodeDataLocation();  node.close();  if  (clearNodeWork  &&  !settings.get( "gateway.type ").equals( "local "))  {  FileSystemUtils.deleteRecursively(nodeWork);  }  }  if  ((System.currentTimeMillis()  -  testStart)  >  period.millis())  {  	File  nodeWork  =  ((InternalNode)  node).injector().getInstance(NodeEnvironment.class).nodeDataLocation();  
libgdx_c2f3bd4e496421e53e4b93522f1f996c6d7d9d2b	buggy:  return  c.getName();  context:  static  public  Class  forName  (String  name)  throws  ReflectionException  {  try  {  return  ReflectionCache.forName(name).getClassOfType();  }  catch  (ClassNotFoundException  e)  {  throw  new  ReflectionException( "Class  not  found:   "  +  name);  }  }  static  public  String  getSimpleName  (Class  c)  {  return  c.getName();  return  c.getSimpleName();  }  static  public  boolean  isInstance  (Class  c,  Object  obj)  {  return  obj  !=  null  &&  isAssignableFrom(c,  obj.getClass());  }  	return  c.getSimpleName();  
elasticsearch_fe52c5665fd70fb1d628cb8108947c74e543e615	buggy:  ChunkEncoder  enc  =  new  ChunkEncoder(length);  context:  public  static  byte[]  encode(byte[]  data)  throws  IOException  {  return  encode(data,  data.length);  }  public  static  byte[]  encode(byte[]  data,  int  length)  throws  IOException  {          ChunkEncoder  enc  =  new  ChunkEncoder(length);          ChunkEncoder  enc  =  new  ChunkEncoder(length,  BufferRecycler.instance());  byte[]  result  =  encode(enc,  data,  length);  enc.close();  return  result;  }  public  static  byte[]  encode(ChunkEncoder  enc,  byte[]  data,  int  length)  throws  IOException  {  	ChunkEncoder  enc  =  new  ChunkEncoder(length,  BufferRecycler.instance());  
libgdx_9f2eee6a85cb9faacbc8cbd64396610d3a957e81	buggy:  usedIds.add(layer.tiles[y][x]);  context:  for  (File  file  :  files)  {  map  =  TiledLoader.createMap(new  FileHandle(file.getAbsolutePath()));  IntArray  usedIds  =  null;  if  (this.settings.stripUnusedTiles)  {  usedIds  =  new  IntArray(map.layers.size()  *  map.height  *  map.width);  for  (TiledLayer  layer  :  map.layers)  {  for  (int  y  =  0;  y  <  layer.tiles.length;  ++y)  {  for  (int  x  =  0;  x  <  layer.tiles[y].length;  ++x)  {  usedIds.add(layer.tiles[y][x]);  usedIds.add(layer.tiles[y][x]  &  ~0xE0000000);  }  }  }  }  for  (TileSet  set  :  map.tileSets)  {  if  (!processedTileSets.contains(set.imageName))  {  processedTileSets.add(set.imageName);  	usedIds.add(layer.tiles[y][x]  &  ~0xE0000000);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Callable<Void>>  tasks  =  new  ArrayList<Callable<Void>>(taskCount);  context:  public  void  testCreatedFlagParallelExecution()  throws  Exception  {  createIndex( "test ");  ensureGreen();  int  threadCount  =  20;  final  int  docCount  =  300;  int  taskCount  =  docCount  *  threadCount;  final  AtomicIntegerArray  createdCounts  =  new  AtomicIntegerArray(docCount);  ExecutorService  threadPool  =  Executors.newFixedThreadPool(threadCount);          List<Callable<Void>>  tasks  =  new  ArrayList<Callable<Void>>(taskCount);          List<Callable<Void>>  tasks  =  new  ArrayList<>(taskCount);  final  Random  random  =  getRandom();  for  (int  i=0;i<  taskCount;  i++  )  {  tasks.add(new  Callable<Void>()  {  public  Void  call()  throws  Exception  {  int  docId  =  random.nextInt(docCount);  IndexResponse  indexResponse  =  index( "test ",   "type ",  Integer.toString(docId),   "field1 ",   "value ");  if  (indexResponse.isCreated())  createdCounts.incrementAndGet(docId);  	List<Callable<Void>>  tasks  =  new  ArrayList<>(taskCount);  
elasticsearch_e0b280f9b3dc1bf64b35a0d009abe07f3df55686	buggy:  assert  fieldname.equals(indexFieldData.getFieldName());  context:  this.indexFieldData  =  indexFieldData;  }  public  SortField.Type  reducedType()  {  return  SortField.Type.STRING;  }  public  FieldComparator<?>  newComparator(String  fieldname,  int  numHits,  int  sortPos,  boolean  reversed)  throws  IOException  {          assert  fieldname.equals(indexFieldData.getFieldName());          assert  fieldname.equals(indexFieldData.getFieldNames().indexName());  if  (indexFieldData.valuesOrdered()  &&  indexFieldData  instanceof  IndexOrdinalFieldData)  {  return  new  BytesRefOrdValComparator((IndexOrdinalFieldData)  indexFieldData,  numHits);  }  return  new  BytesRefValComparator(indexFieldData,  numHits);  }  }  	assert  fieldname.equals(indexFieldData.getFieldNames().indexName());  
elasticsearch_a8e43578a256f7ab87e3c210349ba15d4f778d20	buggy:  injector.getInstance(MapperService.class).add( "person ",  mapping);  context:  new  IndexNameModule(index),  new  AbstractModule()  {  protected  void  configure()  {  bind(ClusterService.class).toProvider(Providers.of((ClusterService)  null));  }  }  ).createInjector();  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/test/unit/index/query/mapping.json ");          injector.getInstance(MapperService.class).add( "person ",  mapping);          injector.getInstance(MapperService.class).add( "person ",  mapping,  true);  injector.getInstance(MapperService.class).documentMapper( "person ").parse(new  BytesArray(copyToBytesFromClasspath( "/org/elasticsearch/test/unit/index/query/data.json ")));  this.queryParser  =  injector.getInstance(IndexQueryParserService.class);  }  public  void  close()  {  injector.getInstance(ThreadPool.class).shutdownNow();  }  	injector.getInstance(MapperService.class).add( "person ",  mapping,  true);  
elasticsearch_f0914d13af4e4c0a2c363e9e64c930e815d8aaba	buggy:  injector.getInstance(CacheRecycler.class).clear();  context:  injector.getInstance(ThreadPool.class).awaitTermination(10,  TimeUnit.SECONDS);  }  catch  (InterruptedException  e)  {  }  try  {  injector.getInstance(ThreadPool.class).shutdownNow();  }  catch  (Exception  e)  {  }          injector.getInstance(CacheRecycler.class).clear();          injector.getInstance(CacheRecycler.class).close();  CachedStreams.clear();  ThreadLocals.clearReferencesThreadLocals();  }  public  Settings  settings()  {  return  this.settings;  	injector.getInstance(CacheRecycler.class).close();  
libgdx_c93ba2c1881e6a810c2a218cba1b275c5c9f97b9	buggy:  return  new  DefaultShader(renderable.material,  renderable.lights  ==  null  ?  -1  :  maxLightsCount);  context:  public  class  DefaultShaderProvider  extends  BaseShaderProvider  {  public  int  maxLightsCount  =  5;  protected  Shader  createShader(final  Renderable  renderable)  {  Gdx.app.log( "DefaultShaderProvider ",   "Creating  new  shader ");  if  (Gdx.graphics.isGL20Available())  return  new  DefaultShader(renderable.material,  renderable.lights  ==  null  ?  -1  :  maxLightsCount);  return  new  DefaultShader(renderable.material,  renderable.mesh.getVertexAttributes(),  renderable.lights  ==  null  ?  -1  :  maxLightsCount);  return  new  GLES10Shader(maxLightsCount);  }  }  	return  new  DefaultShader(renderable.material,  renderable.mesh.getVertexAttributes(),  renderable.lights  ==  null  ?  -1  :  maxLightsCount);  
elasticsearch_a654c3d103d0f8756bd42f93e27f640c5b79c515	buggy:  final  NoisyChannelSpellChecker  checker  =  new  NoisyChannelSpellChecker(realWordErrorLikelihood,  suggestion.getRequireUnigram());  context:  double  realWordErrorLikelihood  =  suggestion.realworldErrorLikelyhood();  List<PhraseSuggestionContext.DirectCandidateGenerator>  generators  =  suggestion.generators();  CandidateGenerator[]  gens  =  new  CandidateGenerator[generators.size()];  for  (int  i  =  0;  i  <  gens.length;  i++)  {  PhraseSuggestionContext.DirectCandidateGenerator  generator  =  generators.get(i);  DirectSpellChecker  directSpellChecker  =  SuggestUtils.getDirectSpellChecker(generator);  gens[i]  =  new  DirectCandidateGenerator(directSpellChecker,  generator.field(),  generator.suggestMode(),  indexReader,  realWordErrorLikelihood,  generator.size(),  generator.preFilter(),  generator.postFilter());  }          final  NoisyChannelSpellChecker  checker  =  new  NoisyChannelSpellChecker(realWordErrorLikelihood,  suggestion.getRequireUnigram());          final  NoisyChannelSpellChecker  checker  =  new  NoisyChannelSpellChecker(realWordErrorLikelihood,  suggestion.getRequireUnigram(),  suggestion.getTokenLimit());  final  BytesRef  separator  =  suggestion.separator();  TokenStream  stream  =  checker.tokenStream(suggestion.getAnalyzer(),  suggestion.getText(),  spare,  suggestion.getField());  WordScorer  wordScorer  =  suggestion.model().newScorer(indexReader,  suggestion.getField(),  realWordErrorLikelihood,  separator);  Correction[]  corrections  =  checker.getCorrections(stream,  new  MultiCandidateGeneratorWrapper(suggestion.getShardSize(),  gens),  suggestion.maxErrors(),  suggestion.getShardSize(),  indexReader,wordScorer  ,  separator,  suggestion.confidence(),  suggestion.gramSize());  UnicodeUtil.UTF8toUTF16(suggestion.getText(),  spare);  	final  NoisyChannelSpellChecker  checker  =  new  NoisyChannelSpellChecker(realWordErrorLikelihood,  suggestion.getRequireUnigram(),  suggestion.getTokenLimit());  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  builder.startObject(name);  context:  XContentBuilder  builder  =  XContentFactory.contentBuilder(Requests.CONTENT_TYPE);  builder.map(aggs);  return  subAggregation(builder);  }  catch  (IOException  e)  {  throw  new  ElasticsearchGenerationException( "Failed  to  generate  [ "  +  aggs  +   "] ",  e);  }  }  public  final  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {          builder.startObject(name);          builder.startObject(getName());  builder.field(type);  internalXContent(builder,  params);  if  (aggregations  !=  null  ||  aggregationsBinary  !=  null)  {  builder.startObject( "aggregations ");  if  (aggregations  !=  null)  {  	builder.startObject(getName());  
elasticsearch_e01f8c250d9c79911180b2e383fb184f4d278222	buggy:  return  new  QueueRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));  context:  package  org.elasticsearch.common.recycler;  public  class  QueueRecyclerTests  extends  AbstractRecyclerTests  {  protected  Recycler<byte[]>  newRecycler()  {          return  new  QueueRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));          return  Recyclers.concurrentDeque(RECYCLER_C,  randomIntBetween(5,  10));  }  }  	return  Recyclers.concurrentDeque(RECYCLER_C,  randomIntBetween(5,  10));  
libgdx_39a7a9fe68e7465cb42497ff0623da437c27f905	buggy:  l.position.set(MathUtils.random(32)  -  16,  MathUtils.random(8)  -  2,  -MathUtils.random(32)  +  16);  context:  }  public  void  create  ()  {  lightManager  =  new  LightManager(LIGHTS_NUM,  LightQuality.FRAGMENT);  shader  =  ShaderFactory.createShader(null,  lightManager);  for  (int  i  =  0;  i  <  8;  i++)  {  PointLight  l  =  new  PointLight();  l.position.set(MathUtils.random(32)  -  16,  MathUtils.random(8)  -  2,  -MathUtils.random(32)  +  16);  l.position.set(MathUtils.random(8)  -  4,  MathUtils.random(6),  MathUtils.random(8)  -  4);  l.color.r  =  MathUtils.random();  l.color.b  =  MathUtils.random();  l.color.g  =  MathUtils.random();  l.intensity  =  LIGHT_INTESITY;  lightManager.addLigth(l);  }  lightManager.dirLight  =  new  DirectionalLight();  lightManager.dirLight.color.set(0.05f,  0.15f,  0.1f,  1);  	l.position.set(MathUtils.random(8)  -  4,  MathUtils.random(6),  MathUtils.random(8)  -  4);  
elasticsearch_e0846448e985fab1c137c6f729a237df2c7eff0f	buggy:  assertHitCount(world,  246);  context:  }  SearchResponse  world  =  client().prepareSearch().addField( "pin ").setQuery(  filteredQuery(  matchAllQuery(),  geoBoundingBoxFilter( "pin ")  .topLeft(90,  -179.99999)  .bottomRight(-90,  179.99999))  ).execute().actionGet();          assertHitCount(world,  246);          assertHitCount(world,  53);  SearchResponse  distance  =  client().prepareSearch().addField( "pin ").setQuery(  filteredQuery(  matchAllQuery(),  geoDistanceFilter( "pin ").distance( "425km ").point(51.11,  9.851)  )).execute().actionGet();  assertHitCount(distance,  5);  	assertHitCount(world,  53);  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  clearIndicesCacheRequest.filterCache(request.paramAsBoolean( "filterCache ",  clearIndicesCacheRequest.filterCache()));  context:  super(settings,  client);  controller.registerHandler(POST,   "/_cache/clear ",  this);  controller.registerHandler(POST,   "/{index}/_cache/clear ",  this);  }  ClearIndicesCacheRequest  clearIndicesCacheRequest  =  new  ClearIndicesCacheRequest(RestActions.splitIndices(request.param( "index ")));  try  {              clearIndicesCacheRequest.filterCache(request.paramAsBoolean( "filterCache ",  clearIndicesCacheRequest.filterCache()));              clearIndicesCacheRequest.filterCache(request.paramAsBoolean( "filter_cache ",  clearIndicesCacheRequest.filterCache()));  clearIndicesCacheRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  	clearIndicesCacheRequest.filterCache(request.paramAsBoolean( "filter_cache ",  clearIndicesCacheRequest.filterCache()));  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  assertThat(((UpdateRequest)  bulkRequest.requests().get(1)).scriptParams().size(),  equalTo(1));  assertThat(((Integer)  ((UpdateRequest)  bulkRequest.requests().get(1)).scriptParams().get( "param1 ")),  equalTo(1));  assertThat(((UpdateRequest)  bulkRequest.requests().get(1)).upsertRequest().source().toUtf8(),  equalTo( "{\ "counter\ ":1} "));  }  public  void  testBulkAllowExplicitIndex()  throws  Exception  {  String  bulkAction  =  copyToStringFromClasspath( "/org/elasticsearch/action/bulk/simple-bulk.json ");  try  {  new  BulkRequest().add(new  BytesArray(bulkAction.getBytes(Charsets.UTF_8)),  true,  null,  null,  false);              assert  false;              fail();  }  catch  (Exception  e)  {  }  bulkAction  =  copyToStringFromClasspath( "/org/elasticsearch/action/bulk/simple-bulk5.json ");  new  BulkRequest().add(new  BytesArray(bulkAction.getBytes(Charsets.UTF_8)),  true,   "test ",  null,  false);  }  }  	fail();  
elasticsearch_57169d42334d39659bfcd8db2b062c7f6001a668	buggy:  return   "bound_address[ "  +  boundAddress  +   "],  publish_address[ "  +  publishAddress  +   "] ";  context:  boundAddress  =  TransportAddressSerializers.addressFromStream(in);  publishAddress  =  TransportAddressSerializers.addressFromStream(in);  }  TransportAddressSerializers.addressToStream(out,  boundAddress);  TransportAddressSerializers.addressToStream(out,  publishAddress);  }          return   "bound_address[ "  +  boundAddress  +   "],  publish_address[ "  +  publishAddress  +   "] ";          return   "bound_address  { "  +  boundAddress  +   "},  publish_address  { "  +  publishAddress  +   "} ";  }  }  	return   "bound_address  { "  +  boundAddress  +   "},  publish_address  { "  +  publishAddress  +   "} ";  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  String  templateString  =   "{  \ "template\ ":  {  \ "query\ ":  \ "storedTemplate\ "  ,\ "params\ ":{\ "template\ ":\ "all\ "  }  }  }   ";  context:  XContentParser  templateSourceParser  =  XContentFactory.xContent(templateString).createParser(templateString);  context.reset(templateSourceParser);  TemplateQueryParser  parser  =  injector.getInstance(TemplateQueryParser.class);  Query  query  =  parser.parse(context);  assertTrue( "Parsing  template  query  failed. ",  query  instanceof  ConstantScoreQuery);  }  public  void  testParserCanExtractTemplateNames()  throws  Exception  {          String  templateString  =   "{  \ "template\ ":  {  \ "query\ ":  \ "storedTemplate\ "  ,\ "params\ ":{\ "template\ ":\ "all\ "  }  }  }   ";          String  templateString  =   "{  \ "template\ ":  {  \ "file\ ":  \ "storedTemplate\ "  ,\ "params\ ":{\ "template\ ":\ "all\ "  }  }  }   ";  XContentParser  templateSourceParser  =  XContentFactory.xContent(templateString).createParser(templateString);  context.reset(templateSourceParser);  TemplateQueryParser  parser  =  injector.getInstance(TemplateQueryParser.class);  Query  query  =  parser.parse(context);  assertTrue( "Parsing  template  query  failed. ",  query  instanceof  ConstantScoreQuery);  }  	String  templateString  =   "{  \ "template\ ":  {  \ "file\ ":  \ "storedTemplate\ "  ,\ "params\ ":{\ "template\ ":\ "all\ "  }  }  }   ";  
libgdx_6b1f6e2e139683a01b4f19b1765b466de095cb9a	buggy:  Gdx.app.error(PolygonRegionLoader.class.getSimpleName(),   "could  not  read   "  +  fileName,  e);  context:  String  image  =  null;  try  {  BufferedReader  reader  =  file.reader(params.readerBuffer);  for  (String  line  =  reader.readLine();  line  !=  null;  line  =  reader.readLine())  if  (line.startsWith(params.texturePrefix))  {  image  =  line.substring(params.texturePrefix.length());  break;  }  reader.close();  }  catch  (IOException  e)  {  Gdx.app.error(PolygonRegionLoader.class.getSimpleName(),   "could  not  read   "  +  fileName,  e);  throw  new  GdxRuntimeException( "Error  reading   "  +  fileName,  e);  }  if  (image  ==  null  &&  params.textureExtensions  !=  null)  for  (String  extension  :  params.textureExtensions)  {  FileHandle  sibling  =  file.sibling(file.nameWithoutExtension().concat( ". "  +  extension));  if  (sibling.exists())  image  =  sibling.name();  }  if  (image  !=  null)  {  	throw  new  GdxRuntimeException( "Error  reading   "  +  fileName,  e);  
libgdx_0b63264cf3f3779823ec1791ed09b3491b78e726	buggy:  if  (pool  ==  null)  return;  //  Ignore  freeing  an  object  that  was  never  retained.  context:  }  static  public  void  freeAll  (Array  objects)  {  if  (objects  ==  null)  throw  new  IllegalArgumentException( "objects  cannot  be  null. ");  for  (int  i  =  0,  n  =  objects.size;  i  <  n;  i++)  {  Object  object  =  objects.get(i);  if  (object  ==  null)  continue;  ReflectionPool  pool  =  typePools.get(object.getClass());  if  (pool  ==  null)  return;  //  Ignore  freeing  an  object  that  was  never  retained.  if  (pool  ==  null)  continue;  //  Ignore  freeing  an  object  that  was  never  retained.  pool.free(object);  }  }  private  Pools  ()  {  }  }  	if  (pool  ==  null)  continue;  //  Ignore  freeing  an  object  that  was  never  retained.  
elasticsearch_bf41f56f24cb25d336643dc599e4ffbfb9b56a86	buggy:  }  else  if  ( "mode ".equals(currentName))  {  context:  reverse  =  parser.booleanValue();  }  else  if  ( "order ".equals(currentName))  {  reverse  =   "desc ".equals(parser.text());  }  else  if  (currentName.equals( "unit "))  {  unit  =  DistanceUnit.fromString(parser.text());  }  else  if  (currentName.equals( "distance_type ")  ||  currentName.equals( "distanceType "))  {  geoDistance  =  GeoDistance.fromString(parser.text());  }  else  if  ( "normalize ".equals(currentName))  {  normalizeLat  =  parser.booleanValue();  normalizeLon  =  parser.booleanValue();                  }  else  if  ( "mode ".equals(currentName))  {                  }  else  if  ( "sort_mode ".equals(currentName)  ||   "sortMode ".equals(currentName)  ||   "mode ".equals(currentName))  {  sortMode  =  SortMode.fromString(parser.text());  }  else  if  ( "nested_path ".equals(currentName)  ||   "nestedPath ".equals(currentName))  {  nestedPath  =  parser.text();  }  else  {  point.resetFromString(parser.text());  fieldName  =  currentName;  }  }  	}  else  if  ( "sort_mode ".equals(currentName)  ||   "sortMode ".equals(currentName)  ||   "mode ".equals(currentName))  {  
elasticsearch_24ccd73c5dc3fd8602c770547e16cc41e000d5e3	buggy:  if  (text.contains( ": ")  ||  text.contains( "- "))  {  context:  mapper.parse(context);  return;  }  BuilderContext  builderContext  =  new  BuilderContext(context.path());  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  String  text  =  context.parser().text();  boolean  isDate  =  false;                  if  (text.contains( ": ")  ||  text.contains( "- "))  {                  if  (text.contains( ": ")  ||  text.contains( "- ")  ||  text.contains( "/ "))  {  for  (FormatDateTimeFormatter  dateTimeFormatter  :  dateTimeFormatters)  {  try  {  dateTimeFormatter.parser().parseMillis(text);  mapper  =  dateField(currentFieldName).dateTimeFormatter(dateTimeFormatter).build(builderContext);  isDate  =  true;  break;  }  catch  (Exception  e)  {  	if  (text.contains( ": ")  ||  text.contains( "- ")  ||  text.contains( "/ "))  {  
elasticsearch_f72e0c89f76287ca723bd0e2be61be1a83475796	buggy:  throw  new  ElasticsearchException( "failed  to  walk  tree ",  e);  context:  public  void  run()  {  try  {  Files.walkFileTree(shardLoc.toPath(),  new  SimpleFileVisitor<Path>()  {  public  FileVisitResult  visitFile(Path  file,  BasicFileAttributes  attrs)  throws  IOException  {  assertThat( "found  a  temporary  recovery  file:   "  +  file,  file.getFileName().toString(),  not(startsWith( "recovery. ")));  return  FileVisitResult.CONTINUE;  }  });  }  catch  (IOException  e)  {                              throw  new  ElasticsearchException( "failed  to  walk  tree ",  e);                              throw  new  AssertionError( "failed  to  walk  file  tree  starting  at  [ "  +  shardLoc.toPath()  +   "] ",  e);  }  }  });  }  }  }  class  RecoveryCorruption  extends  MockTransportService.DelegateTransport  {  	throw  new  AssertionError( "failed  to  walk  file  tree  starting  at  [ "  +  shardLoc.toPath()  +   "] ",  e);  
elasticsearch_1584c73e4a85037ce83744a384805f234b288548	buggy:  newNodes.add(new  DiscoveryNode(nodeWithInfo.name(),  nodeWithInfo.id(),  listedNode.address(),  nodeWithInfo.attributes(),  nodeWithInfo.version()));  context:  public  NodesInfoResponse  newInstance()  {  return  new  NodesInfoResponse();  }  }).txGet();  if  (!ignoreClusterName  &&  !clusterName.equals(nodeInfo.getClusterName()))  {  newFilteredNodes.add(listedNode);  }  else  if  (nodeInfo.getNodes().length  !=  0)  {  DiscoveryNode  nodeWithInfo  =  nodeInfo.getNodes()[0].getNode();                          newNodes.add(new  DiscoveryNode(nodeWithInfo.name(),  nodeWithInfo.id(),  listedNode.address(),  nodeWithInfo.attributes(),  nodeWithInfo.version()));                          newNodes.add(new  DiscoveryNode(nodeWithInfo.name(),  nodeWithInfo.id(),  nodeWithInfo.getHostName(),  nodeWithInfo.getHostAddress(),  listedNode.address(),  nodeWithInfo.attributes(),  nodeWithInfo.version()));  }  else  {  newNodes.add(listedNode);  }  }  catch  (Throwable  e)  {  transportService.disconnectFromNode(listedNode);  	newNodes.add(new  DiscoveryNode(nodeWithInfo.name(),  nodeWithInfo.id(),  nodeWithInfo.getHostName(),  nodeWithInfo.getHostAddress(),  listedNode.address(),  nodeWithInfo.attributes(),  nodeWithInfo.version()));  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.readFile()));  context:  buffer  =  new  byte[10000  *  ain.getFormat().getFrameSize()];  ain.close();  ain  =  null;  thread  =  new  Thread(this);  thread.setDaemon(true);  thread.start();  }  private  void  openAudioInputStream  ()  throws  UnsupportedAudioFileException,  IOException  {  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.readFile()));  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.read()));  AudioFormat  baseFormat  =  ain.getFormat();  AudioFormat  decodedFormat  =  new  AudioFormat(AudioFormat.Encoding.PCM_SIGNED,  baseFormat.getSampleRate(),  16,  baseFormat.getChannels(),  baseFormat.getChannels()  *  2,  baseFormat.getSampleRate(),  false);  ain  =  AudioSystem.getAudioInputStream(decodedFormat,  ain);  }  	ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.read()));  
libgdx_a08f828afc841de967cde8cec4f5751249215002	buggy:  throw  new  GdxRuntimeException(ex);  context:  try  {  graphics.setupDisplay();  listener.create();  listener.resize(Math.max(1,  graphics.getWidth()),  Math.max(1,  graphics.getHeight()));  start();  }  catch  (Exception  ex)  {  stopped();  exception(ex);  throw  new  GdxRuntimeException(ex);  return;  }  EventQueue.invokeLater(new  Runnable()  {  int  lastWidth  =  Math.max(1,  graphics.getWidth());  int  lastHeight  =  Math.max(1,  graphics.getHeight());  public  void  run  ()  {  if  (!running  ||  Display.isCloseRequested())  {  	return;  
libgdx_c7dc67f4c2fadf5b1b269b14d6de36ffc897b904	buggy:  world.constructors.put( "bar ",  new  BulletConstructor(barMesh,  0f));  //  mass  =  0:  static  body  context:  final  Mesh  barMesh  =  new  Mesh(true,  8,  36,  new  VertexAttribute(Usage.Position,  3,   "a_position "));  barMesh.setVertices(new  float[]  {5f,  0.5f,  0.5f,  5f,  0.5f,  -0.5f,  -5f,  0.5f,  0.5f,  -5f,  0.5f,  -0.5f,  5f,  -0.5f,  0.5f,  5f,  -0.5f,  -0.5f,  -5f,  -0.5f,  0.5f,  -5f,  -0.5f,  -0.5f});  barMesh.setIndices(new  short[]  {0,  1,  2,  1,  2,  3,  //  top  4,  5,  6,  5,  6,  7,  //  bottom  0,  2,  4,  4,  6,  2,  //  front  1,  3,  5,  5,  7,  3,  //  back  2,  3,  6,  6,  7,  3,  //  left  0,  1,  4,  4,  5,  1  //  right  });  world.constructors.put( "bar ",  new  BulletConstructor(barMesh,  0f));  //  mass  =  0:  static  body  world.addConstructor( "bar ",  new  BulletConstructor(barMesh,  0f));  //  mass  =  0:  static  body  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  BulletEntity  bar  =  world.add( "bar ",  0f,  7f,  0f);  bar.color.set(0.75f  +  0.25f  *  (float)Math.random(),  0.75f  +  0.25f  *  (float)Math.random(),  0.75f  +  0.25f  *  (float)Math.random(),  1f);  	world.addConstructor( "bar ",  new  BulletConstructor(barMesh,  0f));  //  mass  =  0:  static  body  
libgdx_f707d7a105a9aea84576aff3120e7363208bb55b	buggy:  ((LwjglInput)Gdx.input).processEvents();  context:  if  (graphics.canvas  !=  null)  {  int  width  =  graphics.canvas.getWidth();  int  height  =  graphics.canvas.getHeight();  if  (lastWidth  !=  width  ||  lastHeight  !=  height)  {  lastWidth  =  width;  lastHeight  =  height;  listener.resize(lastWidth,  lastHeight);  }  }  ((LwjglInput)Gdx.input).processEvents();  input.processEvents();  listener.render();  audio.update();  Display.update();  Display.sync(60);  }  listener.pause();  listener.dispose();  	input.processEvents();  
libgdx_32b98412f7409d91e046a8ede5b988c00464e9c6	buggy:  public  void  purchase  (PurchaseListener  listener,  String  identifier)  {  context:  return  false;  }  public  void  dispose  ()  {  }  public  void  purchase  (PurchaseListener  listener,  String  identifier)  {  public  void  purchase  (String  identifier,  PurchaseListener  listener)  {  }  public  void  purchaseRestore  ()  {  	public  void  purchase  (String  identifier,  PurchaseListener  listener)  {  
libgdx_098997d08beba438cdae225ce520a51f4995e785	buggy:  public  String  getText  ()  {  context:  }  public  Cell  getLabelCell  ()  {  return  getCell(label);  }  public  void  setText  (String  text)  {  label.setText(text);  }  public  String  getText  ()  {  public  CharSequence  getText  ()  {  return  label.getText();  }  static  public  class  TextButtonStyle  extends  ButtonStyle  {  public  BitmapFont  font;  	public  CharSequence  getText  ()  {  
libgdx_4e1cc538aaa75a9d0e9514effa6e3f3beeab3985	buggy:  handles[i]  =  new  AndroidFileHandle(assets,  new  File(file,  path),  type);  context:  public  FileHandle[]  list  (String  suffix)  {  if  (type  ==  FileType.Internal)  {  try  {  String[]  relativePaths  =  assets.list(file.getPath());  FileHandle[]  handles  =  new  FileHandle[relativePaths.length];  int  count  =  0;  for  (int  i  =  0,  n  =  handles.length;  i  <  n;  i++)  {  String  path  =  relativePaths[i];  if  (!path.endsWith(suffix))  continue;  handles[i]  =  new  AndroidFileHandle(assets,  new  File(file,  path),  type);  handles[count]  =  new  AndroidFileHandle(assets,  new  File(file,  path),  type);  count++;  }  if  (count  <  relativePaths.length)  {  FileHandle[]  newHandles  =  new  FileHandle[count];  System.arraycopy(handles,  0,  newHandles,  0,  count);  handles  =  newHandles;  }  return  handles;  	handles[count]  =  new  AndroidFileHandle(assets,  new  File(file,  path),  type);  
elasticsearch_111f9cb751f466de13300b9437ea5358d0c24d03	buggy:  if  (getResponse.exists())  {  context:  transportService.registerHandler(TransportActions.MORE_LIKE_THIS,  new  TransportHandler());  }  GetRequest  getRequest  =  getRequest(request.index())  .type(request.type())  .id(request.id())  .listenerThreaded(false);  getAction.execute(getRequest,  new  ActionListener<GetResponse>()  {                  if  (getResponse.exists())  {                  if  (!getResponse.exists())  {  listener.onFailure(new  ElasticSearchException( "document  missing "));  return;  }  final  BoolJsonQueryBuilder  boolBuilder  =  boolQuery();  try  {  DocumentMapper  docMapper  =  indicesService.indexServiceSafe(request.index()).mapperService().documentMapper(request.type());  final  Set<String>  fields  =  Sets.newHashSet();  if  (request.fields()  !=  null)  {  	if  (!getResponse.exists())  {  
elasticsearch_2801d06aee684aa6eac86b25785876283e42c519	buggy:  deleteByQueryAction.execute(Requests.deleteByQueryRequest(concreteIndices).source(querySourceBuilder),  new  ActionListener<DeleteByQueryResponse>()  {  context:  filterBuilder.should(new  TypeFilterBuilder(type.key));  types.add(type.key);  }  }  if  (types.size()  ==  0)  {  throw  new  TypeMissingException(new  Index( "_all "),  request.types(),   "No  index  has  the  type. ");  }  request.types(types.toArray(new  String[types.size()]));  QuerySourceBuilder  querySourceBuilder  =  new  QuerySourceBuilder()  .setQuery(QueryBuilders.filteredQuery(QueryBuilders.matchAllQuery(),  filterBuilder));                  deleteByQueryAction.execute(Requests.deleteByQueryRequest(concreteIndices).source(querySourceBuilder),  new  ActionListener<DeleteByQueryResponse>()  {                  deleteByQueryAction.execute(Requests.deleteByQueryRequest(concreteIndices).types(request.types()).source(querySourceBuilder),  new  ActionListener<DeleteByQueryResponse>()  {  public  void  onResponse(DeleteByQueryResponse  deleteByQueryResponse)  {  if  (logger.isTraceEnabled())  {  for  (IndexDeleteByQueryResponse  indexResponse  :  deleteByQueryResponse)  {  if  (indexResponse.getFailedShards()  >  0)  {  for  (ShardOperationFailedException  failure  :  indexResponse.getFailures())  {  	deleteByQueryAction.execute(Requests.deleteByQueryRequest(concreteIndices).types(request.types()).source(querySourceBuilder),  new  ActionListener<DeleteByQueryResponse>()  {  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  return  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  org.elasticsearch.Version.CURRENT).luceneVersion;  context:  String  sVersion  =  settings.get( "version ");  if  (sVersion  !=  null)  {  return  Lucene.parseVersion(sVersion,  Lucene.ANALYZER_VERSION,  logger);  }  sVersion  =  indexSettings.get( "index.analysis.version ");  if  (sVersion  !=  null)  {  return  Lucene.parseVersion(sVersion,  Lucene.ANALYZER_VERSION,  logger);  }          return  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  org.elasticsearch.Version.CURRENT).luceneVersion;          return  org.elasticsearch.Version.indexCreated(indexSettings).luceneVersion;  }  public  static  boolean  isNoStopwords(Settings  settings)  {  String  value  =  settings.get( "stopwords ");  return  value  !=  null  &&   "_none_ ".equals(value);  }  public  static  CharArraySet  parseStemExclusion(Settings  settings,  CharArraySet  defaultStemExclusion,  Version  version)  {  	return  org.elasticsearch.Version.indexCreated(indexSettings).luceneVersion;  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  GeoPointDoubleArrayAtomicFieldData.WithOrdinals(  lon.toArray(new  double[lon.size()]),  lat.toArray(new  double[lat.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  throw  new  ElasticSearchIllegalArgumentException( "can't  sort  on  geo_point  field  without  using  specific  sorting  feature,  like  geo_distance ");  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Long  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_629f91ae57b5a2223f2edaa213b5d0d08a155885	buggy:  return  MultiValueMode.MIN.select(atomicFieldData.getOrdinalsValues(),  -1);  context:  for  (ObjectCursor<String>  cursor  :  typeToIds.keys())  {  types.add(cursor.value);  }  return  types;  }  public  SortedDocValues  getOrdinalsValues(String  type)  {  AtomicOrdinalsFieldData  atomicFieldData  =  typeToIds.get(type);  if  (atomicFieldData  !=  null)  {              return  MultiValueMode.MIN.select(atomicFieldData.getOrdinalsValues(),  -1);              return  MultiValueMode.MIN.select(atomicFieldData.getOrdinalsValues());  }  else  {  return  DocValues.emptySorted();  }  }  public  AtomicOrdinalsFieldData  getAtomicFieldData(String  type)  {  return  typeToIds.get(type);  }  	return  MultiValueMode.MIN.select(atomicFieldData.getOrdinalsValues());  
libgdx_467ab9c64c91c62dd3305c7b28f77b55947cdafe	buggy:  new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ");  context:  public  class  StbTrueTypeBuild  {  public  static  void  main(String[]  args)  throws  Exception  {  new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ");  new  NativeCodeGenerator().generate();  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  BuildTarget  win32  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  	new  NativeCodeGenerator().generate();  
elasticsearch_49d84cb47f8f543ce1fb067267d6fafa71f9c479	buggy:  return  Longs.compare(startTime,  ((BlobStoreSnapshot)  o).startTime);  context:  public  int  compareTo(Snapshot  o)  {          return  Longs.compare(startTime,  ((BlobStoreSnapshot)  o).startTime);          return  Long.compare(startTime,  ((BlobStoreSnapshot)  o).startTime);  }  public  static  class  Builder  {  private  String  name;  	return  Long.compare(startTime,  ((BlobStoreSnapshot)  o).startTime);  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  deleted  =  FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[dataDirToClean.size()]),  false);  context:  final  Collection<NodeAndClient>  nodesAndClients  =  nodes.values();  for  (NodeAndClient  nodeAndClient  :  nodesAndClients)  {  nodeAndClient.resetClient();  }  }  private  void  wipeDataDirectories()  {  if  (!dataDirToClean.isEmpty())  {  boolean  deleted  =  false;  try  {                  deleted  =  FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[dataDirToClean.size()]),  false);                  deleted  =  FileSystemUtils.deleteSubDirectories(dataDirToClean.toArray(new  File[dataDirToClean.size()]));  }  finally  {  this.dataDirToClean.clear();  }  }  }  	deleted  =  FileSystemUtils.deleteSubDirectories(dataDirToClean.toArray(new  File[dataDirToClean.size()]));  
elasticsearch_e1fe89389c4e6f81a59bbb4b6790ee18410ae895	buggy:  if  (op.parsedDoc().mappersAdded())  {  context:  }  else  {  Engine.Create  create  =  indexShard.prepareCreate(sourceToParse).version(indexRequest.version()).versionType(indexRequest.versionType()).origin(Engine.Operation.Origin.PRIMARY);  indexShard.create(create);  version  =  create.version();  op  =  create;  }  indexRequest.version(version);                      if  (op.parsedDoc().mappersAdded())  {                      if  (op.parsedDoc().mappingsModified())  {  if  (mappingsToUpdate  ==  null)  {  mappingsToUpdate  =  Sets.newHashSet();  }  mappingsToUpdate.add(Tuple.tuple(indexRequest.index(),  indexRequest.type()));  }  if  (Strings.hasLength(indexRequest.percolate()))  {  	if  (op.parsedDoc().mappingsModified())  {  
elasticsearch_3a7f7664b61696141841a5d7e3166d69c28eab98	buggy:  assertThat(doc.doc().getFieldable( "date_field ").tokenStreamValue(),  notNullValue());  context:  DocumentMapper  defaultMapper  =  MapperTests.newParser().parse(mapping);  long  value  =  System.currentTimeMillis();  ParsedDocument  doc  =  defaultMapper.parse( "type ",   "1 ",  XContentFactory.jsonBuilder()  .startObject()  .field( "date_field ",  value)  .endObject()  .copiedBytes());          assertThat(doc.doc().getFieldable( "date_field ").tokenStreamValue(),  notNullValue());          assertThat(doc.masterDoc().getFieldable( "date_field ").tokenStreamValue(),  notNullValue());  }  }  	assertThat(doc.masterDoc().getFieldable( "date_field ").tokenStreamValue(),  notNullValue());  
elasticsearch_6804c02e97628700e589498dbf56fde2f41aa617	buggy:  File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");  context:  }  IndexMetaData  metaData  =  clusterService.state().metaData().index(shardId.index().name());  if  (metaData  ==  null)  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }  String  storeType  =  metaData.settings().get( "index.store.type ",   "fs ");  if  (!storeType.contains( "fs "))  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }          File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");          File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeDataLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");  if  (!indexFile.exists())  {  return  new  StoreFilesMetaData(false,  shardId,  ImmutableMap.<String,  StoreFileMetaData>of());  }  Map<String,  StoreFileMetaData>  files  =  Maps.newHashMap();  for  (File  file  :  indexFile.listFiles())  {  if  (file.getName().endsWith( ".cks "))  {  continue;  }  	File  indexFile  =  new  File(new  File(new  File(new  File(nodeEnv.nodeDataLocation(),   "indices "),  shardId.index().name()),  Integer.toString(shardId.id())),   "index ");  
libgdx_b233ea6fa98c2f2b5364e149b68f8a3785532ce8	buggy:  if  (doubleValue  ==  longValue)  return  Long.toString(longValue);  context:  }  return  size;  }  public  String  asString  ()  {  if  (stringValue  !=  null)  return  stringValue;  if  (doubleValue  !=  null)  {  if  (doubleValue  ==  longValue)  return  Long.toString(longValue);  if  (doubleValue  %  1  ==  0)  return  Long.toString(longValue);  return  Double.toString(doubleValue);  }  if  (booleanValue  !=  null)  return  Boolean.toString(booleanValue);  if  (type  ==  ValueType.nullValue)  return  null;  throw  new  IllegalStateException( "Value  cannot  be  converted  to  string:   "  +  type);  }  	if  (doubleValue  %  1  ==  0)  return  Long.toString(longValue);  
elasticsearch_383945416866849139755c6761ad162faaadcbe0	buggy:  final  LongHash  longHash  =  new  LongHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randomCacheRecycler());  context:  public  void  testDuell()  {  final  Long[]  values  =  new  Long[randomIntBetween(1,  100000)];  for  (int  i  =  0;  i  <  values.length;  ++i)  {  values[i]  =  randomLong();  }  final  LongLongMap  valueToId  =  new  LongLongOpenHashMap();  final  long[]  idToValue  =  new  long[values.length];  final  float  maxLoadFactor  =  0.6f  +  randomFloat()  *  0.39f;          final  LongHash  longHash  =  new  LongHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randomCacheRecycler());          final  LongHash  longHash  =  new  LongHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randombigArrays());  final  int  iters  =  randomInt(1000000);  for  (int  i  =  0;  i  <  iters;  ++i)  {  final  Long  value  =  randomFrom(values);  if  (valueToId.containsKey(value))  {  assertEquals(-  1  -  valueToId.get(value),  longHash.add(value));  }  else  {  assertEquals(valueToId.size(),  longHash.add(value));  idToValue[valueToId.size()]  =  value;  	final  LongHash  longHash  =  new  LongHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randombigArrays());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<String>  terms  =  new  ArrayList<String>();  context:  facet  =  searchResponse.getFacets().facet( "partially_mapped_str ");  assertThat(facet.getName(),  equalTo( "partially_mapped_str "));  assertThat(facet.getEntries().size(),  is(10));  assertThat(facet.getTotalCount(),  is(10l));  assertThat(facet.getOtherCount(),  is(0l));  assertThat(facet.getMissingCount(),  is(10l));  facet  =  searchResponse.getFacets().facet( "partially_mapped_bool ");  assertThat(facet.getName(),  equalTo( "partially_mapped_bool "));          ArrayList<String>  terms  =  new  ArrayList<String>();          ArrayList<String>  terms  =  new  ArrayList<>();  for  (TermsFacet.Entry  entry  :  facet.getEntries())  {  terms.add(entry.getTerm().toString());  }  assertThat( "unexpected  number  of  bool  terms: "  +  terms,  facet.getEntries().size(),  is(2));  assertThat(facet.getTotalCount(),  is(10l));  assertThat(facet.getOtherCount(),  is(0l));  assertThat(facet.getMissingCount(),  is(10l));  	ArrayList<String>  terms  =  new  ArrayList<>();  
elasticsearch_365c29b902fc41488faaa39fd60100f6865c5b96	buggy:  return  false;  context:  MetaData  previousMetaData  =  previousState.metaData();  if  (previousMetaData  ==  null)  {  return  true;  }  IndexMetaData  previousIndexMetaData  =  previousMetaData.index(current.index());  if  (previousIndexMetaData  ==  current)  {  return  false;  }          return  false;          return  true;  }  public  boolean  blocksChanged()  {  return  state.blocks()  !=  previousState.blocks();  }  public  boolean  localNodeMaster()  {  return  state.nodes().localNodeMaster();  	return  true;  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  ClusterState  clusterState  =  listener.onJoin(request.node);  if  (request.withClusterState)  {  channel.sendResponse(new  JoinResponse(clusterState));  }  else  {  channel.sendResponse(VoidStreamable.INSTANCE);  }  }  public  String  executor()  {              return  ThreadPool.Names.CACHED;              return  ThreadPool.Names.GENERIC;  }  }  private  static  class  LeaveRequest  implements  Streamable  {  private  DiscoveryNode  node;  private  LeaveRequest()  {  	return  ThreadPool.Names.GENERIC;  
elasticsearch_6560a9ec7bc33de0912d23143f167a8cbecb6a36	buggy:  sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request,  filteringAliases),  new  SearchServiceListener<FirstResult>()  {  context:  void  performFirstPhase(final  ShardIterator  shardIt,  final  ShardRouting  shard)  {  if  (shard  ==  null)  {  onFirstPhaseResult(null,  shardIt,  null);  }  else  {  DiscoveryNode  node  =  nodes.get(shard.currentNodeId());  if  (node  ==  null)  {  onFirstPhaseResult(shard,  shardIt,  null);  }  else  {  String[]  filteringAliases  =  clusterState.metaData().filteringAliases(shard.index(),  request.indices());                      sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request,  filteringAliases),  new  SearchServiceListener<FirstResult>()  {                      sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request,  filteringAliases,  startTime),  new  SearchServiceListener<FirstResult>()  {  onFirstPhaseResult(shard,  result,  shardIt);  }  onFirstPhaseResult(shard,  shardIt,  t);  }  });  	sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request,  filteringAliases,  startTime),  new  SearchServiceListener<FirstResult>()  {  
elasticsearch_c3124efe51b54ef06b9670dce21582d9f2ec3ce4	buggy:  out.writeBoolean(false);  context:  }  out.writeUTF(term);  out.writeInt(startOffset);  out.writeInt(endOffset);  out.writeVInt(position);  if  (type  ==  null)  {  out.writeBoolean(false);  }  else  {                  out.writeBoolean(false);                  out.writeBoolean(true);  out.writeUTF(type);  }  }  }  private  List<AnalyzeToken>  tokens;  AnalyzeResponse()  {  	out.writeBoolean(true);  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  try  {  return  blobStore.fileSystem().exists(new  Path(path,  blobName));  }  catch  (IOException  e)  {  return  false;  }  }          blobStore.executorService().execute(new  Runnable()  {          blobStore.executor().execute(new  Runnable()  {  byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  FSDataInputStream  fileStream;  try  {  fileStream  =  blobStore.fileSystem().open(new  Path(path,  blobName));  }  catch  (IOException  e)  {  	blobStore.executor().execute(new  Runnable()  {  
libgdx_aff1c801a7c42c6dcca60f91ebef77fdceab6da1	buggy:  return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  context:  }  public  float  getAngleAroundRad  (final  float  axisX,  final  float  axisY,  final  float  axisZ)  {  final  float  d  =  Vector3.dot(this.x,  this.y,  this.z,  axisX,  axisY,  axisZ);  final  float  l2  =  Quaternion.len2(axisX  *  d,  axisY  *  d,  axisZ  *  d,  this.w);  return  MathUtils.isZero(l2)  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  return  l2  ==  0f  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  }  public  float  getAngleAroundRad  (final  Vector3  axis)  {  return  getAngleAroundRad(axis.x,  axis.y,  axis.z);  }  	return  l2  ==  0f  ?  0f  :  (float)(2.0  *  Math.acos(this.w  /  Math.sqrt(l2)));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);  context:  public  abstract  class  ValuesSourceMetricsAggregatorParser<S  extends  MetricsAggregation>  implements  Aggregator.Parser  {  protected  boolean  requiresSortedValues()  {  return  false;  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  String  field  =  null;  String  script  =  null;  String  scriptLang  =  null;  Map<String,  Object>  scriptParams  =  null;  boolean  assumeSorted  =  false;  XContentParser.Token  token;  	ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  
elasticsearch_cabbf7805b4fdc9342970e4e4b9f873436c9615c	buggy:  int  randomReplicaNumber  =  between(0,  numberOfNodes()  -  1);  context:  assertThat(putMappingResponse.isAcknowledged(),  is(true));  ensureYellow();  }  private  void  createIndexAndMapping(String  indexAnalyzer,  String  searchAnalyzer,  boolean  payloads,  boolean  preserveSeparators,  boolean  preservePositionIncrements)  throws  IOException  {  createIndexAndMappingAndSettings(createDefaultSettings(),  indexAnalyzer,  searchAnalyzer,  payloads,  preserveSeparators,  preservePositionIncrements);  }  private  ImmutableSettings.Builder  createDefaultSettings()  {  int  randomShardNumber  =  between(1,  5);          int  randomReplicaNumber  =  between(0,  numberOfNodes()  -  1);          int  randomReplicaNumber  =  between(0,  cluster().numNodes()  -  1);  return  settingsBuilder().put(SETTING_NUMBER_OF_SHARDS,  randomShardNumber).put(SETTING_NUMBER_OF_REPLICAS,  randomReplicaNumber);  }  private  void  createData(boolean  optimize)  throws  IOException,  InterruptedException,  ExecutionException  {  String[][]  input  =  {{ "Foo  Fighters "},  { "Generator ",   "Foo  Fighters  Generator "},  { "Learn  to  Fly ",   "Foo  Fighters  Learn  to  Fly "},  { "The  Prodigy "},  { "Firestarter ",   "The  Prodigy  Firestarter "},  { "Turbonegro "},  { "Get  it  on ",   "Turbonegro  Get  it  on "}};  String[]  surface  =  { "Foo  Fighters ",   "Generator  -  Foo  Fighters ",   "Learn  to  Fly  -  Foo  Fighters ",   "The  Prodigy ",   "Firestarter  -  The  Prodigy ",   "Turbonegro ",   "Get  it  on  -  Turbonegro "};  int[]  weight  =  {10,  9,  8,  12,  11,  6,  7};  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[input.length];  	int  randomReplicaNumber  =  between(0,  cluster().numNodes()  -  1);  
elasticsearch_db431b7cb35949806987dfe12a2ac8c0495a5097	buggy:  QueryBuilders.fieldQuery( "foo ",   "1 ")  context:  assertExplanation(QueryBuilders.constantScoreQuery(FilterBuilders.termsFilter( "foo ",   "1 ",   "2 ",   "3 ")),  equalTo( "ConstantScore(cache(foo:1  foo:2  foo:3)) "));  assertExplanation(QueryBuilders.constantScoreQuery(FilterBuilders.notFilter(FilterBuilders.termFilter( "foo ",   "bar "))),  equalTo( "ConstantScore(NotFilter(cache(foo:bar))) "));  assertExplanation(QueryBuilders.filteredQuery(  QueryBuilders.termQuery( "foo ",   "1 "),  FilterBuilders.hasChildFilter(   "child-type ",                          QueryBuilders.fieldQuery( "foo ",   "1 ")                          QueryBuilders.matchQuery( "foo ",   "1 ")  )  ),  equalTo( "filtered(foo:1)->CustomQueryWrappingFilter(child_filter[child-type/type1](filtered(foo:1)->cache(_type:child-type))) "));  assertExplanation(QueryBuilders.filteredQuery(  QueryBuilders.termQuery( "foo ",   "1 "),  FilterBuilders.scriptFilter( "true ")  ),  equalTo( "filtered(foo:1)->ScriptFilter(true) "));  	QueryBuilders.matchQuery( "foo ",   "1 ")  
libgdx_496183ec39214d5e5c59c24f973a1b5f4e5c0d11	buggy:  spriteBatch.drawText(  font,  score,  Gdx.graphics.getWidth()  /  2  -  font.getStringWidth(score)  /  2,  Gdx.graphics.getHeight(),  Color.WHITE  );  context:  gl.glPushMatrix();  gl.glTranslatef(  rightPaddle.x,  rightPaddle.y,  0  );  paddleMesh.render(GL10.GL_TRIANGLE_FAN);  gl.glPopMatrix();  spriteBatch.begin();  spriteBatch.drawText(  font,  score,  Gdx.graphics.getWidth()  /  2  -  font.getStringWidth(score)  /  2,  Gdx.graphics.getHeight(),  Color.WHITE  );  spriteBatch.drawText(  font,  score,  Gdx.graphics.getWidth()  /  2  -  font.getStringWidth(score)  /  2,  Gdx.graphics.getHeight()  -  font.getLineHeight(),  Color.WHITE  );  spriteBatch.end();  }  	spriteBatch.drawText(  font,  score,  Gdx.graphics.getWidth()  /  2  -  font.getStringWidth(score)  /  2,  Gdx.graphics.getHeight()  -  font.getLineHeight(),  Color.WHITE  );  
elasticsearch_6abe4c951dcb81c16aed873d26009b99823b74bd	buggy:  bigArrays.ramBytesUsed.addAndGet(-ramBytesUsed());  context:  public  final  boolean  clearOnResize;  private  boolean  released  =  false;  AbstractArray(BigArrays  bigArrays,  boolean  clearOnResize)  {  this.bigArrays  =  bigArrays;  this.clearOnResize  =  clearOnResize;  }  public  final  void  close()  {          bigArrays.ramBytesUsed.addAndGet(-ramBytesUsed());          bigArrays.adjustBreaker(-ramBytesUsed());  assert  !released  :   "double  release ";  released  =  true;  doClose();  }  protected  abstract  void  doClose();  }  	bigArrays.adjustBreaker(-ramBytesUsed());  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  .source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  controller.registerHandler(PUT,   "/{index}/_warmer/{name} ",  this);  controller.registerHandler(PUT,   "/{index}/{type}/_warmer/{name} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  PutWarmerRequest  putWarmerRequest  =  new  PutWarmerRequest(request.param( "name "));  putWarmerRequest.listenerThreaded(false);  SearchRequest  searchRequest  =  new  SearchRequest(RestActions.splitIndices(request.param( "index ")))  .types(RestActions.splitTypes(request.param( "type ")))                  .source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());                  .source(request.content(),  request.contentUnsafe());  putWarmerRequest.searchRequest(searchRequest);  client.admin().indices().putWarmer(putWarmerRequest,  new  ActionListener<PutWarmerResponse>()  {  public  void  onResponse(PutWarmerResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject()  .field( "ok ",  true)  	.source(request.content(),  request.contentUnsafe());  
libgdx_0c6a387f7b0b4f5180014459b3dafaac486d61d4	buggy:  nextIndex  =  currentIndex;  context:  hasNext  =  true;  break;  }  }  }  public  void  remove  ()  {  if  (currentIndex  <  0)  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  null;  }  currentIndex  =  -1;  map.size--;  }  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_44a604029366f5983de181eeb2ac54bd1ad3b219	buggy:  modules.add(new  IndexModule());  context:  modules.add(new  IndexPluginsModule(indexSettings,  pluginsService));  modules.add(new  IndexStoreModule(indexSettings));  modules.add(new  IndexEngineModule(indexSettings));  modules.add(new  AnalysisModule(indexSettings,  indicesAnalysisService));  modules.add(new  SimilarityModule(indexSettings));  modules.add(new  IndexCacheModule(indexSettings));  modules.add(new  IndexQueryParserModule(indexSettings));  modules.add(new  MapperServiceModule());  modules.add(new  IndexAliasesServiceModule());  modules.add(new  IndexGatewayModule(indexSettings,  injector.getInstance(Gateway.class)));          modules.add(new  IndexModule());          modules.add(new  IndexModule(indexSettings));  modules.add(new  PercolatorModule());  Injector  indexInjector;  try  {  indexInjector  =  modules.createChildInjector(injector);  }  catch  (CreationException  e)  {  throw  new  IndexCreationException(index,  Injectors.getFirstErrorFailure(e));  }  	modules.add(new  IndexModule(indexSettings));  
libgdx_9ef257986e7604c477b540bfca662845d114099c	buggy:  config.useGL20  =  false;  context:  public  class  GdxInvadersDesktop  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.title  =   "Gdx  Invaders ";  config.vSyncEnabled  =  true;  config.useGL20  =  false;  config.useGL20  =  true;  new  LwjglApplication(new  GdxInvaders(),  config);  }  }  	config.useGL20  =  true;  
libgdx_b25991f995e0353188ba076de99f0076a604dd54	buggy:  Display.sync(60);  context:  lastWidth  =  width;  lastHeight  =  height;  listener.resize(lastWidth,  lastHeight);  }  }  input.processEvents();  listener.render();  audio.update();  Display.update();  Display.sync(60);  if  (graphics.vsync)  Display.sync(60);  }  listener.pause();  listener.dispose();  Display.destroy();  audio.dispose();  }  	if  (graphics.vsync)  Display.sync(60);  
elasticsearch_4e4495ff1d27f65d4acdcc239998a463151fe561	buggy:  assertThat(((TermQuery)  bQuery.getClauses()[0].getQuery()).getTerm().text(),  equalTo( "12-54-23 "));  context:  }  IndexQueryParser  queryParser  =  queryParser();  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/xcontent/field2.json ");  Query  parsedQuery  =  queryParser.parse(query).query();  assertThat(parsedQuery,  instanceOf(BooleanQuery.class));  BooleanQuery  bQuery  =  (BooleanQuery)  parsedQuery;  assertThat(bQuery.getClauses().length,  equalTo(2));  assertThat(((TermQuery)  bQuery.getClauses()[0].getQuery()).getTerm().field(),  equalTo( "name.first "));          assertThat(((TermQuery)  bQuery.getClauses()[0].getQuery()).getTerm().text(),  equalTo( "12-54-23 "));          assertThat(((TermQuery)  bQuery.getClauses()[0].getQuery()).getTerm().text(),  equalTo( "something "));  assertThat(((TermQuery)  bQuery.getClauses()[1].getQuery()).getTerm().field(),  equalTo( "name.first "));  assertThat(((TermQuery)  bQuery.getClauses()[1].getQuery()).getTerm().text(),  equalTo( "else "));  }  IndexQueryParser  queryParser  =  queryParser();  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/xcontent/field3.json ");  Query  parsedQuery  =  queryParser.parse(query).query();  	assertThat(((TermQuery)  bQuery.getClauses()[0].getQuery()).getTerm().text(),  equalTo( "something "));  
libgdx_3a7227189279ee0218eccb05f5483e1c465ab626	buggy:  if(relativePath.trim().isEmpty())  return  path;  context:  temp  =  s;  index  =  temp.lastIndexOf('/');  if(index  !=  -1)  return  s.substring(index  +  1);  else  return  s;  }  private  static  FileHandle  getRelativeFileHandle(FileHandle  path,  String  relativePath){  if(relativePath.trim().isEmpty())  return  path;  if(relativePath.trim().length()  ==  0)  return  path;  FileHandle  child  =  path;  StringTokenizer  tokenizer  =  new  StringTokenizer(relativePath,   "\\/ ");  while  (tokenizer.hasMoreElements())  {  String  token  =  tokenizer.nextToken();  if(token.equals( ".. "))  child  =  child.parent();  	if(relativePath.trim().length()  ==  0)  return  path;  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  .put( "index.engine.robin.refreshInterval ",   "-1 ")  context:  public  class  ChildSearchShortCircuitBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()                  .put( "index.engine.robin.refreshInterval ",   "-1 ")                  .put( "index.refresh_interval ",   "-1 ")  .put( "gateway.type ",   "local ")  .put(SETTING_NUMBER_OF_SHARDS,  1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)  .build();  String  clusterName  =  ChildSearchShortCircuitBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().clusterName(clusterName)  .settings(settingsBuilder().put(settings).put( "name ",   "node1 "))  	.put( "index.refresh_interval ",   "-1 ")  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  JsonBuilder  builder  =  JsonBuilder.cached();  context:  public  abstract  class  BaseJsonQueryBuilder  implements  JsonQueryBuilder  {  try  {              JsonBuilder  builder  =  JsonBuilder.cached();              JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  toJson(builder);  return  builder.string();  }  catch  (Exception  e)  {  throw  new  QueryBuilderException( "Failed  to  build  query ",  e);  }  }  	JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  
elasticsearch_514df4ee3f99b8f860847a06b3b44e137af70234	buggy:  DefaultShardsRoutingStrategy  strategy  =  new  DefaultShardsRoutingStrategy();  context:  public  class  SingleShardOneBackupRoutingStrategyTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(SingleShardOneBackupRoutingStrategyTests.class);          DefaultShardsRoutingStrategy  strategy  =  new  DefaultShardsRoutingStrategy();          ShardsRoutingStrategy  strategy  =  new  ShardsRoutingStrategy();  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	ShardsRoutingStrategy  strategy  =  new  ShardsRoutingStrategy();  
elasticsearch_ccb30d42e9512c2618880a3cd026d6c6c2e5a253	buggy:  },  timeout);  context:  public  void  add(final  Listener  listener,  TimeValue  timeout)  {  listeners.add(listener);  threadPool.schedule(new  Runnable()  {  boolean  removed  =  listeners.remove(listener);  if  (removed)  {  listener.onTimeout();  }  }          },  timeout);          },  timeout,  ThreadPool.ExecutionType.THREADED);  }  public  void  remove(Listener  listener)  {  listeners.remove(listener);  }  public  void  nodeMappingCreated(final  NodeMappingCreatedResponse  response)  throws  ElasticSearchException  {  DiscoveryNodes  nodes  =  clusterService.state().nodes();  	},  timeout,  ThreadPool.ExecutionType.THREADED);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  DiscoverySettings  discoverySettings  =  cluster().getInstance(DiscoverySettings.class);  context:  assertAcked(response3);  assertThat(response3.getTransientSettings().get(key1),  nullValue());  assertThat(response3.getTransientSettings().get(key2),  nullValue());  assertThat(response3.getPersistentSettings().get(key1),  notNullValue());  assertThat(response3.getPersistentSettings().get(key2),  notNullValue());  }  public  void  testUpdateDiscoveryPublishTimeout()  {          DiscoverySettings  discoverySettings  =  cluster().getInstance(DiscoverySettings.class);          DiscoverySettings  discoverySettings  =  internalCluster().getInstance(DiscoverySettings.class);  assertThat(discoverySettings.getPublishTimeout(),  equalTo(DiscoverySettings.DEFAULT_PUBLISH_TIMEOUT));  ClusterUpdateSettingsResponse  response  =  client().admin().cluster()  .prepareUpdateSettings()  .setTransientSettings(ImmutableSettings.builder().put(DiscoverySettings.PUBLISH_TIMEOUT,   "1s ").build())  .get();  	DiscoverySettings  discoverySettings  =  internalCluster().getInstance(DiscoverySettings.class);  
elasticsearch_cccce2b11452c464c6de2f081aba24a538cb21d1	buggy:  settingsBuilder.put( "path.workWithCluster ",  cleanPath(environment.workWithClusterFile().getAbsolutePath()));  context:  .putProperties( "elasticsearch. ",  System.getProperties())  .putProperties( "es. ",  System.getProperties())  .replacePropertyPlaceholders();  Environment  environment  =  new  Environment(settingsBuilder.build());  settingsBuilder  =  settingsBuilder().put(pSettings);  settingsBuilder.put( "path.home ",  cleanPath(environment.homeFile().getAbsolutePath()));  settingsBuilder.put( "path.work ",  cleanPath(environment.workFile().getAbsolutePath()));          settingsBuilder.put( "path.workWithCluster ",  cleanPath(environment.workWithClusterFile().getAbsolutePath()));          settingsBuilder.put( "path.work_with_cluster ",  cleanPath(environment.workWithClusterFile().getAbsolutePath()));  settingsBuilder.put( "path.logs ",  cleanPath(environment.logsFile().getAbsolutePath()));  if  (loadConfigSettings)  {  try  {  settingsBuilder.loadFromUrl(environment.resolveConfig( "elasticsearch.yml "));  }  catch  (FailedToResolveConfigException  e)  {  }  catch  (NoClassDefFoundError  e)  {  	settingsBuilder.put( "path.work_with_cluster ",  cleanPath(environment.workWithClusterFile().getAbsolutePath()));  
elasticsearch_5cd9da45659e300956fb643bb076d217aba99fa4	buggy:  files.put(file.getName(),  new  StoreFileMetaData(file.getName(),  file.length(),  file.lastModified(),  checksums.get(file.getName())));  context:  continue;  }  for  (File  file  :  listedFiles)  {  if  (file.getName().endsWith( ".cks "))  {  continue;  }  if  (Store.isChecksum(file.getName()))  {  continue;  }                  files.put(file.getName(),  new  StoreFileMetaData(file.getName(),  file.length(),  file.lastModified(),  checksums.get(file.getName())));                  files.put(file.getName(),  new  StoreFileMetaData(file.getName(),  file.length(),  checksums.get(file.getName())));  }  }  return  new  StoreFilesMetaData(false,  shardId,  files);  }  protected  boolean  accumulateExceptions()  {  	files.put(file.getName(),  new  StoreFileMetaData(file.getName(),  file.length(),  checksums.get(file.getName())));  
elasticsearch_35e5432354ee968e516ddeefbd842d3f1742b448	buggy:  throw  new  ElasticsearchParseException( "failed  to  parse  doc  to  extract  routing/timestamp ",  e);  context:  id  =  parseContext.id();  }  if  (parseContext.shouldParseRouting())  {  routing  =  parseContext.routing();  }  if  (parseContext.shouldParseTimestamp())  {  timestamp  =  parseContext.timestamp();  timestamp  =  MappingMetaData.Timestamp.parseStringTimestamp(timestamp,  mappingMd.timestamp().dateTimeFormatter());  }  }  catch  (Exception  e)  {                      throw  new  ElasticsearchParseException( "failed  to  parse  doc  to  extract  routing/timestamp ",  e);                      throw  new  ElasticsearchParseException( "failed  to  parse  doc  to  extract  routing/timestamp/id ",  e);  }  finally  {  if  (parser  !=  null)  {  parser.close();  }  }  }  	throw  new  ElasticsearchParseException( "failed  to  parse  doc  to  extract  routing/timestamp/id ",  e);  
elasticsearch_a344fe6590f204ac1fb8b8287ed520a0715c8ea5	buggy:  logger.debug( "[{}][{}]  deleting  shard  that  is  no  longer  used ",  shardId);  context:  return  currentState;  }  IndexService  indexService  =  indicesService.indexService(shardId.getIndex());  if  (indexService  ==  null)  {  if  (nodeEnv.hasNodeFile())  {  File[]  shardLocations  =  nodeEnv.shardLocations(shardId);  if  (FileSystemUtils.exists(shardLocations))  {                                  logger.debug( "[{}][{}]  deleting  shard  that  is  no  longer  used ",  shardId);                                  logger.debug( "{}  deleting  shard  that  is  no  longer  used ",  shardId);  FileSystemUtils.deleteRecursively(shardLocations);  }  }  }  else  {  if  (!indexService.hasShard(shardId.id()))  {  if  (indexService.store().canDeleteUnallocated(shardId))  {  try  {  	logger.debug( "{}  deleting  shard  that  is  no  longer  used ",  shardId);  
elasticsearch_5517df635324ff1157857a875dce46dbf9a47227	buggy:  timestamp  =  String.valueOf(System.currentTimeMillis());  context:  if  (allowIdGeneration)  {  if  (id  ==  null)  {  id(UUID.randomBase64UUID());  opType(IndexRequest.OpType.CREATE);  }  }  if  (timestamp  ==  null)  {              timestamp  =  String.valueOf(System.currentTimeMillis());              timestamp  =  Long.toString(System.currentTimeMillis());  }  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  type  =  in.readUTF();  if  (in.readBoolean())  {  	timestamp  =  Long.toString(System.currentTimeMillis());  
elasticsearch_e735ff49d69951c756db260967cc2527869ed18c	buggy:  .putInt( "transport.netty.port ",  9999)  context:  public  class  BenchmarkNettyServer  {  public  static  void  main(String[]  args)  {  final  boolean  spawn  =  true;  Settings  settings  =  ImmutableSettings.settingsBuilder()                  .putInt( "transport.netty.port ",  9999)                  .put( "transport.netty.port ",  9999)  .build();  final  ThreadPool  threadPool  =  new  CachedThreadPool();  final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool)).start();  transportService.registerHandler( "benchmark ",  new  BaseTransportRequestHandler<BenchmarkMessage>()  {  return  new  BenchmarkMessage();  	.put( "transport.netty.port ",  9999)  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  pendingTasks  =  new  ArrayList<PendingClusterTask>(size);  context:  static  final  XContentBuilderString  SOURCE  =  new  XContentBuilderString( "source ");  static  final  XContentBuilderString  TIME_IN_QUEUE_MILLIS  =  new  XContentBuilderString( "time_in_queue_millis ");  static  final  XContentBuilderString  TIME_IN_QUEUE  =  new  XContentBuilderString( "time_in_queue ");  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  int  size  =  in.readVInt();          pendingTasks  =  new  ArrayList<PendingClusterTask>(size);          pendingTasks  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  PendingClusterTask  task  =  new  PendingClusterTask();  task.readFrom(in);  pendingTasks.add(task);  }  }  	pendingTasks  =  new  ArrayList<>(size);  
libgdx_e167a69c58e51a796103b6124b63b7dce0631440	buggy:  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  context:  worldInfo.getM_sparsesdf().Initialize();  return  new  BulletWorld(collisionConfiguration,  dispatcher,  broadphase,  solver,  dynamicsWorld);  }  public  void  create  ()  {  super.create();  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  .getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  float  x0  =  -2f,  y0  =  6f,  z0  =  -2f;  float  x1  =  8f,  y1  =  6f,  z1  =  8f;  Vector3  patch00  =  new  Vector3(x0,  y0,  z0);  Vector3  patch10  =  new  Vector3(x1,  y1,  z0);  Vector3  patch01  =  new  Vector3(x0,  y0,  z1);  Vector3  patch11  =  new  Vector3(x1,  y1,  z1);  softBody  =  btSoftBodyHelpers.CreatePatch(worldInfo,  patch00,  patch10,  patch01,  patch11,  15,  15,  15,  false);  	.getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  
elasticsearch_d111e169a4d6aca4233ed147f75282dd5ab3bd91	buggy:  MetaData.Builder  metaDataBuilder  =  MetaData.builder().metaData(newState.metaData()).removeAllIndices();  context:  ClusterState.Builder  builder  =  ClusterState.builder().state(newState);  if  (newState.routingTable().version()  ==  currentState.routingTable().version())  {  builder.routingTable(currentState.routingTable());  }  if  (newState.metaData().version()  ==  currentState.metaData().version())  {  builder.metaData(currentState.metaData());  }  else  {                              MetaData.Builder  metaDataBuilder  =  MetaData.builder().metaData(newState.metaData()).removeAllIndices();                              MetaData.Builder  metaDataBuilder  =  MetaData.builder(newState.metaData()).removeAllIndices();  for  (IndexMetaData  indexMetaData  :  newState.metaData())  {  IndexMetaData  currentIndexMetaData  =  currentState.metaData().index(indexMetaData.index());  if  (currentIndexMetaData  ==  null  ||  currentIndexMetaData.version()  !=  indexMetaData.version())  {  metaDataBuilder.put(indexMetaData,  false);  }  else  {  metaDataBuilder.put(currentIndexMetaData,  false);  }  }  	MetaData.Builder  metaDataBuilder  =  MetaData.builder(newState.metaData()).removeAllIndices();  
libgdx_3bc3aa0954ec39fa82b91b84fe34953fe061403d	buggy:  context.setDepthTest(true,  GL10.GL_LEQUAL);  context:  }  public  boolean  equals  (GLES10Shader  obj)  {  return  (obj  ==  this);  }  public  void  begin  (final  Camera  camera,  final  RenderContext  context)  {  this.context  =  context;  this.camera  =  camera;  context.setDepthTest(true,  GL10.GL_LEQUAL);  context.setDepthTest(GL10.GL_LEQUAL,  0,  1,  true);  Gdx.gl10.glMatrixMode(GL10.GL_PROJECTION);  Gdx.gl10.glLoadMatrixf(camera.combined.val,  0);  Gdx.gl10.glMatrixMode(GL10.GL_MODELVIEW);  }  private  final  float[]  lightVal  =  {0,0,0,0};  private  final  float[]  zeroVal4  =  {0,0,0,0};  private  final  float[]  oneVal4  =  {1,1,1,1};  	context.setDepthTest(GL10.GL_LEQUAL,  0,  1,  true);  
libgdx_a045d507fbe13a89587cf72c574c8ffd2e967260	buggy:  actor.size(amountWidth  *  percentDelta,  amountHeight  *  percentDelta);  context:  package  com.badlogic.gdx.scenes.scene2d.actions;  public  class  SizeByAction  extends  RelativeTemporalAction  {  private  float  amountWidth,  amountHeight;  protected  void  updateRelative  (float  percentDelta)  {  actor.size(amountWidth  *  percentDelta,  amountHeight  *  percentDelta);  actor.sizeBy(amountWidth  *  percentDelta,  amountHeight  *  percentDelta);  }  public  void  setAmount  (float  width,  float  height)  {  amountWidth  =  width;  amountHeight  =  height;  }  public  float  getAmountWidth  ()  {  	actor.sizeBy(amountWidth  *  percentDelta,  amountHeight  *  percentDelta);  
elasticsearch_e488d524c3fe625965043cae55a235fd986a05b0	buggy:  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler. ",   "MergeSchedulerProvider "))  context:  private  final  Settings  settings;  public  MergeSchedulerModule(Settings  settings)  {  this.settings  =  settings;  }  protected  void  configure()  {  bind(MergeSchedulerProvider.class)                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler. ",   "MergeSchedulerProvider "))                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.merge.scheduler. ",   "MergeSchedulerProvider "))  .asEagerSingleton();  }  }  	.to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.merge.scheduler. ",   "MergeSchedulerProvider "))  
libgdx_880cbf8d57403d0b765a5b140d2995165c8ae0ad	buggy:  shapes.rect(getX(),  getY(),  getWidth(),  getHeight(),  getOriginX(),  getOriginY(),  getScaleX(),  getScaleY(),  context:  return  true;  }  });  scale.setPosition(128,  blend.getY());  {  Actor  shapeActor  =  new  Actor()  {  public  void  drawDebug  (ShapeRenderer  shapes)  {  shapes.set(ShapeType.Filled);  shapes.setColor(getColor());  shapes.rect(getX(),  getY(),  getWidth(),  getHeight(),  getOriginX(),  getOriginY(),  getScaleX(),  getScaleY(),  shapes.rect(getX(),  getY(),  getOriginX(),  getOriginY(),  getWidth(),  getHeight(),  getScaleX(),  getScaleY(),  getRotation());  }  };  shapeActor.setBounds(0,  0,  100,  150);  shapeActor.setOrigin(50,  75);  shapeActor.debug();  sprites.add(shapeActor);  	shapes.rect(getX(),  getY(),  getOriginX(),  getOriginY(),  getWidth(),  getHeight(),  getScaleX(),  getScaleY(),  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  Object  optimizeMutex  =  new  Object();  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MERGE;  }  return  TransportActions.Admin.Indices.OPTIMIZE;  }  return   "indices/optimize/shard ";  	return  ThreadPool.Names.MERGE;  
elasticsearch_7e041c43e080dfff1be70ddf7a71147d6da36396	buggy:  deleteByQueryRequest.querySource(RestActions.parseQuerySource(request));  context:  super(settings,  client);  controller.registerHandler(DELETE,   "/{index}/_query ",  this);  controller.registerHandler(DELETE,   "/{index}/{type}/_query ",  this);  }  DeleteByQueryRequest  deleteByQueryRequest  =  new  DeleteByQueryRequest(splitIndices(request.param( "index ")));  deleteByQueryRequest.listenerThreaded(false);  try  {              deleteByQueryRequest.querySource(RestActions.parseQuerySource(request));              deleteByQueryRequest.query(RestActions.parseQuerySource(request));  deleteByQueryRequest.queryParserName(request.param( "query_parser_name "));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  deleteByQueryRequest.types(RestActions.splitTypes(typesParam));  }  deleteByQueryRequest.timeout(request.paramAsTime( "timeout ",  ShardDeleteByQueryRequest.DEFAULT_TIMEOUT));  }  catch  (Exception  e)  {  try  {  	deleteByQueryRequest.query(RestActions.parseQuerySource(request));  
elasticsearch_6ef0e4dddaafe0b2b93233c61a33afdba56a4164	buggy:  }  else  if  ( "type ".equals(currentFieldName)  ||   "type ".equals(currentFieldName))  {  context:  }  else  if  ( "routing ".equals(currentFieldName))  {  searchRequest.routing(parser.text());  }  else  if  ( "query_hint ".equals(currentFieldName)  ||   "queryHint ".equals(currentFieldName))  {  searchRequest.queryHint(parser.text());  }  else  if  ( "ignore_indices ".equals(currentFieldName)  ||   "ignoreIndices ".equals(currentFieldName))  {  searchRequest.ignoreIndices(IgnoreIndices.fromString(parser.text()));  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "index ".equals(currentFieldName)  ||   "indices ".equals(currentFieldName))  {  searchRequest.indices(parseArray(parser));                                  }  else  if  ( "type ".equals(currentFieldName)  ||   "type ".equals(currentFieldName))  {                                  }  else  if  ( "type ".equals(currentFieldName)  ||   "types ".equals(currentFieldName))  {  searchRequest.types(parseArray(parser));  }  else  {  throw  new  ElasticSearchParseException(currentFieldName  +   "  doesn't  support  arrays ");  }  }  }  }  }  finally  {  	}  else  if  ( "type ".equals(currentFieldName)  ||   "types ".equals(currentFieldName))  {  
libgdx_b5f5b65ea9821a09346eedee8f4c5b09bbf507d6	buggy:  JoglApplication  app  =  new  JoglApplication(   "Simple  Test ",  640,  480,  false  );  context:  package  com.badlogic.gdx.tests.desktop.box2d;  public  class  TestCollection  {  public  static  void  main(  String[]  argv  )  {  JoglApplication  app  =  new  JoglApplication(   "Simple  Test ",  640,  480,  false  );  JoglApplication  app  =  new  JoglApplication(   "Simple  Test ",  480,  320,  false  );  app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.box2d.TestCollection(  )  );  }  }  	JoglApplication  app  =  new  JoglApplication(   "Simple  Test ",  480,  320,  false  );  
elasticsearch_0ff84d222f64f7f18f70d56d6f5cb5625ef47997	buggy:  ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer);  context:  }  catch  (Exception  e)  {  handleException(handler,  new  ResponseHandlerFailureTransportException(e));  }  }  });  }  private  void  handlerResponseError(StreamInput  buffer,  final  TransportResponseHandler  handler)  {  Throwable  error;  try  {              ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer);              ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer,  settings.getClassLoader());  error  =  (Throwable)  ois.readObject();  }  catch  (Exception  e)  {  error  =  new  TransportSerializationException( "Failed  to  deserialize  exception  response  from  stream ",  e);  }  handleException(handler,  error);  }  private  void  handleException(final  TransportResponseHandler  handler,  Throwable  error)  {  	ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer,  settings.getClassLoader());  
elasticsearch_087f5d6bea68a8498e029ff55c03ba88727350fd	buggy:  future  =  threadPool.schedule(interval,  ThreadPool.Names.SAME,  this);  context:  }  catch  (EngineClosedException  e)  {  }  catch  (FlushNotAllowedEngineException  e)  {  }  catch  (Exception  e)  {  }  lastFlushTime  =  System.currentTimeMillis();  if  (indexShard.state()  !=  IndexShardState.CLOSED)  {                          future  =  threadPool.schedule(interval,  ThreadPool.Names.SAME,  this);                          future  =  threadPool.schedule(interval,  ThreadPool.Names.SAME,  TranslogBasedFlush.this);  }  }  });  }  }  }  	future  =  threadPool.schedule(interval,  ThreadPool.Names.SAME,  TranslogBasedFlush.this);  
elasticsearch_fef647cb92926c97107f506831bfbdc0b838e80c	buggy:  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());  context:  indexNames[i]  =  request.indices[i].index();  }  clusterService.submitStateUpdateTask( "allocation  dangled  indices   "  +  Arrays.toString(indexNames),  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  if  (currentState.blocks().disableStatePersistence())  {  return  currentState;  }  MetaData.Builder  metaData  =  MetaData.builder(currentState.metaData());  ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks());                      RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());                      RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  boolean  importNeeded  =  false;  StringBuilder  sb  =  new  StringBuilder();  for  (IndexMetaData  indexMetaData  :  request.indices)  {  if  (currentState.metaData().hasIndex(indexMetaData.index()))  {  continue;  }  	RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  SpanTermQuery  query  =  new  SpanTermQuery(new  Term(fieldName,  value));  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
elasticsearch_15c798fb4c5a166198b5d04f57990a6cdf7a9249	buggy:  builder.field( "minimum_should_write ",  minimumShouldMatch);  context:  if  (phraseSlop  !=  -1)  {  builder.field( "phrase_slop ",  phraseSlop);  }  if  (analyzeWildcard  !=  null)  {  builder.field( "analyze_wildcard ",  analyzeWildcard);  }  if  (rewrite  !=  null)  {  builder.field( "rewrite ",  rewrite);  }  if  (minimumShouldMatch  !=  null)  {              builder.field( "minimum_should_write ",  minimumShouldMatch);              builder.field( "minimum_should_match ",  minimumShouldMatch);  }  builder.endObject();  }  }  	builder.field( "minimum_should_match ",  minimumShouldMatch);  
libgdx_a796233dee600d6acf20bb488c15a613eb6de386	buggy:  return  new  BufferFormat(caps.getRedBits(),  caps.getGreenBits(),  caps.getBlueBits(),  caps.getAlphaBits(),  caps.getDepthBits(),  caps.getStencilBits(),  caps.getNumSamples());  context:  return  null;  }  if(vsync)  canvas.getGL().setSwapInterval(1);  else  canvas.getGL().setSwapInterval(0);  }  GLCapabilities  caps  =  canvas.getChosenGLCapabilities();  return  new  BufferFormat(caps.getRedBits(),  caps.getGreenBits(),  caps.getBlueBits(),  caps.getAlphaBits(),  caps.getDepthBits(),  caps.getStencilBits(),  caps.getNumSamples());  return  new  BufferFormat(caps.getRedBits(),  caps.getGreenBits(),  caps.getBlueBits(),  caps.getAlphaBits(),  caps.getDepthBits(),  caps.getStencilBits(),  caps.getNumSamples(),  false);  }  }  	return  new  BufferFormat(caps.getRedBits(),  caps.getGreenBits(),  caps.getBlueBits(),  caps.getAlphaBits(),  caps.getDepthBits(),  caps.getStencilBits(),  caps.getNumSamples(),  false);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  fields  =  new  HashSet<String>(Arrays.asList( "field1 ",   "field2 ",   "field3 "));  context:  doc2.add(new  StoredField( "field1 ",  new  BytesRef(Numbers.intToBytes(1))));  doc2.add(new  StoredField( "field2 ",  new  BytesRef(Numbers.floatToBytes(1.1f))));  doc2.add(new  StoredField( "field3 ",  new  BytesRef(Numbers.longToBytes(1l))));  doc2.add(new  StoredField( "field3 ",  new  BytesRef(Numbers.longToBytes(2l))));  doc2.add(new  StoredField( "field3 ",  new  BytesRef(Numbers.longToBytes(3l))));  writer.addDocument(doc2);  DirectoryReader  reader  =  DirectoryReader.open(writer,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);          Set<String>  fields  =  new  HashSet<String>(Arrays.asList( "field1 ",   "field2 ",   "field3 "));          Set<String>  fields  =  new  HashSet<>(Arrays.asList( "field1 ",   "field2 ",   "field3 "));  CustomFieldsVisitor  fieldsVisitor  =  new  CustomFieldsVisitor(fields,  false);  searcher.doc(0,  fieldsVisitor);  fieldsVisitor.postProcess(mapper);  assertThat(fieldsVisitor.fields().size(),  equalTo(3));  assertThat(fieldsVisitor.fields().get( "field1 ").size(),  equalTo(1));  assertThat((Integer)  fieldsVisitor.fields().get( "field1 ").get(0),  equalTo(1));  assertThat(fieldsVisitor.fields().get( "field2 ").size(),  equalTo(1));  assertThat((Float)  fieldsVisitor.fields().get( "field2 ").get(0),  equalTo(1.1f));  	Set<String>  fields  =  new  HashSet<>(Arrays.asList( "field1 ",   "field2 ",   "field3 "));  
libgdx_eab196531d022ac42556bd4bc0ab6ee0d02cf0b4	buggy:  if  (hasZeroValue  &&  zeroValue  ==  value)  return  true;  context:  if  (hasZeroValue  &&  zeroValue  ==  value)  return  true;  float[]  valueTable  =  this.valueTable;  for  (int  i  =  capacity  +  stashSize;  i--  >  0;)  if  (valueTable[i]  ==  value)  return  true;  return  false;  }  public  boolean  containsValue  (float  value,  float  epsilon)  {  if  (hasZeroValue  &&  zeroValue  ==  value)  return  true;  if  (hasZeroValue  &&  Math.abs(zeroValue  -  value)  <=  epsilon)  return  true;  float[]  valueTable  =  this.valueTable;  for  (int  i  =  capacity  +  stashSize;  i--  >  0;)  if  (Math.abs(valueTable[i]  -  value)  <=  epsilon)  return  true;  return  false;  }  public  boolean  containsKey  (int  key)  {  if  (key  ==  0)  return  hasZeroValue;  	if  (hasZeroValue  &&  Math.abs(zeroValue  -  value)  <=  epsilon)  return  true;  
libgdx_1ab6849614157115963e631247b28b6cf2120db2	buggy:  actor.translate(amountX  *  percentDelta,  amountY  *  percentDelta);  context:  package  com.badlogic.gdx.scenes.scene2d.actions;  public  class  MoveByAction  extends  RelativeTemporalAction  {  private  float  amountX,  amountY;  protected  void  updateRelative  (float  percentDelta)  {  actor.translate(amountX  *  percentDelta,  amountY  *  percentDelta);  actor.moveBy(amountX  *  percentDelta,  amountY  *  percentDelta);  }  public  void  setAmount  (float  x,  float  y)  {  amountX  =  x;  amountY  =  y;  }  public  float  getAmountX  ()  {  	actor.moveBy(amountX  *  percentDelta,  amountY  *  percentDelta);  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  public  int  nextDoc()  throws  IOException  {  return  scorer.nextDoc();  }  public  float  score()  throws  IOException  {  return  subQueryBoost  *  function.score(scorer.docID(),  scorer.score());  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  scorer.freq();  }  }  public  String  toString(String  field)  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "custom  score  ( ").append(subQuery.toString(field)).append( ",function= ").append(function).append(')');  	public  int  freq()  throws  IOException  {  
elasticsearch_09528610c1dcbd1f4cee78fa8549fde19783c897	buggy:  IndexReader  reader  =  indexWriter.getReader();  context:  Directory  dir  =  new  RAMDirectory();  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  indexWriter.commit();  indexWriter.addDocument(doc().add(field( "_id ",   "1 ")).add(field( "text ",   "lucene ")).build());  indexWriter.addDocument(doc().add(field( "_id ",   "2 ")).add(field( "text ",   "lucene  release ")).build());          IndexReader  reader  =  indexWriter.getReader();          IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  MoreLikeThisQuery  mltQuery  =  new  MoreLikeThisQuery( "lucene ",  new  String[]{ "text "},  Lucene.STANDARD_ANALYZER);  mltQuery.setLikeText( "lucene ");  mltQuery.setMinTermFrequency(1);  mltQuery.setMinDocFreq(1);  long  count  =  Lucene.count(searcher,  mltQuery,  -1);  assertThat(count,  equalTo(2l));  	IndexReader  reader  =  IndexReader.open(indexWriter,  true);  
elasticsearch_90371beedc3e02df45778513d8fe72c7d8bbe15b	buggy:  return  new  StoreStats(Directories.estimateSize(directory));  context:  }  public  void  fullDelete()  throws  IOException  {  deleteContent();  for  (Directory  delegate  :  directory.delegates())  {  directoryService.fullDelete(delegate);  }  }  public  StoreStats  stats()  throws  IOException  {          return  new  StoreStats(Directories.estimateSize(directory));          return  new  StoreStats(Directories.estimateSize(directory),  directoryService.throttleTimeInNanos());  }  public  ByteSizeValue  estimateSize()  throws  IOException  {  return  new  ByteSizeValue(Directories.estimateSize(directory));  }  public  void  renameFile(String  from,  String  to)  throws  IOException  {  synchronized  (mutex)  {  	return  new  StoreStats(Directories.estimateSize(directory),  directoryService.throttleTimeInNanos());  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  return  execute(new  Request(nodesIds).timeout(timeout));  context:  public  TransportNodesListGatewayMetaState(Settings  settings,  ClusterName  clusterName,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  }  TransportNodesListGatewayMetaState  init(LocalGatewayMetaState  metaState)  {  this.metaState  =  metaState;  return  this;  }  public  ActionFuture<NodesLocalGatewayMetaState>  list(Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {          return  execute(new  Request(nodesIds).timeout(timeout));          return  execute(new  Request(nodesIds).setTimeout(timeout));  }  protected  String  executor()  {  return  ThreadPool.Names.GENERIC;  }  	return  execute(new  Request(nodesIds).setTimeout(timeout));  
libgdx_9923a4f2c8dba5a8a946658d43b6774a4269e746	buggy:  GdxTest  test  =  new  TiledMapDirectLoaderTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  TiledMapDirectLoaderTest();  GdxTest  test  =  new  TiledMapBench();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  TiledMapBench();  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  parser  =  XContentFactory.xContent(unsafeBytes.unsafeByteArray(),  0,  unsafeBytes.size()).createParser(unsafeBytes.unsafeByteArray(),  0,  unsafeBytes.size());  context:  }  public  FilterParser  filterParser(String  name)  {  return  filterParsers.get(name);  }  public  ParsedQuery  parse(QueryBuilder  queryBuilder)  throws  ElasticSearchException  {  XContentParser  parser  =  null;  try  {  BytesStream  unsafeBytes  =  queryBuilder.buildAsUnsafeBytes();              parser  =  XContentFactory.xContent(unsafeBytes.unsafeByteArray(),  0,  unsafeBytes.size()).createParser(unsafeBytes.unsafeByteArray(),  0,  unsafeBytes.size());              parser  =  XContentFactory.xContent(unsafeBytes.underlyingBytes(),  0,  unsafeBytes.size()).createParser(unsafeBytes.underlyingBytes(),  0,  unsafeBytes.size());  return  parse(cache.get(),  parser);  }  catch  (QueryParsingException  e)  {  throw  e;  }  catch  (Exception  e)  {  throw  new  QueryParsingException(index,   "Failed  to  parse ",  e);  }  finally  {  if  (parser  !=  null)  {  parser.close();  	parser  =  XContentFactory.xContent(unsafeBytes.underlyingBytes(),  0,  unsafeBytes.size()).createParser(unsafeBytes.underlyingBytes(),  0,  unsafeBytes.size());  
elasticsearch_3c142e550d946347d87c6b48d5bc7ef6f99fff0a	buggy:  incrementBucketDocCount(numChildren,  bucketOrd);  context:  return;  }  int  prevParentDoc  =  parentDocs.prevSetBit(parentDoc  -  1);  int  numChildren  =  0;  for  (int  i  =  (parentDoc  -  1);  i  >  prevParentDoc;  i--)  {  if  (childDocs.get(i))  {  +numChildren;  collectBucketNoCounts(i,  bucketOrd);  }  }          incrementBucketDocCount(numChildren,  bucketOrd);          incrementBucketDocCount(bucketOrd,  numChildren);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  return  new  InternalNested(name,  bucketDocCount(owningBucketOrdinal),  bucketAggregations(owningBucketOrdinal));  }  	incrementBucketDocCount(bucketOrd,  numChildren);  
elasticsearch_1f50b07406d0fa5f10a733445a622044671ccabe	buggy:  HasChildFilter  childFilter  =  HasChildFilter.create(query,  null,  parentType,  childType,  searchContext,  executionType);  context:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();          HasChildFilter  childFilter  =  HasChildFilter.create(query,  null,  parentType,  childType,  searchContext,  executionType);          HasChildFilter  childFilter  =  HasChildFilter.create(query,  parentType,  childType,  searchContext,  executionType);  searchContext.addRewrite(childFilter);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  childFilter);  }  return  childFilter;  }  }  	HasChildFilter  childFilter  =  HasChildFilter.create(query,  parentType,  childType,  searchContext,  executionType);  
elasticsearch_be282cc4c8b44956be4ec98be73061ca3e25b73a	buggy:  hitContext.reset(searchHit,  subReader,  subDoc,  doc);  context:  searchHit.fields().put(extractFieldName,  hitField);  }  hitField.values().add(value);  }  }  }  for  (FetchSubPhase  fetchSubPhase  :  fetchSubPhases)  {  FetchSubPhase.HitContext  hitContext  =  new  FetchSubPhase.HitContext();  if  (fetchSubPhase.hitExecutionNeeded(context))  {                      hitContext.reset(searchHit,  subReader,  subDoc,  doc);                      hitContext.reset(searchHit,  subReader,  subDoc,  context.searcher().getIndexReader(),  docId,  doc);  fetchSubPhase.hitExecute(context,  hitContext);  }  }  }  for  (FetchSubPhase  fetchSubPhase  :  fetchSubPhases)  {  if  (fetchSubPhase.hitsExecutionNeeded(context))  {  fetchSubPhase.hitsExecute(context,  hits);  	hitContext.reset(searchHit,  subReader,  subDoc,  context.searcher().getIndexReader(),  docId,  doc);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  map2.release();  context:  assertEquals(map1.size(),  map2.size());  }  }  for  (int  i  =  0;  i  <=  maxKey;  ++i)  {  assertSame(map1.get(i),  map2.get(i));  }  final  LongObjectOpenHashMap<Object>  copy  =  new  LongObjectOpenHashMap<>();  for  (LongObjectPagedHashMap.Cursor<Object>  cursor  :  map2)  {  copy.put(cursor.key,  cursor.value);  }          map2.release();          map2.close();  assertEquals(map1,  copy);  }  }  	map2.close();  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  WildcardQuery  query  =  new  WildcardQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  
libgdx_7a9f61cf3584f51edffbcf6cfe7ed8d98c903e5a	buggy:  light.priority  =  light.intensity  /  light.position.dst(x,  y,  z);  context:  public  void  calculateLights  (float  x,  float  y,  float  z)  {  final  int  maxSize  =  pointLights.size;  if  (maxSize  >  maxLightsPerModel)  {  for  (int  i  =  0;  i  <  maxSize;  i++)  {  final  PointLight  light  =  pointLights.get(i);  light.priority  =  light.intensity  /  light.position.dst(x,  y,  z);  light.priority  =  (int)(PointLight.PRIORITY_DISCRETE_STEPS  *  (light.intensity  /  light.position.dst(x,  y,  z)));  }  pointLights.sort();  }  final  int  size  =  maxLightsPerModel  >  maxSize  ?  maxSize  :  maxLightsPerModel;  for  (int  i  =  0;  i  <  size;  i++)  {  	light.priority  =  (int)(PointLight.PRIORITY_DISCRETE_STEPS  *  (light.intensity  /  light.position.dst(x,  y,  z)));  
elasticsearch_b009c9c6521fced35371eb4e73f616cd247da54f	buggy:  indexOutput  =  shard.store().createOutputWithNoChecksum(name);  context:  String  name  =  request.name();  if  (shard.store().directory().fileExists(name))  {  name  =  name  +   ". "  +  onGoingRecovery.startTime;  }                  indexOutput  =  shard.store().createOutputWithNoChecksum(name);                  indexOutput  =  shard.store().createOutputRaw(name);  onGoingRecovery.openIndexOutputs.put(request.name(),  indexOutput);  }  else  {  indexOutput  =  onGoingRecovery.openIndexOutputs.get(request.name());  }  if  (indexOutput  ==  null)  {  throw  new  IndexShardClosedException(shard.shardId());  	indexOutput  =  shard.store().createOutputRaw(name);  
libgdx_f0195e0837bca3a9c5c6da4e47f28f5f41c48ee2	buggy:  if  (ray.origin.z  <=  box.min.y  &&  ray.direction.z  >  0)  {  context:  if  (t  >=  0)  {  Vector3.tmp3.set(ray.direction).scl(t).add(ray.origin);  if  (Vector3.tmp3.x  >=  box.min.x  &&  Vector3.tmp3.x  <=  box.max.x  &&  Vector3.tmp3.z  >=  box.min.z  &&  Vector3.tmp3.z  <=  box.max.z  &&  (!hit  ||  t  <  lowest))  {  hit  =  true;  lowest  =  t;  }  }  }  if  (ray.origin.z  <=  box.min.y  &&  ray.direction.z  >  0)  {  if  (ray.origin.z  <=  box.min.z  &&  ray.direction.z  >  0)  {  t  =  (box.min.z  -  ray.origin.z)  /  ray.direction.z;  if  (t  >=  0)  {  Vector3.tmp3.set(ray.direction).scl(t).add(ray.origin);  if  (Vector3.tmp3.x  >=  box.min.x  &&  Vector3.tmp3.x  <=  box.max.x  &&  Vector3.tmp3.y  >=  box.min.y  &&  Vector3.tmp3.y  <=  box.max.y  &&  (!hit  ||  t  <  lowest))  {  hit  =  true;  lowest  =  t;  }  	if  (ray.origin.z  <=  box.min.z  &&  ray.direction.z  >  0)  {  
libgdx_6238b7716f375dea84022fe13f67d6be2c554004	buggy:  if  (comp.compare(array[i],  pivotValue)  ==  -1)  {  context:  this.array  =  items;  this.comp  =  comp;  return  recursiveSelect(0,  size  -  1,  n);  }  private  int  partition(int  left,  int  right,  int  pivot)  {  T  pivotValue  =  array[pivot];  swap(right,  pivot);  int  storage  =  left;  for  (int  i  =  left;  i  <  right;  i++)  {  if  (comp.compare(array[i],  pivotValue)  ==  -1)  {  if  (comp.compare(array[i],  pivotValue)  <  0)  {  swap(storage,  i);  storage++;  }  }  swap(right,  storage);  return  storage;  }  	if  (comp.compare(array[i],  pivotValue)  <  0)  {  
libgdx_77f82f9b4ceb51a78975e2064ca06034fc458150	buggy:  mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit ";  context:  lin32.libraries  =   "-lX11 ";  BuildTarget  lin64  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  true);  lin64.cppIncludes  =  linuxSrc;  lin64.headerDirs  =  includes;  lin64.libraries  =   "-lX11 ";  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  mac.cppIncludes  =  macSrc;  mac.headerDirs  =  includes;  mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit ";  mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit  -framework  Cocoa ";  new  AntScriptGenerator().generate(buildConfig,  win32home,  win32,  win64,  lin32,  lin64,  mac);  if(!BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler=true  -v  postcompile "))  {  throw  new  Exception( "build  failed ");  }  BuildExecutor.executeAnt( "jni/build.xml ",   "pack-natives ");  }  }  	mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit  -framework  Cocoa ";  
libgdx_f7b2c3d92be930928a5e181fc81a851cee39166d	buggy:  inputProcessor.touchDown(event.x,  event.y,  event.pointer,  Buttons.LEFT);  context:  inputProcessor.touchDown(event.x,  event.y,  event.pointer,  Buttons.LEFT);  if(numTouched  ==  1)  justTouched  =  true;  break;  case  UITouchPhase.Cancelled:  case  UITouchPhase.Ended:  inputProcessor.touchUp(event.x,  event.y,  event.pointer,  Buttons.LEFT);  break;  case  UITouchPhase.Moved:  case  UITouchPhase.Stationary:  inputProcessor.touchDown(event.x,  event.y,  event.pointer,  Buttons.LEFT);  inputProcessor.touchDragged(event.x,  event.y,  event.pointer);  break;  }  }  }  touchEventPool.free(touchEvents);  touchEvents.clear();  }  }  	inputProcessor.touchDragged(event.x,  event.y,  event.pointer);  
elasticsearch_4d09e7562a73eb90a10c212c996d6f0d0d703e3b	buggy:  masterFD.restart(latestDiscoNodes.masterNode(),   "new  cluster  stare  received  and  we  monitor  the  wrong  master  [ "  +  masterFD.masterNode()  +   "] ");  context:  latestDiscoNodes  =  newState.nodes();  if  (masterFD.masterNode()  ==  null  ||  !masterFD.masterNode().equals(latestDiscoNodes.masterNode()))  {                              masterFD.restart(latestDiscoNodes.masterNode(),   "new  cluster  stare  received  and  we  monitor  the  wrong  master  [ "  +  masterFD.masterNode()  +   "] ");                              masterFD.restart(latestDiscoNodes.masterNode(),   "new  cluster  state  received  and  we  are  monitoring  the  wrong  master  [ "  +  masterFD.masterNode()  +   "] ");  }  ClusterState.Builder  builder  =  ClusterState.builder().state(newState);  if  (newState.routingTable().version()  ==  currentState.routingTable().version())  {  builder.routingTable(currentState.routingTable());  }  	masterFD.restart(latestDiscoNodes.masterNode(),   "new  cluster  state  received  and  we  are  monitoring  the  wrong  master  [ "  +  masterFD.masterNode()  +   "] ");  
elasticsearch_a465d97adb18a6c01dba958af57c414fac861f07	buggy:  logger.debug( "failed  to  rollback  writer  on  close ",  e);  context:  }  if  (indexWriter  !=  null)  {  try  {  indexWriter.rollback();  }  catch  (AlreadyClosedException  e)  {  }  }  }  catch  (Throwable  e)  {              logger.debug( "failed  to  rollback  writer  on  close ",  e);              logger.warn( "failed  to  rollback  writer  on  close ",  e);  }  finally  {  indexWriter  =  null;  }  }  private  HashedBytesRef  versionKey(Term  uid)  {  return  new  HashedBytesRef(uid.bytes());  }  	logger.warn( "failed  to  rollback  writer  on  close ",  e);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  byte  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
libgdx_622d74c64e12ddc1e24e215a9cac9506b891d285	buggy:  shadowMap  =  new  FrameBuffer(Format.RGBA8888,  512,  512,  true);  context:  cam.update();  currCam  =  cam;  flatShader  =  new  ShaderProgram(Gdx.files.internal( "data/shaders/flat-vert.glsl ").readString(),  Gdx.files.internal( "data/shaders/flat-frag.glsl ").readString());  if(!flatShader.isCompiled())  throw  new  GdxRuntimeException( "Couldn't  compile  flat  shader:   "  +  flatShader.getLog());  currShader  =  flatShader;  }  private  void  setupShadowMap()  {  shadowMap  =  new  FrameBuffer(Format.RGBA8888,  512,  512,  true);  shadowMap  =  new  FrameBuffer(Format.RGBA8888,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  lightCam  =  new  PerspectiveCamera(67,  shadowMap.getWidth(),  shadowMap.getHeight());  lightCam.position.set(-10,  10,  0);  lightCam.lookAt(0,  0,  0);  lightCam.update();  shadowGenShader  =  new  ShaderProgram(Gdx.files.internal( "data/shaders/shadowgen-vert.glsl ").readString(),  Gdx.files.internal( "data/shaders/shadowgen-frag.glsl ").readString());  if(!shadowGenShader.isCompiled())  throw  new  GdxRuntimeException( "Couldn't  compile  shadow  gen  shader:   "  +  shadowGenShader.getLog());  	shadowMap  =  new  FrameBuffer(Format.RGBA8888,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  num  =  atLeast(150);  context:  public  void  testDuellCompletions()  throws  IOException,  NoSuchFieldException,  SecurityException,  IllegalArgumentException,  IllegalAccessException  {  final  boolean  preserveSeparators  =  getRandom().nextBoolean();  final  boolean  preservePositionIncrements  =  getRandom().nextBoolean();  final  boolean  usePayloads  =  getRandom().nextBoolean();  final  int  options  =  preserveSeparators  ?  AnalyzingSuggester.PRESERVE_SEP  :  0;  XAnalyzingSuggester  reference  =  new  XAnalyzingSuggester(new  StandardAnalyzer(TEST_VERSION_CURRENT),  null,  new  StandardAnalyzer(  TEST_VERSION_CURRENT),  options,  256,  -1,  preservePositionIncrements,  null,  false,  1,  XAnalyzingSuggester.SEP_LABEL,  XAnalyzingSuggester.PAYLOAD_SEP,  XAnalyzingSuggester.END_BYTE,  XAnalyzingSuggester.HOLE_CHARACTER);  LineFileDocs  docs  =  new  LineFileDocs(getRandom());          int  num  =  atLeast(150);          int  num  =  scaledRandomIntBetween(150,  300);  final  String[]  titles  =  new  String[num];  final  long[]  weights  =  new  long[num];  for  (int  i  =  0;  i  <  titles.length;  i++)  {  Document  nextDoc  =  docs.nextDoc();  IndexableField  field  =  nextDoc.getField( "title ");  titles[i]  =  field.stringValue();  weights[i]  =  between(0,  100);  	int  num  =  scaledRandomIntBetween(150,  300);  
elasticsearch_b80eee305e2fc4b9c7e3dee0c0af797047dea891	buggy:  builder.field( "state ",  indexMetaData.state().toString().toLowerCase());  context:  builder.endObject();  }  builder.endObject();  builder.startObject( "indices ");  for  (IndexMetaData  indexMetaData  :  state.metaData())  {  builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);                              builder.field( "state ",  indexMetaData.state().toString().toLowerCase());                              builder.field( "state ",  indexMetaData.state().toString().toLowerCase(Locale.ENGLISH));  builder.startObject( "settings ");  Settings  settings  =  settingsFilter.filterSettings(indexMetaData.settings());  for  (Map.Entry<String,  String>  entry  :  settings.getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  	builder.field( "state ",  indexMetaData.state().toString().toLowerCase(Locale.ENGLISH));  
elasticsearch_9503fca2ae35c52797aef1bbdac818f3086b74fd	buggy:  sb.append( "    index    :  files            [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");  context:  }  indexShard.refresh(new  Engine.Refresh(false));  recoveryStatus.time(System.currentTimeMillis()  -  recoveryStatus.startTime());  recoveryStatus.updateStage(RecoveryStatus.Stage.DONE);  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(timeValueMillis(recoveryStatus.time())).append( "]\n ");                          sb.append( "    index    :  files            [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");                          sb.append( "    index    :  files            [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");  sb.append( "              :  recovered_files  [ ").append(recoveryStatus.index().numberOfRecoveredFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().recoveredTotalSize())).append( "]\n ");  sb.append( "              :  reusing_files    [ ").append(recoveryStatus.index().numberOfReusedFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().reusedTotalSize())).append( "]\n ");  sb.append( "    translog  :  number_of_operations  [ ").append(recoveryStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.translog().time())).append( "] ");  }  listener.onRecoveryDone();  scheduleSnapshotIfNeeded();  }  catch  (IndexShardGatewayRecoveryException  e)  {  	sb.append( "        index        :  files                      [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");  
libgdx_fd5f6266c79ff99f86f44c9889323a8425f25a1f	buggy:  BuildExecutor.executeAnt(JNI_DIR  +   "/build-windows32.xml ",   "clean  link  -v ");  context:  String[]  headerDirs  =  {   "./ ",   "etc1/ ",   "gdx2d/ "  };  BuildConfig  config  =  new  BuildConfig( "gdx ",   "../target/native ",  LIBS_DIR,  JNI_DIR);  BuildTarget  target  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  target.compilerPrefix  =   " ";  target.excludeFromMasterBuildFile  =  true;  target.headerDirs  =  headerDirs;  new  AntScriptGenerator().generate(config,  target);  BuildExecutor.executeAnt(JNI_DIR  +   "/build-windows32.xml ",   "clean  link  -v ");  BuildExecutor.executeAnt(JNI_DIR  +   "/build-windows32.xml ",   " ");  }  }  	BuildExecutor.executeAnt(JNI_DIR  +   "/build-windows32.xml ",   " ");  
elasticsearch_3afe4da55078e7b14eb4f7ef38d897c7f0f7f13d	buggy:  source  =  Arrays.copyOfRange(source,  sourceOffset,  sourceLength);  context:  public  IndexRequest  id(String  id)  {  this.id  =  id;  return  this;  }  public  byte[]  source()  {  if  (sourceUnsafe  ||  sourceOffset  >  0)  {              source  =  Arrays.copyOfRange(source,  sourceOffset,  sourceLength);              source  =  Arrays.copyOfRange(source,  sourceOffset,  sourceOffset  +  sourceLength);  sourceOffset  =  0;  sourceUnsafe  =  false;  }  return  source;  }  	source  =  Arrays.copyOfRange(source,  sourceOffset,  sourceOffset  +  sourceLength);  
libgdx_36a4ac8ffe5f7c2bcbf1ff6678778c8e5ddcc1f0	buggy:  FlickScrollPane  scroll  =  new  FlickScrollPane(table,  stage);  context:  Gdx.input.setInputProcessor(stage);  Gdx.graphics.setVSync(false);  container  =  new  Table();  stage.addActor(container);  container.getTableLayout().debug();  Table  table  =  new  Table();  FlickScrollPane  scroll  =  new  FlickScrollPane(table,  stage);  FlickScrollPane  scroll  =  new  FlickScrollPane(table);  container.add(scroll).expand().fill();  table.parse( "pad:10  *  expand:x  space:4 ");  for  (int  i  =  0;  i  <  100;  i++)  {  table.row();  table.add(new  Label(i  +   "uno ",  new  LabelStyle(font,  Color.RED))).expandX().fillX();  table.add(new  Label(i  +   "dos ",  new  LabelStyle(font,  Color.RED)));  table.add(new  Label(i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9  long10  long11  long12 ",  	FlickScrollPane  scroll  =  new  FlickScrollPane(table);  
libgdx_c9489c555ac9aa01f770862e538d829d05eb9676	buggy:  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  false);  context:  ++  libgdx_c9489c555ac9aa01f770862e538d829d05eb9676_5847.java  package  com.badlogic.cubocy;  public  class  CubocDesktop  {  public  static  void  main  (String[]  argv)  {  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  false);  new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  true);  }  }  	new  LwjglApplication(new  Cubocy(),   "Cubocy ",  480,  320,  true);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  values[i]  =  indexFieldDatas[i].load(context).getBytesValues(true);  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  for  (int  i  =  0;  i  <  indexFieldDatas.length;  i++)  {                  values[i]  =  indexFieldDatas[i].load(context).getBytesValues(true);                  values[i]  =  indexFieldDatas[i].load(context).getBytesValues();  }  if  (script  !=  null)  {  script.setNextReader(context);  }  }  public  void  collect(int  doc)  throws  IOException  {  	values[i]  =  indexFieldDatas[i].load(context).getBytesValues();  
libgdx_13805f5791d36481aa94f7e2d7ab0408ec7af451	buggy:  app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.SoundTest()  );  context:  ++  libgdx_13805f5791d36481aa94f7e2d7ab0408ec7af451_9178.java  package  com.badlogic.gdx.tests.desktop;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  JoglApplication  app  =  new  JoglApplication(   "Debug  Test ",  480,  320,  false  );  app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.SoundTest()  );  app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.VertexBufferObjectClassTest()  );  }  }  	app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.VertexBufferObjectClassTest()  );  
libgdx_995aa4fb356df46df284d5f16816eeb971e60fd4	buggy:  GdxTest  test  =  new  TideMapDirectLoaderTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  TideMapDirectLoaderTest();  GdxTest  test  =  new  SuperKoalio();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  SuperKoalio();  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  return  true;  context:  readerState.done  =  true;  readerStates.put(currentReader,  readerState);  }  this.currentReader  =  context.reader();  this.docBase  =  context.docBase;  this.readerState  =  new  ReaderState();  }  public  boolean  acceptsDocsOutOfOrder()  {              return  true;              return  false;  }  public  static  final  RuntimeException  StopCollectingException  =  new  StopCollectingException();  static  class  StopCollectingException  extends  RuntimeException  {  public  Throwable  fillInStackTrace()  {  return  null;  	return  false;  
elasticsearch_2c4b9d9ba2ba14e881ea7c75f5dc2ddb14e384c9	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,   "_local ");  context:  protected  ShardValidateQueryResponse  newShardResponse()  {  return  new  ShardValidateQueryResponse();  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  ValidateQueryRequest  request,  String[]  concreteIndices)  {  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(Integer.toString(ThreadLocalRandom.current().nextInt(1000)),  request.indices());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,   "_local ");          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,   "_local ");  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  ValidateQueryRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.READ);  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,   "_local ");  
libgdx_93e7685506a671b5a0ac0cc5230e52a39f5fdf29	buggy:  font.draw(batch,   "fps:   "  +  Gdx.graphics.getFramesPerSecond(),  10,  10,  Color.RED);  context:  camera.setViewport(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  camera.setMatrices();  tiles.bind();  gl.glColor4f(1,  1,  1,  1);  floorMesh.render(GL10.GL_TRIANGLES);  wallMesh.render(GL10.GL_TRIANGLES);  batch.begin();  font.draw(batch,   "fps:   "  +  Gdx.graphics.getFramesPerSecond(),  10,  10,  Color.RED);  font.draw(batch,   "fps:   "  +  Gdx.graphics.getFramesPerSecond()  +   ",  delta: "  +  Gdx.graphics.getDeltaTime(),  10,  10,  Color.WHITE);  batch.end();  processInput();  }  private  void  processInput()  {  float  delta  =  Gdx.graphics.getDeltaTime();  	font.draw(batch,   "fps:   "  +  Gdx.graphics.getFramesPerSecond()  +   ",  delta: "  +  Gdx.graphics.getDeltaTime(),  10,  10,  Color.WHITE);  
elasticsearch_6c552b4187e49696e81c12f10baa75304114dae0	buggy:  @Override  public  boolean  get(int  doc)  throws  IOException  {  context:  public  class  LimitDocSet  extends  GetDocSet  {  private  final  int  limit;  public  LimitDocSet(int  maxDoc,  int  limit)  {  super(maxDoc);  this.limit  =  limit;  }          @Override  public  boolean  get(int  doc)  throws  IOException  {          @Override  public  boolean  get(int  doc)  {  if  (++counter  >  limit)  {  return  false;  }  return  true;  }  }  }  	@Override  public  boolean  get(int  doc)  {  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  false);  context:  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30f));  stage.draw();  Table.drawDebug(stage);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  false);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  skin.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
elasticsearch_ebd6316db9be1ef69ddc0a929bb225ec6d9b7ed6	buggy:  createIndexService.createIndex(new  MetaDataCreateIndexService.Request(cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  context:  String  cause  =  request.cause();  if  (cause.length()  ==  0)  {  cause  =   "api ";  }  final  AtomicReference<CreateIndexResponse>  responseRef  =  new  AtomicReference<CreateIndexResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          createIndexService.createIndex(new  MetaDataCreateIndexService.Request(cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {          createIndexService.createIndex(new  MetaDataCreateIndexService.Request(MetaDataCreateIndexService.Request.Origin.API,  cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  responseRef.set(new  CreateIndexResponse(response.acknowledged()));  latch.countDown();  }  failureRef.set(t);  latch.countDown();  	createIndexService.createIndex(new  MetaDataCreateIndexService.Request(MetaDataCreateIndexService.Request.Origin.API,  cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  
elasticsearch_eaccd4383db5f534491a6ce0dd23f94ae2987038	buggy:  .field( "content ",  html)  context:  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/xcontent/test-mapping.json ");  DocumentMapper  docMapper  =  mapperParser.parse(mapping);  byte[]  html  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/ "  +  filename);  BytesReference  json  =  jsonBuilder()  .startObject()  .field( "_id ",  1)  .startObject( "file ")  .field( "_name ",  filename)                          .field( "content ",  html)                          .field( "_content ",  html)  .endObject()  .endObject().bytes();  ParseContext.Document  doc  =  docMapper.parse(json).rootDoc();  assertThat(doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()),  containsString( "World "));  assertThat(doc.get(docMapper.mappers().smartName( "file.name ").mapper().names().indexName()),  equalTo(filename));  if  (expectedDate  ==  null)  {  assertThat(doc.getField(docMapper.mappers().smartName( "file.date ").mapper().names().indexName()),  nullValue());  	.field( "_content ",  html)  
elasticsearch_180f83828acf90a2e4a0b392a0797c902c91209f	buggy:  int  index  =  counter.getAndIncrement();  context:  }  return  new  PlainShardIterator(shardId,  ImmutableList.of(primary));  }  public  ShardIterator  preferLocalShardsIt(String  nodeId)  {  ArrayList<ShardRouting>  ordered  =  new  ArrayList<ShardRouting>(this.shards.size());          int  index  =  counter.getAndIncrement();          int  index  =  Math.abs(counter.getAndIncrement());  for  (int  i  =  0;  i  <  this.shards.size();  i++)  {  int  loc  =  (index  +  i)  %  this.shards.size();  ordered.add(this.shards.get(loc));  }  for  (int  i  =  0;  i  <  ordered.size();  i++)  {  ShardRouting  current  =  ordered.get(i);  if  (nodeId.equals(current.currentNodeId()))  {  	int  index  =  Math.abs(counter.getAndIncrement());  
elasticsearch_6c8aa5fa6c58db1d3919a40c9c3ce73f8d433b9e	buggy:  if  (indexOutput.getFilePointer()  ==  request.length())  {  context:  BytesReference  content  =  request.content();  if  (!content.hasArray())  {  content  =  content.toBytesArray();  }  indexOutput.writeBytes(content.array(),  content.arrayOffset(),  content.length());  onGoingRecovery.recoveryState.getIndex().addRecoveredByteCount(content.length());  RecoveryState.File  file  =  onGoingRecovery.recoveryState.getIndex().file(request.name());  if  (file  !=  null)  {  file.updateRecovered(request.length());  }                          if  (indexOutput.getFilePointer()  ==  request.length())  {                          if  (indexOutput.getFilePointer()  >=  request.length()  ||  request.lastChunk())  {  Store.verify(indexOutput);  indexOutput.close();  onGoingRecovery.legacyChecksums.add(request.metadata());  store.directory().sync(Collections.singleton(request.name()));  IndexOutput  remove  =  onGoingRecovery.removeOpenIndexOutputs(request.name());  onGoingRecovery.recoveryState.getIndex().addRecoveredFileCount(1);  	if  (indexOutput.getFilePointer()  >=  request.length()  ||  request.lastChunk())  {  
elasticsearch_cda633afeec2618d1dd2d6f72e50644a85f5e183	buggy:  MapperQueryParser  queryParser  =  parseContext.singleQueryParser(qpSettings);  context:  if  (qpSettings.escape())  {  qpSettings.queryString(org.apache.lucene.queryParser.QueryParser.escape(qpSettings.queryString()));  }  Query  query  =  parseContext.indexCache().queryParserCache().get(qpSettings);  if  (query  !=  null)  {  return  query;  }          MapperQueryParser  queryParser  =  parseContext.singleQueryParser(qpSettings);          MapperQueryParser  queryParser  =  parseContext.queryParser(qpSettings);  try  {  query  =  queryParser.parse(qpSettings.queryString());  query.setBoost(qpSettings.boost());  query  =  optimizeQuery(fixNegativeQueryIfNeeded(query));  if  (query  instanceof  BooleanQuery)  {  Queries.applyMinimumShouldMatch((BooleanQuery)  query,  qpSettings.minimumShouldMatch());  }  	MapperQueryParser  queryParser  =  parseContext.queryParser(qpSettings);  
elasticsearch_06da379f5045e0c1d7436a7757400f9ba5b7f993	buggy:  if  (smartNameFieldMappers.hasDocMapper())  {  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  prefix  filter ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              if  (smartNameFieldMappers.hasDocMapper())  {              if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  filter  =  smartNameFieldMappers.mapper().prefixFilter(value,  parseContext);  }  finally  {  QueryParseContext.setTypes(previousTypes);  }  }  else  {  filter  =  smartNameFieldMappers.mapper().prefixFilter(value,  parseContext);  	if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  filteringAliases[i]  =  in.readUTF();  }  }  explain  =  in.readBoolean();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  if  (filteringAliases  !=  null)  {  out.writeVInt(filteringAliases.length);  for  (String  alias  :  filteringAliases)  {  	out.writeBytesReference(querySource);  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()  context:  public  class  ConcurrentRebalanceRoutingTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(ConcurrentRebalanceRoutingTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()          AllocationService  strategy  =  new  AllocationService(settingsBuilder()  .put( "cluster.routing.allocation.concurrent_recoveries ",  10)  .put( "cluster.routing.allocation.allow_rebalance ",   "always ")  .put( "cluster.routing.allocation.cluster_concurrent_rebalance ",  3)  .build());  MetaData  metaData  =  newMetaDataBuilder()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder()  
elasticsearch_4ff1b429f1351c17ae5f3a4338a7ac33db49ef70	buggy:  recoveryStatus().index().startTime(System.currentTimeMillis());  context:  return   "local ";  }  return  recoveryStatus;  }          recoveryStatus().index().startTime(System.currentTimeMillis());          recoveryStatus.index().startTime(System.currentTimeMillis());  long  version  =  -1;  try  {  if  (IndexReader.indexExists(indexShard.store().directory()))  {  version  =  IndexReader.getCurrentVersion(indexShard.store().directory());  }  }  catch  (IOException  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "Failed  to  fetch  index  version  after  copying  it  over ",  e);  }  	recoveryStatus.index().startTime(System.currentTimeMillis());  
elasticsearch_4f96b3637643ea2b9e4ddf58b1858c04aea27388	buggy:  if  (fieldType().stored()  !=  Defaults.SIZE_FIELD_TYPE.stored())  {  context:  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (enabledState  ==  Defaults.ENABLED_STATE  &&  fieldType().stored()  ==  Defaults.SIZE_FIELD_TYPE.stored())  {  return  builder;  }  builder.startObject(contentType());  if  (enabledState  !=  Defaults.ENABLED_STATE)  {  builder.field( "enabled ",  enabledState.enabled);  }          if  (fieldType().stored()  !=  Defaults.SIZE_FIELD_TYPE.stored())  {          if  (fieldType().stored()  !=  Defaults.SIZE_FIELD_TYPE.stored()  &&  enabledState.enabled)  {  builder.field( "store ",  fieldType().stored());  }  builder.endObject();  return  builder;  }  public  void  merge(Mapper  mergeWith,  MergeContext  mergeContext)  throws  MergeMappingException  {  	if  (fieldType().stored()  !=  Defaults.SIZE_FIELD_TYPE.stored()  &&  enabledState.enabled)  {  
libgdx_ea23703713d5d00c0a0839ef0c6b74427d56cf01	buggy:  if  (isMac)  return   "lib "  +  libraryName  +   ".dylib ";  context:  }  catch  (Exception  ex)  {  StreamUtils.closeQuietly(input);  }  return  Long.toString(crc.getValue(),  16);  }  public  String  mapLibraryName  (String  libraryName)  {  if  (isWindows)  return  libraryName  +  (is64Bit  ?   "64.dll "  :   ".dll ");  if  (isLinux)  return   "lib "  +  libraryName  +  (isARM  ?   "arm "  +  abi  :   " ")  +  (is64Bit  ?   "64.so "  :   ".so ");  if  (isMac)  return   "lib "  +  libraryName  +   ".dylib ";  if  (isMac)  return   "lib "  +  libraryName  +  (is64Bit  ?   "64.dylib "  :   ".dylib ");  return  libraryName;  }  public  synchronized  void  load  (String  libraryName)  {  if  (isIos)  return;  	if  (isMac)  return   "lib "  +  libraryName  +  (is64Bit  ?   "64.dylib "  :   ".dylib ");  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  effect.load(Gdx.files.getFileHandle( "data/test.p ",  FileType.Internal),   "data ",  FileType.Internal);  context:  ArrayList<ParticleEmitter>  emitters;  int  particleCount  =  10;  float  fpsCounter;  InputProcessor  inputProcessor;  public  void  create  ()  {  spriteBatch  =  new  SpriteBatch();  effect  =  new  ParticleEffect();  effect.load(Gdx.files.getFileHandle( "data/test.p ",  FileType.Internal),   "data ",  FileType.Internal);  effect.load(Gdx.files.internal( "data/test.p "),  Gdx.files.internal( "data "));  effect.setPosition(Gdx.graphics.getWidth()  /  2,  Gdx.graphics.getHeight()  /  2);  emitters  =  new  ArrayList(effect.getEmitters());  effect.getEmitters().clear();  effect.getEmitters().add(emitters.get(0));  inputProcessor  =  new  InputProcessor()  {  public  boolean  touchUp  (int  x,  int  y,  int  pointer)  {  	effect.load(Gdx.files.internal( "data/test.p "),  Gdx.files.internal( "data "));  
elasticsearch_d7a02fb28f1a4a816971dc6d0cf6678dd1160b35	buggy:  return  ThreadPool.Names.SAME;  context:  ClusterState  clusterState  =  listener.onJoin(request.node);  if  (request.withClusterState)  {  channel.sendResponse(new  JoinResponse(clusterState));  }  else  {  channel.sendResponse(VoidStreamable.INSTANCE);  }  }              return  ThreadPool.Names.SAME;              return  ThreadPool.Names.CACHED;  }  }  private  static  class  LeaveRequest  implements  Streamable  {  private  DiscoveryNode  node;  private  LeaveRequest()  {  	return  ThreadPool.Names.CACHED;  
elasticsearch_8ccfca3a2f0193f0a4da38e206c35cf08402218f	buggy:  queries.put(idValues.copyShared(),  parseQuery);  context:  if  (idValues.setDocument(doc)  >  0)  {  BytesRef  id  =  idValues.nextValue();  fieldsVisitor.reset();  reader.document(doc,  fieldsVisitor);  try  {  final  Query  parseQuery  =  percolator.parsePercolatorDocument(null,  fieldsVisitor.source());  if  (parseQuery  !=  null)  {                      queries.put(idValues.copyShared(),  parseQuery);                      queries.put(BytesRef.deepCopyOf(id),  parseQuery);  }  else  {  }  }  catch  (Exception  e)  {  }  }  	queries.put(BytesRef.deepCopyOf(id),  parseQuery);  
libgdx_d4852dfeb7415f6a6a0e8a0a7d3102c502eed8b4	buggy:  final  BulletConstructor  sceneConstructor  =  new  BulletConstructor(sceneModel,  0f,  new  btBvhTriangleMeshShape(true,  sceneModel));  context:  final  Model  sphereModel  =  modelBuilder.createSphere(0.5f,  0.5f,  0.5f,  8,  8,  new  Material(ColorAttribute.createDiffuse(Color.WHITE),  ColorAttribute.createSpecular(Color.WHITE)),  Usage.Position  |  Usage.Normal);  disposables.add(sphereModel);  final  BulletConstructor  sphereConstructor  =  new  BulletConstructor(sphereModel,  0.25f,  new  btSphereShape(0.25f));  sphereConstructor.bodyInfo.setRestitution(1f);  world.addConstructor( "sphere ",  sphereConstructor);  final  Model  sceneModel  =  objLoader.loadModel(Gdx.files.internal( "data/scene.obj "));  disposables.add(sceneModel);  final  BulletConstructor  sceneConstructor  =  new  BulletConstructor(sceneModel,  0f,  new  btBvhTriangleMeshShape(true,  sceneModel));  final  BulletConstructor  sceneConstructor  =  new  BulletConstructor(sceneModel,  0f,  new  btBvhTriangleMeshShape(sceneModel.meshParts));  sceneConstructor.bodyInfo.setRestitution(0.25f);  world.addConstructor( "scene ",  sceneConstructor);  world.add( "scene ",  (new  Matrix4()).setToTranslation(0f,  2f,  0f).rotate(Vector3.Y,  -90))  .setColor(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  world.add( "ground ",  0f,  0f,  0f)  .setColor(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  	final  BulletConstructor  sceneConstructor  =  new  BulletConstructor(sceneModel,  0f,  new  btBvhTriangleMeshShape(sceneModel.meshParts));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<Object>(2));  context:  public  void  hitExecute(SearchContext  context,  HitContext  hitContext)  throws  ElasticsearchException  {  for  (PartialFieldsContext.PartialField  field  :  context.partialFields().fields())  {  Object  value  =  context.lookup().source().filter(field.includes(),  field.excludes());  if  (hitContext.hit().fieldsOrNull()  ==  null)  {  hitContext.hit().fields(new  HashMap<String,  SearchHitField>(2));  }  SearchHitField  hitField  =  hitContext.hit().fields().get(field.name());  if  (hitField  ==  null)  {                  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<Object>(2));                  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<>(2));  hitContext.hit().fields().put(field.name(),  hitField);  }  hitField.values().add(value);  }  }  }  	hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<>(2));  
elasticsearch_d14a8afaf024cd5a6620479ab4a8063d4130a699	buggy:  logger.trace( "[{}]  Failed  to  send  multicast  ping  on  interface  {} ",  id,  inf);  context:  boolean  sentToAtLeastOne  =  false;  for  (NetworkInterface  inf  :  networkInterfaces)  {  if  (logger.isTraceEnabled())  {  }  try  {  multicastSocket.setNetworkInterface(inf);  multicastSocket.send(datagramPacketSend);  sentToAtLeastOne  =  true;  }  catch  (Exception  e)  {                          logger.trace( "[{}]  Failed  to  send  multicast  ping  on  interface  {} ",  id,  inf);                          logger.trace( "[{}]  Failed  to  send  multicast  ping  on  interface  {} ",  e,  id,  inf);  lastException  =  e;  }  }  if  (!sentToAtLeastOne)  {  throw  new  ZenPingException( "Failed  to  send  on  any  of  the  network  interfaces ",  lastException);  }  }  else  {  try  {  	logger.trace( "[{}]  Failed  to  send  multicast  ping  on  interface  {} ",  e,  id,  inf);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  releasable.release();  context:  public  class  ReleaseChannelFutureListener  implements  ChannelFutureListener  {  private  final  Releasable  releasable;  public  ReleaseChannelFutureListener(Releasable  releasable)  {  this.releasable  =  releasable;  }  public  void  operationComplete(ChannelFuture  future)  throws  Exception  {          releasable.release();          releasable.close();  }  }  	releasable.close();  
elasticsearch_b5b1960a2bbc719411fa490b82e13490df808aff	buggy:  TopChildrenQuery  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  innerQuery,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  parseContext.cacheRecycler(),  nonNestedDocsFilter);  context:  Filter  nonNestedDocsFilter  =  null;  if  (childDocMapper.hasNestedObjects())  {  nonNestedDocsFilter  =  parseContext.cacheFilter(NonNestedDocsFilter.INSTANCE,  null);  }  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);          TopChildrenQuery  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  innerQuery,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  parseContext.cacheRecycler(),  nonNestedDocsFilter);          TopChildrenQuery  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  innerQuery,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  nonNestedDocsFilter);  if  (queryName  !=  null)  {  parseContext.addNamedFilter(queryName,  new  CustomQueryWrappingFilter(query));  }  return  query;  }  }  	TopChildrenQuery  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  innerQuery,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  nonNestedDocsFilter);  
elasticsearch_7cc48c8e8723d3b31fbcb371070bc2a8d87b1f7e	buggy:  indexShard.flush(new  Engine.Flush().refresh(request.refresh()).type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  context:  }  protected  ShardFlushResponse  newShardResponse()  {  return  new  ShardFlushResponse();  }  protected  ShardFlushResponse  shardOperation(ShardFlushRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          indexShard.flush(new  Engine.Flush().refresh(request.refresh()).type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));          indexShard.flush(new  Engine.Flush().type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  return  new  ShardFlushResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  FlushRequest  request,  String[]  concreteIndices)  {  	indexShard.flush(new  Engine.Flush().type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  
libgdx_c4eb672a79a125d12fdb26248da7e3e93152f96c	buggy:  writer.write(value.toString());  context:  current.needsComma  =  true;  else  writer.write( ", ");  writer.write( "\ " ");  writer.write(name);  if  (value  ==  null  ||  value  instanceof  Number  ||  value  instanceof  Boolean)  {  writer.write( "\ ": ");  writer.write(String.valueOf(value));  }  else  {  writer.write( "\ ":\ " ");  writer.write(value.toString());  writer.write(value.toString().replace( "\\ ",   "\\\\ "));  writer.write( "\ " ");  }  return  this;  }  public  JsonWriter  pop  ()  throws  IOException  {  stack.pop().close();  current  =  stack.peek();  	writer.write(value.toString().replace( "\\ ",   "\\\\ "));  
elasticsearch_7aa2d11cdd657f7ed2175a0f4ffecaf230ca449c	buggy:  createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  context:  this.mappingUpdatedAction  =  mappingUpdatedAction;  this.autoCreateIndex  =  new  AutoCreateIndex(settings);  this.allowIdGeneration  =  settings.getAsBoolean( "action.allow_id_generation ",  true);  }  protected  void  doExecute(final  IndexRequest  request,  final  ActionListener<IndexResponse>  listener)  {  if  (autoCreateIndex.shouldAutoCreate(request.index(),  clusterService.state()))  {  request.beforeLocalFork();  //  we  fork  on  another  thread...              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  	createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(index  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_f8a08a46ac4bb34f9df23a22baae2021cbe0b541	buggy:  return  new  TermFilter(names().createIndexNameTerm(nullValue  ?   "T "  :   "F "));  context:  return  Values.TRUE;  }  return  Values.FALSE;  }  public  Filter  nullValueFilter()  {  if  (nullValue  ==  null)  {  return  null;  }          return  new  TermFilter(names().createIndexNameTerm(nullValue  ?   "T "  :   "F "));          return  new  TermFilter(names().createIndexNameTerm(nullValue  ?  Values.TRUE  :  Values.FALSE));  }  protected  Field  parseCreateField(ParseContext  context)  throws  IOException  {  if  (!fieldType().indexed()  &&  !fieldType().stored())  {  return  null;  }  XContentParser.Token  token  =  context.parser().currentToken();  	return  new  TermFilter(names().createIndexNameTerm(nullValue  ?  Values.TRUE  :  Values.FALSE));  
elasticsearch_76e595278ae251155e5dc9199b7573b0d4b4099a	buggy:   "{\ "facet1\ ":{\ "terms\ ":{\ "field\ ":\ "tag\ "},\ "facet_filter\ ":{  }}} ").array())  context:  createIndex( "test ");  ensureGreen();  client().prepareIndex( "test ",   "type1 ").setSource(jsonBuilder().startObject()  .field( "tag ",   "green ")  .endObject()).execute().actionGet();  refresh();  SearchResponse  searchResponse  =  client().prepareSearch()  .setSearchType(SearchType.COUNT)  .setFacets(new  BytesArray(                           "{\ "facet1\ ":{\ "terms\ ":{\ "field\ ":\ "tag\ "},\ "facet_filter\ ":{  }}} ").array())                           "{\ "facet1\ ":{\ "terms\ ":{\ "field\ ":\ "tag\ "},\ "facet_filter\ ":{  }}} "))  .get();  assertHitCount(searchResponse,  1l);  assertThat(searchResponse.getHits().hits().length,  equalTo(0));  TermsFacet  facet  =  searchResponse.getFacets().facet( "facet1 ");  assertThat(facet.getName(),  equalTo( "facet1 "));  assertThat(facet.getEntries().size(),  equalTo(1));  assertThat(facet.getEntries().get(0).getTerm().string(),  equalTo( "green "));  	 "{\ "facet1\ ":{\ "terms\ ":{\ "field\ ":\ "tag\ "},\ "facet_filter\ ":{  }}} "))  
libgdx_83192ece209ea8181d1b270adb6e9d1c96bf4b2e	buggy:  new  String[0],  new  String[0],   "i586-mingw32msvc- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",  context:  this.cFlags  =  cFlags;  this.cppFlags  =  cppFlags;  this.linkerFlags  =  linkerFlags;  }  public  static  BuildTarget  newDefaultTarget  (BuildTarget.TargetOs  type,  boolean  is64Bit)  {  if  (type  ==  TargetOs.Windows  &&  !is64Bit)  {  return  new  BuildTarget(TargetOs.Windows,  false,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   "i586-mingw32msvc- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",  new  String[0],  new  String[0],   "i686-w64-mingw32- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-Wl,--kill-at  -shared  -m32 ");  }  if  (type  ==  TargetOs.Windows  &&  is64Bit)  {  return  new  BuildTarget(TargetOs.Windows,  true,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   "x86_64-w64-mingw32- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m64 ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m64 ",  	new  String[0],  new  String[0],   "i686-w64-mingw32- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",  
elasticsearch_d111e169a4d6aca4233ed147f75282dd5ab3bd91	buggy:  MetaData.Builder  metaData  =  MetaData.builder().metaData(currentState.metaData())  context:  }  }  else  {  }  }  if  (!changed)  {  return  currentState;  }                  MetaData.Builder  metaData  =  MetaData.builder().metaData(currentState.metaData())                  MetaData.Builder  metaData  =  MetaData.builder(currentState.metaData())  .persistentSettings(persistentSettings.build())  .transientSettings(transientSettings.build());  ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks());  boolean  updatedReadOnly  =  metaData.persistentSettings().getAsBoolean(MetaData.SETTING_READ_ONLY,  false)  ||  metaData.transientSettings().getAsBoolean(MetaData.SETTING_READ_ONLY,  false);  if  (updatedReadOnly)  {  blocks.addGlobalBlock(MetaData.CLUSTER_READ_ONLY_BLOCK);  }  else  {  	MetaData.Builder  metaData  =  MetaData.builder(currentState.metaData())  
elasticsearch_25717ab2536b91fab710df595c841d7e6ee0e523	buggy:  if  (!omitNormsSet)  {  context:  public  StringFieldMapper  build(BuilderContext  context)  {  if  (positionOffsetGap  >  0)  {  indexAnalyzer  =  new  NamedCustomAnalyzer(indexAnalyzer,  positionOffsetGap);  searchAnalyzer  =  new  NamedCustomAnalyzer(searchAnalyzer,  positionOffsetGap);  searchQuotedAnalyzer  =  new  NamedCustomAnalyzer(searchQuotedAnalyzer,  positionOffsetGap);  }  if  (fieldType.indexed()  &&  !fieldType.tokenized())  {                  if  (!omitNormsSet)  {                  if  (!omitNormsSet  &&  boost  ==  Defaults.BOOST)  {  fieldType.setOmitNorms(true);  }  if  (!indexOptionsSet)  {  fieldType.setIndexOptions(IndexOptions.DOCS_ONLY);  }  }  StringFieldMapper  fieldMapper  =  new  StringFieldMapper(buildNames(context),  boost,  fieldType,  nullValue,  	if  (!omitNormsSet  &&  boost  ==  Defaults.BOOST)  {  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  filter  =  fieldMapper.termsFilter(parseContext.fieldData(),  terms,  parseContext);  context:  if  (cache  ==  null  ||  cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  }  else  if  ( "fielddata ".equals(execution))  {  if  (fieldMapper  ==  null)  {  return  Queries.MATCH_NO_FILTER;  }                  filter  =  fieldMapper.termsFilter(parseContext.fieldData(),  terms,  parseContext);                  filter  =  fieldMapper.termsFilter(parseContext,  terms,  parseContext);  if  (cache  !=  null  &&  cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  }  else  if  ( "bool ".equals(execution))  {  XBooleanFilter  boolFiler  =  new  XBooleanFilter();  if  (fieldMapper  !=  null)  {  for  (Object  term  :  terms)  {  boolFiler.add(parseContext.cacheFilter(fieldMapper.termFilter(term,  parseContext),  null),  BooleanClause.Occur.SHOULD);  	filter  =  fieldMapper.termsFilter(parseContext,  terms,  parseContext);  
elasticsearch_1bcd3b67ee9f3462d6cac310b3be9a952f154b48	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing());  context:  return  new  ShardCountRequest(shard.index(),  shard.id(),  request);  }  return  new  ShardCountResponse();  }          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing(),  null);  }  for  (String  index  :  request.indices())  {  state.blocks().indexBlocked(ClusterBlockLevel.READ,  index);  }  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing(),  null);  
libgdx_3d5b25c4b1602fa62ab235181aa612ba877e0e20	buggy:  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  context:  buffer.position(0);  buffer.limit(count);  bufferChanged();  }  public  void  updateVertices  (int  targetOffset,  float[]  vertices,  int  sourceOffset,  int  count)  {  isDirty  =  true;  final  int  pos  =  byteBuffer.position();  byteBuffer.position(targetOffset  *  4);  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  byteBuffer.position(pos);  buffer.position(0);  bufferChanged();  }  public  void  bind  ()  {  GL11  gl  =  Gdx.gl11;  	BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  return  new  ScriptDocValues.Strings(getBytesValues());  context:  super(reader,  field);  }  public  boolean  isValuesOrdered()  {  return  true;  }  public  Strings  getScriptValues()  {          return  new  ScriptDocValues.Strings(getBytesValues());          return  new  ScriptDocValues.Strings(getBytesValues(false));  }  }  	return  new  ScriptDocValues.Strings(getBytesValues(false));  
elasticsearch_106b747a08ed88bc657a79f6b6b24999f127610d	buggy:  latch.wait();  context:  latch.countDown();  }  }  }  });  }  return  new  TerminationHandle()  {  public  void  awaitTermination()  throws  InterruptedException  {                      latch.wait();                      latch.await();  }  };  }  }  class  Reaper  implements  Runnable  {  public  void  run()  {  	latch.await();  
elasticsearch_39cb08fc1c713835af3061c3a0360c2f76559724	buggy:  versionedMap  =  new  NonBlockingVersionedMap();  context:  public  class  VersionedIndexReaderTests  {  private  RAMDirectory  dir;  private  IndexReader  indexReader;  private  IndexWriter  indexWriter;  private  VersionedMap  versionedMap;          versionedMap  =  new  NonBlockingVersionedMap();          versionedMap  =  new  ConcurrentVersionedMapLong();  dir  =  new  RAMDirectory();  indexWriter  =  new  IndexWriter(dir,  Lucene.STANDARD_ANALYZER,  true,  IndexWriter.MaxFieldLength.UNLIMITED);  indexWriter.addDocument(doc().add(field( "value ",   "0 ")).build());  indexWriter.addDocument(doc().add(field( "value ",   "1 ")).build());  indexWriter.addDocument(doc().add(field( "value ",   "2 ")).build());  indexWriter.addDocument(doc().add(field( "value ",   "3 ")).build());  indexWriter.commit();  indexReader  =  IndexReader.open(dir,  true);  	versionedMap  =  new  ConcurrentVersionedMapLong();  
libgdx_8a436bdfd87bcf159009e9590034c7c7891aaca4	buggy:  return  0;  context:  EventQueue.invokeLater(this);  }  });  }  protected  int  getFrameRate  ()  {  int  frameRate  =  Display.isActive()  ?  graphics.config.foregroundFPS  :  graphics.config.backgroundFPS;  if  (frameRate  ==  -1)  frameRate  =  10;  if  (frameRate  ==  0)  frameRate  =  graphics.config.backgroundFPS;  if  (frameRate  ==  0)  frameRate  =  30;  return  0;  return  frameRate;  }  protected  void  exception  (Throwable  ex)  {  ex.printStackTrace();  stop();  }  	return  frameRate;  
elasticsearch_6cd3fc92edf0e02fa922e59c55e271a9fde9df02	buggy:  contentType  =  XContentFactory.xContentType(request.contentAsBytes());  context:  public  class  RestXContentBuilder  {  public  static  BinaryXContentBuilder  restContentBuilder(RestRequest  request)  throws  IOException  {  XContentType  contentType  =  XContentType.fromRestContentType(request.header( "Content-Type "));  if  (contentType  ==  null)  {  if  (request.hasContent())  {                  contentType  =  XContentFactory.xContentType(request.contentAsBytes());                  contentType  =  XContentFactory.xContentType(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  }  }  if  (contentType  ==  null)  {  contentType  =  XContentType.JSON;  }  BinaryXContentBuilder  builder  =  XContentFactory.contentBinaryBuilder(contentType);  if  (request.paramAsBoolean( "pretty ",  false))  {  	contentType  =  XContentFactory.xContentType(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  
elasticsearch_ec6fa83856654d33f5939cc6e530f6b70149b9ae	buggy:  if  (context.includeInAll(includeInAll))  {  context:  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  ipAsString  =  nullValue;  }  else  {  ipAsString  =  context.parser().text();  }  }  if  (ipAsString  ==  null)  {  return  null;  }          if  (context.includeInAll(includeInAll))  {          if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  ipAsString,  boost);  }  final  long  value  =  ipToLong(ipAsString);  return  new  LongFieldMapper.CustomLongNumericField(this,  value);  }  	if  (context.includeInAll(includeInAll,  this))  {  
elasticsearch_9a13763315e8da781bf7f7b6e12c8819f9271513	buggy:  List<Object>  values  =  lookup.source().getValues(mapper.names().fullName());  context:  }  public  static  final  Field[]  EMPTY_FIELDS  =  new  Field[0];  SearchLookup  lookup  =  searchContext.lookup();  lookup.setNextReader(reader);  lookup.setNextDocId(docId);          List<Object>  values  =  lookup.source().getValues(mapper.names().fullName());          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  if  (values.isEmpty())  {  return  EMPTY_FIELDS;  }  Field[]  fields  =  new  Field[values.size()];  for  (int  i  =  0;  i  <  values.size();  i++)  {  fields[i]  =  new  Field(mapper.names().indexName(),  values.get(i).toString(),  Field.Store.NO,  Field.Index.ANALYZED);  }  return  fields;  	List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  
elasticsearch_5706858722452b13465b15930e4f4cb2e8286449	buggy:  true,  request.version(),  request.versionType(),  FetchSourceContext.FETCH_SOURCE);  context:  public  Result  prepare(UpdateRequest  request)  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  return  prepare(request,  indexShard);  }  public  Result  prepare(UpdateRequest  request,  IndexShard  indexShard)  {  long  getDate  =  System.currentTimeMillis();  final  GetResult  getResult  =  indexShard.getService().get(request.type(),  request.id(),  new  String[]{RoutingFieldMapper.NAME,  ParentFieldMapper.NAME,  TTLFieldMapper.NAME},                  true,  request.version(),  request.versionType(),  FetchSourceContext.FETCH_SOURCE);                  true,  request.version(),  request.versionType(),  FetchSourceContext.FETCH_SOURCE,  false);  if  (!getResult.isExists())  {  if  (request.upsertRequest()  ==  null  &&  !request.docAsUpsert())  {  throw  new  DocumentMissingException(new  ShardId(request.index(),  request.shardId()),  request.type(),  request.id());  }  IndexRequest  indexRequest  =  request.docAsUpsert()  ?  request.doc()  :  request.upsertRequest();  indexRequest.index(request.index()).type(request.type()).id(request.id())  	true,  request.version(),  request.versionType(),  FetchSourceContext.FETCH_SOURCE,  false);  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  public  class  ScrollPane2Test  extends  GdxTest  {  Stage  stage;  Skin  skin;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false);  Gdx.input.setInputProcessor(stage);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  Table  mytable  =  new  Table();  mytable.debug();  mytable.add(new  Image(new  Texture( "data/group-debug.png ")));  mytable.row();  mytable.add(new  Image(new  Texture( "data/group-debug.png ")));  mytable.row();  mytable.add(new  Image(new  Texture( "data/group-debug.png ")));  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(searchSource,  true);  context:  for  (String  type  :  searchTypes)  {  out.writeUTF(type);  }  }  if  (searchScroll  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  searchScroll.writeTo(out);  }          out.writeBytesReference(searchSource,  true);          out.writeBytesReference(searchSource);  out.writeVInt(searchSize);  out.writeVInt(searchFrom);  }  }  	out.writeBytesReference(searchSource);  
elasticsearch_4bcedde0116807979c6e4ac59b32b0208354d95a	buggy:  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.source()));  context:  request.index(clusterState.metaData().concreteIndex(request.index()));  return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.source()));          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  return  new  PercolateResponse(percolate.matches());  }  }  	PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  
elasticsearch_baaac70da5618921d7be09177aa4283b10c368ac	buggy:  dateTimeFormatter.formatter().parseMillis(jsonContext.jp().getText());  context:  mapper.parse(jsonContext);  return;  }  BuilderContext  builderContext  =  new  BuilderContext(jsonContext.path());  if  (token  ==  JsonToken.VALUE_STRING)  {  boolean  isDate  =  false;  for  (FormatDateTimeFormatter  dateTimeFormatter  :  dateTimeFormatters)  {  try  {                          dateTimeFormatter.formatter().parseMillis(jsonContext.jp().getText());                          dateTimeFormatter.parser().parseMillis(jsonContext.jp().getText());  mapper  =  dateField(currentFieldName).dateTimeFormatter(dateTimeFormatter).build(builderContext);  isDate  =  true;  break;  }  catch  (Exception  e)  {  }  }  if  (!isDate)  {  	dateTimeFormatter.parser().parseMillis(jsonContext.jp().getText());  
elasticsearch_7d6c567e6f879cc502c05cc433f2af9631d7bc5c	buggy:  return  DocIdSet.EMPTY_DOCIDSET;  context:  public  DocIdSet  getDocIdSet(IndexReader  reader)  throws  IOException  {  if  (parents  ==  null)  {  throw  new  ElasticSearchIllegalStateException( "has_parent  filter/query  hasn't  executed  properly ");  }  IdReaderTypeCache  idReaderTypeCache  =  context.idCache().reader(reader).type(parentType);  if  (idReaderTypeCache  !=  null)  {  return  new  ChildrenDocSet(reader,  parents,  idReaderTypeCache);  }  else  {                  return  DocIdSet.EMPTY_DOCIDSET;                  return  null;  }  }  public  void  clear()  {  if  (parents  !=  null)  {  CacheRecycler.pushHashSet(parents);  }  parents  =  null;  	return  null;  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(int  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  IntegerFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  IntegerFieldMapper  fieldMapper  =  new  IntegerFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_fe50a6f64e59fa84aa270388217fcba67dc6f1a8	buggy:  holderToNotify.handler().handleException(new  NodeDisconnectedTransportException(node,  holderToNotify.action()));  context:  for  (Map.Entry<Long,  RequestHolder>  entry  :  clientHandlers.entrySet())  {  RequestHolder  holder  =  entry.getValue();  if  (holder.node().equals(node))  {  final  RequestHolder  holderToNotify  =  clientHandlers.remove(entry.getKey());  if  (holderToNotify  !=  null)  {  threadPool.execute(new  Runnable()  {                                          holderToNotify.handler().handleException(new  NodeDisconnectedTransportException(node,  holderToNotify.action()));                                          holderToNotify.handler().handleException(new  NodeDisconnectedException(node,  holderToNotify.action()));  }  });  }  }  }  }  });  }  	holderToNotify.handler().handleException(new  NodeDisconnectedException(node,  holderToNotify.action()));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  bucketsByKey.release();  context:  }  List<B>  reducedBuckets  =  new  ArrayList<>((int)  bucketsByKey.size());  for  (LongObjectPagedHashMap.Cursor<List<B>>  cursor  :  bucketsByKey)  {  List<B>  sameTermBuckets  =  cursor.value;  B  bucket  =  sameTermBuckets.get(0).reduce(sameTermBuckets,  reduceContext.bigArrays());  if  (bucket.getDocCount()  >=  minDocCount)  {  reducedBuckets.add(bucket);  }  }          bucketsByKey.release();          bucketsByKey.close();  if  (minDocCount  ==  0)  {  CollectionUtil.introSort(reducedBuckets,  order.asc  ?  InternalOrder.KEY_ASC.comparator()  :  InternalOrder.KEY_DESC.comparator());  List<B>  list  =  order.asc  ?  reducedBuckets  :  Lists.reverse(reducedBuckets);  B  lastBucket  =  null;  ExtendedBounds  bounds  =  emptyBucketInfo.bounds;  ListIterator<B>  iter  =  list.listIterator();  	bucketsByKey.close();  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  return  new  NodeHotThreads(clusterService.state().nodes().localNode(),  hotThreads.detect());  context:  }  protected  NodeHotThreads  nodeOperation(NodeRequest  request)  throws  ElasticSearchException  {  HotThreads  hotThreads  =  new  HotThreads()  .busiestThreads(request.request.threads)  .type(request.request.type)  .interval(request.request.interval)  .threadElementsSnapshotCount(request.request.snapshots);  try  {              return  new  NodeHotThreads(clusterService.state().nodes().localNode(),  hotThreads.detect());              return  new  NodeHotThreads(clusterService.localNode(),  hotThreads.detect());  }  catch  (Exception  e)  {  throw  new  ElasticSearchException( "failed  to  detect  hot  threads ",  e);  }  }  protected  boolean  accumulateExceptions()  {  return  false;  	return  new  NodeHotThreads(clusterService.localNode(),  hotThreads.detect());  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  keyFieldData  =  (NumericFieldData)  fieldDataCache.cache(keyFieldDataType,  context.reader(),  keyFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  else  {  aggregator.valueFieldData  =  (NumericFieldData)  fieldDataCache.cache(valueFieldDataType,  context.reader(),  valueFieldName);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  keyFieldData.forEachValueInDoc(doc,  aggregator);  	script.setNextReader(context);  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper);  context:  token  =  parser.nextToken();  if  (token  !=  XContentParser.Token.END_OBJECT)  {  throw  new  QueryParsingException(parseContext.index(),   "[range]  query  malformed,  does  not  end  with  an  object ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper);                  query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper,  parseContext);  }  }  if  (query  ==  null)  {  query  =  new  TermRangeQuery(fieldName,  from,  to,  includeLower,  includeUpper);  }  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  	query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper,  parseContext);  
libgdx_0d6b6ad77103ccecc5067a10d406719569d7e2ee	buggy:  if  (hit  ==  null  &&  isModal)  return  this;  context:  else  y  -=  (getPadTop()  -  bounds.height)  /  2;  }  titleCache.setColor(Color.tmp.set(getColor()).mul(style.titleFontColor));  titleCache.setPosition((int)x,  (int)y);  titleCache.draw(batch,  parentAlpha);  }  public  Actor  hit  (float  x,  float  y,  boolean  touchable)  {  Actor  hit  =  super.hit(x,  y,  touchable);  if  (hit  ==  null  &&  isModal)  return  this;  if  (hit  ==  null  &&  isModal  &&  (!touchable  ||  getTouchable()  ==  Touchable.enabled))  return  this;  return  hit;  }  public  void  setTitle  (String  title)  {  this.title  =  title;  titleCache.setMultiLineText(title,  0,  0);  }  	if  (hit  ==  null  &&  isModal  &&  (!touchable  ||  getTouchable()  ==  Touchable.enabled))  return  this;  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  context:  return  TransportActions.PERCOLATE;  }  return   "indices/percolate/shard ";  }  request.index(clusterState.metaData().concreteIndex(request.index()));          return  clusterState.routingTable().index(request.index()).randomAllShardsIt();          return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  return  new  PercolateResponse(percolate.matches());  	return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  
elasticsearch_924f91588b6c8cf6ff8826efb6023c87a3c99e7d	buggy:  final  int  numberOfThreads  =  scaledRandomIntBetween(5,10);  context:  .startObject()  .startObject( "type1 ")  .startObject( "_timestamp ").field( "enabled ",  true).field( "store ",   "yes ").endObject()  .startObject( "_ttl ").field( "enabled ",  true).field( "store ",   "yes ").endObject()  .endObject()  .endObject())  .setSettings(ImmutableSettings.builder().put(MergePolicyModule.MERGE_POLICY_TYPE_KEY,  NoMergePolicyProvider.class))  .execute().actionGet();  ensureGreen();          final  int  numberOfThreads  =  scaledRandomIntBetween(5,10);          final  int  numberOfThreads  =  scaledRandomIntBetween(3,5);  final  int  numberOfIdsPerThread  =  scaledRandomIntBetween(3,10);  final  int  numberOfUpdatesPerId  =  scaledRandomIntBetween(100,200);  final  int  retryOnConflict  =  randomIntBetween(0,1);  final  CountDownLatch  latch  =  new  CountDownLatch(numberOfThreads);  final  CountDownLatch  startLatch  =  new  CountDownLatch(1);  final  List<Throwable>  failures  =  new  CopyOnWriteArrayList<>();  final  class  UpdateThread  extends  Thread  {  	final  int  numberOfThreads  =  scaledRandomIntBetween(3,5);  
elasticsearch_588ae1ba9e41afdd7bf82cc1aa1892d6cc05a775	buggy:  return  new  FieldDataBreakerStats(breaker.getMaximum(),  breaker.getUsed(),  breaker.getOverhead());  context:  public  synchronized  void  resetBreaker()  {  final  MemoryCircuitBreaker  oldBreaker  =  this.breaker;  this.breaker  =  new  MemoryCircuitBreaker(new  ByteSizeValue(maxBytes),  overhead,  oldBreaker,  logger);  }  public  FieldDataBreakerStats  stats()  {          return  new  FieldDataBreakerStats(breaker.getMaximum(),  breaker.getUsed(),  breaker.getOverhead());          return  new  FieldDataBreakerStats(breaker.getMaximum(),  breaker.getUsed(),  breaker.getOverhead(),  breaker.getTrippedCount());  }  protected  void  doStart()  throws  ElasticsearchException  {  }  protected  void  doStop()  throws  ElasticsearchException  {  	return  new  FieldDataBreakerStats(breaker.getMaximum(),  breaker.getUsed(),  breaker.getOverhead(),  breaker.getTrippedCount());  
libgdx_6b0b467a791370bdb583901355ddaa31bdf2de9c	buggy:  listener.setup(  app  );  context:  this.width  =  width;  this.height  =  height;  }  public  void  onSurfaceCreated(javax.microedition.khronos.opengles.GL10  gl,  EGLConfig  config)  {  setupGL(  gl  );  if(  listener  !=  null  )  listener.setup(  app  );  listener.surfaceCreated(  app  );  }  public  float  getDeltaTime()  {  	listener.surfaceCreated(  app  );  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicArray<String>  nodes  =  new  AtomicArray<String>(3);  context:  .put( "discovery.zen.ping.multicast.ping.enabled ",  false)  .put( "discovery.zen.minimum_master_nodes ",  2)  .put( "discovery.zen.ping.unicast.hosts ",   "localhost:15300,localhost:15301,localhost:15302 ")  .put( "transport.tcp.port ",   "15300-15400 ")  .build();  final  CountDownLatch  latch  =  new  CountDownLatch(3);          final  AtomicArray<String>  nodes  =  new  AtomicArray<String>(3);          final  AtomicArray<String>  nodes  =  new  AtomicArray<>(3);  Runnable  r1  =  new  Runnable()  {  public  void  run()  {  nodes.set(0,  cluster().startNode(settings));  latch.countDown();  }  	final  AtomicArray<String>  nodes  =  new  AtomicArray<>(3);  
libgdx_d3151bcae8c112186bf127141eba9a2bfe6d46fc	buggy:  debugRenderer.render(world);  context:  angle);  //  the  rotation  angle  }  batch.end();  camera.apply(Gdx.gl10);  debugRenderer.render(world);  debugRenderer.render(world,  camera.combined);  gl.glPointSize(4);  renderer.begin(GL10.GL_POINTS);  for  (int  i  =  0;  i  <  world.getContactCount();  i++)  {  Contact  contact  =  world.getContactList().get(i);  if  (contact.isTouching())  {  	debugRenderer.render(world,  camera.combined);  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.indexCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  mltQuery.setAnalyzer(smartNameFieldMappers.mapper().searchAnalyzer());  }  }  if  (mltQuery.getAnalyzer()  ==  null)  {  mltQuery.setAnalyzer(parseContext.mapperService().searchAnalyzer());  }  mltQuery.setMoreLikeFields(new  String[]{fieldName});          return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext);  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  parseMultiField(builder,  name,  node,  parserContext,  propName,  propNode);  context:  }  if  (builder.searchAnalyzer  ==  null)  {  builder.searchAnalyzer  =  parserContext.analysisService().defaultSearchAnalyzer();  }  if  (builder.searchQuotedAnalyzer  ==  null)  {  builder.searchQuotedAnalyzer  =  parserContext.analysisService().defaultSearchQuoteAnalyzer();  }  }  else  if  (propName.equals( "ignore_above "))  {  builder.ignoreAbove(XContentMapValues.nodeIntegerValue(propNode,  -1));  }  else  {                      parseMultiField(builder,  name,  node,  parserContext,  propName,  propNode);                      parseMultiField(builder,  name,  parserContext,  propName,  propNode);  }  }  return  builder;  }  }  private  String  nullValue;  private  Boolean  includeInAll;  	parseMultiField(builder,  name,  parserContext,  propName,  propNode);  
libgdx_ee9c31351540f4bc3aa5f7a934bc198be2bf8ea7	buggy:  float  c  =  start.dist2(center)  -  radius  *  radius;  context:  public  static  boolean  intersectRaySphere  (Ray  ray,  Vector3  center,  float  radius,  Vector3  intersection)  {  dir.set(ray.direction).nor();  start.set(ray.origin);  float  b  =  2  *  (dir.dot(start.tmp().sub(center)));  float  c  =  start.dist2(center)  -  radius  *  radius;  float  c  =  start.dst2(center)  -  radius  *  radius;  float  disc  =  b  *  b  -  4  *  c;  if  (disc  <  0)  return  false;  float  distSqrt  =  (float)Math.sqrt(disc);  float  q;  if  (b  <  0)  q  =  (-b  -  distSqrt)  /  2.0f;  	float  c  =  start.dst2(center)  -  radius  *  radius;  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(2).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode( "node1 ")).put(newNode( "node2 "))).build();  RoutingTable  prevRoutingTable  =  routingTable;  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
libgdx_316757eba548254ac303543fa185b5860230e98d	buggy:  if  (type  instanceof  IntBuffer)  ((IntBuffer)type).put(typeTmp.get(0));  context:  size.put(typeTmp.get(0));  if  (type  instanceof  IntBuffer)  ((IntBuffer)type).put(typeTmp.get(1));  return  name;  }  public  String  glGetActiveUniform  (int  program,  int  index,  IntBuffer  size,  Buffer  type)  {  IntBuffer  typeTmp  =  BufferUtils.createIntBuffer(2);  String  name  =  GL20.glGetActiveUniform(program,  index,  256,  typeTmp);  size.put(typeTmp.get(0));  if  (type  instanceof  IntBuffer)  ((IntBuffer)type).put(typeTmp.get(0));  if  (type  instanceof  IntBuffer)  ((IntBuffer)type).put(typeTmp.get(1));  return  name;  }  public  void  glGetAttachedShaders  (int  program,  int  maxcount,  Buffer  count,  IntBuffer  shaders)  {  GL20.glGetAttachedShaders(program,  (IntBuffer)count,  shaders);  }  public  int  glGetAttribLocation  (int  program,  String  name)  {  	if  (type  instanceof  IntBuffer)  ((IntBuffer)type).put(typeTmp.get(1));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  public  InternalFacet  buildFacet(String  facetName)  {  List<InternalFullHistogramFacet.FullEntry>  fullEntries  =  new  ArrayList<>(entries.v().size());  boolean[]  states  =  entries.v().allocated;  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  fullEntries.add((InternalFullHistogramFacet.FullEntry)  values[i]);  }  }          entries.release();          entries.close();  return  new  InternalFullHistogramFacet(facetName,  comparatorType,  fullEntries);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  class  Collector  extends  FacetExecutor.Collector  {  	entries.close();  
elasticsearch_371b071fb791a73f6757c813200877ff3b6c8824	buggy:  searchContext.addScopePhase(childFilter);  context:  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  HasChildFilter  childFilter  =  HasChildFilter.create(query,  null,  parentType,  childType,  searchContext,  executionType);          searchContext.addScopePhase(childFilter);          searchContext.addRewrite(childFilter);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  childFilter);  }  return  childFilter;  }  }  	searchContext.addRewrite(childFilter);  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(dateRange( "date_range ").addRange( "0-1 ",  0,  1)))  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(dateRange( "date_range ").addRange( "0-1 ",  0,  1)))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(dateRange( "date_range ").addRange( "0-1 ",  0,  1)))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(dateRange( "date_range ").addRange( "0-1 ",  0,  1)))  
elasticsearch_723a40ef34b634e0f7d8c0e77490ffa5cc004817	buggy:  if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta))  {  context:  public  void  setAllowUnmappedFields(boolean  allowUnmappedFields)  {  this.allowUnmappedFields  =  allowUnmappedFields;  }  private  <T>  T  failIfFieldMappingNotFound(String  name,  T  fieldMapping)  {  if  (allowUnmappedFields)  {  return  fieldMapping;  }  else  {  Version  indexCreatedVersion  =  indexQueryParser.getIndexCreatedVersion();              if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta))  {              if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1))  {  throw  new  QueryParsingException(index,   "Strict  field  resolution  and  no  field  mapping  can  be  found  for  the  field  with  name  [ "  +  name  +   "] ");  }  else  {  return  fieldMapping;  }  }  }  	if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1))  {  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/{index}/_ping/replication ",  this);  }  ReplicationPingRequest  replicationPingRequest  =  new  ReplicationPingRequest(RestActions.splitIndices(request.param( "index ")));  replicationPingRequest.timeout(request.paramAsTime( "timeout ",  ShardReplicationPingRequest.DEFAULT_TIMEOUT));  replicationPingRequest.listenerThreaded(false);  client.admin().cluster().execPing(replicationPingRequest,  new  ActionListener<ReplicationPingResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  for  (IndexReplicationPingResponse  indexResponse  :  result.indices().values())  {  builder.startObject(indexResponse.index())  .field( "ok ",  true)  .field( "totalShards ",  indexResponse.totalShards())  .field( "successfulShards ",  indexResponse.successfulShards())  .field( "failedShards ",  indexResponse.failedShards())  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_0f121ff3517c9566df8543eec2c6e85e76603747	buggy:  .put( "discovery.zen.ping_timeout ",   "200ms ")  context:  }  assertTrue(controlSources.isEmpty());  block2.countDown();  }  public  void  testLocalNodeMasterListenerCallbacks()  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "discovery.type ",   "zen ")  .put( "discovery.zen.minimum_master_nodes ",  1)                  .put( "discovery.zen.ping_timeout ",   "200ms ")                  .put( "discovery.zen.ping_timeout ",   "400ms ")  .put( "discovery.initial_state_timeout ",   "500ms ")  .put( "plugin.types ",  TestPlugin.class.getName())  .build();  internalCluster().startNode(settings);  ClusterService  clusterService  =  internalCluster().getInstance(ClusterService.class);  MasterAwareService  testService  =  internalCluster().getInstance(MasterAwareService.class);  	.put( "discovery.zen.ping_timeout ",   "400ms ")  
libgdx_d32a5e0fed31ba373f4f867d417bb8154cfca5b8	buggy:  slidingPlaneNormal.set(  packet.position  ).sub(  packet.getIntersectionPoint()  ).nor();  context:  {  newVelocity.set(  packet.velocity  ).nor().mul(packet.getNearestDistance()  -  displacementDistance  );  newPosition.add(  newVelocity  );  newVelocity.nor();  packet.getIntersectionPoint().sub(  newVelocity.mul(  displacementDistance  )  );  }  slidingPlaneOrigin.set(  packet.getIntersectionPoint()  );  slidingPlaneNormal.set(  packet.position  ).sub(  packet.getIntersectionPoint()  ).nor();  slidingPlaneNormal.set(  newPosition  ).sub(  packet.getIntersectionPoint()  ).nor();  slidingPlane.set(  slidingPlaneOrigin,  slidingPlaneNormal  );  newDestination.set(  destination  ).sub(  slidingPlane.normal.mul(slidingPlane.distance(  destination  ))  );  newVelocity.set(  newDestination  ).sub(  packet.getIntersectionPoint()  );  packet.velocity.set(  newVelocity  );  packet.position.set(  newPosition  );  }  	slidingPlaneNormal.set(  newPosition  ).sub(  packet.getIntersectionPoint()  ).nor();  
libgdx_045b0211fb25a30804e717f2f0aa968f1c679efb	buggy:  if  (!valid)  throw  new  GdxRuntimeException( "Array#iterator()  cannot  be  used  nested. ");  context:  public  ArrayIterator  (Array<T>  array)  {  this.array  =  array;  }  public  boolean  hasNext  ()  {  return  index  <  array.size;  }  public  T  next  ()  {  if  (index  >=  array.size)  throw  new  NoSuchElementException(String.valueOf(index));  if  (!valid)  throw  new  GdxRuntimeException( "Array#iterator()  cannot  be  used  nested. ");  if  (!valid)  throw  new  GdxRuntimeException( "#iterator()  cannot  be  used  nested. ");  return  array.items[index++];  }  public  void  remove  ()  {  index--;  array.removeIndex(index);  }  	if  (!valid)  throw  new  GdxRuntimeException( "#iterator()  cannot  be  used  nested. ");  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  ValueAndBoost  valueAndBoost  =  StringFieldMapper.parseCreateFieldForString(context,  null  /*  Out  null  value  is  an  int  so  we  convert*/,  context.fieldBoost(this));  context:  SimilarityProvider  similarity,  Loading  normsLoading,  Settings  fieldDataSettings,  Settings  indexSettings,  NamedAnalyzer  analyzer,  MultiFields  multiFields,  CopyTo  copyTo)  {  super(names,  precisionStep,  boost,  fieldType,  docValues,  nullValue,  ignoreMalformed,  coerce,  postingsProvider,  docValuesProvider,  similarity,  normsLoading,  fieldDataSettings,  indexSettings,  multiFields,  copyTo);  this.analyzer  =  analyzer;  }  protected  void  parseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {          ValueAndBoost  valueAndBoost  =  StringFieldMapper.parseCreateFieldForString(context,  null  /*  Out  null  value  is  an  int  so  we  convert*/,  context.fieldBoost(this));          ValueAndBoost  valueAndBoost  =  StringFieldMapper.parseCreateFieldForString(context,  null  /*  Out  null  value  is  an  int  so  we  convert*/,  boost);  if  (valueAndBoost.value()  ==  null  &&  nullValue()  ==  null)  {  return;  }  if  (fieldType.indexed()  ||  fieldType.stored()  ||  hasDocValues())  {  int  count;  if  (valueAndBoost.value()  ==  null)  {  count  =  nullValue();  	ValueAndBoost  valueAndBoost  =  StringFieldMapper.parseCreateFieldForString(context,  null  /*  Out  null  value  is  an  int  so  we  convert*/,  boost);  
elasticsearch_3c8cf68a17094ed31e8943171d4b2678325b4d9a	buggy:  threadPool.execute(new  Runnable()  {  context:  private  final  ThreadPool  threadPool;  private  final  TimerTask  task;  private  ThreadedTimerTask(ThreadPool  threadPool,  TimerTask  task)  {  this.threadPool  =  threadPool;  this.task  =  task;  }              threadPool.execute(new  Runnable()  {              threadPool.cached().execute(new  Runnable()  {  try  {  task.run(timeout);  }  catch  (Exception  e)  {  }  }  });  	threadPool.cached().execute(new  Runnable()  {  
elasticsearch_15bdba30e5901361a0408d8e8b4068bef66169ec	buggy:  if  (propName.equals( "nullValue "))  {  context:  public  static  class  TypeParser  implements  JsonTypeParser  {  ObjectNode  shortNode  =  (ObjectNode)  node;  JsonShortFieldMapper.Builder  builder  =  shortField(name);  parseNumberField(builder,  name,  shortNode,  parserContext);  for  (Iterator<Map.Entry<String,  JsonNode>>  propsIt  =  shortNode.getFields();  propsIt.hasNext();)  {  Map.Entry<String,  JsonNode>  entry  =  propsIt.next();  String  propName  =  entry.getKey();  JsonNode  propNode  =  entry.getValue();                  if  (propName.equals( "nullValue "))  {                  if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  builder.nullValue(nodeShortValue(propNode));  }  }  return  builder;  }  }  private  final  Short  nullValue;  	if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  
elasticsearch_72629fc5ec60edd6f8159a2f02bbc14c41ae579d	buggy:  return  transport.clientChannels.size();  context:  public  class  NettyTransportManagement  {  private  final  NettyTransport  transport;  this.transport  =  transport;  }  public  long  getNumberOfOutboundConnections()  {          return  transport.clientChannels.size();          return  transport.connectedNodes.size();  }  public  int  getWorkerCount()  {  return  transport.workerCount;  }  	return  transport.connectedNodes.size();  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  IndicesStatusRequest  indicesStatusRequest  =  new  IndicesStatusRequest(splitIndices(request.param( "index ")));  indicesStatusRequest.listenerThreaded(false);  if  (request.hasParam( "ignore_indices "))  {  indicesStatusRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }  indicesStatusRequest.recovery(request.paramAsBoolean( "recovery ",  indicesStatusRequest.recovery()));  indicesStatusRequest.snapshot(request.paramAsBoolean( "snapshot ",  indicesStatusRequest.snapshot()));          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  indicesStatusRequest.operationThreading(operationThreading);  client.admin().indices().status(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {  public  void  onResponse(IndicesStatusResponse  response)  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_b128b7a7509ee0cda67fdc8e28844cbc55bd1449	buggy:  UAX29URLEmailTokenizer  tokenizer  =  new  UAX29URLEmailTokenizer(reader);  context:  private  final  int  maxTokenLength;  public  UAX29URLEmailTokenizerFactory(Index  index,  @IndexSettings  Settings  indexSettings,  @Assisted  String  name,  @Assisted  Settings  settings)  {  super(index,  indexSettings,  name,  settings);  maxTokenLength  =  settings.getAsInt( "max_token_length ",  StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);  }  public  Tokenizer  create(Reader  reader)  {          UAX29URLEmailTokenizer  tokenizer  =  new  UAX29URLEmailTokenizer(reader);          UAX29URLEmailTokenizer  tokenizer  =  new  UAX29URLEmailTokenizer(version,  reader);  tokenizer.setMaxTokenLength(maxTokenLength);  return  tokenizer;  }  }  	UAX29URLEmailTokenizer  tokenizer  =  new  UAX29URLEmailTokenizer(version,  reader);  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
libgdx_cfd67486c3b1b287313fcdf1261ea46a0091161c	buggy:  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "  -v ");  context:  android.cFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.cppFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.headerDirs  =  headerDirs;  android.cIncludes  =  cIncludes;  android.cppIncludes  =  cppIncludes;  android.cppExcludes  =  cppExcludes;  android.preCompileTask  =  precompileTask;  new  AntScriptGenerator().generate(buildConfig,  win32home,  win32,  win64,  lin32,  lin64,  android);  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "  -v ");  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "clean  postcompile  -v ");  BuildExecutor.executeAnt( "jni/build.xml ",   "pack-natives  -v ");  }  }  	BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "clean  postcompile  -v ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  fields  =  new  HashMap<String,  GetField>(fieldVisitor.fields().size());  context:  if  (fieldVisitor  !=  null)  {  try  {  docIdAndVersion.context.reader().document(docIdAndVersion.docId,  fieldVisitor);  }  catch  (IOException  e)  {  throw  new  ElasticsearchException( "Failed  to  get  type  [ "  +  type  +   "]  and  id  [ "  +  id  +   "] ",  e);  }  source  =  fieldVisitor.source();  if  (!fieldVisitor.fields().isEmpty())  {  fieldVisitor.postProcess(docMapper);                  fields  =  new  HashMap<String,  GetField>(fieldVisitor.fields().size());                  fields  =  new  HashMap<>(fieldVisitor.fields().size());  for  (Map.Entry<String,  List<Object>>  entry  :  fieldVisitor.fields().entrySet())  {  fields.put(entry.getKey(),  new  GetField(entry.getKey(),  entry.getValue()));  }  }  }  if  (gFields  !=  null  &&  gFields.length  >  0)  {  	fields  =  new  HashMap<>(fieldVisitor.fields().size());  
libgdx_261d5100ad73ab0990b7e2b31574c937ba981f73	buggy:  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_8888  );  context:  return  (int)(Math.ceil(width[0]));  }  public  Pixmap  getGlyphBitmap(char  character)  {  Rect  rect  =  new  Rect();  paint.getTextBounds(   " "  +  character,  0,  1,  rect  );  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  Bitmap.Config.ARGB_8888  );  Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  AndroidPixmap.getInternalFormat(Font.pixelFormat)  );  Canvas  g  =  new  Canvas(  bitmap  );  paint.setAntiAlias(true);  paint.setColor(0x00000000);  paint.setStyle(Style.FILL);  g.drawRect(  new  Rect(  0,  0,  rect.width()  +  5,  getLineHeight()),  paint);  paint.setColor(0xFFFFFFFF);  g.drawText(   " "  +  character,  0,  -metrics.ascent,  paint  );  return  new  AndroidPixmap(  bitmap  );  	Bitmap  bitmap  =  Bitmap.createBitmap(  rect.width()==0?1:rect.width()  +  5,  getLineHeight(),  AndroidPixmap.getInternalFormat(Font.pixelFormat)  );  
elasticsearch_ee2fabb9ddb5cc8f17051a64b6237356927bac80	buggy:  return  Status.CONTINUE;  context:  org.elasticsearch.thrift.RestResponse  tResponse  =  new  org.elasticsearch.thrift.RestResponse(getStatus(response.status()));  if  (response.contentLength()  >  0)  {  tResponse.setBody(ByteBuffer.wrap(response.content(),  0,  response.contentLength()));  }  return  tResponse;  }  private  Status  getStatus(RestResponse.Status  status)  {  switch  (status)  {  case  CONTINUE:                  return  Status.CONTINUE;                  return  Status.CONT;  case  SWITCHING_PROTOCOLS:  return  Status.SWITCHING_PROTOCOLS;  case  OK:  return  Status.OK;  case  CREATED:  return  Status.CREATED;  case  ACCEPTED:  return  Status.ACCEPTED;  	return  Status.CONT;  
elasticsearch_221992548523681ff7eb67ebcfd4f72ab3cdef5a	buggy:  fragListBuilder  =  field.fragmentOffset()  ==  -1  ?  new  XSimpleFragListBuilder()  :  new  XSimpleFragListBuilder(field.fragmentOffset());  context:  if  (field.numberOfFragments()  ==  0)  {  fragListBuilder  =  new  SingleFragListBuilder();  if  (mapper.fieldType().stored())  {  fragmentsBuilder  =  new  SimpleFragmentsBuilder(field.preTags(),  field.postTags(),  boundaryScanner);  }  else  {  fragmentsBuilder  =  new  SourceSimpleFragmentsBuilder(mapper,  context,  field.preTags(),  field.postTags(),  boundaryScanner);  }  }  else  {                                  fragListBuilder  =  field.fragmentOffset()  ==  -1  ?  new  XSimpleFragListBuilder()  :  new  XSimpleFragListBuilder(field.fragmentOffset());                                  fragListBuilder  =  field.fragmentOffset()  ==  -1  ?  new  SimpleFragListBuilder()  :  new  SimpleFragListBuilder(field.fragmentOffset());  if  (field.scoreOrdered())  {  if  (mapper.fieldType().stored())  {  fragmentsBuilder  =  new  ScoreOrderFragmentsBuilder(field.preTags(),  field.postTags(),  boundaryScanner);  }  else  {  fragmentsBuilder  =  new  SourceScoreOrderFragmentsBuilder(mapper,  context,  field.preTags(),  field.postTags(),  boundaryScanner);  }  }  else  {  if  (mapper.fieldType().stored())  {  	fragListBuilder  =  field.fragmentOffset()  ==  -1  ?  new  SimpleFragListBuilder()  :  new  SimpleFragListBuilder(field.fragmentOffset());  
libgdx_cb7ea54d31d0735d0bb4d2727d043a858b3905a7	buggy:  model.setAnimation(model.getAnimations()[0].name,  0);  context:  lineNum  =  1;  try  {  String  version  =  readString(in);  if(!version.equals( "g3dt-keyframed-1.0 "))  throw  new  GdxRuntimeException( "incorrect  version ");  int  numMeshes  =  readInt(in);  KeyframedSubMesh[]  subMeshes  =  new  KeyframedSubMesh[numMeshes];  for(int  i  =  0;  i  <  numMeshes;  i++)  {  subMeshes[i]  =  readMesh(in);  }  KeyframedModel  model  =  new  KeyframedModel(subMeshes);  model.setAnimation(model.getAnimations()[0].name,  0);  model.setAnimation(model.getAnimations()[0].name,  0,  false);  return  model;  }  catch(Throwable  e)  {  throw  new  GdxRuntimeException( "Couldn't  read  keyframed  model,  error  in  line   "  +  lineNum  +   ",  ' "  +  line  +   "'  :   "  +  e.getMessage(),  e);  }  }  private  static  KeyframedSubMesh  readMesh(BufferedReader  in)  throws  IOException  {  String  name  =  readString(in);  	model.setAnimation(model.getAnimations()[0].name,  0,  false);  
elasticsearch_53935f078a73c828be301a2c850e139ba9c2a8c9	buggy:  List<LongEntry>  ordered  =  new  ArrayList<LongEntry>();  context:  }  if  (requiredSize  ==  0)  {  //  all  terms  LongEntry[]  entries1  =  map.values(new  LongEntry[map.size()]);  Arrays.sort(entries1,  comparatorType.comparator());  return  new  InternalTermsStatsLongFacet(name,  comparatorType,  requiredSize,  Arrays.asList(entries1),  missing);  }  else  {  Object[]  values  =  map.internalValues();  Arrays.sort(values,  (Comparator)  comparatorType.comparator());              List<LongEntry>  ordered  =  new  ArrayList<LongEntry>();              List<LongEntry>  ordered  =  new  ArrayList<LongEntry>(map.size());  for  (int  i  =  0;  i  <  requiredSize;  i++)  {  LongEntry  value  =  (LongEntry)  values[i];  if  (value  ==  null)  {  break;  }  ordered.add(value);  }  return  new  InternalTermsStatsLongFacet(name,  comparatorType,  requiredSize,  ordered,  missing);  	List<LongEntry>  ordered  =  new  ArrayList<LongEntry>(map.size());  
elasticsearch_cb839b56b26406ad3d93ccbb8979908db74a2ec6	buggy:  return  new  ExecutorHolder(MoreExecutors.sameThreadExecutor(),  new  Info(name,  type));  context:  }  Info  previousInfo  =  previousExecutorHolder  !=  null  ?  previousExecutorHolder.info  :  null;  String  type  =  settings.get( "type ",  previousInfo  !=  null  ?  previousInfo.getType()  :  defaultSettings.get( "type "));  ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(this.settings,  name);  if  ( "same ".equals(type))  {  if  (previousExecutorHolder  !=  null)  {  }  else  {  }              return  new  ExecutorHolder(MoreExecutors.sameThreadExecutor(),  new  Info(name,  type));              return  new  ExecutorHolder(MoreExecutors.directExecutor(),  new  Info(name,  type));  }  else  if  ( "cached ".equals(type))  {  TimeValue  defaultKeepAlive  =  defaultSettings.getAsTime( "keep_alive ",  timeValueMinutes(5));  if  (previousExecutorHolder  !=  null)  {  if  ( "cached ".equals(previousInfo.getType()))  {  TimeValue  updatedKeepAlive  =  settings.getAsTime( "keep_alive ",  previousInfo.getKeepAlive());  if  (!previousInfo.getKeepAlive().equals(updatedKeepAlive))  {  ((EsThreadPoolExecutor)  previousExecutorHolder.executor).setKeepAliveTime(updatedKeepAlive.millis(),  TimeUnit.MILLISECONDS);  	return  new  ExecutorHolder(MoreExecutors.directExecutor(),  new  Info(name,  type));  
elasticsearch_daedf853a010a882f99cfe9605264adac6746a42	buggy:  @Test  @TestLogging( "org.elasticsearch.cluster.metadata:TRACE ")  context:  CloseIndexResponse  closeIndexResponse  =  client.admin().indices().prepareClose( "test1-alias ").execute().actionGet();  assertThat(closeIndexResponse.isAcknowledged(),  equalTo(true));  assertIndexIsClosed( "test1 ");  OpenIndexResponse  openIndexResponse  =  client.admin().indices().prepareOpen( "test1-alias ").execute().actionGet();  assertThat(openIndexResponse.isAcknowledged(),  equalTo(true));  assertIndexIsOpened( "test1 ");  }      @Test  @TestLogging( "org.elasticsearch.cluster.metadata:TRACE ")      @Test  @TestLogging( "cluster.metadata:TRACE ")  public  void  testCloseOpenAliasMultipleIndices()  {  Client  client  =  client();  createIndex( "test1 ",   "test2 ");  ClusterHealthResponse  healthResponse  =  client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();  assertThat(healthResponse.isTimedOut(),  equalTo(false));  IndicesAliasesResponse  aliasesResponse1  =  client.admin().indices().prepareAliases().addAlias( "test1 ",   "test-alias ").execute().actionGet();  assertThat(aliasesResponse1.isAcknowledged(),  equalTo(true));  	@Test  @TestLogging( "cluster.metadata:TRACE ")  
elasticsearch_ca8ff571f9266609ff3559355d8b5626e58d183d	buggy:  .put(indexSettings())  context:  phraseSuggestion.clearCandidateGenerators()  .addCandidateGenerator(candidateGenerator( "body ").minWordLength(1).prefixLength(1).suggestMode( "always ").size(2).accuracy(0.1f));  searchSuggest  =  searchSuggest(   "Xorr  the  Gut-Jewel ",  phraseSuggestion);  assertSuggestion(searchSuggest,  0,   "simple_phrase ",   "xorr  the  god  jewel ");  }  public  void  testPhraseBoundaryCases()  throws  ElasticsearchException,  IOException  {  CreateIndexRequestBuilder  builder  =  prepareCreate( "test ").setSettings(settingsBuilder()                  .put(indexSettings())                  .put(indexSettings()).put(SETTING_NUMBER_OF_SHARDS,  1)  //  to  get  reliable  statistics  we  should  put  this  all  into  one  shard  .put( "index.analysis.analyzer.body.tokenizer ",   "standard ")  .putArray( "index.analysis.analyzer.body.filter ",   "lowercase ")  .put( "index.analysis.analyzer.bigram.tokenizer ",   "standard ")  .putArray( "index.analysis.analyzer.bigram.filter ",   "my_shingle ",   "lowercase ")  .put( "index.analysis.analyzer.ngram.tokenizer ",   "standard ")  .putArray( "index.analysis.analyzer.ngram.filter ",   "my_shingle2 ",   "lowercase ")  .put( "index.analysis.analyzer.myDefAnalyzer.tokenizer ",   "standard ")  .putArray( "index.analysis.analyzer.myDefAnalyzer.filter ",   "shingle ",   "lowercase ")  	.put(indexSettings()).put(SETTING_NUMBER_OF_SHARDS,  1)  //  to  get  reliable  statistics  we  should  put  this  all  into  one  shard  
libgdx_ac686b47406849d3fc10bc054c557e71724e8467	buggy:  vboBatch  =  new  SpriteBatch(1000,  VertexDataType.VertexBufferObject);  context:  long  startTime;  int  frames;  String[]  modes  =  {   "SpriteBatch  blended ",   "SpriteBatch  not  blended ",   "SpriteBatch  animated  blended ",   "SpriteBatch  animated  not  blended ",   "SpriteBatch  VBO  blended ",   "SpriteBatch  VBO  not  blended ",   "SpriteBatch  VBO  animated  blended ",   "SpriteBatch  VBO  animated  not  blended ",   "SpriteCache  blended ",   "SpriteCache  not  blended "  };  int  mode  =  0;  public  void  create()  {  texture  =  Gdx.graphics.newTexture(Gdx.files.internal( "data/badlogicsmall.jpg "),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  vaBatch  =  new  SpriteBatch(1000);  vboBatch  =  new  SpriteBatch(1000,  VertexDataType.VertexBufferObject);  vboBatch  =  new  SpriteBatch(1000,  1,  VertexDataType.VertexBufferObject);  cache  =  new  SpriteCache();  sprites  =  new  Sprite[SPRITES];  for(int  i  =  0;  i  <  SPRITES;  i++)  {  int  x  =  (int)(Math.random()  *  (Gdx.graphics.getWidth()  -  32));  int  y  =  (int)(Math.random()  *  (Gdx.graphics.getHeight()  -  32));  sprites[i]  =  new  Sprite(texture);  	vboBatch  =  new  SpriteBatch(1000,  1,  VertexDataType.VertexBufferObject);  
elasticsearch_4723c2a2ee264390227a089c59d1930469d8b5e5	buggy:  spare  =  new  LongTerms.Bucket(0,  0,  null,  showTermDocCountError,  0);  context:  }  }  }  final  int  size  =  (int)  Math.min(bucketOrds.size(),  bucketCountThresholds.getShardSize());  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(this));  LongTerms.Bucket  spare  =  null;  for  (long  i  =  0;  i  <  bucketOrds.size();  i++)  {  if  (spare  ==  null)  {                  spare  =  new  LongTerms.Bucket(0,  0,  null,  showTermDocCountError,  0);                  spare  =  new  LongTerms.Bucket(0,  0,  null,  showTermDocCountError,  0,  formatter);  }  spare.term  =  bucketOrds.get(i);  spare.docCount  =  bucketDocCount(i);  spare.bucketOrd  =  i;  if  (bucketCountThresholds.getShardMinDocCount()  <=  spare.docCount)  {  spare  =  (LongTerms.Bucket)  ordered.insertWithOverflow(spare);  }  }  	spare  =  new  LongTerms.Bucket(0,  0,  null,  showTermDocCountError,  0,  formatter);  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  controller.registerHandler(DELETE,   "/{index}/_query ",  this);  controller.registerHandler(DELETE,   "/{index}/{type}/_query ",  this);  }  DeleteByQueryRequest  deleteByQueryRequest  =  new  DeleteByQueryRequest(splitIndices(request.param( "index ")));  deleteByQueryRequest.listenerThreaded(false);  try  {  if  (request.hasContent())  {                  deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  deleteByQueryRequest.query(source);  }  else  {  deleteByQueryRequest.query(RestActions.parseQuerySource(request));  }  }  	deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Long.MIN_VALUE;  context:  this.nullValueAsString  =  nullValue  ==  null  ?  null  :  nullValue.toString();  }  return  64;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Long.MIN_VALUE;              return  null;  }  return  Numbers.bytesToLong(value);  }  return  indexedValue(Long.parseLong(value));  }  	return  null;  
elasticsearch_c2d02e4e3af7ee8b5524cc5c8155e2b8ab91782d	buggy:  out.writeInt(shardId);  context:  return  shardId;  }  index  =  Index.readIndexName(in);  shardId  =  in.readVInt();  }  index.writeTo(out);          out.writeInt(shardId);          out.writeVInt(shardId);  }  }  	out.writeVInt(shardId);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  segments  =  new  ArrayList<Segment>(size);  context:  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  shardRouting  =  readShardRoutingEntry(in);  int  size  =  in.readVInt();  if  (size  ==  0)  {  segments  =  ImmutableList.of();  }  else  {              segments  =  new  ArrayList<Segment>(size);              segments  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  segments.add(Segment.readSegment(in));  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  	segments  =  new  ArrayList<>(size);  
elasticsearch_948f0ef0da3042d6f98c67e602600f209cf6ae08	buggy:  if  (result.empty())  {  context:  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);  getRequest.threadedOperation(true);  client.execGet(getRequest,  new  ActionListener<GetResponse>()  {  try  {                      if  (result.empty())  {                      if  (result.exists())  {  channel.sendResponse(new  JsonRestResponse(request,  NOT_FOUND));  }  else  {  JsonBuilder  builder  =  restJsonBuilder(request);  builder.startObject();  builder.field( "_index ",  result.index());  builder.field( "_type ",  result.type());  builder.field( "_id ",  result.id());  builder.raw( ",  \ "_source\ "  :   ");  	if  (result.exists())  {  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  4,  4,  new  VertexAttribute(Usage.Position,  2,   "a_position "),  new  VertexAttribute(  context:  public  class  ManagedTest  implements  GdxTest  {  Mesh  mesh;  Texture  texture;  if  (mesh  ==  null)  {  mesh  =  new  Mesh(true,  false,  4,  4,  new  VertexAttribute(Usage.Position,  2,   "a_position "),  new  VertexAttribute(  mesh  =  new  Mesh(true,  4,  4,  new  VertexAttribute(Usage.Position,  2,   "a_position "),  new  VertexAttribute(  Usage.TextureCoordinates,  2,   "a_texCoord "));  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  0,  0.5f,  -0.5f,  1,  0,  0.5f,  0.5f,  1,  1,  -0.5f,  0.5f,  0,  1});  mesh.setIndices(new  short[]  {0,  1,  2,  3});  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  }  }  	mesh  =  new  Mesh(true,  4,  4,  new  VertexAttribute(Usage.Position,  2,   "a_position "),  new  VertexAttribute(  
elasticsearch_15fbbd43ce74c211f6878aee9fd24d872fed2815	buggy:  list.add(new  BulkItemRequest(i,  request));  context:  MappingMetaData  mappingMd  =  clusterState.metaData().index(deleteRequest.index()).mappingOrDefault(deleteRequest.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required()  &&  deleteRequest.routing()  ==  null)  {  GroupShardsIterator  groupShards  =  clusterService.operationRouting().broadcastDeleteShards(clusterState,  deleteRequest.index());  for  (ShardIterator  shardIt  :  groupShards)  {  List<BulkItemRequest>  list  =  requestsByShard.get(shardIt.shardId());  if  (list  ==  null)  {  list  =  Lists.newArrayList();  requestsByShard.put(shardIt.shardId(),  list);  }                          list.add(new  BulkItemRequest(i,  request));                          list.add(new  BulkItemRequest(i,  new  DeleteRequest(deleteRequest)));  }  }  else  {  ShardId  shardId  =  clusterService.operationRouting().deleteShards(clusterState,  deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  deleteRequest.routing()).shardId();  List<BulkItemRequest>  list  =  requestsByShard.get(shardId);  if  (list  ==  null)  {  list  =  Lists.newArrayList();  requestsByShard.put(shardId,  list);  }  	list.add(new  BulkItemRequest(i,  new  DeleteRequest(deleteRequest)));  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  BytesValues  bytesValues  =  fieldData.getBytesValues(randomBoolean());  context:  bytesList2.add(randomBytes());  bytesList2.add(randomBytes());  doc  =  XContentFactory.jsonBuilder().startObject().startArray( "field ").value(bytesList2.get(0)).value(bytesList2.get(1)).value(bytesList2.get(0)).endArray().endObject();  d  =  mapper.parse( "test ",   "4 ",  doc.bytes());  writer.addDocument(d.rootDoc());  AtomicReaderContext  reader  =  refreshReader();  IndexFieldData  indexFieldData  =  getForField( "field ");  AtomicFieldData  fieldData  =  indexFieldData.load(reader);          BytesValues  bytesValues  =  fieldData.getBytesValues(randomBoolean());          BytesValues  bytesValues  =  fieldData.getBytesValues();  CollectionUtils.sortAndDedup(bytesList1);  assertThat(bytesValues.setDocument(0),  equalTo(2));  assertThat(bytesValues.nextValue(),  equalTo(new  BytesRef(bytesList1.get(0))));  assertThat(bytesValues.nextValue(),  equalTo(new  BytesRef(bytesList1.get(1))));  assertThat(bytesValues.setDocument(1),  equalTo(1));  assertThat(bytesValues.nextValue(),  equalTo(new  BytesRef(bytes1)));  	BytesValues  bytesValues  =  fieldData.getBytesValues();  
elasticsearch_b11f81d744a5c23bf7c20d696939e226905c60e7	buggy:  parsedQuery(ParsedQuery.MATCH_ALL_PARSED_QUERY);  context:  searcher.release();  engineSearcher.release();  return  true;  }  public  void  preProcess()  {  if  (query()  ==  null)  {              parsedQuery(ParsedQuery.MATCH_ALL_PARSED_QUERY);              parsedQuery(ParsedQuery.parsedMatchAllQuery());  }  if  (queryBoost()  !=  1.0f)  {  parsedQuery(new  ParsedQuery(new  FunctionScoreQuery(query(),  new  BoostScoreFunction(queryBoost)),  parsedQuery()));  }  Filter  searchFilter  =  searchFilter(types());  if  (searchFilter  !=  null)  {  if  (Queries.isConstantMatchAllQuery(query()))  {  Query  q  =  new  XConstantScoreQuery(searchFilter);  	parsedQuery(ParsedQuery.parsedMatchAllQuery());  
libgdx_3a07232892047c06492835c5851f027744ebe998	buggy:  public  static  AnimationAction  $  (float  scaleX,  float  scaleY,  float  duration)  {  context:  }  };  protected  float  scaleX;  protected  float  scaleY;  protected  float  startScaleX;  protected  float  startScaleY;  protected  float  deltaScaleX;  protected  float  deltaScaleY;  public  static  AnimationAction  $  (float  scaleX,  float  scaleY,  float  duration)  {  public  static  ScaleTo  $  (float  scaleX,  float  scaleY,  float  duration)  {  ScaleTo  action  =  pool.obtain();  action.scaleX  =  scaleX;  action.scaleY  =  scaleY;  action.duration  =  duration;  action.invDuration  =  1  /  duration;  return  action;  }  	public  static  ScaleTo  $  (float  scaleX,  float  scaleY,  float  duration)  {  
elasticsearch_0f954997037d6aa8b9e99b473de0eaf3a038fe0f	buggy:  return  Math.log10(channelScore(path[0],  candidateSet[0].originalTerm)  *  scoreUnigram(path[0]));  context:  protected  double  channelScore(Candidate  candidate,  Candidate  original)  throws  IOException  {  if  (candidate.stringDistance  ==  1.0d)  {  return  realWordLikelyhood;  }  return  candidate.stringDistance;  }  public  double  score(Candidate[]  path,  CandidateSet[]  candidateSet,  int  at,  int  gramSize)  throws  IOException  {  if  (at  ==  0  ||  gramSize  ==  1)  {            return  Math.log10(channelScore(path[0],  candidateSet[0].originalTerm)  *  scoreUnigram(path[0]));            return  Math.log10(channelScore(path[at],  candidateSet[at].originalTerm)  *  scoreUnigram(path[at]));  }  else  if  (at  ==  1  ||  gramSize  ==  2)  {  return  Math.log10(channelScore(path[at],  candidateSet[at].originalTerm)  *  scoreBigram(path[at],  path[at  -  1]));  }  else  {  return  Math.log10(channelScore(path[at],  candidateSet[at].originalTerm)  *  scoreTrigram(path[at],  path[at  -  1],  path[at  -  2]));  }  }  protected  double  scoreUnigram(Candidate  word)  throws  IOException  {  	return  Math.log10(channelScore(path[at],  candidateSet[at].originalTerm)  *  scoreUnigram(path[at]));  
libgdx_fbef43ca95617a93068852b688a6857d4f172193	buggy:  BufferUtils.freeMemory(compressedData);  context:  write.close();  }  catch  (Exception  e)  {  }  }  compressedData.position(dataOffset);  compressedData.limit(compressedData.capacity());  }  public  void  dispose  ()  {  BufferUtils.freeMemory(compressedData);  BufferUtils.disposeUnsafeByteBuffer(compressedData);  }  public  String  toString  ()  {  if  (hasPKMHeader())  {  return  (ETC1.isValidPKM(compressedData,  0)  ?   "valid "  :   "invalid ")  +   "  pkm  [ "  +  ETC1.getWidthPKM(compressedData,  0)   "x "  +  ETC1.getHeightPKM(compressedData,  0)  +   "],  compressed:   "  (compressedData.capacity()  -  ETC1.PKM_HEADER_SIZE);  }  else  {  	BufferUtils.disposeUnsafeByteBuffer(compressedData);  
elasticsearch_6af80d501797903e3a3b627cd7cc331e6806bc38	buggy:  routingNode.add(shardRouting);  context:  Decision  decision  =  allocation.deciders().canAllocate(shardRouting,  routingNode,  allocation);  if  (decision.type()  ==  Decision.Type.NO)  {  throw  new  ElasticSearchIllegalArgumentException( "[allocate]  allocation  of   "  +  shardId  +   "  on  node   "  +  discoNode  +   "  is  not  allowed,  reason:   "  +  decision);  }  for  (Iterator<MutableShardRouting>  it  =  allocation.routingNodes().unassigned().iterator();  it.hasNext();  )  {  if  (it.next()  !=  shardRouting)  {  continue;  }  it.remove();              routingNode.add(shardRouting);              allocation.routingNodes().assignShardToNode(  shardRouting,  routingNode.nodeId()  );  if  (shardRouting.primary())  {  allocation.routingNodes().addClearPostAllocationFlag(shardRouting.shardId());  }  break;  }  }  	allocation.routingNodes().assignShardToNode(  shardRouting,  routingNode.nodeId()  );  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices( "_all ");  context:  }  public  void  restoreIndexWithMissingShards()  throws  Exception  {  cluster().startNode(settingsBuilder().put( "gateway.type ",   "local "));  cluster().startNode(settingsBuilder().put( "gateway.type ",   "local "));          wipeIndices( "_all ");          cluster().wipeIndices( "_all ");  assertAcked(prepareCreate( "test-idx-1 ",  2,  settingsBuilder().put( "number_of_shards ",  6)  .put( "number_of_replicas ",  0)  .put(MockDirectoryHelper.RANDOM_NO_DELETE_OPEN_FILE,  false)));  ensureGreen();  for  (int  i  =  0;  i  <  100;  i++)  {  	cluster().wipeIndices( "_all ");  
elasticsearch_8d669ff54e239af907002cce28209709a81cc9f9	buggy:  return  cache(type.fieldDataClass,  reader,  fieldName);  context:  cache.remove(reader.getFieldCacheKey());  }  }          return  cache(type.fieldDataClass,  reader,  fieldName);          return  cache(type.fieldDataClass(),  reader,  fieldName);  }  ConcurrentMap<String,  FieldData>  fieldDataCache  =  cache.get(reader.getFieldCacheKey());  if  (fieldDataCache  ==  null)  {  synchronized  (creationMutex)  {  fieldDataCache  =  cache.get(reader.getFieldCacheKey());  if  (fieldDataCache  ==  null)  {  	return  cache(type.fieldDataClass(),  reader,  fieldName);  
libgdx_2588bd69ef75d5c043a484d31c2cfb1cbd3d4f15	buggy:  Vector2  size  =  scaling.apply(regionWidth,  regionHeight,  width  *  scaleX,  height  *  scaleY);  context:  float  regionWidth,  regionHeight;  if  (patch  !=  null)  {  regionWidth  =  patch.getTotalWidth();  regionHeight  =  patch.getTotalHeight();  }  else  if  (region  !=  null)  {  regionWidth  =  region.getRegionWidth();  regionHeight  =  region.getRegionHeight();  }  else  return;  Vector2  size  =  scaling.apply(regionWidth,  regionHeight,  width  *  scaleX,  height  *  scaleY);  Vector2  size  =  scaling.apply(regionWidth,  regionHeight,  width,  height);  imageWidth  =  size.x;  imageHeight  =  size.y;  if  ((align  &  Align.LEFT)  !=  0)  imageX  =  0;  else  if  ((align  &  Align.RIGHT)  !=  0)  imageX  =  (int)(width  -  imageWidth);  else  	Vector2  size  =  scaling.apply(regionWidth,  regionHeight,  width,  height);  
libgdx_32c98da9f705b1881a0c7084fb0971f021c0ee32	buggy:  if(time  <  0  ||  time  >  anim.duration)  throw  new  IllegalArgumentException( "time  must  be  0  <=  time  <=  animation  duration ");  context:  sceneMatrix.mul(rotMatrix);  combinedMatrix.set(sceneMatrix);  combinedMatrix.mul(offsetMatrices.get(i));  }  }  public  void  setAnimation(String  name,  float  time)  {  SkeletonAnimation  anim  =  animations.get(name);  if(anim  ==  null)  throw  new  IllegalArgumentException( "Animation  with  name  ' "  +  name  +   "'  does  not  exist ");  if(time  <  0  ||  time  >  anim.duration)  throw  new  IllegalArgumentException( "time  must  be  0  <=  time  <=  animation  duration ");  if(time  <  0  ||  time  >  anim.totalDuration)  throw  new  IllegalArgumentException( "time  must  be  0  <=  time  <=  animation  duration ");  int  len  =  anim.perJointkeyFrames.length;  for(int  i  =  0;  i  <  len;  i++)  {  SkeletonKeyframe[]  jointTrack  =  anim.perJointkeyFrames[i];  int  idx  =  0;  int  len2  =  jointTrack.length;  for(int  j  =  0;  j  <  len2;  j++)  {  SkeletonKeyframe  jointFrame  =  jointTrack[j];  	if(time  <  0  ||  time  >  anim.totalDuration)  throw  new  IllegalArgumentException( "time  must  be  0  <=  time  <=  animation  duration ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<SearchContextFacets.Entry>  entries  =  new  ArrayList<SearchContextFacets.Entry>();  context:  public  FacetParseElement(FacetParsers  facetParsers)  {  this.facetParsers  =  facetParsers;  }  public  void  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  XContentParser.Token  token;          List<SearchContextFacets.Entry>  entries  =  new  ArrayList<SearchContextFacets.Entry>();          List<SearchContextFacets.Entry>  entries  =  new  ArrayList<>();  String  facetName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  facetName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  FacetExecutor  facetExecutor  =  null;  boolean  global  =  false;  	List<SearchContextFacets.Entry>  entries  =  new  ArrayList<>();  
elasticsearch_94eed4ef5602077852f2ee9f26f291c472709b3a	buggy:  Nested  nested  =  new  Nested(parentFilter,  childFilter);  context:  break;  case  2:  missingValue  =  new  BytesRef(RandomPicks.randomFrom(getRandom(),  values));  break;  default:  missingValue  =  new  BytesRef(TestUtil.randomSimpleString(getRandom()));  break;  }  Filter  parentFilter  =  new  TermFilter(new  Term( "type ",   "parent "));  Filter  childFilter  =  new  NotFilter(parentFilter);          Nested  nested  =  new  Nested(parentFilter,  childFilter);          Nested  nested  =  createNested(parentFilter,  childFilter);  BytesRefFieldComparatorSource  nestedComparatorSource  =  new  BytesRefFieldComparatorSource(fieldData,  missingValue,  sortMode,  nested);  ToParentBlockJoinQuery  query  =  new  ToParentBlockJoinQuery(new  XFilteredQuery(new  MatchAllDocsQuery(),  childFilter),  new  FixedBitSetCachingWrapperFilter(parentFilter),  ScoreMode.None);  Sort  sort  =  new  Sort(new  SortField( "text ",  nestedComparatorSource));  TopFieldDocs  topDocs  =  searcher.search(query,  randomIntBetween(1,  numParents),  sort);  assertTrue(topDocs.scoreDocs.length  >  0);  BytesRef  previous  =  null;  for  (int  i  =  0;  i  <  topDocs.scoreDocs.length;  ++i)  {  final  int  docID  =  topDocs.scoreDocs[i].doc;  	Nested  nested  =  createNested(parentFilter,  childFilter);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  return  out.copiedByteArray();  context:  public  static  byte[]  copyToByteArray(InputStream  in)  throws  IOException  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {  BytesStreamOutput  out  =  cachedEntry.bytes();  copy(in,  out);              return  out.copiedByteArray();              return  out.bytes().copyBytesArray().toBytes();  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  }  }  	return  out.bytes().copyBytesArray().toBytes();  
libgdx_d2270c040f6a537132d7f0444092886b7eca0d51	buggy:  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shot.ogg ",  FileType.Internal));  context:  public  class  SoundTest  extends  GdxTest  {  Sound  sound;  float  volume  =  0.5f;  long  soundId  =  0;  Stage  ui;  Skin  skin;  public  void  create  ()  {  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shot.ogg ",  FileType.Internal));  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.ogg ",  FileType.Internal));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  TextButton  play  =  new  TextButton( "Play ",  skin);  TextButton  stop  =  new  TextButton( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  false,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  	sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.ogg ",  FileType.Internal));  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  boolean  resolveRequest(ClusterState  state,  Request  request,  ActionListener<Response>  listener)  {          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  return  true;  }  protected  TransportRequestOptions  transportOptions()  {  return  TransportRequestOptions.EMPTY;  }  	request.index(state.metaData().concreteSingleIndex(request.index()));  
elasticsearch_577f06fd438f0c1d8b6691f47b76d07c9abcb6bc	buggy:  AnalyzeResponse  analyzeResponse  =  client.admin().indices().prepareAnalyzer( "test ",   "this  is  a  test ").execute().actionGet();  context:  try  {  client.admin().indices().prepareDelete( "test ").execute().actionGet();  }  catch  (Exception  e)  {  }  client.admin().indices().prepareCreate( "test ").execute().actionGet();  client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();  for  (int  i  =  0;  i  <  10;  i++)  {              AnalyzeResponse  analyzeResponse  =  client.admin().indices().prepareAnalyzer( "test ",   "this  is  a  test ").execute().actionGet();              AnalyzeResponse  analyzeResponse  =  client.admin().indices().prepareAnalyze( "test ",   "this  is  a  test ").execute().actionGet();  assertThat(analyzeResponse.tokens().size(),  equalTo(1));  AnalyzeResponse.AnalyzeToken  token  =  analyzeResponse.tokens().get(0);  assertThat(token.term(),  equalTo( "test "));  assertThat(token.startOffset(),  equalTo(10));  assertThat(token.endOffset(),  equalTo(14));  }  }  }  	AnalyzeResponse  analyzeResponse  =  client.admin().indices().prepareAnalyze( "test ",   "this  is  a  test ").execute().actionGet();  
elasticsearch_0b09fd0806364c0785fc649b6483f00fb8e8ebf4	buggy:  return  new  InternalStatisticalFacet(facetName,   "_na ",  min,  max,  total,  sumOfSquares,  count);  context:  sumOfSquares  +=  value  *  value;  total  +=  value;  count++;  }  script.setNextReader(reader);  }          return  new  InternalStatisticalFacet(facetName,   "_na ",  min,  max,  total,  sumOfSquares,  count);          return  new  InternalStatisticalFacet(facetName,  min,  max,  total,  sumOfSquares,  count);  }  }  	return  new  InternalStatisticalFacet(facetName,  min,  max,  total,  sumOfSquares,  count);  
elasticsearch_a42f9491b5f01846352c0b3e808524f416b3d2a0	buggy:  throw  new  DumpContributionFailedException(getName(),   "Heap  dump  not  enalbed  on  this  JVM ");  context:  }  public  String  getName()  {  return  name;  }  public  void  contribute(Dump  dump)  throws  DumpContributionFailedException  {  if  (heapDumpMethod  ==  null)  {              throw  new  DumpContributionFailedException(getName(),   "Heap  dump  not  enalbed  on  this  JVM ");              throw  new  DumpContributionFailedException(getName(),   "Heap  dump  not  enabled  on  this  JVM ");  }  try  {  heapDumpMethod.invoke(diagnosticMBean,  dump.createFile( "heap.hprof ").getAbsolutePath(),  true);  }  catch  (Exception  e)  {  throw  new  DumpContributionFailedException(getName(),   "Failed  to  generate  heap  dump ",  e);  }  }  }  	throw  new  DumpContributionFailedException(getName(),   "Heap  dump  not  enabled  on  this  JVM ");  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  particle.velocity.mul((float)  Math.pow(damping,  delta));  context:  }  }  private  void  updateParticle(Particle  particle)  {  delta  =  Math.min(0.06f,  Gdx.graphics.getDeltaTime());  if  (particle.life  >  0)  {  particle.life  -=  delta;  particle.position.add(particle.velocity.x  *  delta*10,particle.velocity.y  *  delta*10);  particle.velocity.mul((float)  Math.pow(damping,  delta));  particle.velocity.scl((float)  Math.pow(damping,  delta));  particle.scale  +=  this.delta_scale  *  delta/5f;  }  }  public  void  addParticle(Vector2  position,  Vector2  velocity,  float  life,  float  scale)  {  if(particles.size>maxParticle)  return;  if(Gdx.graphics.getFramesPerSecond()<25  &&  !(this  instanceof  ExplosionParticleEmitter))  return;  Particle  particle  =  freeParticles.obtain();  	particle.velocity.scl((float)  Math.pow(damping,  delta));  
elasticsearch_277996727952938f2397e126721629113de5e437	buggy:  if  (actualValueClassName.startsWith( "org.elasticsearch ")  ||  actualValueClassName.startsWith( "org.lucene "))  {  context:  Field  valueField  =  tableValue.getClass().getDeclaredField( "value ");  valueField.setAccessible(true);  Object  value  =  valueField.get(tableValue);  if  (value  !=  null)  {  Object  actualValue  =  value;  if  (value  instanceof  SoftReference)  {  actualValue  =  ((SoftReference)  value).get();  }  if  (actualValue  !=  null)  {  String  actualValueClassName  =  actualValue.getClass().getName();                                  if  (actualValueClassName.startsWith( "org.elasticsearch ")  ||  actualValueClassName.startsWith( "org.lucene "))  {                                  if  (actualValueClassName.startsWith( "org.elasticsearch ")  ||  actualValueClassName.startsWith( "org.apache.lucene "))  {  remove  =  true;  }  }  }  if  (remove)  {  Object[]  args  =  new  Object[4];  if  (key  !=  null)  {  args[0]  =  key.getClass().getCanonicalName();  	if  (actualValueClassName.startsWith( "org.elasticsearch ")  ||  actualValueClassName.startsWith( "org.apache.lucene "))  {  
libgdx_cb42e3df8e1782c3946fcecf0554172dde98dd30	buggy:  JFrame  frame  =  new  JFrame( "Gdx  -  LWJGL  Test  Launcher ");  context:  app.getGraphics().setRenderListener(test);  }  });  add(pane,  BorderLayout.CENTER);  add(button,  BorderLayout.SOUTH);  }  }  public  static  void  main  (String[]  argv)  {  JFrame  frame  =  new  JFrame( "Gdx  -  LWJGL  Test  Launcher ");  JFrame  frame  =  new  JFrame( "GDX  -  LWJGL  Test  Launcher ");  frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);  frame.setContentPane(new  TestList());  frame.pack();  frame.setSize(frame.getWidth(),  600);  frame.setLocationRelativeTo(null);  frame.setVisible(true);  }  }  	JFrame  frame  =  new  JFrame( "GDX  -  LWJGL  Test  Launcher ");  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  protected  abstract  Request  newRequest();  protected  abstract  Response  newResponse();  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  void  resolveRequest(ClusterState  state,  Request  request)  {          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  }  protected  abstract  ShardIterator  shards(ClusterState  state,  Request  request)  throws  ElasticsearchException;  class  AsyncSingleAction  {  private  final  ActionListener<Response>  listener;  private  final  ShardIterator  shardIt;  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<RepositoryMetaData>  repository  =  new  ArrayList<RepositoryMetaData>();  context:  repository.writeTo(out);  }  }  public  RepositoriesMetaData  fromXContent(XContentParser  parser)  throws  IOException  {  XContentParser.Token  token;              List<RepositoryMetaData>  repository  =  new  ArrayList<RepositoryMetaData>();              List<RepositoryMetaData>  repository  =  new  ArrayList<>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  String  name  =  parser.currentName();  if  (parser.nextToken()  !=  XContentParser.Token.START_OBJECT)  {  throw  new  ElasticsearchParseException( "failed  to  parse  repository  [ "  +  name  +   "],  expected  object ");  }  String  type  =  null;  Settings  settings  =  ImmutableSettings.EMPTY;  	List<RepositoryMetaData>  repository  =  new  ArrayList<>();  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  e)  {  context:  }  else  {  transportService.sendRequest(node,  transportShardAction(),  shardRequest,  new  BaseTransportResponseHandler<ShardResponse>()  {  return  newShardResponse();  }  onOperation(shard,  response,  false);  }                              @Override  public  void  handleException(RemoteTransportException  e)  {                              @Override  public  void  handleException(TransportException  e)  {  onOperation(shard,  shardIt,  e,  false);  }  return  false;  }  });  	@Override  public  void  handleException(TransportException  e)  {  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  this.indicesService  =  indicesService;  this.nodeEnv  =  nodeEnv;  }  public  ActionFuture<NodesStoreFilesMetaData>  list(ShardId  shardId,  boolean  onlyUnallocated,  Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {  return  execute(new  Request(shardId,  onlyUnallocated,  nodesIds).timeout(timeout));  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return   "/cluster/nodes/indices/shard/store ";  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_5a8ebab96e00e0be8bc5a2bafe14f38e300e5119	buggy:  assertThat(explanation,  containsString( "  1.0  =  -exp(-0.5*pow(MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)],2.0)/18.033688011112044) "));  context:  SearchResponse  response  =  client().search(  searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(  searchSource().explain(true)  .query(functionScoreQuery(termQuery( "test ",   "value "))  .add(gaussDecayFunction( "num ",  1.0,  5.0).setOffset(1.0))  .add(linearDecayFunction( "num ",  1.0,  5.0).setOffset(1.0))  .add(exponentialDecayFunction( "num ",  1.0,  5.0).setOffset(1.0))  .boostMode(CombineFunction.REPLACE.getName())))).get();  String  explanation  =  response.getHits().getAt(0).getExplanation().toString();          assertThat(explanation,  containsString( "  1.0  =  -exp(-0.5*pow(MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)],2.0)/18.033688011112044) "));          assertThat(explanation,  containsString( "  1.0  =  exp(-0.5*pow(MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)],2.0)/18.033688011112044) "));  assertThat(explanation,  containsString( "1.0  =  max(0.0,  ((10.0  -  MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)])/10.0) "));  assertThat(explanation,  containsString( "1.0  =  exp(-  MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)]  *  0.13862943611198905) "));  }  }  	assertThat(explanation,  containsString( "  1.0  =  exp(-0.5*pow(MIN[Math.max(Math.abs(0.5(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0),  Math.max(Math.abs(0.7(=doc  value)  -  1.0(=origin)))  -  1.0(=offset),  0)],2.0)/18.033688011112044) "));  
elasticsearch_28b9e250536f8a554abb26b49d6a80a0d4fb4f03	buggy:  builder.field( "index ",  fieldType.indexed());  context:  fieldType.stored()  ==  Defaults.FIELD_TYPE.stored()  &&  enabledState  ==  Defaults.ENABLED  &&  path  ==  Defaults.PATH  &&  dateTimeFormatter.format().equals(Defaults.DATE_TIME_FORMATTER.format()))  {  return  builder;  }  builder.startObject(CONTENT_TYPE);  if  (enabledState  !=  Defaults.ENABLED)  {  builder.field( "enabled ",  enabledState.enabled);  }  if  (enabledState.enabled)  {  if  (fieldType.indexed()  !=  Defaults.FIELD_TYPE.indexed())  {                  builder.field( "index ",  fieldType.indexed());                  builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  }  if  (fieldType.stored()  !=  Defaults.FIELD_TYPE.stored())  {  builder.field( "store ",  fieldType.stored());  }  if  (path  !=  Defaults.PATH)  {  builder.field( "path ",  path);  }  if  (!dateTimeFormatter.format().equals(Defaults.DATE_TIME_FORMATTER.format()))  {  	builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  
elasticsearch_ccdbbef2765057ae19c9a9f01c2435f1336acea4	buggy:  if  (!master)  {  context:  asyncJoinCluster();  }  pingService.stop();  masterFD.stop( "zen  disco  stop ");  nodesFD.stop();  initialStateSent.set(false);  if  (sendLeaveRequest)  {              if  (!master)  {              if  (!master  &&  latestDiscoNodes.masterNode()  !=  null)  {  try  {  membership.sendLeaveRequestBlocking(latestDiscoNodes.masterNode(),  localNode,  TimeValue.timeValueSeconds(1));  }  catch  (Exception  e)  {  }  }  else  {  DiscoveryNode[]  possibleMasters  =  electMaster.nextPossibleMasters(latestDiscoNodes.nodes().values(),  5);  for  (DiscoveryNode  possibleMaster  :  possibleMasters)  {  	if  (!master  &&  latestDiscoNodes.masterNode()  !=  null)  {  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  NonNestedDocsFilter.INSTANCE);  context:  SearchContext.removeCurrent();  Releasables.close(current);  }  public  void  testBasicQuerySanities()  {  Query  childQuery  =  new  TermQuery(new  Term( "field ",   "value "));  ScoreType  scoreType  =  ScoreType.values()[random().nextInt(ScoreType.values().length)];  ParentFieldMapper  parentFieldMapper  =  SearchContext.current().mapperService().documentMapper( "child ").parentFieldMapper();  ParentChildIndexFieldData  parentChildIndexFieldData  =  SearchContext.current().fieldData().getForField(parentFieldMapper);          Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  NonNestedDocsFilter.INSTANCE);          Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  wrap(NonNestedDocsFilter.INSTANCE));  QueryUtils.check(query);  }  }  	Query  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  childQuery,   "child ",   "parent ",  scoreType,  1,  1,  wrap(NonNestedDocsFilter.INSTANCE));  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);  context:  public  static  FlushStats  readFlushStats(StreamInput  in)  throws  IOException  {  FlushStats  flushStats  =  new  FlushStats();  flushStats.readFrom(in);  return  flushStats;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(Fields.FLUSH);  builder.field(Fields.TOTAL,  total);          builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);          builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  builder.endObject();  return  builder;  }  static  final  class  Fields  {  static  final  XContentBuilderString  FLUSH  =  new  XContentBuilderString( "flush ");  static  final  XContentBuilderString  TOTAL  =  new  XContentBuilderString( "total ");  static  final  XContentBuilderString  TOTAL_TIME  =  new  XContentBuilderString( "total_time ");  	builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  
elasticsearch_f1467dbde256a968bfffed6ce470f162ac307655	buggy:  return  GeoPointDoubleArrayAtomicFieldData.EMPTY;  context:  }  }  }  public  GeoPointDoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  GeoPointDoubleArrayAtomicFieldData.EMPTY;              return  GeoPointDoubleArrayAtomicFieldData.empty(reader.maxDoc());  }  final  BigDoubleArrayList  lat  =  new  BigDoubleArrayList();  final  BigDoubleArrayList  lon  =  new  BigDoubleArrayList();  lat.add(0);  //  first   "t "  indicates  null  value  lon.add(0);  //  first   "t "  indicates  null  value  final  float  acceptableTransientOverheadRatio  =  fieldDataType.getSettings().getAsFloat( "acceptable_transient_overhead_ratio ",  OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO);  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(terms.size(),  reader.maxDoc(),  acceptableTransientOverheadRatio);  	return  GeoPointDoubleArrayAtomicFieldData.empty(reader.maxDoc());  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  {  context:  public  Class<?  extends  IndexShardGateway>  shardGatewayClass()  {  return  NoneIndexShardGateway.class;  }  public  String  toString()  {  return   "_none_ ";  }      public  void  close(boolean  delete)  {      public  void  close()  {  }  }  	public  void  close()  {  
elasticsearch_cea2d21c50c5a680cbbaefba254866601b5b4608	buggy:  index  =  index  +  this.placeholderPrefix.length()  -  1;  context:  return  buf.toString();  }  private  int  findPlaceholderEndIndex(CharSequence  buf,  int  startIndex)  {  int  index  =  startIndex  +  this.placeholderPrefix.length();  int  withinNestedPlaceholder  =  0;  while  (index  <  buf.length())  {  if  (Strings.substringMatch(buf,  index,  this.placeholderSuffix))  {  if  (withinNestedPlaceholder  >  0)  {  withinNestedPlaceholder--;                      index  =  index  +  this.placeholderPrefix.length()  -  1;                      index  =  index  +  this.placeholderSuffix.length();  }  else  {  return  index;  }  }  else  if  (Strings.substringMatch(buf,  index,  this.placeholderPrefix))  {  withinNestedPlaceholder++;  index  =  index  +  this.placeholderPrefix.length();  }  else  {  index++;  	index  =  index  +  this.placeholderSuffix.length();  
elasticsearch_d9699e02f4e28c75cc5ffdd125b11d99325766c4	buggy:  final  Distance  precision  =  new  Distance(randomDouble()  *  10,  randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS,  DistanceUnit.METERS,  DistanceUnit.KILOMETERS)));  context:  public  class  GeoEncodingTests  extends  ElasticsearchTestCase  {  public  void  test()  {  for  (int  i  =  0;  i  <  10000;  ++i)  {  final  double  lat  =  randomDouble()  *  180  -  90;  final  double  lon  =  randomDouble()  *  360  -  180;              final  Distance  precision  =  new  Distance(randomDouble()  *  10,  randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS,  DistanceUnit.METERS,  DistanceUnit.KILOMETERS)));              final  Distance  precision  =  new  Distance(1+(randomDouble()  *  9),  randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS,  DistanceUnit.METERS,  DistanceUnit.KILOMETERS)));  final  GeoPointFieldMapper.Encoding  encoding  =  GeoPointFieldMapper.Encoding.of(precision);  assertThat(encoding.precision().convert(DistanceUnit.METERS).value,  lessThanOrEqualTo(precision.convert(DistanceUnit.METERS).value));  final  GeoPoint  geoPoint  =  encoding.decode(encoding.encodeCoordinate(lat),  encoding.encodeCoordinate(lon),  new  GeoPoint());  final  double  error  =  GeoDistance.PLANE.calculate(lat,  lon,  geoPoint.lat(),  geoPoint.lon(),  DistanceUnit.METERS);  assertThat(error,  lessThanOrEqualTo(precision.convert(DistanceUnit.METERS).value));  }  }  	final  Distance  precision  =  new  Distance(1+(randomDouble()  *  9),  randomFrom(Arrays.asList(DistanceUnit.MILLIMETERS,  DistanceUnit.METERS,  DistanceUnit.KILOMETERS)));  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(EMPTY_SETTINGS),  context:  public  class  SimpleIcuAnalysisTests  {  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(                  new  IndexSettingsModule(EMPTY_SETTINGS),                  new  IndexSettingsModule(index,  EMPTY_SETTINGS),  new  IndexNameModule(index),  new  AnalysisModule(EMPTY_SETTINGS).addProcessor(new  IcuAnalysisBinderProcessor())).createInjector();  AnalysisService  analysisService  =  injector.getInstance(AnalysisService.class);  TokenFilterFactory  filterFactory  =  analysisService.tokenFilter( "icu_normalizer ");  MatcherAssert.assertThat(filterFactory,  instanceOf(IcuNormalizerTokenFilterFactory.class));  }  	new  IndexSettingsModule(index,  EMPTY_SETTINGS),  
elasticsearch_ad50afbec8c2d619a33fdb591361d5d2ad4c766d	buggy:  Settings  settings  =  settingsFilter.filterSettings(nodeInfo.getSettings());  context:  builder.startObject( "attributes ");  for  (Map.Entry<String,  String>  attr  :  nodeInfo.getNode().attributes().entrySet())  {  builder.field(attr.getKey(),  attr.getValue(),  XContentBuilder.FieldCaseConversion.NONE);  }  builder.endObject();  }  if  (nodeInfo.getSettings()  !=  null)  {  builder.startObject( "settings ");                  Settings  settings  =  settingsFilter.filterSettings(nodeInfo.getSettings());                  Settings  settings  =  settingsFilter  !=  null  ?  settingsFilter.filterSettings(nodeInfo.getSettings())  :  nodeInfo.getSettings();  for  (Map.Entry<String,  String>  entry  :  settings.getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue(),  XContentBuilder.FieldCaseConversion.NONE);  }  builder.endObject();  }  if  (nodeInfo.getOs()  !=  null)  {  nodeInfo.getOs().toXContent(builder,  params);  	Settings  settings  =  settingsFilter  !=  null  ?  settingsFilter.filterSettings(nodeInfo.getSettings())  :  nodeInfo.getSettings();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  builder.endObject();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  foundAny  ?  OK  :  NOT_FOUND,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_33d5a722b332f8a9bacfd3d3b5779494eae3cda7	buggy:  boolean  skip  =  testSection.getSkipSection().skipVersion(parseContext.getCurrentVersion());  context:  public  class  RestTestSectionParser  implements  RestTestFragmentParser<TestSection>  {  public  TestSection  parse(RestTestSuiteParseContext  parseContext)  throws  IOException,  RestTestParseException  {  XContentParser  parser  =  parseContext.parser();  parseContext.advanceToFieldName();  TestSection  testSection  =  new  TestSection(parser.currentName());  parser.nextToken();  testSection.setSkipSection(parseContext.parseSkipSection());          boolean  skip  =  testSection.getSkipSection().skipVersion(parseContext.getCurrentVersion());          boolean  skip  =  testSection.getSkipSection().skip(parseContext.getCurrentVersion());  while  (  parser.currentToken()  !=  XContentParser.Token.END_ARRAY)  {  if  (skip)  {  assert  parser.currentToken()  ==  XContentParser.Token.START_OBJECT;  parser.skipChildren();  	boolean  skip  =  testSection.getSkipSection().skip(parseContext.getCurrentVersion());  
elasticsearch_0f0b41e4faca256819742ebea827f09b78dc9180	buggy:  .startObject( "properties ").startObject( "point ").field( "type ",   "geo_point ").field( "lat_lon ",  true).endObject().endObject()  context:  .copiedBytes());  assert  false;  }  catch  (ElasticSearchIllegalArgumentException  e)  {  }  }  String  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type ")                  .startObject( "properties ").startObject( "point ").field( "type ",   "geo_point ").field( "lat_lon ",  true).endObject().endObject()                  .startObject( "properties ").startObject( "point ").field( "type ",   "geo_point ").field( "lat_lon ",  true).field( "normalize ",  false).field( "validate ",  false).endObject().endObject()  .endObject().endObject().string();  DocumentMapper  defaultMapper  =  MapperTests.newParser().parse(mapping);  ParsedDocument  doc  =  defaultMapper.parse( "type ",   "1 ",  XContentFactory.jsonBuilder()  .startObject()  .startObject( "point ").field( "lat ",  90).field( "lon ",  1.3).endObject()  	.startObject( "properties ").startObject( "point ").field( "type ",   "geo_point ").field( "lat_lon ",  true).field( "normalize ",  false).field( "validate ",  false).endObject().endObject()  
elasticsearch_30c80319c05362fae49fdfe5d6422c59f942f0db	buggy:  Query  booleanQuery  =  createBooleanQuery(field,  queryText,  Occur.SHOULD);  context:  }  return  prefixQuery;  }  else  if  (query  instanceof  TermQuery)  {  prefixQuery.add(((TermQuery)  query).getTerm());  return  prefixQuery;  }  return  query;  }  public  Query  createCommonTermsQuery(String  field,  String  queryText,  Occur  highFreqOccur,  Occur  lowFreqOccur,  float  maxTermFrequency,  FieldMapper<?>  mapper)  {              Query  booleanQuery  =  createBooleanQuery(field,  queryText,  Occur.SHOULD);              Query  booleanQuery  =  createBooleanQuery(field,  queryText,  lowFreqOccur);  if  (booleanQuery  !=  null  &&  booleanQuery  instanceof  BooleanQuery)  {  BooleanQuery  bq  =  (BooleanQuery)  booleanQuery;  ExtendedCommonTermsQuery  query  =  new  ExtendedCommonTermsQuery(highFreqOccur,  lowFreqOccur,  maxTermFrequency,  ((BooleanQuery)booleanQuery).isCoordDisabled(),  mapper);  for  (BooleanClause  clause  :  bq.clauses())  {  if  (!(clause.getQuery()  instanceof  TermQuery))  {  return  booleanQuery;  }  query.add(((TermQuery)  clause.getQuery()).getTerm());  	Query  booleanQuery  =  createBooleanQuery(field,  queryText,  lowFreqOccur);  
libgdx_6b1f6e2e139683a01b4f19b1765b466de095cb9a	buggy:  int  result  =  (int)type;  context:  this(rhs.type,  rhs.depthFunc,  rhs.depthRangeNear,  rhs.depthRangeFar,  rhs.depthMask);  }  public  Attribute  copy  ()  {  return  new  DepthTestAttribute(this);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  971  *  result  +  depthFunc;  result  =  971  *  result  +  NumberUtils.floatToRawIntBits(depthRangeNear);  result  =  971  *  result  +  NumberUtils.floatToRawIntBits(depthRangeFar);  result  =  971  *  result  +  (depthMask  ?  1  :  0);  return  result;  }  }  	int  result  =  super.hashCode();  
elasticsearch_4a9c7d672ed83604123448501d73d18258243c6f	buggy:  String[]  fragments  =  null;  context:  DocumentMapper  documentMapper  =  context.mapperService().type(internalHit.type());  int  docId  =  internalHit.docId();  Map<String,  HighlightField>  highlightFields  =  new  HashMap<String,  HighlightField>();  for  (SearchContextHighlight.ParsedHighlightField  parsedHighlightField  :  context.highlight().fields())  {  String  indexName  =  parsedHighlightField.field();  FieldMapper  mapper  =  documentMapper.mappers().smartNameFieldMapper(parsedHighlightField.field());  if  (mapper  !=  null)  {  indexName  =  mapper.names().indexName();  }                  String[]  fragments  =  null;                  String[]  fragments;  try  {  fragments  =  highlighter.getBestFragments(fieldQuery,  context.searcher().getIndexReader(),  docId,  indexName,  parsedHighlightField.fragmentCharSize(),  parsedHighlightField.numberOfFragments());  }  catch  (IOException  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  highlight  field  [ "  +  parsedHighlightField.field()  +   "] ",  e);  }  HighlightField  highlightField  =  new  HighlightField(parsedHighlightField.field(),  fragments);  highlightFields.put(highlightField.name(),  highlightField);  }  	String[]  fragments;  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthRequest  clusterHealthRequest  =  clusterHealth(RestActions.splitIndices(request.param( "index ")));  context:  public  class  RestClusterHealthAction  extends  BaseRestHandler  {  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/health ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/health/{index} ",  this);  }          ClusterHealthRequest  clusterHealthRequest  =  clusterHealth(RestActions.splitIndices(request.param( "index ")));          ClusterHealthRequest  clusterHealthRequest  =  clusterHealthRequest(RestActions.splitIndices(request.param( "index ")));  int  level  =  0;  try  {  clusterHealthRequest.timeout(request.paramAsTime( "timeout ",  clusterHealthRequest.timeout()));  String  waitForStatus  =  request.param( "wait_for_status ");  if  (waitForStatus  !=  null)  {  clusterHealthRequest.waitForStatus(ClusterHealthStatus.valueOf(waitForStatus.toUpperCase()));  }  clusterHealthRequest.waitForRelocatingShards(request.paramAsInt( "wait_for_relocating_shards ",  clusterHealthRequest.waitForRelocatingShards()));  	ClusterHealthRequest  clusterHealthRequest  =  clusterHealthRequest(RestActions.splitIndices(request.param( "index ")));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  ProviderMethod<T>(key,  method,  delegate,  ImmutableSet.copyOf(dependencies),  context:  TypeLiteral<T>  returnType  =  (TypeLiteral<T>)  typeLiteral.getReturnType(method);  Key<T>  key  =  getKey(errors,  returnType,  method,  method.getAnnotations());  Class<?  extends  Annotation>  scopeAnnotation  =  Annotations.findScopeAnnotation(errors,  method.getAnnotations());  for  (Message  message  :  errors.getMessages())  {  binder.addError(message);  }          return  new  ProviderMethod<T>(key,  method,  delegate,  ImmutableSet.copyOf(dependencies),          return  new  ProviderMethod<>(key,  method,  delegate,  ImmutableSet.copyOf(dependencies),  parameterProviders,  scopeAnnotation);  }  <T>  Key<T>  getKey(Errors  errors,  TypeLiteral<T>  type,  Member  member,  Annotation[]  annotations)  {  Annotation  bindingAnnotation  =  Annotations.findBindingAnnotation(errors,  member,  annotations);  return  bindingAnnotation  ==  null  ?  Key.get(type)  :  Key.get(type,  bindingAnnotation);  }  	return  new  ProviderMethod<>(key,  method,  delegate,  ImmutableSet.copyOf(dependencies),  
libgdx_047bbb8561118281a5b29b072046660d906bac82	buggy:  ellipse(radius,  radius,  0,  0,  centerX,  centerY,  centerZ,  normalX,  normalY,  normalZ,  tangentX,  tangentY,  tangentZ,  binormalX,  binormalY,  binormalZ,  divisions,  angleFrom,  angleTo);  context:  }  public  void  circle(float  radius,  final  Vector3  center,  final  Vector3  normal,  final  Vector3  tangent,  final  Vector3  binormal,  int  divisions,  float  angleFrom,  float  angleTo)  {  circle(radius,  center.x,  center.y,  center.z,  normal.x,  normal.y,  normal.z,  tangent.x,  tangent.y,  tangent.z,  binormal.x,  binormal.y,  binormal.z,  divisions,  angleFrom,  angleTo);  }  public  void  circle(float  radius,  float  centerX,  float  centerY,  float  centerZ,  float  normalX,  float  normalY,  float  normalZ,  float  tangentX,  float  tangentY,  float  tangentZ,  float  binormalX,  float  binormalY,  float  binormalZ,  int  divisions,  float  angleFrom,  float  angleTo)  {  ellipse(radius,  radius,  0,  0,  centerX,  centerY,  centerZ,  normalX,  normalY,  normalZ,  tangentX,  tangentY,  tangentZ,  binormalX,  binormalY,  binormalZ,  divisions,  angleFrom,  angleTo);  ellipse(radius*2,  radius*2,  0,  0,  centerX,  centerY,  centerZ,  normalX,  normalY,  normalZ,  tangentX,  tangentY,  tangentZ,  binormalX,  binormalY,  binormalZ,  divisions,  angleFrom,  angleTo);  }  public  void  ellipse(float  width,  float  height,  float  innerWidth,  float  innerHeight,  Vector3  center,  Vector3  normal,  int  divisions)  {  ellipse(width,  height,  innerWidth,  innerHeight,  center.x,  center.y,  center.z,  normal.x,  normal.y,  normal.z,  divisions,  0,  360);  }  	ellipse(radius*2,  radius*2,  0,  0,  centerX,  centerY,  centerZ,  normalX,  normalY,  normalZ,  tangentX,  tangentY,  tangentZ,  binormalX,  binormalY,  binormalZ,  divisions,  angleFrom,  angleTo);  
elasticsearch_aa851225e5d544a870c08810b67a919859a7790c	buggy:  if  (response.getVersion()  ==  1)  {  context:  .field(Fields._VERSION,  response.getVersion());  if  (response.getMatches()  !=  null)  {  builder.startArray(Fields.MATCHES);  for  (String  match  :  response.getMatches())  {  builder.value(match);  }  builder.endArray();  }  builder.endObject();  RestStatus  status  =  OK;                      if  (response.getVersion()  ==  1)  {                      if  (response.isCreated())  {  status  =  CREATED;  }  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));  }  catch  (Throwable  e)  {  onFailure(e);  }  }  	if  (response.isCreated())  {  
elasticsearch_4ffd8a663c44f8ddd3a54ced2aa745a3665056b7	buggy:  builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId(),  State.FAILED,   "primary  shard  is  not  allocated "));  context:  IndexMetaData  indexMetaData  =  metaData.index(index);  IndexRoutingTable  indexRoutingTable  =  clusterState.getRoutingTable().index(index);  if  (indexRoutingTable  ==  null)  {  throw  new  SnapshotCreationException(snapshotId,   "Missing  routing  table  for  index  [ "  +  index  +   "] ");  }  for  (int  i  =  0;  i  <  indexMetaData.numberOfShards();  i++)  {  ShardId  shardId  =  new  ShardId(index,  i);  ShardRouting  primary  =  indexRoutingTable.shard(i).primaryShard();  if  (primary  ==  null  ||  !primary.assignedToNode())  {                      builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId(),  State.FAILED,   "primary  shard  is  not  allocated "));                      builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(null,  State.FAILED,   "primary  shard  is  not  allocated "));  }  else  if  (!primary.started())  {  builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId(),  State.FAILED,   "primary  shard  hasn't  been  started  yet "));  }  else  {  builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(primary.currentNodeId()));  }  }  }  	builder.put(shardId,  new  SnapshotMetaData.ShardSnapshotStatus(null,  State.FAILED,   "primary  shard  is  not  allocated "));  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  !childIdToScore.containsKey(child);  context:  indexWriter.addDocument(document);  if  (!markParentAsDeleted)  {  NavigableMap<String,  Float>  childIdToScore;  if  (parentValueToChildIds.containsKey(parentValue))  {  childIdToScore  =  parentValueToChildIds.lget();  }  else  {  parentValueToChildIds.put(parentValue,  childIdToScore  =  new  TreeMap<String,  Float>());  }  if  (!markChildAsDeleted  &&  !filterMe)  {                          assert  !childIdToScore.containsKey(child);                          assertFalse( "child  [ "+  child  +   "]  already  has  a  score ",  childIdToScore.containsKey(child));  childIdToScore.put(child,  1f);  childIdToParentId.put(Integer.valueOf(child),  parentDocId);  }  }  }  }  	assertFalse( "child  [ "+  child  +   "]  already  has  a  score ",  childIdToScore.containsKey(child));  
elasticsearch_8aeb589a42d9f742161dde05be755c3f5d58e01a	buggy:  proc.onValue(values[loc],  docId);  context:  return  order[docId]  !=  0;  }  int  loc  =  order[docId];  if  (loc  ==  0)  {  return;  }          proc.onValue(values[loc],  docId);          proc.onValue(docId,  values[loc]);  }  return  values[order[docId]];  }  int  loc  =  order[docId];  	proc.onValue(docId,  values[loc]);  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  ByteArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  ByteArrayAtomicFieldData.WithOrdinals(  values.toArray(new  byte[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  ByteValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
libgdx_5377296492a5bff129062f8c1314678a1c3d5e7e	buggy:  return  BufferFactory.newByteBuffer(capacity);  context:  public  static  ByteBuffer  allocateDirect  (int  capacity)  {  if  (capacity  <  0)  {  throw  new  IllegalArgumentException();  }  return  BufferFactory.newByteBuffer(capacity);  return  BufferFactory.newDirectByteBuffer(capacity);  }  	return  BufferFactory.newDirectByteBuffer(capacity);  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  CreateIndexClusterStateUpdateRequest  updateRequest  =  new  CreateIndexClusterStateUpdateRequest(cause,  request.index())  context:  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,  request.index());  }  protected  void  masterOperation(final  CreateIndexRequest  request,  final  ClusterState  state,  final  ActionListener<CreateIndexResponse>  listener)  throws  ElasticsearchException  {  String  cause  =  request.cause();  if  (cause.length()  ==  0)  {  cause  =   "api ";  }          CreateIndexClusterStateUpdateRequest  updateRequest  =  new  CreateIndexClusterStateUpdateRequest(cause,  request.index())          final  CreateIndexClusterStateUpdateRequest  updateRequest  =  new  CreateIndexClusterStateUpdateRequest(request,  cause,  request.index())  .ackTimeout(request.timeout()).masterNodeTimeout(request.masterNodeTimeout())  .settings(request.settings()).mappings(request.mappings())  .aliases(request.aliases()).customs(request.customs());  createIndexService.createIndex(updateRequest,  new  ActionListener<ClusterStateUpdateResponse>()  {  public  void  onResponse(ClusterStateUpdateResponse  response)  {  	final  CreateIndexClusterStateUpdateRequest  updateRequest  =  new  CreateIndexClusterStateUpdateRequest(request,  cause,  request.index())  
elasticsearch_66c9f2f8344bdf9e58e0bc8a9fb59a527ec547cf	buggy:  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));  context:  assertThat( "make  sure  we  don't  have  duplicates ",  expectedIds.remove(hit.id()),  notNullValue());  }  assertThat( "make  sure  we  got  all  [ "  +  expectedIds  +   "] ",  expectedIds.size(),  equalTo(0));  }  SearchSourceBuilder  sourceBuilder  =  searchSource()  .query(termQuery( "multi ",   "test "))  .from(0).size(20).explain(true).sort( "age ",  false)                  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));                  .facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test ")).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  Map<SearchShardTarget,  QuerySearchResultProvider>  queryResults  =  newHashMap();  for  (ShardsIterator  shardsIt  :  indicesService.searchShards(clusterService.state(),  new  String[]{ "test "},  null))  {  for  (ShardRouting  shardRouting  :  shardsIt)  {  InternalSearchRequest  searchRequest  =  searchRequest(shardRouting,  sourceBuilder)  .scroll(new  Scroll(new  TimeValue(10,  TimeUnit.MINUTES)));  QuerySearchResult  queryResult  =  nodeToSearchService.get(shardRouting.currentNodeId()).executeQueryPhase(searchRequest);  queryResults.put(queryResult.shardTarget(),  queryResult);  	.facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test ")).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Byte  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execRefresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  context:  RefreshRequest  refreshRequest  =  new  RefreshRequest(RestActions.splitIndices(request.param( "index ")));  refreshRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  refreshRequest.operationThreading(operationThreading);          client.admin().indices().execRefresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {          client.admin().indices().refresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  	client.admin().indices().refresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  
elasticsearch_a414e4f2f3ce03c1cd80ca3ef7d01c370e49d5a7	buggy:  for  (RepositoriesService  repositoriesService  :  cluster().getInstances(RepositoriesService.class))  {  context:  public  abstract  class  AbstractSnapshotTests  extends  ElasticsearchIntegrationTest  {  public  static  long  getFailureCount(String  repository)  {  long  failureCount  =  0;          for  (RepositoriesService  repositoriesService  :  cluster().getInstances(RepositoriesService.class))  {          for  (RepositoriesService  repositoriesService  :  cluster().getDataNodeInstances(RepositoriesService.class))  {  MockRepository  mockRepository  =  (MockRepository)  repositoriesService.repository(repository);  failureCount  +=  mockRepository.getFailureCount();  }  return  failureCount;  }  public  static  int  numberOfFiles(File  dir)  {  int  count  =  0;  	for  (RepositoriesService  repositoriesService  :  cluster().getDataNodeInstances(RepositoriesService.class))  {  
libgdx_f5d0f1f3dd77f08d995859d3899992106c8b3627	buggy:  out.scl(scale);  context:  public  Transform  lerp(final  Vector3  targetT,  final  Quaternion  targetR,  final  Vector3  targetS,  final  float  alpha)  {  translation.lerp(targetT,  alpha);  rotation.slerp(targetR,  alpha);  scale.lerp(targetS,  alpha);  return  this;  }  public  Matrix4  toMatrix4(final  Matrix4  out)  {  out.idt();  out.translate(translation);  out.rotate(rotation);  out.scl(scale);  out.scale(scale.x,  scale.y,  scale.z);  return  out;  }  public  void  reset  ()  {  idt();  }  }  	out.scale(scale.x,  scale.y,  scale.z);  
elasticsearch_ebcc1e0bf5b0afcf76d7889bea94e9c8ff165535	buggy:  }  else  if  ( "id ".equals(currentFieldName))  {  context:  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  vars  =  parser.map();  }  else  {  throw  new  QueryParsingException(parseContext.index(),  NAMES[0]  +   "  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "id ".equals(currentFieldName))  {                  }  else  if  ( "script_id ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INDEXED;  }  else  if  ( "file ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.FILE;  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  {  	}  else  if  ( "script_id ".equals(currentFieldName))  {  
elasticsearch_5bd37f6f47bc9428cdb13fe5749f3dfb299e0389	buggy:  snapshotStatus.index().totalSize());  context:  stage  =  GatewaySnapshotStatus.Stage.FINALIZE;  break;  case  INDEX:  stage  =  GatewaySnapshotStatus.Stage.INDEX;  break;  default:  stage  =  GatewaySnapshotStatus.Stage.NONE;  break;  }  shardStatus.gatewaySnapshotStatus  =  new  GatewaySnapshotStatus(stage,  snapshotStatus.startTime(),  snapshotStatus.time(),                      snapshotStatus.index().totalSize());                      snapshotStatus.index().totalSize(),  snapshotStatus.translog().expectedNumberOfOperations());  }  return  shardStatus;  }  public  static  class  IndexShardStatusRequest  extends  BroadcastShardOperationRequest  {  IndexShardStatusRequest()  {  	snapshotStatus.index().totalSize(),  snapshotStatus.translog().expectedNumberOfOperations());  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  return  Font.createFont(Font.TRUETYPE_FONT,  Gdx.files.readFile(ttfFileRef,  FileType.Absolute));  context:  }  if  (ttfFileRef.length()  ==  0)  return  null;  return  ttfFileRef;  }  static  private  Font  createFont  (String  ttfFileRef)  {  try  {  return  Font.createFont(Font.TRUETYPE_FONT,  Gdx.files.readFile(ttfFileRef,  FileType.Absolute));  return  Font.createFont(Font.TRUETYPE_FONT,  Gdx.files.absolute(ttfFileRef).read());  }  catch  (FontFormatException  ex)  {  throw  new  GdxRuntimeException( "Invalid  font:   "  +  ttfFileRef,  ex);  }  catch  (IOException  ex)  {  throw  new  GdxRuntimeException( "Error  reading  font:   "  +  ttfFileRef,  ex);  }  }  	return  Font.createFont(Font.TRUETYPE_FONT,  Gdx.files.absolute(ttfFileRef).read());  
elasticsearch_473c2fa8f41daac0f8627eb398819ce506b3a144	buggy:  shard.relocated();  context:  if  (shard.state()  ==  IndexShardState.CLOSED)  {  throw  new  IndexShardClosedException(request.shardId());  }  StopWatch  stopWatch  =  new  StopWatch().start();  int  totalOperations  =  sendSnapshot(snapshot);  transportService.submitRequest(request.targetNode(),  RecoveryTarget.Actions.FINALIZE,  new  RecoveryFinalizeRecoveryRequest(request.shardId()),  VoidTransportResponseHandler.INSTANCE).txGet();  if  (request.markAsRelocated())  {  try  {                          shard.relocated();                          shard.relocated( "to   "  +  request.targetNode());  }  catch  (IllegalIndexShardStateException  e)  {  }  }  stopWatch.stop();  	shard.relocated( "to   "  +  request.targetNode());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<FiltersFunctionScoreQuery.FilterFunction>  filterFunctions  =  new  ArrayList<FiltersFunctionScoreQuery.FilterFunction>();  context:  }  public  Query  parse(QueryParseContext  parseContext)  throws  IOException,  QueryParsingException  {  XContentParser  parser  =  parseContext.parser();  Query  query  =  null;  float  boost  =  1.0f;  FiltersFunctionScoreQuery.ScoreMode  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Multiply;          ArrayList<FiltersFunctionScoreQuery.FilterFunction>  filterFunctions  =  new  ArrayList<FiltersFunctionScoreQuery.FilterFunction>();          ArrayList<FiltersFunctionScoreQuery.FilterFunction>  filterFunctions  =  new  ArrayList<>();  float  maxBoost  =  Float.MAX_VALUE;  String  currentFieldName  =  null;  XContentParser.Token  token;  CombineFunction  combineFunction  =  CombineFunction.MULT;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  	ArrayList<FiltersFunctionScoreQuery.FilterFunction>  filterFunctions  =  new  ArrayList<>();  
elasticsearch_57169d42334d39659bfcd8db2b062c7f6001a668	buggy:  logger.info( "bound_address[{}],  publish_address[{}] ",  serviceUrl,  publishUrl);  context:  }  catch  (Exception  e)  {  lastException.set(e);  return  false;  }  return  true;  }  });  if  (!success)  {  throw  new  JmxConnectorCreationException( "Failed  to  bind  to  [ "  +  port  +   "] ",  lastException.get());  }              logger.info( "bound_address[{}],  publish_address[{}] ",  serviceUrl,  publishUrl);              logger.info( "bound_address  {{}},  publish_address  {{}} ",  serviceUrl,  publishUrl);  }  for  (ResourceDMBean  resource  :  constructionMBeans)  {  register(resource);  }  }  public  void  registerMBean(Object  instance)  {  	logger.info( "bound_address  {{}},  publish_address  {{}} ",  serviceUrl,  publishUrl);  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  return  newPixmap(file.getInputStream());  context:  BufferedImage  img  =  (BufferedImage)  ImageIO.read(in);  return  new  JoglPixmap(img);  }  catch  (Exception  ex)  {  throw  new  GdxRuntimeException(   "Couldn't  load  Pixmap  from  InputStream ",  ex);  }  }  public  Pixmap  newPixmap(FileHandle  file)  {  return  newPixmap(file.getInputStream());  return  newPixmap(file.readFile());  }  public  Pixmap  newPixmap(Object  nativePixmap)  {  return  new  JoglPixmap((BufferedImage)  nativePixmap);  }  private  static  boolean  isPowerOfTwo(int  value)  {  	return  newPixmap(file.readFile());  
libgdx_b88d9fbbc43f08fcfb322680b1c7efdd0eb28155	buggy:  buffer.append(type.getSimpleName());  context:  this.fileName  =  fileName.replaceAll( "\\\\ ",   "/ ");  this.type  =  assetType;  this.params  =  params;  }  public  String  toString  ()  {  StringBuffer  buffer  =  new  StringBuffer();  buffer.append(fileName);  buffer.append( ",   ");  buffer.append(type.getSimpleName());  buffer.append(type.getName());  return  buffer.toString();  }  }  	buffer.append(type.getName());  
elasticsearch_393de984bd8b9f1d972f3d7fed4de30a9c64f7ff	buggy:  out.writeUTF(failure);  context:  out.writeVInt(numberOfDataNodes);  out.writeByte(status.value());  out.writeVInt(indices.size());  for  (ClusterIndexHealth  indexHealth  :  this)  {  indexHealth.writeTo(out);  }  out.writeBoolean(timedOut);  out.writeVInt(validationFailures.size());  for  (String  failure  :  validationFailures)  {              out.writeUTF(failure);              out.writeString(failure);  }  }  }  	out.writeString(failure);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.moreLikeThis(mltRequest,  new  ActionListener<SearchResponse>()  {  public  void  onResponse(SearchResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_cb7ea54d31d0735d0bb4d2727d043a858b3905a7	buggy:  model.setAnimation(animation,  time);  context:  Gdx.gl.glEnable(GL10.GL_LIGHT0);  Gdx.gl10.glLightfv(GL10.GL_LIGHT0,  GL10.GL_DIFFUSE,  lightColor,  0);  Gdx.gl10.glLightfv(GL10.GL_LIGHT0,  GL10.GL_POSITION,  lightPosition,  0);  angle  +=  45  *  Gdx.graphics.getDeltaTime();  long  processingTime  =  0;  for(int  i  =  0;  i  <  NUM_INSTANCES;  i++)  {  model.setAnimation(animation,  time);  model.setAnimation(animation,  time,  true);  model.render();  }  Gdx.gl.glDisable(GL10.GL_LIGHTING);  Gdx.gl.glDisable(GL10.GL_DEPTH_TEST);  Gdx.gl.glDisable(GL10.GL_TEXTURE_2D);  	model.setAnimation(animation,  time,  true);  
elasticsearch_3decb2a61e80fedd465ba2beb12a29858760d8c3	buggy:  mapperParser.putTypeParser(JsonAttachmentMapper.JSON_TYPE,  new  JsonAttachmentTypeParser());  context:  public  class  SimpleAttachmentMapperTests  {  private  JsonDocumentMapperParser  mapperParser;  mapperParser  =  new  JsonDocumentMapperParser(new  AnalysisService(new  Index( "test ")));          mapperParser.putTypeParser(JsonAttachmentMapper.JSON_TYPE,  new  JsonAttachmentTypeParser());          mapperParser.putTypeParser(JsonAttachmentMapper.JSON_TYPE,  new  JsonAttachmentMapper.TypeParser());  }  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/plugin/attachments/index/mapper/test-mapping.json ");  JsonDocumentMapper  docMapper  =  (JsonDocumentMapper)  mapperParser.parse(mapping);  byte[]  json  =  jsonBuilder().startObject().field( "_id ",  1).field( "file ",  copyToBytesFromClasspath( "/org/elasticsearch/plugin/attachments/index/mapper/testXHTML.html ")).endObject().copiedBytes();  Document  doc  =  docMapper.parse(json).doc();  	mapperParser.putTypeParser(JsonAttachmentMapper.JSON_TYPE,  new  JsonAttachmentMapper.TypeParser());  
elasticsearch_0a4e582404de860c367e078b5fad701d65ba677a	buggy:  request.queryParserName(),  request.filteringAliases(),  request.types());  context:  count  +=  ((ShardCountResponse)  shardResponse).count();  successfulShards++;  }  }  return  new  CountResponse(count,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  long  count  =  indexShard.count(request.minScore(),  request.querySource(),  request.querySourceOffset(),  request.querySourceLength(),                  request.queryParserName(),  request.filteringAliases(),  request.types());                  request.filteringAliases(),  request.types());  return  new  ShardCountResponse(request.index(),  request.shardId(),  count);  }  }  	request.filteringAliases(),  request.types());  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(GeoDistanceFacetCollectorParser.NAME);  context:  if  (fieldName  ==  null)  {  throw  new  SearchSourceBuilderException( "field  must  be  set  on  geo_distance  facet  for  facet  [ "  +  name  +   "] ");  }  if  (entries.isEmpty())  {  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(GeoDistanceFacetCollectorParser.NAME);          builder.startObject(GeoDistanceFacet.TYPE);  if  (geohash  !=  null)  {  builder.field(fieldName,  geohash);  }  else  {  builder.startArray(fieldName).value(lat).value(lon).endArray();  }  if  (valueFieldName  !=  null)  {  	builder.startObject(GeoDistanceFacet.TYPE);  
libgdx_baa8e10ff3a4997238509d8d1cc2530de6a9fb27	buggy:  if  (offset  <  0  ||  count  <  1  ||  offset  +  count  >  numIndices)  throw  new  GdxRuntimeException( "Not  enough  indices ");  context:  private  final  Vector3  tmpV  =  new  Vector3();  public  BoundingBox  extendBoundingBox  (final  BoundingBox  out,  int  offset,  int  count,  final  Matrix4  transform)  {  int  numIndices  =  getNumIndices();  if  (offset  <  0  ||  count  <  1  ||  offset  +  count  >  numIndices)  throw  new  GdxRuntimeException( "Not  enough  indices ");  if  (offset  <  0  ||  count  <  1  ||  offset  +  count  >  numIndices)  throw  new  GdxRuntimeException( "Not  enough  indices  (  offset= "+offset+ ",  count= "+count+ ",  max= "+numIndices+ "  ) ");  final  FloatBuffer  verts  =  vertices.getBuffer();  final  ShortBuffer  index  =  indices.getBuffer();  final  VertexAttribute  posAttrib  =  getVertexAttribute(Usage.Position);  final  int  posoff  =  posAttrib.offset  /  4;  final  int  vertexSize  =  vertices.getAttributes().vertexSize  /  4;  final  int  end  =  offset  +  count;  	if  (offset  <  0  ||  count  <  1  ||  offset  +  count  >  numIndices)  throw  new  GdxRuntimeException( "Not  enough  indices  (  offset= "+offset+ ",  count= "+count+ ",  max= "+numIndices+ "  ) ");  
elasticsearch_82e9a4e80a398d7cfc729347a1f3e8b34f2aa17c	buggy:  builder.field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  context:  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(name);  builder.field( "doc_count ",  subsetSize);  builder.startArray(CommonFields.BUCKETS);  for  (InternalSignificantTerms.Bucket  bucket  :  buckets)  {  if  (bucket.subsetDf  >=  minDocCount)  {  builder.startObject();                  builder.field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);                  builder.utf8Field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  builder.field(CommonFields.DOC_COUNT,  bucket.getDocCount());  builder.field( "score ",  bucket.score);  builder.field( "bg_count ",  bucket.supersetDf);  ((InternalAggregations)  bucket.getAggregations()).toXContentInternal(builder,  params);  builder.endObject();  }  }  builder.endArray();  	builder.utf8Field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  context:  shardStatus.state  =  indexShard.state();  try  {  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  shardStatus.translogId  =  indexShard.translog().currentId();  shardStatus.translogOperations  =  indexShard.translog().estimatedNumberOfOperations();              Engine.Searcher  searcher  =  indexShard.acquireSearcher();              Engine.Searcher  searcher  =  indexShard.acquireSearcher( "indices_status ");  try  {  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {  searcher.release();  }  	Engine.Searcher  searcher  =  indexShard.acquireSearcher( "indices_status ");  
libgdx_c7dc67f4c2fadf5b1b269b14d6de36ffc897b904	buggy:  len  =  i  -  1;  context:  frame.vertices  =  new  float[header.numVertices  *  3];  frame.normalIndices  =  new  int[header.numVertices];  float  scaleX  =  in.readFloat(),  scaleY  =  in.readFloat(),  scaleZ  =  in.readFloat();  float  transX  =  in.readFloat(),  transY  =  in.readFloat(),  transZ  =  in.readFloat();  in.read(charBuffer);  int  len  =  0;  for  (int  i  =  0;  i  <  charBuffer.length;  i++)  if  (charBuffer[i]  ==  0)  {  len  =  i  -  1;  len  =  i;  break;  }  frame.name  =  new  String(charBuffer,  0,  len);  int  vertIdx  =  0;  for  (int  i  =  0;  i  <  header.numVertices;  i++)  {  	len  =  i;  
elasticsearch_34ed85a40f186a2892007e89aabcfc8552bca36e	buggy:  public  FieldData.Type  getType()  {  context:  }  public  String  stringValue()  {  return  fieldData.stringValue(docId);  }  public  String  getStringValue()  {  return  stringValue();  }      public  FieldData.Type  getType()  {      public  FieldDataType  getType()  {  return  fieldData.type();  }  public  boolean  isMultiValued()  {  return  fieldData.multiValued();  }  }  	public  FieldDataType  getType()  {  
libgdx_d8f7d5a551ee1b16e3c3a7f15bd518dc18c61f58	buggy:  #if  defined(WIN32)  context:  b2Timer();  void  Reset();  float32  GetMilliseconds()  const;  private:  #if  defined(WIN32)  #if  defined(_WIN32)  float64  m_start;  static  float64  s_invFrequency;  #elif  defined(__linux__)  ||  defined  (__APPLE__)  unsigned  long  m_start_sec;  unsigned  long  m_start_msec;  #endif  };  	#if  defined(_WIN32)  
elasticsearch_73a447da861d2413269064899443b297b9ca3f88	buggy:  if  (facet.name().equals(facet1.name()))  {  context:  if  (!queryResults.isEmpty())  {  if  (querySearchResult.facets()  !=  null  &&  querySearchResult.facets().facets()  !=  null  &&  !querySearchResult.facets().facets().isEmpty())  {  List<Facet>  aggregatedFacets  =  Lists.newArrayList();  List<Facet>  namedFacets  =  Lists.newArrayList();  for  (Facet  facet  :  querySearchResult.facets())  {  namedFacets.clear();  for  (QuerySearchResultProvider  queryResultProvider  :  queryResults.values())  {  for  (Facet  facet1  :  queryResultProvider.queryResult().facets())  {                              if  (facet.name().equals(facet1.name()))  {                              if  (facet.getName().equals(facet1.getName()))  {  namedFacets.add(facet1);  }  }  }  if  (!namedFacets.isEmpty())  {  Facet  aggregatedFacet  =  ((InternalFacet)  namedFacets.get(0)).reduce(namedFacets);  aggregatedFacets.add(aggregatedFacet);  }  	if  (facet.getName().equals(facet1.getName()))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);  context:  this.transportAction  =  GetFieldMappingsAction.NAME;  transportService.registerHandler(transportAction,  new  TransportHandler());  }  protected  void  doExecute(GetFieldMappingsRequest  request,  final  ActionListener<GetFieldMappingsResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);          final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);          final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {  listener.onResponse(new  GetFieldMappingsResponse());  }  else  {  boolean  probablySingleFieldRequest  =  concreteIndices.length  ==  1  &&  request.types().length  ==  1  &&  request.fields().length  ==  1;  for  (final  String  index  :  concreteIndices)  {  GetFieldMappingsIndexRequest  shardRequest  =  new  GetFieldMappingsIndexRequest(request,  index,  probablySingleFieldRequest);  	final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  
elasticsearch_bd8d52f3f8dd6788a415a3dcc283483ce764ade0	buggy:  builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "devBuild ",  Version.devBuild()).endObject();  context:  }  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request).prettyPrint();  builder.startObject();  builder.field( "ok ",  true);  if  (settings.get( "name ")  !=  null)  {  builder.field( "name ",  settings.get( "name "));  }              builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "devBuild ",  Version.devBuild()).endObject();              builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshotBuild ",  Version.snapshotBuild()).endObject();  builder.field( "version ",  Version.number());  builder.field( "tagline ",   "You  Know,  for  Search ");  builder.field( "cover ",   "DON'T  PANIC ");  if  (rootNode  !=  null)  {  builder.startObject( "quote ");  ArrayNode  arrayNode  =  (ArrayNode)  rootNode.get( "quotes ");  JsonNode  quoteNode  =  arrayNode.get(ThreadLocalRandom.current().nextInt(quotesSize));  builder.field( "book ",  quoteNode.get( "book ").getValueAsText());  	builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshotBuild ",  Version.snapshotBuild()).endObject();  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.field( "name ",  nodeInfo.node().name());  context:  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "cluster_name ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeInfo  nodeInfo  :  result)  {  builder.startObject(nodeInfo.node().id(),  XContentBuilder.FieldCaseConversion.NONE);                          builder.field( "name ",  nodeInfo.node().name());                          builder.field( "name ",  nodeInfo.node().name(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "transport_address ",  nodeInfo.node().address().toString());  builder.startObject( "attributes ");  for  (Map.Entry<String,  String>  attr  :  nodeInfo.node().attributes().entrySet())  {  builder.field(attr.getKey(),  attr.getValue());  }  builder.endObject();  	builder.field( "name ",  nodeInfo.node().name(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  IndicesService  indicesService  =  cluster().getInstance(IndicesService.class);  context:  public  void  testIndexShardLifecycleLeak()  throws  Exception  {  client().admin().indices().prepareCreate( "test ")  .setSettings(ImmutableSettings.builder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  0))  .execute().actionGet();  client().admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();          IndicesService  indicesService  =  cluster().getInstance(IndicesService.class);          IndicesService  indicesService  =  internalCluster().getInstance(IndicesService.class);  IndexService  indexService  =  indicesService.indexServiceSafe( "test ");  Injector  indexInjector  =  indexService.injector();  IndexShard  shard  =  indexService.shardSafe(0);  Injector  shardInjector  =  indexService.shardInjector(0);  performCommonOperations();  List<WeakReference>  indexReferences  =  new  ArrayList<>();  	IndicesService  indicesService  =  internalCluster().getInstance(IndicesService.class);  
elasticsearch_4723c2a2ee264390227a089c59d1930469d8b5e5	buggy:  buckets.add(histogramFactory.createBucket(rounding.valueForKey(bucketOrds.get(i)),  bucketDocCount(i),  bucketAggregations(i),  formatter));  context:  }  previousKey  =  key;  }  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  assert  owningBucketOrdinal  ==  0;  List<InternalHistogram.Bucket>  buckets  =  new  ArrayList<>((int)  bucketOrds.size());  for  (long  i  =  0;  i  <  bucketOrds.size();  i++)  {              buckets.add(histogramFactory.createBucket(rounding.valueForKey(bucketOrds.get(i)),  bucketDocCount(i),  bucketAggregations(i),  formatter));              buckets.add(histogramFactory.createBucket(rounding.valueForKey(bucketOrds.get(i)),  bucketDocCount(i),  bucketAggregations(i),  keyed,  formatter));  }  CollectionUtil.introSort(buckets,  order.comparator());  InternalHistogram.EmptyBucketInfo  emptyBucketInfo  =  minDocCount  ==  0  ?  new  InternalHistogram.EmptyBucketInfo(rounding,  buildEmptySubAggregations(),  extendedBounds)  :  null;  return  histogramFactory.create(name,  buckets,  order,  minDocCount,  emptyBucketInfo,  formatter,  keyed);  }  	buckets.add(histogramFactory.createBucket(rounding.valueForKey(bucketOrds.get(i)),  bucketDocCount(i),  bucketAggregations(i),  keyed,  formatter));  
elasticsearch_5da14a7ed1ed6ef2c1817491e3f8cd8a8107948a	buggy:  builder.startArray(name).value(lat).value(lon).endArray();  context:  public  GeoDistanceFilterBuilder  cache(boolean  cache)  {  this.cache  =  cache;  return  this;  }  builder.startObject(GeoDistanceFilterParser.NAME);  if  (geohash  !=  null)  {  builder.field(name,  geohash);  }  else  {              builder.startArray(name).value(lat).value(lon).endArray();              builder.startArray(name).value(lon).value(lat).endArray();  }  builder.field( "distance ",  distance);  if  (geoDistance  !=  null)  {  builder.field( "distance_type ",  geoDistance.name().toLowerCase());  }  if  (filterName  !=  null)  {  builder.field( "_name ",  filterName);  }  	builder.startArray(name).value(lon).value(lat).endArray();  
elasticsearch_36e6102a1bb9912f9c0547e96797d0833023b81d	buggy:  Loggers.getLogger(MonitorModule.class).debug( "failed  to  load  sigar ",  e);  context:  SigarService  sigarService  =  new  SigarService(settings);  if  (sigarService.sigarAvailable())  {  bind(SigarService.class).toInstance(sigarService);  bind(ProcessProbe.class).to(SigarProcessProbe.class).asEagerSingleton();  bind(OsProbe.class).to(SigarOsProbe.class).asEagerSingleton();  bind(NetworkProbe.class).to(SigarNetworkProbe.class).asEagerSingleton();  sigarLoaded  =  true;  }  }  catch  (Throwable  e)  {              Loggers.getLogger(MonitorModule.class).debug( "failed  to  load  sigar ",  e);              Loggers.getLogger(MonitorModule.class).trace( "failed  to  load  sigar ",  e);  }  if  (!sigarLoaded)  {  bind(ProcessProbe.class).to(JmxProcessProbe.class).asEagerSingleton();  bind(OsProbe.class).to(JmxOsProbe.class).asEagerSingleton();  bind(NetworkProbe.class).to(JmxNetworkProbe.class).asEagerSingleton();  }  	Loggers.getLogger(MonitorModule.class).trace( "failed  to  load  sigar ",  e);  
elasticsearch_45319dc27f2815eb7d00e194f3dface6c868c96c	buggy:  threadPool.shutdown();  context:  assertThat( "failed  to  wait  for  all  nodes  to  connect ",  latch.await(5,  TimeUnit.SECONDS),  equalTo(true));  serviceA.removeConnectionListener(waitForConnection);  serviceB.removeConnectionListener(waitForConnection);  }  public  void  tearDown()  throws  Exception  {  super.tearDown();  serviceA.close();  serviceB.close();          threadPool.shutdown();          terminate(threadPool);  }  protected  MockTransportService  build(Settings  settings,  Version  version)  {  MockTransportService  transportService  =  new  MockTransportService(ImmutableSettings.EMPTY,  new  LocalTransport(settings,  threadPool,  version),  threadPool);  transportService.start();  return  transportService;  }  	terminate(threadPool);  
elasticsearch_668d55758b751e848f2b82299e2c5e74af55cd12	buggy:  request.realtime(),  request.version(),  request.versionType());  context:  protected  GetResponse  shardOperation(GetRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {  indexShard.refresh(new  Engine.Refresh(false));  }  GetResult  result  =  indexShard.getService().get(request.type(),  request.id(),  request.fields(),                  request.realtime(),  request.version(),  request.versionType());                  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());  return  new  GetResponse(result);  }  protected  GetRequest  newRequest()  {  return  new  GetRequest();  }  	request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());  
libgdx_241f53085fb57300b52c51198600d184cd9caa78	buggy:  translate(tmpVec.mul(-1));  context:  public  void  rotateAround  (Vector3  point,  Vector3  axis,  float  angle)  {  tmpVec.set(point);  tmpVec.sub(position);  translate(tmpVec);  rotate(axis,  angle);  tmpVec.rotate(axis,  angle);  translate(tmpVec.mul(-1));  translate(-tmpVec.x,  -tmpVec.y,  -tmpVec.z);  }  public  void  translate  (float  x,  float  y,  float  z)  {  position.add(x,  y,  z);  	translate(-tmpVec.x,  -tmpVec.y,  -tmpVec.z);  
elasticsearch_5d6e84f206c85476d25e4b26e7998db2067e3bac	buggy:  return  new  DictionaryCompoundWordTokenFilter(tokenStream,  wordList,  context:  public  class  DictionaryCompoundWordTokenFilterFactory  extends  AbstractCompoundWordTokenFilterFactory  {  super(index,  indexSettings,  name,  settings);  }          return  new  DictionaryCompoundWordTokenFilter(tokenStream,  wordList,          return  new  DictionaryCompoundWordTokenFilter(version,  tokenStream,  wordList,  minWordSize,  minSubwordSize,  maxSubwordSize,  onlyLongestMatch);  }  }  	return  new  DictionaryCompoundWordTokenFilter(version,  tokenStream,  wordList,  
elasticsearch_35bd7f0086cace871c861510c7282633d26adcdc	buggy:  listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e));  context:  finishHim();  }  }  });  }  private  void  finishHim()  {  try  {  innerFinishHim();  }  catch  (Exception  e)  {                  listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e));                  listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures()));  }  }  private  void  innerFinishHim()  {  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  fetchResults.values());  	listener.onFailure(new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures()));  
elasticsearch_7cfdd9ef59be2b572470e2fcbe0b0cf29e99205a	buggy:  if  ( "query_filter ".equals(value)  ||   "queryFirst ".equals(value))  {  context:  query  =  parseContext.parseInnerQuery();  }  else  if  ( "filter ".equals(currentFieldName))  {  filterFound  =  true;  filter  =  parseContext.parseInnerFilter();  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[filtered]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "strategy ".equals(currentFieldName))  {  String  value  =  parser.text();                      if  ( "query_filter ".equals(value)  ||   "queryFirst ".equals(value))  {                      if  ( "query_first ".equals(value)  ||   "queryFirst ".equals(value))  {  filterStrategy  =  XFilteredQuery.QUERY_FIRST_FILTER_STRATEGY;  }  else  if  ( "random_access_random ".equals(value)  ||   "randomAccessAlways ".equals(value))  {  filterStrategy  =  XFilteredQuery.ALWAYS_RANDOM_ACCESS_FILTER_STRATEGY;  }  else  if  ( "leap_frog ".equals(value)  ||   "leapFrog ".equals(value))  {  filterStrategy  =  XFilteredQuery.LEAP_FROG_QUERY_FIRST_STRATEGY;  }  else  if  (value.startsWith( "random_access_ "))  {  int  threshold  =  Integer.parseInt(value.substring( "random_access_ ".length()));  filterStrategy  =  new  XFilteredQuery.CustomRandomAccessFilterStrategy(threshold);  	if  ( "query_first ".equals(value)  ||   "queryFirst ".equals(value))  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(OpenIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  OpenIndexRequest  request,  final  ClusterState  state,  final  ActionListener<OpenIndexResponse>  listener)  throws  ElasticsearchException  {          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  OpenIndexClusterStateUpdateRequest  updateRequest  =  new  OpenIndexClusterStateUpdateRequest()  .ackTimeout(request.timeout()).masterNodeTimeout(request.masterNodeTimeout())  .indices(request.indices());  indexStateService.openIndex(updateRequest,  new  ClusterStateUpdateListener()  {  public  void  onResponse(ClusterStateUpdateResponse  response)  {  	request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_81965d0ea94170e06de225c8cc9b822084daf63c	buggy:  filter  =  smartNameFieldMappers.mapper().fieldFilter(value);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  filter  =  smartNameFieldMappers.mapper().fieldFilter(value);                  filter  =  smartNameFieldMappers.mapper().fieldFilter(value,  parseContext);  }  }  if  (filter  ==  null)  {  filter  =  new  TermFilter(new  Term(fieldName,  value));  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  	filter  =  smartNameFieldMappers.mapper().fieldFilter(value,  parseContext);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  final  byte[]  data  =  cachedEntry.bytes().copiedByteArray();  context:  stream.writeUTF(action);  message.writeTo(stream);  stream.close();  final  LocalTransport  targetTransport  =  connectedNodes.get(node);  if  (targetTransport  ==  null)  {  throw  new  NodeNotConnectedException(node,   "Node  not  connected ");  }              final  byte[]  data  =  cachedEntry.bytes().copiedByteArray();              final  byte[]  data  =  cachedEntry.bytes().bytes().copyBytesArray().toBytes();  transportServiceAdapter.sent(data.length);  threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  targetTransport.messageReceived(data,  action,  LocalTransport.this,  requestId);  }  	final  byte[]  data  =  cachedEntry.bytes().bytes().copyBytesArray().toBytes();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  new  ArrayList<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket>(ranges.size());  context:  public  InternalRange  buildAggregation(long  owningBucketOrdinal)  {  return  buildEmptyAggregation();  }  public  InternalRange  buildEmptyAggregation()  {  InternalAggregations  subAggs  =  buildEmptySubAggregations();  List<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket>  buckets  =                      new  ArrayList<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket>(ranges.size());                      new  ArrayList<>(ranges.size());  for  (RangeAggregator.Range  range  :  ranges)  {  buckets.add(factory.createBucket(range.key,  range.from,  range.to,  0,  subAggs,  formatter));  }  return  factory.create(name,  buckets,  formatter,  keyed,  true);  }  }  public  static  class  Factory  extends  ValueSourceAggregatorFactory<NumericValuesSource>  {  	new  ArrayList<>(ranges.size());  
elasticsearch_45234f4d90a8f2132dc51a506d3cfaf99751ea10	buggy:  toJson(builder,  params,  null);  context:  }  }  else  {  mergeIntoMapper.merge(mergeWithMapper,  mergeContext);  }  }  }  }  }          toJson(builder,  params,  null);          toJson(builder,  params,  JsonMapper.EMPTY_ARRAY);  }  public  void  toJson(JsonBuilder  builder,  Params  params,  JsonMapper...  additionalMappers)  throws  IOException  {  builder.startObject(name);  builder.field( "type ",  JSON_TYPE);  builder.field( "dynamic ",  dynamic);  builder.field( "enabled ",  enabled);  builder.field( "pathType ",  pathType.name().toLowerCase());  	toJson(builder,  params,  JsonMapper.EMPTY_ARRAY);  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  if  (!running)  {  return;  }  NodeFD  nodeFD  =  nodesFD.get(node);  if  (nodeFD  !=  null)  {  nodeFD.retryCount  =  0;  threadPool.schedule(SendPingRequest.this,  pingInterval);  }  }                          @Override  public  void  handleException(RemoteTransportException  exp)  {                          @Override  public  void  handleException(TransportException  exp)  {  if  (!running)  {  return;  }  NodeFD  nodeFD  =  nodesFD.get(node);  if  (nodeFD  !=  null)  {  int  retryCount  =  ++nodeFD.retryCount;  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  builder.treeLevelsByDistance(DistanceUnit.parse(fieldNode.toString(),  DistanceUnit.METERS,  DistanceUnit.METERS));  context:  Builder  builder  =  geoShapeField(name);  for  (Map.Entry<String,  Object>  entry  :  node.entrySet())  {  String  fieldName  =  Strings.toUnderscoreCase(entry.getKey());  Object  fieldNode  =  entry.getValue();  if  (Names.TREE.equals(fieldName))  {  builder.tree(fieldNode.toString());  }  else  if  (Names.TREE_LEVELS.equals(fieldName))  {  builder.treeLevels(Integer.parseInt(fieldNode.toString()));  }  else  if  (Names.TREE_PRESISION.equals(fieldName))  {                      builder.treeLevelsByDistance(DistanceUnit.parse(fieldNode.toString(),  DistanceUnit.METERS,  DistanceUnit.METERS));                      builder.treeLevelsByDistance(DistanceUnit.parse(fieldNode.toString(),  DistanceUnit.DEFAULT,  DistanceUnit.DEFAULT));  }  else  if  (Names.DISTANCE_ERROR_PCT.equals(fieldName))  {  builder.distanceErrorPct(Double.parseDouble(fieldNode.toString()));  }  else  if  (Names.STRATEGY.equals(fieldName))  {  builder.strategy(fieldNode.toString());  }  }  return  builder;  }  	builder.treeLevelsByDistance(DistanceUnit.parse(fieldNode.toString(),  DistanceUnit.DEFAULT,  DistanceUnit.DEFAULT));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  listener  =  new  ThreadedActionListener<Response>(threadPool,  listener,  logger);  context:  PlainActionFuture<Response>  future  =  newFuture();  request.listenerThreaded(false);  execute(request,  future);  return  future;  }  public  void  execute(Request  request,  ActionListener<Response>  listener)  {  if  (request.listenerThreaded())  {              listener  =  new  ThreadedActionListener<Response>(threadPool,  listener,  logger);              listener  =  new  ThreadedActionListener<>(threadPool,  listener,  logger);  }  ActionRequestValidationException  validationException  =  request.validate();  if  (validationException  !=  null)  {  listener.onFailure(validationException);  return;  }  try  {  doExecute(request,  listener);  	listener  =  new  ThreadedActionListener<>(threadPool,  listener,  logger);  
libgdx_a356f5d144b5c5c09cd7d4fd47b0e0d14e4d880d	buggy:  for  (int  i  =  0;  i  <  500;  i++)  {  context:  public  class  TextButtonTest  extends  GdxTest  {  private  Stage  stage;  private  Skin  skin;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false,  new  SpriteBatch());  Gdx.input.setInputProcessor(stage);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  for  (int  i  =  0;  i  <  500;  i++)  {  for  (int  i  =  0;  i  <  1;  i++)  {  TextButton  t  =  new  TextButton( "Button "+i,  skin);  t.setX(MathUtils.random(0,  Gdx.graphics.getWidth()));  t.setY(MathUtils.random(0,  Gdx.graphics.getHeight()));  t.setWidth(MathUtils.random(50,  200));  t.setHeight(MathUtils.random(0,  100));  stage.addActor(t);  }  }  	for  (int  i  =  0;  i  <  1;  i++)  {  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index());  context:  public  MoreLikeThisRequest  newRequestInstance(){  return  new  MoreLikeThisRequest();  }  protected  void  doExecute(final  MoreLikeThisRequest  request,  final  ActionListener<SearchResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();          final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index());          final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index(),  request.indicesOptions());  Iterable<MutableShardRouting>  routingNode  =  clusterState.getRoutingNodes().routingNodeIter(clusterService.localNode().getId());  if  (routingNode  ==  null)  {  redirect(request,  concreteIndex,  listener,  clusterState);  return;  }  boolean  hasIndexLocally  =  false;  for  (MutableShardRouting  shardRouting  :  routingNode)  {  	final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index(),  request.indicesOptions());  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  routingTableBuilder.add(indexMetaData,  false);  context:  boolean  importNeeded  =  false;  StringBuilder  sb  =  new  StringBuilder();  for  (IndexMetaData  indexMetaData  :  request.indices)  {  if  (currentState.metaData().hasIndex(indexMetaData.index()))  {  continue;  }  metaData.put(indexMetaData,  false);  blocks.addBlocks(indexMetaData);                          routingTableBuilder.add(indexMetaData,  false);                          routingTableBuilder.addAsRecovery(indexMetaData);  sb.append( "[ ").append(indexMetaData.index()).append( "/ ").append(indexMetaData.state()).append( "] ");  }  if  (!importNeeded)  {  return  currentState;  }  ClusterState  updatedState  =  ClusterState.builder().state(currentState).metaData(metaData).blocks(blocks).routingTable(routingTableBuilder).build();  	routingTableBuilder.addAsRecovery(indexMetaData);  
libgdx_82d246c4b1ab94dd9dbb9ca4de4d7127dc594bd7	buggy:  if  (Gdx.input.isTouched())  {  context:  spriteBatch.draw(logo,  0,  320  -  128,  480,  128,  0,  256,  512,  256,  false,  false);  String  text  =   "It  is  the  end  my  friend.\nTouch  to  continue! ";  TextBounds  bounds  =  font.getMultiLineBounds(text);  spriteBatch.setBlendFunction(GL10.GL_ONE,  GL10.GL_ONE_MINUS_SRC_ALPHA);  font.drawMultiLine(spriteBatch,  text,  0,  160  +  bounds.height  /  2,  480,  HAlignment.CENTER);  spriteBatch.end();  }  public  void  update  (float  delta)  {  if  (Gdx.input.isTouched())  {  if  (Gdx.input.justTouched())  {  isDone  =  true;  }  }  }  	if  (Gdx.input.justTouched())  {  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  multiGetRequest.preference(request.param( "preference "));  multiGetRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  String[]  sFields  =  null;  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  sFields  =  Strings.splitStringByCommaToArray(sField);  }  try  {              multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());              multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  request.content());  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  	multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  request.content());  
elasticsearch_c0288a62e653f66df2b6b0d0786aa3f36bdc1eb0	buggy:  .setQuery(functionScoreQuery(matchAllQuery()).scoreMode( "total ").add(termFilter( "field ",   "value4 "),  new  FactorBuilder().boostFactor(2)).add(termFilter( "field ",   "value1 "),  new  FactorBuilder().boostFactor(3)).add(termFilter( "color ",   "red "),  new  FactorBuilder().boostFactor(5)))  context:  assertThat(searchResponse.getHits().getAt(0).score(),  equalTo(3.0f));  assertThat(searchResponse.getHits().getAt(1).id(),  equalTo( "4 "));  assertThat(searchResponse.getHits().getAt(1).score(),  equalTo(2.0f));  assertThat(searchResponse.getHits().getAt(2).id(),  anyOf(equalTo( "1 "),  equalTo( "3 ")));  assertThat(searchResponse.getHits().getAt(2).score(),  equalTo(1.0f));  assertThat(searchResponse.getHits().getAt(3).id(),  anyOf(equalTo( "1 "),  equalTo( "3 ")));  assertThat(searchResponse.getHits().getAt(3).score(),  equalTo(1.0f));  searchResponse  =  client().prepareSearch( "test ")                  .setQuery(functionScoreQuery(matchAllQuery()).scoreMode( "total ").add(termFilter( "field ",   "value4 "),  new  FactorBuilder().boostFactor(2)).add(termFilter( "field ",   "value1 "),  new  FactorBuilder().boostFactor(3)).add(termFilter( "color ",   "red "),  new  FactorBuilder().boostFactor(5)))                  .setQuery(functionScoreQuery(matchAllQuery()).scoreMode( "sum ").add(termFilter( "field ",   "value4 "),  new  FactorBuilder().boostFactor(2)).add(termFilter( "field ",   "value1 "),  new  FactorBuilder().boostFactor(3)).add(termFilter( "color ",   "red "),  new  FactorBuilder().boostFactor(5)))  .setExplain(true)  .execute().actionGet();  assertThat(Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getFailedShards(),  equalTo(0));  assertThat(searchResponse.getHits().totalHits(),  equalTo(4l));  assertThat(searchResponse.getHits().getAt(0).id(),  equalTo( "1 "));  assertThat(searchResponse.getHits().getAt(0).score(),  equalTo(8.0f));  	.setQuery(functionScoreQuery(matchAllQuery()).scoreMode( "sum ").add(termFilter( "field ",   "value4 "),  new  FactorBuilder().boostFactor(2)).add(termFilter( "field ",   "value1 "),  new  FactorBuilder().boostFactor(3)).add(termFilter( "color ",   "red "),  new  FactorBuilder().boostFactor(5)))  
elasticsearch_461063d20b2d9e9502ea0c776962a8a505b6bf47	buggy:  throw  new  ElasticSearchIllegalStateException( "No  should  routing  state  mapped  for  [ "  +  value  +   "] ");  context:  switch  (value)  {  case  1:  return  UNASSIGNED;  case  2:  return  INITIALIZING;  case  3:  return  STARTED;  case  4:  return  RELOCATING;  default:                  throw  new  ElasticSearchIllegalStateException( "No  should  routing  state  mapped  for  [ "  +  value  +   "] ");                  throw  new  ElasticSearchIllegalStateException( "No  routing  state  mapped  for  [ "  +  value  +   "] ");  }  }  }  	throw  new  ElasticSearchIllegalStateException( "No  routing  state  mapped  for  [ "  +  value  +   "] ");  
libgdx_f3060bacc1a82a69be2ed475b656707bbf58a746	buggy:  root.render(batch);  context:  root.act(delta);  }  public  void  render  ()  {  batch.setProjectionMatrix(projection);  batch.setTransformMatrix(identity);  batch.begin();  root.render(batch);  root.draw(batch,  1);  batch.end();  }  public  void  dispose  ()  {  batch.dispose();  	root.draw(batch,  1);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  return  new  GetSettingsRequest();  }  protected  GetSettingsResponse  newResponse()  {  return  new  GetSettingsResponse();  }  protected  void  masterOperation(GetSettingsRequest  request,  ClusterState  state,  ActionListener<GetSettingsResponse>  listener)  throws  ElasticsearchException  {          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  ImmutableOpenMap.Builder<String,  Settings>  indexToSettingsBuilder  =  ImmutableOpenMap.builder();  for  (String  concreteIndex  :  request.indices())  {  IndexMetaData  indexMetaData  =  state.getMetaData().index(concreteIndex);  if  (indexMetaData  ==  null)  {  continue;  }  Settings  settings  =  settingsFilter.filterSettings(indexMetaData.settings());  	request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  messageReceived(final  BulkRequest  request,  final  TransportChannel  channel)  throws  Exception  {  request.listenerThreaded(false);  execute(request,  new  ActionListener<BulkResponse>()  {  public  void  onResponse(BulkResponse  result)  {  try  {  channel.sendResponse(result);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
libgdx_01d1bff4eb9ad9fe86b15551847e8ffeaac80b5b	buggy:  if  (scrollbarsOnTop  &&  scrollX)  {  context:  if  (scrollY)  vKnobBounds.y  =  vScrollBounds.y  +  (int)((vScrollBounds.height  -  vKnobBounds.height)  *  (1  -  getScrollPercentY()));  float  y  =  widgetAreaBounds.y;  if  (!scrollY)  y  -=  (int)maxY;  else  y  -=  (int)(maxY  -  visualAmountY);  if  (scrollbarsOnTop  &&  scrollX)  {  if  (!fadeScrollBars  &&  scrollbarsOnTop  &&  scrollX)  {  float  scrollbarHeight  =  0;  if  (style.hScrollKnob  !=  null)  scrollbarHeight  =  style.hScrollKnob.getMinHeight();  if  (style.hScroll  !=  null)  scrollbarHeight  =  Math.max(scrollbarHeight,  style.hScroll.getMinHeight());  y  +=  scrollbarHeight;  }  float  x  =  widgetAreaBounds.x;  if  (scrollX)  x  -=  (int)visualAmountX;  	if  (!fadeScrollBars  &&  scrollbarsOnTop  &&  scrollX)  {  
elasticsearch_947c5f69207d3442c5f51667e7f09b99dde60343	buggy:  sortedShardList  =  searchPhaseController.sortDocs(firstResults);  context:  }  catch  (Throwable  e)  {  ReduceSearchPhaseException  failure  =  new  ReduceSearchPhaseException( "merge ",   " ",  e,  buildShardFailures());  if  (logger.isDebugEnabled())  {  }  listener.onFailure(failure);  }  }  private  void  innerFinishHim()  throws  IOException  {              sortedShardList  =  searchPhaseController.sortDocs(firstResults);              sortedShardList  =  searchPhaseController.sortDocs(request,  useSlowScroll,  firstResults);  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  firstResults,  firstResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  firstResults,  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  	sortedShardList  =  searchPhaseController.sortDocs(request,  useSlowScroll,  firstResults);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  doc.add(new  Field( "_source ",  builder.underlyingBytes(),  0,  builder.underlyingBytesLength()));  context:  IndexWriter  compressedSnappyWriter  =  new  IndexWriter(compressedSnappyDir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  TestData  testData  =  new  TestData();  while  (testData.next()  &&  testData.getTotalSize()  <  MAX_SIZE)  {  XContentBuilder  builder  =  XContentFactory.jsonBuilder();  testData.current(builder);  builder.close();  Document  doc  =  new  Document();              doc.add(new  Field( "_source ",  builder.underlyingBytes(),  0,  builder.underlyingBytesLength()));              doc.add(new  Field( "_source ",  builder.bytes().array(),  builder.bytes().arrayOffset(),  builder.bytes().length()));  if  (WITH_TV)  {  Field  field  =  new  Field( "text ",  builder.string(),  Field.Store.NO,  Field.Index.ANALYZED,  Field.TermVector.WITH_POSITIONS_OFFSETS);  doc.add(field);  }  uncompressedWriter.addDocument(doc);  compressedLzfWriter.addDocument(doc);  compressedSnappyWriter.addDocument(doc);  }  	doc.add(new  Field( "_source ",  builder.bytes().array(),  builder.bytes().arrayOffset(),  builder.bytes().length()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<ValuesSource>  config  =  new  ValuesSourceConfig<ValuesSource>(ValuesSource.class);  context:  public  class  MissingParser  implements  Aggregator.Parser  {  public  String  type()  {  return  InternalMissing.TYPE.name();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          ValuesSourceConfig<ValuesSource>  config  =  new  ValuesSourceConfig<ValuesSource>(ValuesSource.class);          ValuesSourceConfig<ValuesSource>  config  =  new  ValuesSourceConfig<>(ValuesSource.class);  String  field  =  null;  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  	ValuesSourceConfig<ValuesSource>  config  =  new  ValuesSourceConfig<>(ValuesSource.class);  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardSuggestRequest(shard.index(),  shard.id(),  request);  context:  return  new  SuggestRequest();  }  protected  ShardSuggestRequest  newShardRequest()  {  return  new  ShardSuggestRequest();  }  protected  ShardSuggestRequest  newShardRequest(int  numShards,  ShardRouting  shard,  SuggestRequest  request)  {          return  new  ShardSuggestRequest(shard.index(),  shard.id(),  request);          return  new  ShardSuggestRequest(shard.shardId(),  request);  }  protected  ShardSuggestResponse  newShardResponse()  {  return  new  ShardSuggestResponse();  }  	return  new  ShardSuggestRequest(shard.shardId(),  request);  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  precision  =  Distance.parseDistance(precisionAsString,  DistanceUnit.METERS);  context:  public  static  class  Builder  implements  IndexFieldData.Builder  {  public  IndexFieldData<?>  build(Index  index,  @IndexSettings  Settings  indexSettings,  FieldMapper<?>  mapper,  IndexFieldDataCache  cache,  CircuitBreakerService  breakerService)  {  FieldDataType  type  =  mapper.fieldDataType();  final  String  precisionAsString  =  type.getSettings().get(PRECISION_KEY);  final  Distance  precision;  if  (precisionAsString  !=  null)  {                  precision  =  Distance.parseDistance(precisionAsString,  DistanceUnit.METERS);                  precision  =  Distance.parseDistance(precisionAsString);  }  else  {  precision  =  DEFAULT_PRECISION_VALUE;  }  return  new  GeoPointCompressedIndexFieldData(index,  indexSettings,  mapper.names(),  mapper.fieldDataType(),  cache,  precision,  breakerService);  }  }  private  final  GeoPointFieldMapper.Encoding  encoding;  	precision  =  Distance.parseDistance(precisionAsString);  
libgdx_febe9af92ea9c5b2e924788628b928bda8c7d1d8	buggy:  camera.setMatrices(  app.getGraphics()  );  context:  long  start  =  System.nanoTime();  world.step(  app.getGraphics().getDeltaTime(),  3,  3  );  float  updateTime  =  (System.nanoTime()  -  start)  /  1000000000.0f;  GL10  gl  =  app.getGraphics().getGL10();  gl.glClear(  GL10.GL_COLOR_BUFFER_BIT  );  camera.setMatrices(  app.getGraphics()  );  camera.setMatrices(  );  renderBox(  gl,  groundBody,  50,  1  );  for(  int  i  =  0;  i  <  boxes.size();  i++  )  {  	camera.setMatrices(  );  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  if  (masterToPing.equals(MasterFaultDetection.this.masterNode()))  {  if  (!response.connectedToMaster)  {  notifyDisconnectedFromMaster();  }  threadPool.schedule(MasterPinger.this,  pingInterval);  }  }                          @Override  public  void  handleException(RemoteTransportException  exp)  {                          @Override  public  void  handleException(TransportException  exp)  {  if  (!running)  {  return;  }  synchronized  (masterNodeMutex)  {  if  (masterToPing.equals(MasterFaultDetection.this.masterNode()))  {  int  retryCount  =  ++MasterFaultDetection.this.retryCount;  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(clusterState.metaData().concreteSingleIndex(request.index()));  context:  }  protected  void  doExecute(final  Request  request,  final  ActionListener<Response>  listener)  {  ClusterState  clusterState  =  clusterService.state();  ClusterBlockException  blockException  =  checkGlobalBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }          request.index(clusterState.metaData().concreteSingleIndex(request.index()));          request.index(clusterState.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  blockException  =  checkRequestBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }  GroupShardsIterator  groups;  try  {  groups  =  shards(request);  	request.index(clusterState.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  if  (!routingNodes.routingTable().index(shard.index()).shard(shard.id()).allocatedPostApi())  {  context:  Iterator<MutableShardRouting>  unassignedIterator  =  routingNodes.unassigned().iterator();  while  (unassignedIterator.hasNext())  {  MutableShardRouting  shard  =  unassignedIterator.next();  if  (!shard.primary())  {  continue;  }              if  (!routingNodes.routingTable().index(shard.index()).shard(shard.id()).allocatedPostApi())  {              if  (!routingNodes.routingTable().index(shard.index()).shard(shard.id()).primaryAllocatedPostApi())  {  continue;  }  TObjectLongHashMap<DiscoveryNode>  nodesState  =  buildShardStates(nodes,  shard);  int  numberOfAllocationsFound  =  0;  long  highestVersion  =  -1;  Set<DiscoveryNode>  nodesWithHighestVersion  =  Sets.newHashSet();  	if  (!routingNodes.routingTable().index(shard.index()).shard(shard.id()).primaryAllocatedPostApi())  {  
libgdx_5528873ffa6d2ccbb0595e7fc09738833a79bf68	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.StagePerformanceTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.StagePerformanceTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.FramebufferToTextureTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.FramebufferToTextureTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_c0288a62e653f66df2b6b0d0786aa3f36bdc1eb0	buggy:  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Total;  context:  boost  =  parser.floatValue();  }  else  if  ( "score_mode ".equals(currentFieldName)  ||   "scoreMode ".equals(currentFieldName))  {  String  sScoreMode  =  parser.text();  if  ( "avg ".equals(sScoreMode))  {  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Avg;  }  else  if  ( "max ".equals(sScoreMode))  {  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Max;  }  else  if  ( "min ".equals(sScoreMode))  {  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Min;  }  else  if  ( "total ".equals(sScoreMode))  {                          scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Total;                          scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Sum;  }  else  if  ( "multiply ".equals(sScoreMode))  {  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Multiply;  }  else  if  ( "first ".equals(sScoreMode))  {  scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.First;  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[custom_filters_score]  illegal  score_mode  [ "  +  sScoreMode   "] ");  }  	scoreMode  =  FiltersFunctionScoreQuery.ScoreMode.Sum;  
libgdx_304a52f855f3d24f385976d9fea435d11c6ed05c	buggy:  Array<AssetDescriptor>  dependencies  =  new  Array<AssetDescriptor>();  context:  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  atlasFile,  TextureAtlasParameter  parameter)  {  FileHandle  imgDir  =  atlasFile.parent();  if  (parameter  !=  null)  data  =  new  TextureAtlasData(atlasFile,  imgDir,  parameter.flip);  else  {  data  =  new  TextureAtlasData(atlasFile,  imgDir,  false);  }  Array<AssetDescriptor>  dependencies  =  new  Array<AssetDescriptor>();  Array<AssetDescriptor>  dependencies  =  Array.of(AssetDescriptor.class);  for  (Page  page  :  data.getPages())  {  TextureParameter  params  =  new  TextureParameter();  params.format  =  page.format;  params.genMipMaps  =  page.useMipMaps;  params.minFilter  =  page.minFilter;  params.magFilter  =  page.magFilter;  dependencies.add(new  AssetDescriptor(page.textureFile,  Texture.class,  params));  }  	Array<AssetDescriptor>  dependencies  =  Array.of(AssetDescriptor.class);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  IndexRequest  indexRequest  =  new  IndexRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  indexRequest.listenerThreaded(false);  indexRequest.operationThreaded(true);  indexRequest.routing(request.param( "routing "));  indexRequest.parent(request.param( "parent "));  //  order  is  important,  set  it  after  routing,  so  it  will  set  the  routing  indexRequest.timestamp(request.param( "timestamp "));  if  (request.hasParam( "ttl "))  {  indexRequest.ttl(request.paramAsTime( "ttl ",  null).millis());  }          indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());          indexRequest.source(request.content(),  request.contentUnsafe());  indexRequest.timeout(request.paramAsTime( "timeout ",  IndexRequest.DEFAULT_TIMEOUT));  indexRequest.refresh(request.paramAsBoolean( "refresh ",  indexRequest.refresh()));  indexRequest.version(RestActions.parseVersion(request));  indexRequest.versionType(VersionType.fromString(request.param( "version_type "),  indexRequest.versionType()));  indexRequest.percolate(request.param( "percolate ",  null));  String  sOpType  =  request.param( "op_type ");  if  (sOpType  !=  null)  {  if  ( "index ".equals(sOpType))  {  	indexRequest.source(request.content(),  request.contentUnsafe());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  types  =  new  HashSet<String>();  context:  if  (logger.isTraceEnabled())  {  traceLogResponse( "Flush ",  flushResponse);  }  ImmutableOpenMap<String,  ImmutableOpenMap<String,  MappingMetaData>>  result  =  clusterService.state().metaData().findMappings(  request.indices(),  request.types()  );  BoolFilterBuilder  filterBuilder  =  new  BoolFilterBuilder();                  Set<String>  types  =  new  HashSet<String>();                  Set<String>  types  =  new  HashSet<>();  for  (ObjectObjectCursor<String,  ImmutableOpenMap<String,  MappingMetaData>>  typesMeta  :  result)  {  for  (ObjectObjectCursor<String,  MappingMetaData>  type  :  typesMeta.value)  {  filterBuilder.should(new  TypeFilterBuilder(type.key));  types.add(type.key);  }  }  if  (types.size()  ==  0)  {  throw  new  TypeMissingException(new  Index( "_all "),  request.types(),   "No  index  has  the  type. ");  	Set<String>  types  =  new  HashSet<>();  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.startObject(entry.getKey());  context:  indexingStats.readFrom(in);  return  indexingStats;  }  builder.startObject(Fields.INDEXING);  totalStats.toXContent(builder,  params);  if  (typeStats  !=  null  &&  !typeStats.isEmpty())  {  builder.startObject(Fields.TYPES);  for  (Map.Entry<String,  Stats>  entry  :  typeStats.entrySet())  {                  builder.startObject(entry.getKey());                  builder.startObject(entry.getKey(),  XContentBuilder.FieldCaseConversion.NONE);  entry.getValue().toXContent(builder,  params);  builder.endObject();  }  builder.endObject();  }  builder.endObject();  return  builder;  }  	builder.startObject(entry.getKey(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  cluster().wipeIndices( "test ");  context:  }  catch  (Throwable  t)  {  if  (firstError  ==  null)  {  firstError  =  t;  }  }  }  if  (firstError  !=  null)  {  fail(firstError.getMessage());  }              cluster().wipeIndices( "test ");              internalCluster().wipeIndices( "test ");  }  }  public  void  testCreatedFlag()  throws  Exception  {  createIndex( "test ");  ensureGreen();  	internalCluster().wipeIndices( "test ");  
elasticsearch_5da14a7ed1ed6ef2c1817491e3f8cd8a8107948a	buggy:  builder.startArray(fieldName).value(lat).value(lon).endArray();  context:  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);  builder.startObject(GeoDistanceFacet.TYPE);  if  (geohash  !=  null)  {  builder.field(fieldName,  geohash);  }  else  {              builder.startArray(fieldName).value(lat).value(lon).endArray();              builder.startArray(fieldName).value(lon).value(lat).endArray();  }  if  (valueFieldName  !=  null)  {  builder.field( "value_field ",  valueFieldName);  }  if  (valueScript  !=  null)  {  builder.field( "value_script ",  valueScript);  	builder.startArray(fieldName).value(lon).value(lat).endArray();  
libgdx_9fdd285d30c306b99e59984c535fa1988620d523	buggy:  vertexAttributes.add(VertexAttribute.Color());  context:  for  (JsonValue  value  =  attributes.child;  value  !=  null;  value  =  value.next)  {  String  attribute  =  value.asString();  String  attr  =  (String)attribute;  if  (attr.equals( "POSITION "))  {  vertexAttributes.add(VertexAttribute.Position());  }  else  if  (attr.equals( "NORMAL "))  {  vertexAttributes.add(VertexAttribute.Normal());  }  else  if  (attr.equals( "COLOR "))  {  vertexAttributes.add(VertexAttribute.ColorUnpacked());  }  else  if  (attr.equals( "COLORPACKED "))  {  vertexAttributes.add(VertexAttribute.Color());  vertexAttributes.add(VertexAttribute.ColorPacked());  }  else  if  (attr.equals( "TANGENT "))  {  vertexAttributes.add(VertexAttribute.Tangent());  }  else  if  (attr.equals( "BINORMAL "))  {  vertexAttributes.add(VertexAttribute.Binormal());  }  else  if  (attr.startsWith( "TEXCOORD "))  {  vertexAttributes.add(VertexAttribute.TexCoords(unit++));  }  else  if  (attr.startsWith( "BLENDWEIGHT "))  {  vertexAttributes.add(VertexAttribute.BoneWeight(blendWeightCount++));  	vertexAttributes.add(VertexAttribute.ColorPacked());  
elasticsearch_668d55758b751e848f2b82299e2c5e74af55cd12	buggy:  shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType());  context:  .getShards(clusterState,  item.index(),  item.type(),  item.id(),  item.routing(),  null).shardId();  MultiGetShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiGetShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequest.realtime(request.realtime);  shardRequest.refresh(request.refresh);  shardRequests.put(shardId,  shardRequest);  }              shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType());              shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType(),  item.fetchSourceContext());  }  if  (shardRequests.size()  ==  0)  {  listener.onResponse(new  MultiGetResponse(responses.toArray(new  MultiGetItemResponse[responses.length()])));  }  final  AtomicInteger  counter  =  new  AtomicInteger(shardRequests.size());  	shardRequest.add(i,  item.type(),  item.id(),  item.fields(),  item.version(),  item.versionType(),  item.fetchSourceContext());  
libgdx_98b3e5f6ab5185fa2e80c7a93b0f245e500cae60	buggy:  vertices[0].rotate(transform.getRotation()).add(transform.getPosition());  context:  }  }  }  private  void  drawAABB  (Fixture  fixture,  Transform  transform)  {  if  (fixture.getType()  ==  Type.Circle)  {  CircleShape  shape  =  (CircleShape)fixture.getShape();  float  radius  =  shape.getRadius();  vertices[0].set(shape.getPosition());  vertices[0].rotate(transform.getRotation()).add(transform.getPosition());  transform.mul(vertices[0]);  lower.set(vertices[0].x  -  radius,  vertices[0].y  -  radius);  upper.set(vertices[0].x  +  radius,  vertices[0].y  +  radius);  vertices[0].set(lower.x,  lower.y);  vertices[1].set(upper.x,  lower.y);  vertices[2].set(upper.x,  upper.y);  vertices[3].set(lower.x,  upper.y);  	transform.mul(vertices[0]);  
libgdx_458fa9ad4b4fb6c6a06d37f0d2e2f2a598c6d186	buggy:  changed((ChangeEvent)event,  event.getTargetActor());  context:  abstract  public  class  ChangeListener  implements  EventListener  {  public  boolean  handle  (Event  event)  {  if  (!(event  instanceof  ChangeEvent))  return  false;  changed((ChangeEvent)event,  event.getTargetActor());  changed((ChangeEvent)event,  event.getTarget());  return  false;  }  abstract  public  void  changed  (ChangeEvent  event,  Actor  actor);  static  public  class  ChangeEvent  extends  Event  {  	changed((ChangeEvent)event,  event.getTarget());  
elasticsearch_a4acb9a95b006998d11b73e35bca5e55a9f3fc16	buggy:  logger.warn( "Failed  to  clean  thread  locals ",  e);  context:  threadLocalMap  =  threadLocalsField.get(threads[i]);  clearThreadLocalMap(threadLocalMap,  tableField);  threadLocalMap  =  inheritableThreadLocalsField.get(threads[i]);  clearThreadLocalMap(threadLocalMap,  tableField);  }  }  }  catch  (Exception  e)  {              logger.warn( "Failed  to  clean  thread  locals ",  e);              logger.debug( "failed  to  clean  thread  locals ",  e);  }  }  	logger.debug( "failed  to  clean  thread  locals ",  e);  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  searchRequest.source(request.searchSource(),  request.searchSourceOffset(),  request.searchSourceLength());  context:  SearchRequest  searchRequest  =  searchRequest(searchIndices)  .types(searchTypes)  .searchType(request.searchType())  .scroll(request.searchScroll())  .extraSource(searchSource()  .query(boolBuilder)  )  .listenerThreaded(request.listenerThreaded());  if  (request.searchSource()  !=  null)  {                      searchRequest.source(request.searchSource(),  request.searchSourceOffset(),  request.searchSourceLength());                      searchRequest.source(request.searchSource(),  request.searchSourceOffset(),  request.searchSourceLength(),  request.searchSourceUnsafe());  }  searchAction.execute(searchRequest,  new  ActionListener<SearchResponse>()  {  listener.onResponse(response);  }  listener.onFailure(e);  	searchRequest.source(request.searchSource(),  request.searchSourceOffset(),  request.searchSourceLength(),  request.searchSourceUnsafe());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  context[i]  =  new  Tuple<String,  Long>(element.substring(sep  +  1),  Long.parseLong(element.substring(0,  sep)));  context:  int  index  =  0;  String  type  =  elements[index++];  int  contextSize  =  Integer.parseInt(elements[index++]);  for  (int  i  =  0;  i  <  contextSize;  i++)  {  String  element  =  elements[index++];  int  sep  =  element.indexOf(':');  if  (sep  ==  -1)  {  throw  new  ElasticsearchIllegalArgumentException( "Malformed  scrollId  [ "  +  scrollId  +   "] ");  }              context[i]  =  new  Tuple<String,  Long>(element.substring(sep  +  1),  Long.parseLong(element.substring(0,  sep)));              context[i]  =  new  Tuple<>(element.substring(sep  +  1),  Long.parseLong(element.substring(0,  sep)));  }  Map<String,  String>  attributes;  int  attributesSize  =  Integer.parseInt(elements[index++]);  if  (attributesSize  ==  0)  {  attributes  =  ImmutableMap.of();  }  else  {  attributes  =  Maps.newHashMapWithExpectedSize(attributesSize);  for  (int  i  =  0;  i  <  attributesSize;  i++)  {  	context[i]  =  new  Tuple<>(element.substring(sep  +  1),  Long.parseLong(element.substring(0,  sep)));  
elasticsearch_473c2fa8f41daac0f8627eb398819ce506b3a144	buggy:  indexShard.start();  context:  recoveryStatus().index().startTime(System.currentTimeMillis());  try  {  indexShard.store().deleteContent();  }  catch  (IOException  e)  {  }          indexShard.start();          indexShard.start( "post  recovery  from  gateway ");  recoveryStatus.index().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  recoveryStatus.translog().startTime(System.currentTimeMillis());  recoveryStatus.translog().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  }  return  NoneGateway.TYPE;  }  	indexShard.start( "post  recovery  from  gateway ");  
elasticsearch_66d5eb94fbe6a8b39ebe64f18c606bc64f58492e	buggy:  assertThat(custom5.tokenFilters()[0],  instanceOf(MappingCharFilterFactory.class));  context:  analyzer  =  analysisService.analyzer( "custom5 ").analyzer();  assertThat(analyzer,  instanceOf(CustomAnalyzer.class));  CustomAnalyzer  custom5  =  (CustomAnalyzer)  analyzer;          assertThat(custom5.tokenFilters()[0],  instanceOf(MappingCharFilterFactory.class));          assertThat(custom5.charFilters()[0],  instanceOf(MappingCharFilterFactory.class));  analyzer  =  analysisService.analyzer( "alias1 ").analyzer();  assertThat(analyzer,  instanceOf(StandardAnalyzer.class));  analyzer  =  analysisService.analyzer( "custom3 ").analyzer();  assertThat(analyzer,  instanceOf(CustomAnalyzer.class));  	assertThat(custom5.charFilters()[0],  instanceOf(MappingCharFilterFactory.class));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  docIdSets  =  new  IdentityHashMap<AtomicReader,  DocIdSet>();  context:  public  final  Query  getQuery()  {  return  query;  }  public  DocIdSet  getDocIdSet(final  AtomicReaderContext  context,  final  Bits  acceptDocs)  throws  IOException  {  final  SearchContext  searchContext  =  SearchContext.current();  if  (docIdSets  ==  null)  {  assert  searcher  ==  null;  IndexSearcher  searcher  =  searchContext.searcher();              docIdSets  =  new  IdentityHashMap<AtomicReader,  DocIdSet>();              docIdSets  =  new  IdentityHashMap<>();  this.searcher  =  searcher;  searchContext.addReleasable(this);  final  Weight  weight  =  searcher.createNormalizedWeight(query);  for  (final  AtomicReaderContext  leaf  :  searcher.getTopReaderContext().leaves())  {  final  DocIdSet  set  =  DocIdSets.toCacheable(leaf.reader(),  new  DocIdSet()  {  public  DocIdSetIterator  iterator()  throws  IOException  {  	docIdSets  =  new  IdentityHashMap<>();  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  client().prepareUpdate( "test ",   "type ",   "1 ").setScript( "custom ").setScriptLang( "native ").setScriptParams(params).get();  context:  public  void  testThatUpdateUsingNativeScriptWorks()  throws  Exception  {  createIndex( "test ");  ensureYellow();  index( "test ",   "type ",   "1 ",   "text ",   "value ");  Map<String,  Object>  params  =  Maps.newHashMap();  params.put( "foo ",   "SETVALUE ");          client().prepareUpdate( "test ",   "type ",   "1 ").setScript( "custom ").setScriptLang( "native ").setScriptParams(params).get();          client().prepareUpdate( "test ",   "type ",   "1 ").setInlineScript( "custom ").setScriptLang( "native ").setScriptParams(params).get();  Map<String,  Object>  data  =  client().prepareGet( "test ",   "type ",   "1 ").get().getSource();  assertThat(data,  hasKey( "foo "));  assertThat(data.get( "foo ").toString(),  is( "SETVALUE "));  }  static  class  CustomNativeScriptFactory  implements  NativeScriptFactory  {  	client().prepareUpdate( "test ",   "type ",   "1 ").setInlineScript( "custom ").setScriptLang( "native ").setScriptParams(params).get();  
elasticsearch_5fa66cd59299e81ffebf9220e1761b58ee1a3348	buggy:  if  (notification.getKey()  !=  null)  {  context:  public  void  close()  {  cache.invalidateAll();  }  public  IndexFieldDataCache  buildIndexFieldDataCache(@Nullable  IndexService  indexService,  Index  index,  FieldMapper.Names  fieldNames,  FieldDataType  fieldDataType)  {  return  new  IndexFieldCache(indexService,  index,  fieldNames,  fieldDataType);  }  public  void  onRemoval(RemovalNotification<Key,  AtomicFieldData>  notification)  {          if  (notification.getKey()  !=  null)  {          if  (notification.getKey()  !=  null  &&  notification.getKey().listener  !=  null)  {  IndexFieldCache  indexCache  =  notification.getKey().indexCache;  notification.getKey().listener.onUnload(indexCache.fieldNames,  indexCache.fieldDataType,  notification.wasEvicted(),  notification.getKey().sizeInBytes,  notification.getValue());  }  }  public  static  class  FieldDataWeigher  implements  Weigher<Key,  AtomicFieldData>  {  	if  (notification.getKey()  !=  null  &&  notification.getKey().listener  !=  null)  {  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  return  new  JoglFileHandle(file);  context:  File  file  =  null;  if  (type  ==  FileType.Absolute  ||  type  ==  FileType.Internal)  file  =  new  File(filename);  else  file  =  new  File(this.externalPath  +  filename);  if  (file.exists()  ==  false)  throw  new  GdxRuntimeException( "File  ' "  +  filename  +   "'  doesn't  exist ");  else  return  new  JoglFileHandle(file);  return  new  JoglFileHandle(file,  type);  }  File  file  =  null;  if  (type  ==  FileType.Absolute  ||  type  ==  FileType.Internal)  	return  new  JoglFileHandle(file,  type);  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  System.out.println(data  +   "\t "  +  loadingTimeMs  +   "\t "  +  afd.getClass().getSimpleName()  +   "\t "  +  RamUsageEstimator.humanSizeOf(afd.getLongValues())  +   "\t "  +  RamUsageEstimator.humanReadableUnits(afd.getMemorySizeInBytes()));  context:  indexWriter.forceMerge(1,  true);  indexWriter.close();  final  DirectoryReader  dr  =  DirectoryReader.open(dir);  final  IndexFieldDataService  fds  =  new  IndexFieldDataService(new  Index( "dummy "),  new  DummyCircuitBreakerService());  final  LongFieldMapper  mapper  =  new  LongFieldMapper.Builder(fieldName).build(new  BuilderContext(null,  new  ContentPath(1)));  final  IndexNumericFieldData<AtomicNumericFieldData>  fd  =  fds.getForField(mapper);  final  long  start  =  System.nanoTime();  final  AtomicNumericFieldData  afd  =  fd.loadDirect(SlowCompositeReaderWrapper.wrap(dr).getContext());  final  long  loadingTimeMs  =  (System.nanoTime()  -  start)  /  1000  /  1000;              System.out.println(data  +   "\t "  +  loadingTimeMs  +   "\t "  +  afd.getClass().getSimpleName()  +   "\t "  +  RamUsageEstimator.humanSizeOf(afd.getLongValues())  +   "\t "  +  RamUsageEstimator.humanReadableUnits(afd.getMemorySizeInBytes()));              System.out.println(data  +   "\t "  +  loadingTimeMs  +   "\t "  +  afd.getClass().getSimpleName()  +   "\t "  +  RamUsageEstimator.humanReadableUnits(afd.ramBytesUsed()));  dr.close();  }  }  }  	System.out.println(data  +   "\t "  +  loadingTimeMs  +   "\t "  +  afd.getClass().getSimpleName()  +   "\t "  +  RamUsageEstimator.humanReadableUnits(afd.ramBytesUsed()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.startObject();  builder.field( "ok ",  true);  builder.field( "status ",  status.getStatus());  if  (settings.get( "name ")  !=  null)  {  builder.field( "name ",  settings.get( "name "));  }  builder.startObject( "version ").field( "number ",  Version.CURRENT.number()).field( "snapshot_build ",  Version.CURRENT.snapshot).endObject();  builder.field( "tagline ",   "You  Know,  for  Search ");  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  if  (request.method()  ==  HEAD)  {  	}  catch  (Throwable  e)  {  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.field(FilterFacetCollectorParser.NAME);  context:  public  FilterFacetBuilder  filter(XContentFilterBuilder  filter)  {  this.filter  =  filter;  return  this;  }  if  (filter  ==  null)  {  throw  new  SearchSourceBuilderException( "filter  must  be  set  on  filter  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.field(FilterFacetCollectorParser.NAME);          builder.field(FilterFacet.TYPE);  filter.toXContent(builder,  params);  addFilterFacetAndGlobal(builder,  params);  builder.endObject();  }  }  	builder.field(FilterFacet.TYPE);  
libgdx_8480b29e196d01a0b772edceea1dc31ab14e4988	buggy:  if  (knownType  ==  null)  knownType  =  ReflectionCache.getType(OrderedMap.class);  context:  writeObjectStart(actualType.getClassOfType(),  knownType.getClassOfType());  for  (Entry  entry  :  ((ObjectMap<?,  ?>)value).entries())  {  writer.name(convertToString(entry.key));  writeValue(entry.value,  elementType,  null);  }  writeObjectEnd();  return;  }  if  (value  instanceof  Map)  {  if  (knownType  ==  null)  knownType  =  ReflectionCache.getType(OrderedMap.class);  if  (knownType  ==  null)  knownType  =  ReflectionCache.getType(HashMap.class);  writeObjectStart(actualType.getClassOfType(),  knownType.getClassOfType());  for  (Map.Entry  entry  :  ((Map<?,  ?>)value).entrySet())  {  writer.name(convertToString(entry.getKey()));  writeValue(entry.getValue(),  elementType,  null);  }  writeObjectEnd();  return;  }  	if  (knownType  ==  null)  knownType  =  ReflectionCache.getType(HashMap.class);  
elasticsearch_ab3be76644157eed6724dfe1f1937ee5f7e93a11	buggy:  logger.debug( "{}:  failed  to  execute  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  context:  if  (!TransportActions.isShardNotAvailableException(t))  {  }  }  }  performOperation(shardIt,  nextShard,  shardIndex);  }  else  {  if  (logger.isDebugEnabled())  {  if  (t  !=  null)  {  if  (!TransportActions.isShardNotAvailableException(t))  {                              logger.debug( "{}:  failed  to  execute  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);                              logger.debug( "{}:  failed  to  executed  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  }  }  }  if  (expectedOps  ==  counterOps.incrementAndGet())  {  finishHim();  }  }  }  	logger.debug( "{}:  failed  to  executed  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  SearchResponse  sr  =  client().prepareSearch( "test ").setQuery(QueryBuilders.matchAllQuery()).addScriptField( "tvtest ",  script)  .execute().actionGet();  ElasticsearchAssertions.assertHitCount(sr,  numExpectedDocs);  for  (SearchHit  hit  :  sr.getHits().getHits())  {  Object  result  =  hit.getFields().get( "tvtest ").getValues().get(0);  if  (result  instanceof  Integer)  {  assertThat(((Integer)  result).intValue(),  equalTo(value));  }  else  if  (result  instanceof  Long)  {  assertThat(((Long)  result).intValue(),  equalTo(value));  }  else  {                  assert  false;                  fail();  }  }  }  }  	fail();  
libgdx_e218b01bb2d42b16d9afbd0603f0eaca1da7a278	buggy:  return  new  IOSApplication(new  MyGdxGame(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  MyGdxGame(),  config);  return  new  IOSApplication(new  MultitouchTest(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  MultitouchTest(),  config);  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  null,  indexShard.acquireSearcher(),  indexService,  indexShard,  context:  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  boolean  valid;  String  explanation  =  null;  String  error  =  null;  if  (request.querySource().length()  ==  0)  {  valid  =  true;  }  else  {  SearchContext.setCurrent(new  DefaultSearchContext(0,  new  ShardSearchRequest().types(request.types()).nowInMillis(request.nowInMillis()),                      null,  indexShard.acquireSearcher(),  indexService,  indexShard,                      null,  indexShard.acquireSearcher( "validate_query "),  indexService,  indexShard,  scriptService,  cacheRecycler));  try  {  ParsedQuery  parsedQuery  =  queryParserService.parse(request.querySource());  valid  =  true;  if  (request.explain())  {  explanation  =  parsedQuery.query().toString();  }  }  catch  (QueryParsingException  e)  {  	null,  indexShard.acquireSearcher( "validate_query "),  indexService,  indexShard,  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Wrapped<T>(callable,  priority);  context:  public  abstract  class  PrioritizedCallable<T>  implements  Callable<T>,  Comparable<PrioritizedCallable>  {  private  final  Priority  priority;  public  static  <T>  PrioritizedCallable<T>  wrap(Callable<T>  callable,  Priority  priority)  {          return  new  Wrapped<T>(callable,  priority);          return  new  Wrapped<>(callable,  priority);  }  protected  PrioritizedCallable(Priority  priority)  {  this.priority  =  priority;  }  public  int  compareTo(PrioritizedCallable  pc)  {  	return  new  Wrapped<>(callable,  priority);  
elasticsearch_73a447da861d2413269064899443b297b9ca3f88	buggy:  facetsAsMap.put(facet.name(),  facet);  context:  public  Map<String,  Facet>  facetsAsMap()  {  if  (facetsAsMap  !=  null)  {  return  facetsAsMap;  }  Map<String,  Facet>  facetsAsMap  =  newHashMap();  for  (Facet  facet  :  facets)  {              facetsAsMap.put(facet.name(),  facet);              facetsAsMap.put(facet.getName(),  facet);  }  this.facetsAsMap  =  facetsAsMap;  return  facetsAsMap;  }  	facetsAsMap.put(facet.getName(),  facet);  
libgdx_b98aa44ba8f4a5ae555add2a5fed5e625af61851	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.AnimationTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.AnimationTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_15453272f7e34d22bb9d21647fad21526af9f7de	buggy:  GetResponse  response  =  client.get(new  GetRequest(index,  type,  id).preference( "_local ")).actionGet();  context:  public  Shape  fetch(String  id,  String  type,  String  index,  String  shapeField)  throws  IOException  {          GetResponse  response  =  client.get(new  GetRequest(index,  type,  id).preference( "_local ")).actionGet();          GetResponse  response  =  client.get(new  GetRequest(index,  type,  id).preference( "_local ").operationThreaded(false)).actionGet();  if  (!response.exists())  {  throw  new  ElasticSearchIllegalArgumentException( "Shape  with  ID  [ "  +  id  +   "]  in  type  [ "  +  type  +   "]  not  found ");  }  XContentParser  parser  =  null;  try  {  parser  =  XContentHelper.createParser(response.sourceRef());  XContentParser.Token  currentToken;  	GetResponse  response  =  client.get(new  GetRequest(index,  type,  id).preference( "_local ").operationThreaded(false)).actionGet();  
elasticsearch_5d781961a07368ae458126e4fad0a8db566637da	buggy:  final  boolean  includeSettings  =  HttpActions.paramAsBoolean( "settings ",  false);  context:  super(settings,  client);  httpServer.registerHandler(HttpRequest.Method.GET,   "/_cluster/nodes ",  this);  httpServer.registerHandler(HttpRequest.Method.GET,   "/_cluster/nodes/${nodeId} ",  this);  }  String[]  nodesIds  =  HttpActions.splitNodes(request.param( "nodeId "));          final  boolean  includeSettings  =  HttpActions.paramAsBoolean( "settings ",  false);          final  boolean  includeSettings  =  request.paramAsBoolean( "settings ",  false);  NodesInfoRequest  nodesInfoRequest  =  new  NodesInfoRequest(nodesIds);  nodesInfoRequest.listenerThreaded(false);  client.admin().cluster().execNodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  try  {  JsonBuilder  builder  =  HttpJsonBuilder.cached(request);  builder.startObject();  builder.field( "clusterName ",  result.clusterName().value());  	final  boolean  includeSettings  =  request.paramAsBoolean( "settings ",  false);  
elasticsearch_66c9f2f8344bdf9e58e0bc8a9fb59a527ec547cf	buggy:  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));  context:  }  SearchSourceBuilder  sourceBuilder  =  searchSource()  .query(termQuery( "multi ",   "test "))  .from(0).size(20).explain(true).sort( "age ",  false)                  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));                  .facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test ")).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  Map<SearchShardTarget,  QuerySearchResultProvider>  queryResults  =  newHashMap();  for  (ShardsIterator  shardsIt  :  indicesService.searchShards(clusterService.state(),  new  String[]{ "test "},  null))  {  for  (ShardRouting  shardRouting  :  shardsIt)  {  InternalSearchRequest  searchRequest  =  searchRequest(shardRouting,  sourceBuilder)  .scroll(new  Scroll(new  TimeValue(10,  TimeUnit.MINUTES)));  QuerySearchResult  queryResult  =  nodeToSearchService.get(shardRouting.currentNodeId()).executeQueryPhase(searchRequest);  queryResults.put(queryResult.shardTarget(),  queryResult);  	.facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test ")).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  ShortValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  short  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Short.MIN_VALUE  :  Short.MAX_VALUE;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Short.MAX_VALUE  :  Short.MIN_VALUE;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).shortValue()  :  Short.parseShort(missingValue.toString());  }          return  new  ShortValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  ShortValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  ShortValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
elasticsearch_6c29142b91fe6582154e273a1e73632b2883551e	buggy:  throw  new  IOException( "Malformed  commit,  missing  size  for  [ "  +  fileName  +   "] ");  context:  physicalName  =  parser.text();  }  else  if  ( "length ".equals(currentFieldName))  {  size  =  parser.longValue();  }  }  }  if  (physicalName  ==  null)  {  throw  new  IOException( "Malformed  commit,  missing  physical_name  for  [ "  +  fileName  +   "] ");  }  if  (size  ==  -1)  {                                  throw  new  IOException( "Malformed  commit,  missing  size  for  [ "  +  fileName  +   "] ");                                  throw  new  IOException( "Malformed  commit,  missing  length  for  [ "  +  fileName  +   "] ");  }  files.add(new  CommitPoint.FileInfo(fileName,  physicalName,  size));  }  }  }  else  if  (token.isValue())  {  if  ( "version ".equals(currentFieldName))  {  version  =  parser.longValue();  }  else  if  ( "name ".equals(currentFieldName))  {  	throw  new  IOException( "Malformed  commit,  missing  length  for  [ "  +  fileName  +   "] ");  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execOptimize(optimizeRequest,  new  ActionListener<OptimizeResponse>()  {  context:  optimizeRequest.operationThreading(operationThreading);  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }          client.admin().indices().execOptimize(optimizeRequest,  new  ActionListener<OptimizeResponse>()  {          client.admin().indices().optimize(optimizeRequest,  new  ActionListener<OptimizeResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  	client.admin().indices().optimize(optimizeRequest,  new  ActionListener<OptimizeResponse>()  {  
elasticsearch_a414e4f2f3ce03c1cd80ca3ef7d01c370e49d5a7	buggy:  for  (RepositoriesService  repositoriesService  :  cluster().getInstances(RepositoriesService.class))  {  context:  RestoreSnapshotResponse  restoreSnapshotResponse  =  client.admin().cluster().prepareRestoreSnapshot( "test-repo ",   "test-snap ").setWaitForCompletion(true).execute().actionGet();  assertThat(restoreSnapshotResponse.getRestoreInfo().totalShards(),  greaterThan(0));  ensureGreen();  assertThat(client.prepareCount( "test-idx ").get().getCount(),  equalTo(100L));  long  snapshotPause  =  0L;  long  restorePause  =  0L;          for  (RepositoriesService  repositoriesService  :  cluster().getInstances(RepositoriesService.class))  {          for  (RepositoriesService  repositoriesService  :  cluster().getDataNodeInstances(RepositoriesService.class))  {  snapshotPause  +=  repositoriesService.repository( "test-repo ").snapshotThrottleTimeInNanos();  restorePause  +=  repositoriesService.repository( "test-repo ").restoreThrottleTimeInNanos();  }  if  (throttleSnapshot)  {  assertThat(snapshotPause,  greaterThan(0L));  }  else  {  assertThat(snapshotPause,  equalTo(0L));  	for  (RepositoriesService  repositoriesService  :  cluster().getDataNodeInstances(RepositoriesService.class))  {  
elasticsearch_bae3203e3beee284ca79ef9e004dd7abb1cb5b94	buggy:  assertThat(nodesMap.size(),  equalTo(cluster().size()));  context:  type  =  null;  }  final  CountDownLatch  latch  =  new  CountDownLatch(1);  nodesHotThreadsRequestBuilder.execute(new  ActionListener<NodesHotThreadsResponse>()  {  public  void  onResponse(NodesHotThreadsResponse  nodeHotThreads)  {  boolean  success  =  false;  try  {  assertThat(nodeHotThreads,  notNullValue());  Map<String,NodeHotThreads>  nodesMap  =  nodeHotThreads.getNodesMap();                          assertThat(nodesMap.size(),  equalTo(cluster().size()));                          assertThat(nodesMap.size(),  equalTo(immutableCluster().size()));  for  (NodeHotThreads  ht  :  nodeHotThreads)  {  assertNotNull(ht.getHotThreads());  }  success  =  true;  }  finally  {  if  (!success)  {  hasErrors.set(true);  	assertThat(nodesMap.size(),  equalTo(immutableCluster().size()));  
elasticsearch_ebcc1e0bf5b0afcf76d7889bea94e9c8ff165535	buggy:  }  else  if  ( "id ".equals(currentFieldName))  {  context:  fields.add(parser.text());  }  fieldsNames  =  fields.toArray(new  String[fields.size()]);  }  }  else  if  (token.isValue())  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INLINE;                  }  else  if  ( "id ".equals(currentFieldName))  {                  }  else  if  ( "script_id ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INDEXED;  }  else  if  ( "file ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.FILE;  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  	}  else  if  ( "script_id ".equals(currentFieldName))  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(IndicesSegmentResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_c3332db7d016b348fbb6c364427aae56123e6fc0	buggy:  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");  context:  String  fieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  fieldName  =  currentFieldName;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  Object  value  =  parser.objectBytes();  if  (value  ==  null)  {                          throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  term  filter ");                          throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  terms  filter ");  }  terms.add(value);  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  fieldName  =  currentFieldName;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  	throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  terms  filter ");  
libgdx_b778dc7a89b5b1961ce4688bb68d5d135a2761a3	buggy:  app.getGraphics().getGL20().glClearColor(  0f,  0f,  0f,  1  );  context:  public  void  dispose(Application  app)  {  }  public  void  render(Application  app)  {  frameBuffer.begin();  app.getGraphics().getGL20().glViewport(  0,  0,  app.getGraphics().getWidth(),  app.getGraphics().getHeight()  );  app.getGraphics().getGL20().glClearColor(  0f,  0f,  0f,  1  );  app.getGraphics().getGL20().glClearColor(  0f,  1f,  0f,  1  );  app.getGraphics().getGL20().glClear(  GL20.GL_COLOR_BUFFER_BIT  );  meshShader.begin();  mesh.render(meshShader,  GL20.GL_TRIANGLES);  meshShader.end();  frameBuffer.end();  app.getGraphics().getGL20().glClearColor(  0.2f,  0.2f,  0.2f,  1  );  app.getGraphics().getGL20().glClear(  GL20.GL_COLOR_BUFFER_BIT  );  	app.getGraphics().getGL20().glClearColor(  0f,  1f,  0f,  1  );  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  final  ClusterStateRequest  clusterStateRequest  =  Requests.clusterState();  context:  SettingsFilter  settingsFilter)  {  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/state ",  this);  this.settingsFilter  =  settingsFilter;  }          final  ClusterStateRequest  clusterStateRequest  =  Requests.clusterState();          final  ClusterStateRequest  clusterStateRequest  =  Requests.clusterStateRequest();  clusterStateRequest.filterNodes(request.paramAsBoolean( "filter_nodes ",  clusterStateRequest.filterNodes()));  clusterStateRequest.filterRoutingTable(request.paramAsBoolean( "filter_routing_table ",  clusterStateRequest.filterRoutingTable()));  clusterStateRequest.filterMetaData(request.paramAsBoolean( "filter_metadata ",  clusterStateRequest.filterMetaData()));  clusterStateRequest.filterBlocks(request.paramAsBoolean( "filter_blocks ",  clusterStateRequest.filterBlocks()));  clusterStateRequest.filteredIndices(RestActions.splitIndices(request.param( "filter_indices ",  null)));  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  try  {  	final  ClusterStateRequest  clusterStateRequest  =  Requests.clusterStateRequest();  
libgdx_91ad79fb49bc9a2b5b247105acaafdf27482d1a0	buggy:  layout();  context:  textBounds.set(titleFont.getBounds(title));  textBounds.height  -=  titleFont.getDescent();  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  final  NinePatch  backgroundPatch  =  style.background;  final  BitmapFont  titleFont  =  style.titleFont;  final  Color  titleFontColor  =  style.titleFontColor;  layout();  validate();  applyTransform(batch);  calculateBoundsAndScissors(batch.getTransformMatrix());  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  backgroundPatch.draw(batch,  0,  0,  width,  height);  float  textY  =  height  -  (int)(backgroundPatch.getTopHeight()  /  2)  +  (int)(textBounds.height  /  2);  titleFont.setColor(titleFontColor.r,  titleFontColor.g,  titleFontColor.b,  titleFontColor.a  *  parentAlpha);  titleFont.drawMultiLine(batch,  title,  (int)(width  /  2),  textY,  0,  HAlignment.CENTER);  	validate();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  constructionContext  =  new  ConstructionContext<T>();  context:  public  final  class  InternalContext  {  private  Map<Object,  ConstructionContext<?>>  constructionContexts  =  Maps.newHashMap();  private  Dependency  dependency;  public  <T>  ConstructionContext<T>  getConstructionContext(Object  key)  {  ConstructionContext<T>  constructionContext  =  (ConstructionContext<T>)  constructionContexts.get(key);  if  (constructionContext  ==  null)  {              constructionContext  =  new  ConstructionContext<T>();              constructionContext  =  new  ConstructionContext<>();  constructionContexts.put(key,  constructionContext);  }  return  constructionContext;  }  public  Dependency  getDependency()  {  return  dependency;  }  	constructionContext  =  new  ConstructionContext<>();  
libgdx_64ca274676f5015154232c7437475ad088a935a2	buggy:  model  =  new  Model(loader.parseModel(Gdx.files.internal( "data/g3d/cubes.g3dj "),  null));  context:  new  Light(Color.BLUE,  Vector3.tmp.set(10f,  5f,  0f),  10f),  new  Light(Color.GREEN,  Vector3.tmp.set(0f,  10f,  5f),  5f)  };  float  touchStartX  =  0;  float  touchStartY  =  0;  public  void  create  ()  {  JsonModelLoader  loader  =  new  JsonModelLoader();  model  =  new  Model(loader.parseModel(Gdx.files.internal( "data/g3d/cubes.g3dj "),  null));  model  =  new  Model(loader.parseModel(Gdx.files.internal( "data/g3d/cubes.g3dj ")));  instance  =  new  ModelInstance(model);  modelBatch  =  new  ModelBatch();  TestShader.ignoreUnimplemented  =  true;  shapeRenderer  =  new  ShapeRenderer();  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(10f,  10f,  10f);  cam.direction.set(-1,  -1,  -1);  	model  =  new  Model(loader.parseModel(Gdx.files.internal( "data/g3d/cubes.g3dj ")));  
elasticsearch_8713a090c2096bea7927590ab02302740021a0f3	buggy:  onGoingRecovery.recoveryState.getIndex().addRecoveredByteCount(request.length());  context:  synchronized  (indexOutput)  {  try  {  if  (recoverySettings.rateLimiter()  !=  null)  {  recoverySettings.rateLimiter().pause(request.content().length());  }  BytesReference  content  =  request.content();  if  (!content.hasArray())  {  content  =  content.toBytesArray();  }  indexOutput.writeBytes(content.array(),  content.arrayOffset(),  content.length());                          onGoingRecovery.recoveryState.getIndex().addRecoveredByteCount(request.length());                          onGoingRecovery.recoveryState.getIndex().addRecoveredByteCount(content.length());  RecoveryState.File  file  =  onGoingRecovery.recoveryState.getIndex().file(request.name());  if  (file  !=  null)  {  file.updateRecovered(request.length());  }  if  (indexOutput.getFilePointer()  ==  request.length())  {  indexOutput.close();  	onGoingRecovery.recoveryState.getIndex().addRecoveredByteCount(content.length());  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:   "        {\n "  +   "          \ "object\ ":  {  \ "value\ ":  \ "value\ "  }\n "  +   "        },\n "  +   "        {\n "  +   "          \ "object\ ":\ "value\ "\n "  +   "        }\n "  +   "        ]\n "  +   "      },\n "  +   "      \ "value\ ":\ "value\ "\n "  +   "    } "));              assert  false;              fail();  }  catch  (MapperParsingException  e)  {  }  }  }  	fail();  
elasticsearch_873b491f4e980d50584fbd004f413c4c3fa95ec0	buggy:  client().admin().indices().prepareFlush( "test ").execute().get();  context:  client().admin().indices().prepareCreate( "test ")  .setSettings(settings)  .addMapping( "type ",  mapping).execute().actionGet();  numInitialDocs  =  between(10,  100);  ensureYellow();  for  (int  i  =  0;  i  <  numInitialDocs  ;  i++)  {  client().prepareIndex( "test ",   "initial ",   " "  +  i).setTimeout(TimeValue.timeValueSeconds(1)).setSource( "test ",   "init ").get();  }  client().admin().indices().prepareRefresh( "test ").execute().get();              client().admin().indices().prepareFlush( "test ").execute().get();              client().admin().indices().prepareFlush( "test ").setWaitIfOngoing(true).execute().get();  client().admin().indices().prepareClose( "test ").execute().get();  client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder()  .put(MockFSDirectoryService.CHECK_INDEX_ON_CLOSE,  true)  .put(MockDirectoryHelper.RANDOM_IO_EXCEPTION_RATE,  exceptionRate)  .put(MockDirectoryHelper.RANDOM_IO_EXCEPTION_RATE_ON_OPEN,  exceptionOnOpenRate));  client().admin().indices().prepareOpen( "test ").execute().get();  }  else  {  Builder  settings  =  settingsBuilder()  	client().admin().indices().prepareFlush( "test ").setWaitIfOngoing(true).execute().get();  
libgdx_18459375e19091771139f1fbf6644f30ab77b30f	buggy:  circle(x,  y,  radius,  (int)(4  *  (float)Math.sqrt(radius)));  context:  renderer.vertex(x  +  width,  y  +  height,  z  +  depth);  renderer.color(color.r,  color.g,  color.b,  color.a);  renderer.vertex(x,  y,  z  +  depth);  renderer.color(color.r,  color.g,  color.b,  color.a);  renderer.vertex(x,  y  +  height,  z  +  depth);  }  public  void  circle  (float  x,  float  y,  float  radius)  {  circle(x,  y,  radius,  (int)(4  *  (float)Math.sqrt(radius)));  circle(x,  y,  radius,  (int)(6  *  (float)Math.cbrt(radius)));  }  public  void  circle  (float  x,  float  y,  float  radius,  int  segments)  {  if  (segments  <=  0)  throw  new  IllegalArgumentException( "segments  must  be  >=  0. ");  if  (currType  !=  ShapeType.Circle)  throw  new  GdxRuntimeException( "Must  call  begin(ShapeType.Circle) ");  checkDirty();  checkFlush(segments  *  2  +  2);  	circle(x,  y,  radius,  (int)(6  *  (float)Math.cbrt(radius)));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  class  StartRecoveryTransportRequestHandler  extends  BaseTransportRequestHandler<StartRecoveryRequest>  {  public  StartRecoveryRequest  newInstance()  {  return  new  StartRecoveryRequest();  }  public  String  executor()  {              return  ThreadPool.Names.CACHED;              return  ThreadPool.Names.GENERIC;  }  public  void  messageReceived(final  StartRecoveryRequest  request,  final  TransportChannel  channel)  throws  Exception  {  RecoveryResponse  response  =  recover(request);  channel.sendResponse(response);  }  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.timeValueField(Fields.TIME,  Fields.TIME_IN_MILLIS,  percolateTimeInMillis);  context:  }  public  long  getCurrent()  {  return  current;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(Fields.PERCOLATE);  builder.field(Fields.TOTAL,  percolateCount);          builder.timeValueField(Fields.TIME,  Fields.TIME_IN_MILLIS,  percolateTimeInMillis);          builder.timeValueField(Fields.TIME_IN_MILLIS,  Fields.TIME,  percolateTimeInMillis);  builder.field(Fields.CURRENT,  current);  builder.endObject();  return  builder;  }  public  void  add(PercolateStats  percolate)  {  if  (percolate  ==  null)  {  return;  	builder.timeValueField(Fields.TIME_IN_MILLIS,  Fields.TIME,  percolateTimeInMillis);  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  new  Nested(parentFilter,  childFilter));  context:  }  protected  IndexableField  createField(String  name,  int  value,  Field.Store  store)  {  return  new  DoubleField(name,  value,  store);  }  protected  void  assertAvgScoreMode(Filter  parentFilter,  IndexSearcher  searcher)  throws  IOException  {  MultiValueMode  sortMode  =  MultiValueMode.AVG;  Filter  childFilter  =  new  NotFilter(parentFilter);          XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  new  Nested(parentFilter,  childFilter));          XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  createNested(parentFilter,  childFilter));  Query  query  =  new  ToParentBlockJoinQuery(new  XFilteredQuery(new  MatchAllDocsQuery(),  childFilter),  new  FixedBitSetCachingWrapperFilter(parentFilter),  ScoreMode.None);  Sort  sort  =  new  Sort(new  SortField( "field2 ",  nestedComparatorSource));  TopDocs  topDocs  =  searcher.search(query,  5,  sort);  assertThat(topDocs.totalHits,  equalTo(7));  assertThat(topDocs.scoreDocs.length,  equalTo(5));  assertThat(topDocs.scoreDocs[0].doc,  equalTo(11));  assertThat(((Number)  ((FieldDoc)  topDocs.scoreDocs[0]).fields[0]).intValue(),  equalTo(2));  assertThat(topDocs.scoreDocs[1].doc,  equalTo(7));  	XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  createNested(parentFilter,  childFilter));  
elasticsearch_43b21719f53bb5849eb3487471e638e0e26685d2	buggy:  int  size  =  randomIntBetween(0,  10);  context:  assertThat((Long)  hits.getAt(0).sortValues()[0],  equalTo(higestSortValue));  assertThat((Long)  hits.getAt(1).sortValues()[0],  equalTo(higestSortValue  -  1));  assertThat((Long)  hits.getAt(2).sortValues()[0],  equalTo(higestSortValue  -  2));  assertThat(hits.getAt(0).sourceAsMap().size(),  equalTo(4));  }  }  public  void  testPagination()  throws  Exception  {          int  size  =  randomIntBetween(0,  10);          int  size  =  randomIntBetween(1,  10);  int  from  =  randomIntBetween(0,  10);  SearchResponse  response  =  client().prepareSearch( "idx ").setTypes( "type ")  .addAggregation(terms( "terms ")  .executionHint(randomExecutionHint())  .field(TERMS_AGGS_FIELD)  .subAggregation(  topHits( "hits ").addSort(SortBuilders.fieldSort(SORT_FIELD).order(SortOrder.DESC))  .setFrom(from)  	int  size  =  randomIntBetween(1,  10);  
elasticsearch_7e0182d8829a7929e26cdabc80d50e9dee10939c	buggy:  throw  new  ElasticSearchParseException( "Failed  to  derive  xcontent  from   "  +  Arrays.toString(data));  context:  public  static  XContent  xContent(byte[]  data)  {  return  xContent(data,  0,  data.length);  }  public  static  XContent  xContent(byte[]  data,  int  offset,  int  length)  {  XContentType  type  =  xContentType(data,  offset,  length);  if  (type  ==  null)  {              throw  new  ElasticSearchParseException( "Failed  to  derive  xcontent  from   "  +  Arrays.toString(data));              throw  new  ElasticSearchParseException( "Failed  to  derive  xcontent  from  (offset= "  +  offset  +   ",  length= "  +  length  +   "):   "  +  Arrays.toString(data));  }  return  xContent(type);  }  public  static  XContentType  xContentType(byte[]  data)  {  	throw  new  ElasticSearchParseException( "Failed  to  derive  xcontent  from  (offset= "  +  offset  +   ",  length= "  +  length  +   "):   "  +  Arrays.toString(data));  
elasticsearch_f1467dbde256a968bfffed6ce470f162ac307655	buggy:  return  FloatArrayAtomicFieldData.EMPTY;  context:  throw  new  ElasticSearchException(e.getMessage(),  e);  }  }  }  public  FloatArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  FloatArrayAtomicFieldData.EMPTY;              return  FloatArrayAtomicFieldData.empty(reader.maxDoc());  }  final  BigFloatArrayList  values  =  new  BigFloatArrayList();  values.add(0);  //  first   "t "  indicates  null  value  final  float  acceptableTransientOverheadRatio  =  fieldDataType.getSettings().getAsFloat( "acceptable_transient_overhead_ratio ",  OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO);  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(reader.maxDoc(),  acceptableTransientOverheadRatio);  	return  FloatArrayAtomicFieldData.empty(reader.maxDoc());  
elasticsearch_bd52d61d5db256dfd4632772544a5dbb9e0ccaa8	buggy:  clusterService.submitStateUpdateTask( "reroute  post  shard-started  ( "  +  shardRouting  +   "),  reason  [ "  +  reason  +   "] ",  new  ClusterStateUpdateTask()  {  context:  RoutingAllocation.Result  routingResult  =  allocationService.applyStartedShards(currentState,  shards,  false);  if  (!routingResult.changed())  {  return  currentState;  }  return  newClusterStateBuilder().state(currentState).routingResult(routingResult).build();  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  rerouteRequired.set(true);                  clusterService.submitStateUpdateTask( "reroute  post  shard-started  ( "  +  shardRouting  +   "),  reason  [ "  +  reason  +   "] ",  new  ClusterStateUpdateTask()  {                  clusterService.submitStateUpdateTask( "reroute  post  shard-started  ( "  +  shardRouting  +   "),  reason  [ "  +  reason  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  if  (rerouteRequired.compareAndSet(true,  false))  {  RoutingAllocation.Result  routingResult  =  allocationService.reroute(currentState);  if  (!routingResult.changed())  {  return  currentState;  }  return  newClusterStateBuilder().state(currentState).routingResult(routingResult).build();  	clusterService.submitStateUpdateTask( "reroute  post  shard-started  ( "  +  shardRouting  +   "),  reason  [ "  +  reason  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  throws  ElasticSearchException  {  context:  mergePolicy.setMergeFactor(mergeFactor);  mergePolicy.setMaxMergeDocs(maxMergeDocs);  mergePolicy.setCalibrateSizeByDeletes(calibrateSizeByDeletes);  mergePolicy.setUseCompoundFile(compoundFormat);  policies.add(mergePolicy);  return  mergePolicy;  }      public  void  close(boolean  delete)  throws  ElasticSearchException  {      public  void  close()  throws  ElasticSearchException  {  indexSettingsService.removeListener(applySettings);  }  public  static  final  String  INDEX_MERGE_POLICY_MIN_MERGE_SIZE  =   "index.merge.policy.min_merge_size ";  public  static  final  String  INDEX_MERGE_POLICY_MAX_MERGE_SIZE  =   "index.merge.policy.max_merge_size ";  public  static  final  String  INDEX_MERGE_POLICY_MAX_MERGE_DOCS  =   "index.merge.policy.max_merge_docs ";  public  static  final  String  INDEX_MERGE_POLICY_MERGE_FACTOR  =   "index.merge.policy.merge_factor ";  public  static  final  String  INDEX_COMPOUND_FORMAT  =   "index.compound_format ";  	public  void  close()  throws  ElasticSearchException  {  
elasticsearch_4e6217c54de37f99188666ff7f43959fa1529630	buggy:  return   "FilterCacheFilterWrapper( "  +  filter  +   ") ";  context:  FilterCacheValue<DocSet>  previous  =  innerCache.putIfAbsent(cacheKey,  cacheValue);  if  (previous  ==  null)  {  cache.totalMetric.inc(cacheValue.value().sizeInBytes());  }  }  return  cacheValue.value()  ==  DocSet.EMPTY_DOC_SET  ?  null  :  cacheValue.value();  }  public  String  toString()  {              return   "FilterCacheFilterWrapper( "  +  filter  +   ") ";              return   "cache( "  +  filter  +   ") ";  }  public  boolean  equals(Object  o)  {  if  (!(o  instanceof  FilterCacheFilterWrapper))  return  false;  return  this.filter.equals(((FilterCacheFilterWrapper)  o).filter);  }  public  int  hashCode()  {  	return   "cache( "  +  filter  +   ") ";  
libgdx_f20e74c1cd1586ff25bdf0026f0cce6acd7f3357	buggy:  lights.add(new  DirectionalLight().set(0.8f,  0.8f,  0.8f,  -1f,  -1f,  0f));  context:  public  ModelBatch  modelBatch;  public  Model  model;  public  ModelInstance  instance;  public  Lights  lights;  public  void  create  ()  {  modelBatch  =  new  ModelBatch();  lights  =  new  Lights();  lights.ambientLight.set(0.4f,  0.4f,  0.4f,  1f);  lights.add(new  DirectionalLight().set(0.8f,  0.8f,  0.8f,  -1f,  -1f,  0f));  lights.add(new  DirectionalLight().set(0.8f,  0.8f,  0.8f,  -1f,  -0.8f,  -0.2f));  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(10f,  10f,  10f);  cam.lookAt(0,0,0);  cam.near  =  0.1f;  cam.far  =  300f;  cam.update();  	lights.add(new  DirectionalLight().set(0.8f,  0.8f,  0.8f,  -1f,  -0.8f,  -0.2f));  
elasticsearch_ad50afbec8c2d619a33fdb591361d5d2ad4c766d	buggy:  NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().setPlugin(true).execute().actionGet();  context:  String  server2NodeId  =  startNodeWithPlugins(2);  String  server3NodeId  =  startNodeWithPlugins(3,TestPlugin.class.getName());  String  server4NodeId  =  startNodeWithPlugins(4,TestNoVersionPlugin.class.getName());  ClusterHealthResponse  clusterHealth  =  client().admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();          NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().setPlugin(true).execute().actionGet();          NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().execute().actionGet();  assertNodeContainsPlugins(response,  server1NodeId,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST);  assertNodeContainsPlugins(response,  server2NodeId,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Lists.newArrayList(Fields.SITE_PLUGIN),  Lists.newArrayList(Fields.SITE_PLUGIN_DESCRIPTION));  	NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().execute().actionGet();  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(settings),  context:  bindings.processXContentQueryFilter( "my ",  PluginJsonFilterParser.class);  }  });  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),  new  ScriptModule(settings),                  new  IndexSettingsModule(settings),                  new  IndexSettingsModule(index,  settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  queryParserModule,  new  IndexNameModule(index)  ).createInjector();  IndexQueryParserService  indexQueryParserService  =  injector.getInstance(IndexQueryParserService.class);  	new  IndexSettingsModule(index,  settings),  
elasticsearch_e7d80b8244337555086bdabdcf38d9efa5d9b192	buggy:  return  shards().size()  <  metaData.maxNumberOfShardsPerNode();  context:  for  (MutableShardRouting  shardEntry  :  this)  {  if  (shardEntry.state()  !=  ShardRoutingState.RELOCATING)  {  count++;  }  }  return  count;  }  public  boolean  canAllocate(MetaData  metaData,  RoutingTable  routingTable)  {          return  shards().size()  <  metaData.maxNumberOfShardsPerNode();          return  true;  }  public  boolean  canAllocate(ShardRouting  requested)  {  for  (MutableShardRouting  current  :  shards)  {  if  (current.shardId().equals(requested.shardId()))  {  return  false;  }  	return  true;  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices( "test ");  context:  ensureGreen();  SearchResponse  searchResponseAfterGreen  =  client.prepareSearch( "test ").setPreference(preference).setQuery(QueryBuilders.termQuery( "field ",   "test ")).execute().actionGet();  assertHitCount(searchResponse,  1);  }  assertHitCount(searchResponse,  1);  status  =  client().admin().cluster().prepareHealth( "test ").get().getStatus();  cluster().ensureAtLeastNumNodes(numberOfReplicas  +  1);  }              wipeIndices( "test ");              cluster().wipeIndices( "test ");  }  }  }  	cluster().wipeIndices( "test ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<ContextDocIdSet>  filteredEntries  =  new  ArrayList<ContextDocIdSet>(docSets.size());  context:  private  final  Post  post;  private  final  Filter  filter;  public  Filtered(Post  post,  Filter  filter)  {  this.post  =  post;  this.filter  =  filter;  }  public  void  executePost(List<ContextDocIdSet>  docSets)  throws  IOException  {                  List<ContextDocIdSet>  filteredEntries  =  new  ArrayList<ContextDocIdSet>(docSets.size());                  List<ContextDocIdSet>  filteredEntries  =  new  ArrayList<>(docSets.size());  for  (int  i  =  0;  i  <  docSets.size();  i++)  {  ContextDocIdSet  entry  =  docSets.get(i);  DocIdSet  filteredSet  =  filter.getDocIdSet(entry.context,  null);  if  (filteredSet  !=  null)  {  filteredEntries.add(new  ContextDocIdSet(  entry.context,  new  AndDocIdSet(new  DocIdSet[]{entry.docSet,  filteredSet})  	List<ContextDocIdSet>  filteredEntries  =  new  ArrayList<>(docSets.size());  
libgdx_32c98da9f705b1881a0c7084fb0971f021c0ee32	buggy:  skelAnim.duration  =  animation.length;  context:  if(joint.parent  ==  null)  skel.hierarchy.add(joint);  }  skel.buildFromHierarchy();  List<Animation>  animations  =  ogreSkel.getAnimations().getAnimation();  for(int  i  =  0;  i  <  animations.size();  i++)  {  Animation  animation  =  animations.get(i);  SkeletonAnimation  skelAnim  =  new  SkeletonAnimation();  skelAnim.duration  =  animation.length;  skelAnim.totalDuration  =  animation.length;  skelAnim.perJointkeyFrames  =  new  SkeletonKeyframe[skel.bindPoseJoints.size][];  List<Track>  tracks  =  animation.getTracks().getTrack();  if(tracks.size()  !=  skelAnim.perJointkeyFrames.length)  throw  new  IllegalArgumentException( "Number  of  tracks  does  not  equal  number  of  joints ");  Matrix4  rotation  =  new  Matrix4();  Matrix4  transform  =  new  Matrix4();  	skelAnim.totalDuration  =  animation.length;  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  if  (entry.bytes().underlyingBytes().length  >  BYTES_LIMIT)  {  context:  if  (entry  ==  null)  {  return  newEntry();  }  counter.decrementAndGet();  entry.reset();  return  entry;  }  public  static  void  pushEntry(Entry  entry)  {  entry.reset();          if  (entry.bytes().underlyingBytes().length  >  BYTES_LIMIT)  {          if  (entry.bytes().bytes().length()  >  BYTES_LIMIT)  {  return;  }  Queue<Entry>  ref  =  cache.get();  if  (ref  ==  null)  {  ref  =  new  LinkedTransferQueue<Entry>();  counter.set(0);  cache.set(ref);  }  	if  (entry.bytes().bytes().length()  >  BYTES_LIMIT)  {  
libgdx_b4cc9de25becdcd50d4c82401ee8d2784afe39c6	buggy:  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-v ");  context:  android.cFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.cppFlags  +=   "  -DFIXED_POINT  -D_ARM_ASSEM_  -D__ANDROID__ ";  android.headerDirs  =  headerDirs;  android.cIncludes  =  cIncludes;  android.cppIncludes  =  cppIncludes;  android.cppExcludes  =  cppExcludes;  android.preCompileTask  =  precompileTask;  new  AntScriptGenerator().generate(buildConfig,  win32home,  win32,  win64,  lin32,  lin64,  android);  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-v ");  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "clean  postcompile  -v ");  }  }  	BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "clean  postcompile  -v ");  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  }  builder.endObject();  }  builder.endObject();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  boolean  resolveRequest(ClusterState  state,  Request  request,  ActionListener<Response>  listener)  {          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  return  true;  }  protected  boolean  retryOnFailure(Throwable  e)  {  return  false;  }  protected  TransportRequestOptions  transportOptions()  {  	request.index(state.metaData().concreteSingleIndex(request.index()));  
libgdx_a5b526df8840f8a77da73f54cbae0a3693a30874	buggy:  return  areaHeight;  context:  public  float  getScrollBarHeight  ()  {  return  style.hScrollKnob  ==  null  ||  !scrollX  ?  0  :  style.hScrollKnob.getMinHeight();  }  public  float  getScrollBarWidth  ()  {  return  style.vScrollKnob  ==  null  ||  !scrollY  ?  0  :  style.vScrollKnob.getMinWidth();  }  public  float  getScrollWidth  ()  {  return  areaHeight;  return  areaWidth;  }  public  float  getScrollHeight  ()  {  return  areaHeight;  }  public  boolean  isScrollX  ()  {  	return  areaWidth;  
elasticsearch_b4b92a8e7f14aa85fbc272a30da412ce65172ecc	buggy:  for  (String  alias  :  indexMetaData.aliases())  {  context:  if  (mapping.size()  ==  1  &&  mapping.containsKey(entry.getKey()))  {  mapping  =  (Map<String,  Object>)  mapping.get(entry.getKey());  }  builder.field(entry.getKey());  builder.map(mapping);  }  builder.endObject();  builder.startArray( "aliases ");                              for  (String  alias  :  indexMetaData.aliases())  {                              for  (String  alias  :  indexMetaData.aliases().keySet())  {  builder.value(alias);  }  builder.endArray();  builder.endObject();  }  builder.endObject();  	for  (String  alias  :  indexMetaData.aliases().keySet())  {  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  joystick.set(dx,  dy).mul(JOYSTICK_DISTANCE_MULTIPLIER);  context:  worldCam.unproject(touchPoint.set(Gdx.input.getX(),  Gdx.input.getY(),  0));  if  (world.isPaused())  {  presenter.resume();  }  else  if  (touchPoint.y  >=  worldMaxY)  {  presenter.pause();  }  }  else  if  (Gdx.input.isTouched())  {  worldCam.unproject(dragPoint.set(Gdx.input.getX(),  Gdx.input.getY(),  0));  float  dx  =  dragPoint.x  -  touchPoint.x;  float  dy  =  dragPoint.y  -  touchPoint.y;  joystick.set(dx,  dy).mul(JOYSTICK_DISTANCE_MULTIPLIER);  joystick.set(dx,  dy).scl(JOYSTICK_DISTANCE_MULTIPLIER);  float  len  =  joystick.len();  if  (len  >  1)  {  joystick.nor();  }  if  (presenter  !=  null)  {  presenter.setController(joystick.x,  joystick.y);  if  (len  >=  FIRING_DEAD_ZONE)  {  joystick.nor();  	joystick.set(dx,  dy).scl(JOYSTICK_DISTANCE_MULTIPLIER);  
libgdx_0ff5bd284c452b749d059f0f76c0f7a82f1de401	buggy:  return  x  +   ", "  +  y  +   ", "  +  z;  context:  final  float  tx  =  target.x  -  x  *  dot;  final  float  ty  =  target.y  -  y  *  dot;  final  float  tz  =  target.z  -  z  *  dot;  final  float  l2  =  tx  *  tx  +  ty  *  ty  +  tz  *  tz;  final  float  dl  =  st  *  ((l2  <  0.0001f)  ?  1f  :  1f  /  (float)Math.sqrt(l2));  return  scl((float)Math.cos(theta)).add(tx  *  dl,  ty  *  dl,  tz  *  dl).nor();  }  public  String  toString  ()  {  return  x  +   ", "  +  y  +   ", "  +  z;  return   "[ "  +  x  +   ",   "  +  y  +   ",   "  +  z  +   "] ";  }  public  Vector3  limit  (float  limit)  {  if  (len2()  >  limit  *  limit)  nor().scl(limit);  return  this;  }  	return   "[ "  +  x  +   ",   "  +  y  +   ",   "  +  z  +   "] ";  
elasticsearch_0b09fd0806364c0785fc649b6483f00fb8e8ebf4	buggy:  return  new  InternalStatisticalFacet(name,  ((InternalStatisticalFacet)  facets.get(0)).fieldName(),  min,  max,  total,  sumOfSquares,  count);  context:  min  =  statsFacet.min();  }  if  (statsFacet.max()  >  max  ||  Double.isNaN(max))  {  max  =  statsFacet.max();  }  total  +=  statsFacet.total();  sumOfSquares  +=  statsFacet.sumOfSquares();  count  +=  statsFacet.count();  }          return  new  InternalStatisticalFacet(name,  ((InternalStatisticalFacet)  facets.get(0)).fieldName(),  min,  max,  total,  sumOfSquares,  count);          return  new  InternalStatisticalFacet(name,  min,  max,  total,  sumOfSquares,  count);  }  }  	return  new  InternalStatisticalFacet(name,  min,  max,  total,  sumOfSquares,  count);  
libgdx_7a0fb79365d7a425b9f0c71a1077c9b776e73133	buggy:  mac.libraries  =   " ";  //  FIXME  context:  lin32.libraries  =   "-lX11 ";  BuildTarget  lin64  =  BuildTarget.newDefaultTarget(TargetOs.Linux,  true);  lin64.cppIncludes  =  linuxSrc;  lin64.headerDirs  =  includes;  lin64.libraries  =   "-lX11 ";  BuildTarget  mac  =  BuildTarget.newDefaultTarget(TargetOs.MacOsX,  false);  mac.cppIncludes  =  macSrc;  mac.headerDirs  =  includes;  mac.libraries  =   " ";  //  FIXME  mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit ";  new  AntScriptGenerator().generate(buildConfig,  win32home,  win32,  win64,  lin32,  lin64,  mac);  if(!BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler=true  -v  postcompile "))  {  throw  new  Exception( "build  failed ");  }  BuildExecutor.executeAnt( "jni/build.xml ",   "pack-natives ");  }  }  	mac.libraries  =   "-framework  CoreServices  -framework  Carbon  -framework  IOKit ";  
elasticsearch_2cb40fcb1741ce1bf4c770aeec8b85717f2b5d98	buggy:  assertThat( "doc[ "  +  id  +   "]  should  have  been  deleted,  but  isn't ",  response.isNotFound(),  equalTo(false));  context:  do  {  if  (liveIds.isEmpty())  {  continue  outer;  }  id  =  Integer.toString(randomInt(idGen.get()));  }  while  (!liveIds.remove(id));  DeleteResponse  response  =  client().prepareDelete( "index ",  PercolatorService.TYPE_NAME,  id)  .execute().actionGet();  assertThat(response.getId(),  equalTo(id));                                      assertThat( "doc[ "  +  id  +   "]  should  have  been  deleted,  but  isn't ",  response.isNotFound(),  equalTo(false));                                      assertThat( "doc[ "  +  id  +   "]  should  have  been  deleted,  but  isn't ",  response.isFound(),  equalTo(true));  }  else  {  String  id  =  Integer.toString(idGen.getAndIncrement());  IndexResponse  response  =  client().prepareIndex( "index ",  PercolatorService.TYPE_NAME,  id)  .setSource(doc)  .execute().actionGet();  liveIds.add(id);  assertThat(response.isCreated(),  equalTo(true));  //  We  only  add  new  docs  assertThat(response.getId(),  equalTo(id));  	assertThat( "doc[ "  +  id  +   "]  should  have  been  deleted,  but  isn't ",  response.isFound(),  equalTo(true));  
libgdx_cb42e3df8e1782c3946fcecf0554172dde98dd30	buggy:  JFrame  frame  =  new  JFrame( "Gdx  -  Jogl  Test  Launcher ");  context:  app.getGraphics().setRenderListener(test);  }  });  add(pane,  BorderLayout.CENTER);  add(button,  BorderLayout.SOUTH);  }  }  public  static  void  main  (String[]  argv)  {  JFrame  frame  =  new  JFrame( "Gdx  -  Jogl  Test  Launcher ");  JFrame  frame  =  new  JFrame( "GDX  -  Jogl  Test  Launcher ");  frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);  frame.setContentPane(new  TestList());  frame.pack();  frame.setSize(frame.getWidth(),  600);  frame.setLocationRelativeTo(null);  frame.setVisible(true);  }  }  	JFrame  frame  =  new  JFrame( "GDX  -  Jogl  Test  Launcher ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  String[]>  bFilters  =  new  HashMap<String,  String[]>();  context:  OR  }  ;  public  static  DiscoveryNodeFilters  buildFromSettings(OpType  opType,  String  prefix,  Settings  settings)  {  return  buildFromKeyValue(opType,  settings.getByPrefix(prefix).getAsMap());  }  public  static  DiscoveryNodeFilters  buildFromKeyValue(OpType  opType,  Map<String,  String>  filters)  {          Map<String,  String[]>  bFilters  =  new  HashMap<String,  String[]>();          Map<String,  String[]>  bFilters  =  new  HashMap<>();  for  (Map.Entry<String,  String>  entry  :  filters.entrySet())  {  String[]  values  =  Strings.splitStringByCommaToArray(entry.getValue());  if  (values.length  >  0)  {  bFilters.put(entry.getKey(),  values);  }  }  if  (bFilters.isEmpty())  {  return  null;  	Map<String,  String[]>  bFilters  =  new  HashMap<>();  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index()));  context:  if  (!clusterState.metaData().hasConcreteIndex(termVectorRequest.index()))  {  responses.set(i,  new  MultiTermVectorsItemResponse(null,  new  MultiTermVectorsResponse.Failure(termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),   "[ "  +  termVectorRequest.index()  +   "]  missing ")));  continue;  }  if  (termVectorRequest.routing()  ==  null  &&  clusterState.getMetaData().routingRequired(termVectorRequest.index(),  termVectorRequest.type()))  {  responses.set(i,  new  MultiTermVectorsItemResponse(null,  new  MultiTermVectorsResponse.Failure(termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),   "routing  is  required,  but  hasn't  been  specified ")));  continue;  }              termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index()));              termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index(),  termVectorRequest.indicesOptions()));  ShardId  shardId  =  clusterService  .operationRouting()  .getShards(clusterState,  termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),  termVectorRequest.routing(),  null).shardId();  MultiTermVectorsShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiTermVectorsShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  	termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index(),  termVectorRequest.indicesOptions()));  
libgdx_399384e407dc91fb7a5735ed3545e32afdebd513	buggy:  if  (Gdx.app.getType()  ==  ApplicationType.Desktop  ||  Gdx.graphics.isGL20Available()  ==  false)  {  context:  }  width  =  data.width;  height  =  data.height;  isPrepared  =  true;  }  public  void  consumeCompressedData  ()  {  if  (!isPrepared)  throw  new  GdxRuntimeException( "Call  prepare()  before  calling  consumeCompressedData() ");  if  (Gdx.app.getType()  ==  ApplicationType.Desktop  ||  Gdx.graphics.isGL20Available()  ==  false)  {  if  (!Gdx.graphics.supportsExtension( "GL_OES_compressed_ETC1_RGB8_texture ")  ||  Gdx.graphics.isGL20Available()  ==  false)  {  Pixmap  pixmap  =  ETC1.decodeImage(data,  Format.RGB565);  Gdx.gl.glTexImage2D(GL10.GL_TEXTURE_2D,  0,  pixmap.getGLInternalFormat(),  pixmap.getWidth(),  pixmap.getHeight(),  0,  pixmap.getGLFormat(),  pixmap.getGLType(),  pixmap.getPixels());  if  (useMipMaps)  MipMapGenerator.generateMipMap(pixmap,  pixmap.getWidth(),  pixmap.getHeight(),  false);  pixmap.dispose();  useMipMaps  =  false;  }  else  {  Gdx.gl.glCompressedTexImage2D(GL10.GL_TEXTURE_2D,  0,  ETC1.ETC1_RGB8_OES,  width,  height,  0,  	if  (!Gdx.graphics.supportsExtension( "GL_OES_compressed_ETC1_RGB8_texture ")  ||  Gdx.graphics.isGL20Available()  ==  false)  {  
elasticsearch_899189694f32edc808fd0e0ce3491587e9ae479e	buggy:  Query  q  =  getFieldQuerySingle(mField,  queryText,  true);  context:  disMaxQuery.add(q);  }  }  if  (!added)  {  return  null;  }  return  disMaxQuery;  }  else  {  List<BooleanClause>  clauses  =  new  ArrayList<BooleanClause>();  for  (String  mField  :  fields)  {                      Query  q  =  getFieldQuerySingle(mField,  queryText,  true);                      Query  q  =  getFieldQuerySingle(mField,  queryText,  quoted);  if  (q  !=  null)  {  applyBoost(mField,  q);  clauses.add(new  BooleanClause(q,  BooleanClause.Occur.SHOULD));  }  }  if  (clauses.size()  ==  0)  //  happens  for  stopwords  return  null;  return  getBooleanQuery(clauses,  true);  	Query  q  =  getFieldQuerySingle(mField,  queryText,  quoted);  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  countRequest.listenerThreaded(false);  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);  if  (request.hasContent())  {                  countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  countRequest.query(source);  }  else  {  countRequest.query(RestActions.parseQuerySource(request));  }  }  	countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);  
elasticsearch_4723c2a2ee264390227a089c59d1930469d8b5e5	buggy:  return  new  DoubleTerms.Bucket(value,  bucket.docCount,  bucket.aggregations,  bucket.showDocCountError,  bucket.docCountError);  context:  public  DoubleTerms  buildEmptyAggregation()  {  final  LongTerms  terms  =  (LongTerms)  super.buildEmptyAggregation();  return  convertToDouble(terms);  }  private  static  DoubleTerms.Bucket  convertToDouble(InternalTerms.Bucket  bucket)  {  final  long  term  =  bucket.getKeyAsNumber().longValue();  final  double  value  =  NumericUtils.sortableLongToDouble(term);          return  new  DoubleTerms.Bucket(value,  bucket.docCount,  bucket.aggregations,  bucket.showDocCountError,  bucket.docCountError);          return  new  DoubleTerms.Bucket(value,  bucket.docCount,  bucket.aggregations,  bucket.showDocCountError,  bucket.docCountError,  bucket.formatter);  }  private  static  DoubleTerms  convertToDouble(LongTerms  terms)  {  final  InternalTerms.Bucket[]  buckets  =  terms.getBuckets().toArray(new  InternalTerms.Bucket[0]);  for  (int  i  =  0;  i  <  buckets.length;  ++i)  {  buckets[i]  =  convertToDouble(buckets[i]);  }  return  new  DoubleTerms(terms.getName(),  terms.order,  terms.formatter,  terms.requiredSize,  terms.shardSize,  terms.minDocCount,  Arrays.asList(buckets),  terms.showTermDocCountError,  terms.docCountError);  	return  new  DoubleTerms.Bucket(value,  bucket.docCount,  bucket.aggregations,  bucket.showDocCountError,  bucket.docCountError,  bucket.formatter);  
elasticsearch_1c5477d4eda4ccb2a6b2c84419cdb2841a9ce736	buggy:  assertThat(searchResponse.hits().getAt(0).field( "field2 "),  nullValue());  context:  .setQuery(termQuery( "field1 ",   "value1 "))  .addField( "field1 ").addField( "field2 ")  .execute().actionGet();  if  (searchResponse.failedShards()  >  0)  {  }  assertThat(searchResponse.failedShards(),  equalTo(0));  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  assertThat(searchResponse.hits().hits().length,  equalTo(1));  assertThat(searchResponse.hits().getAt(0).field( "field1 ").value().toString(),  equalTo( "value1 "));          assertThat(searchResponse.hits().getAt(0).field( "field2 "),  nullValue());          assertThat(searchResponse.hits().getAt(0).field( "field2 ").value().toString(),  equalTo( "value  2 "));  //  this  will  still  be  loaded  because  of  the  source  feature  client.prepareIndex( "text_index ",   "type1 ",   "1 ").setSource( "field1 ",   "value1 ",   "field2 ",   "value  2 ").setRefresh(true).execute().actionGet();  client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();  searchResponse  =  client.prepareSearch( "text_index ")  .setQuery(termQuery( "field1 ",   "value1 "))  	assertThat(searchResponse.hits().getAt(0).field( "field2 ").value().toString(),  equalTo( "value  2 "));  //  this  will  still  be  loaded  because  of  the  source  feature  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Short.MIN_VALUE;  context:  this.nullValueAsString  =  nullValue  ==  null  ?  null  :  nullValue.toString();  }  return  32;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Short.MIN_VALUE;              return  null;  }  return  Numbers.bytesToShort(value);  }  return  indexedValue(Short.parseShort(value));  }  	return  null;  
libgdx_2dc2458d830d26ab052fc3b5f461312cb88ca643	buggy:  public  Array<Actor>  getChildren  ()  {  context:  public  boolean  swapActor  (Actor  first,  Actor  second)  {  int  firstIndex  =  children.indexOf(first,  true);  int  secondIndex  =  children.indexOf(second,  true);  if  (firstIndex  ==  -1  ||  secondIndex  ==  -1)  return  false;  children.swap(firstIndex,  secondIndex);  return  true;  }  public  Array<Actor>  getChildren  ()  {  public  SnapshotArray<Actor>  getChildren  ()  {  return  children;  }  	public  SnapshotArray<Actor>  getChildren  ()  {  
elasticsearch_8266315f51c2393290172272444369893c7bf9f9	buggy:  }  catch  (IOException  e)  {  context:  synchronized  (mutex)  {  try  {  raf.increaseRefCount();  if  (useStream)  {  return  new  FsStreamSnapshot(shardId,  this.id,  raf,  lastPosition,  operationCounter.get(),  operationCounter.get());  }  else  {  return  new  FsChannelSnapshot(shardId,  this.id,  raf,  lastPosition,  operationCounter.get(),  operationCounter.get());  }              }  catch  (IOException  e)  {              }  catch  (Exception  e)  {  throw  new  TranslogException(shardId,   "Failed  to  snapshot ",  e);  }  }  }  synchronized  (mutex)  {  if  (currentId()  !=  snapshot.translogId())  {  	}  catch  (Exception  e)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  queryExplanations  =  new  ArrayList<QueryExplanation>(size);  context:  }  return  queryExplanations;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  valid  =  in.readBoolean();  int  size  =  in.readVInt();  if  (size  >  0)  {              queryExplanations  =  new  ArrayList<QueryExplanation>(size);              queryExplanations  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  queryExplanations.add(readQueryExplanation(in));  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  	queryExplanations  =  new  ArrayList<>(size);  
elasticsearch_48979ab6c88ada1f9992771b615b560b377f0fd3	buggy:  ClusterChangedEvent  clusterChangedEvent  =  new  ClusterChangedEvent(source,  clusterState,  previousClusterState,  discoveryService.firstMaster());  context:  if  (logger.isTraceEnabled())  {  StringBuilder  sb  =  new  StringBuilder( "Cluster  State  updated:\nVersion  [ ").append(clusterState.version()).append( "],  source  [ ").append(source).append( "]\n ");  sb.append(clusterState.nodes().prettyPrint());  sb.append(clusterState.routingTable().prettyPrint());  sb.append(clusterState.readOnlyRoutingNodes().prettyPrint());  }  else  if  (logger.isDebugEnabled())  {  }                      ClusterChangedEvent  clusterChangedEvent  =  new  ClusterChangedEvent(source,  clusterState,  previousClusterState,  discoveryService.firstMaster());                      ClusterChangedEvent  clusterChangedEvent  =  new  ClusterChangedEvent(source,  clusterState,  previousClusterState);  final  DiscoveryNodes.Delta  nodesDelta  =  clusterChangedEvent.nodesDelta();  if  (nodesDelta.hasChanges()  &&  logger.isInfoEnabled())  {  String  summary  =  nodesDelta.shortSummary();  if  (summary.length()  >  0)  {  }  }  	ClusterChangedEvent  clusterChangedEvent  =  new  ClusterChangedEvent(source,  clusterState,  previousClusterState);  
elasticsearch_8e6c4ce8e89d05dc1cd9cad5e5e5f0f67a8b370e	buggy:  assertThat( "Unexpectd  ShardFailures:   "  +  Arrays.toString(response.getShardFailures()),  response.getFailedShards(),  equalTo(0));  context:  assertVersionSerializable(searchResponse);  }  public  static  void  assertNoFailures(SearchResponse  searchResponse)  {  assertThat( "Unexpected  ShardFailures:   "  +  Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getShardFailures().length,  equalTo(0));  assertVersionSerializable(searchResponse);  }  public  static  void  assertNoFailures(BroadcastOperationResponse  response)  {          assertThat( "Unexpectd  ShardFailures:   "  +  Arrays.toString(response.getShardFailures()),  response.getFailedShards(),  equalTo(0));          assertThat( "Unexpected  ShardFailures:   "  +  Arrays.toString(response.getShardFailures()),  response.getFailedShards(),  equalTo(0));  assertVersionSerializable(response);  }  public  static  void  assertSearchHit(SearchHit  searchHit,  Matcher<SearchHit>  matcher)  {  assertThat(searchHit,  matcher);  assertVersionSerializable(searchHit);  }  	assertThat( "Unexpected  ShardFailures:   "  +  Arrays.toString(response.getShardFailures()),  response.getFailedShards(),  equalTo(0));  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  3,  0,  new  VertexAttribute(VertexAttributes.Usage.Color,  4,   "a_Color "),  new  VertexAttribute(  context:  TextureWrap.ClampToEdge);  pixmap  =  Gdx.graphics.newPixmap(256,  256,  Format.RGBA8888);  pixmap.setColor(1,  1,  1,  1);  pixmap.fill();  pixmap.setColor(0,  0,  0,  1);  pixmap.drawLine(128,  0,  128,  256);  tex2  =  Gdx.graphics.newUnmanagedTexture(pixmap,  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  mesh  =  new  Mesh(true,  false,  3,  0,  new  VertexAttribute(VertexAttributes.Usage.Color,  4,   "a_Color "),  new  VertexAttribute(  mesh  =  new  Mesh(true,  3,  0,  new  VertexAttribute(VertexAttributes.Usage.Color,  4,   "a_Color "),  new  VertexAttribute(  VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoords1 "),  new  VertexAttribute(  VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoords2 "),  new  VertexAttribute(VertexAttributes.Usage.Position,  3,   "a_Position "));  mesh.setVertices(new  float[]  {1,  0,  0,  1,  0,  1,  0,  1,  -0.5f,  -0.5f,  0,  0,  1,  0,  1,  1,  1,  1,  1,  0.5f,  -0.5f,  0,  	mesh  =  new  Mesh(true,  3,  0,  new  VertexAttribute(VertexAttributes.Usage.Color,  4,   "a_Color "),  new  VertexAttribute(  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);  context:  }  protected  ClusterSearchShardsResponse  newResponse()  {  return  new  ClusterSearchShardsResponse();  }  protected  void  masterOperation(final  ClusterSearchShardsRequest  request,  final  ClusterState  state,  final  ActionListener<ClusterSearchShardsResponse>  listener)  throws  ElasticSearchException  {  ClusterState  clusterState  =  clusterService.state();          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(request.routing(),  request.indices());  Set<String>  nodeIds  =  newHashSet();  GroupShardsIterator  groupShardsIterator  =  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  request.preference());  ShardRouting  shard;  ClusterSearchShardsGroup[]  groupResponses  =  new  ClusterSearchShardsGroup[groupShardsIterator.size()];  int  currentGroup  =  0;  for  (ShardIterator  shardIt  :  groupShardsIterator)  {  String  index  =  shardIt.shardId().getIndex();  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_33d357dbb425de727ec834e6c59ce8c5a183cc2e	buggy:  dir.releaseBuffer(buffer);  context:  return  this.buffers.length;  }  void  buffers(ByteBuffer[]  buffers)  {  this.buffers  =  buffers;  }  void  clean()  {  if  (buffers  !=  null)  {  for  (ByteBuffer  buffer  :  buffers)  {                  dir.releaseBuffer(buffer);                  dir.byteBufferCache.releaseBuffer(buffer);  }  buffers  =  null;  }  }  }  	dir.byteBufferCache.releaseBuffer(buffer);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  keyValues  =  keyIndexFieldData.load(context).getBytesValues(true);  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {              keyValues  =  keyIndexFieldData.load(context).getBytesValues(true);              keyValues  =  keyIndexFieldData.load(context).getBytesValues();  if  (script  !=  null)  {  script.setNextReader(context);  }  else  {  aggregator.valueValues  =  valueIndexFieldData.load(context).getDoubleValues();  }  }  	keyValues  =  keyIndexFieldData.load(context).getBytesValues();  
elasticsearch_b11f81d744a5c23bf7c20d696939e226905c60e7	buggy:  return  new  EngineSearcherTotalHitsMatcher(Queries.MATCH_ALL_QUERY,  totalHits);  context:  public  void  describeTo(Description  description)  {  description.appendText( "total  hits  of  size   ").appendValue(totalHits).appendText( "  with  query   ").appendValue(query);  }  public  static  Matcher<Engine.Searcher>  engineSearcherTotalHits(Query  query,  int  totalHits)  {  return  new  EngineSearcherTotalHitsMatcher(query,  totalHits);  }  public  static  Matcher<Engine.Searcher>  engineSearcherTotalHits(int  totalHits)  {          return  new  EngineSearcherTotalHitsMatcher(Queries.MATCH_ALL_QUERY,  totalHits);          return  new  EngineSearcherTotalHitsMatcher(Queries.newMatchAllQuery(),  totalHits);  }  }  	return  new  EngineSearcherTotalHitsMatcher(Queries.newMatchAllQuery(),  totalHits);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  ValueAndBoost  valueAndBoost  =  parseCreateFieldForString(context,  nullValue,  context.fieldBoost(this));  context:  public  Filter  nullValueFilter()  {  if  (nullValue  ==  null)  {  return  null;  }  return  termFilter(nullValue,  null);  }  protected  void  parseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {          ValueAndBoost  valueAndBoost  =  parseCreateFieldForString(context,  nullValue,  context.fieldBoost(this));          ValueAndBoost  valueAndBoost  =  parseCreateFieldForString(context,  nullValue,  boost);  if  (valueAndBoost.value()  ==  null)  {  return;  }  if  (ignoreAbove  >  0  &&  valueAndBoost.value().length()  >  ignoreAbove)  {  return;  }  if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  valueAndBoost.value(),  valueAndBoost.boost());  	ValueAndBoost  valueAndBoost  =  parseCreateFieldForString(context,  nullValue,  boost);  
elasticsearch_3e30fa2089d5454df717431f5d3d7397cf8b90e9	buggy:  String[]  indices  =  concreteIndices(IndicesOptions.strictSingleIndexNoExpand(),  indexOrAlias);  context:  Collections.addAll(actualIndices,  indices);  }  if  (!indicesOptions.allowNoIndices()  &&  actualIndices.isEmpty())  {  throw  new  IndexMissingException(new  Index(Arrays.toString(aliasesOrIndices)));  }  return  actualIndices.toArray(new  String[actualIndices.size()]);  }  public  String  concreteSingleIndex(String  indexOrAlias)  throws  IndexMissingException,  ElasticsearchIllegalArgumentException  {          String[]  indices  =  concreteIndices(IndicesOptions.strictSingleIndexNoExpand(),  indexOrAlias);          String[]  indices  =  concreteIndices(IndicesOptions.strictSingleIndexNoExpandForbidClosed(),  indexOrAlias);  assert  indices.length  ==  1  :   "expected  an  exception  to  be  thrown  otherwise ";  return  indices[0];  }  private  String[]  concreteIndices(String  aliasOrIndex,  boolean  allowNoIndices,  boolean  failClosed,  boolean  allowMultipleIndices)  throws  IndexMissingException,  ElasticsearchIllegalArgumentException  {  IndexMetaData  indexMetaData  =  indices.get(aliasOrIndex);  if  (indexMetaData  !=  null)  {  	String[]  indices  =  concreteIndices(IndicesOptions.strictSingleIndexNoExpandForbidClosed(),  indexOrAlias);  
libgdx_5649b5bafc9268dce18575f5b9e5d0ff1ebd92a5	buggy:  texturePackerSettings.duplicatePadding  =  true;  context:  public  static  void  main  (String[]  args)  {  final  Settings  texturePackerSettings  =  new  Settings();  texturePackerSettings.paddingX  =  2;  texturePackerSettings.paddingY  =  2;  texturePackerSettings.duplicatePadding  =  true;  texturePackerSettings.bleed  =  true;  texturePackerSettings.alias  =  true;  texturePackerSettings.useIndexes  =  true;  final  TiledMapPackerSettings  packerSettings  =  new  TiledMapPackerSettings();  switch  (args.length)  {  case  3:  {  inputDir  =  new  File(args[0]);  	texturePackerSettings.bleed  =  true;  
elasticsearch_15bdba30e5901361a0408d8e8b4068bef66169ec	buggy:  if  (propName.equals( "nullValue "))  {  context:  public  static  class  TypeParser  implements  JsonTypeParser  {  ObjectNode  floatNode  =  (ObjectNode)  node;  JsonFloatFieldMapper.Builder  builder  =  floatField(name);  parseNumberField(builder,  name,  floatNode,  parserContext);  for  (Iterator<Map.Entry<String,  JsonNode>>  propsIt  =  floatNode.getFields();  propsIt.hasNext();)  {  Map.Entry<String,  JsonNode>  entry  =  propsIt.next();  String  propName  =  entry.getKey();  JsonNode  propNode  =  entry.getValue();                  if  (propName.equals( "nullValue "))  {                  if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  builder.nullValue(nodeFloatValue(propNode));  }  }  return  builder;  }  }  private  final  Float  nullValue;  	if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  controller.registerHandler(GET,   "/{index}/_segments ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  IndicesSegmentsRequest  indicesSegmentsRequest  =  new  IndicesSegmentsRequest(splitIndices(request.param( "index ")));  indicesSegmentsRequest.listenerThreaded(false);  if  (request.hasParam( "ignore_indices "))  {  indicesSegmentsRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  indicesSegmentsRequest.operationThreading(operationThreading);  client.admin().indices().segments(indicesSegmentsRequest,  new  ActionListener<IndicesSegmentResponse>()  {  public  void  onResponse(IndicesSegmentResponse  response)  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_5f25ae4f2f2c6a0b9794739b8ca3e953509925f7	buggy:  if  (!executorService.isTerminated())  {  context:  if  (!cached.isShutdown())  {  cached.shutdown();  }  }  started  =  false;  if  (!executorService.isTerminated())  {  executorService.shutdownNow();  }          if  (!executorService.isTerminated())  {          if  (!scheduledExecutorService.isTerminated())  {  scheduledExecutorService.shutdownNow();  }  if  (!cached.isTerminated())  {  cached.shutdownNow();  }  }  	if  (!scheduledExecutorService.isTerminated())  {  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  ByteArrayAtomicFieldData.Single(new  byte[0],  0);  context:  }  }  }  public  ByteArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  ByteArrayAtomicFieldData.Single(new  byte[0],  0);              return  new  ByteArrayAtomicFieldData.SingleFixedSet(new  byte[1],  0,  new  FixedBitSet(1));  }  final  TByteArrayList  values  =  new  TByteArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  ByteArrayAtomicFieldData.SingleFixedSet(new  byte[1],  0,  new  FixedBitSet(1));  
libgdx_b61538a41d7e33639c04d3a695595c51742ea33c	buggy:  }  else  if  ((child  ==  element.getChildByName( "ellipse ")))  {  context:  object  =  new  PolygonMapObject(vertices);  }  else  if  ((child  =  element.getChildByName( "polyline "))  !=  null)  {  String[]  points  =  child.getAttribute( "points ").split( "   ");  float[]  vertices  =  new  float[points.length  *  2];  for  (int  i  =  0;  i  <  points.length;  i++)  {  String[]  point  =  points[i].split( ", ");  vertices[i  *  2]  =  x  +  Integer.parseInt(point[0]);  vertices[i  *  2  +  1]  =  y  +  Integer.parseInt(point[1]);  }  object  =  new  PolylineMapObject(vertices);  }  else  if  ((child  ==  element.getChildByName( "ellipse ")))  {  }  else  if  ((child  =  element.getChildByName( "ellipse "))  !=  null)  {  object  =  new  EllipseMapObject(x,  y,  width,  height);  }  }  if  (object  ==  null)  {  object  =  new  RectangleMapObject(x,  y,  width,  height);  }  object.setName(element.getAttribute( "name ",  null));  String  type  =  element.getAttribute( "type ",  null);  	}  else  if  ((child  =  element.getChildByName( "ellipse "))  !=  null)  {  
elasticsearch_0909055e8342a9511a095ac3f25b8e97e7cb4900	buggy:  final  Client  client  =  client();  context:  public  void  noPreferenceRandom()  throws  Exception  {  client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  1)).execute().actionGet();  ensureGreen();  client().prepareIndex( "test ",   "type1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().admin().indices().prepareRefresh().execute().actionGet();          final  Client  client  =  client();          final  Client  client  =  cluster().smartClient();  SearchResponse  searchResponse  =  client.prepareSearch( "test ").setQuery(matchAllQuery()).execute().actionGet();  String  firstNodeId  =  searchResponse.getHits().getAt(0).shard().nodeId();  searchResponse  =  client.prepareSearch( "test ").setQuery(matchAllQuery()).execute().actionGet();  String  secondNodeId  =  searchResponse.getHits().getAt(0).shard().nodeId();  assertThat(firstNodeId,  not(equalTo(secondNodeId)));  }  	final  Client  client  =  cluster().smartClient();  
libgdx_9c7f885c8024a0007ae486756fe1bc42d947eb68	buggy:  throw  new  RuntimeException( "Unknown  array  type   "  +  type);  context:  int  arrayDim  =  0;  for  (int  i  =  0;  i  <  type.length();  i++)  {  if  (type.charAt(i)  ==  '[')  arrayDim++;  }  type  =  type.replace( "[ ",   " ").replace( "] ",   " ");  if  (arrayDim  >=  1)  {  if  (arrayDim  >  1)  return  ArgumentType.ObjectArray;  ArgumentType  arrayType  =  arrayTypes.get(type);  if  (arrayType  ==  null)  {  throw  new  RuntimeException( "Unknown  array  type   "  +  type);  return  ArgumentType.ObjectArray;  }  return  arrayType;  }  if  (plainOldDataTypes.containsKey(type))  return  plainOldDataTypes.get(type);  if  (bufferTypes.containsKey(type))  return  bufferTypes.get(type);  if  (type.equals( "String "))  return  ArgumentType.String;  return  ArgumentType.Object;  	return  ArgumentType.ObjectArray;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  SearchHitField>  fields  =  new  HashMap<String,  SearchHitField>();  context:  public  void  initialize(Engine.Searcher  docSearcher,  ParsedDocument  parsedDocument)  {  this.docSearcher  =  docSearcher;  IndexReader  indexReader  =  docSearcher.reader();  AtomicReaderContext  atomicReaderContext  =  indexReader.leaves().get(0);  lookup().setNextReader(atomicReaderContext);  lookup().setNextDocId(0);  lookup().source().setNextSource(parsedDocument.source());          Map<String,  SearchHitField>  fields  =  new  HashMap<String,  SearchHitField>();          Map<String,  SearchHitField>  fields  =  new  HashMap<>();  for  (IndexableField  field  :  parsedDocument.rootDoc().getFields())  {  fields.put(field.name(),  new  InternalSearchHitField(field.name(),  ImmutableList.of()));  }  hitContext().reset(  new  InternalSearchHit(0,   "unknown ",  new  StringText(parsedDocument.type()),  fields),  atomicReaderContext,  0,  indexReader,  0,  new  JustSourceFieldsVisitor()  );  }  	Map<String,  SearchHitField>  fields  =  new  HashMap<>();  
libgdx_fb8a152afdd3b3cf5db54f33e5e0fcbeb3226a80	buggy:  Gdx.gl  =  graphics.getGLCommon();  context:  root.clear();  root.add(new  Label( "Sorry,  your  browser  doesn't  seem  to  support  WebGL "));  return;  }  lastWidth  =  graphics.getWidth();  lastHeight  =  graphics.getHeight();  Gdx.app  =  this;  Gdx.audio  =  new  GwtAudio();  Gdx.graphics  =  graphics;  Gdx.gl20  =  graphics.getGL20();  Gdx.gl  =  graphics.getGLCommon();  Gdx.gl  =  Gdx.gl20;  Gdx.files  =  new  GwtFiles(preloader);  this.input  =  new  GwtInput(graphics.canvas);  Gdx.input  =  this.input;  this.net  =  new  GwtNet();  Gdx.net  =  this.net;  this.clipboard  =  new  GwtClipboard();  	Gdx.gl  =  Gdx.gl20;  
elasticsearch_3f62b9ea96ec7f1d5195d99118b37b2a433968c7	buggy:  if  (logger.isDebugEnabled())  {  context:  remove  =  true;  }  if  (remove)  {  Object[]  args  =  new  Object[4];  if  (key  !=  null)  {  args[0]  =  key.getClass().getCanonicalName();  args[1]  =  key.toString();  }  args[2]  =  value.getClass().getCanonicalName();  args[3]  =  value.toString();                              if  (logger.isDebugEnabled())  {                              if  (logger.isTraceEnabled())  {  }  if  (key  ==  null)  {  staleEntriesCount++;  }  else  {  mapRemove.invoke(map,  key);  }  }  	if  (logger.isTraceEnabled())  {  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  filter  =  parseContext.cacheFilter(filter);  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }          filter  =  parseContext.cacheFilter(filter);          filter  =  parseContext.cacheFilter(filter,  null);  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  return  new  DeletionAwareConstantScoreQuery(filter);  }  }  	filter  =  parseContext.cacheFilter(filter,  null);  
elasticsearch_96729b309dff2fb36a30e0c83a5c4fb1538dbc06	buggy:  assertThat(((CustomQueryWrappingFilter)  ((XConstantScoreQuery)  parsedQuery).getFilter()).getQuery().toString(),  equalTo( "parent_filter[foo](*:*) "));  context:  String  query  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json ");  IndexService  indexService  =  createIndex( "testidx ",  client().admin().indices().prepareCreate( "testidx ")  .addMapping( "foo ")  .addMapping( "test ",   "_parent ",   "type=foo "));  SearchContext.setCurrent(createSearchContext(indexService));  IndexQueryParserService  queryParser  =  indexService.queryParserService();  Query  parsedQuery  =  queryParser.parse(query).query();  assertThat(parsedQuery,  instanceOf(XConstantScoreQuery.class));  assertThat(((XConstantScoreQuery)  parsedQuery).getFilter(),  instanceOf(CustomQueryWrappingFilter.class));  assertThat(((CustomQueryWrappingFilter)  ((XConstantScoreQuery)  parsedQuery).getFilter()).getQuery(),  instanceOf(ParentConstantScoreQuery.class));          assertThat(((CustomQueryWrappingFilter)  ((XConstantScoreQuery)  parsedQuery).getFilter()).getQuery().toString(),  equalTo( "parent_filter[foo](*:*) "));          assertThat(((CustomQueryWrappingFilter)  ((XConstantScoreQuery)  parsedQuery).getFilter()).getQuery().toString(),  equalTo( "parent_filter[foo](filtered(*:*)->cache(_type:foo)) "));  SearchContext.removeCurrent();  }  }  	assertThat(((CustomQueryWrappingFilter)  ((XConstantScoreQuery)  parsedQuery).getFilter()).getQuery().toString(),  equalTo( "parent_filter[foo](filtered(*:*)->cache(_type:foo)) "));  
elasticsearch_9a2d27a03574446e7a2554848d6b28eeb7e48a06	buggy:  }  else  if  ( "prefix_length ".equals(fieldName)  ||   "prefixLength ".equals(fieldName))  {  context:  suggestion.stringDistance(SuggestUtils.resolveDistance(parser.text()));  }  else  if  ( "max_edits ".equals(fieldName)  ||   "maxEdits ".equals(fieldName))  {  suggestion.maxEdits(parser.intValue());  if  (suggestion.maxEdits()  <  1  ||  suggestion.maxEdits()  >  LevenshteinAutomata.MAXIMUM_SUPPORTED_DISTANCE)  {  throw  new  ElasticSearchIllegalArgumentException( "Illegal  max_edits  value   "  +  suggestion.maxEdits());  }  }  else  if  ( "max_inspections ".equals(fieldName)  ||   "maxInspections ".equals(fieldName))  {  suggestion.maxInspections(parser.intValue());  }  else  if  ( "max_term_freq ".equals(fieldName)  ||   "maxTermFreq ".equals(fieldName))  {  suggestion.maxTermFreq(parser.floatValue());              }  else  if  ( "prefix_length ".equals(fieldName)  ||   "prefixLength ".equals(fieldName))  {              }  else  if  ( "prefix_len ".equals(fieldName)  ||   "prefixLen ".equals(fieldName))  {  suggestion.prefixLength(parser.intValue());  }  else  if  ( "min_word_len ".equals(fieldName)  ||   "minWordLen ".equals(fieldName))  {  suggestion.minQueryLength(parser.intValue());  }  else  if  ( "min_doc_freq ".equals(fieldName)  ||   "minDocFreq ".equals(fieldName))  {  suggestion.minDocFreq(parser.floatValue());  }  else  {  return  false;  }  	}  else  if  ( "prefix_len ".equals(fieldName)  ||   "prefixLen ".equals(fieldName))  {  
elasticsearch_53935f078a73c828be301a2c850e139ba9c2a8c9	buggy:  List<DoubleEntry>  ordered  =  new  ArrayList<DoubleEntry>();  context:  }  if  (requiredSize  ==  0)  {  //  all  terms  DoubleEntry[]  entries1  =  map.values(new  DoubleEntry[map.size()]);  Arrays.sort(entries1,  comparatorType.comparator());  return  new  InternalTermsStatsDoubleFacet(name,  comparatorType,  requiredSize,  Arrays.asList(entries1),  missing);  }  else  {  Object[]  values  =  map.internalValues();  Arrays.sort(values,  (Comparator)  comparatorType.comparator());              List<DoubleEntry>  ordered  =  new  ArrayList<DoubleEntry>();              List<DoubleEntry>  ordered  =  new  ArrayList<DoubleEntry>(map.size());  for  (int  i  =  0;  i  <  requiredSize;  i++)  {  DoubleEntry  value  =  (DoubleEntry)  values[i];  if  (value  ==  null)  {  break;  }  ordered.add(value);  }  return  new  InternalTermsStatsDoubleFacet(name,  comparatorType,  requiredSize,  ordered,  missing);  	List<DoubleEntry>  ordered  =  new  ArrayList<DoubleEntry>(map.size());  
elasticsearch_46e1886975e3e13bc69588169c3f889c0afc57ef	buggy:  }  else  if  (resourceName.endsWith( ".yml "))  {  context:  private  SettingsLoaderFactory()  {  }  public  static  SettingsLoader  loaderFromResource(String  resourceName)  {  if  (resourceName.endsWith( ".json "))  {  return  new  JsonSettingsLoader();          }  else  if  (resourceName.endsWith( ".yml "))  {          }  else  if  (resourceName.endsWith( ".yml ")  ||  resourceName.endsWith( ".yaml "))  {  return  new  YamlSettingsLoader();  }  else  if  (resourceName.endsWith( ".properties "))  {  return  new  PropertiesSettingsLoader();  }  else  {  return  new  JsonSettingsLoader();  }  }  	}  else  if  (resourceName.endsWith( ".yml ")  ||  resourceName.endsWith( ".yaml "))  {  
elasticsearch_588ae1ba9e41afdd7bf82cc1aa1892d6cc05a775	buggy:  return  new  FieldDataBreakerStats(-1,  -1,  0);  context:  public  DummyCircuitBreakerService()  {}  public  MemoryCircuitBreaker  getBreaker()  {  return  breaker;  }  public  FieldDataBreakerStats  stats()  {          return  new  FieldDataBreakerStats(-1,  -1,  0);          return  new  FieldDataBreakerStats(-1,  -1,  0,  0);  }  }  	return  new  FieldDataBreakerStats(-1,  -1,  0,  0);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  HashMap<String,  Object>  newSettings  =  new  HashMap<String,  Object>();  context:  }  }  private  void  setClusterReadOnly(String  value)  {  Settings  settings  =  settingsBuilder().put(MetaData.SETTING_READ_ONLY,  value).build();  client().admin().cluster().prepareUpdateSettings().setTransientSettings(settings).execute().actionGet();  }  private  void  setIndexReadOnly(String  index,  Object  value)  {          HashMap<String,  Object>  newSettings  =  new  HashMap<String,  Object>();          HashMap<String,  Object>  newSettings  =  new  HashMap<>();  newSettings.put(IndexMetaData.SETTING_READ_ONLY,  value);  UpdateSettingsRequestBuilder  settingsRequest  =  client().admin().indices().prepareUpdateSettings(index);  settingsRequest.setSettings(newSettings);  UpdateSettingsResponse  settingsResponse  =  settingsRequest.execute().actionGet();  assertThat(settingsResponse,  notNullValue());  }  }  	HashMap<String,  Object>  newSettings  =  new  HashMap<>();  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  PrefixQuery  query  =  new  PrefixQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  builder.dateTimeFormatter(parseDateTimeFormatter(propName,  propNode));  context:  public  Mapper.Builder<?,  ?>  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  DateFieldMapper.Builder  builder  =  dateField(name);  parseNumberField(builder,  name,  node,  parserContext);  for  (Map.Entry<String,  Object>  entry  :  node.entrySet())  {  String  propName  =  Strings.toUnderscoreCase(entry.getKey());  Object  propNode  =  entry.getValue();  if  (propName.equals( "null_value "))  {  builder.nullValue(propNode.toString());  }  else  if  (propName.equals( "format "))  {                      builder.dateTimeFormatter(parseDateTimeFormatter(propName,  propNode));                      builder.dateTimeFormatter(parseDateTimeFormatter(propNode));  }  else  if  (propName.equals( "numeric_resolution "))  {  builder.timeUnit(TimeUnit.valueOf(propNode.toString().toUpperCase(Locale.ROOT)));  }  else  if  (propName.equals( "locale "))  {  builder.locale(LocaleUtils.parse(propNode.toString()));  }  }  return  builder;  }  	builder.dateTimeFormatter(parseDateTimeFormatter(propNode));  
libgdx_af5287684aa4acdb40715b85593d008435d4741a	buggy:  new  LwjglApplication(new  com.badlogic.gdx.tests.IntegerBitmapFontTest(),  config);  context:  package  com.badlogic.gdx.tests.lwjgl;  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  new  LwjglApplication(new  com.badlogic.gdx.tests.IntegerBitmapFontTest(),  config);  new  LwjglApplication(new  com.badlogic.gdx.tests.SpriteCacheTest(),  config);  }  }  	new  LwjglApplication(new  com.badlogic.gdx.tests.SpriteCacheTest(),  config);  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(5).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(5));  for  (int  i  =  0;  i  <  routingTable.index( "test ").shards().size();  i++)  {  assertThat(routingTable.index( "test ").shard(i).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(i).shards().get(0).currentNodeId(),  nullValue());  assertThat(routingTable.index( "test ").shard(i).shards().get(1).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_c20d4bb69ed29cf11a747f0fdc40ce4237f79ce4	buggy:  builder.prettyPrint();  context:  if  (request.method()  ==  RestRequest.Method.HEAD)  {  channel.sendResponse(new  StringRestResponse(status));  return;  }  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  if  (!request.hasParam( "pretty "))  {                          builder.prettyPrint();                          builder.prettyPrint().lfAtEnd();  }  builder.startObject();  builder.field( "ok ",  true);  builder.field( "status ",  status.getStatus());  if  (settings.get( "name ")  !=  null)  {  builder.field( "name ",  settings.get( "name "));  }  	builder.prettyPrint().lfAtEnd();  
libgdx_cb1b06a90494ba176dee99705490ee8f33805bcb	buggy:  for  (int  i  =  0;  i  <  app.executedRunnables.size();  i++)  {  context:  app.listener.resume();  Gdx.app.log( "AndroidGraphics ",   "resumed ");  }  if  (lrunning)  {  synchronized  (app.runnables)  {  app.executedRunnables.clear();  app.executedRunnables.addAll(app.runnables);  app.runnables.clear();  for  (int  i  =  0;  i  <  app.executedRunnables.size();  i++)  {  for  (int  i  =  0;  i  <  app.executedRunnables.size;  i++)  {  try  {  app.executedRunnables.get(i).run();  }  catch(Throwable  t)  {  t.printStackTrace();  }  }  }  	for  (int  i  =  0;  i  <  app.executedRunnables.size;  i++)  {  
elasticsearch_4b04db903075a84df34c1b847951a58bff058b6d	buggy:  if  (context.fieldNames()  ==  null  ||  context.fieldNames().length  ==  0)  {  context:  Document  doc;  try  {  doc  =  context.searcher().doc(docId,  fieldSelector);  }  catch  (IOException  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  fetch  doc  id  [ "  +  docId  +   "] ",  e);  }  return  doc;  }  private  FieldSelector  buildFieldSelectors(SearchContext  context)  {          if  (context.fieldNames()  ==  null  ||  context.fieldNames().length  ==  0)  {          if  (context.fieldNames()  ==  null)  {  return  new  UidAndSourceFieldSelector();  }  FieldMappersFieldSelector  fieldSelector  =  new  FieldMappersFieldSelector();  for  (String  fieldName  :  context.fieldNames())  {  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);  if  (x  ==  null)  {  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "] ");  	if  (context.fieldNames()  ==  null)  {  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  counts.release();  context:  final  boolean[]  states  =  counts.v().allocated;  final  long[]  keys  =  counts.v().keys;  final  long[]  values  =  counts.v().values;  CountEntry[]  entries  =  new  CountEntry[counts.v().size()];  int  entryIndex  =  0;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  entries[entryIndex++]  =  new  CountEntry(keys[i],  values[i]);  }  }          counts.release();          counts.close();  Arrays.sort(entries,  comparatorType.comparator());  return  new  InternalCountHistogramFacet(getName(),  comparatorType,  entries);  }  static  final  class  Fields  {  static  final  XContentBuilderString  _TYPE  =  new  XContentBuilderString( "_type ");  	counts.close();  
libgdx_6bc4874417625a637330083ea146c31472eccae1	buggy:  }  else  if  (Gdx.gl11  !=  null)  {  context:  buffer.clear();  buffer.put(indices,  offset,  count);  buffer.flip();  byteBuffer.position(0);  byteBuffer.limit(count  <<  1);  if  (isBound)  {  if  (Gdx.gl11  !=  null)  {  GL11  gl  =  Gdx.gl11;  gl.glBufferData(GL11.GL_ELEMENT_ARRAY_BUFFER,  byteBuffer.limit(),  byteBuffer,  usage);  }  else  if  (Gdx.gl11  !=  null)  {  }  else  if  (Gdx.gl20  !=  null)  {  GL20  gl  =  Gdx.gl20;  gl.glBufferData(GL20.GL_ELEMENT_ARRAY_BUFFER,  byteBuffer.limit(),  byteBuffer,  usage);  }  isDirty  =  false;  }  }  	}  else  if  (Gdx.gl20  !=  null)  {  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(dateHistogram( "date_histo ").interval(1)))  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(dateHistogram( "date_histo ").interval(1)))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(dateHistogram( "date_histo ").interval(1)))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(dateHistogram( "date_histo ").interval(1)))  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  generator  =  RestJsonBuilder.cached(request);  context:  SinglePingRequest  singlePingRequest  =  new  SinglePingRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  singlePingRequest.listenerThreaded(false);  singlePingRequest.threadedOperation(true);  client.admin().cluster().execPing(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {  try  {                      JsonBuilder  generator  =  RestJsonBuilder.cached(request);                      JsonBuilder  generator  =  RestJsonBuilder.restJsonBuilder(request);  generator.startObject().field( "ok ",  true).endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  generator));  }  catch  (Exception  e)  {  onFailure(e);  }  }  	JsonBuilder  generator  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_f974a172295faf525291a6b76a07f17e9b498052	buggy:  AbstractFragmentsBuilder  fragmentsBuilder;  context:  if  (fragments  !=  null  &&  fragments.length  >  0)  {  HighlightField  highlightField  =  new  HighlightField(fieldName,  StringText.convertFromStringArray(fragments));  highlightFields.put(highlightField.name(),  highlightField);  }  }  else  {  try  {  MapperHighlightEntry  entry  =  cache.mappers.get(mapper);  FieldQuery  fieldQuery  =  null;  if  (entry  ==  null)  {  FragListBuilder  fragListBuilder;                              AbstractFragmentsBuilder  fragmentsBuilder;                              BaseFragmentsBuilder  fragmentsBuilder;  BoundaryScanner  boundaryScanner  =  SimpleBoundaryScanner2.DEFAULT;  if  (field.boundaryMaxScan()  !=  SimpleBoundaryScanner2.DEFAULT_MAX_SCAN  ||  field.boundaryChars()  !=  SimpleBoundaryScanner2.DEFAULT_BOUNDARY_CHARS)  {  boundaryScanner  =  new  SimpleBoundaryScanner2(field.boundaryMaxScan(),  field.boundaryChars());  }  if  (field.numberOfFragments()  ==  0)  {  fragListBuilder  =  new  SingleFragListBuilder();  	BaseFragmentsBuilder  fragmentsBuilder;  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  if  (entry.bytes().unsafeByteArray().length  >  BYTES_LIMIT)  {  context:  }  Entry  entry  =  ref.poll();  if  (entry  ==  null)  {  return  newEntry();  }  counter.decrementAndGet();  return  entry;  }  public  static  void  pushEntry(Entry  entry)  {          if  (entry.bytes().unsafeByteArray().length  >  BYTES_LIMIT)  {          if  (entry.bytes().underlyingBytes().length  >  BYTES_LIMIT)  {  return;  }  Queue<Entry>  ref  =  cache.get();  if  (ref  ==  null)  {  ref  =  new  LinkedTransferQueue<Entry>();  cache.set(ref);  }  if  (counter.incrementAndGet()  >  COUNT_LIMIT)  {  	if  (entry.bytes().underlyingBytes().length  >  BYTES_LIMIT)  {  
elasticsearch_723a40ef34b634e0f7d8c0e77490ffa5cc004817	buggy:  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta).build();  context:  public  class  DateHistogramOffsetTests  extends  ElasticsearchIntegrationTest  {  private  DateTime  date(String  date)  {  return  DateFieldMapper.Defaults.DATE_TIME_FORMATTER.parser().parseDateTime(date);  }  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.builder()  .put(super.nodeSettings(nodeOrdinal))                  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta).build();                  .put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta1).build();  }  public  void  afterEachTest()  throws  IOException  {  internalCluster().wipeIndices( "idx2 ");  }  	.put(AssertingLocalTransport.ASSERTING_TRANSPORT_MIN_VERSION_KEY,  Version.V_1_4_0_Beta1).build();  
libgdx_c2d97ec73ae9767823a528b6168feb8aa9798b18	buggy:  font.setColor(fontColor);  context:  textPos.y  =  prefHeight;  invalidated  =  false;  }  protected  void  draw(SpriteBatch  batch,  float  parentAlpha)  {  final  BitmapFont  font  =  style.font;  final  Color  fontColor  =  style.fontColor;  if(invalidated)  layout();  font.setColor(fontColor);  font.setColor(fontColor.r,  fontColor.g,  fontColor.b,  fontColor.a  *  parentAlpha);  font.drawMultiLine(batch,  label,  x  +  textPos.x,  y  +  height);  }  protected  boolean  touchDown(float  x,  float  y,  int  pointer)  {  return  false;  }  	font.setColor(fontColor.r,  fontColor.g,  fontColor.b,  fontColor.a  *  parentAlpha);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.fs(),  request.transport(),  request.http());  context:  }  protected  NodeStats  newNodeResponse()  {  return  new  NodeStats();  }  protected  NodeStats  nodeOperation(NodeStatsRequest  nodeStatsRequest)  throws  ElasticSearchException  {  NodesStatsRequest  request  =  nodeStatsRequest.request;          return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.fs(),  request.transport(),  request.http());          return  nodeService.stats(request.isIndices(),  request.isOs(),  request.isProcess(),  request.isJvm(),  request.isThreadPool(),  request.isNetwork(),  request.isFs(),  request.isTransport(),  request.isHttp());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeStatsRequest  extends  NodeOperationRequest  {  	return  nodeService.stats(request.isIndices(),  request.isOs(),  request.isProcess(),  request.isJvm(),  request.isThreadPool(),  request.isNetwork(),  request.isFs(),  request.isTransport(),  request.isHttp());  
elasticsearch_93906903b6f0f813414e865ebece49ce2bb4e71c	buggy:  scriptField.script().setNextReader(hitContext.reader());  context:  }  public  boolean  hitExecutionNeeded(SearchContext  context)  {  return  context.hasScriptFields();  }  public  void  hitExecute(SearchContext  context,  HitContext  hitContext)  throws  ElasticSearchException  {  for  (ScriptFieldsContext.ScriptField  scriptField  :  context.scriptFields().fields())  {              scriptField.script().setNextReader(hitContext.reader());              scriptField.script().setNextReader(hitContext.readerContext());  scriptField.script().setNextDocId(hitContext.docId());  Object  value;  try  {  value  =  scriptField.script().run();  value  =  scriptField.script().unwrap(value);  }  catch  (RuntimeException  e)  {  if  (scriptField.ignoreException())  {  	scriptField.script().setNextReader(hitContext.readerContext());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  infos  =  new  ArrayList<ThreadPool.Info>(size);  context:  public  static  ThreadPoolInfo  readThreadPoolInfo(StreamInput  in)  throws  IOException  {  ThreadPoolInfo  info  =  new  ThreadPoolInfo();  info.readFrom(in);  return  info;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  int  size  =  in.readVInt();          infos  =  new  ArrayList<ThreadPool.Info>(size);          infos  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  ThreadPool.Info  info  =  new  ThreadPool.Info();  info.readFrom(in);  infos.add(info);  }  }  	infos  =  new  ArrayList<>(size);  
elasticsearch_645db6867b79ecade2bda27425b8d5a861281da6	buggy:  Settings  settings  =  ImmutableSettings.builder().put(settingsSource.node(nodeOrdinal)).put(defaultSettings).build();  context:  throw  new  IllegalArgumentException( "path  must  be  a  directory ");  }  this.path  =  path;  this.clusterName  =  clusterName;  this.random  =  new  Random(seed);  this.settingsSource  =  settingsSource;  }  synchronized  ExternalNode  start(Client  localNode,  Settings  defaultSettings,  String  nodeName,  String  clusterName,  int  nodeOrdinal)  throws  IOException,  InterruptedException  {  ExternalNode  externalNode  =  new  ExternalNode(path,  clusterName,  random.nextLong(),  settingsSource);          Settings  settings  =  ImmutableSettings.builder().put(settingsSource.node(nodeOrdinal)).put(defaultSettings).build();          Settings  settings  =  ImmutableSettings.builder().put(defaultSettings).put(settingsSource.node(nodeOrdinal)).build();  externalNode.startInternal(localNode,  settings,  nodeName,  clusterName);  return  externalNode;  }  synchronized  void  startInternal(Client  client,  Settings  settings,  String  nodeName,  String  clusterName)  throws  IOException,  InterruptedException  {  if  (process  !=  null)  {  throw  new  IllegalStateException( "Already  started ");  }  	Settings  settings  =  ImmutableSettings.builder().put(defaultSettings).put(settingsSource.node(nodeOrdinal)).build();  
elasticsearch_5706858722452b13465b15930e4f4cb2e8286449	buggy:  GetResult  getResult  =  indexShard.getService().get(type,  id,  fields,  request.realtime(),  version,  versionType,  fetchSourceContext);  context:  String[]  fields  =  request.fields.get(i);  long  version  =  request.versions.get(i);  VersionType  versionType  =  request.versionTypes.get(i);  if  (versionType  ==  null)  {  versionType  =  VersionType.INTERNAL;  }  FetchSourceContext  fetchSourceContext  =  request.fetchSourceContexts.get(i);  try  {                  GetResult  getResult  =  indexShard.getService().get(type,  id,  fields,  request.realtime(),  version,  versionType,  fetchSourceContext);                  GetResult  getResult  =  indexShard.getService().get(type,  id,  fields,  request.realtime(),  version,  versionType,  fetchSourceContext,  request.ignoreErrorsOnGeneratedFields());  response.add(request.locations.get(i),  new  GetResponse(getResult));  }  catch  (Throwable  t)  {  if  (TransportActions.isShardNotAvailableException(t))  {  throw  (ElasticsearchException)  t;  }  else  {  response.add(request.locations.get(i),  new  MultiGetResponse.Failure(request.index(),  type,  id,  ExceptionsHelper.detailedMessage(t)));  }  	GetResult  getResult  =  indexShard.getService().get(type,  id,  fields,  request.realtime(),  version,  versionType,  fetchSourceContext,  request.ignoreErrorsOnGeneratedFields());  
elasticsearch_9a13763315e8da781bf7f7b6e12c8819f9271513	buggy:  List<Object>  values  =  lookup.source().getValues(mapper.names().fullName());  context:  this.mapper  =  mapper;  this.searchContext  =  searchContext;  }  SearchLookup  lookup  =  searchContext.lookup();  lookup.setNextReader(reader);  lookup.setNextDocId(docId);          List<Object>  values  =  lookup.source().getValues(mapper.names().fullName());          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  Field[]  fields  =  new  Field[values.size()];  for  (int  i  =  0;  i  <  values.size();  i++)  {  fields[i]  =  new  Field(mapper.names().indexName(),  values.get(i).toString(),  Field.Store.NO,  Field.Index.ANALYZED);  }  return  fields;  }  }  	List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  TextButtonStyle  style  =  skin.getStyle(TextButtonStyle.class);  context:  return  true;  }  public  void  touchUp  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  }  });  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  TextButtonStyle  style  =  skin.getStyle(TextButtonStyle.class);  TextButtonStyle  style  =  skin.get(TextButtonStyle.class);  style.up  =  new  EmptyDrawable()  {  ShapeRenderer  renderer  =  new  ShapeRenderer();  public  void  draw  (SpriteBatch  batch,  float  x,  float  y,  float  width,  float  height)  {  batch.end();  renderer.setProjectionMatrix(batch.getProjectionMatrix());  renderer.setTransformMatrix(batch.getTransformMatrix());  renderer.begin(ShapeType.Line);  	TextButtonStyle  style  =  skin.get(TextButtonStyle.class);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(source,  true);  context:  sourceUnsafe  =  false;  source  =  in.readBytesReference();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeUTF(index);  out.writeUTF(type);          out.writeBytesReference(source,  true);          out.writeBytesReference(source);  }  }  	out.writeBytesReference(source);  
libgdx_d8394b19ba40b5d738282ed7451d5f4e6e12efcb	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  480,  320,  false  );  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  480,  320,  false  );  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  960,  640,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  960,  640,  false  );  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(long  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  LongFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  !=  1.0f);  LongFieldMapper  fieldMapper  =  new  LongFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  !=  1.0f);  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  listener.onFailure(new  NodeClosedException(clusterState.nodes().localNode()));  context:  public  void  postAdded()  {  if  (start(true))  {  clusterService.remove(this);  }  }  public  void  onClose()  {  clusterService.remove(this);                          listener.onFailure(new  NodeClosedException(clusterState.nodes().localNode()));                          listener.onFailure(new  NodeClosedException(clusterService.localNode()));  }  public  void  clusterChanged(ClusterChangedEvent  event)  {  if  (start(true))  {  clusterService.remove(this);  }  	listener.onFailure(new  NodeClosedException(clusterService.localNode()));  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  keyFieldData  =  fieldDataCache.cache(keyFieldDataType,  context.reader(),  keyFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  else  {  aggregator.valueFieldData  =  (NumericFieldData)  fieldDataCache.cache(valueFieldDataType,  context.reader(),  valueFieldName);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  keyFieldData.forEachValueInDoc(doc,  aggregator);  	script.setNextReader(context);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  buckets.release();  context:  return  (InternalGeoHashGrid)  aggregations.get(0);  }  final  int  size  =  (int)  Math.min(requiredSize,  buckets.size());  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size);  for  (LongObjectPagedHashMap.Cursor<List<Bucket>>  cursor  :  buckets)  {  List<Bucket>  sameCellBuckets  =  cursor.value;  ordered.insertWithOverflow(sameCellBuckets.get(0).reduce(sameCellBuckets,  reduceContext.bigArrays()));  }          buckets.release();          buckets.close();  Bucket[]  list  =  new  Bucket[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  ordered.pop();  }  reduced.buckets  =  Arrays.asList(list);  return  reduced;  }  	buckets.close();  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().allShardsGrouped(concreteIndices);  context:  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.refresh(new  Engine.Refresh(request.waitForOperations()));  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }          return  clusterState.routingTable().allShardsGrouped(concreteIndices);          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  
elasticsearch_04c16b7ba5658c928b9bdd7201ef41ab151540ae	buggy:  if  (!cursor.equals(metaData2.custom(cursor.key)))  return  false;  context:  if  (!metaData1.persistentSettings.equals(metaData2.persistentSettings))  {  return  false;  }  if  (!metaData1.templates.equals(metaData2.templates()))  {  return  false;  }  int  customCount1  =  0;  for  (ObjectObjectCursor<String,  Custom>  cursor  :  metaData1.customs)  {  if  (customFactories.get(cursor.key).isPersistent())  {                  if  (!cursor.equals(metaData2.custom(cursor.key)))  return  false;                  if  (!cursor.value.equals(metaData2.custom(cursor.key)))  return  false;  customCount1++;  }  }  int  customCount2  =  0;  for  (ObjectObjectCursor<String,  Custom>  cursor  :  metaData2.customs)  {  if  (customFactories.get(cursor.key).isPersistent())  {  customCount2++;  }  	if  (!cursor.value.equals(metaData2.custom(cursor.key)))  return  false;  
elasticsearch_3cee291bc2d9af7177f51804e82fca0663c8341a	buggy:  createIndexAction.execute(new  CreateIndexRequest(request.index()),  new  ActionListener<CreateIndexResponse>()  {  context:  protected  String  executor()  {  return  ThreadPool.Names.INDEX;  }  protected  void  doExecute(final  DeleteRequest  request,  final  ActionListener<DeleteResponse>  listener)  {  if  (autoCreateIndex  &&  !clusterService.state().metaData().hasConcreteIndex(request.index()))  {  request.beforeLocalFork();              createIndexAction.execute(new  CreateIndexRequest(request.index()),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  	createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
libgdx_0f0607810281eefd64ae695a59d132e69a887e1d	buggy:  texture  =  new  Texture(Gdx.files.internal( "data/ui.png "));  context:  public  class  PixelsPerInchTest  extends  GdxTest  {  BitmapFont  font;  SpriteBatch  batch;  Texture  texture;  font  =  new  BitmapFont();  batch  =  new  SpriteBatch();  texture  =  new  Texture(Gdx.files.internal( "data/ui.png "));  texture  =  new  Texture(Gdx.files.internal( "data/badlogicsmall.jpg "));  }  public  void  render  ()  {  Gdx.gl10.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  float  width  =  (int)(Gdx.graphics.getPpcX()  *  2);  float  height  =  (int)(Gdx.graphics.getPpcY()  *  1);  	texture  =  new  Texture(Gdx.files.internal( "data/badlogicsmall.jpg "));  
elasticsearch_658594fa70069d1fa0a1f87f074a02645dd5d4f6	buggy:  ClusterBlockException  blockException  =  checkBlock(request,  clusterState);  context:  if  (nodes.localNodeMaster()  ||  localExecute(request))  {  final  ClusterBlockException  blockException  =  checkBlock(request,  clusterState);  if  (blockException  !=  null)  {  if  (!blockException.retryable())  {  listener.onFailure(blockException);  return;  }  clusterService.add(request.masterNodeTimeout(),  new  TimeoutClusterStateListener()  {                          ClusterBlockException  blockException  =  checkBlock(request,  clusterState);                          ClusterBlockException  blockException  =  checkBlock(request,  clusterService.state());  if  (blockException  ==  null  ||  !blockException.retryable())  {  clusterService.remove(this);  innerExecute(request,  listener,  false);  }  }  clusterService.remove(this);  	ClusterBlockException  blockException  =  checkBlock(request,  clusterService.state());  
elasticsearch_7aa2d11cdd657f7ed2175a0f4ffecaf230ca449c	buggy:  createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  context:  protected  String  executor()  {  return  ThreadPool.Names.INDEX;  }  protected  void  doExecute(final  DeleteRequest  request,  final  ActionListener<DeleteResponse>  listener)  {  if  (autoCreateIndex.shouldAutoCreate(request.index(),  clusterService.state()))  {  request.beforeLocalFork();              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  	createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(delete  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_f8a08a46ac4bb34f9df23a22baae2021cbe0b541	buggy:  long  version  =  UidField.loadVersion(context,  new  Term(UidFieldMapper.NAME,  uid.toString()));  context:  public  boolean  acceptsDocsOutOfOrder()  {  return  true;  }  public  void  collect(int  doc)  {  try  {  UidAndRoutingFieldsVisitor  fieldsVisitor  =  new  UidAndRoutingFieldsVisitor();  context.reader().document(doc,  fieldsVisitor);  Uid  uid  =  fieldsVisitor.uid();                  long  version  =  UidField.loadVersion(context,  new  Term(UidFieldMapper.NAME,  uid.toString()));                  long  version  =  UidField.loadVersion(context,  new  Term(UidFieldMapper.NAME,  uid.toBytesRef()));  docsToPurge.add(new  DocToPurge(uid.type(),  uid.id(),  version,  fieldsVisitor.routing()));  }  catch  (Exception  e)  {  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  this.context  =  context;  	long  version  =  UidField.loadVersion(context,  new  Term(UidFieldMapper.NAME,  uid.toBytesRef()));  
elasticsearch_c087bbe804ff695f92ec157914dc6d61086be519	buggy:  if  (context.fieldNames().length  ==  0)  {  context:  throw  new  FetchPhaseExecutionException(context,   "Failed  to  fetch  doc  id  [ "  +  docId  +   "] ",  e);  }  return  doc;  }  private  FieldSelector  buildFieldSelectors(SearchContext  context)  {  if  (context.fieldNames()  ==  null)  {  return  new  UidAndSourceFieldSelector();  }          if  (context.fieldNames().length  ==  0)  {          if  (context.fieldNames().isEmpty())  {  return  new  UidFieldSelector();  }  FieldMappersFieldSelector  fieldSelector  =  new  FieldMappersFieldSelector();  for  (String  fieldName  :  context.fieldNames())  {  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);  if  (x  ==  null)  {  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "] ");  	if  (context.fieldNames().isEmpty())  {  
elasticsearch_d111e169a4d6aca4233ed147f75282dd5ab3bd91	buggy:  MetaData.Builder  mdBuilder  =  MetaData.builder().metaData(currentState.metaData());  context:  }  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {                  MetaData.Builder  mdBuilder  =  MetaData.builder().metaData(currentState.metaData());                  MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  boolean  globalFoundAtLeastOne  =  false;  for  (String  index  :  request.indices())  {  IndexMetaData  indexMetaData  =  currentState.metaData().index(index);  if  (indexMetaData  ==  null)  {  throw  new  IndexMissingException(new  Index(index));  }  IndexWarmersMetaData  warmers  =  indexMetaData.custom(IndexWarmersMetaData.TYPE);  	MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  
elasticsearch_0d57c4eafd56ae0c733bc30c5f81adb36496fe5b	buggy:  .masterNode().address()).address().getHostString())  context:  try  {  RestStatus  status  =  RestStatus.OK;  Table  tab  =  new  Table();  tab.addRow(new  Row()  .addCell( "id ")  .addCell( "transport  addr ")  .addCell( "name "),  true);  tab.addRow(new  Row()  .addCell(clusterStateResponse.getState().nodes().masterNode().id())  .addCell(((InetSocketTransportAddress)clusterStateResponse.getState().nodes()                                      .masterNode().address()).address().getHostString())                                      .masterNode().address()).address().getAddress().getHostAddress())  .addCell(clusterStateResponse.getState().nodes().masterNode().name()));  channel.sendResponse(new  StringRestResponse(status,  tab.render(verbose)));  }  catch  (Throwable  e)  {  onFailure(e);  }  }  	.masterNode().address()).address().getAddress().getHostAddress())  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  context:  String  parentType  =  childDocMapper.parentFieldMapper().type();  Filter  nonNestedDocsFilter  =  null;  if  (childDocMapper.hasNestedObjects())  {  nonNestedDocsFilter  =  parseContext.cacheFilter(NonNestedDocsFilter.INSTANCE,  null);  }  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  TopChildrenQuery  query  =  new  TopChildrenQuery(parentChildIndexFieldData,  innerQuery,  childType,  parentType,  scoreType,  factor,  incrementalFactor,  parseContext.cacheRecycler(),  nonNestedDocsFilter);  if  (queryName  !=  null)  {  parseContext.addNamedFilter(queryName,  new  CustomQueryWrappingFilter(query));  }  return  query;  }  }  	ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  
elasticsearch_cb0d89700ca316caf88ef342f47de979ccb8acb3	buggy:  .indexShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing());  context:  return   "indices/get/shard ";  }  state.blocks().indexBlockedRaiseException(ClusterBlockLevel.READ,  request.index());  }  return  clusterService.operationRouting()                  .indexShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing());                  .getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  }  if  (request.realtime  ==  null)  {  request.realtime  =  this.realtime;  }  MetaData  metaData  =  clusterService.state().metaData();  	.getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  
libgdx_3d5b25c4b1602fa62ab235181aa612ba877e0e20	buggy:  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  context:  bufferChanged();  }  public  void  updateVertices  (int  targetOffset,  float[]  vertices,  int  sourceOffset,  int  count)  {  isDirty  =  true;  if  (isDirect)  {  final  int  pos  =  byteBuffer.position();  byteBuffer.position(targetOffset  *  4);  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  byteBuffer.position(pos);  }  else  throw  new  GdxRuntimeException( "Buffer  must  be  allocated  direct. ");  //  Should  never  happen  bufferChanged();  }  	BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  nextIndex  =  currentIndex;  context:  }  }  public  void  remove  ()  {  if  (currentIndex  ==  INDEX_ZERO  &&  map.hasZeroValue)  {  map.hasZeroValue  =  false;  }  else  if  (currentIndex  <  0)  {  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  }  else  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  EMPTY;  }  currentIndex  =  INDEX_ILLEGAL;  map.size--;  }  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_1bcd3b67ee9f3462d6cac310b3be9a952f154b48	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null);  context:  return   "/cluster/ping/broadcast/shard ";  }  return  new  BroadcastPingRequest();  }          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null);          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null,  null);  }  int  successfulShards  =  0;  int  failedShards  =  0;  List<ShardOperationFailedException>  shardFailures  =  null;  for  (int  i  =  0;  i  <  shardsResponses.length();  i++)  {  Object  shardResponse  =  shardsResponses.get(i);  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null,  null);  
elasticsearch_25c1b93d57d86093b20844ab459803d3cb91a26c	buggy:  if  (now  >=  expire)  {  context:  long  ttl  =  context.sourceToParse().ttl();  if  (ttl  <=  0  &&  defaultTTL  >  0)  {  //  no  ttl  provided  so  we  use  the  default  value  ttl  =  defaultTTL;  context.sourceToParse().ttl(ttl);  }  if  (ttl  >  0)  {  //  a  ttl  has  been  provided  either  externally  or  in  the  _source  long  timestamp  =  context.sourceToParse().timestamp();  long  expire  =  new  Date(timestamp  +  ttl).getTime();  long  now  =  System.currentTimeMillis();                  if  (now  >=  expire)  {                  if  (context.sourceToParse().origin()  ==  SourceToParse.Origin.PRIMARY  &&  now  >=  expire)  {  throw  new  AlreadyExpiredException(context.index(),  context.type(),  context.id(),  timestamp,  ttl,  now);  }  return  new  CustomLongNumericField(this,  expire,  fieldType);  }  }  return  null;  }  	if  (context.sourceToParse().origin()  ==  SourceToParse.Origin.PRIMARY  &&  now  >=  expire)  {  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  t.getMessage()).endObject()));  context:  channel.sendResponse(new  JsonHttpResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  try  {  Throwable  t  =  unwrapCause(e);  if  (t  instanceof  IndexAlreadyExistsException  ||  t  instanceof  InvalidIndexNameException)  {                          channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  t.getMessage()).endObject()));                          channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  t.getMessage()).endObject()));  }  else  {  channel.sendResponse(new  JsonThrowableHttpResponse(request,  e));  }  }  catch  (IOException  e1)  {  }  }  });  	channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  t.getMessage()).endObject()));  
libgdx_3fea6c956ceaa0edc638bcbcb04017774cfb31e5	buggy:  table.add(new  Label(null,  i  +   "uno ",  new  LabelStyle(font,  Color.RED)));  context:  Container  table  =  new  Container(null,  0,  0);  FlickScrollPane  scroll  =  new  FlickScrollPane(null,  stage,  table,  0,  0);  container.add(scroll).expand(true,  true).fill(true,  true);  table.layout.parse( "pad:10  *  expand:x  space:4 ");  for  (int  i  =  0;  i  <  100;  i++)  {  table.row();  table.add(new  Label(null,  i  +   "uno ",  new  LabelStyle(font,  Color.RED)));  table.add(new  Label(null,  i  +   "uno ",  new  LabelStyle(font,  Color.RED))).expand(true,  false).fill(true,  false);  table.add(new  Label(null,  i  +   "dos ",  new  LabelStyle(font,  Color.RED)));  table.add(new  Label(null,  i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9 ",  new  LabelStyle(font,  Color.RED)));  }  container.row();  container.add(new  Label(null,   "stuff  at  bottom! ",  new  LabelStyle(font,  Color.WHITE))).pad(20,  20,  20,  20);  }  	table.add(new  Label(null,  i  +   "uno ",  new  LabelStyle(font,  Color.RED))).expand(true,  false).fill(true,  false);  
elasticsearch_06da379f5045e0c1d7436a7757400f9ba5b7f993	buggy:  if  (smartNameFieldMappers.hasDocMapper())  {  context:  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  prefix  query ");  }  MultiTermQuery.RewriteMethod  method  =  QueryParsers.parseRewriteMethod(rewriteMethod);  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              if  (smartNameFieldMappers.hasDocMapper())  {              if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  query  =  smartNameFieldMappers.mapper().prefixQuery(value,  method,  parseContext);  }  finally  {  QueryParseContext.setTypes(previousTypes);  }  }  else  {  query  =  smartNameFieldMappers.mapper().prefixQuery(value,  method,  parseContext);  	if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  
libgdx_e069a5993224598b7ac673fcd62f16da5ca48302	buggy:  return  Build.VERSION.SDK.charAt(0)  -  '0';  context:  public  ApplicationType  getType()  {  return  ApplicationType.Android;  }  public  int  getVersion()  {          return  Build.VERSION.SDK.charAt(0)  -  '0';      return  Integer.parseInt(android.os.Build.VERSION.SDK);  }  public  long  getJavaHeap()  {  return  Runtime.getRuntime().totalMemory()  -  Runtime.getRuntime().freeMemory();  }  	return  Integer.parseInt(android.os.Build.VERSION.SDK);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  }  explain  =  in.readBoolean();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  out.writeBoolean(explain);  }  	out.writeBytesReference(querySource);  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  context:  public  class  ElectReplicaAsPrimaryDuringRelocationTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(ElectReplicaAsPrimaryDuringRelocationTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(2).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  
elasticsearch_596f9db8d81aad5b3b583de9c8ec1bd3d92a289f	buggy:  return  facetsAsMap;  context:  public  List<Facet>  facets()  {  return  facets;  }  public  Map<String,  Facet>  getFacets()  {          return  facetsAsMap;          return  facetsAsMap();  }  public  Map<String,  Facet>  facetsAsMap()  {  if  (facetsAsMap  !=  null)  {  return  facetsAsMap;  	return  facetsAsMap();  
elasticsearch_4ff1b429f1351c17ae5f3a4338a7ac33db49ef70	buggy:  if  (primaryNodeStore.fileExists(storeFileMetaData.name())  &&  primaryNodeStore.file(storeFileMetaData.name()).length()  ==  storeFileMetaData.length())  {  context:  if  (!shard.primary())  {  MutableShardRouting  primaryShard  =  routingNodes.findPrimaryForReplica(shard);  if  (primaryShard  !=  null  &&  primaryShard.active())  {  DiscoveryNode  primaryNode  =  nodes.get(primaryShard.currentNodeId());  if  (primaryNode  !=  null)  {  TransportNodesListShardStoreMetaData.StoreFilesMetaData  primaryNodeStore  =  shardStores.get(primaryNode);  if  (primaryNodeStore  !=  null  &&  primaryNodeStore.allocated())  {  long  sizeMatched  =  0;  for  (StoreFileMetaData  storeFileMetaData  :  storeFilesMetaData)  {                                      if  (primaryNodeStore.fileExists(storeFileMetaData.name())  &&  primaryNodeStore.file(storeFileMetaData.name()).length()  ==  storeFileMetaData.length())  {                                      if  (primaryNodeStore.fileExists(storeFileMetaData.name())  &&  primaryNodeStore.file(storeFileMetaData.name()).isSame(storeFileMetaData))  {  sizeMatched  +=  storeFileMetaData.length();  }  }  if  (sizeMatched  >  lastSizeMatched)  {  lastSizeMatched  =  sizeMatched;  lastDiscoNodeMatched  =  discoNode;  lastNodeMatched  =  node;  }  	if  (primaryNodeStore.fileExists(storeFileMetaData.name())  &&  primaryNodeStore.file(storeFileMetaData.name()).isSame(storeFileMetaData))  {  
elasticsearch_4f96b3637643ea2b9e4ddf58b1858c04aea27388	buggy:  if  (fieldType().stored()  !=  Defaults.FIELD_TYPE.stored())  {  context:  return  CONTENT_TYPE;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (fieldType().stored()  ==  Defaults.FIELD_TYPE.stored()  &&  enabledState  ==  Defaults.ENABLED_STATE)  {  return  builder;  }  builder.startObject(CONTENT_TYPE);          if  (fieldType().stored()  !=  Defaults.FIELD_TYPE.stored())  {          if  (fieldType().stored()  !=  Defaults.FIELD_TYPE.stored()  &&  enabledState.enabled)  {  builder.field( "store ",  fieldType().stored());  }  if  (enabledState  !=  Defaults.ENABLED_STATE)  {  builder.field( "enabled ",  enabledState.enabled);  }  builder.endObject();  return  builder;  }  	if  (fieldType().stored()  !=  Defaults.FIELD_TYPE.stored()  &&  enabledState.enabled)  {  
libgdx_bab56d4e4c643aa2c447fb61a7532fcf41130864	buggy:  if(  minor  <  5  )  context:  int  major  =  Integer.parseInt( " "  +  version.charAt(0));  int  minor  =  Integer.parseInt( " "  +  version.charAt(2));  if(  useGL2  &&  major  >=  2  )  {  gl20  =  new  JoglGL20(  graphicPanel.getGL()  );  }  else  {  if(  minor  <  5  )  if(  major  ==  1  &&  minor  <  5  )  {  gl10  =  new  JoglGL10(  graphicPanel.getGL()  );  }  else  {  gl11  =  new  JoglGL11(  graphicPanel.getGL()  );  gl10  =  gl11;  }  	if(  major  ==  1  &&  minor  <  5  )  
libgdx_6ac205c949ac9550ecd4badd41a793b6efd2c2c4	buggy:  config.useGL20  =  false;  context:  package  com.badlogic.gdx.tests.lwjgl;  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  false;  config.useGL20  =  true;  config.vSyncEnabled  =  true;  new  LwjglApplication(new  ShapeRendererTest(),  config);  }  }  	config.useGL20  =  true;  
elasticsearch_8ccfca3a2f0193f0a4da38e206c35cf08402218f	buggy:  subs[i]  =  atomicFD[i].getTermsEnum();  context:  public  IndexFieldData.WithOrdinals  build(final  IndexReader  indexReader,  IndexFieldData.WithOrdinals  indexFieldData,  Settings  settings,  CircuitBreakerService  breakerService)  throws  IOException  {  assert  indexReader.leaves().size()  >  1;  long  startTime  =  System.currentTimeMillis();  final  AtomicFieldData.WithOrdinals<?>[]  atomicFD  =  new  AtomicFieldData.WithOrdinals[indexReader.leaves().size()];  final  TermsEnum[]  subs  =  new  TermsEnum[indexReader.leaves().size()];  for  (int  i  =  0;  i  <  indexReader.leaves().size();  ++i)  {  atomicFD[i]  =  indexFieldData.load(indexReader.leaves().get(i));              subs[i]  =  atomicFD[i].getTermsEnum();              subs[i]  =  atomicFD[i].getBytesValues().getTermsEnum();  }  final  OrdinalMap  ordinalMap  =  new  OrdinalMap(null,  subs);  final  long  memorySizeInBytes  =  ordinalMap.ramBytesUsed();  breakerService.getBreaker().addWithoutBreaking(memorySizeInBytes);  if  (logger.isDebugEnabled())  {   "Global-ordinals[{}][{}]  took  {}  ms ",  	subs[i]  =  atomicFD[i].getBytesValues().getTermsEnum();  
libgdx_b299dbe195bbcde4e8509c8aca1b4afe853903bb	buggy:  pref  =  new  GwtPreferences();  context:  public  long  getNativeHeap  ()  {  return  0;  }  public  Preferences  getPreferences  (String  name)  {  Preferences  pref  =  prefs.get(name);  if(pref  ==  null)  {  pref  =  new  GwtPreferences();  pref  =  new  GwtPreferences(name);  prefs.put(name,  pref);  }  return  pref;  }  public  void  postRunnable  (Runnable  runnable)  {  runnables.add(runnable);  	pref  =  new  GwtPreferences(name);  
libgdx_4c58307a70ef9881454a2826d5dd777c2c549646	buggy:  event.pointer  =  0;  context:  input.touchX[pointerId]  =  x;  input.touchY[pointerId]  =  y;  }  break;  }  }  private  void  postTouchEvent  (AndroidInput  input,  int  type,  int  x,  int  y,  int  pointer)  {  synchronized  (input)  {  TouchEvent  event  =  input.freeTouchEvents.newObject();  event.pointer  =  0;  event.pointer  =  pointer;  event.x  =  x;  event.y  =  y;  event.type  =  type;  input.touchEvents.add(event);  }  }  public  boolean  supportsMultitouch  (AndroidApplication  activity)  {  	event.pointer  =  pointer;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<Object>(2));  context:  }  public  void  hitExecute(SearchContext  context,  HitContext  hitContext)  throws  ElasticsearchException  {  for  (FieldDataFieldsContext.FieldDataField  field  :  context.fieldDataFields().fields())  {  if  (hitContext.hit().fieldsOrNull()  ==  null)  {  hitContext.hit().fields(new  HashMap<String,  SearchHitField>(2));  }  SearchHitField  hitField  =  hitContext.hit().fields().get(field.name());  if  (hitField  ==  null)  {                  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<Object>(2));                  hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<>(2));  hitContext.hit().fields().put(field.name(),  hitField);  }  FieldMapper  mapper  =  context.mapperService().smartNameFieldMapper(field.name());  if  (mapper  !=  null)  {  AtomicFieldData  data  =  context.fieldData().getForField(mapper).load(hitContext.readerContext());  ScriptDocValues  values  =  data.getScriptValues();  values.setNextDocId(hitContext.docId());  hitField.values().addAll(values.getValues());  	hitField  =  new  InternalSearchHitField(field.name(),  new  ArrayList<>(2));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  searcher.release();  context:  throw  new  ElasticsearchIllegalArgumentException( "suggest  content  missing ");  }  final  SuggestionSearchContext  context  =  suggestPhase.parseElement().parseInternal(parser,  indexService.mapperService(),  request.index(),  request.shardId());  final  Suggest  result  =  suggestPhase.execute(context,  searcher.reader());  return  new  ShardSuggestResponse(request.index(),  request.shardId(),  result);  }  return  new  ShardSuggestResponse(request.index(),  request.shardId(),  new  Suggest());  }  catch  (Throwable  ex)  {  throw  new  ElasticsearchException( "failed  to  execute  suggest ",  ex);  }  finally  {              searcher.release();              searcher.close();  if  (parser  !=  null)  {  parser.close();  }  shardSuggestService.postSuggest(System.nanoTime()  -  startTime);  }  }  }  	searcher.close();  
libgdx_621e33745ea68d1722609aae0a5a4c5d2cc0d06e	buggy:  viewController.getInterfaceOrientation();  context:  CGSize  getBounds  (UIViewController  viewController)  {  CGSize  bounds  =  UIScreen.getMainScreen().getApplicationFrame().size();  UIInterfaceOrientation  orientation;  if  (viewController  !=  null)  {  viewController.getInterfaceOrientation();  orientation  =  viewController.getInterfaceOrientation();  }  else  if  (config.orientationLandscape  ==  config.orientationPortrait)  {  orientation  =  uiApp.getStatusBarOrientation();  }  else  if  (config.orientationLandscape)  {//  is  landscape  true  and  portrait  false  orientation  =  UIInterfaceOrientation.LandscapeRight;  	orientation  =  viewController.getInterfaceOrientation();  
elasticsearch_db7b6097cc58a2a67dbdd3fe8c698fb2755bd032	buggy:  this.used.addAndGet(-bytes);  context:  }  while  (!this.used.compareAndSet(currentUsed,  newUsed));  }  try  {  parent.checkParentLimit(label);  }  catch  (CircuitBreakingException  e)  {              this.used.addAndGet(-bytes);              this.addWithoutBreaking(-bytes);  throw  e;  }  return  newUsed;  }  	this.addWithoutBreaking(-bytes);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<AllocationDecider>  list  =  new  ArrayList<AllocationDecider>();  context:  }  public  static  AllocationService  createAllocationService(Settings  settings,  Random  random)  {  return  new  AllocationService(settings,  randomAllocationDeciders(settings,  new  NodeSettingsService(ImmutableSettings.Builder.EMPTY_SETTINGS),  random),  new  ShardsAllocators(settings),  ClusterInfoService.EMPTY);  }  public  static  AllocationDeciders  randomAllocationDeciders(Settings  settings,  NodeSettingsService  nodeSettingsService,  Random  random)  {  final  ImmutableSet<Class<?  extends  AllocationDecider>>  defaultAllocationDeciders  =  AllocationDecidersModule.DEFAULT_ALLOCATION_DECIDERS;          final  List<AllocationDecider>  list  =  new  ArrayList<AllocationDecider>();          final  List<AllocationDecider>  list  =  new  ArrayList<>();  for  (Class<?  extends  AllocationDecider>  deciderClass  :  defaultAllocationDeciders)  {  try  {  try  {  Constructor<?  extends  AllocationDecider>  constructor  =  deciderClass.getConstructor(Settings.class,  NodeSettingsService.class);  list.add(constructor.newInstance(settings,  nodeSettingsService));  }  catch  (NoSuchMethodException  e)  {  Constructor<?  extends  AllocationDecider>  constructor  =  null;  constructor  =  deciderClass.getConstructor(Settings.class);  	final  List<AllocationDecider>  list  =  new  ArrayList<>();  
elasticsearch_3afe4da55078e7b14eb4f7ef38d897c7f0f7f13d	buggy:  querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceLength);  context:  public  DeleteByQueryRequest  indices(String...  indices)  {  this.indices  =  indices;  return  this;  }  byte[]  querySource()  {  if  (querySourceUnsafe  ||  querySourceOffset  >  0)  {              querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceLength);              querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceOffset  +  querySourceLength);  querySourceOffset  =  0;  querySourceUnsafe  =  false;  }  return  querySource;  }  	querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceOffset  +  querySourceLength);  
libgdx_e81e2cd18869ab795210326049214f733e1c3f66	buggy:  if  (def.type  ==  JointType.GearJoint)  joint  =  new  GearJoint(this,  jointAddr);  context:  public  Joint  createJoint  (JointDef  def)  {  long  jointAddr  =  createProperJoint(def);  Joint  joint  =  null;  if  (def.type  ==  JointType.DistanceJoint)  joint  =  new  DistanceJoint(this,  jointAddr);  if  (def.type  ==  JointType.FrictionJoint)  joint  =  new  FrictionJoint(this,  jointAddr);  if  (def.type  ==  JointType.GearJoint)  joint  =  new  GearJoint(this,  jointAddr);  if  (def.type  ==  JointType.GearJoint)  joint  =  new  GearJoint(this,  jointAddr,  ((GearJointDef)  def).joint1,  ((GearJointDef)  def).joint2);  if  (def.type  ==  JointType.MouseJoint)  joint  =  new  MouseJoint(this,  jointAddr);  if  (def.type  ==  JointType.PrismaticJoint)  joint  =  new  PrismaticJoint(this,  jointAddr);  if  (def.type  ==  JointType.PulleyJoint)  joint  =  new  PulleyJoint(this,  jointAddr);  if  (def.type  ==  JointType.RevoluteJoint)  joint  =  new  RevoluteJoint(this,  jointAddr);  if  (def.type  ==  JointType.WeldJoint)  joint  =  new  WeldJoint(this,  jointAddr);  if  (def.type  ==  JointType.RopeJoint)  joint  =  new  RopeJoint(this,  jointAddr);  if  (def.type  ==  JointType.WheelJoint)  joint  =  new  WheelJoint(this,  jointAddr);  if  (joint  !=  null)  joints.put(joint.addr,  joint);  	if  (def.type  ==  JointType.GearJoint)  joint  =  new  GearJoint(this,  jointAddr,  ((GearJointDef)  def).joint1,  ((GearJointDef)  def).joint2);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  final  BytesValues  values  =  fieldData.load(context).getBytesValues(false);  //  load  fielddata  context:  .append( ": ")  .append(terms  !=  null  ?  terms.toString()  :   " ")  .toString();  }  public  DocIdSet  getDocIdSet(AtomicReaderContext  context,  Bits  acceptDocs)  throws  IOException  {  if  (terms  ==  null  ||  terms.isEmpty())  return  null;              final  BytesValues  values  =  fieldData.load(context).getBytesValues(false);  //  load  fielddata              final  BytesValues  values  =  fieldData.load(context).getBytesValues();  //  load  fielddata  return  new  MatchDocIdSet(context.reader().maxDoc(),  acceptDocs)  {  protected  boolean  matchDoc(int  doc)  {  final  int  numVals  =  values.setDocument(doc);  for  (int  i  =  0;  i  <  numVals;  i++)  {  if  (terms.contains(values.nextValue()))  {  return  true;  }  	final  BytesValues  values  =  fieldData.load(context).getBytesValues();  //  load  fielddata  
elasticsearch_476e28f4ce5923bd95d2f7170a04edf319c20d92	buggy:  AbortBenchmarkRequestBuilder  prepareAbortBench(String  benchmarkId);  context:  BenchmarkRequestBuilder  prepareBench(String...  indices);  void  abortBench(AbortBenchmarkRequest  request,  ActionListener<AbortBenchmarkResponse>  listener);      AbortBenchmarkRequestBuilder  prepareAbortBench(String  benchmarkId);      AbortBenchmarkRequestBuilder  prepareAbortBench(String...  benchmarkNames);  void  benchStatus(BenchmarkStatusRequest  request,  ActionListener<BenchmarkStatusResponse>  listener);  	AbortBenchmarkRequestBuilder  prepareAbortBench(String...  benchmarkNames);  
elasticsearch_965d7303cf237397f72720f9fdb9babb32904d68	buggy:  shardStatus.docs  =  new  ShardStatus.Docs();  context:  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  shardStatus.translogId  =  indexShard.translog().currentId();  shardStatus.translogOperations  =  indexShard.translog().size();  Engine.Searcher  searcher  =  indexShard.searcher();  try  {                  shardStatus.docs  =  new  ShardStatus.Docs();                  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {  searcher.release();  }  }  	shardStatus.docs  =  new  DocsStatus();  
libgdx_c64a9d86f2a70f4e9cc4715927afadb7c96b7ba6	buggy:  modelBatch.render(lights,  instance);  context:  shapeRenderer.setColor(Color.GREEN);  shapeRenderer.line(0,  0,  0,  0,  100,  0);  shapeRenderer.setColor(Color.BLUE);  shapeRenderer.line(0,  0,  0,  0,  0,  100);  shapeRenderer.end();  instance.transform.idt();  instance.transform.translate(0,  0,  3);  modelBatch.begin(cam);  modelBatch.render(lights,  instance);  modelBatch.render(instance,  lights);  modelBatch.end();  }  public  void  dispose  ()  {  model.dispose();  modelBatch.dispose();  }  	modelBatch.render(instance,  lights);  
elasticsearch_b078c9206a71d639ee76fa5b6a8b44344e797d98	buggy:  logger.warn( "[{}][{}]  failed  to  delete  shard  after  failed  startup ",  e,  indexService.index().name(),  shardRouting.id());  context:  }  }  }  }  catch  (Exception  e)  {  if  (indexService.hasShard(shardId))  {  try  {  indexService.cleanShard(shardId);  }  catch  (Exception  e1)  {                              logger.warn( "[{}][{}]  failed  to  delete  shard  after  failed  startup ",  e,  indexService.index().name(),  shardRouting.id());                              logger.warn( "[{}][{}]  failed  to  delete  shard  after  failed  startup ",  e1,  indexService.index().name(),  shardRouting.id());  }  }  try  {  shardStateAction.shardFailed(shardRouting,   "Failed  to  start  shard,  message  [ "  +  detailedMessage(e)  +   "] ");  }  catch  (Exception  e1)  {  }  }  	logger.warn( "[{}][{}]  failed  to  delete  shard  after  failed  startup ",  e1,  indexService.index().name(),  shardRouting.id());  
elasticsearch_b2db7c8222cbc2a33e06c31de6f59862d2f6c6f3	buggy:  protected  void  doPostCollection()  {  context:  aggregators  =  bigArrays.newObjectArray(arraySize);  aggregators.set(0,  first);  }  public  boolean  shouldCollect()  {  return  first.shouldCollect();  }                  protected  void  doPostCollection()  {                  protected  void  doPostCollection()  throws  IOException  {  for  (long  i  =  0;  i  <  aggregators.size();  ++i)  {  final  Aggregator  aggregator  =  aggregators.get(i);  if  (aggregator  !=  null)  {  aggregator.postCollection();  }  }  }  	protected  void  doPostCollection()  throws  IOException  {  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  logger.trace( "[{}][{}]  recovery  from  [{}]  failed ",  e,  request.shardId().index().name(),  request.shardId().id(),  request.sourceNode());  context:  if  (cause  instanceof  IndexShardClosedException)  {  listener.onIgnoreRecovery(true,   "source  shard  is  closed  ( "  +  request.sourceNode()  +   ") ");  return;  }  if  (cause  instanceof  AlreadyClosedException)  {  listener.onIgnoreRecovery(true,   "source  shard  is  closed  ( "  +  request.sourceNode()  +   ") ");  return;  }              logger.trace( "[{}][{}]  recovery  from  [{}]  failed ",  e,  request.shardId().index().name(),  request.shardId().id(),  request.sourceNode());              logger.warn( "[{}][{}]  recovery  from  [{}]  failed ",  e,  request.shardId().index().name(),  request.shardId().id(),  request.sourceNode());  listener.onRecoveryFailure(new  RecoveryFailedException(request,  e),  true);  }  }  public  static  interface  RecoveryListener  {  void  onRecoveryDone();  void  onRetryRecovery(TimeValue  retryAfter,  RecoveryStatus  status);  	logger.warn( "[{}][{}]  recovery  from  [{}]  failed ",  e,  request.shardId().index().name(),  request.shardId().id(),  request.sourceNode());  
libgdx_93e7685506a671b5a0ac0cc5230e52a39f5fdf29	buggy:  new  LwjglApplication(new  com.badlogic.gdx.tests.UITest(),   "UI  Test ",  480,  320,  false);  context:  ++  libgdx_93e7685506a671b5a0ac0cc5230e52a39f5fdf29_159.java  package  com.badlogic.gdx.tests.lwjgl;  public  class  LwjglDebugStarter  {  public  static  void  main(String[]  argv)  {  new  LwjglApplication(new  com.badlogic.gdx.tests.UITest(),   "UI  Test ",  480,  320,  false);  new  LwjglApplication(new  com.badlogic.gdx.tests.VBOVATest(),   "UI  Test ",  480,  320,  false);  }  }  	new  LwjglApplication(new  com.badlogic.gdx.tests.VBOVATest(),   "UI  Test ",  480,  320,  false);  
elasticsearch_1acca2050c8220a3663e661311a25313da17535b	buggy:  builder.field( "date_detection ",  Defaults.DATE_DETECTION);  context:  for  (DynamicTemplate  dynamicTemplate  :  dynamicTemplates)  {  builder.startObject();  builder.field(dynamicTemplate.name());  builder.map(dynamicTemplate.conf());  builder.endObject();  }  builder.endArray();  }  if  (dateDetection  !=  Defaults.DATE_DETECTION)  {              builder.field( "date_detection ",  Defaults.DATE_DETECTION);              builder.field( "date_detection ",  dateDetection);  }  }  }  	builder.field( "date_detection ",  dateDetection);  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  nextIndex  =  currentIndex;  context:  }  public  void  remove  ()  {  if  (currentIndex  ==  INDEX_ZERO  &&  map.hasZeroValue)  {  map.zeroValue  =  null;  map.hasZeroValue  =  false;  }  else  if  (currentIndex  <  0)  {  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  }  else  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  EMPTY;  map.valueTable[currentIndex]  =  null;  }  currentIndex  =  INDEX_ILLEGAL;  map.size--;  }  	nextIndex  =  currentIndex  -  1;  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  true);  context:  public  void  render  ()  {  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  Table.drawDebug(stage);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
elasticsearch_b009c9c6521fced35371eb4e73f616cd247da54f	buggy:  indexInput  =  snapshot.getDirectory().openInput(name);  context:  final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();  for  (final  String  name  :  response.phase1FileNames)  {  recoverySettings.concurrentStreamPool().execute(new  Runnable()  {  public  void  run()  {  IndexInput  indexInput  =  null;  try  {  final  int  BUFFER_SIZE  =  (int)  recoverySettings.fileChunkSize().bytes();  byte[]  buf  =  new  byte[BUFFER_SIZE];  StoreFileMetaData  md  =  shard.store().metaData(name);                                      indexInput  =  snapshot.getDirectory().openInput(name);                                      indexInput  =  shard.store().openInputRaw(name);  long  len  =  indexInput.length();  long  readCount  =  0;  while  (readCount  <  len)  {  if  (shard.state()  ==  IndexShardState.CLOSED)  {  //  check  if  the  shard  got  closed  on  us  throw  new  IndexShardClosedException(shard.shardId());  }  int  toRead  =  readCount  +  BUFFER_SIZE  >  len  ?  (int)  (len  -  readCount)  :  BUFFER_SIZE;  long  position  =  indexInput.getFilePointer();  	indexInput  =  shard.store().openInputRaw(name);  
libgdx_24be4cdfe2a884863ae01bea386f7927120d88db	buggy:  public  static  native  void  convertToShort  (FloatBuffer  source,  FloatBuffer  target,  int  numSamples);  context:  public  static  native  void  convertToShort  (FloatBuffer  source,  FloatBuffer  target,  int  numSamples);  public  static  native  void  convertToShort  (FloatBuffer  source,  ShortBuffer  target,  int  numSamples);  	public  static  native  void  convertToShort  (FloatBuffer  source,  ShortBuffer  target,  int  numSamples);  
elasticsearch_d2bf446d9c47ed8acb9c792b6137da40141b8fe1	buggy:  listener.onFailure(new  ReplicationShardOperationFailedException(shards.shardId(),  e));  context:  public  boolean  start(final  boolean  fromClusterEvent)  throws  ElasticSearchException  {  ClusterState  clusterState  =  clusterService.state();  nodes  =  clusterState.nodes();  try  {  shards  =  shards(request);  }  catch  (Exception  e)  {                  listener.onFailure(new  ReplicationShardOperationFailedException(shards.shardId(),  e));                  listener.onFailure(e);  return  true;  }  boolean  foundPrimary  =  false;  for  (final  ShardRouting  shard  :  shards)  {  if  (shard.primary())  {  if  (!shard.active())  {  retryPrimary(fromClusterEvent,  shard);  	listener.onFailure(e);  
libgdx_997ab4fe33556a880ade79e6bb25375f4aa13d7f	buggy:  new  LwjglApplication(new  com.badlogic.gdx.tests.SpriteCacheTest(),  config);  context:  package  com.badlogic.gdx.tests.lwjgl;  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  new  LwjglApplication(new  com.badlogic.gdx.tests.SpriteCacheTest(),  config);  new  LwjglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  }  }  	new  LwjglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  
elasticsearch_596d511466c279c8f5e808599c3aff19e029c477	buggy:  QueriesLoaderCollector  queryCollector  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  context:  private  void  loadQueries(IndexShard  shard)  {  try  {  shard.refresh(new  Engine.Refresh( "percolator_load_queries ").force(true));  Engine.Searcher  searcher  =  shard.acquireSearcher( "percolator_load_queries ");  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.TYPE_NAME))  )  );                      QueriesLoaderCollector  queryCollector  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);                      QueriesLoaderCollector  queryCollector  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  mapperService,  indexFieldDataService);  searcher.searcher().search(query,  queryCollector);  Map<HashedBytesRef,  Query>  queries  =  queryCollector.queries();  for  (Map.Entry<HashedBytesRef,  Query>  entry  :  queries.entrySet())  {  Query  previousQuery  =  percolateQueries.put(entry.getKey(),  entry.getValue());  shardPercolateService.addedQuery(entry.getKey(),  previousQuery,  entry.getValue());  }  }  finally  {  searcher.release();  	QueriesLoaderCollector  queryCollector  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  mapperService,  indexFieldDataService);  
libgdx_7783ad3e5eb7217c317a281ececc62517270d259	buggy:  cache.add(texture,  tileX,  tileY,  rand.nextInt(2)  *  54,  0,TILE_WIDTH,  TILE_HEIGHT,  Color.WHITE);  context:  caches[i]  =  new  SpriteCache();  SpriteCache  cache  =  caches[i];  cache.beginCache();  int  colX  =  HEIGHT  *  TILE_WIDTH  /  2  -  TILE_WIDTH  /  2;  int  colY  =  BOUND_Y  -  TILE_HEIGHT_DIAMOND;  for(int  x=0;  x  <  WIDTH;  x++)  {  for(int  y=0;  y  <  HEIGHT;  y++)  {  int  tileX  =  colX  -  y  *  TILE_WIDTH  /  2;  int  tileY  =  colY  -  y  *  TILE_HEIGHT_DIAMOND  /  2;  cache.add(texture,  tileX,  tileY,  rand.nextInt(2)  *  54,  0,TILE_WIDTH,  TILE_HEIGHT,  Color.WHITE);  cache.add(texture,  tileX,  tileY,  rand.nextInt(2)  *  54,  0,TILE_WIDTH,  TILE_HEIGHT);  }  colX  +=  TILE_WIDTH  /  2;  colY  -=  TILE_HEIGHT_DIAMOND  /  2;  }  layers[i]  =  cache.endCache();  }  }  	cache.add(texture,  tileX,  tileY,  rand.nextInt(2)  *  54,  0,TILE_WIDTH,  TILE_HEIGHT);  
elasticsearch_3450e82855df8594df4644fd2f3206d1b679a08e	buggy:  .put(super.nodeSettings(nodeOrdinal))  context:  .put(super.nodeSettings(nodeOrdinal))  .build();  }  protected  Settings  externalNodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.settingsBuilder()  .put( "transport.tcp.port ",  9390  +  nodeOrdinal)  .put( "discovery.zen.ping.multicast.enabled ",  false)  .put( "discovery.zen.ping.unicast.hosts ",   "localhost:9380,localhost:9381,localhost:9390,localhost:9391 ")                  .put(super.nodeSettings(nodeOrdinal))                  .put(super.externalNodeSettings(nodeOrdinal))  .build();  }  public  void  testUnicastDiscovery()  {  ClusterHealthResponse  healthResponse  =  client().admin().cluster().prepareHealth().get();  assertThat(healthResponse.getNumberOfDataNodes(),  equalTo(cluster().numDataNodes()));  }  	.put(super.externalNodeSettings(nodeOrdinal))  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:   "tests.assertion.disabled ",   "tests.security.manager ");  context:  return  this;  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TestCluster.TESTS_ENABLE_MOCK_MODULES,                       "tests.assertion.disabled ",   "tests.security.manager ");                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  return  this;  }  protected  ReproduceErrorMessageBuilder  appendProperties(String...  properties)  {  for  (String  sysPropName  :  properties)  {  	 "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ");  
elasticsearch_b80eee305e2fc4b9c7e3dee0c0af797047dea891	buggy:  builder.field( "type ",  type.toString().toLowerCase());  context:  return  this;  }  public  void  doXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(TextQueryParser.NAME);  builder.startObject(name);  builder.field( "query ",  text);  if  (type  !=  null)  {              builder.field( "type ",  type.toString().toLowerCase());              builder.field( "type ",  type.toString().toLowerCase(Locale.ENGLISH));  }  if  (operator  !=  null)  {  builder.field( "operator ",  operator.toString());  }  if  (analyzer  !=  null)  {  builder.field( "analyzer ",  analyzer);  }  if  (boost  !=  null)  {  	builder.field( "type ",  type.toString().toLowerCase(Locale.ENGLISH));  
libgdx_22deb2e572586fd56b080714cd706501de3403b4	buggy:  tests[testIndex].destroy();  context:  if  (this.app  ==  null)  {  this.app  =  Gdx.app;  Box2DTest  test  =  tests[testIndex];  test.create();  }  }  if  (keycode  ==  Keys.KEYCODE_SPACE)  {  app.log( "TestCollection ",   "disposing  test  ' "  +  tests[testIndex].getClass().getName());  tests[testIndex].destroy();  tests[testIndex].dispose();  testIndex++;  if  (testIndex  >=  tests.length)  testIndex  =  0;  Box2DTest  test  =  tests[testIndex];  test.create();  app.log( "TestCollection ",   "created  test  ' "  +  tests[testIndex].getClass().getName());  }  else  {  tests[testIndex].keyDown(keycode);  	tests[testIndex].dispose();  
elasticsearch_ab2a655a5974593d65cf3d7f1388196a709e29dc	buggy:  Query  facetQuery  =  indexQueryParser.parse(parser);  context:  public  class  QueryFacetCollectorParser  implements  FacetCollectorParser  {  public  static  final  String  NAME  =   "query ";  return  new  String[]{ "query "};  }  XContentIndexQueryParser  indexQueryParser  =  (XContentIndexQueryParser)  context.queryParser();          Query  facetQuery  =  indexQueryParser.parse(parser);          Query  facetQuery  =  indexQueryParser.parse(parser).query();  return  new  QueryFacetCollector(facetName,  facetQuery,  context.filterCache());  }  }  	Query  facetQuery  =  indexQueryParser.parse(parser).query();  
libgdx_06a0ae7bc8217eff50f5770f821cd12abd045145	buggy:  cache.setText(text,  0,  0);  context:  public  class  Label  extends  Actor  {  public  BitmapFontCache  cache;  public  Label  (String  name,  BitmapFont  font,  String  text)  {  super(name);  cache  =  new  BitmapFontCache(font);  setText(text);  }  public  void  setText  (String  text)  {  cache.setText(text,  0,  0);  cache.setText(text,  0,  cache.getFont().isFlipped()  ?  0  :  cache.getFont().getCapHeight());  TextBounds  bounds  =  cache.getBounds();  width  =  bounds.width;  height  =  bounds.height;  }  cache.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  cache.setPosition(x,  y);  	cache.setText(text,  0,  cache.getFont().isFlipped()  ?  0  :  cache.getFont().getCapHeight());  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  .setSettings(ImmutableSettings.settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  0))  context:  final  long  NUM_WARM  =  50;  final  long  NUM_RUNS  =  100;  if  (client.admin().indices().prepareExists( "test ").execute().actionGet().exists())  {  }  else  {  String  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type1 ")  .startObject( "properties ").startObject( "location ").field( "type ",   "geo_point ").field( "lat_lon ",  true).endObject().endObject()  .endObject().endObject().string();  client.admin().indices().prepareCreate( "test ")                      .setSettings(ImmutableSettings.settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  0))                      .setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  0))  .addMapping( "type1 ",  mapping)  .execute().actionGet();  System.err.println( "-->  Indexing  [ "  +  NUM_DOCS  +   "] ");  for  (long  i  =  0;  i  <  NUM_DOCS;  )  {  client.prepareIndex( "test ",   "type1 ",  Long.toString(i++)).setSource(jsonBuilder().startObject()  .field( "name ",   "New  York ")  .startObject( "location ").field( "lat ",  40.7143528).field( "lon ",  -74.0059731).endObject()  	.setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  0))  
elasticsearch_0ff84d222f64f7f18f70d56d6f5cb5625ef47997	buggy:  ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer);  context:  threadPool.executor(handler.executor()).execute(new  ResponseHandler(handler,  streamable));  }  }  catch  (Exception  e)  {  handleException(handler,  new  ResponseHandlerFailureTransportException(e));  }  }  private  void  handlerResponseError(StreamInput  buffer,  final  TransportResponseHandler  handler)  {  Throwable  error;  try  {              ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer);              ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer,  transport.settings().getClassLoader());  error  =  (Throwable)  ois.readObject();  }  catch  (Exception  e)  {  error  =  new  TransportSerializationException( "Failed  to  deserialize  exception  response  from  stream ",  e);  }  handleException(handler,  error);  }  private  void  handleException(final  TransportResponseHandler  handler,  Throwable  error)  {  	ThrowableObjectInputStream  ois  =  new  ThrowableObjectInputStream(buffer,  transport.settings().getClassLoader());  
elasticsearch_087f5d6bea68a8498e029ff55c03ba88727350fd	buggy:  refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  this);  context:  }  else  if  (e.getCause()  instanceof  ThreadInterruptedException)  {  }  else  {  }  }  catch  (Exception  e)  {  }  if  (state  !=  IndexShardState.CLOSED)  {                          refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  this);                          refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  EngineRefresher.this);  }  }  });  }  }  private  class  EngineOptimizer  implements  Runnable  {  	refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  EngineRefresher.this);  
elasticsearch_bbd63f0ffef611842315044f4275a341ce7110cf	buggy:  Query  query  =  new  DeletionAwareConstantScoreQuery(filter,  true);  context:  }  if  (filter  ==  null)  {  throw  new  QueryParsingException(index,   "[constant_score]  requires  'filter'  element ");  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter);  }          Query  query  =  new  DeletionAwareConstantScoreQuery(filter,  true);          Query  query  =  new  DeletionAwareConstantScoreQuery(filter);  query.setBoost(boost);  return  query;  }  }  	Query  query  =  new  DeletionAwareConstantScoreQuery(filter);  
elasticsearch_ee33ee457a4d36986fcbea4b75fc153f9b6ab2ef	buggy:  new  StringMessage( "moshe "),  TransportRequestOptions.options().withCompress(),  new  BaseTransportResponseHandler<StringMessage>()  {  context:  try  {  channel.sendResponse(new  StringMessage( "hello   "  +  request.message),  TransportResponseOptions.options().withCompress());  }  catch  (IOException  e)  {  e.printStackTrace();  assertThat(e.getMessage(),  false,  equalTo(true));  }  }  });  TransportFuture<StringMessage>  res  =  serviceB.submitRequest(serviceANode,   "sayHello ",                  new  StringMessage( "moshe "),  TransportRequestOptions.options().withCompress(),  new  BaseTransportResponseHandler<StringMessage>()  {                  new  StringMessage( "moshe "),  TransportRequestOptions.options().withCompress(true),  new  BaseTransportResponseHandler<StringMessage>()  {  return  new  StringMessage();  }  assertThat( "hello  moshe ",  equalTo(response.message));  }  	new  StringMessage( "moshe "),  TransportRequestOptions.options().withCompress(true),  new  BaseTransportResponseHandler<StringMessage>()  {  
libgdx_a796233dee600d6acf20bb488c15a613eb6de386	buggy:  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  context:  for(int  i  =  0;  i  <  100;  i++)  {  cavemen[i]  =  new  Caveman((float)Math.random()  *  Gdx.graphics.getWidth(),  (float)Math.random()  *  Gdx.graphics.getHeight(),  Math.random()  >  0.5?true:false);  }  batch  =  new  SpriteBatch();  fpsLog  =  new  FPSLogger();  }  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  batch.begin();  for(int  i  =  0;  i  <  cavemen.length;  i++)  {  Caveman  caveman  =  cavemen[i];  TextureRegion  frame  =  caveman.headsLeft?  leftWalk.getKeyFrame(caveman.stateTime,  true):  rightWalk.getKeyFrame(caveman.stateTime,  true);  batch.draw(frame,  caveman.pos.x,  caveman.pos.y);  }  	Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  
libgdx_a045d507fbe13a89587cf72c574c8ffd2e967260	buggy:  GdxTest  test  =  new  FullscreenTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  FullscreenTest();  GdxTest  test  =  new  Scene2dTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  Scene2dTest();  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  query  =  smartNameFieldMappers.mapper().fieldQuery(value);  }  }  if  (query  ==  null)  {  query  =  new  TermQuery(new  Term(fieldName,  value));  }  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
libgdx_1ab6849614157115963e631247b28b6cf2120db2	buggy:  return  line(start.x,  start.y,  end.y,  end.y);  context:  }  };  public  Array<GridPoint2>  line(GridPoint2  start,  GridPoint2  end)  {  return  line(start.x,  start.y,  end.y,  end.y);  return  line(start.x,  start.y,  end.x,  end.y);  }  	return  line(start.x,  start.y,  end.x,  end.y);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Long>  values  =  new  ArrayList<Long>();  context:  return  MapperTestUtils.newParser().parse(rebuildMapping);  }  private  void  assertNumericTokensEqual(ParsedDocument  doc,  DocumentMapper  defaultMapper,  String  fieldA,  String  fieldB)  throws  IOException  {  assertThat(doc.rootDoc().getField(fieldA).tokenStream(defaultMapper.indexAnalyzer()),  notNullValue());  assertThat(doc.rootDoc().getField(fieldB).tokenStream(defaultMapper.indexAnalyzer()),  notNullValue());  TokenStream  tokenStream  =  doc.rootDoc().getField(fieldA).tokenStream(defaultMapper.indexAnalyzer());  tokenStream.reset();  NumericTermAttribute  nta  =  tokenStream.addAttribute(NumericTermAttribute.class);          List<Long>  values  =  new  ArrayList<Long>();          List<Long>  values  =  new  ArrayList<>();  while(tokenStream.incrementToken())  {  values.add(nta.getRawValue());  }  tokenStream  =  doc.rootDoc().getField(fieldB).tokenStream(defaultMapper.indexAnalyzer());  tokenStream.reset();  nta  =  tokenStream.addAttribute(NumericTermAttribute.class);  int  pos  =  0;  	List<Long>  values  =  new  ArrayList<>();  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  this.uidToScore  =  uidToScore;  this.parentsIterator  =  parentsIterator;  }  public  float  score()  throws  IOException  {  return  currentScore;  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  1;  }  public  int  docID()  {  return  currentDocId;  	public  int  freq()  throws  IOException  {  
elasticsearch_7feb742a9b3e8a5bceaaf77e2767d116a858d07d	buggy:  .script( "ceil(_doc.score()/3) ")  context:  }  }  public  void  script_Score()  {  SearchResponse  response  =  client().prepareSearch( "idx ").setTypes( "type ")  .setQuery(functionScoreQuery(matchAllQuery()).add(ScoreFunctionBuilders.scriptFunction( "doc[' "  +  SINGLE_VALUED_FIELD_NAME  +   "'].value ")))  .addAggregation(terms( "terms ")  .collectMode(randomFrom(SubAggCollectionMode.values()))                          .script( "ceil(_doc.score()/3) ")                          .script( "ceil(_score.doubleValue()/3) ")  ).execute().actionGet();  assertSearchResponse(response);  Terms  terms  =  response.getAggregations().get( "terms ");  assertThat(terms,  notNullValue());  assertThat(terms.getName(),  equalTo( "terms "));  assertThat(terms.getBuckets().size(),  equalTo(3));  	.script( "ceil(_score.doubleValue()/3) ")  
elasticsearch_09528610c1dcbd1f4cee78fa8549fde19783c897	buggy:  IndexReader  reader  =  indexWriter.getReader();  context:  .build());  indexWriter.addDocument(doc()  .add(new  NumericField( "mvalue ").setIntValue(102))  .build());  indexWriter.addDocument(doc()  .add(new  NumericField( "svalue ").setIntValue(4))  .build());          IndexReader  reader  =  indexWriter.getReader();          IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IntFieldData  sFieldData  =  IntFieldData.load(reader,   "svalue ");  IntFieldData  mFieldData  =  IntFieldData.load(reader,   "mvalue ");  assertThat(sFieldData.fieldName(),  equalTo( "svalue "));  assertThat(sFieldData.multiValued(),  equalTo(false));  assertThat(mFieldData.fieldName(),  equalTo( "mvalue "));  	IndexReader  reader  =  IndexReader.open(indexWriter,  true);  
elasticsearch_5b4846b0b68af6d4893322ac51a87d6283930497	buggy:  return  translog.size();  context:  }  }  public  long  getTranslogId()  {  return  translog.currentId();  }  public  long  getTranslogNumberOfOperations()  {          return  translog.size();          return  translog.numberOfOperations();  }  public  String  getTranslogSize()  {  return  new  ByteSizeValue(translog.memorySizeInBytes()).toString();  }  	return  translog.numberOfOperations();  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  shardStores.put(nodeStoreFilesMetaData.node(),  nodeStoreFilesMetaData.storeFilesMetaData());  context:  continue;  }  sb.append( "\n    ->   ").append(nodesStoreFilesMetaData.failures()[i].getDetailedMessage());  }  }  }  for  (TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData  nodeStoreFilesMetaData  :  nodesStoreFilesMetaData)  {  if  (nodeStoreFilesMetaData.storeFilesMetaData()  !=  null)  {                      shardStores.put(nodeStoreFilesMetaData.node(),  nodeStoreFilesMetaData.storeFilesMetaData());                      shardStores.put(nodeStoreFilesMetaData.getNode(),  nodeStoreFilesMetaData.storeFilesMetaData());  }  }  }  return  shardStores;  }  }  	shardStores.put(nodeStoreFilesMetaData.getNode(),  nodeStoreFilesMetaData.storeFilesMetaData());  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  return  builder.unsafeStream();  context:  return  builder.string();  }  catch  (Exception  e)  {  return   "{  \ "error\ "  :  \ " "  +  e.getMessage()  +   "\ "} ";  }  }  public  BytesStream  buildAsUnsafeBytes(XContentType  contentType)  throws  SearchSourceBuilderException  {  try  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(contentType);  toXContent(builder,  ToXContent.EMPTY_PARAMS);              return  builder.unsafeStream();              return  builder.underlyingStream();  }  catch  (Exception  e)  {  throw  new  SearchSourceBuilderException( "Failed  to  build  search  source ",  e);  }  }  public  byte[]  buildAsBytes()  throws  SearchSourceBuilderException  {  return  buildAsBytes(Requests.CONTENT_TYPE);  }  	return  builder.underlyingStream();  
libgdx_a9b31ca640ed4a2826729c14c4621e685f78ed29	buggy:  libSuffix  =   ".dylib ";  context:  String  libSuffix  =   " ";  if  (os  ==  TargetOs.Windows)  {  libSuffix  =  (is64Bit  ?   "64 "  :   " ")  +   ".dll ";  }  if  (os  ==  TargetOs.Linux  ||  os  ==  TargetOs.Android)  {  libPrefix  =   "lib ";  libSuffix  =  (is64Bit  ?   "64 "  :   " ")  +   ".so ";  }  if  (os  ==  TargetOs.MacOsX)  {  libPrefix  =   "lib ";  libSuffix  =   ".dylib ";  libSuffix  =  (is64Bit  ?   "64 "  :   " ")  +   ".dylib ";  }  if  (os  ==  TargetOs.IOS)  {  libPrefix  =   "lib ";  libSuffix  =   ".a ";  }  return  libPrefix  +  sharedLibName  +  libSuffix;  }  	libSuffix  =  (is64Bit  ?   "64 "  :   " ")  +   ".dylib ";  
elasticsearch_1f50b07406d0fa5f10a733445a622044671ccabe	buggy:  HasParentFilter  parentFilter  =  HasParentFilter.create(executionType,  query,  null,  parentType,  searchContext);  context:  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[parent]  filter  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();          HasParentFilter  parentFilter  =  HasParentFilter.create(executionType,  query,  null,  parentType,  searchContext);          HasParentFilter  parentFilter  =  HasParentFilter.create(executionType,  query,  parentType,  searchContext);  searchContext.addRewrite(parentFilter);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  parentFilter);  }  return  parentFilter;  }  	HasParentFilter  parentFilter  =  HasParentFilter.create(executionType,  query,  parentType,  searchContext);  
libgdx_c81d15a3d08d6d468e221dcfac6aa2f7e358fc19	buggy:  if  (currentlyLoading  ==  null  ||  currentlyLoading.isEmpty())  return;  context:  }  currentlyLoading  =   "data/ "  +  name;  loadingMaterial  =  false;  if  (!name.equals(currentModel))  assets.load(currentlyLoading,  Model.class);  loading  =  true;  }  protected  void  onLoaded  ()  {  if  (currentlyLoading  ==  null  ||  currentlyLoading.isEmpty())  return;  if  (currentlyLoading  ==  null  ||  currentlyLoading.length()  ==  0)  return;  if  (loadingMaterial)  {  loadingMaterial  =  false;  if  (currentMaterial  !=  null  &&  !currentMaterial.equals(currentlyLoading))  assets.unload(currentMaterial);  currentMaterial  =  currentlyLoading;  currentlyLoading  =  null;  ModelInstance  instance  =  instances.get(0);  if  (instance  !=  null)  {  	if  (currentlyLoading  ==  null  ||  currentlyLoading.length()  ==  0)  return;  
elasticsearch_24ef9876243a39ce3ae4ce093f4ed5b34965d52d	buggy:  searchContext.idCache().refresh(searchContext.searcher().subReaders());  context:  context.preProcess();  facetPhase.preProcess(context);  }  public  void  execute(SearchContext  searchContext)  throws  QueryPhaseExecutionException  {  searchContext.queryResult().searchTimedOut(false);  if  (searchContext.scopePhases()  !=  null)  {  try  {                  searchContext.idCache().refresh(searchContext.searcher().subReaders());                  searchContext.idCache().refresh(searchContext.searcher().getTopReaderContext().leaves());  }  catch  (Exception  e)  {  throw  new  QueryPhaseExecutionException(searchContext,   "Failed  to  refresh  id  cache  for  child  queries ",  e);  }  for  (ScopePhase  scopePhase  :  searchContext.scopePhases())  {  if  (scopePhase  instanceof  ScopePhase.TopDocsPhase)  {  ScopePhase.TopDocsPhase  topDocsPhase  =  (ScopePhase.TopDocsPhase)  scopePhase;  	searchContext.idCache().refresh(searchContext.searcher().getTopReaderContext().leaves());  
elasticsearch_508d1d40fba92cd0b2c544cef0213a9c18e9002f	buggy:  IndicesStatusResponse  statusResponse  =  client( "server1 ").admin().indices().prepareStatus().execute().actionGet();  context:  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForActiveShards(1)).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  assertThat(client( "server1 ").prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),  equalTo(1234l));          IndicesStatusResponse  statusResponse  =  client( "server1 ").admin().indices().prepareStatus().execute().actionGet();          IndicesStatusResponse  statusResponse  =  client( "server1 ").admin().indices().prepareStatus().setRecovery(true).execute().actionGet();  for  (IndexShardStatus  indexShardStatus  :  statusResponse.index( "test "))  {  for  (ShardStatus  shardStatus  :  indexShardStatus)  {  if  (shardStatus.shardRouting().primary())  {  if  (fullRecovery  ||  !isPersistentStorage())  {  assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  equalTo(0l));  }  else  {  assertThat(shardStatus.gatewayRecoveryStatus().reusedIndexSize().bytes(),  greaterThan(shardStatus.gatewayRecoveryStatus().indexSize().bytes()  -  8196  /*  segments  file  and  others  */));  }  	IndicesStatusResponse  statusResponse  =  client( "server1 ").admin().indices().prepareStatus().setRecovery(true).execute().actionGet();  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());  context:  }  if  (fieldMapper  !=  null)  {  value  =  fieldMapper.indexedValue(value);  }  termsFilter.addTerm(new  Term(fieldName,  value));  }  jp.nextToken();  Filter  filter  =  parseContext.cacheFilterIfPossible(termsFilter);          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  JsonBuilder  builder  =  JsonBuilder.cached();  context:  public  SearchSourceBuilder  field(String  name)  {  if  (fieldNames  ==  null)  {  fieldNames  =  new  ArrayList<String>();  }  fieldNames.add(name);  return  this;  }  public  String  build()  {  try  {              JsonBuilder  builder  =  JsonBuilder.cached();              JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  builder.startObject();  if  (from  !=  -1)  {  builder.field( "from ",  from);  }  if  (size  !=  -1)  {  builder.field( "size ",  size);  }  	JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  
elasticsearch_514df4ee3f99b8f860847a06b3b44e137af70234	buggy:  DefaultShardsRoutingStrategy  strategy  =  new  DefaultShardsRoutingStrategy();  context:  public  class  TenShardsOneBackupRoutingTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(TenShardsOneBackupRoutingTests.class);          DefaultShardsRoutingStrategy  strategy  =  new  DefaultShardsRoutingStrategy();          ShardsRoutingStrategy  strategy  =  new  ShardsRoutingStrategy();  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(10).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	ShardsRoutingStrategy  strategy  =  new  ShardsRoutingStrategy();  
libgdx_64b91cfcbe5b21b11fd2358788a94ec1be124d95	buggy:  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/badlogicsmall.jpg "));  context:  int  width  =  0;  int  height  =  0;  public  void  load()  {  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/badlogicsmall.jpg "));  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/stone2.png "));  Gdx.gl.glTexImage2D(GL10.GL_TEXTURE_2D,  0,  pixmap.getGLInternalFormat(),  pixmap.getWidth(),  pixmap.getHeight(),  0,  pixmap.getGLFormat(),  pixmap.getGLType(),  pixmap.getPixels());  width  =  pixmap.getWidth();  height  =  pixmap.getHeight();  pixmap.dispose();  }  public  int  getWidth()  {  return  width;  	Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/stone2.png "));  
elasticsearch_ccb30d42e9512c2618880a3cd026d6c6c2e5a253	buggy:  },  request.delay);  context:  try  {  node.stop();  node.start();  }  catch  (Exception  e)  {  }  finally  {  restartRequested.set(false);  }  }  }          },  request.delay);          },  request.delay,  ThreadPool.ExecutionType.THREADED);  return  new  NodesRestartResponse.NodeRestartResponse(clusterService.state().nodes().localNode());  }  return  false;  }  protected  static  class  NodeRestartRequest  extends  NodeOperationRequest  {  	},  request.delay,  ThreadPool.ExecutionType.THREADED);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  List<String>  nodes  =  cluster().startNodesAsync(  context:  public  class  UpdateSettingsValidationTests  extends  ElasticsearchIntegrationTest  {  public  void  testUpdateSettingsValidation()  throws  Exception  {          List<String>  nodes  =  cluster().startNodesAsync(          List<String>  nodes  =  internalCluster().startNodesAsync(  settingsBuilder().put( "node.data ",  false).build(),  settingsBuilder().put( "node.master ",  false).build(),  settingsBuilder().put( "node.master ",  false).build()  ).get();  String  master  =  nodes.get(0);  String  node_1  =  nodes.get(1);  String  node_2  =  nodes.get(2);  	List<String>  nodes  =  internalCluster().startNodesAsync(  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);  context:  protected  abstract  Map<String,  Set<String>>  resolveRouting(ClusterState  clusterState,  Request  request)  throws  ElasticSearchException;  protected  void  doExecute(final  Request  request,  final  ActionListener<Response>  listener)  {  ClusterState  clusterState  =  clusterService.state();  ClusterBlockException  blockException  =  checkGlobalBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  blockException  =  checkRequestBlock(clusterState,  request,  concreteIndices);  if  (blockException  !=  null)  {  throw  blockException;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_e735ff49d69951c756db260967cc2527869ed18c	buggy:  .putAll(settings)  context:  }  public  Server  buildServer(String  id)  {  return  buildServer(id,  EMPTY_SETTINGS);  }  public  Server  buildServer(String  id,  Settings  settings)  {  String  settingsSource  =  getClass().getName().replace('.',  '/')  +   ".yml ";  Settings  finalSettings  =  settingsBuilder()  .loadFromClasspath(settingsSource)                  .putAll(settings)                  .put(settings)  .put( "name ",  id)  .build();  Server  server  =  serverBuilder()  .settings(finalSettings)  .build();  servers.put(id,  server);  clients.put(id,  server.client());  return  server;  	.put(settings)  
libgdx_3bc3aa0954ec39fa82b91b84fe34953fe061403d	buggy:  return  new  DefaultShader(vertexShader,  fragmentShader,  renderable.material,  renderable.mesh.getVertexAttributes(),  renderable.lights  !=  null,  renderable.lights  !=  null  &&  renderable.lights.fog  !=  null,  2,  5,  3,  renderable.bones  ==  null  ?  0  :  12);  context:  }  public  DefaultShaderProvider()  {  this(DefaultShader.getDefaultVertexShader(),  DefaultShader.getDefaultFragmentShader());  }  protected  Shader  createShader(final  Renderable  renderable)  {  Gdx.app.log( "DefaultShaderProvider ",   "Creating  new  shader ");  if  (Gdx.graphics.isGL20Available())  {              return  new  DefaultShader(vertexShader,  fragmentShader,  renderable.material,  renderable.mesh.getVertexAttributes(),  renderable.lights  !=  null,  renderable.lights  !=  null  &&  renderable.lights.fog  !=  null,  2,  5,  3,  renderable.bones  ==  null  ?  0  :  12);              return  new  DefaultShader(vertexShader,  fragmentShader,  renderable,  renderable.lights  !=  null,  renderable.lights  !=  null  &&  renderable.lights.fog  !=  null,  2,  5,  3,  renderable.bones  ==  null  ?  0  :  12);  }  return  new  GLES10Shader();  }  }  	return  new  DefaultShader(vertexShader,  fragmentShader,  renderable,  renderable.lights  !=  null,  renderable.lights  !=  null  &&  renderable.lights.fog  !=  null,  2,  5,  3,  renderable.bones  ==  null  ?  0  :  12);  
elasticsearch_8aa2ee7bacd9ea6908e230dd670934f0b8bde538	buggy:  clusterService.add(this);  context:  this.nodeIndexCreatedAction  =  nodeIndexCreatedAction;  this.nodeIndexDeletedAction  =  nodeIndexDeletedAction;  this.nodeMappingCreatedAction  =  nodeMappingCreatedAction;  this.nodeMappingRefreshAction  =  nodeMappingRefreshAction;  this.nodeAliasesUpdatedAction  =  nodeAliasesUpdatedAction;  this.nodeIndicesStateUpdatedAction  =  nodeIndicesStateUpdatedAction;  }  protected  void  doStart()  throws  ElasticSearchException  {          clusterService.add(this);          clusterService.addFirst(this);  }  protected  void  doStop()  throws  ElasticSearchException  {  clusterService.remove(this);  }  	clusterService.addFirst(this);  
libgdx_13c2341e94904326dfd264ff018c585edef06894	buggy:  gl.glUniformMatrix2x4fv(  location,  count,  transpose,  value  );  context:  public  void  glUniformMatrix3fv(int  location,  int  count,  boolean  transpose,  FloatBuffer  value)  {  gl.glUniformMatrix3fv(  location,  count,  transpose,  value  );  }  public  void  glUniformMatrix4fv(int  location,  int  count,  boolean  transpose,  FloatBuffer  value)  {  gl.glUniformMatrix2x4fv(  location,  count,  transpose,  value  );  gl.glUniformMatrix4fv(  location,  count,  transpose,  value  );  }  public  void  glUseProgram(int  program)  {  gl.glUseProgram(  program  );  }  	gl.glUniformMatrix4fv(  location,  count,  transpose,  value  );  
elasticsearch_11ca3ea0ecd0dfc329c20a856101a99242a3ce72	buggy:  settingsBuilder.loadFromUrl(environment.resolveConfig(System.getProperty( "es.config ")));  context:  .putProperties( "es. ",  System.getProperties(),  ignorePrefixes)  .replacePropertyPlaceholders();  Environment  environment  =  new  Environment(settingsBuilder.build());  if  (loadConfigSettings)  {  boolean  loadFromEnv  =  true;  if  (System.getProperty( "es.default.config ")  !=  null)  {  loadFromEnv  =  true;                  settingsBuilder.loadFromUrl(environment.resolveConfig(System.getProperty( "es.config ")));                  settingsBuilder.loadFromUrl(environment.resolveConfig(System.getProperty( "es.default.config ")));  }  if  (System.getProperty( "es.config ")  !=  null)  {  loadFromEnv  =  false;  settingsBuilder.loadFromUrl(environment.resolveConfig(System.getProperty( "es.config ")));  }  if  (System.getProperty( "elasticsearch.config ")  !=  null)  {  loadFromEnv  =  false;  	settingsBuilder.loadFromUrl(environment.resolveConfig(System.getProperty( "es.default.config ")));  
elasticsearch_8c9000c54cafe7861ac81b236c29b3df332e6d2f	buggy:  return  new  CacheStats(fieldDataCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  bloomCache.sizeInBytes());  context:  public  void  setClusterService(@Nullable  ClusterService  clusterService)  {  this.clusterService  =  clusterService;  if  (clusterService  !=  null)  {  clusterService.add(this);  }  }  public  CacheStats  stats()  {          return  new  CacheStats(fieldDataCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  bloomCache.sizeInBytes());          return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());  }  public  FilterCache  filter()  {  return  filterCache;  }  public  FieldDataCache  fieldData()  {  return  fieldDataCache;  	return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());  
elasticsearch_a8656c8a6f4dfbebee3867effb012a06c8ff7f91	buggy:  if  (boost  ==  -1)  {  context:  throw  new  QueryBuilderException( "Must  specify  include  when  using  spanNot  query ");  }  if  (exclude  ==  null)  {  throw  new  QueryBuilderException( "Must  specify  exclude  when  using  spanNot  query ");  }  builder.startObject(SpanNotQueryParser.NAME);  builder.field( "include ");  include.toXContent(builder,  params);  builder.field( "exclude ");  exclude.toXContent(builder,  params);          if  (boost  ==  -1)  {          if  (boost  !=  -1)  {  builder.field( "boost ",  boost);  }  builder.endObject();  }  }  	if  (boost  !=  -1)  {  
libgdx_501eb16ea8fbe820d08692b5baf7d47b0e371f91	buggy:  if  (knownType  !=  null  &&  actualType  !=  knownType)  context:  return;  }  Serializer  serializer  =  classToSerializer.get(actualType);  if  (serializer  !=  null)  {  serializer.write(this,  value,  knownType);  return;  }  if  (value  instanceof  Array)  {  if  (knownType  !=  null  &&  actualType  !=  knownType)  if  (knownType  !=  null  &&  actualType  !=  knownType  &&  actualType  !=  Array.class)  throw  new  SerializationException( "Serialization  of  an  Array  other  than  the  known  type  is  not  supported.\n "   "Known  type:   "  +  knownType  +   "\nActual  type:   "  +  actualType);  writeArrayStart();  Array  array  =  (Array)value;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  writeValue(array.get(i),  elementType,  null);  writeArrayEnd();  return;  	if  (knownType  !=  null  &&  actualType  !=  knownType  &&  actualType  !=  Array.class)  
elasticsearch_be1e5becbbf7aa6efa2a30c1b1e5e3633ba0a11e	buggy:  searchLookup  =  new  SearchLookup(mapperService(),  fieldDataCache(),  request.types());  context:  return  this.keepAlive;  }  public  void  keepAlive(long  keepAlive)  {  this.keepAlive  =  keepAlive;  }  public  SearchLookup  lookup()  {  if  (searchLookup  ==  null)  {              searchLookup  =  new  SearchLookup(mapperService(),  fieldDataCache(),  request.types());              searchLookup  =  new  SearchLookup(mapperService(),  fieldData(),  request.types());  }  return  searchLookup;  }  public  DfsSearchResult  dfsResult()  {  return  dfsResult;  }  	searchLookup  =  new  SearchLookup(mapperService(),  fieldData(),  request.types());  
libgdx_62096635537ae880431708d6e383efbd7313a013	buggy:  return  BufferedImage.TYPE_4BYTE_ABGR;  context:  pixmap  =  new  BufferedImage(width,  height,  internalformat);  composite  =  AlphaComposite.Src;  }  LwjglPixmap  (BufferedImage  image)  {  pixmap  =  image;  }  private  int  getInternalFormat  (Pixmap.Format  format)  {  if  (format  ==  Pixmap.Format.RGBA4444  ||  format  ==  Pixmap.Format.RGBA8888  ||  format  ==  Pixmap.Format.RGB565)  return  BufferedImage.TYPE_4BYTE_ABGR;  return  BufferedImage.TYPE_4BYTE_ABGR_PRE;  else  return  BufferedImage.TYPE_BYTE_GRAY;  }  public  void  drawCircle  (int  x,  int  y,  int  radius)  {  Graphics2D  g  =  (Graphics2D)pixmap.getGraphics();  g.setRenderingHint(RenderingHints.KEY_ANTIALIASING,  RenderingHints.VALUE_ANTIALIAS_ON);  	return  BufferedImage.TYPE_4BYTE_ABGR_PRE;  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal),  true);  context:  float  touchStartX  =  0;  float  touchStartY  =  0;  long  frameStart;  int  frames  =  0;  if  (mesh  ==  null)  {  Gdx.input.addInputListener(this);  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal),  true);  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpd ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  cam  =  new  PerspectiveCamera();  cam.getPosition().set(2,  2,  2);  cam.getDirection().set(-1,  -1,  -1);  }  frameStart  =  System.nanoTime();  	mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  
elasticsearch_9f2afeb4cacbac1262b23f268e9ab28abd9cbbdd	buggy:  final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool,  timerService).start();  context:  final  AtomicLong  idGenerator  =  new  AtomicLong();  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "network.server ",  false)  .put( "network.tcp.blocking ",  false)  .build();  final  ThreadPool  threadPool  =  new  CachedThreadPool(settings);  final  TimerService  timerService  =  new  TimerService(settings,  threadPool);          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool,  timerService).start();          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  final  DiscoveryNode  node  =  new  DiscoveryNode( "server ",  new  InetSocketTransportAddress( "localhost ",  9999));  transportService.connectToNode(node);  for  (int  i  =  0;  i  <  10000;  i++)  {  BenchmarkMessage  message  =  new  BenchmarkMessage(1,  payload);  transportService.submitRequest(node,   "benchmark ",  message,  new  BaseTransportResponseHandler<BenchmarkMessage>()  {  	final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  
libgdx_a045d507fbe13a89587cf72c574c8ffd2e967260	buggy:  actor.scale(amountX  *  percentDelta,  amountY  *  percentDelta);  context:  package  com.badlogic.gdx.scenes.scene2d.actions;  public  class  ScaleByAction  extends  RelativeTemporalAction  {  private  float  amountX,  amountY;  protected  void  updateRelative  (float  percentDelta)  {  actor.scale(amountX  *  percentDelta,  amountY  *  percentDelta);  actor.scaleBy(amountX  *  percentDelta,  amountY  *  percentDelta);  }  public  void  setAmount  (float  x,  float  y)  {  amountX  =  x;  amountY  =  y;  }  public  void  setAmount  (float  scale)  {  	actor.scaleBy(amountX  *  percentDelta,  amountY  *  percentDelta);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataStateIndexService  stateIndexService;  ThreadPool  threadPool,  MetaDataStateIndexService  stateIndexService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.stateIndexService  =  stateIndexService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.OPEN;  }  return  new  OpenIndexRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_7e041c43e080dfff1be70ddf7a71147d6da36396	buggy:  DeleteByQueryResponse  queryResponse  =  client2.deleteByQuery(deleteByQueryRequest( "test ").querySource(termQuery( "name ",   "test2 "))).actionGet();  context:  countResponse  =  client1.count(countRequest( "test ").querySource(Unicode.fromStringAsBytes( "{  term  :  {  _type  :  \ "type1  }  } "))).actionGet();  assertThat(countResponse.count(),  equalTo(0l));  assertThat(countResponse.successfulShards(),  equalTo(0));  assertThat(countResponse.failedShards(),  equalTo(5));  }          DeleteByQueryResponse  queryResponse  =  client2.deleteByQuery(deleteByQueryRequest( "test ").querySource(termQuery( "name ",   "test2 "))).actionGet();          DeleteByQueryResponse  queryResponse  =  client2.deleteByQuery(deleteByQueryRequest( "test ").query(termQuery( "name ",   "test2 "))).actionGet();  assertThat(queryResponse.index(getConcreteIndexName()).successfulShards(),  equalTo(5));  assertThat(queryResponse.index(getConcreteIndexName()).failedShards(),  equalTo(0));  client1.admin().indices().refresh(refreshRequest( "test ")).actionGet();  for  (int  i  =  0;  i  <  5;  i++)  {  getResult  =  client1.get(getRequest( "test ").type( "type1 ").id( "1 ")).actionGet();  assertThat(getResult.index(),  equalTo(getConcreteIndexName()));  	DeleteByQueryResponse  queryResponse  =  client2.deleteByQuery(deleteByQueryRequest( "test ").query(termQuery( "name ",   "test2 "))).actionGet();  
elasticsearch_b11f81d744a5c23bf7c20d696939e226905c60e7	buggy:  return  Queries.MATCH_ALL_QUERY;  context:  Query  termQuery  =  currentMapper.queryStringTermQuery(term);  if  (termQuery  !=  null)  {  return  termQuery;  }  }  return  super.newTermQuery(term);  }  protected  Query  newMatchAllDocsQuery()  {          return  Queries.MATCH_ALL_QUERY;          return  Queries.newMatchAllQuery();  }  public  Query  getFieldQuery(String  field,  String  queryText,  boolean  quoted)  throws  ParseException  {  FieldQueryExtension  fieldQueryExtension  =  fieldQueryExtensions.get(field);  if  (fieldQueryExtension  !=  null)  {  return  fieldQueryExtension.query(parseContext,  queryText);  }  	return  Queries.newMatchAllQuery();  
elasticsearch_2f66bf0720c3559553407484d34fda80fe7e4f8e	buggy:  return  MockRamDirecorySerivce.class;  context:  super(index,  indexSettings,  indexService,  indicesStore);  }  public  boolean  persistent()  {  return  false;  }  public  Class<?  extends  DirectoryService>  shardDirectory()  {          return  MockRamDirecorySerivce.class;          return  MockRamDirectoryService.class;  }  public  ByteSizeValue  backingStoreTotalSpace()  {  return  JvmInfo.jvmInfo().getMem().heapMax();  }  	return  MockRamDirectoryService.class;  
libgdx_ebe5a1e0b3536a1366e94fee87eb3e1040a1fd12	buggy:  if  (atlasFile.exists())  atlasFilePath  =  atlasFile.path();  context:  if  (imageElement  !=  null)  {  imageSource  =  imageElement.getAttribute( "source ");  imageWidth  =  imageElement.getIntAttribute( "width ",  0);  imageHeight  =  imageElement.getIntAttribute( "height ",  0);  }  }  String  atlasFilePath  =  map.getProperties().get( "atlas ",  String.class);  if  (atlasFilePath  ==  null)  {  FileHandle  atlasFile  =  tmxFile.sibling(tmxFile.nameWithoutExtension()  +   ".atlas ");  if  (atlasFile.exists())  atlasFilePath  =  atlasFile.path();  if  (atlasFile.exists())  atlasFilePath  =  atlasFile.name();  }  if  (atlasFilePath  ==  null)  {  throw  new  GdxRuntimeException( "The  map  is  missing  the  'atlas'  property ");  }  FileHandle  atlasHandle  =  getRelativeFileHandle(tmxFile,  atlasFilePath);  atlasHandle  =  resolve(atlasHandle.path());  	if  (atlasFile.exists())  atlasFilePath  =  atlasFile.name();  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  },  cloudBlobStore.executorService());  context:  future.get();  listener.onCompleted();  }  catch  (InterruptedException  e)  {  listener.onFailure(e);  }  catch  (ExecutionException  e)  {  listener.onFailure(e.getCause());  }  catch  (Throwable  t)  {  listener.onFailure(t);  }  }          },  cloudBlobStore.executorService());          },  cloudBlobStore.executor());  }  BlobStores.syncWriteBlob(this,  blobName,  is,  sizeInBytes);  }  }  	},  cloudBlobStore.executor());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalTerms.Bucket>  buckets  =  new  ArrayList<InternalTerms.Bucket>(size);  context:  return  TYPE;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  this.name  =  in.readString();  this.order  =  InternalOrder.Streams.readOrder(in);  this.requiredSize  =  readSize(in);  this.minDocCount  =  in.readVLong();  int  size  =  in.readVInt();          List<InternalTerms.Bucket>  buckets  =  new  ArrayList<InternalTerms.Bucket>(size);          List<InternalTerms.Bucket>  buckets  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  buckets.add(new  Bucket(in.readBytesRef(),  in.readVLong(),  InternalAggregations.readAggregations(in)));  }  this.buckets  =  buckets;  this.bucketMap  =  null;  }  	List<InternalTerms.Bucket>  buckets  =  new  ArrayList<>(size);  
libgdx_ebc9a305a1015728cfb90fd73e05bc6c58748571	buggy:  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  context:  public  Matrix4  setToLookAt  (Vector3  position,  Vector3  target,  Vector3  up)  {  tmpVec.set(target).sub(position);  setToLookAt(tmpVec,  up);  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  this.mul(tmpMat.setToTranslation(-position.x,  -position.y,  -position.z));  return  this;  }  static  final  Vector3  right  =  new  Vector3();  static  final  Vector3  tmpForward  =  new  Vector3();  static  final  Vector3  tmpUp  =  new  Vector3();  	this.mul(tmpMat.setToTranslation(-position.x,  -position.y,  -position.z));  
elasticsearch_10f0eaad68557ff2aae92dd65e8f1b9037ea0942	buggy:  return   "attachments ";  context:  public  class  AttachmentsPlugin  extends  AbstractPlugin  {          return   "attachments ";          return   "mapper-attachments ";  }  return   "Adds  the  attachment  type  allowing  to  parse  difference  attachment  formats ";  }  Collection<Class<?  extends  Module>>  modules  =  newArrayList();  	return   "mapper-attachments ";  
elasticsearch_6abe4c951dcb81c16aed873d26009b99823b74bd	buggy:  if  (sValue.endsWith( "% "))  {  context:  public  enum  MemorySizeValue  {  ;  public  static  ByteSizeValue  parseBytesSizeValueOrHeapRatio(String  sValue)  {          if  (sValue.endsWith( "% "))  {          if  (sValue  !=  null  &&  sValue.endsWith( "% "))  {  final  String  percentAsString  =  sValue.substring(0,  sValue.length()  -  1);  try  {  final  double  percent  =  Double.parseDouble(percentAsString);  if  (percent  <  0  ||  percent  >  100)  {  throw  new  ElasticsearchParseException( "Percentage  should  be  in  [0-100],  got   "  +  percentAsString);  }  return  new  ByteSizeValue((long)  ((percent  /  100)  *  JvmInfo.jvmInfo().getMem().getHeapMax().bytes()),  ByteSizeUnit.BYTES);  }  catch  (NumberFormatException  e)  {  	if  (sValue  !=  null  &&  sValue.endsWith( "% "))  {  
libgdx_f789e60522557d95de7ef6a5f14790b75f6d0ed2	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.MultiTouchActorTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.MultiTouchActorTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleStageCullingTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.SimpleStageCullingTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  bulkRequest.add(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe(),  defaultIndex,  defaultType);  context:  String  replicationType  =  request.param( "replication ");  if  (replicationType  !=  null)  {  bulkRequest.replicationType(ReplicationType.fromString(replicationType));  }  String  consistencyLevel  =  request.param( "consistency ");  if  (consistencyLevel  !=  null)  {  bulkRequest.consistencyLevel(WriteConsistencyLevel.fromString(consistencyLevel));  }  bulkRequest.refresh(request.paramAsBoolean( "refresh ",  bulkRequest.refresh()));  try  {              bulkRequest.add(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe(),  defaultIndex,  defaultType);              bulkRequest.add(request.content(),  request.contentUnsafe(),  defaultIndex,  defaultType);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  	bulkRequest.add(request.content(),  request.contentUnsafe(),  defaultIndex,  defaultType);  
elasticsearch_44a604029366f5983de181eeb2ac54bd1ad3b219	buggy:  modules.add(new  IndexShardModule(shardId));  context:  if  (shardsInjectors.containsKey(shardId.id()))  {  throw  new  IndexShardAlreadyExistsException(shardId  +   "  already  exists ");  }  indicesLifecycle.beforeIndexShardCreated(shardId);  ModulesBuilder  modules  =  new  ModulesBuilder();  modules.add(new  ShardsPluginsModule(indexSettings,  pluginsService));          modules.add(new  IndexShardModule(shardId));          modules.add(new  IndexShardModule(indexSettings,  shardId));  modules.add(new  ShardIndexingModule());  modules.add(new  ShardSearchModule());  modules.add(new  ShardGetModule());  modules.add(new  StoreModule(indexSettings,  injector.getInstance(IndexStore.class)));  modules.add(new  DeletionPolicyModule(indexSettings));  modules.add(new  MergePolicyModule(indexSettings));  modules.add(new  MergeSchedulerModule(indexSettings));  modules.add(new  TranslogModule(indexSettings));  	modules.add(new  IndexShardModule(indexSettings,  shardId));  
libgdx_b25991f995e0353188ba076de99f0076a604dd54	buggy:  Display.sync(60);  context:  int  height  =  Math.max(1,  graphics.getHeight());  if  (lastWidth  !=  width  ||  lastHeight  !=  height)  {  lastWidth  =  width;  lastHeight  =  height;  listener.resize(width,  height);  }  input.processEvents();  listener.render();  audio.update();  Display.update();  Display.sync(60);  if  (graphics.vsync)  Display.sync(60);  }  };  new  Thread( "LWJGL  Canvas ")  {  public  void  run  ()  {  while  (running  &&  !Display.isCloseRequested())  {  try  {  EventQueue.invokeAndWait(runnable);  	if  (graphics.vsync)  Display.sync(60);  
elasticsearch_4e4495ff1d27f65d4acdcc239998a463151fe561	buggy:  DocIdSet  docIdSet  =  parentDocs.get(reader.getFieldCacheKey());  context:  return  this.scope;  }  parentDocs  =  null;  }          DocIdSet  docIdSet  =  parentDocs.get(reader.getFieldCacheKey());          DocIdSet  docIdSet  =  parentDocs.get(reader.getCoreCacheKey());  if  (docIdSet  ==  null)  {  return  DocIdSet.EMPTY_DOCIDSET;  }  return  docIdSet;  }  StringBuilder  sb  =  new  StringBuilder();  	DocIdSet  docIdSet  =  parentDocs.get(reader.getCoreCacheKey());  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  .put( "index.engine.robin.refreshInterval ",   "-1 ")  context:  public  class  ChildSearchBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()                  .put( "index.engine.robin.refreshInterval ",   "-1 ")                  .put( "index.refresh_interval ",   "-1 ")  .put( "gateway.type ",   "local ")  .put(SETTING_NUMBER_OF_SHARDS,  1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)  .build();  String  clusterName  =  ChildSearchBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().clusterName(clusterName)  .settings(settingsBuilder().put(settings).put( "name ",   "node1 ")).node();  	.put( "index.refresh_interval ",   "-1 ")  
libgdx_de51972881d28d76f4f51deac1c5eeca5247f7ed	buggy:  return  (float)  Math.toDegrees(angle);  context:  axis.x  =  this.x;  //  if  it  is  important  that  axis  is  normalised  then  replace  with  x=1;  y=z=0;  axis.y  =  this.y;  axis.z  =  this.z;  }  else  {  axis.x  =  (float)  (this.x  /  s);  //  normalise  axis  axis.y  =  (float)  (this.y  /  s);  axis.z  =  (float)  (this.z  /  s);  }        return  (float)  Math.toDegrees(angle);        return  MathUtils.radiansToDegrees  *  angle;  }  }  	return  MathUtils.radiansToDegrees  *  angle;  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Integer  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_629f91ae57b5a2223f2edaa213b5d0d08a155885	buggy:  final  SortedDocValues  singleOrds  =  MultiValueMode.MIN.select(docs,  -1);  context:  if  (o1.ord  >  o2.ord)  {  return  1;  }  return  0;  }  return  1;  }  });  Ordinals  ords  =  creationMultiOrdinals(builder);  RandomAccessOrds  docs  =  ords.ordinals();          final  SortedDocValues  singleOrds  =  MultiValueMode.MIN.select(docs,  -1);          final  SortedDocValues  singleOrds  =  MultiValueMode.MIN.select(docs);  int  docId  =  ordsAndIds.get(0).id;  List<Long>  docOrds  =  new  ArrayList<>();  for  (OrdAndId  ordAndId  :  ordsAndIds)  {  if  (docId  ==  ordAndId.id)  {  docOrds.add(ordAndId.ord);  }  else  {  if  (!docOrds.isEmpty())  {  assertThat((long)  singleOrds.getOrd(docId),  equalTo(docOrds.get(0)));  	final  SortedDocValues  singleOrds  =  MultiValueMode.MIN.select(docs);  
libgdx_467ab9c64c91c62dd3305c7b28f77b55947cdafe	buggy:  return  file.getPath();  context:  this.type  =  type;  file  =  new  File(fileName);  }  protected  FileDescriptor  (File  file,  FileType  type)  {  this.file  =  file;  this.type  =  type;  }  public  String  path  ()  {  return  file.getPath();  return  file.getPath().replace('\\',  '/');  }  public  String  name  ()  {  return  file.getName();  }  public  String  extension  ()  {  String  name  =  file.getName();  	return  file.getPath().replace('\\',  '/');  
libgdx_3930c6b18c81fab6065c885459e06a9617f7170f	buggy:  if  (body  !=  null)  body.delete();  context:  ((btRigidBody)this.body).setMotionState(motionState);  }  else  body.setWorldTransform(transform);  }  }  public  void  dispose  ()  {  if  (motionState  !=  null)  motionState.dispose();  if  (body  !=  null)  body.delete();  if  (body  !=  null)  body.dispose();  motionState  =  null;  body  =  null;  }  static  class  MotionState  extends  btMotionState  implements  Disposable  {  private  final  Matrix4  transform;  	if  (body  !=  null)  body.dispose();  
elasticsearch_49d84cb47f8f543ce1fb067267d6fafa71f9c479	buggy:  return  Longs.compare(term,  other.getKeyAsNumber().longValue());  context:  return  new  StringText(String.valueOf(term));  }  public  Number  getKeyAsNumber()  {  return  term;  }  int  compareTerm(SignificantTerms.Bucket  other)  {              return  Longs.compare(term,  other.getKeyAsNumber().longValue());              return  Long.compare(term,  other.getKeyAsNumber().longValue());  }  public  String  getKey()  {  return  Long.toString(term);  }  }  	return  Long.compare(term,  other.getKeyAsNumber().longValue());  
libgdx_d5a8271cd34c14e83c6b04a4435782dfd2a530ea	buggy:  contact.GetWorldManifold();  context:  private  final  Contact  contact  =  new  Contact(this,  0);  private  void  beginContact  (long  contactAddr)  {  contact.addr  =  contactAddr;  if  (contactListener  !=  null)  contactListener.beginContact(contact);  }  private  void  endContact  (long  contactAddr)  {  contact.addr  =  contactAddr;  contact.GetWorldManifold();  contact.getWorldManifold();  if  (contactListener  !=  null)  contactListener.endContact(contact);  }  private  boolean  reportFixture  (long  addr)  {  if  (queryCallback  !=  null)  return  queryCallback.reportFixture(fixtures.get(addr));  else  return  false;  	contact.getWorldManifold();  
elasticsearch_e1fe89389c4e6f81a59bbb4b6790ee18410ae895	buggy:  if  (op.parsedDoc().mappersAdded())  {  context:  version  =  create.version();  op  =  create;  }  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh(false));  }  catch  (Exception  e)  {  }  }          if  (op.parsedDoc().mappersAdded())  {          if  (op.parsedDoc().mappingsModified())  {  updateMappingOnMaster(request);  }  request.version(version);  IndexResponse  response  =  new  IndexResponse(request.index(),  request.type(),  request.id(),  version);  return  new  PrimaryResponse<IndexResponse,  IndexRequest>(shardRequest.request,  response,  op);  }  	if  (op.parsedDoc().mappingsModified())  {  
elasticsearch_383945416866849139755c6761ad162faaadcbe0	buggy:  hash  =  new  BytesRefHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randomCacheRecycler());  context:  public  class  BytesRefHashTests  extends  ElasticsearchTestCase  {  BytesRefHash  hash;  private  void  newHash()  {  if  (hash  !=  null)  {  hash.release();  }  final  float  maxLoadFactor  =  0.6f  +  randomFloat()  *  0.39f;          hash  =  new  BytesRefHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randomCacheRecycler());          hash  =  new  BytesRefHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randombigArrays());  }  public  void  setUp()  throws  Exception  {  super.setUp();  newHash();  }  	hash  =  new  BytesRefHash(randomIntBetween(0,  100),  maxLoadFactor,  BigArraysTests.randombigArrays());  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  this.metaState  =  metaState;  return  this;  }  public  ActionFuture<NodesLocalGatewayMetaState>  list(Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {  return  execute(new  Request(nodesIds).timeout(timeout));  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return   "/gateway/local/meta-state ";  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_c85133c857f0b9ee4e7acaa86b751f01279f7e12	buggy:  Matcher  matcher  =  Pattern.compile( "[a-zA-Z0-9\\-_]+ ").matcher( " ");  context:  .field( "field ",   "tag ")  .endObject()  .endObject()  .endObject()  .endObject()).execute().actionGet();  }  public  void  testInvalidAggregationName()  throws  Exception  {          Matcher  matcher  =  Pattern.compile( "[a-zA-Z0-9\\-_]+ ").matcher( " ");          Matcher  matcher  =  Pattern.compile( "[^\\[\\]>]+ ").matcher( " ");  String  name;  SecureRandom  rand  =  new  SecureRandom();  int  len  =  randomIntBetween(1,  5);  char[]  word  =  new  char[len];  while(true)  {  for  (int  i  =  0;  i  <  word.length;  i++)  {  word[i]  =  (char)  rand.nextInt(127);  }  	Matcher  matcher  =  Pattern.compile( "[^\\[\\]>]+ ").matcher( " ");  
elasticsearch_ad9549462efd83f690ecec1fe74bca2fffad3b54	buggy:  termsRequest.sortType(TermsRequest.SortType.fromString(request.param( "sort "),  termsRequest.sortType()));  context:  termsRequest.lte(temp);  }  }  termsRequest.exact(request.paramAsBoolean( "exact ",  termsRequest.exact()));  termsRequest.minFreq(request.paramAsInt( "min_freq ",  termsRequest.minFreq()));  termsRequest.maxFreq(request.paramAsInt( "max_freq ",  termsRequest.maxFreq()));  termsRequest.size(request.paramAsInt( "size ",  termsRequest.size()));  termsRequest.prefix(request.param( "prefix "));  termsRequest.regexp(request.param( "regexp "));              termsRequest.sortType(TermsRequest.SortType.fromString(request.param( "sort "),  termsRequest.sortType()));              termsRequest.sortType(request.param( "sort "));  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  	termsRequest.sortType(request.param( "sort "));  
elasticsearch_e5f43a1867be80161f95551ef01c20d0a0fe3b3f	buggy:  clusterStateRequest.nodes(metrics.contains( "nodes "));  context:  final  String[]  indices  =  Strings.splitStringByCommaToArray(request.param( "indices ",   "_all "));  boolean  isAllIndicesOnly  =  indices.length  ==  1  &&   "_all ".equals(indices[0]);  if  (!isAllIndicesOnly)  {  clusterStateRequest.indices(indices);  }  Set<String>  metrics  =  Strings.splitStringByCommaToSet(request.param( "metric ",   "_all "));  boolean  isAllMetricsOnly  =  metrics.size()  ==  1  &&  metrics.contains( "_all ");  if  (!isAllMetricsOnly)  {              clusterStateRequest.nodes(metrics.contains( "nodes "));              clusterStateRequest.nodes(metrics.contains( "nodes ")  ||  metrics.contains( "master_node "));  clusterStateRequest.routingTable(metrics.contains( "routing_table "));  clusterStateRequest.metaData(metrics.contains( "metadata "));  clusterStateRequest.blocks(metrics.contains( "blocks "));  clusterStateRequest.indexTemplates(request.paramAsStringArray( "index_templates ",  Strings.EMPTY_ARRAY));  }  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  	clusterStateRequest.nodes(metrics.contains( "nodes ")  ||  metrics.contains( "master_node "));  
elasticsearch_e01f8c250d9c79911180b2e383fb184f4d278222	buggy:  return  new  NoneRecycler<byte[]>(RECYCLER_C);  context:  package  org.elasticsearch.common.recycler;  public  class  NoneRecyclerTests  extends  AbstractRecyclerTests  {  protected  Recycler<byte[]>  newRecycler()  {          return  new  NoneRecycler<byte[]>(RECYCLER_C);          return  Recyclers.none(RECYCLER_C);  }  }  	return  Recyclers.none(RECYCLER_C);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  docsAndPositions  !=  null;  context:  Fields  fields  =  response.getFields();  assertThat(fields.size(),  equalTo(1));  Terms  terms  =  fields.terms( "field ");  TermsEnum  iterator  =  terms.iterator(null);  while  (iterator.next()  !=  null)  {  String  term  =  iterator.term().utf8ToString();  DocsAndPositionsEnum  docsAndPositions  =  iterator.docsAndPositions(null,  null);  assertThat(docsAndPositions.nextDoc(),  equalTo(0));  List<BytesRef>  curPayloads  =  payloads.get(term);  assertThat(term,  curPayloads,  Matchers.notNullValue());              assert  docsAndPositions  !=  null;              assertNotNull(docsAndPositions);  for  (int  k  =  0;  k  <  docsAndPositions.freq();  k++)  {  docsAndPositions.nextPosition();  if  (docsAndPositions.getPayload()!=null){  String  infoString  =   "\nterm:   "  +  term  +   "  has  payload  \n "+  docsAndPositions.getPayload().toString()  +   "\n  but  should  have  payload  \n "+curPayloads.get(k).toString();  assertThat(infoString,  docsAndPositions.getPayload(),  equalTo(curPayloads.get(k)));  }  else  {  String  infoString  =   "\nterm:   "  +  term  +   "  has  no  payload  but  should  have  payload  \n "+curPayloads.get(k).toString();  assertThat(infoString,  curPayloads.get(k).length,  equalTo(0));  	assertNotNull(docsAndPositions);  
elasticsearch_57169d42334d39659bfcd8db2b062c7f6001a668	buggy:  StringBuilder  sb  =  new  StringBuilder( "ElasticSearch/ ");  context:  public  static  String  date()  {  return  date;  }  public  static  boolean  snapshotBuild()  {  return  snapshotBuild;  }  public  static  String  full()  {          StringBuilder  sb  =  new  StringBuilder( "ElasticSearch/ ");          StringBuilder  sb  =  new  StringBuilder( "elasticsearch/ ");  sb.append(number);  if  (snapshotBuild)  {  sb.append( "/ ").append(date);  }  return  sb.toString();  }  public  static  void  main(String[]  args)  {  	StringBuilder  sb  =  new  StringBuilder( "elasticsearch/ ");  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  client().prepareUpdate( "test ",   "type1 ",   "1 ").setScript( "test  script ").setTimeout(timeout).execute().actionGet();  context:  client().preparePercolate()  .setIndices( "test ").setDocumentType( "type1 ")  .setSource(percolateSource).execute().actionGet();  fail( "Expected  ClusterBlockException ");  }  catch  (ClusterBlockException  e)  {  assertThat(e.status(),  equalTo(RestStatus.SERVICE_UNAVAILABLE));  }  long  now  =  System.currentTimeMillis();  try  {              client().prepareUpdate( "test ",   "type1 ",   "1 ").setScript( "test  script ").setTimeout(timeout).execute().actionGet();              client().prepareUpdate( "test ",   "type1 ",   "1 ").setInlineScript( "test  script ").setTimeout(timeout).execute().actionGet();  fail( "Expected  ClusterBlockException ");  }  catch  (ClusterBlockException  e)  {  assertThat(System.currentTimeMillis()  -  now,  greaterThan(timeout.millis()  -  50));  assertThat(e.status(),  equalTo(RestStatus.SERVICE_UNAVAILABLE));  }  try  {  client().admin().indices().prepareAnalyze( "test ",   "this  is  a  test ").execute().actionGet();  	client().prepareUpdate( "test ",   "type1 ",   "1 ").setInlineScript( "test  script ").setTimeout(timeout).execute().actionGet();  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "clusterName ",  result.clusterName().value());  context:  String[]  nodesIds  =  RestActions.splitNodes(request.param( "nodeId "));  NodesShutdownRequest  nodesShutdownRequest  =  new  NodesShutdownRequest(nodesIds);  nodesShutdownRequest.listenerThreaded(false);  nodesShutdownRequest.delay(request.paramAsTime( "delay ",  nodesShutdownRequest.delay()));  client.admin().cluster().nodesShutdown(nodesShutdownRequest,  new  ActionListener<NodesShutdownResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();                      builder.field( "clusterName ",  result.clusterName().value());                      builder.field( "cluster_name ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodesShutdownResponse.NodeShutdownResponse  nodeInfo  :  result)  {  builder.startObject(nodeInfo.node().id());  builder.field( "name ",  nodeInfo.node().name());  builder.endObject();  }  builder.endObject();  	builder.field( "cluster_name ",  result.clusterName().value());  
elasticsearch_b02e6dc996d3985a8a136f290c4a8810ce05aaab	buggy:  NodesInfoResponse  nodesInfoResponse  =  client().admin().cluster().prepareNodesInfo().clear().setPlugin(true).get();  context:  FileSystemUtils.mkdirs(initialSettings.v2().pluginsFile());  }  return  new  PluginManager(initialSettings.v2(),  pluginUrl,  PluginManager.OutputMode.SILENT,  TimeValue.timeValueSeconds(30));  }  private  static  void  downloadAndExtract(String  pluginName,  String  pluginUrl)  throws  IOException  {  pluginManager(pluginUrl).downloadAndExtract(pluginName);  }  private  void  assertPluginLoaded(String  pluginName)  {          NodesInfoResponse  nodesInfoResponse  =  client().admin().cluster().prepareNodesInfo().clear().setPlugin(true).get();          NodesInfoResponse  nodesInfoResponse  =  client().admin().cluster().prepareNodesInfo().clear().setPlugins(true).get();  assertThat(nodesInfoResponse.getNodes().length,  equalTo(1));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos(),  notNullValue());  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().size(),  equalTo(1));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().get(0).getName(),  equalTo(pluginName));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().get(0).isSite(),  equalTo(true));  }  private  void  assertPluginAvailable(String  nodeName,  String  pluginName)  {  	NodesInfoResponse  nodesInfoResponse  =  client().admin().cluster().prepareNodesInfo().clear().setPlugins(true).get();  
libgdx_a6df7f89310e87781896d00ee26dbaddae3c0dd5	buggy:  if  (other.type  !=  other.type)  return  false;  context:  }  public  abstract  Attribute  copy();  protected  abstract  boolean  equals(Attribute  other);  public  boolean  equals  (Object  obj)  {  if  (obj  ==  null)  return  false;  if  (obj  ==  this)  return  true;  if  (!(obj  instanceof  Attribute))  return  false;  final  Attribute  other  =  (Attribute)obj;  if  (other.type  !=  other.type)  return  false;  if  (this.type  !=  other.type)  return  false;  return  equals(other);  }  public  String  toString  ()  {  return  Material.getAttributeAlias(type);  }  }  	if  (this.type  !=  other.type)  return  false;  
elasticsearch_a0f4359ffa324548c802fc66241d54df562026cc	buggy:  }  catch  (IOException  e)  {  context:  raf.increaseRefCount();  if  (useStream)  {  FsStreamSnapshot  newSnapshot  =  new  FsStreamSnapshot(shardId,  id,  raf,  lastPosition,  operationCounter.get(),  operationCounter.get()  -  snapshot.totalOperations());  newSnapshot.seekForward(snapshot.position());  return  newSnapshot;  }  else  {  FsChannelSnapshot  newSnapshot  =  new  FsChannelSnapshot(shardId,  id,  raf,  lastPosition,  operationCounter.get(),  operationCounter.get()  -  snapshot.totalOperations());  newSnapshot.seekForward(snapshot.position());  return  newSnapshot;  }              }  catch  (IOException  e)  {              }  catch  (Exception  e)  {  throw  new  TranslogException(shardId,   "Failed  to  snapshot ",  e);  }  }  }  synchronized  (mutex)  {  if  (raf  !=  null)  {  	}  catch  (Exception  e)  {  
elasticsearch_beb77c9b0ae5ca65026d9a4874bfd73aa47d9c60	buggy:  String  propName  =  Strings.toUnderscoreCase(entry.getKey());  context:  builder.includeInAll(nodeBooleanValue(fieldNode));  }  else  {  processField(builder,  fieldName,  fieldNode);  }  }  return  builder;  }  private  void  parseProperties(ObjectMapper.Builder  objBuilder,  Map<String,  Object>  propsNode,  ParserContext  parserContext)  {  for  (Map.Entry<String,  Object>  entry  :  propsNode.entrySet())  {                  String  propName  =  Strings.toUnderscoreCase(entry.getKey());                  String  propName  =  entry.getKey();  Map<String,  Object>  propNode  =  (Map<String,  Object>)  entry.getValue();  String  type;  Object  typeNode  =  propNode.get( "type ");  if  (typeNode  !=  null)  {  type  =  typeNode.toString();  }  else  {  	String  propName  =  entry.getKey();  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  return  newPixmap(file.readFile());  context:  public  Pixmap  newPixmap  (InputStream  in)  {  try  {  BufferedImage  img  =  (BufferedImage)ImageIO.read(in);  return  new  LwjglPixmap(img);  }  catch  (Exception  ex)  {  throw  new  GdxRuntimeException( "Couldn't  load  Pixmap  from  InputStream ",  ex);  }  }  public  Pixmap  newPixmap  (FileHandle  file)  {  return  newPixmap(file.readFile());  return  newPixmap(file.read());  }  public  Pixmap  newPixmap  (Object  nativePixmap)  {  return  new  LwjglPixmap((BufferedImage)nativePixmap);  }  public  Texture  newUnmanagedTexture  (int  width,  int  height,  Pixmap.Format  format,  TextureFilter  minFilter,  TextureFilter  magFilter,  TextureWrap  uWrap,  TextureWrap  vWrap)  {  	return  newPixmap(file.read());  
libgdx_32b98412f7409d91e046a8ede5b988c00464e9c6	buggy:  public  void  purchase  (com.badlogic.gdx.pay.PurchaseListener  listener,  String  identifier)  {  context:  handler.sendEmptyMessage(requestPurchaseRestore);  }  public  void  requestProductList  ()  {  handler.sendEmptyMessage(requestOUYAproducts);  }  public  void  purchase  (com.badlogic.gdx.pay.PurchaseListener  listener,  String  identifier)  {  public  void  purchase  (String  identifier,  com.badlogic.gdx.pay.PurchaseListener  listener)  {  this.appPurchaseListener  =  listener;  //  store  the  listener  OUYApurchaseProduct  =  getProduct(identifier);  if  (OUYApurchaseProduct  !=  null)  {  try  {  requestPurchase(OUYApurchaseProduct);  	public  void  purchase  (String  identifier,  com.badlogic.gdx.pay.PurchaseListener  listener)  {  
libgdx_5f758806661bca13539eda2d3f18b68523fb1e19	buggy:  JoglApplication  app  =  new  JoglApplication(   "Float  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.desktop;  public  class  BitmapFontTest  {  public  static  void  main(  String[]  argv  )  {  JoglApplication  app  =  new  JoglApplication(   "Float  Test ",  480,  320,  false);  JoglApplication  app  =  new  JoglApplication(   "BitmapFont  Test ",  480,  320,  false);  app.getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.BitmapFontTest()  );  }  }  	JoglApplication  app  =  new  JoglApplication(   "BitmapFont  Test ",  480,  320,  false);  
libgdx_892fa8582b813351cb51bc4a79dd0e61f6820c51	buggy:  return  null;  context:  return  deltaTime;  }  public  int  getFramesPerSecond()  {  return  fps;  }  public  GraphicsType  getType()  {  return  null;  return  GraphicsType.iOSGL;  }  public  float  getPpiX()  {  return  0;  }  	return  GraphicsType.iOSGL;  
libgdx_4e1cc538aaa75a9d0e9514effa6e3f3beeab3985	buggy:  handles[i]  =  child(path);  context:  public  FileHandle[]  list  (String  suffix)  {  if  (type  ==  FileType.Classpath)  throw  new  GdxRuntimeException( "Cannot  list  a  classpath  directory:   "  +  file);  String[]  relativePaths  =  file().list();  if  (relativePaths  ==  null)  return  new  FileHandle[0];  FileHandle[]  handles  =  new  FileHandle[relativePaths.length];  int  count  =  0;  for  (int  i  =  0,  n  =  relativePaths.length;  i  <  n;  i++)  {  String  path  =  relativePaths[i];  if  (!path.endsWith(suffix))  continue;  handles[i]  =  child(path);  handles[count]  =  child(path);  count++;  }  if  (count  <  relativePaths.length)  {  FileHandle[]  newHandles  =  new  FileHandle[count];  System.arraycopy(handles,  0,  newHandles,  0,  count);  handles  =  newHandles;  }  return  handles;  	handles[count]  =  child(path);  
elasticsearch_111f9cb751f466de13300b9437ea5358d0c24d03	buggy:  return  source  ==  null;  context:  this.index  =  index;  this.type  =  type;  this.id  =  id;  this.source  =  source;  }  public  boolean  exists()  {          return  source  ==  null;          return  source  !=  null  &&  source.length  >  0;  }  public  String  index()  {  return  this.index;  }  	return  source  !=  null  &&  source.length  >  0;  
libgdx_62576adba23525c8ff7351ba004cd8a029fcb48c	buggy:  time  =  (diff  <  0f)  ?  duration  :  0f;  context:  time  +=  duration;  }  time  =  Math.abs(time  %  duration);  for  (int  i  =  0;  i  <  loops;  i++)  {  if  (loopCount  >  0)  loopCount--;  if  (loopCount  !=  0  &&  listener  !=  null)  listener.onLoop(this);  if  (loopCount  ==  0)  {  final  float  result  =  ((loops  -  1)  -  i)  *  duration  +  (diff  <  0f  ?  duration  -  time  :  time);  time  =  (diff  <  0f)  ?  duration  :  0f;  time  =  (diff  <  0f)  ?  0f  :  duration;  if  (listener  !=  null)  listener.onEnd(this);  return  result;  }  }  return  0f;  }  else  return  delta;  	time  =  (diff  <  0f)  ?  0f  :  duration;  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  FloatArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  FloatArrayAtomicFieldData.WithOrdinals(  values.toArray(new  float[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  FloatValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_b970f0dcc266a358e0a88d29f3bbcf41854da7a1	buggy:  String  suffix  =   " ";  context:  return  ((double)  bytes())  /  ByteSizeUnit.C3;  }  public  double  getGbFrac()  {  return  gbFrac();  }  long  bytes  =  bytes();  double  value  =  bytes;          String  suffix  =   " ";          String  suffix  =   "b ";  if  (bytes  >=  ByteSizeUnit.C3)  {  value  =  gbFrac();  suffix  =   "gb ";  }  else  if  (bytes  >=  ByteSizeUnit.C2)  {  value  =  mbFrac();  suffix  =   "mb ";  }  else  if  (bytes  >=  ByteSizeUnit.C1)  {  value  =  kbFrac();  	String  suffix  =   "b ";  
elasticsearch_683be6fc645fe3e917caeb883d3f29c63a6763a2	buggy:  UidFilter  filter  =  new  UidFilter(types,  ids,  parseContext.indexCache().bloomCache());  context:  if  (ids.size()  ==  0)  {  throw  new  QueryParsingException(parseContext.index(),   "[ids]  filter,  no  ids  values  provided ");  }  if  (types  ==  null  ||  types.isEmpty())  {  types  =  parseContext.queryTypes();  }  else  if  (types.size()  ==  1  &&  Iterables.getFirst(types,  null).equals( "_all "))  {  types  =  parseContext.mapperService().types();  }          UidFilter  filter  =  new  UidFilter(types,  ids,  parseContext.indexCache().bloomCache());          UidFilter  filter  =  new  UidFilter(types,  ids);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  return  filter;  }  }  	UidFilter  filter  =  new  UidFilter(types,  ids);  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.byteSizeField(Fields.SIZE,  Fields.SIZE_IN_BYTES,  segment.getSizeInBytes());  context:  builder.field(Fields.NUM_COMMITTED_SEGMENTS,  shardSegments.getNumberOfCommitted());  builder.field(Fields.NUM_SEARCH_SEGMENTS,  shardSegments.getNumberOfSearch());  builder.startObject(Fields.SEGMENTS);  for  (Segment  segment  :  shardSegments)  {  builder.startObject(segment.getName());  builder.field(Fields.GENERATION,  segment.getGeneration());  builder.field(Fields.NUM_DOCS,  segment.getNumDocs());  builder.field(Fields.DELETED_DOCS,  segment.getDeletedDocs());                          builder.byteSizeField(Fields.SIZE,  Fields.SIZE_IN_BYTES,  segment.getSizeInBytes());                          builder.byteSizeField(Fields.SIZE_IN_BYTES,  Fields.SIZE,  segment.getSizeInBytes());  builder.field(Fields.COMMITTED,  segment.isCommitted());  builder.field(Fields.SEARCH,  segment.isSearch());  if  (segment.getVersion()  !=  null)  {  builder.field(Fields.VERSION,  segment.getVersion());  }  if  (segment.isCompound()  !=  null)  {  builder.field(Fields.COMPOUND,  segment.isCompound());  }  	builder.byteSizeField(Fields.SIZE_IN_BYTES,  Fields.SIZE,  segment.getSizeInBytes());  
elasticsearch_ee3cbce11804b1bc1ae49cc3245753422a24277a	buggy:  handleRequest(request,  channel,  usefulHeaders.size()  ==  0  ?  client  :  new  HeadersAndContextCopyClient(client,  request,  usefulHeaders));  context:  private  final  Client  client;  protected  BaseRestHandler(Settings  settings,  Client  client)  {  super(settings);  this.client  =  client;  }  public  final  void  handleRequest(RestRequest  request,  RestChannel  channel)  throws  Exception  {          handleRequest(request,  channel,  usefulHeaders.size()  ==  0  ?  client  :  new  HeadersAndContextCopyClient(client,  request,  usefulHeaders));          handleRequest(request,  channel,  new  HeadersAndContextCopyClient(client,  request,  usefulHeaders));  }  protected  abstract  void  handleRequest(RestRequest  request,  RestChannel  channel,  Client  client)  throws  Exception;  static  final  class  HeadersAndContextCopyClient  extends  FilterClient  {  private  final  RestRequest  restRequest;  private  final  IndicesAdmin  indicesAdmin;  	handleRequest(request,  channel,  new  HeadersAndContextCopyClient(client,  request,  usefulHeaders));  
elasticsearch_6804c02e97628700e589498dbf56fde2f41aa617	buggy:  File  nodeWork  =  ((InternalNode)  nodes[nodeIndex]).injector().getInstance(NodeEnvironment.class).nodeLocation();  context:  }  for  (int  i  =  0;  i  <  indexerThreads.length;  i++)  {  indexerThreads[i].start();  }  long  testStart  =  System.currentTimeMillis();  int  nodeIndex  =  0;  while  (true)  {              File  nodeWork  =  ((InternalNode)  nodes[nodeIndex]).injector().getInstance(NodeEnvironment.class).nodeLocation();              File  nodeWork  =  ((InternalNode)  nodes[nodeIndex]).injector().getInstance(NodeEnvironment.class).nodeDataLocation();  nodes[nodeIndex].close();  if  (clearNodeWork)  {  FileSystemUtils.deleteRecursively(nodeWork);  }  nodes[nodeIndex]  =  NodeBuilder.nodeBuilder().settings(settings).node();  try  {  ClusterHealthResponse  clusterHealth  =  client.client().admin().cluster().prepareHealth().setWaitForGreenStatus().setTimeout( "10m ").execute().actionGet();  	File  nodeWork  =  ((InternalNode)  nodes[nodeIndex]).injector().getInstance(NodeEnvironment.class).nodeDataLocation();  
elasticsearch_91c4824a0f768f2d3e3651958656384d0735a85e	buggy:  HashSet<DiscoveryNode>  newNodes  =  new  HashSet<>(listedNodes);  context:  }  });  }  try  {  latch.await();  }  catch  (InterruptedException  e)  {  return;  }              HashSet<DiscoveryNode>  newNodes  =  new  HashSet<>(listedNodes);              HashSet<DiscoveryNode>  newNodes  =  new  HashSet<>();  HashSet<DiscoveryNode>  newFilteredNodes  =  new  HashSet<>();  for  (Map.Entry<DiscoveryNode,  ClusterStateResponse>  entry  :  clusterStateResponses.entrySet())  {  if  (!ignoreClusterName  &&  !clusterName.equals(entry.getValue().getClusterName()))  {  newFilteredNodes.add(entry.getKey());  continue;  }  for  (ObjectCursor<DiscoveryNode>  cursor  :  entry.getValue().getState().nodes().dataNodes().values())  {  	HashSet<DiscoveryNode>  newNodes  =  new  HashSet<>();  
elasticsearch_66c9f2f8344bdf9e58e0bc8a9fb59a527ec547cf	buggy:  throw  new  QueryPhaseExecutionException(searchContext,   " ",  e);  context:  }  TopDocs  topDocs;  if  (searchContext.sort()  !=  null)  {  topDocs  =  searchContext.searcher().search(query,  null,  searchContext.from()  +  searchContext.size(),  searchContext.sort());  }  else  {  topDocs  =  searchContext.searcher().search(query,  searchContext.from()  +  searchContext.size());  }  searchContext.queryResult().topDocs(topDocs);  }  catch  (Exception  e)  {              throw  new  QueryPhaseExecutionException(searchContext,   " ",  e);              throw  new  QueryPhaseExecutionException(searchContext,   "Failed  to  execute  main  query ",  e);  }  facetsPhase.execute(searchContext);  }  }  	throw  new  QueryPhaseExecutionException(searchContext,   "Failed  to  execute  main  query ",  e);  
elasticsearch_104613c0b95b43c6f532af9df12a32df491de1a7	buggy:  String  source  =  client().admin().indices().prepareGetMappings( "test ").setTypes( "type ").get().getMappings().get( "test ").get( "type ").source().string();  context:  }  });  RefreshResponse  refreshResponse  =  client().admin().indices().prepareRefresh().execute().actionGet();  assertThat(refreshResponse.getFailedShards(),  equalTo(0));  CountResponse  response  =  client().prepareCount( "test ").execute().actionGet();  assertThat(response.getCount(),  equalTo((long)  recCount));          String  source  =  client().admin().indices().prepareGetMappings( "test ").setTypes( "type ").get().getMappings().get( "test ").get( "type ").source().string();          String  source  =  client().admin().cluster().prepareState().get().getState().getMetaData().getIndices().get( "test ").getMappings().get( "type ").source().string();  for  (int  rec  =  0;  rec  <  recCount;  rec++)  {  assertThat(source,  containsString( "\ "field "  +  rec  +   "\ " "));  }  }  public  void  updateMappingWithConflicts()  throws  Exception  {  	String  source  =  client().admin().cluster().prepareState().get().getState().getMetaData().getIndices().get( "test ").getMappings().get( "type ").source().string();  
elasticsearch_e8a0ccc20c2bf9fe7cee6699ed85886b198718d3	buggy:  return  ThreadPool.Names.INDEX;  context:  public  TransportShardBulkAction(Settings  settings,  TransportService  transportService,  ClusterService  clusterService,  IndicesService  indicesService,  ThreadPool  threadPool,  ShardStateAction  shardStateAction,  MappingUpdatedAction  mappingUpdatedAction)  {  super(settings,  transportService,  clusterService,  indicesService,  threadPool,  shardStateAction);  this.mappingUpdatedAction  =  mappingUpdatedAction;  }  protected  String  executor()  {          return  ThreadPool.Names.INDEX;          return  ThreadPool.Names.BULK;  }  protected  boolean  checkWriteConsistency()  {  return  true;  }  	return  ThreadPool.Names.BULK;  
elasticsearch_4f4471483de7638880e81da935cc4a4a2f7da4bb	buggy:  RoutingNodes  routingNodes  =  routingTable.routingNodes(clusterState.metaData());  context:  .build();  ClusterState  clusterState  =  newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();  clusterState  =  newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().put(newNode( "node1 "))).build();  routingTable  =  strategy.reroute(clusterState);  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();          RoutingNodes  routingNodes  =  routingTable.routingNodes(clusterState.metaData());          RoutingNodes  routingNodes  =  clusterState.routingNodes();  routingTable  =  strategy.applyStartedShards(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING));  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  assertThat(routingTable.shardsWithState(STARTED).size(),  equalTo(5));  clusterState  =  newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().putAll(clusterState.nodes()).put(newNode( "node2 "))).build();  routingTable  =  strategy.reroute(clusterState);  	RoutingNodes  routingNodes  =  clusterState.routingNodes();  
libgdx_483385602cb3f57e53949f48cc4629be1bc0eb01	buggy:  gl  =  new  JoglGL10(GLContext.getCurrent().getGL());  context:  public  AudioDevice  getAudioDevice()  {  return  new  JoglAudioDevice();  }  public  GL10  getGL()  {  if(  gl  ==  null  )  gl  =  new  JoglGL10(GLContext.getCurrent().getGL());  gl  =  new  JoglGL11(GLContext.getCurrent().getGL());  return  gl;  }  }  	gl  =  new  JoglGL11(GLContext.getCurrent().getGL());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Document>  docs  =  new  ArrayList<Document>();  context:  public  class  NestedSortingTests  extends  AbstractFieldDataTests  {  protected  FieldDataType  getFieldDataType()  {  return  new  FieldDataType( "string ",  ImmutableSettings.builder().put( "format ",   "paged_bytes "));  }  public  void  testNestedSorting()  throws  Exception  {          List<Document>  docs  =  new  ArrayList<Document>();          List<Document>  docs  =  new  ArrayList<>();  Document  document  =  new  Document();  document.add(new  StringField( "field2 ",   "a ",  Field.Store.NO));  document.add(new  StringField( "filter_1 ",   "T ",  Field.Store.NO));  docs.add(document);  document  =  new  Document();  document.add(new  StringField( "field2 ",   "b ",  Field.Store.NO));  document.add(new  StringField( "filter_1 ",   "T ",  Field.Store.NO));  docs.add(document);  	List<Document>  docs  =  new  ArrayList<>();  
elasticsearch_4567b326cf4ff54c77c6baf59994354166f459c7	buggy:  throw  new  ElasticsearchGenerationException( "Failed  to  generate  [ "  +  source  +   "] ",  e);  context:  this.extraSourceUnsafe  =  false;  return  this;  }  public  SearchRequest  extraSource(Map  extraSource)  {  try  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(Requests.CONTENT_TYPE);  builder.map(extraSource);  return  extraSource(builder);  }  catch  (IOException  e)  {              throw  new  ElasticsearchGenerationException( "Failed  to  generate  [ "  +  source  +   "] ",  e);              throw  new  ElasticsearchGenerationException( "Failed  to  generate  [ "  +  extraSource  +   "] ",  e);  }  }  public  SearchRequest  extraSource(XContentBuilder  builder)  {  this.extraSource  =  builder.bytes();  this.extraSourceUnsafe  =  false;  return  this;  }  	throw  new  ElasticsearchGenerationException( "Failed  to  generate  [ "  +  extraSource  +   "] ",  e);  
libgdx_065aa34a06edfd7801e3d3c3c7a8e276386ae5f5	buggy:  private  native  boolean  jniEnableMotor(  long  addr,  boolean  flag  );  context:  private  native  boolean  jniIsMotorEnabled(  long  addr  );  public  void  enableMotor(boolean  flag)  {  jniEnableMotor(  addr,  flag  );  }  private  native  boolean  jniEnableMotor(  long  addr,  boolean  flag  );  private  native  void  jniEnableMotor(  long  addr,  boolean  flag  );  public  void  setMotorSpeed(float  speed)  {  jniSetMotorSpeed(  addr,  speed  );  }  	private  native  void  jniEnableMotor(  long  addr,  boolean  flag  );  
elasticsearch_e0b280f9b3dc1bf64b35a0d009abe07f3df55686	buggy:  assert  fieldname.equals(indexFieldData.getFieldName());  context:  this.missingValue  =  missingValue;  }  public  SortField.Type  reducedType()  {  return  SortField.Type.DOUBLE;  }  public  FieldComparator<?>  newComparator(String  fieldname,  int  numHits,  int  sortPos,  boolean  reversed)  throws  IOException  {          assert  fieldname.equals(indexFieldData.getFieldName());          assert  fieldname.equals(indexFieldData.getFieldNames().indexName());  double  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Double.NEGATIVE_INFINITY  :  Double.POSITIVE_INFINITY;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Double.POSITIVE_INFINITY  :  Double.NEGATIVE_INFINITY;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).doubleValue()  :  Double.parseDouble(missingValue.toString());  	assert  fieldname.equals(indexFieldData.getFieldNames().indexName());  
elasticsearch_f0914d13af4e4c0a2c363e9e64c930e815d8aaba	buggy:  injector.getInstance(CacheRecycler.class).clear();  context:  }  catch  (Exception  e)  {  }  stopWatch.stop();  if  (logger.isTraceEnabled())  {  }  injector.getInstance(NodeEnvironment.class).close();          injector.getInstance(CacheRecycler.class).clear();          injector.getInstance(CacheRecycler.class).close();  Injectors.close(injector);  CachedStreams.clear();  ThreadLocals.clearReferencesThreadLocals();  }  	injector.getInstance(CacheRecycler.class).close();  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  indicesService.deleteIndex(request.index,  failureReason  !=  null  ?  failureReason  :   "failed  to  create  index ");  context:  listener.onResponse(new  Response(false,  indexMetaData));  nodeIndexCreatedAction.remove(nodeIndexCreatedListener);  }  });  return  updatedState;  }  catch  (Throwable  e)  {  if  (indexCreated)  {                          indicesService.deleteIndex(request.index,  failureReason  !=  null  ?  failureReason  :   "failed  to  create  index ");                          indicesService.removeIndex(request.index,  failureReason  !=  null  ?  failureReason  :   "failed  to  create  index ");  }  listener.onFailure(e);  return  currentState;  }  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  	indicesService.removeIndex(request.index,  failureReason  !=  null  ?  failureReason  :   "failed  to  create  index ");  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "child_type  must  be  set  on  children  aggregation  [ "  +  name  +   "] ");  context:  public  ChildrenBuilder  childType(String  childType)  {  this.childType  =  childType;  return  this;  }  protected  XContentBuilder  internalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject();  if  (childType  ==  null)  {              throw  new  SearchSourceBuilderException( "child_type  must  be  set  on  children  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "child_type  must  be  set  on  children  aggregation  [ "  +  getName()  +   "] ");  }  builder.field( "type ",  childType);  return  builder.endObject();  }  }  	throw  new  SearchSourceBuilderException( "child_type  must  be  set  on  children  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_adb5c198491fc3dce97778ed935a0c2b1efc12ea	buggy:  ((IndicesAdminClient)  client).getAliases(request,  listener);  context:  public  class  GetAliasesRequestBuilder  extends  BaseAliasesRequestBuilder<GetAliasesResponse,  GetAliasesRequestBuilder>  {  public  GetAliasesRequestBuilder(IndicesAdminClient  client,  String...  aliases)  {  super(client,  aliases);  }  protected  void  doExecute(ActionListener<GetAliasesResponse>  listener)  {          ((IndicesAdminClient)  client).getAliases(request,  listener);          client.getAliases(request,  listener);  }  }  	client.getAliases(request,  listener);  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  clusterRerouteRequest.listenerThreaded(false);  clusterRerouteRequest.dryRun(request.paramAsBoolean( "dry_run ",  clusterRerouteRequest.dryRun()));  clusterRerouteRequest.explain(request.paramAsBoolean( "explain ",  clusterRerouteRequest.explain()));  clusterRerouteRequest.timeout(request.paramAsTime( "timeout ",  clusterRerouteRequest.timeout()));  clusterRerouteRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterRerouteRequest.masterNodeTimeout()));  if  (request.hasContent())  {  try  {  clusterRerouteRequest.source(request.content());  }  catch  (Exception  e)  {  try  {                      channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                      channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  }  client.admin().cluster().reroute(clusterRerouteRequest,  new  AcknowledgedRestResponseActionListener<ClusterRerouteResponse>(request,  channel,  logger)  {  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_f1e23067cd641e27efcc0523161a3904b7d06ae3	buggy:  return  FieldSelectorResult.LOAD_AND_BREAK;  context:  public  SingleFieldSelector(String  name)  {  this.name  =  name;  }  public  void  name(String  name)  {  this.name  =  name;  }  if  (name.equals(fieldName))  {              return  FieldSelectorResult.LOAD_AND_BREAK;              return  FieldSelectorResult.LOAD;  }  return  FieldSelectorResult.NO_LOAD;  }  }  }  	return  FieldSelectorResult.LOAD;  
libgdx_4bfa5a9a87603d026360aaedfc7771a07d77845a	buggy:  return  bitmapFont.computeVisibleGlpyhs(str,  start,  end,  width);  context:  public  int  computeTextWidth  (CharSequence  str)  {  return  bitmapFont.getBounds(str).width;  }  public  int  computeTextWidth  (CharSequence  str,  int  start,  int  end)  {  return  bitmapFont.getBounds(str,  start,  end).width;  }  public  int  computeVisibleGlpyhs  (CharSequence  str,  int  start,  int  end,  int  width)  {  return  bitmapFont.computeVisibleGlpyhs(str,  start,  end,  width);  return  bitmapFont.computeVisibleGlyphs(str,  start,  end,  width);  }  FontState  evalFontState  (AnimationState  animationState)  {  int  i  =  0;  for  (int  n  =  fontStates.length  -  1;  i  <  n;  i++)  if  (fontStates[i].condition.evaluate(animationState))  break;  return  fontStates[i];  }  	return  bitmapFont.computeVisibleGlyphs(str,  start,  end,  width);  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  builder.addSurface(spare.surfaceForm,  spare.payload,  spare.weight);  context:  this.builder  =  builder;  }  public  void  startDoc(int  docID,  int  freq)  throws  IOException  {  }  public  void  addPosition(int  position,  BytesRef  payload,  int  startOffset,  int  endOffset)  throws  IOException  {  analyzingSuggestLookupProvider.parsePayload(payload,  spare);              builder.addSurface(spare.surfaceForm,  spare.payload,  spare.weight);              builder.addSurface(spare.surfaceForm.get(),  spare.payload.get(),  spare.weight);  maxAnalyzedPathsForOneInput  =  Math.max(maxAnalyzedPathsForOneInput,  position  +  1);  }  public  void  finishDoc()  throws  IOException  {  }  	builder.addSurface(spare.surfaceForm.get(),  spare.payload.get(),  spare.weight);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  SpanMultiTermQueryWrapper<MultiTermQuery>((MultiTermQuery)  subQuery);  context:  if  (token  !=  XContentParser.Token.START_OBJECT)  {  throw  new  QueryParsingException(parseContext.index(),   "spanMultiTerm  must  have  [ "  +  MATCH_NAME  +   "]  multi  term  query  clause ");  }  Query  subQuery  =  parseContext.parseInnerQuery();  if  (!(subQuery  instanceof  MultiTermQuery))  {  throw  new  QueryParsingException(parseContext.index(),   "spanMultiTerm  [ "  +  MATCH_NAME  +   "]  must  be  of  type  multi  term  query ");  }  parser.nextToken();          return  new  SpanMultiTermQueryWrapper<MultiTermQuery>((MultiTermQuery)  subQuery);          return  new  SpanMultiTermQueryWrapper<>((MultiTermQuery)  subQuery);  }  }  	return  new  SpanMultiTermQueryWrapper<>((MultiTermQuery)  subQuery);  
elasticsearch_2eee92726c6ad29d22415c8ac671ef9c695a377a	buggy:  SizeValue  capacity  =  settings.getAsSize( "capacity ",  settings.getAsSize( "queue_size ",  defaultSettings.getAsSize( "queue_size ",  null)));  context:  }  else  if  ( "cached ".equals(type))  {  TimeValue  keepAlive  =  settings.getAsTime( "keep_alive ",  defaultSettings.getAsTime( "keep_alive ",  timeValueMinutes(5)));  Executor  executor  =  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAlive.millis(),  TimeUnit.MILLISECONDS,  new  SynchronousQueue<Runnable>(),  threadFactory);  return  new  ExecutorHolder(executor,  new  Info(name,  type,  -1,  -1,  keepAlive,  null));  }  else  if  ( "fixed ".equals(type))  {  int  size  =  settings.getAsInt( "size ",  defaultSettings.getAsInt( "size ",  Runtime.getRuntime().availableProcessors()  *  5));              SizeValue  capacity  =  settings.getAsSize( "capacity ",  settings.getAsSize( "queue_size ",  defaultSettings.getAsSize( "queue_size ",  null)));              SizeValue  capacity  =  settings.getAsSize( "capacity ",  settings.getAsSize( "queue ",  settings.getAsSize( "queue_size ",  defaultSettings.getAsSize( "queue ",  defaultSettings.getAsSize( "queue_size ",  null)))));  RejectedExecutionHandler  rejectedExecutionHandler;  String  rejectSetting  =  settings.get( "reject_policy ",  defaultSettings.get( "reject_policy ",   "abort "));  if  ( "abort ".equals(rejectSetting))  {  rejectedExecutionHandler  =  EsAbortPolicy.INSTANCE;  }  else  if  ( "caller ".equals(rejectSetting))  {  rejectedExecutionHandler  =  new  ThreadPoolExecutor.CallerRunsPolicy();  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "reject_policy  [ "  +  rejectSetting  +   "]  not  valid  for  [ "  +  name  +   "]  thread  pool ");  	SizeValue  capacity  =  settings.getAsSize( "capacity ",  settings.getAsSize( "queue ",  settings.getAsSize( "queue_size ",  defaultSettings.getAsSize( "queue ",  defaultSettings.getAsSize( "queue_size ",  null)))));  
elasticsearch_498e0b418a0244bb54ba71f35353304c93f0df82	buggy:  table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  stats.getOs().getLoadAverage()[0]);  context:  table.addCell(info  ==  null  ?  null  :  info.getProcess().id());  table.addCell(((InetSocketTransportAddress)  node.address()).address().getAddress().getHostAddress());  table.addCell(((InetSocketTransportAddress)  node.address()).address().getPort());  table.addCell(info  ==  null  ?  null  :  info.getVersion().number());  table.addCell(info  ==  null  ?  null  :  info.getJvm().version());  table.addCell(availableDisk  <  0  ?  null  :  ByteSizeValue.parseBytesSizeValue(new  Long(availableDisk).toString()));  table.addCell(heapRatio  <  0  ?  null  :  String.format(Locale.ROOT,   "%.1f ",  heapRatio*100.0));  table.addCell(heapMax  <  0  ?  null  :  new  ByteSizeValue(heapMax));  table.addCell(stats  ==  null  ?  null  :  stats.getOs().mem()  ==  null  ?  null  :  stats.getOs().mem().usedPercent());  table.addCell(info  ==  null  ?  null  :  info.getOs().mem()  ==  null  ?  null  :  info.getOs().mem().total());  //  sigar  fails  to  load  in  IntelliJ              table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  stats.getOs().getLoadAverage()[0]);              table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  String.format(Locale.ROOT,   "%.2f ",  stats.getOs().getLoadAverage()[0]));  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().uptime());  table.addCell(node.clientNode()  ?   "c "  :  node.dataNode()  ?   "d "  :   "- ");  table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  table.addCell(node.name());  table.endRow();  }  	table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  String.format(Locale.ROOT,   "%.2f ",  stats.getOs().getLoadAverage()[0]));  
elasticsearch_49c74e08859736d09add31436554dfa76e395dd8	buggy:  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  context:  }  }  private  void  innerFinishHim()  throws  IOException  {  sortedShardList  =  searchPhaseController.sortDocs(request,  useSlowScroll,  firstResults);  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  firstResults,  firstResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  firstResults,  null);  }              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  final  Set<IntsRef>  ref  =  XSpecialOperations.getFiniteStrings(automaton,  -1);  context:  }  public  TokenStreamToAutomaton  getTokenStreamToAutomaton()  {  final  TokenStreamToAutomaton  tsta  =  super.getTokenStreamToAutomaton();  tsta.setUnicodeArcs(unicodeAware);  return  tsta;  }  Automaton  toLevenshteinAutomata(Automaton  automaton)  {          final  Set<IntsRef>  ref  =  XSpecialOperations.getFiniteStrings(automaton,  -1);          final  Set<IntsRef>  ref  =  SpecialOperations.getFiniteStrings(automaton,  -1);  Automaton  subs[]  =  new  Automaton[ref.size()];  int  upto  =  0;  for  (IntsRef  path  :  ref)  {  if  (path.length  <=  nonFuzzyPrefix  ||  path.length  <  minFuzzyLength)  {  subs[upto]  =  BasicAutomata.makeString(path.ints,  path.offset,  path.length);  upto++;  }  else  {  Automaton  prefix  =  BasicAutomata.makeString(path.ints,  path.offset,  nonFuzzyPrefix);  	final  Set<IntsRef>  ref  =  SpecialOperations.getFiniteStrings(automaton,  -1);  
elasticsearch_8f9693063820fb7417c53e7fbe8b10ddcd16c422	buggy:  multiGetRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  context:  this.allowExplicitIndex  =  settings.getAsBoolean( "rest.action.multi.allow_explicit_index ",  true);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest();  multiGetRequest.listenerThreaded(false);  multiGetRequest.refresh(request.paramAsBoolean( "refresh ",  multiGetRequest.refresh()));  multiGetRequest.preference(request.param( "preference "));          multiGetRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));          multiGetRequest.realtime(request.paramAsBoolean( "realtime ",  null));  String[]  sFields  =  null;  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  sFields  =  Strings.splitStringByCommaToArray(sField);  }  FetchSourceContext  defaultFetchSource  =  FetchSourceContext.parseFromRestRequest(request);  	multiGetRequest.realtime(request.paramAsBoolean( "realtime ",  null));  
elasticsearch_45956a5a270c4956755e43ebd9142705f367a196	buggy:  return  docSet;  context:  DocSet  docSet  =  cacheValue.value().get(filter);  if  (docSet  !=  null)  {  return  docSet;  }  DocIdSet  docIdSet  =  filter.getDocIdSet(reader);  docSet  =  FilterCacheValue.cacheable(reader,  cacheValue.longsLAB(),  docIdSet);  DocSet  prev  =  cacheValue.value().putIfAbsent(filter,  docSet);  if  (prev  !=  null)  {  docSet  =  prev;  }              return  docSet;              return  docSet  ==  DocSet.EMPTY_DOC_SET  ?  null  :  docSet;  }  public  String  toString()  {  return   "FilterCacheFilterWrapper( "  +  filter  +   ") ";  }  public  boolean  equals(Object  o)  {  if  (!(o  instanceof  FilterCacheFilterWrapper))  return  false;  	return  docSet  ==  DocSet.EMPTY_DOC_SET  ?  null  :  docSet;  
elasticsearch_720edafa0d8d357a59f4e1bd3fed0f6a6dfbd4c3	buggy:  boolean  verbose  =  request.paramAsBoolean( "v ",  true);  context:  builder.field(headerName,  renderValue(request,  row.get(i).value));  }  }  builder.endObject();  }  builder.endArray();  return  new  XContentRestResponse(request,  RestStatus.OK,  builder);  }  public  static  RestResponse  buildTextPlainResponse(Table  table,  RestRequest  request,  RestChannel  channel)  {          boolean  verbose  =  request.paramAsBoolean( "v ",  true);          boolean  verbose  =  request.paramAsBoolean( "v ",  false);  int[]  width  =  buildWidths(table,  request,  verbose);  Set<String>  displayHeaders  =  buildDisplayHeaders(table,  request);  StringBuilder  out  =  new  StringBuilder();  if  (verbose)  {  for  (int  i  =  0;  i  <  width.length;  i++)  {  String  headerName  =  table.getHeaders().get(i).value.toString();  	boolean  verbose  =  request.paramAsBoolean( "v ",  false);  
elasticsearch_fffa6a21dcc8157de5ba98774b738c82cdb42da7	buggy:  String  newPath  =  optionalPathPrefix  +  File.separator  +  path;  context:  collectFiles(resolveFile(optionalPathPrefix,  path,  YAML_SUFFIX),  YAML_SUFFIX,  yamlSuites);  }  return  yamlSuites;  }  private  static  File  resolveFile(String  optionalPathPrefix,  String  path,  String  optionalFileSuffix)  throws  FileNotFoundException  {  URL  resource  =  findResource(path,  optionalFileSuffix);  if  (resource  ==  null)  {              String  newPath  =  optionalPathPrefix  +  File.separator  +  path;              String  newPath  =  optionalPathPrefix  +   "/ "  +  path;  resource  =  findResource(newPath,  optionalFileSuffix);  if  (resource  ==  null)  {  File  file  =  findFile(path,  optionalFileSuffix);  if  (!file.exists())  {  throw  new  FileNotFoundException( "file  [ "  +  path  +   "]  doesn't  exist ");  }  return  file;  	String  newPath  =  optionalPathPrefix  +   "/ "  +  path;  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (parentFieldMapper  !=  null)  {  context:  Map<Object,  Map<String,  TypeBuilder>>  builders  =  new  HashMap<Object,  Map<String,  TypeBuilder>>();  Map<Object,  IndexReader>  cacheToReader  =  new  HashMap<Object,  IndexReader>();  NavigableSet<HashedBytesArray>  parentTypes  =  new  TreeSet<HashedBytesArray>(UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder);  BytesRef  spare  =  new  BytesRef();  for  (String  type  :  indexService.mapperService().types())  {  ParentFieldMapper  parentFieldMapper  =  indexService.mapperService().documentMapper(type).parentFieldMapper();                      if  (parentFieldMapper  !=  null)  {                      if  (parentFieldMapper.active())  {  parentTypes.add(new  HashedBytesArray(Strings.toUTF8Bytes(parentFieldMapper.type(),  spare)));  }  }  for  (AtomicReaderContext  context  :  atomicReaderContexts)  {  AtomicReader  reader  =  context.reader();  if  (idReaders.containsKey(reader.getCoreCacheKey()))  {  	if  (parentFieldMapper.active())  {  
libgdx_07b497ea207e17445692c3c53c2bceae32f6ea20	buggy:  int  type  =  Shape.jniGetType(  addr  );  context:  private  native  int  jniGetType(  long  addr  );  public  Shape  getShape(  )  {  if(  shape  ==  null  )  {  long  shapeAddr  =  jniGetShape(  addr  );  int  type  =  Shape.jniGetType(  addr  );  int  type  =  Shape.jniGetType(  shapeAddr  );  if(  type  ==  0  )  shape  =  new  CircleShape(  shapeAddr  );  else  shape  =  new  PolygonShape(  shapeAddr  );  }  return  shape;  	int  type  =  Shape.jniGetType(  shapeAddr  );  
elasticsearch_45a1b447599909a294ba63887bd91789c2e9b772	buggy:  listener.onResponse(new  SearchResponse(InternalSearchResponse.EMPTY,  null,  0,  0,  System.currentTimeMillis()  -  startTime,  ShardSearchFailure.EMPTY_ARRAY));  context:  useSlowScroll  =  true;  }  }  }  this.useSlowScroll  =  useSlowScroll;  }  public  void  start()  {  if  (expectedSuccessfulOps  ==  0)  {                  listener.onResponse(new  SearchResponse(InternalSearchResponse.EMPTY,  null,  0,  0,  System.currentTimeMillis()  -  startTime,  ShardSearchFailure.EMPTY_ARRAY));                  listener.onResponse(new  SearchResponse(InternalSearchResponse.empty(),  null,  0,  0,  System.currentTimeMillis()  -  startTime,  ShardSearchFailure.EMPTY_ARRAY));  return;  }  request.beforeStart();  int  localOperations  =  0;  int  shardIndex  =  -1;  for  (final  ShardIterator  shardIt  :  shardsIts)  {  shardIndex++;  	listener.onResponse(new  SearchResponse(InternalSearchResponse.empty(),  null,  0,  0,  System.currentTimeMillis()  -  startTime,  ShardSearchFailure.EMPTY_ARRAY));  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Double.NaN;  context:  this.nullValueAsString  =  nullValue  ==  null  ?  null  :  nullValue.toString();  }  return  64;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Double.NaN;              return  null;  }  return  Numbers.bytesToDouble(value);  }  return  indexedValue(Double.parseDouble(value));  }  	return  null;  
elasticsearch_510397aecdb95047995930f48dc439614aeafce0	buggy:  toRoutingNode.nodeId(),  shardRouting.currentNodeId(),  context:  RoutingNode  toRoutingNode  =  allocation.routingNodes().node(toDiscoNode.id());  Decision  decision  =  allocation.deciders().canAllocate(shardRouting,  toRoutingNode,  allocation);  if  (decision.type()  ==  Decision.Type.NO)  {  throw  new  ElasticSearchIllegalArgumentException( "[move_allocation]  can't  move   "  +  shardId  +   ",  from   "  +  fromDiscoNode  +   ",  to   "  +  toDiscoNode  +   ",  since  its  not  allowed,  reason:   "  +  decision);  }  if  (decision.type()  ==  Decision.Type.THROTTLE)  {  }  toRoutingNode.add(new  MutableShardRouting(shardRouting.index(),  shardRouting.id(),                      toRoutingNode.nodeId(),  shardRouting.currentNodeId(),                      toRoutingNode.nodeId(),  shardRouting.currentNodeId(),  shardRouting.restoreSource(),  shardRouting.primary(),  ShardRoutingState.INITIALIZING,  shardRouting.version()  +  1));  shardRouting.relocate(toRoutingNode.nodeId());  }  if  (!found)  {  throw  new  ElasticSearchIllegalArgumentException( "[move_allocation]  can't  move   "  +  shardId  +   ",  failed  to  find  it  on  node   "  +  fromDiscoNode);  }  	toRoutingNode.nodeId(),  shardRouting.currentNodeId(),  shardRouting.restoreSource(),  
libgdx_a80a00bddd5ff73ddfc8c64e70ba3e12218da5dd	buggy:  NinePatch  patch  =  skin.getResource( "default-round ",  NinePatch.class);  context:  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false);  Gdx.input.setInputProcessor(stage);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  TextureRegion  region  =  new  TextureRegion(new  Texture(Gdx.files.internal( "data/badlogic.jpg ")));  NinePatch  patch  =  skin.getResource( "default-round ",  NinePatch.class);  NinePatch  patch  =  skin.getPatch( "default-round ");  Label  label  =  new  Label( "This  is  some  text. ",  skin);  root  =  new  Table();  stage.addActor(root);  Table  table  =  new  Table();  	NinePatch  patch  =  skin.getPatch( "default-round ");  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  Engine.Searcher  searcher  =  indexShard.searcher();  context:  shardStatus.state  =  indexShard.state();  try  {  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  shardStatus.translogId  =  indexShard.translog().currentId();  shardStatus.translogOperations  =  indexShard.translog().estimatedNumberOfOperations();              Engine.Searcher  searcher  =  indexShard.searcher();              Engine.Searcher  searcher  =  indexShard.acquireSearcher();  try  {  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {  searcher.release();  }  	Engine.Searcher  searcher  =  indexShard.acquireSearcher();  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  mltResponse  =  cluster().clientNodeClient().moreLikeThis(moreLikeThisRequest( "beta ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  context:  mltResponse  =  client().moreLikeThis(moreLikeThisRequest( "beta ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  assertHitCount(mltResponse,  1l);  assertThat(mltResponse.getHits().getAt(0).id(),  equalTo( "3 "));  mltResponse  =  client().moreLikeThis(moreLikeThisRequest( "test ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1).searchIndices( "release ")).actionGet();  assertHitCount(mltResponse,  1l);  assertThat(mltResponse.getHits().getAt(0).id(),  equalTo( "2 "));          mltResponse  =  cluster().clientNodeClient().moreLikeThis(moreLikeThisRequest( "beta ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();          mltResponse  =  internalCluster().clientNodeClient().moreLikeThis(moreLikeThisRequest( "beta ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  assertHitCount(mltResponse,  1l);  assertThat(mltResponse.getHits().getAt(0).id(),  equalTo( "3 "));  }  public  void  testMoreLikeThisIssue2197()  throws  Exception  {  Client  client  =  client();  	mltResponse  =  internalCluster().clientNodeClient().moreLikeThis(moreLikeThisRequest( "beta ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  
elasticsearch_008b00f51a073765c46441e2ad299bf0a6f95646	buggy:  out.write(facets.size());  context:  if  (id  ==  Facet.Type.COUNT.id())  {  facets.add(readCountFacet(in));  }  else  {  throw  new  IOException( "Can't  handle  facet  type  with  id  [ "  +  id  +   "] ");  }  }  }  }          out.write(facets.size());          out.writeInt(facets.size());  for  (Facet  facet  :  facets)  {  out.write(facet.type().id());  facet.writeTo(out);  }  }  }  	out.writeInt(facets.size());  
elasticsearch_f869951364ef1c5f437b65e4bb8004283cb69ecb	buggy:  DocumentMapper  documentMapper  =  context.mapperService().type(uid.type());  context:  public  void  execute(SearchContext  context)  {  FieldSelector  fieldSelector  =  buildFieldSelectors(context);  InternalSearchHit[]  hits  =  new  InternalSearchHit[context.docIdsToLoadSize()];  for  (int  index  =  0;  index  <  context.docIdsToLoadSize();  index++)  {  int  docId  =  context.docIdsToLoad()[context.docIdsToLoadFrom()  +  index];  Document  doc  =  loadDocument(context,  fieldSelector,  docId);  Uid  uid  =  extractUid(context,  doc);              DocumentMapper  documentMapper  =  context.mapperService().type(uid.type());              DocumentMapper  documentMapper  =  context.mapperService().documentMapper(uid.type());  byte[]  source  =  extractSource(doc,  documentMapper);  InternalSearchHit  searchHit  =  new  InternalSearchHit(docId,  uid.id(),  uid.type(),  source,  null);  hits[index]  =  searchHit;  for  (Object  oField  :  doc.getFields())  {  Fieldable  field  =  (Fieldable)  oField;  	DocumentMapper  documentMapper  =  context.mapperService().documentMapper(uid.type());  
libgdx_eb04c74353ebdde873abe92417a43bbac6911ce0	buggy:  if  (idx[j]  >=  0)  {  //  ignore  if  this  texture  has  no  glyphs  context:  color.r  =  (intBits  &  0xff)  /  255f;  color.g  =  ((intBits  >>>  8)  &  0xff)  /  255f;  color.b  =  ((intBits  >>>  16)  &  0xff)  /  255f;  color.a  =  ((intBits  >>>  24)  &  0xff)  /  255f;  return  color;  }  public  void  draw  (Batch  spriteBatch)  {  TextureRegion[]  regions  =  font.getRegions();  for  (int  j  =  0,  n  =  vertexData.length;  j  <  n;  j++)  {  if  (idx[j]  >=  0)  {  //  ignore  if  this  texture  has  no  glyphs  if  (idx[j]  >  0)  {  //  ignore  if  this  texture  has  no  glyphs  float[]  vertices  =  vertexData[j];  spriteBatch.draw(regions[j].getTexture(),  vertices,  0,  idx[j]);  }  }  }  public  void  draw  (Batch  spriteBatch,  int  start,  int  end)  {  if  (vertexData.length  ==  1)  {  //  i.e.  1  page  	if  (idx[j]  >  0)  {  //  ignore  if  this  texture  has  no  glyphs  
libgdx_29121807a61d9b37f41cbbcccf08e4f39b7bcd71	buggy:  if(  format  ==  Pixmap.Format.RGBA4444  ||  format  ==  Pixmap.Format.RGBA8888  )  context:  composite  =  AlphaComposite.Src;  }  JoglPixmap(BufferedImage  image)  {  pixmap  =  image;  }  private  int  getInternalFormat(  Pixmap.Format  format  )  {  if(  format  ==  Pixmap.Format.RGBA4444  ||  format  ==  Pixmap.Format.RGBA8888  )  if(  format  ==  Pixmap.Format.RGBA4444  ||  format  ==  Pixmap.Format.RGBA8888  ||  format  ==  Pixmap.Format.RGB565  )  return  BufferedImage.TYPE_4BYTE_ABGR;  else  return  BufferedImage.TYPE_BYTE_GRAY;  }  	if(  format  ==  Pixmap.Format.RGBA4444  ||  format  ==  Pixmap.Format.RGBA8888  ||  format  ==  Pixmap.Format.RGB565  )  
libgdx_79c851e2d9846dfe31731630ae328acbd972ea2f	buggy:  onModelClicked( "g3d/test/test4.g3dj ");  context:  );  shaderProvider  =  new  TestShaderProvider();  shaderBatch  =  new  ModelBatch(shaderProvider);  cam.position.set(1,1,1);  cam.lookAt(0,0,0);  cam.update();  showAxes  =  true;  onModelClicked( "g3d/test/test4.g3dj ");  onModelClicked( "g3d/shapes/teapot.g3dj ");  shaderRoot  =  (hotLoadFolder  !=  null  &&  Gdx.app.getType()  ==  ApplicationType.Desktop)  ?  Gdx.files.absolute(hotLoadFolder)  :  Gdx.files.internal( "data/g3d/shaders ");  }  public  void  dispose  ()  {  shaderBatch.dispose();  	onModelClicked( "g3d/shapes/teapot.g3dj ");  
elasticsearch_b078c9206a71d639ee76fa5b6a8b44344e797d98	buggy:  shardGatewayService.snapshot();  context:  return  new  ShardGatewaySnapshotResponse();  }  return   "indices/index/shard/gateway/snapshot ";  }  IndexShardGatewayService  shardGatewayService  =  indicesService.indexServiceSafe(shardRequest.request.index())  .shardInjectorSafe(shardRequest.shardId).getInstance(IndexShardGatewayService.class);          shardGatewayService.snapshot();          shardGatewayService.snapshot( "api ");  return  new  ShardGatewaySnapshotResponse();  }  }  	shardGatewayService.snapshot( "api ");  
libgdx_b5bb397ae1354a586cdae63f6dd0b2ce4666ce9f	buggy:  currLayer.tiles[row][col]  =  Integer.parseInt(st.nextToken().trim());  context:  if  ( "object ".equals(property.parentType))  {  currObject.properties.put(property.name,  property.value);  return;  }  }  private  void  fromCSV  ()  {  StringTokenizer  st  =  new  StringTokenizer(dataString.trim(),   ", ");  for  (int  row  =  0;  row  <  currLayerHeight;  row++)  {  for  (int  col  =  0;  col  <  currLayerWidth;  col++)  {  currLayer.tiles[row][col]  =  Integer.parseInt(st.nextToken().trim());  currLayer.tiles[row][col]  =  (int)  Long.parseLong(st.nextToken().trim());  }  }  }  private  void  arrangeData  ()  {  int  byteCounter  =  0;  for  (int  row  =  0;  row  <  currLayerHeight;  row++)  {  for  (int  col  =  0;  col  <  currLayerWidth;  col++)  {  	currLayer.tiles[row][col]  =  (int)  Long.parseLong(st.nextToken().trim());  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  public  class  TransportFlushAction  extends  TransportBroadcastOperationAction<FlushRequest,  FlushResponse,  ShardFlushRequest,  ShardFlushResponse>  {  private  final  IndicesService  indicesService;  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.FLUSH;  }  return   "indices/flush/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_48ca7b874d8e1838764823e2f6a9fa837f1ceab4	buggy:  nodeIndexDeletedAction.nodeIndexStoreDeleted(indexDeleted,  event.state().nodes().masterNodeId());  context:  FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(current.index())));  indicesDeleted.add(current.index());  }  }  }  }  currentMetaData  =  event.state().metaData();  for  (String  indexDeleted  :  indicesDeleted)  {  try  {                          nodeIndexDeletedAction.nodeIndexStoreDeleted(indexDeleted,  event.state().nodes().masterNodeId());                          nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  indexDeleted,  event.state().nodes().localNodeId());  }  catch  (Exception  e)  {  }  }  }  });  }  	nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  indexDeleted,  event.state().nodes().localNodeId());  
elasticsearch_5ae12368574b33a8fad215ef104108fbf5435eb3	buggy:  return  maxes.get(owningBucketOrd);  context:  final  int  valueCount  =  values.setDocument(doc);  double  max  =  maxes.get(owningBucketOrdinal);  for  (int  i  =  0;  i  <  valueCount;  i++)  {  max  =  Math.max(max,  values.nextValue());  }  maxes.set(owningBucketOrdinal,  max);  }  public  double  metric(long  owningBucketOrd)  {          return  maxes.get(owningBucketOrd);          return  valuesSource  ==  null  ?  Double.NEGATIVE_INFINITY  :  maxes.get(owningBucketOrd);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  if  (valuesSource  ==  null)  {  return  new  InternalMax(name,  Double.NEGATIVE_INFINITY);  }  assert  owningBucketOrdinal  <  maxes.size();  	return  valuesSource  ==  null  ?  Double.NEGATIVE_INFINITY  :  maxes.get(owningBucketOrd);  
elasticsearch_013b3194158e18441f2b3ea27f7d459aa6cc4f60	buggy:  return  true;  context:  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  aggregationContext.setNextReader(context);  }  public  boolean  acceptsDocsOutOfOrder()  {              return  true;              return  !aggregationContext.scoreDocsInOrder();  }  public  void  postCollection()  throws  IOException  {  for  (Aggregator  collector  :  collectors)  {  collector.postCollection();  }  }  	return  !aggregationContext.scoreDocsInOrder();  
elasticsearch_8b295b53d0ec023e3a71448bf33050f60c00f123	buggy:  indexShard.refresh(new  Engine.Refresh(false));  context:  }  protected  MultiGetShardResponse  shardOperation(MultiGetShardRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {              indexShard.refresh(new  Engine.Refresh(false));              indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE));  }  MultiGetShardResponse  response  =  new  MultiGetShardResponse();  for  (int  i  =  0;  i  <  request.locations.size();  i++)  {  String  type  =  request.types.get(i);  String  id  =  request.ids.get(i);  String[]  fields  =  request.fields.get(i);  	indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE));  
libgdx_5bfeb071d07d2ae298e5c519991fc488d356f34c	buggy:  if  (telegram.getTimestamp()  <  currentTime)  break;  context:  long  currentTime  =  getCurrentTime();  do  {  final  Telegram  telegram  =  queue.peek();  if  (telegram.getTimestamp()  <  currentTime)  break;  if  (telegram.getTimestamp()  >  currentTime)  break;  if  (debugEnabled)  {  Gdx.app.log(LOG_TAG,   "Queued  telegram  ready  for  dispatch:  Sent  to   "  +  telegram.receiver  +   ".  Msg  is   "  telegram.message);  }  discharge(telegram);  	if  (telegram.getTimestamp()  >  currentTime)  break;  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  assertThat(doc.rootDoc().getField( "_timestamp ").tokenStream(docMapper.indexAnalyzer()),  notNullValue());  context:  DocumentMapper  docMapper  =  MapperTestUtils.newParser().parse(mapping);  BytesReference  source  =  XContentFactory.jsonBuilder()  .startObject()  .field( "field ",   "value ")  .endObject()  .bytes();  ParsedDocument  doc  =  docMapper.parse(SourceToParse.source(source).type( "type ").id( "1 ").timestamp(1));  assertThat(doc.rootDoc().getField( "_timestamp ").fieldType().stored(),  equalTo(true));  assertThat(doc.rootDoc().getField( "_timestamp ").fieldType().indexed(),  equalTo(true));          assertThat(doc.rootDoc().getField( "_timestamp ").tokenStream(docMapper.indexAnalyzer()),  notNullValue());          assertThat(doc.rootDoc().getField( "_timestamp ").tokenStream(docMapper.indexAnalyzer(),  null),  notNullValue());  }  public  void  testDefaultValues()  throws  Exception  {  String  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type ").endObject().string();  DocumentMapper  docMapper  =  MapperTestUtils.newParser().parse(mapping);  assertThat(docMapper.timestampFieldMapper().enabled(),  equalTo(TimestampFieldMapper.Defaults.ENABLED.enabled));  assertThat(docMapper.timestampFieldMapper().fieldType().stored(),  equalTo(TimestampFieldMapper.Defaults.FIELD_TYPE.stored()));  	assertThat(doc.rootDoc().getField( "_timestamp ").tokenStream(docMapper.indexAnalyzer(),  null),  notNullValue());  
elasticsearch_fd5719b2324367e73df6e09fa8a592381a3f8b44	buggy:  filterTerms[i]  =  fieldMapper.names().createIndexNameTerm(fieldMapper.indexedValue(terms.get(i)));  context:  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  }  }  try  {  Filter  filter;  if  ( "plain ".equals(execution))  {  Term[]  filterTerms  =  new  Term[terms.size()];  if  (fieldMapper  !=  null)  {  for  (int  i  =  0;  i  <  filterTerms.length;  i++)  {                          filterTerms[i]  =  fieldMapper.names().createIndexNameTerm(fieldMapper.indexedValue(terms.get(i)));                          filterTerms[i]  =  fieldMapper.names().createIndexNameTerm(fieldMapper.indexedValueForSearch(terms.get(i)));  }  }  else  {  for  (int  i  =  0;  i  <  filterTerms.length;  i++)  {  filterTerms[i]  =  new  Term(fieldName,  terms.get(i));  }  }  filter  =  new  XTermsFilter(filterTerms);  	filterTerms[i]  =  fieldMapper.names().createIndexNameTerm(fieldMapper.indexedValueForSearch(terms.get(i)));  
elasticsearch_edf0075025b35336af2ff122c2df212e946fb5fc	buggy:  sb.append( "    index    :  number_of_files  [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().totalSize()).append( "],  throttling_wait  [ ").append(recoveryStatus.index().throttlingWaitTime()).append( "]\n ");  context:  lastTranslogSize  =  recoveryStatus.translog().numberOfOperations();  if  (indexShard.state()  !=  IndexShardState.STARTED)  {  indexShard.start();  }  stopWatch.stop();  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(stopWatch.totalTime()).append( "],  throttling_wait  [ ").append(throttlingWaitTime.totalTime()).append( "]\n ");                      sb.append( "    index    :  number_of_files  [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().totalSize()).append( "],  throttling_wait  [ ").append(recoveryStatus.index().throttlingWaitTime()).append( "]\n ");                      sb.append( "    index    :  recovered_files  [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().totalSize()).append( "],  throttling_wait  [ ").append(recoveryStatus.index().throttlingWaitTime()).append( "]\n ");  sb.append( "              :  reusing_files  [ ").append(recoveryStatus.index().numberOfExistingFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().existingTotalSize()).append( "]\n ");  sb.append( "    translog  :  translog_id  [ ").append(recoveryStatus.translog().translogId()).append( "],  number_of_operations  [ ").append(recoveryStatus.translog().numberOfOperations()).append( "]  with  total_size[ ").append(recoveryStatus.translog().totalSize()).append( "] ");  }  indexShard.refresh(new  Engine.Refresh(false));  scheduleSnapshotIfNeeded();  }  finally  {  	sb.append( "        index        :  recovered_files  [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().totalSize()).append( "],  throttling_wait  [ ").append(recoveryStatus.index().throttlingWaitTime()).append( "]\n ");  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  font  =  new  BitmapFont();  context:  BitmapFont  font;  public  void  create  ()  {  renderer  =  new  ShapeRenderer();  cam  =  new  PerspectiveCamera(47,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(0,  0,  2);  cam.near  =  0.1f;  controller  =  new  PerspectiveCamController(cam);  Gdx.input.setInputProcessor(controller);  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  Gdx.gl.glEnable(GL10.GL_DEPTH_TEST);  cam.update();  renderer.setProjectionMatrix(cam.combined);  renderer.identity();  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  ShortArrayAtomicFieldData.Single(new  short[0],  0);  context:  }  }  }  public  ShortArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  ShortArrayAtomicFieldData.Single(new  short[0],  0);              return  new  ShortArrayAtomicFieldData.SingleFixedSet(new  short[1],  0,  new  FixedBitSet(1));  }  final  TShortArrayList  values  =  new  TShortArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  ShortArrayAtomicFieldData.SingleFixedSet(new  short[1],  0,  new  FixedBitSet(1));  
elasticsearch_2cb40fcb1741ce1bf4c770aeec8b85717f2b5d98	buggy:  DeleteResponse  deleteResponse  =  new  DeleteResponse(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  delete.version(),  delete.notFound());  context:  IndexResponse  indexResponse  =  new  IndexResponse(indexRequest.index(),  indexRequest.type(),  indexRequest.id(),  version,  created);  return  new  WriteResult(indexResponse,  preVersion,  mappingsToUpdate,  op);  }  private  WriteResult  shardDeleteOperation(DeleteRequest  deleteRequest,  IndexShard  indexShard)  {  Engine.Delete  delete  =  indexShard.prepareDelete(deleteRequest.type(),  deleteRequest.id(),  deleteRequest.version()).versionType(deleteRequest.versionType()).origin(Engine.Operation.Origin.PRIMARY);  indexShard.delete(delete);  deleteRequest.version(delete.version());          DeleteResponse  deleteResponse  =  new  DeleteResponse(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  delete.version(),  delete.notFound());          DeleteResponse  deleteResponse  =  new  DeleteResponse(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  delete.version(),  delete.found());  return  new  WriteResult(deleteResponse,  deleteRequest.version(),  null,  null);  }  static  class  UpdateResult  {  final  UpdateHelper.Result  result;  final  ActionRequest  actionRequest;  final  boolean  retry;  	DeleteResponse  deleteResponse  =  new  DeleteResponse(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  delete.version(),  delete.found());  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  return  new  Vector3(origin).add(direction.tmp().mul(distance));  context:  public  Ray  cpy  ()  {  return  new  Ray(this.origin,  this.direction);  }  public  Vector3  getEndPoint  (float  distance)  {  return  new  Vector3(origin).add(direction.tmp().mul(distance));  return  new  Vector3(origin).add(direction.tmp().scl(distance));  }  static  Vector3  tmp  =  new  Vector3();  	return  new  Vector3(origin).add(direction.tmp().scl(distance));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  scrollId  =  request.contentAsString();  context:  controller.registerHandler(GET,   "/_search/scroll ",  this);  controller.registerHandler(POST,   "/_search/scroll ",  this);  controller.registerHandler(GET,   "/_search/scroll/{scroll_id} ",  this);  controller.registerHandler(POST,   "/_search/scroll/{scroll_id} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  String  scrollId  =  request.param( "scroll_id ");  if  (scrollId  ==  null  &&  request.hasContent())  {              scrollId  =  request.contentAsString();              scrollId  =  request.content().toUtf8();  }  SearchScrollRequest  searchScrollRequest  =  new  SearchScrollRequest(scrollId);  searchScrollRequest.listenerThreaded(false);  try  {  String  scroll  =  request.param( "scroll ");  if  (scroll  !=  null)  {  searchScrollRequest.scroll(new  Scroll(parseTimeValue(scroll,  null)));  }  	scrollId  =  request.content().toUtf8();  
elasticsearch_2eeb609353070fd518b5a9a0774c63c8892bc110	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  public  void  run()  {  if  (!engine().refreshNeeded())  {  synchronized  (mutex)  {  if  (state  !=  IndexShardState.CLOSED)  {  refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  this);  }  }  return;  }              threadPool.cached().execute(new  Runnable()  {              threadPool.executor(ThreadPool.Names.REFRESH).execute(new  Runnable()  {  public  void  run()  {  try  {  if  (engine.refreshNeeded())  {  refresh(new  Engine.Refresh(false));  }  }  catch  (EngineClosedException  e)  {  	threadPool.executor(ThreadPool.Names.REFRESH).execute(new  Runnable()  {  
libgdx_23c37c1feaa1bc09d5adc19aedc4ea7af148f9a7	buggy:  Array<Actor>  actors  =  root.getActors();  context:  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  if  (useStage)  {  stage.act(Gdx.graphics.getDeltaTime());  stage.getSpriteBatch().disableBlending();  Group  root  =  stage.getRoot();  Array<Actor>  actors  =  root.getActors();  Array<Actor>  actors  =  root.getChildren();  stage.draw();  }  else  {  batch.getProjectionMatrix().setToOrtho2D(0,  0,  24,  12);  batch.getTransformMatrix().idt();  batch.disableBlending();  	Array<Actor>  actors  =  root.getChildren();  
libgdx_b432442fda59f17f4c481c8cab34cf0b49e3aa6e	buggy:  modelBatch.render(instance,  lights);  context:  shapeRenderer.setColor(Color.GREEN);  shapeRenderer.line(0,  0,  0,  0,  100,  0);  shapeRenderer.setColor(Color.BLUE);  shapeRenderer.line(0,  0,  0,  0,  0,  100);  shapeRenderer.end();  instance.transform.idt();  instance.transform.translate(0,  0,  3);  modelBatch.begin(cam);  modelBatch.render(instance,  lights);  modelBatch.render(lights,  instance);  modelBatch.end();  }  public  void  dispose  ()  {  model.dispose();  modelBatch.dispose();  }  	modelBatch.render(lights,  instance);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());  context:  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  from,  to,  includeLower,  includeUpper);  }          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_af39f07213ccce2419688191b47fbac5fbd4de40	buggy:  SearchResponse  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.termQuery( "_id ",  Integer.toString(i))).execute().actionGet();  context:  client.admin().indices().prepareRefresh().execute().actionGet();  for  (int  i  =  1;  i  <  100;  i++)  {  GetResponse  getResponse  =  client.prepareGet( "test ",   "type1 ",  Integer.toString(i)).execute().actionGet();  assertThat(getResponse.source(),  equalTo(buildSource(i).copiedBytes()));  }  GetResponse  getResponse  =  client.prepareGet( "test ",   "type1 ",  Integer.toString(10000)).execute().actionGet();  assertThat(getResponse.source(),  equalTo(buildSource(10000).copiedBytes()));  for  (int  i  =  1;  i  <  100;  i++)  {              SearchResponse  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.termQuery( "_id ",  Integer.toString(i))).execute().actionGet();              SearchResponse  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.idsQuery( "type1 ").ids(Integer.toString(i))).execute().actionGet();  assertThat(searchResponse.hits().getTotalHits(),  equalTo(1l));  assertThat(searchResponse.hits().getAt(0).source(),  equalTo(buildSource(i).copiedBytes()));  }  }  private  XContentBuilder  buildSource(int  count)  throws  IOException  {  XContentBuilder  builder  =  XContentFactory.jsonBuilder().startObject();  StringBuilder  sb  =  new  StringBuilder();  	SearchResponse  searchResponse  =  client.prepareSearch().setQuery(QueryBuilders.idsQuery( "type1 ").ids(Integer.toString(i))).execute().actionGet();  
elasticsearch_507b6a6e8c259535f82912211058467df3c68a8f	buggy:  client().admin().indices().prepareRefresh(index).execute().get();  context:  if  (rarely())  {  client().admin().indices().prepareRefresh(index).execute().get();  }  else  if  (rarely())  {  client().admin().indices().prepareFlush(index).execute().get();  }  else  if  (rarely())  {  client().admin().indices().prepareOptimize(index).setMaxNumSegments(between(1,  10)).setFlush(random.nextBoolean()).execute().get();  }  }  }  if  (forceRefresh)  {              client().admin().indices().prepareRefresh(index).execute().get();              assertNoFailures(client().admin().indices().prepareRefresh(index).execute().get());  }  }  public  void  clearScroll(String...  scrollIds)  {  ClearScrollResponse  clearResponse  =  client().prepareClearScroll()  .setScrollIds(Arrays.asList(scrollIds)).get();  assertThat(clearResponse.isSucceeded(),  equalTo(true));  }  	assertNoFailures(client().admin().indices().prepareRefresh(index).execute().get());  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  multiSearchRequest.listenerThreaded(false);  context:  controller.registerHandler(POST,   "/_msearch ",  this);  controller.registerHandler(GET,   "/{index}/_msearch ",  this);  controller.registerHandler(POST,   "/{index}/_msearch ",  this);  controller.registerHandler(GET,   "/{index}/{type}/_msearch ",  this);  controller.registerHandler(POST,   "/{index}/{type}/_msearch ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  MultiSearchRequest  multiSearchRequest  =  new  MultiSearchRequest();          multiSearchRequest.listenerThreaded(false);          multiSearchRequest.setListenerThreaded(false);  String[]  indices  =  RestActions.splitIndices(request.param( "index "));  String[]  types  =  RestActions.splitTypes(request.param( "type "));  IgnoreIndices  ignoreIndices  =  null;  if  (request.hasParam( "ignore_indices "))  {  ignoreIndices  =  IgnoreIndices.fromString(request.param( "ignore_indices "));  }  	multiSearchRequest.setListenerThreaded(false);  
elasticsearch_a4f974dcaacf656b3062c89a9050f9e67873021f	buggy:  IndexService  indexService  =  indicesService.indexService(shardId.getIndex());  context:  protected  void  resolveRequest(ClusterState  state,  InternalRequest  request)  {  request.request().filteringAlias(state.metaData().filteringAliases(request.concreteIndex(),  request.request().index()));  if  (request.request().routing()  ==  null  &&  state.getMetaData().routingRequired(request.concreteIndex(),  request.request().type()))  {  throw  new  RoutingMissingException(request.concreteIndex(),  request.request().type(),  request.request().id());  }  }  protected  ExplainResponse  shardOperation(ExplainRequest  request,  ShardId  shardId)  throws  ElasticsearchException  {          IndexService  indexService  =  indicesService.indexService(shardId.getIndex());          IndexService  indexService  =  indicesService.indexServiceSafe(shardId.getIndex());  IndexShard  indexShard  =  indexService.shardSafe(shardId.id());  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  Engine.GetResult  result  =  indexShard.get(new  Engine.Get(false,  uidTerm));  if  (!result.exists())  {  return  new  ExplainResponse(shardId.getIndex(),  request.type(),  request.id(),  false);  }  SearchContext  context  =  new  DefaultSearchContext(  	IndexService  indexService  =  indicesService.indexServiceSafe(shardId.getIndex());  
libgdx_e94a7c9d4eb78d19371ca735169be78097754e2a	buggy:  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  (viewportWidth  /  2  -  1),  zoom  *  -(viewportHeight  /  2  -  1),  zoom  context:  private  final  Vector3  tmp  =  new  Vector3();  public  void  update  ()  {  update(true);  }  public  void  update  (boolean  updateFrustum)  {  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  (viewportWidth  /  2  -  1),  zoom  *  -(viewportHeight  /  2  -  1),  zoom  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  (viewportWidth  /  2),  zoom  *  -(viewportHeight  /  2),  zoom  view.setToLookAt(position,  tmp.set(position).add(direction),  up);  combined.set(projection);  Matrix4.mul(combined.val,  view.val);  if  (updateFrustum)  {  invProjectionView.set(combined);  Matrix4.inv(invProjectionView.val);  	projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  (viewportWidth  /  2),  zoom  *  -(viewportHeight  /  2),  zoom  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  wipeIndex(getConcreteIndexName());  context:  public  class  DocumentActionsTests  extends  ElasticsearchIntegrationTest  {  protected  void  createIndex()  {          wipeIndex(getConcreteIndexName());          wipeIndices(getConcreteIndexName());  createIndex(getConcreteIndexName());  }  protected  String  getConcreteIndexName()  {  return   "test ";  }  	wipeIndices(getConcreteIndexName());  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execDelete(deleteRequest,  new  ActionListener<DeleteResponse>()  {  context:  controller.registerHandler(DELETE,   "/{index}/{type}/{id} ",  this);  }  DeleteRequest  deleteRequest  =  new  DeleteRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  deleteRequest.timeout(request.paramAsTime( "timeout ",  DeleteRequest.DEFAULT_TIMEOUT));  deleteRequest.listenerThreaded(false);  deleteRequest.operationThreaded(true);          client.execDelete(deleteRequest,  new  ActionListener<DeleteResponse>()  {          client.delete(deleteRequest,  new  ActionListener<DeleteResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "_index ",  result.index())  .field( "_type ",  result.type())  .field( "_id ",  result.id())  	client.delete(deleteRequest,  new  ActionListener<DeleteResponse>()  {  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());  context:  assertThat(searchResponse.facets().facet(QueryFacet.class,   "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().facet(QueryFacet.class,   "all ").count(),  equalTo(100l));  }  testSimpleFacets();  testSimpleFacets();  }  private  InternalSearchRequest  searchRequest(ShardRouting  shardRouting,  SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest(shardRouting).source(builder.buildAsBytes());          return  new  InternalSearchRequest(shardRouting,  3).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  StringBuilder  multi  =  new  StringBuilder().append(nameValue);  	return  new  InternalSearchRequest(shardRouting,  3).source(builder.buildAsBytes());  
libgdx_19442076c07c645dc5b8ec93895fa1a15d84d111	buggy:  Array<K>  keys  =  orderedKeys();  context:  public  void  remove  ()  {  map.remove(keys.get(nextIndex  -  1));  }  };  }  public  String  toString  ()  {  if  (size  ==  0)  return   "{} ";  StringBuilder  buffer  =  new  StringBuilder(32);  buffer.append('{');  Array<K>  keys  =  orderedKeys();  Array<K>  keys  =  this.keys;  for  (int  i  =  0,  n  =  keys.size;  i  <  n;  i++)  {  K  key  =  keys.get(i);  if  (i  >  0)  buffer.append( ",   ");  buffer.append(key);  buffer.append('=');  buffer.append(get(key));  }  buffer.append('}');  	Array<K>  keys  =  this.keys;  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  jsonBuilder().prettyPrint()  context:  public  JsonThrowableRestResponse(RestRequest  request,  Throwable  t)  throws  IOException  {  this(request,  Status.INTERNAL_SERVER_ERROR,  t);  }  public  JsonThrowableRestResponse(RestRequest  request,  Status  status,  Throwable  t)  throws  IOException  {  super(request,  status,  convert(request,  t));  }  private  static  JsonBuilder  convert(RestRequest  request,  Throwable  t)  throws  IOException  {          JsonBuilder  builder  =  jsonBuilder().prettyPrint()          JsonBuilder  builder  =  binaryJsonBuilder().prettyPrint()  .startObject().field( "error ",  detailedMessage(t));  if  (t  !=  null  &&  request.paramAsBoolean( "errorTrace ",  false))  {  builder.startObject( "errorTrace ");  boolean  first  =  true;  while  (t  !=  null)  {  if  (!first)  {  builder.startObject( "cause ");  }  	JsonBuilder  builder  =  binaryJsonBuilder().prettyPrint()  
elasticsearch_82d3693a916b6ae0d445d7f12328a7036dd87043	buggy:  }  catch  (Exception  e)  {  context:  final  ExecutorService  indicesStopExecutor  =  Executors.newFixedThreadPool(5,  EsExecutors.daemonThreadFactory( "indices_shutdown "));  final  ExecutorService  shardsStopExecutor  =  Executors.newFixedThreadPool(5,  EsExecutors.daemonThreadFactory( "shards_shutdown "));  for  (final  String  index  :  indices)  {  indicesStopExecutor.execute(new  Runnable()  {  public  void  run()  {  try  {  removeIndex(index,   "shutdown ",  shardsStopExecutor);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  }  finally  {  latch.countDown();  }  }  });  }  try  {  	}  catch  (Throwable  e)  {  
elasticsearch_932215d6fac6519706d9542721d9f18913f9a80d	buggy:  .put( "index.shard.check_index ",  false)  context:  private  static  final  ESLogger  logger  =  Loggers.getLogger(ManyIndicesStressTest.class);  public  static  void  main(String[]  args)  throws  Exception  {  System.setProperty( "es.logger.prefix ",   " ");  int  numberOfIndices  =  100;  int  numberOfDocs  =  100;  Settings  settings  =  ImmutableSettings.settingsBuilder()                  .put( "index.shard.check_index ",  false)                  .put( "index.shard.check_on_startup ",  false)  .put( "gateway.type ",   "fs ")  .put( "index.number_of_shards ",  1)  .build();  Node  node  =  NodeBuilder.nodeBuilder().settings(settings).node();  for  (int  i  =  0;  i  <  numberOfIndices;  i++)  {  node.client().admin().indices().prepareCreate( "index_ "  +  i).execute().actionGet();  	.put( "index.shard.check_on_startup ",  false)  
elasticsearch_80fa91d873a838e12379037e27ce5656a7e8db95	buggy:  AsyncAction.this.addShardFailure(shardIndex,  t);  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  public  void  onFailure(Throwable  t)  {  if  (logger.isDebugEnabled())  {  }                      AsyncAction.this.addShardFailure(shardIndex,  t);                      AsyncAction.this.addShardFailure(shardIndex,  dfsResult.shardTarget(),  t);  successulOps.decrementAndGet();  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  	AsyncAction.this.addShardFailure(shardIndex,  dfsResult.shardTarget(),  t);  
elasticsearch_223ec2c42d446290af9fb64da87ebf06e553356c	buggy:  throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  field  data  builder  for  field   "  +  fieldNames.fullName()  +   ",  and  type   "  +  type);  context:  if  (format  !=  null)  {  builder  =  buildersByTypeAndFormat.get(Tuple.tuple(type.getType(),  format));  if  (builder  ==  null)  {  }  }  if  (builder  ==  null)  {  builder  =  buildersByType.get(type.getType());  }  if  (builder  ==  null)  {                          throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  field  data  builder  for  field   "  +  fieldNames.fullName()  +   ",  and  type   "  +  type);                          throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  field  data  builder  for  field   "  +  fieldNames.fullName()  +   ",  and  type   "  +  type.getType());  }  IndexFieldDataCache  cache;  String  cacheType  =  type.getSettings().get( "cache ",  indexSettings.get( "index.fielddata.cache ",   "node "));  if  ( "resident ".equals(cacheType))  {  cache  =  new  IndexFieldDataCache.Resident(index,  fieldNames,  type,  this);  	throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  field  data  builder  for  field   "  +  fieldNames.fullName()  +   ",  and  type   "  +  type.getType());  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_50cdf2920fd9dabebd3084874a040f2d12fc7a27	buggy:  void  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException;  context:  String  sValue  =  param(key);  if  (sValue  ==  null)  {  return  defaultValue;  }  return  !(sValue.equals( "false ")  ||  sValue.equals( "0 ")  ||  sValue.equals( "off "));  }  }      void  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException;      XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException;  }  	XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException;  
elasticsearch_b4e5a542f3b3858a7c7218dcf9629060b512c612	buggy:  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.Request(request.source()));  context:  request.index(clusterState.metaData().concreteIndex(request.index()));  return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.Request(request.source()));          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.source()));  return  new  PercolateResponse(percolate.matches());  }  }  	PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.source()));  
libgdx_6dbba77ebebb4d392e780d4b3efb07436b133895	buggy:  return  FastMath.sqrt(  sum  /  values.length  );  context:  if(  !hasEnoughData()  )  return  0;  float  mean  =  getMean();  float  sum  =  0;  for(  int  i  =  0;  i  <  values.length;  i++  )  {  sum  +=  (values[i]  -  mean)  *  (values[i]  -  mean);  }  return  FastMath.sqrt(  sum  /  values.length  );  return  (float)Math.sqrt(  sum  /  values.length  );  }  }  	return  (float)Math.sqrt(  sum  /  values.length  );  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(100000);  context:  public  class  HyperLogLogPlusPlusTests  extends  ElasticsearchTestCase  {  public  void  encodeDecode()  {          final  int  iters  =  atLeast(100000);          final  int  iters  =  scaledRandomIntBetween(100000,  500000);  for  (int  i  =  0;  i  <  iters;  ++i)  {  final  int  p1  =  randomIntBetween(4,  24);  final  long  hash  =  randomLong();  testEncodeDecode(p1,  hash);  }  for  (int  p1  =  MIN_PRECISION;  p1  <=  MAX_PRECISION;  ++p1)  {  	final  int  iters  =  scaledRandomIntBetween(100000,  500000);  
elasticsearch_499cff3b1ef5dcb3564f09709e70eaa01616cd46	buggy:  return  null;  context:  }  else  if  (snapshot.state()  ==  State.SUCCESS  &&  newMaster)  {  endSnapshot(snapshot);  }  }  if  (changed)  {  snapshots  =  new  SnapshotMetaData(entries.toArray(new  SnapshotMetaData.Entry[entries.size()]));  mdBuilder.putCustom(SnapshotMetaData.TYPE,  snapshots);  return  ClusterState.builder(currentState).metaData(mdBuilder).build();  }                      return  null;                      return  currentState;  }  public  void  onFailure(String  source,  Throwable  t)  {  }  });  }  	return  currentState;  
elasticsearch_4ffbdbeaeaf3c2e574dc50f682ecd8014332cf92	buggy:  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "] ");  context:  }  }  else  if  (DOC_FIELD_NAME.equals(fieldName))  {  if  (reverse)  {  sortFields.add(SORT_DOC_REVERSE);  }  else  {  sortFields.add(SORT_DOC);  }  }  else  {  FieldMapper  fieldMapper  =  context.smartNameFieldMapper(fieldName);  if  (fieldMapper  ==  null)  {                  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "] ");                  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "]  in  order  to  sort  on ");  }  sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  }  }  }  	throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "]  in  order  to  sort  on ");  
libgdx_1176e8a1ba798ec3d6967b911f5d8f1c5f754691	buggy:  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  context:  MD5Animation  anim;  MD5AnimationInfo  animInfo;  MD5Joints  skeleton;  MD5Renderer  renderer;  SpriteBatch  batch;  BitmapFont  font;  public  void  create  ()  {  Gdx.app.log( "MD5  Test ",   "created ");  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  anim  =  MD5Loader.loadAnimation(Gdx.files.internal( "data/walk1.md5anim ").read());  skeleton  =  new  MD5Joints();  skeleton.joints  =  new  float[anim.frames[0].joints.length];  animInfo  =  new  MD5AnimationInfo(anim.frames.length,  anim.secondsPerFrame);  renderer  =  new  MD5Renderer(model,  true,  false);  renderer.setSkeleton(model.baseSkeleton);  	model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.startObject( "nodes ");  for  (NodesRestartResponse.NodeRestartResponse  nodeInfo  :  result)  {  builder.startObject(nodeInfo.getNode().id());  builder.field( "name ",  nodeInfo.getNode().name());  builder.endObject();  }  builder.endObject();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  protected  ShardIterator  shards(ClusterState  state,  TermVectorRequest  request)  {  return  clusterService.operationRouting().getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  }  protected  void  resolveRequest(ClusterState  state,  TermVectorRequest  request)  {  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  }  	request.index(state.metaData().concreteSingleIndex(request.index()));  
elasticsearch_876b5a3dcd295f41d9ddf3f70b336d331ee82f20	buggy:  int  freq  =  0;  context:  public  void  nextToken()  throws  IOException  {  anyTokens  =  true;  BytesRef  term  =  fillBytesRef(termsRef);  if  (requireUnigram  &&  typeAttribute.type()  ==  ShingleFilter.DEFAULT_TOKEN_TYPE)  {  return;  }  anyUnigram  =  true;  if  (posIncAttr.getPositionIncrement()  ==  0  &&  typeAttribute.type()  ==  SynonymFilter.TYPE_SYNONYM)  {  assert  currentSet  !=  null;                      int  freq  =  0;                      long  freq  =  0;  if  ((freq  =  generator.frequency(term))  >  0)  {  currentSet.addOneCandidate(generator.createCandidate(BytesRef.deepCopyOf(term),  freq,  realWordLikelihood));  }  }  else  {  if  (currentSet  !=  null)  {  candidateSetsList.add(currentSet);  }  currentSet  =  new  CandidateSet(Candidate.EMPTY,  generator.createCandidate(BytesRef.deepCopyOf(term)));  	long  freq  =  0;  
libgdx_4bf75fdca08f0f94b2989a6d8e3584d125a8edee	buggy:  return  !(min.x  ==  max.x  &&  min.y  ==  max.y  &&  min.z  ==  max.z);  context:  public  BoundingBox  clr  ()  {  crn_dirty  =  true;  return  this.set(min.set(0,  0,  0),  max.set(0,  0,  0));  }  public  boolean  isValid  ()  {  return  !(min.x  ==  max.x  &&  min.y  ==  max.y  &&  min.z  ==  max.z);  return  (min.x  <  max.x  &&  min.y  <  max.y  &&  min.z  <  max.z);  }  public  BoundingBox  ext  (BoundingBox  a_bounds)  {  crn_dirty  =  true;  	return  (min.x  <  max.x  &&  min.y  <  max.y  &&  min.z  <  max.z);  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  GeoPointDoubleArrayAtomicFieldData.Single(new  double[0],  new  double[0],  0);  context:  }  }  }  public  GeoPointDoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  GeoPointDoubleArrayAtomicFieldData.Single(new  double[0],  new  double[0],  0);              return  new  GeoPointDoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  new  double[1],  0,  new  FixedBitSet(1));  }  final  TDoubleArrayList  lat  =  new  TDoubleArrayList();  final  TDoubleArrayList  lon  =  new  TDoubleArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  GeoPointDoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  new  double[1],  0,  new  FixedBitSet(1));  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  .settings(settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  2).put( "routing.hash.type ",   "simple ")))  context:  public  void  closeNodes()  {  closeAllNodes();  }  public  void  testFailedSearchWithWrongQuery()  throws  Exception  {  startNode( "server1 ");  client( "server1 ").admin().indices().create(createIndexRequest( "test ")                  .settings(settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  2).put( "routing.hash.type ",   "simple ")))                  .settings(settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  2).put( "routing.hash.type ",   "simple ")))  .actionGet();  client( "server1 ").admin().cluster().prepareHealth().setWaitForYellowStatus().execute().actionGet();  for  (int  i  =  0;  i  <  100;  i++)  {  index(client( "server1 "),  Integer.toString(i),   "test ",  i);  }  RefreshResponse  refreshResponse  =  client( "server1 ").admin().indices().refresh(refreshRequest( "test ")).actionGet();  	.settings(settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  2).put( "routing.hash.type ",   "simple ")))  
elasticsearch_9f8644472e2c790d317ebac95779eda1294e3678	buggy:  return  new  TermFacetCollector(facetName,  field,  context.fieldDataCache(),  size);  context:  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  termFieldName  =  parser.currentName();  }  else  if  (token.isValue())  {  if  ( "field ".equals(termFieldName))  {  field  =  parser.text();  }  else  if  ( "size ".equals(termFieldName))  {  size  =  parser.intValue();  }  }  }          return  new  TermFacetCollector(facetName,  field,  context.fieldDataCache(),  size);          return  new  TermFacetCollector(facetName,  field,  size,  context.fieldDataCache(),  context.mapperService());  }  }  	return  new  TermFacetCollector(facetName,  field,  size,  context.fieldDataCache(),  context.mapperService());  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage  =  new  Stage(480,  320,  true);  context:  public  class  ActionTest  extends  GdxTest  implements  Runnable  {  Stage  stage;  Texture  texture;  public  void  create  ()  {  stage  =  new  Stage(480,  320,  true);  stage  =  new  Stage();  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  false);  texture.setFilter(TextureFilter.Linear,  TextureFilter.Linear);  final  Image  img  =  new  Image(new  TextureRegion(texture));  img.setSize(100,  100);  img.setOrigin(50,  50);  img.setPosition(100,  100);  img.addAction(forever(sequence(delay(1.0f),  new  Action()  {  	stage  =  new  Stage();  
elasticsearch_cfafb52bebbd5bb50b4fc74b1aebc121a9e91548	buggy:  countRequest.minScore(HttpActions.paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));  context:  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);  countRequest.querySource(HttpActions.parseQuerySource(request));  countRequest.queryParserName(request.param( "queryParserName "));  countRequest.queryHint(request.param( "queryHint "));              countRequest.minScore(HttpActions.paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));              countRequest.minScore(paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  countRequest.types(splitTypes(typesParam));  }  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  	countRequest.minScore(paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  name  +   "] ");  context:  public  DateHistogramBuilder  extendedBounds(DateTime  min,  DateTime  max)  {  extendedBoundsMin  =  min;  extendedBoundsMax  =  max;  return  this;  }  protected  XContentBuilder  doInternalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (interval  ==  null)  {              throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  getName()  +   "] ");  }  if  (interval  instanceof  Number)  {  interval  =  TimeValue.timeValueMillis(((Number)  interval).longValue()).toString();  }  builder.field( "interval ",  interval);  if  (minDocCount  !=  null)  {  builder.field( "min_doc_count ",  minDocCount);  	throw  new  SearchSourceBuilderException( "[interval]  must  be  defined  for  histogram  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  nestedFilter  =  context.queryParserService().parseInnerFilter(parser);  context:  XContentParser.Token  token;  String  currentName  =  parser.currentName();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentName))  {  params  =  parser.map();  }  else  if  ( "nested_filter ".equals(currentName)  ||   "nestedFilter ".equals(currentName))  {                      nestedFilter  =  context.queryParserService().parseInnerFilter(parser);                      nestedFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  }  }  else  if  (token.isValue())  {  if  ( "reverse ".equals(currentName))  {  reverse  =  parser.booleanValue();  }  else  if  ( "order ".equals(currentName))  {  reverse  =   "desc ".equals(parser.text());  }  else  if  ( "script ".equals(currentName))  {  script  =  parser.text();  	nestedFilter  =  context.queryParserService().parseInnerFilter(parser).filter();  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",   "opType  [ "  +  sOpType  +   "]  not  allowed,  either  [index]  or  [create]  are  allowed ").endObject()));  context:  IndexRequest  indexRequest  =  new  IndexRequest(request.param( "index "),  request.param( "type "),  request.param( "id "),  request.contentAsString());  indexRequest.timeout(TimeValue.parseTimeValue(request.param( "timeout "),  IndexRequest.DEFAULT_TIMEOUT));  String  sOpType  =  request.param( "opType ");  if  (sOpType  !=  null)  {  if  ( "index ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.INDEX);  }  else  if  ( "create ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.CREATE);  }  else  {  try  {                      channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",   "opType  [ "  +  sOpType  +   "]  not  allowed,  either  [index]  or  [create]  are  allowed ").endObject()));                      channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",   "opType  [ "  +  sOpType  +   "]  not  allowed,  either  [index]  or  [create]  are  allowed ").endObject()));  }  catch  (IOException  e1)  {  return;  }  }  }  indexRequest.listenerThreaded(false);  	channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",   "opType  [ "  +  sOpType  +   "]  not  allowed,  either  [index]  or  [create]  are  allowed ").endObject()));  
elasticsearch_8e0d23b1473b8a3355cddcbad467eb663f1bc753	buggy:  c  =  docA.shardTarget().compareTo(docB.shardTarget());  context:  }  if  (fields[i].getReverse())  {  c  =  -c;  }  }  if  (c  ==  0)  {              c  =  docA.shardTarget().compareTo(docB.shardTarget());              c  =  docA.shardRequestId()  -  docB.shardRequestId();  if  (c  ==  0)  {  return  docA.doc  >  docB.doc;  }  }  return  c  >  0;  }  }  	c  =  docA.shardRequestId()  -  docB.shardRequestId();  
libgdx_f5e1dcd34690011271000e0715860eee2da605c9	buggy:  soundId  =  sound.play();  context:  table.add(volumeValue);  table.row();  table.add(new  Label( "Pan ",  skin));  table.add(pan);  table.add(panValue);  ui.addActor(table);  play.setClickListener(new  ClickListener()  {  public  void  click  (Actor  actor)  {  soundId  =  sound.play();  soundId  =  sound.play(volume.getValue());  sound.setPitch(soundId,  pitch.getValue());  sound.setPan(soundId,  pan.getValue(),  volume.getValue());  }  });  stop.setClickListener(new  ClickListener()  {  public  void  click  (Actor  actor)  {  	soundId  =  sound.play(volume.getValue());  
libgdx_34c0e22e113025a50bc708254ef1b5d5875a952b	buggy:  new  GdxRuntimeException( "Couldn't  shutdown  loading  thread ");  context:  public  void  dispose  ()  {  executor.shutdown();  try  {  executor.awaitTermination(Long.MAX_VALUE,  TimeUnit.SECONDS);  }  catch  (InterruptedException  e)  {  new  GdxRuntimeException( "Couldn't  shutdown  loading  thread ");  throw  new  GdxRuntimeException( "Couldn't  shutdown  loading  thread ",  e);  }  }  }  	throw  new  GdxRuntimeException( "Couldn't  shutdown  loading  thread ",  e);  
elasticsearch_e59b41398046371c7c2712d62098f8ed6ef02ef7	buggy:  client1.admin().indices().aliases(indexAliasesRequest().addAlias( "test ",   "alias1 ")).actionGet();  context:  try  {  client1.index(indexRequest( "alias1 ").type( "type1 ").id( "1 ").source(source( "1 ",   "test "))).actionGet();  assert  false  :   "index  [alias1]  should  not  exists ";  }  catch  (IndexMissingException  e)  {  assertThat(e.index().name(),  equalTo( "alias1 "));  }          client1.admin().indices().aliases(indexAliasesRequest().addAlias( "test ",   "alias1 ")).actionGet();          client1.admin().indices().prepareAliases().addAlias( "test ",   "alias1 ").execute().actionGet();  Thread.sleep(300);  IndexResponse  indexResponse  =  client1.index(indexRequest( "alias1 ").type( "type1 ").id( "1 ").source(source( "1 ",   "test "))).actionGet();  assertThat(indexResponse.index(),  equalTo( "test "));  client1.admin().indices().create(createIndexRequest( "test_x ")).actionGet();  	client1.admin().indices().prepareAliases().addAlias( "test ",   "alias1 ").execute().actionGet();  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {                  if  ( "script_values_sorted ".equals(currentFieldName))  {                  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  {  throw  new  SearchParseException(context,   "Unexpected  token   "  +  token  +   "  in  [ "  +  aggregationName  +   "]. ");  }  }  	if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
libgdx_c68404583edc91820114e44d681db7ecaf73d6f8	buggy:  project.files.add(new  ProjectFile( "core/CoreGdxDefinition ",   "core/src/ "  +  packageDir  +   "/ "  +  mainClass  +   ".gwt.xml ",  true));  context:  project.files.add(new  ProjectFile( "gradlew ",  false));  project.files.add(new  ProjectFile( "gradlew.bat ",  false));  project.files.add(new  ProjectFile( "gradle/wrapper/gradle-wrapper.jar ",  false));  project.files.add(new  ProjectFile( "gradle/wrapper/gradle-wrapper.properties ",  false));  project.files.add(new  ProjectFile( "local.properties ",  true));  project.files.add(new  ProjectFile( "core/build.gradle "));  project.files.add(new  ProjectFile( "core/src/MainClass ",   "core/src/ "  +  packageDir  +   "/ "  +  mainClass  +   ".java ",  true));  project.files.add(new  ProjectFile( "core/CoreGdxDefinition ",   "core/src/ "  +  packageDir  +   "/ "  +  mainClass  +   ".gwt.xml ",  true));  project.files.add(new  ProjectFile( "core/CoreGdxDefinition ",   "core/src/ "  +  mainClass  +   ".gwt.xml ",  true));  project.files.add(new  ProjectFile( "desktop/build.gradle "));  project.files.add(new  ProjectFile( "desktop/src/DesktopLauncher ",   "desktop/src/ "  +  packageDir  +   "/desktop/DesktopLauncher.java ",  true));  project.files.add(new  ProjectFile( "android/assets/badlogic.jpg ",  false));  project.files.add(new  ProjectFile( "android/res/values/strings.xml "));  	project.files.add(new  ProjectFile( "core/CoreGdxDefinition ",   "core/src/ "  +  mainClass  +   ".gwt.xml ",  true));  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  private  final  double[]  values;  private  double  bottom;  public  DoubleFieldsFunctionDataComparator(int  numHits,  SearchScript  script)  {  this.script  =  script;  values  =  new  double[numHits];  }  public  FieldComparator<Double>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          script.setNextReader(context.reader());          script.setNextReader(context);  return  this;  }  public  void  setScorer(Scorer  scorer)  {  script.setScorer(scorer);  }  	script.setNextReader(context);  
elasticsearch_8c25be6dee4f4c33ed5d737b1be14b31e3de319f	buggy:  return   "[ "  +  index  +   "][ "  +  shardId  +   "] ";  context:  super.readFrom(in);  shardId  =  in.readVInt();  }  super.writeTo(out);  out.writeVInt(shardId);  }          return   "[ "  +  index  +   "][ "  +  shardId  +   "] ";          return   "replication_ping  {[ "  +  index  +   "][ "  +  shardId  +   "]} ";  }  }  	return   "replication_ping  {[ "  +  index  +   "][ "  +  shardId  +   "]} ";  
elasticsearch_c69b94d76923d025a6554b01b81005d35352ced9	buggy:  .startObject( "_analyzer ").field( "field ",   "field_analyzer ").endObject()  context:  public  class  AnalyzerMapperTests  {  String  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type ")                  .startObject( "_analyzer ").field( "field ",   "field_analyzer ").endObject()                  .startObject( "_analyzer ").field( "path ",   "field_analyzer ").endObject()  .startObject( "properties ")  .startObject( "field_analyzer ").field( "type ",   "string ").endObject()  .startObject( "field1 ").field( "type ",   "string ").endObject()  .startObject( "field2 ").field( "type ",   "string ").field( "analyzer ",   "simple ").endObject()  .endObject()  .endObject().endObject().string();  XContentDocumentMapper  documentMapper  =  MapperTests.newParser().parse(mapping);  	.startObject( "_analyzer ").field( "path ",   "field_analyzer ").endObject()  
elasticsearch_eb63bb259d393354d4875c4e41dfed97edd142d1	buggy:  client().admin().indices().prepareDelete().get();  context:  completionSuggestionBuilder.setFuzzyEditDistance(2);  suggestResponse  =  client().prepareSuggest(INDEX).addSuggestion(completionSuggestionBuilder).execute().actionGet();  assertSuggestions(suggestResponse,  false,   "foo ",   " ");  }  public  void  testThatStatsAreWorking()  throws  Exception  {  String  otherField  =   "testOtherField ";          client().admin().indices().prepareDelete().get();          client().admin().indices().prepareDelete( "_all ").get();  client().admin().indices().prepareCreate(INDEX)  .setSettings(createDefaultSettings())  .get();  PutMappingResponse  putMappingResponse  =  client().admin().indices().preparePutMapping(INDEX).setType(TYPE).setSource(jsonBuilder().startObject()  .startObject(TYPE).startObject( "properties ")  .startObject(FIELD)  .field( "type ",   "completion ").field( "analyzer ",   "simple ")  	client().admin().indices().prepareDelete( "_all ").get();  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;  context:  public  String[]  names()  {  return  new  String[]{ "_geo_distance ",   "_geoDistance "};  }  public  SortField  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  String  fieldName  =  null;  GeoPoint  point  =  new  GeoPoint();          DistanceUnit  unit  =  DistanceUnit.KILOMETERS;          DistanceUnit  unit  =  DistanceUnit.DEFAULT;  GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  boolean  reverse  =  false;  SortMode  sortMode  =  null;  String  nestedPath  =  null;  Filter  nestedFilter  =  null;  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  	DistanceUnit  unit  =  DistanceUnit.DEFAULT;  
libgdx_18519c77e83a523709006eedcb153535fc7d0c36	buggy:  ((IOSInput)  Gdx.input).processEvents();  context:  lastFrameTime  =  time;  frames++;  if  (time  -  framesStart  >=  1000000000l)  {  framesStart  =  time;  fps  =  frames;  frames  =  0;  }  makeCurrent();  ((IOSInput)  Gdx.input).processEvents();  input.processEvents();  app.listener.render();  }  void  makeCurrent()  {  EAGLContext.setCurrentContext(context);  }  	input.processEvents();  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  CreateIndexRequest  createIndexRequest  =  new  CreateIndexRequest(request.param( "index "));  createIndexRequest.listenerThreaded(false);  if  (request.hasContent())  {  try  {  createIndexRequest.source(request.content());  }  catch  (Exception  e)  {  try  {                      channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                      channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  }  createIndexRequest.timeout(request.paramAsTime( "timeout ",  createIndexRequest.timeout()));  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_38894632c39e4ac0b8f6cc3faf53c6fc79bfb06a	buggy:  String  pHeaders  =  request.param( "headers ");  context:  pad(table.getAsMap().get(header.name).get(row),  width[col],  request,  out);  out.append( "   ");  }  out.append( "\n ");  }  return  new  StringRestResponse(RestStatus.OK,  out.toString());  }  private  static  List<DisplayHeader>  buildDisplayHeaders(Table  table,  RestRequest  request)  {          String  pHeaders  =  request.param( "headers ");          String  pHeaders  =  request.param( "h ");  List<DisplayHeader>  display  =  new  ArrayList<DisplayHeader>();  if  (pHeaders  !=  null)  {  for  (String  possibility  :  Strings.splitStringByCommaToArray(pHeaders))  {  if  (table.getAsMap().containsKey(possibility))  {  display.add(new  DisplayHeader(possibility,  possibility));  }  else  {  for  (Table.Cell  headerCell  :  table.getHeaders())  {  String  aliases  =  headerCell.attr.get( "alias ");  	String  pHeaders  =  request.param( "h ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  queryCollectors  =  new  ArrayList<Collector>();  context:  this.dfSource  =  dfSource;  }  public  void  addMainQueryCollector(Collector  collector)  {  if  (queryCollectors  ==  null)  {              queryCollectors  =  new  ArrayList<Collector>();              queryCollectors  =  new  ArrayList<>();  }  queryCollectors.add(collector);  }  public  DocIdSetCollector  mainDocIdSetCollector()  {  return  this.mainDocIdSetCollector;  }  	queryCollectors  =  new  ArrayList<>();  
libgdx_bc3e1dce275070b794effd62dae6d4c352fdb83a	buggy:  screen  =  new  GameOver(Gdx.app);  context:  if  (screen  instanceof  GameOver)  screen  =  new  MainMenu(app);  }  }  }  if  (!isInitialized)  {  screen  =  new  GameOver(Gdx.app);  screen  =  new  MainMenu(Gdx.app);  Music  music  =  Gdx.audio.newMusic(Gdx.files.getFileHandle( "data/8.12.mp3 ",  FileType.Internal));  music.setLooping(true);  music.play();  isInitialized  =  true;  }  }  	screen  =  new  MainMenu(Gdx.app);  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  context:  }  }  if  (fieldName  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "exists  must  be  provided  with  a  [field] ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {              filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);              filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }  filter  =  parseContext.cacheFilter(filter,  null);  filter  =  new  NotFilter(filter);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  
elasticsearch_91b60f1d2f41747e9435d411faa068b1864615b0	buggy:  System.setProperty( "es-foreground ",   "yes ");  context:  public  class  ElasticSearchF  {  public  static  void  close(String[]  args)  {  Bootstrap.close(args);  }  public  static  void  main(String[]  args)  {          System.setProperty( "es-foreground ",   "yes ");          System.setProperty( "es.foreground ",   "yes ");  Bootstrap.main(args);  }  }  	System.setProperty( "es.foreground ",   "yes ");  
elasticsearch_d2fea5378ad8beff6e2eb566c9d573f93771e2ef	buggy:  final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action);  context:  }  });  }  }  protected  String  handleRequest(Channel  channel,  StreamInput  buffer,  long  requestId,  Version  version)  throws  IOException  {  final  String  action  =  buffer.readString();  final  NettyTransportChannel  transportChannel  =  new  NettyTransportChannel(transport,  action,  channel,  requestId,  version);  try  {              final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action);              final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action,  version);  if  (handler  ==  null)  {  throw  new  ActionNotFoundTransportException(action);  }  final  TransportRequest  request  =  handler.newInstance();  request.remoteAddress(new  InetSocketTransportAddress((InetSocketAddress)  channel.getRemoteAddress()));  request.readFrom(buffer);  if  (handler.executor()  ==  ThreadPool.Names.SAME)  {  	final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action,  version);  
elasticsearch_d150ac2da418d30c5cfbabe47f27cc31e6f5b397	buggy:  invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));  context:  searchCache.releaseFetchResults(fetchResults);  }  }  private  void  innerFinishHim()  {  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  queryResults.values());  }              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_62cc4d554aaa84795a7700e4ce6f2404f8515a79	buggy:  gatewayRecoveryStatus.index().totalSize(),  gatewayRecoveryStatus.index().existingTotalSize(),  gatewayRecoveryStatus.index().currentFilesSize(),  gatewayRecoveryStatus.translog().currentTranslogOperations());  context:  case  TRANSLOG:  stage  =  GatewayRecoveryStatus.Stage.TRANSLOG;  break;  case  DONE:  stage  =  GatewayRecoveryStatus.Stage.DONE;  break;  default:  stage  =  GatewayRecoveryStatus.Stage.INIT;  }  shardStatus.gatewayRecoveryStatus  =  new  GatewayRecoveryStatus(stage,  gatewayRecoveryStatus.startTime(),  gatewayRecoveryStatus.time(),                      gatewayRecoveryStatus.index().totalSize(),  gatewayRecoveryStatus.index().existingTotalSize(),  gatewayRecoveryStatus.index().currentFilesSize(),  gatewayRecoveryStatus.translog().currentTranslogOperations());                      gatewayRecoveryStatus.index().totalSize(),  gatewayRecoveryStatus.index().reusedTotalSize(),  gatewayRecoveryStatus.index().currentFilesSize(),  gatewayRecoveryStatus.translog().currentTranslogOperations());  }  SnapshotStatus  snapshotStatus  =  gatewayService.snapshotStatus();  if  (snapshotStatus  !=  null)  {  GatewaySnapshotStatus.Stage  stage;  switch  (snapshotStatus.stage())  {  case  DONE:  stage  =  GatewaySnapshotStatus.Stage.DONE;  	gatewayRecoveryStatus.index().totalSize(),  gatewayRecoveryStatus.index().reusedTotalSize(),  gatewayRecoveryStatus.index().currentFilesSize(),  gatewayRecoveryStatus.translog().currentTranslogOperations());  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(DeleteMappingRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  DeleteMappingRequest  request,  final  ClusterState  state,  final  ActionListener<DeleteMappingResponse>  listener)  throws  ElasticsearchException  {          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  flushAction.execute(Requests.flushRequest(request.indices()),  new  ActionListener<FlushResponse>()  {  public  void  onResponse(FlushResponse  flushResponse)  {  if  (logger.isTraceEnabled())  {  traceLogResponse( "Flush ",  flushResponse);  }  	request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_e2400bc40e953671a3a70a606ebe6585e548cdf1	buggy:  if  (s.length()  ==  0)  {  context:  }  }  int  size  =  pos  -  start;  if  (size  >  0)  {  result.add(new  String(chars,  start,  size));  }  return  result;  }  public  static  String[]  splitStringToArray(final  CharSequence  s,  final  char  c)  {          if  (s.length()  ==  0)  {          if  (s  ==  null  ||  s.length()  ==  0)  {  return  Strings.EMPTY_ARRAY;  }  int  count  =  1;  for  (int  i  =  0;  i  <  s.length();  i++)  {  if  (s.charAt(i)  ==  c)  {  count++;  }  }  	if  (s  ==  null  ||  s.length()  ==  0)  {  
elasticsearch_5ad540a1aa187b0f8eb3f272e7925e3b710a4e0f	buggy:  long  totalSizeInBytes  =  merge.totalBytesSize();  context:  return  currentMergesNumDocs.count();  }  public  long  currentMergesSizeInBytes()  {  return  currentMergesSizeInBytes.count();  }  protected  void  doMerge(MergePolicy.OneMerge  merge)  throws  IOException  {  int  totalNumDocs  =  merge.totalNumDocs();          long  totalSizeInBytes  =  merge.totalBytesSize();          long  totalSizeInBytes  =  merge.estimatedMergeBytes;  long  time  =  System.currentTimeMillis();  currentMerges.inc();  currentMergesNumDocs.inc(totalNumDocs);  currentMergesSizeInBytes.inc(totalSizeInBytes);  if  (logger.isTraceEnabled())  {  }  try  {  	long  totalSizeInBytes  =  merge.estimatedMergeBytes;  
elasticsearch_b8366a3213ae5995514357ab300c9efe0dd362b9	buggy:  if  (aggregations.size()  ==  1)  {  context:  }  public  SearchHits  getHits()  {  return  searchHits;  }  public  InternalAggregation  reduce(ReduceContext  reduceContext)  {  List<InternalAggregation>  aggregations  =  reduceContext.aggregations();          if  (aggregations.size()  ==  1)  {          if  (aggregations.size()  ==  1  &&  from  ==  0)  {  return  aggregations.get(0);  }  TopDocs[]  shardDocs  =  new  TopDocs[aggregations.size()];  InternalSearchHits[]  shardHits  =  new  InternalSearchHits[aggregations.size()];  for  (int  i  =  0;  i  <  shardDocs.length;  i++)  {  InternalTopHits  topHitsAgg  =  (InternalTopHits)  aggregations.get(i);  shardDocs[i]  =  topHitsAgg.topDocs;  	if  (aggregations.size()  ==  1  &&  from  ==  0)  {  
libgdx_319bde057ca58a5396b0d99fb653d14f431cc4ae	buggy:  runOnEDT  =  config.forceExit;  context:  protected  void  exception  (Throwable  ex)  {  ex.printStackTrace();  System.exit(0);  }  void  initialize  (JglfwApplicationConfiguration  config)  {  forceExit  =  config.forceExit;  runOnEDT  =  config.forceExit;  runOnEDT  =  config.runOnEDT;  final  Thread  glThread  =  Thread.currentThread();  GdxNativesLoader.load();  boolean  inputCallbacksOnAppKitThread  =  isMac;  if  (inputCallbacksOnAppKitThread)  java.awt.Toolkit.getDefaultToolkit();  //  Ensure  AWT  is  initialized  before  GLFW.  	runOnEDT  =  config.runOnEDT;  
elasticsearch_4ff3e1926b0b0a092a9fcb70f47fb49977ec2d70	buggy:  return  ScriptDocValues.EMPTY;  context:  return  0;  }  public  BytesValues  getBytesValues(boolean  needsHashes)  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {              return  ScriptDocValues.EMPTY;              return  ScriptDocValues.EMPTY_DOUBLES;  }  }  public  static  class  WithOrdinals  extends  DoubleArrayAtomicFieldData  {  private  final  BigDoubleArrayList  values;  private  final  Ordinals  ordinals;  	return  ScriptDocValues.EMPTY_DOUBLES;  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  public  BytesValues  getBytesValues(boolean  needsHashes)  {  context:  public  long  getNumberUniqueValues()  {  return  0;  }  public  long  getMemorySizeInBytes()  {  return  0;  }          public  BytesValues  getBytesValues(boolean  needsHashes)  {          public  BytesValues  getBytesValues()  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {  return  ScriptDocValues.EMPTY_DOUBLES;  }  }  	public  BytesValues  getBytesValues()  {  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  docTerms  =  indexFieldData.load(context).getBytesValues();  context:  }  else  {  if  (values[slot]  ==  null  ||  values[slot]  ==  missingValue)  {  values[slot]  =  new  BytesRef();  }  values[slot].copyBytes(docTerms.nextValue());  }  }  public  FieldComparator<BytesRef>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          docTerms  =  indexFieldData.load(context).getBytesValues();          docTerms  =  indexFieldData.load(context).getBytesValues(false);  if  (docTerms.isMultiValued())  {  docTerms  =  new  MultiValuedBytesWrapper(docTerms,  sortMode);  }  return  this;  }  public  void  setBottom(final  int  bottom)  {  	docTerms  =  indexFieldData.load(context).getBytesValues(false);  
libgdx_36a4ac8ffe5f7c2bcbf1ff6678778c8e5ddcc1f0	buggy:  table.enableClipping(stage);  context:  Label  label  =  new  Label( "This  is  some  text. ",  skin);  root  =  new  Table();  stage.addActor(root);  Table  table  =  new  Table();  table.setBackground(patch);  table.enableClipping(stage);  table.setClip(true);  table.size(75,  75);  table.add(label);  table.setClickListener(new  ClickListener()  {  public  void  click  (Actor  actor,  float  x,  float  y)  {  }  });  	table.setClip(true);  
libgdx_6cc53e2279ec82085265a200ee7cb71e52206682	buggy:  Sprite  sprite  =  atlas.getSprite(imageName);  context:  }  public  void  loadEmitterImages  (TextureAtlas  atlas)  {  for  (int  i  =  0,  n  =  emitters.size();  i  <  n;  i++)  {  ParticleEmitter  emitter  =  emitters.get(i);  String  imagePath  =  emitter.getImagePath();  if  (imagePath  ==  null)  continue;  String  imageName  =  new  File(imagePath.replace('\\',  '/')).getName();  int  lastDotIndex  =  imageName.lastIndexOf('.');  if  (lastDotIndex  !=  -1)  imageName  =  imageName.substring(0,  lastDotIndex);  Sprite  sprite  =  atlas.getSprite(imageName);  Sprite  sprite  =  atlas.createSprite(imageName);  if  (sprite  ==  null)  throw  new  IllegalArgumentException( "SpriteSheet  missing  image:   "  +  imageName);  emitter.setSprite(sprite);  }  }  public  void  loadEmitterImages  (FileHandle  imagesDir)  {  for  (int  i  =  0,  n  =  emitters.size();  i  <  n;  i++)  {  ParticleEmitter  emitter  =  emitters.get(i);  	Sprite  sprite  =  atlas.createSprite(imageName);  
libgdx_f37fae4c93f81db51d3fd43b63c1dcf629b6556a	buggy:  return  distance  <=  radiusSum  *  radiusSum;  context:  return  dx  *  dx  +  dy  *  dy  <=  radius  *  radius;  }  public  boolean  overlaps  (Circle  c)  {  float  dx  =  x  -  c.x;  float  dy  =  y  -  c.y;  float  distance  =  dx  *  dx  +  dy  *  dy;  float  radiusSum  =  radius  +  c.radius;  return  distance  <=  radiusSum  *  radiusSum;  return  distance  <  radiusSum  *  radiusSum;  }  public  String  toString  ()  {  return  x  +   ", "  +  y  +   ", "  +  radius;  }  }  	return  distance  <  radiusSum  *  radiusSum;  
elasticsearch_976152b23e2fe0b658b5b7c3ed225ff76b0a798b	buggy:  e.printStackTrace();  context:  return;  }  boolean  shutdownWithWrapper  =  false;  if  (System.getProperty( "elasticsearch-service ")  !=  null)  {  try  {  Class  wrapperManager  =  settings.getClassLoader().loadClass( "org.tanukisoftware.wrapper.WrapperManager ");  wrapperManager.getMethod( "stopAndReturn ",  int.class).invoke(null,  0);  shutdownWithWrapper  =  true;  }  catch  (Throwable  e)  {                              e.printStackTrace();                              logger.error( "failed  to  initial  shutdown  on  service  wrapper ",  e);  }  }  if  (!shutdownWithWrapper)  {  try  {  node.close();  }  catch  (Exception  e)  {  	logger.error( "failed  to  initial  shutdown  on  service  wrapper ",  e);  
elasticsearch_f57efcf6c868c107edde6bb087dab2280acd86d3	buggy:  public  Object  clone()  {  context:  this.chunkSize  =  in.readVInt();  this.maxCompressedChunkLength  =  in.readVInt();  }  protected  void  doClose()  throws  IOException  {  }      public  Object  clone()  {      public  IndexInput  clone()  {  SnappyCompressedIndexInput  cloned  =  (SnappyCompressedIndexInput)  super.clone();  cloned.inputBuffer  =  new  byte[inputBuffer.length];  return  cloned;  }  }  	public  IndexInput  clone()  {  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray());  context:  DiscoveryNodes  nodes  =  DiscoveryNodes.newNodesBuilder().put(newNode( "node1 ")).put(newNode( "node2 ")).put(newNode( "node3 ")).build();  ClusterState  clusterState  =  newClusterStateBuilder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();  AllocationService  strategy  =  new  AllocationService();  RoutingTable  source  =  strategy.reroute(clusterState).routingTable();  BytesStreamOutput  outStream  =  new  BytesStreamOutput();  RoutingTable.Builder.writeTo(source,  outStream);          BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray());          BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray(),  false);  RoutingTable  target  =  RoutingTable.Builder.readFrom(inStream);  assertThat(target.prettyPrint(),  equalTo(source.prettyPrint()));  }  private  DiscoveryNode  newNode(String  nodeId)  {  return  new  DiscoveryNode(nodeId,  DummyTransportAddress.INSTANCE);  }  	BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray(),  false);  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);  context:  }  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  chosenFilter);  }  return  chosenFilter;  }  protected  boolean  matchesIndices(String  currentIndex,  String...  indices)  {          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  for  (String  index  :  concreteIndices)  {  if  (Regex.simpleMatch(index,  currentIndex))  {  return  true;  }  }  return  false;  }  }  	final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  
libgdx_dcd706c7094ece4464a872334d9c8b6b89bc16ac	buggy:  Keyframe  keyframe  =  anim.keyframes[9];  context:  return  subMeshes;  }  int  len  =  subMeshes.length;  for(int  i  =  0;  i  <  len;  i++)  {  KeyframedSubMesh  subMesh  =  subMeshes[i];  KeyframedAnimation  anim  =  subMesh.animations.get(animation);  if(anim  ==  null)  throw  new  IllegalArgumentException( "No  animation  with  name  ' "  +  animation  +   "'  in  submesh  # "  +  i);  Keyframe  keyframe  =  anim.keyframes[9];  Keyframe  keyframe  =  anim.keyframes[(int)time];  float[]  src  =  keyframe.vertices;  int  numComponents  =  keyframe.animatedComponents;  int  srcLen  =  numComponents  *  subMesh.mesh.getNumVertices();  float[]  dst  =  subMesh.blendedVertices;  int  dstInc  =  subMesh.mesh.getVertexSize()  /  4  -  numComponents;  	Keyframe  keyframe  =  anim.keyframes[(int)time];  
libgdx_696cc6ec4009217cb4f4eb791a7fbb529b11743d	buggy:  int  total  =  count  =  Math.min(available,  count);  context:  copy  =  Math.min(buffer.length  -  available,  count);  System.arraycopy(buffer,  readPosition,  data,  offset,  copy);  readPosition  =  (readPosition  +  copy)  %  buffer.length;  available  -=  copy;  }  return  total;  }  public  int  skip(int  count)  {  int  total  =  count  =  Math.min(available,  count);  int  total  =  Math.min(available,  count);  available  -=  total;  readPosition  =  (readPosition  +  total)  %  buffer.length;  return  total;  }  public  void  clear  ()  {  for  (int  i  =  0,  n  =  buffer.length;  i  <  n;  i++)  buffer[i]  =  0;  	int  total  =  Math.min(available,  count);  
elasticsearch_6c552b4187e49696e81c12f10baa75304114dae0	buggy:  @Override  public  boolean  get(int  doc)  throws  IOException  {  context:  this.points  =  points;  }  return  false;  }          @Override  public  boolean  get(int  doc)  throws  IOException  {          @Override  public  boolean  get(int  doc)  {  if  (!fieldData.hasValue(doc))  {  return  false;  }  if  (fieldData.multiValued())  {  double[]  lats  =  fieldData.latValues(doc);  double[]  lons  =  fieldData.lonValues(doc);  for  (int  i  =  0;  i  <  lats.length;  i++)  {  	@Override  public  boolean  get(int  doc)  {  
elasticsearch_9714dd55c2c7a447618a459e5065ea0975093f0f	buggy:  filter  =  fieldMapper.termsFilter(parseContext,  terms,  parseContext);  context:  if  (cache  ==  null  ||  cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  }  else  if  ( "fielddata ".equals(execution))  {  if  (fieldMapper  ==  null)  {  return  Queries.MATCH_NO_FILTER;  }                  filter  =  fieldMapper.termsFilter(parseContext,  terms,  parseContext);                  filter  =  fieldMapper.fieldDataTermsFilter(terms,  parseContext);  if  (cache  !=  null  &&  cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  }  else  if  ( "bool ".equals(execution))  {  XBooleanFilter  boolFiler  =  new  XBooleanFilter();  if  (fieldMapper  !=  null)  {  for  (Object  term  :  terms)  {  boolFiler.add(parseContext.cacheFilter(fieldMapper.termFilter(term,  parseContext),  null),  BooleanClause.Occur.SHOULD);  	filter  =  fieldMapper.fieldDataTermsFilter(terms,  parseContext);  
elasticsearch_65d3b61b975121c19d79843b24b6c6567a7f468c	buggy:  OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().execute().actionGet();  context:  assertNoFailures(actionGet);  }  return  actionGet;  }  protected  OptimizeResponse  optimize()  {  waitForRelocation();          OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().execute().actionGet();          OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().setForce(randomBoolean()).execute().actionGet();  assertNoFailures(actionGet);  return  actionGet;  }  protected  boolean  indexExists(String  index)  {  	OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().setForce(randomBoolean()).execute().actionGet();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ignoredShardToNodes  =  new  HashMap<ShardId,  String>();  context:  public  void  debugDecision(boolean  debug)  {  this.debugDecision  =  debug;  }  public  boolean  debugDecision()  {  return  this.debugDecision;  }  public  void  addIgnoreShardForNode(ShardId  shardId,  String  nodeId)  {  if  (ignoredShardToNodes  ==  null)  {              ignoredShardToNodes  =  new  HashMap<ShardId,  String>();              ignoredShardToNodes  =  new  HashMap<>();  }  ignoredShardToNodes.put(shardId,  nodeId);  }  public  boolean  shouldIgnoreShardForNode(ShardId  shardId,  String  nodeId)  {  return  ignoredShardToNodes  !=  null  &&  nodeId.equals(ignoredShardToNodes.get(shardId));  }  	ignoredShardToNodes  =  new  HashMap<>();  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  valueScript.setNextReader(context.reader());  context:  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  valueScript.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (NumericFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);          valueScript.setNextReader(context.reader());          valueScript.setNextReader(context);  }  public  Facet  facet()  {  return  new  InternalBoundedFullHistogramFacet(facetName,  comparatorType,  histoProc.interval,  -histoProc.offset,  histoProc.size,  histoProc.entries,  true);  }  public  static  long  bucket(double  value,  long  interval)  {  	valueScript.setNextReader(context);  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  cam.position.mul(30);  context:  final  Sprite[][]  sprites  =  new  Sprite[10][10];  final  Matrix4  matrix  =  new  Matrix4();  public  void  create  ()  {  texture  =  new  Texture(Gdx.files.internal( "data/badlogicsmall.jpg "));  float  unitsOnX  =  (float)Math.sqrt(2)  *  TARGET_WIDTH  /  (UNIT_TO_PIXEL);  float  pixelsOnX  =  Gdx.graphics.getWidth()  /  unitsOnX;  float  unitsOnY  =  Gdx.graphics.getHeight()  /  pixelsOnX;  cam  =  new  OrthographicCamera(unitsOnX,  unitsOnY,  25);  cam.position.mul(30);  cam.position.scl(30);  cam.near  =  1;  cam.far  =  1000;  matrix.setToRotation(new  Vector3(1,  0,  0),  90);  for  (int  z  =  0;  z  <  10;  z++)  {  for  (int  x  =  0;  x  <  10;  x++)  {  sprites[x][z]  =  new  Sprite(texture);  sprites[x][z].setPosition(x,  z);  	cam.position.scl(30);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  if  (aliasesSize  >  0)  {  filteringAliases  =  new  String[aliasesSize];  for  (int  i  =  0;  i  <  aliasesSize;  i++)  {  filteringAliases[i]  =  in.readUTF();  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  if  (routing  !=  null)  {  out.writeVInt(routing.size());  for  (String  r  :  routing)  {  out.writeUTF(r);  	out.writeBytesReference(querySource);  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "keyed ".equals(currentFieldName))  {  keyed  =  parser.booleanValue();                  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {                  }  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  {  throw  new  SearchParseException(context,   "Unexpected  token   "  +  token  +   "  in  [ "  +  aggregationName  +   "]. ");  }  }  	}  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
elasticsearch_eccc7d5ef21dade9bd14d3a3adaf60e664582ac0	buggy:  }  else  if  ( "cache ".equals(currentFieldName))  {  context:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "filter ".equals(currentFieldName))  {  filter  =  parseContext.parseInnerFilter();  }  }  else  if  (token.isValue())  {  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();                  }  else  if  ( "cache ".equals(currentFieldName))  {                  }  else  if  ( "_cache ".equals(currentFieldName))  {  cache  =  parser.booleanValue();  }  }  }  if  (filter  ==  null)  {  throw  new  QueryParsingException(index,   "[constant_score]  requires  'filter'  element ");  }  	}  else  if  ( "_cache ".equals(currentFieldName))  {  
libgdx_7bf31c98c942c51e489dd822312bb1cc3623e0ff	buggy:  new  AngleApplication(new  com.badlogic.gdx.tests.MeshShaderTest(),   "Angle  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.angle;  public  class  AngleDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  AngleApplication(new  com.badlogic.gdx.tests.MeshShaderTest(),   "Angle  Test ",  480,  320,  false);  new  AngleApplication(new  com.badlogic.gdx.tests.gles2.SimpleVertexShader(),   "Angle  Test ",  480,  320,  true);  }  }  	new  AngleApplication(new  com.badlogic.gdx.tests.gles2.SimpleVertexShader(),   "Angle  Test ",  480,  320,  true);  
elasticsearch_deff09434361b854b0ec554364ec593c13170ace	buggy:  RoutingTable  routingTable  =  RoutingTable.builder().version(clusterState.routingTable().version()).build();  context:  nodesFD.stop();  masterFD.stop(reason);  master  =  false;  ClusterBlocks  clusterBlocks  =  ClusterBlocks.builder().blocks(clusterState.blocks())  .addGlobalBlock(NO_MASTER_BLOCK)  .addGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK)  .build();          RoutingTable  routingTable  =  RoutingTable.builder().version(clusterState.routingTable().version()).build();          RoutingTable  routingTable  =  RoutingTable.builder().build();  MetaData  metaData  =  MetaData.builder().build();  latestDiscoNodes  =  new  DiscoveryNodes.Builder().put(localNode).localNodeId(localNode.id()).build();  asyncJoinCluster();  	RoutingTable  routingTable  =  RoutingTable.builder().build();  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  InputStream  input  =  file.getInputStream();  context:  }  }  }  public  void  load  (FileHandle  effectFile,  String  imagesDir,  FileType  fileType)  {  loadEmitters(effectFile);  loadEmitterImages(imagesDir,  fileType);  }  void  loadEmitters  (FileHandle  file)  {  InputStream  input  =  file.getInputStream();  InputStream  input  =  file.readFile();  if  (input  ==  null)  throw  new  GdxRuntimeException( "Effect  file  not  found:   "  +  file);  emitters.clear();  BufferedReader  reader  =  null;  try  {  reader  =  new  BufferedReader(new  InputStreamReader(input),  512);  while  (true)  {  ParticleEmitter  emitter  =  new  ParticleEmitter(reader);  reader.readLine();  	InputStream  input  =  file.readFile();  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  this.dateTimeFormatter  =  dateTimeFormatter;  return  this;  }  public  DateFieldMapper  build(BuilderContext  context)  {  boolean  parseUpperInclusive  =  Defaults.PARSE_UPPER_INCLUSIVE;  if  (context.indexSettings()  !=  null)  {  parseUpperInclusive  =  context.indexSettings().getAsBoolean( "index.mapping.date.parse_upper_inclusive ",  Defaults.PARSE_UPPER_INCLUSIVE);  }              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  DateFieldMapper  fieldMapper  =  new  DateFieldMapper(buildNames(context),  dateTimeFormatter,  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  timeUnit,  parseUpperInclusive,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  AllocateDangledRequest  request  =  new  AllocateDangledRequest(clusterState.nodes().localNode(),  indices);  context:  transportService.registerHandler(AllocateDangledRequestHandler.ACTION,  new  AllocateDangledRequestHandler());  }  public  void  allocateDangled(IndexMetaData[]  indices,  final  Listener  listener)  {  ClusterState  clusterState  =  clusterService.state();  DiscoveryNode  masterNode  =  clusterState.nodes().masterNode();  if  (masterNode  ==  null)  {  listener.onFailure(new  MasterNotDiscoveredException( "no  master  to  send  allocate  dangled  request "));  return;  }          AllocateDangledRequest  request  =  new  AllocateDangledRequest(clusterState.nodes().localNode(),  indices);          AllocateDangledRequest  request  =  new  AllocateDangledRequest(clusterService.localNode(),  indices);  transportService.sendRequest(masterNode,  AllocateDangledRequestHandler.ACTION,  request,  new  TransportResponseHandler<AllocateDangledResponse>()  {  public  AllocateDangledResponse  newInstance()  {  return  new  AllocateDangledResponse();  }  public  void  handleResponse(AllocateDangledResponse  response)  {  	AllocateDangledRequest  request  =  new  AllocateDangledRequest(clusterService.localNode(),  indices);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  snapshotIndexCommit.release();  context:  SnapshotIndexCommit  snapshotIndexCommit  =  indexShard.snapshotIndex();  try  {  indexShardRepository.snapshot(snapshotId,  shardId,  snapshotIndexCommit,  snapshotStatus);  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "snapshot  ( ").append(snapshotId.getSnapshot()).append( ")  completed  to   ").append(indexShardRepository).append( ",  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.time())).append( "]\n ");  sb.append( "    index    :  version  [ ").append(snapshotStatus.indexVersion()).append( "],  number_of_files  [ ").append(snapshotStatus.numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(snapshotStatus.totalSize())).append( "]\n ");  }  }  finally  {                  snapshotIndexCommit.release();                  snapshotIndexCommit.close();  }  }  catch  (SnapshotFailedEngineException  e)  {  throw  e;  }  catch  (IndexShardSnapshotFailedException  e)  {  throw  e;  }  catch  (Throwable  e)  {  throw  new  IndexShardSnapshotFailedException(shardId,   "Failed  to  snapshot ",  e);  }  	snapshotIndexCommit.close();  
libgdx_eb0808f92eddd1a96029a6f55974c78838663252	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.MultiTouchActorTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.MultiTouchActorTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_27b53b8edfac1844a33389af9e97bc062f8b69dc	buggy:  parseContext.addNamedQuery(filterName,  parentConstantScoreQuery);  context:  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(parentTypeStr);  Filter  filter  =  parseContext.cacheFilter(documentMapper.typeFilter(),  null);  parentsFilter.add(filter,  BooleanClause.Occur.SHOULD);  }  parentFilter  =  parentsFilter;  }  Filter  childrenFilter  =  parseContext.cacheFilter(new  NotFilter(parentFilter),  null);  Query  parentConstantScoreQuery  =  new  ParentConstantScoreQuery(query,  parentType,  childrenFilter);  if  (filterName  !=  null)  {              parseContext.addNamedQuery(filterName,  parentConstantScoreQuery);              parseContext.addNamedFilter(filterName,  new  CustomQueryWrappingFilter(parentConstantScoreQuery));  }  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  if  (deleteByQuery)  {  return  new  DeleteByQueryWrappingFilter(parentConstantScoreQuery);  }  else  {  return  new  CustomQueryWrappingFilter(parentConstantScoreQuery);  }  	parseContext.addNamedFilter(filterName,  new  CustomQueryWrappingFilter(parentConstantScoreQuery));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  BoundedTreeSet<InternalStringTermsFacet.TermEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.TermEntry>(comparatorType.comparator(),  shardSize);  context:  ordered.insertWithOverflow(new  InternalStringTermsFacet.TermEntry(key,  values[i]));  }  }  InternalStringTermsFacet.TermEntry[]  list  =  new  InternalStringTermsFacet.TermEntry[ordered.size()];  for  (int  i  =  ordered.size()  -  1;  i  >=  0;  i--)  {  list[i]  =  ((InternalStringTermsFacet.TermEntry)  ordered.pop());  }  facets.release();  return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Arrays.asList(list),  missing,  total);  }  else  {                  BoundedTreeSet<InternalStringTermsFacet.TermEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.TermEntry>(comparatorType.comparator(),  shardSize);                  BoundedTreeSet<InternalStringTermsFacet.TermEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  BytesRef  key  =  (BytesRef)  keys[i];  ordered.add(new  InternalStringTermsFacet.TermEntry(key,  values[i]));  }  }  facets.release();  return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  ordered,  missing,  total);  	BoundedTreeSet<InternalStringTermsFacet.TermEntry>  ordered  =  new  BoundedTreeSet<>(comparatorType.comparator(),  shardSize);  
libgdx_fbef43ca95617a93068852b688a6857d4f172193	buggy:  BufferUtils.freeMemory(byteBuffer);  context:  bufferHandle  =  0;  }  else  {  tmpHandle.clear();  tmpHandle.put(bufferHandle);  tmpHandle.flip();  GL11  gl  =  Gdx.gl11;  gl.glBindBuffer(GL11.GL_ARRAY_BUFFER,  0);  gl.glDeleteBuffers(1,  tmpHandle);  bufferHandle  =  0;  }  BufferUtils.freeMemory(byteBuffer);  BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  }  }  	BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  
elasticsearch_79af3228ad41ac1f2e246b33bb22854b21f6cab8	buggy:  return  RestStatus.SERVICE_UNAVAILABLE;  context:  public  EsRejectedExecutionException()  {  super(null);  }  public  EsRejectedExecutionException(Throwable  e)  {  super(null,  e);  }  public  RestStatus  status()  {          return  RestStatus.SERVICE_UNAVAILABLE;          return  RestStatus.TOO_MANY_REQUESTS;  }  }  	return  RestStatus.TOO_MANY_REQUESTS;  
libgdx_c603fc402fdef85c37f775653707802278d5496e	buggy:  GdxTest  test  =  new  BulletTestCollection();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  BulletTestCollection();  GdxTest  test  =  new  NewModelTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  NewModelTest();  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  parseMultiField(builder,  name,  node,  parserContext,  propName,  propNode);  context:  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  ExternalMapper.Builder  builder  =  new  ExternalMapper.Builder(name,  generatedValue,  mapperName);  parseField(builder,  name,  node,  parserContext);  for  (Map.Entry<String,  Object>  entry  :  node.entrySet())  {  String  propName  =  Strings.toUnderscoreCase(entry.getKey());  Object  propNode  =  entry.getValue();                  parseMultiField(builder,  name,  node,  parserContext,  propName,  propNode);                  parseMultiField(builder,  name,  parserContext,  propName,  propNode);  }  return  builder;  }  }  private  final  String  generatedValue;  private  final  String  mapperName;  	parseMultiField(builder,  name,  parserContext,  propName,  propNode);  
elasticsearch_fef647cb92926c97107f506831bfbdc0b838e80c	buggy:  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());  context:  }  public  ClusterState  execute(final  ClusterState  currentState)  {  if  (!currentState.metaData().hasConcreteIndex(request.index))  {  throw  new  IndexMissingException(new  Index(request.index));  }                  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());                  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  routingTableBuilder.remove(request.index);  MetaData  newMetaData  =  MetaData.builder(currentState.metaData())  .remove(request.index)  .build();  RoutingAllocation.Result  routingResult  =  allocationService.reroute(  newClusterStateBuilder().state(currentState).routingTable(routingTableBuilder).metaData(newMetaData).build());  	RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  
libgdx_752be931ebf139e3a74ab3e477e1434875a7ab95	buggy:  return  localAnchorA.set(joint.getLocalAnchorB().x,  joint.getLocalAnchorB().y);  context:  public  float  getMotorTorque  (float  invDt)  {  return  joint.getMotorTorque(invDt);  }  public  Vector2  getLocalAnchorA  ()  {  return  localAnchorA.set(joint.getLocalAnchorA().x,  joint.getLocalAnchorA().y);  }  public  Vector2  getLocalAnchorB  ()  {  return  localAnchorA.set(joint.getLocalAnchorB().x,  joint.getLocalAnchorB().y);  return  localAnchorB.set(joint.getLocalAnchorB().x,  joint.getLocalAnchorB().y);  }  public  float  getReferenceAngle  ()  {  return  joint.getReferenceAngle();  }  public  float  getMaxMotorTorque  ()  {  	return  localAnchorB.set(joint.getLocalAnchorB().x,  joint.getLocalAnchorB().y);  
elasticsearch_01c5be1da313e9e8c12c6d680b879ca532c11167	buggy:  for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GENERIC,  ThreadPool.Names.GET,  context:  builder.put(TransportModule.TRANSPORT_TYPE_KEY,  AssertingLocalTransportModule.class.getName());  }  else  {  builder.put(Transport.TransportSettings.TRANSPORT_TCP_COMPRESS,  rarely(random));  }  builder.put( "type ",  RandomPicks.randomFrom(random,  CacheRecycler.Type.values()));  if  (random.nextBoolean())  {  builder.put( "cache.recycler.page.type ",  RandomPicks.randomFrom(random,  CacheRecycler.Type.values()));  }  if  (random.nextBoolean())  {              for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GENERIC,  ThreadPool.Names.GET,              for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GET,  ThreadPool.Names.INDEX,  ThreadPool.Names.MANAGEMENT,  ThreadPool.Names.MERGE,  ThreadPool.Names.OPTIMIZE,  ThreadPool.Names.PERCOLATE,  ThreadPool.Names.REFRESH,  ThreadPool.Names.SEARCH,  ThreadPool.Names.SNAPSHOT,  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  if  (random.nextBoolean())  {  final  String  type  =  RandomPicks.randomFrom(random,  Arrays.asList( "fixed ",   "cached ",   "scaling "));  builder.put(ThreadPool.THREADPOOL_GROUP  +  name  +   ".type ",  type);  }  }  	for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GET,  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  context:  return  TransportActions.Admin.Indices.ANALYZE;  }  return   "indices/analyze/shard ";  }  request.index(clusterState.metaData().concreteIndex(request.index()));          return  clusterState.routingTable().index(request.index()).randomAllShardsIt();          return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  Analyzer  analyzer  =  null;  String  field  =  null;  if  (request.field()  !=  null)  {  FieldMapper  fieldMapper  =  indexService.mapperService().smartNameFieldMapper(request.field());  	return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(5).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode( "node1 "))).build();  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  RoutingNodes  routingNodes  =  clusterState.routingNodes();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
libgdx_a595abd836ae1004e7bbdd05f1e5b19788815031	buggy:  frustum.update(combined);  context:  private  final  Vector3  tmp  =  new  Vector3();  public  void  update()  {  projection.setToOrtho(zoom  *  -viewportWidth  /  2,  zoom  *  viewportWidth  /  2,  zoom  *  -viewportHeight  /  2,  zoom  *  viewportHeight  /  2,  Math.abs(near),  Math.abs(far));  view.setToLookAt(position,  tmp.set(position).add(direction),  up);  combined.set(projection);  Matrix4.mul(combined.val,  view.val);  invProjectionView.set(combined);  Matrix4.inv(invProjectionView.val);  frustum.update(combined);  frustum.update(invProjectionView);  }  }  	frustum.update(invProjectionView);  
libgdx_6922b9beeda31b1b08a97e87b284061c8a2b49ad	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.MeshTest(),   "Debug  Test ",  480,  320,  false  );  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.MeshTest(),   "Debug  Test ",  480,  320,  false  );  new  JoglApplication(  new  com.badlogic.gdx.tests.TileTest(),   "Debug  Test ",  480,  320,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.TileTest(),   "Debug  Test ",  480,  320,  false  );  
libgdx_4e79efa5c0f705969de4aa454da31fb6bab84cec	buggy:  sprite.draw(batch);  //,  parentAlpha);  context:  height  =  Math.abs(region.getRegionHeight());  originX  =  width  /  2.0f;  originY  =  height  /  2.0f;  this.region  =  new  TextureRegion(region);  }  updateSprite();  if  (region.getTexture()  !=  null)  {  sprite.draw(batch);  //,  parentAlpha);  sprite.draw(batch,  parentAlpha);  }  }  private  void  updateSprite()  {  if(updated)  return;  if(sX  !=  x  ||  sY  !=  y)  {  sprite.setPosition(x,  y);  sX  =  x;  	sprite.draw(batch,  parentAlpha);  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  refreshRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  refreshRequest.operationThreading(operationThreading);  client.admin().indices().execRefresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  ByteArrayAtomicFieldData.SingleFixedSet(new  byte[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  ByteArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  ByteArrayAtomicFieldData.SingleFixedSet(new  byte[1],  0,  new  FixedBitSet(1));              return  ByteArrayAtomicFieldData.EMPTY;  }  final  TByteArrayList  values  =  new  TByteArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  ByteArrayAtomicFieldData.EMPTY;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "  +  i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i  *  2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(histogram( "sub_histo ").interval(1l)))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  return  execute(new  Request(shardId,  onlyUnallocated,  nodesIds).timeout(timeout));  context:  public  TransportNodesListShardStoreMetaData(Settings  settings,  ClusterName  clusterName,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService,  NodeEnvironment  nodeEnv)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  this.nodeEnv  =  nodeEnv;  }  public  ActionFuture<NodesStoreFilesMetaData>  list(ShardId  shardId,  boolean  onlyUnallocated,  Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {          return  execute(new  Request(shardId,  onlyUnallocated,  nodesIds).timeout(timeout));          return  execute(new  Request(shardId,  onlyUnallocated,  nodesIds).setTimeout(timeout));  }  protected  String  executor()  {  return  ThreadPool.Names.GENERIC;  }  	return  execute(new  Request(shardId,  onlyUnallocated,  nodesIds).setTimeout(timeout));  
libgdx_cb553906a6e25ef0073f29ba1bad66a1cca01cb1	buggy:  Table  table  =  new  Table( "toolbar ");  context:  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  Label  label  =  new  Label( "Camera: ",  skin.getStyle(LabelStyle.class));  ComboBox  cameraCombo  =  new  ComboBox(new  String[]  { "Scene ",   "Light "},  ui,  skin.getStyle(ComboBoxStyle.class));  Label  label2  =  new  Label( "Shader ",  skin.getStyle(LabelStyle.class),   "cameraCombo ");  ComboBox  shaderCombo  =  new  ComboBox(new  String[]  { "flat ",   "shadow-gen ",   "shadow-map "},  ui,  skin.getStyle(ComboBoxStyle.class),   "shaderCombo ");  Label  fpsLabel  =  new  Label( "fps: ",  skin.getStyle(LabelStyle.class),   "fps ");  Table  table  =  new  Table( "toolbar ");  Table  table  =  new  Table();  table.width  =  Gdx.graphics.getWidth();  table.height  =  100;  table.top().padTop(12);  table.defaults().spaceRight(5);  table.add(label);  table.add(cameraCombo);  table.add(label2);  table.add(shaderCombo);  	Table  table  =  new  Table();  
libgdx_bb5ec2d9cf5bcd9c23c4bdbac1fd651f6725e1a8	buggy:  shader  =  new  ShaderProgram(  graphics.getGL20(),  vertexShader,  fragmentShader);  context:   "}  \n ";  String  fragmentShader  =   "precision  mediump  float;\n "  +   "varying  vec4  v_color;\n "  +   "varying  vec2  v_texCoords;\n "  +   "uniform  sampler2D  u_texture;\n "  +   "void  main()                                  \n "  +   "{                                            \n "  +   "  gl_FragColor  =  v_color  *  texture2D(u_texture,  v_texCoords);\n "  +   "} ";  shader  =  new  ShaderProgram(  graphics.getGL20(),  vertexShader,  fragmentShader);  shader  =  new  ShaderProgram(  graphics.getGL20(),  vertexShader,  fragmentShader,  true);  if(  shader.isCompiled()  ==  false  )  throw  new  IllegalArgumentException(   "couldn't  compile  shader:   "  +  shader.getLog()  );  }  	shader  =  new  ShaderProgram(  graphics.getGL20(),  vertexShader,  fragmentShader,  true);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  float  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
elasticsearch_1f3c038f60689bde5cc285e0f45f6076913cb7eb	buggy:  name  =  mapper.names().name();  context:  hits[index]  =  searchHit;  for  (Object  oField  :  doc.getFields())  {  Fieldable  field  =  (Fieldable)  oField;  String  name  =  field.name();  Object  value  =  null;  FieldMappers  fieldMappers  =  documentMapper.mappers().indexName(field.name());  if  (fieldMappers  !=  null)  {  FieldMapper  mapper  =  fieldMappers.mapper();  if  (mapper  !=  null)  {                          name  =  mapper.names().name();                          name  =  mapper.names().fullName();  value  =  mapper.valueForSearch(field);  }  }  if  (value  ==  null)  {  if  (field.isBinary())  {  value  =  field.getBinaryValue();  }  else  {  value  =  field.stringValue();  	name  =  mapper.names().fullName();  
elasticsearch_f6ebee3785f13ce170168371d0d3e8ddf3f3d219	buggy:  shardRequest.add(i,  item.type(),  item.id());  context:  .getShards(clusterState,  item.index(),  item.type(),  item.id(),  item.routing(),  null).shardId();  MultiGetShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiGetShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequest.realtime(request.realtime);  shardRequest.refresh(request.refresh);  shardRequests.put(shardId,  shardRequest);  }              shardRequest.add(i,  item.type(),  item.id());              shardRequest.add(i,  item.type(),  item.id(),  item.fields());  }  final  MultiGetItemResponse[]  responses  =  new  MultiGetItemResponse[request.items.size()];  final  AtomicInteger  counter  =  new  AtomicInteger(shardRequests.size());  for  (final  MultiGetShardRequest  shardRequest  :  shardRequests.values())  {  shardAction.execute(shardRequest,  new  ActionListener<MultiGetShardResponse>()  {  	shardRequest.add(i,  item.type(),  item.id(),  item.fields());  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  numDocs  =  atLeast(100);  context:  public  void  testMultipleDocs()  throws  Exception  {  Directory  dir  =  newDirectory();  IndexWriterConfig  iwc  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  new  MockAnalyzer(random()));  iwc.setMergePolicy(newLogMergePolicy());  RandomIndexWriter  iw  =  new  RandomIndexWriter(random(),  dir,  iwc);  FieldType  offsetsType  =  new  FieldType(TextField.TYPE_STORED);  offsetsType.setIndexOptions(FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);          int  numDocs  =  atLeast(100);          int  numDocs  =  scaledRandomIntBetween(100,  1000);  for(int  i=0;i<numDocs;i++)  {  Document  doc  =  new  Document();  String  content  =   "the  answer  is   "  +  i;  if  ((i  &  1)  ==  0)  {  content  +=   "  some  more  terms ";  }  doc.add(new  Field( "body ",  content,  offsetsType));  doc.add(newStringField( "id ",   " "+i,  Field.Store.YES));  	int  numDocs  =  scaledRandomIntBetween(100,  1000);  
elasticsearch_991b5abdf43447782a5d815b5f2d6c2ea1ec9711	buggy:  return  super.termFilter(values,  context);  context:  int  i  =  0;  for  (String  type  :  context.mapperService().types())  {  typesValues[i++]  =  Uid.createUidAsBytes(type,  bValue);  }  return  new  TermsFilter(names.indexName(),  typesValues);  }  public  Filter  termsFilter(List  values,  @Nullable  QueryParseContext  context)  {  if  (context  ==  null)  {              return  super.termFilter(values,  context);              return  super.termsFilter(values,  context);  }  List<BytesRef>  bValues  =  new  ArrayList<BytesRef>(values.size());  for  (Object  value  :  values)  {  BytesRef  bValue  =  BytesRefs.toBytesRef(value);  for  (String  type  :  context.mapperService().types())  {  bValues.add(Uid.createUidAsBytes(type,  bValue));  }  	return  super.termsFilter(values,  context);  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  return  setMinimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");  context:  public  MoreLikeThisRequestBuilder  setMinimumShouldMatch(String  minimumShouldMatch)  {  request.minimumShouldMatch(minimumShouldMatch);  return  this;  }  public  MoreLikeThisRequestBuilder  setPercentTermsToMatch(float  percentTermsToMatch)  {          return  setMinimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");          return  setMinimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  }  public  MoreLikeThisRequestBuilder  setMinTermFreq(int  minTermFreq)  {  request.minTermFreq(minTermFreq);  return  this;  	return  setMinimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  
elasticsearch_f3d3a8bd58c97625f46b7e99743ec3f037aad12b	buggy:  assertTrue(e.getMessage().endsWith( "IllegalStateException[field  \ "field1\ "  was  indexed  without  position  data;  cannot  run  PhraseQuery  (term=quick)];  } "));  context:  .setSettings( "index.number_of_shards ",  1).get();  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",   "quick  brown  fox ",   "field2 ",   "quick  brown  fox ").execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "2 ").setSource( "field1 ",   "quick  lazy  huge  brown  fox ",   "field2 ",   "quick  lazy  huge  brown  fox ").setRefresh(true).execute().actionGet();  SearchResponse  searchResponse  =  client().prepareSearch().setQuery(QueryBuilders.matchQuery( "field2 ",   "quick  brown ").type(MatchQueryBuilder.Type.PHRASE).slop(0)).get();  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  try  {  client().prepareSearch().setQuery(QueryBuilders.matchQuery( "field1 ",   "quick  brown ").type(MatchQueryBuilder.Type.PHRASE).slop(0)).get();  }  catch  (SearchPhaseExecutionException  e)  {              assertTrue(e.getMessage().endsWith( "IllegalStateException[field  \ "field1\ "  was  indexed  without  position  data;  cannot  run  PhraseQuery  (term=quick)];  } "));              assertTrue( "wrong  exception  message   "  +  e.getMessage(),  e.getMessage().endsWith( "IllegalStateException[field  \ "field1\ "  was  indexed  without  position  data;  cannot  run  PhraseQuery  (term=quick)];  } "));  }  }  public  void  testCommonTermsQuery()  throws  Exception  {  client().admin().indices().prepareCreate( "test ")  .addMapping( "type1 ",   "field1 ",   "type=string,analyzer=whitespace ")  .setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1)).execute().actionGet();  	assertTrue( "wrong  exception  message   "  +  e.getMessage(),  e.getMessage().endsWith( "IllegalStateException[field  \ "field1\ "  was  indexed  without  position  data;  cannot  run  PhraseQuery  (term=quick)];  } "));  
libgdx_0256c6ceff897814a8d532fc43d6006c8b9bd7b6	buggy:  return  a  *  a  +  b  *  b  +  c  *  b;  context:  public  float  dst2  (float  x,  float  y,  float  z)  {  final  float  a  =  x  -  this.x;  final  float  b  =  y  -  this.y;  final  float  c  =  z  -  this.z;  return  a  *  a  +  b  *  b  +  c  *  b;  return  a  *  a  +  b  *  b  +  c  *  c;  }  public  float  dst  (float  x,  float  y,  float  z)  {  final  float  d2  =  dst2(x,  y,  z);  return  (d2  ==  0f  ||  d2  ==  1f)  ?  d2  :  (float)Math.sqrt(d2);  }  	return  a  *  a  +  b  *  b  +  c  *  c;  
libgdx_e2d8370eaf12f29bcf3365ad5e46ed2df382982f	buggy:  event.getCurrentTarget().stageToLocalCoordinates(coords);  context:  return  keyDown(event,  event.getKeyCode());  case  keyUp:  return  keyUp(event,  event.getKeyCode());  case  keyTyped:  return  keyTyped(event,  event.getCharacter());  case  scrolled:  return  scrolled(event,  event.getScrollAmount());  }  Vector2  coords  =  Vector2.tmp.set(event.getStageX(),  event.getStageY());  event.getCurrentTarget().stageToLocalCoordinates(coords);  event.getListenerActor().stageToLocalCoordinates(coords);  switch  (event.getType())  {  case  touchDown:  return  touchDown(event,  coords.x,  coords.y,  event.getPointer(),  event.getButton());  case  touchUp:  touchUp(event,  coords.x,  coords.y,  event.getPointer(),  event.getButton());  return  true;  case  touchDragged:  	event.getListenerActor().stageToLocalCoordinates(coords);  
elasticsearch_b5544769d2718eadaa9649c57f08e195d3833b80	buggy:  ChannelBuffer  buffer  =  ChannelBuffers.dynamicBuffer();  context:  byte  status  =  0;  status  =  setResponse(status);  stream.writeByte(status);  //  0  for  request,  1  for  response.  message.writeTo(stream);  ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(stream.copiedByteArray());  buffer.setInt(0,  buffer.writerIndex()  -  4);  //  update  real  size.  channel.write(buffer);  }          ChannelBuffer  buffer  =  ChannelBuffers.dynamicBuffer();          ChannelBuffer  buffer  =  ChannelBuffers.dynamicBuffer(512,  channel.getConfig().getBufferFactory());  ChannelBufferOutputStream  os  =  new  ChannelBufferOutputStream(buffer);  os.write(LENGTH_PLACEHOLDER);  os.writeLong(requestId);  byte  status  =  0;  status  =  setResponse(status);  status  =  setError(status);  	ChannelBuffer  buffer  =  ChannelBuffers.dynamicBuffer(512,  channel.getConfig().getBufferFactory());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  selectedFields  =  new  HashSet<String>();  context:  termVectorRequest.fieldStatistics(request.paramAsBoolean( "fieldStatistics ",  termVectorRequest.fieldStatistics()));  termVectorRequest.fieldStatistics(request.paramAsBoolean( "field_statistics ",  termVectorRequest.fieldStatistics()));  }  static  public  void  addFieldStringsFromParameter(TermVectorRequest  termVectorRequest,  String  fields)  {  Set<String>  selectedFields  =  termVectorRequest.selectedFields();  if  (fields  !=  null)  {  String[]  paramFieldStrings  =  Strings.commaDelimitedListToStringArray(fields);  for  (String  field  :  paramFieldStrings)  {  if  (selectedFields  ==  null)  {                      selectedFields  =  new  HashSet<String>();                      selectedFields  =  new  HashSet<>();  }  if  (!selectedFields.contains(field))  {  field  =  field.replaceAll( "\\s ",   " ");  selectedFields.add(field);  }  }  }  if  (selectedFields  !=  null)  {  	selectedFields  =  new  HashSet<>();  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  }  if  (value  instanceof  BytesRef)  {  return  Numbers.bytesToLong((BytesRef)  value);  }  return  Long.parseLong(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  long  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).longValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);    //  0  because  of  exact  match  
elasticsearch_a3af3d2f47590c859cac1dbc9f6fa273fc6bbd22	buggy:  if  (Queries.isMatchAllQuery(query()))  {  context:  public  void  preProcess()  {  if  (query()  ==  null)  {  parsedQuery(ParsedQuery.MATCH_ALL_PARSED_QUERY);  }  if  (queryBoost()  !=  1.0f)  {  parsedQuery(new  ParsedQuery(new  FunctionScoreQuery(query(),  new  BoostScoreFunction(queryBoost)),  parsedQuery()));  }  Filter  searchFilter  =  mapperService().searchFilter(types());  if  (searchFilter  !=  null)  {              if  (Queries.isMatchAllQuery(query()))  {              if  (Queries.isConstantMatchAllQuery(query()))  {  Query  q  =  new  DeletionAwareConstantScoreQuery(filterCache().cache(searchFilter));  q.setBoost(query().getBoost());  parsedQuery(new  ParsedQuery(q,  parsedQuery()));  }  else  {  parsedQuery(new  ParsedQuery(new  FilteredQuery(query(),  filterCache().cache(searchFilter)),  parsedQuery()));  }  }  }  	if  (Queries.isConstantMatchAllQuery(query()))  {  
elasticsearch_b8708f276d9f51dda1db724a1b290063504d6626	buggy:  return  XContentFactory.xContent(XContentType.JSON).createParser(response.getBody().array(),  response.getBody().arrayOffset(),  response.getBody().remaining()).map();  context:  assertThat(map.get( "ok ").toString(),  equalTo( "true "));  assertThat(map.get( "_index ").toString(),  equalTo( "test "));  assertThat(map.get( "_type ").toString(),  equalTo( "type1 "));  request  =  new  RestRequest(Method.GET,   "/_cluster/health ");  response  =  client.execute(request);  assertThat(response.getStatus(),  equalTo(Status.OK));  }  private  Map<String,  Object>  parseBody(RestResponse  response)  throws  IOException  {          return  XContentFactory.xContent(XContentType.JSON).createParser(response.getBody().array(),  response.getBody().arrayOffset(),  response.getBody().remaining()).map();          return  XContentFactory.xContent(XContentType.JSON).createParser(response.BufferForBody().array(),  response.BufferForBody().arrayOffset(),  response.BufferForBody().remaining()).map();  }  }  	return  XContentFactory.xContent(XContentType.JSON).createParser(response.BufferForBody().array(),  response.BufferForBody().arrayOffset(),  response.BufferForBody().remaining()).map();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(GatewaySnapshotResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_7ae8d4c669d6afdcc8c5d1fb1773374bf523874e	buggy:  threadPool.execute(new  Runnable()  {  context:  }  return  null;  }  if  (holder.timeout()  !=  null)  {  holder.timeout().cancel();  }  return  holder.handler();  }              threadPool.execute(new  Runnable()  {              threadPool.cached().execute(new  Runnable()  {  for  (TransportConnectionListener  connectionListener  :  connectionListeners)  {  connectionListener.onNodeConnected(node);  }  }  });  }  	threadPool.cached().execute(new  Runnable()  {  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  context:  });  }  if  (timer.isRunning())  return;  timer.start();  speed  =  -speed;  }  });  }  public  void  render  ()  {  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  gui.update();  }  public  void  surfaceChanged  (int  width,  int  height)  {  gui.setSize();  }  public  void  dispose  ()  {  	Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.SEGMENTS;  }  return   "indices/segments/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_be70722de7754bf61dd87e7811222c84f9b32207	buggy:  .put( "codec.postings_format.test1.type ",   "pulsing40 ")  context:  }  catch  (Exception  e)  {  }  client.admin().indices().prepareCreate( "test ")  .addMapping( "type1 ",  jsonBuilder().startObject().startObject( "type1 ").startObject( "properties ").startObject( "field1 ")  .field( "postings_format ",   "test1 ").field( "index_options ",   "docs ").field( "type ",   "string ").endObject().endObject().endObject().endObject())  .setSettings(ImmutableSettings.settingsBuilder()  .put( "number_of_shards ",  1)  .put( "number_of_replicas ",  0)                          .put( "codec.postings_format.test1.type ",   "pulsing40 ")                          .put( "codec.postings_format.test1.type ",   "pulsing ")  ).execute().actionGet();  client.prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",   "quick  brown  fox ",   "field2 ",   "quick  brown  fox ").execute().actionGet();  client.prepareIndex( "test ",   "type1 ",   "2 ").setSource( "field1 ",   "quick  lazy  huge  brown  fox ",   "field2 ",   "quick  lazy  huge  brown  fox ").setRefresh(true).execute().actionGet();  SearchResponse  searchResponse  =  client.prepareSearch().setQuery( "{  \ "text_phrase\ "  :  {  \ "field2\ "  :  \ "quick  brown\ ",  \ "slop\ "  :  \ "2\ "  }} ").execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(1l));  try  {  	.put( "codec.postings_format.test1.type ",   "pulsing ")  
libgdx_f4d499adcdd0f679153944e2d6fa1b0a09e3d094	buggy:  GdxTest  test  =  new  PixmapTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  PixmapTest();  GdxTest  test  =  new  ProgressiveJPEGTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.r  =  config.g  =  config.b  =  config.a  =  8;  config.width  =  960;  config.height  =  600;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  ProgressiveJPEGTest();  
libgdx_d540b9daf86c19ba458ccb785eb6cbfb76f7ee1e	buggy:  if  (wrap)  return  150;  context:  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  validate();  cache.setPosition(x,  y);  cache.draw(batch,  color.a  *  parentAlpha);  }  public  float  getPrefWidth  ()  {  if  (wrap)  return  150;  if  (wrap)  return  0;  return  bounds.width;  }  public  float  getPrefHeight  ()  {  return  bounds.height  -  style.font.getDescent()  *  2;  }  	if  (wrap)  return  0;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  Map<String,  List<Suggest.Suggestion>>  groupedSuggestions  =  new  HashMap<String,  List<Suggest.Suggestion>>();  context:  protected  ClusterBlockException  checkRequestBlock(ClusterState  state,  SuggestRequest  countRequest,  String[]  concreteIndices)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.READ,  concreteIndices);  }  protected  SuggestResponse  newResponse(SuggestRequest  request,  AtomicReferenceArray  shardsResponses,  ClusterState  clusterState)  {  int  successfulShards  =  0;  int  failedShards  =  0;          final  Map<String,  List<Suggest.Suggestion>>  groupedSuggestions  =  new  HashMap<String,  List<Suggest.Suggestion>>();          final  Map<String,  List<Suggest.Suggestion>>  groupedSuggestions  =  new  HashMap<>();  List<ShardOperationFailedException>  shardFailures  =  null;  for  (int  i  =  0;  i  <  shardsResponses.length();  i++)  {  Object  shardResponse  =  shardsResponses.get(i);  if  (shardResponse  ==  null)  {  }  else  if  (shardResponse  instanceof  BroadcastShardOperationFailedException)  {  failedShards++;  	final  Map<String,  List<Suggest.Suggestion>>  groupedSuggestions  =  new  HashMap<>();  
elasticsearch_3a55998a3b2a733451c647599b5b714ce25ba6e5	buggy:  rootObjectMapper.toJson(builder,  params,  allFieldMapper);  context:  builder.startObject();  toJson(builder,  ToJson.EMPTY_PARAMS);  builder.endObject();  return  builder.string();  }  catch  (Exception  e)  {  throw  new  FailedToGenerateSourceMapperException(e.getMessage(),  e);  }  }          rootObjectMapper.toJson(builder,  params,  allFieldMapper);          rootObjectMapper.toJson(builder,  params,  allFieldMapper,  sourceFieldMapper);  }  }  	rootObjectMapper.toJson(builder,  params,  allFieldMapper,  sourceFieldMapper);  
libgdx_c6ff1cb5fe2f755f5801c3ce80b9078e0d60519f	buggy:  ((JoglInput)((JoglApplication)Gdx.app).getInput()).processEvents();  context:  for  (int  i  =  0;  i  <  app.executedRunnables.size();  i++)  {  try  {  app.executedRunnables.get(i).run();  }  catch(Throwable  t)  {  t.printStackTrace();  }  }  }  ((JoglInput)((JoglApplication)Gdx.app).getInput()).processEvents();  ((JoglInput)(Gdx.input)).processEvents();  listener.render();  ((OpenALAudio)Gdx.audio).update();  }  }  }  public  void  displayChanged  (GLAutoDrawable  arg0,  boolean  arg1,  boolean  arg2)  {  	((JoglInput)(Gdx.input)).processEvents();  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  immutableCluster().wipeIndices(getConcreteIndexName());  context:  public  class  DocumentActionsTests  extends  ElasticsearchIntegrationTest  {  protected  void  createIndex()  {          immutableCluster().wipeIndices(getConcreteIndexName());          cluster().wipeIndices(getConcreteIndexName());  createIndex(getConcreteIndexName());  }  protected  String  getConcreteIndexName()  {  return   "test ";  }  	cluster().wipeIndices(getConcreteIndexName());  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.startObject(indexMetaData.index());  context:  }  builder.field(mappingMd.type());  builder.map(mapping);  }  if  (!foundType)  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  new  TypeMissingException(new  Index(indices[0]),  types.iterator().next())));  return;  }  }  else  {  for  (IndexMetaData  indexMetaData  :  metaData)  {                              builder.startObject(indexMetaData.index());                              builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);  for  (MappingMetaData  mappingMd  :  indexMetaData.mappings().values())  {  if  (!types.isEmpty()  &&  !types.contains(mappingMd.type()))  {  continue;  }  byte[]  mappingSource  =  mappingMd.source().uncompressed();  XContentParser  parser  =  XContentFactory.xContent(mappingSource).createParser(mappingSource);  	builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  tokens  =  new  ArrayList<AnalyzeToken>(size);  context:  builder.endObject();  }  builder.endArray();  return  builder;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  int  size  =  in.readVInt();          tokens  =  new  ArrayList<AnalyzeToken>(size);          tokens  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  tokens.add(AnalyzeToken.readAnalyzeToken(in));  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  	tokens  =  new  ArrayList<>(size);  
libgdx_015764fe472f9b7e2aee8ab616a883ad2996452d	buggy:  }  else  {  context:  });  }  }  });  }  public  void  play  ()  {  if  (track.isPaused())  {  track.setPaused(false);  }  else  {  }  else  if  (!track.isPlaying())  {  track.play();  }  }  public  void  pause  ()  {  if  (track.isPlaying())  {  track.setPaused(true);  	}  else  if  (!track.isPlaying())  {  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));  context:  searchRequest  =  parseSearchRequest(request);  searchRequest.listenerThreaded(false);  SearchOperationThreading  operationThreading  =  SearchOperationThreading.fromString(request.param( "operationThreading "),  SearchOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  SearchOperationThreading.NO_THREADS)  {  operationThreading  =  SearchOperationThreading.SINGLE_THREAD;  }  searchRequest.operationThreading(operationThreading);  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));                  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }  client.execSearch(searchRequest,  new  ActionListener<SearchResponse>()  {  try  {  	channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  
elasticsearch_8d7aaa704a644569359e6a1cddc9e2c10b34da79	buggy:  FileSystemUtils.deleteRecursively(nodeEnv.shardLocation(sId));  context:  try  {  store.close();  }  catch  (IOException  e)  {  }  Injectors.close(injector);  if  (delete  ||  indexGateway.type().equals(NoneGateway.TYPE))  {              FileSystemUtils.deleteRecursively(nodeEnv.shardLocation(sId));              FileSystemUtils.deleteRecursively(nodeEnv.shardLocations(sId));  }  }  }  	FileSystemUtils.deleteRecursively(nodeEnv.shardLocations(sId));  
elasticsearch_2bb31fe74037a7ee2a04c9a994bc4bacbc8e8102	buggy:  return  new  CountResponse(count,  successfulShards,  failedShards,  shardFailures);  context:  failedShards++;  if  (shardFailures  ==  null)  {  shardFailures  =  newArrayList();  }  shardFailures.add(new  DefaultShardOperationFailedException((BroadcastShardOperationFailedException)  shardResponse));  }  else  {  count  +=  ((ShardCountResponse)  shardResponse).count();  successfulShards++;  }  }          return  new  CountResponse(count,  successfulShards,  failedShards,  shardFailures);          return  new  CountResponse(count,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  long  count  =  indexShard.count(request.minScore(),  request.querySource(),  request.queryParserName(),  request.types());  return  new  ShardCountResponse(request.index(),  request.shardId(),  count);  }  }  	return  new  CountResponse(count,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  
libgdx_9fc6bdfc109d68f8778b8400279af5596e3a0c93	buggy:  renderer.vertex(  center.x  +  axis.x  *  radius,  center.y  +  axis.y,  0  );  context:  v.set(  (float)Math.cos(angle)  *  radius  +  center.x,  (float)Math.sin(angle)  *  radius  +  center.y  );  renderer.color(  color.r,  color.g,  color.b,  color.a  );  renderer.vertex(  v.x,  v.y,  0  );  }  renderer.end(  );  renderer.begin(  GL10.GL_LINES  );  renderer.color(  color.r,  color.g,  color.b,  color.a  );  renderer.vertex(  center.x,  center.y,  0  );  renderer.color(  color.r,  color.g,  color.b,  color.a  );  renderer.vertex(  center.x  +  axis.x  *  radius,  center.y  +  axis.y,  0  );  renderer.vertex(  center.x  +  axis.x  *  radius,  center.y  +  axis.y  *  radius,  0  );  renderer.end(  );  }  private  void  drawSolidPolygon(  Vector2[]  vertices,  int  vertexCount,  Color  color  )  {  renderer.begin(  GL10.GL_LINE_LOOP  );  for(  int  i  =  0;  i  <  vertexCount;  i++  )  {  	renderer.vertex(  center.x  +  axis.x  *  radius,  center.y  +  axis.y  *  radius,  0  );  
elasticsearch_ccb30d42e9512c2618880a3cd026d6c6c2e5a253	buggy:  },  retryAfter);  context:  shardStateAction.shardStarted(shardRouting,   "after  recovery  (replica)  from  node  [ "  +  request.sourceNode()  +   "] ");  }  threadPool.schedule(new  Runnable()  {  recoveryTarget.startRecovery(request,  true,  PeerRecoveryListener.this);  }              },  retryAfter);              },  retryAfter,  ThreadPool.ExecutionType.THREADED);  }  if  (!removeShard)  {  return;  }  synchronized  (mutex)  {  if  (indexService.hasShard(shardRouting.shardId().id()))  {  	},  retryAfter,  ThreadPool.ExecutionType.THREADED);  
libgdx_0c6a387f7b0b4f5180014459b3dafaac486d61d4	buggy:  nextIndex  =  currentIndex;  context:  }  }  public  void  remove  ()  {  if  (currentIndex  ==  INDEX_ZERO  &&  set.hasZeroValue)  {  set.hasZeroValue  =  false;  }  else  if  (currentIndex  <  0)  {  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  }  else  if  (currentIndex  >=  set.capacity)  {  set.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  set.keyTable[currentIndex]  =  EMPTY;  }  currentIndex  =  INDEX_ILLEGAL;  set.size--;  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  boolean  resolveRequest(ClusterState  state,  Request  request,  ActionListener<Response>  listener)  {          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  return  true;  }  protected  TransportRequestOptions  transportOptions()  {  return  TransportRequestOptions.EMPTY;  }  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_01ff81fa8964a6a1c40b85d21899759d9642221c	buggy:  logger.info( "Adding  three  nodes  and  performing  rerouting ");  context:  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  .add(indexRoutingTable( "test ").initializeEmpty(metaData.index( "test ")))  .build();  ClusterState  clusterState  =  newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();          logger.info( "Adding  three  nodes  and  performing  rerouting ");          logger.info( "Adding  two  nodes  and  performing  rerouting ");  clusterState  =  newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().put(newNode( "node1 ")).put(newNode( "node2 "))).build();  RoutingTable  prevRoutingTable  =  routingTable;  routingTable  =  strategy.reroute(clusterState);  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  RoutingNodes  routingNodes  =  routingTable.routingNodes(clusterState.metaData());  prevRoutingTable  =  routingTable;  	logger.info( "Adding  two  nodes  and  performing  rerouting ");  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;  context:  }  public  FacetExecutor  parse(String  facetName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {  String  fieldName  =  null;  String  valueFieldName  =  null;  String  valueScript  =  null;  String  scriptLang  =  null;  Map<String,  Object>  params  =  null;  GeoPoint  point  =  new  GeoPoint();          DistanceUnit  unit  =  DistanceUnit.KILOMETERS;          DistanceUnit  unit  =  DistanceUnit.DEFAULT;  GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  List<GeoDistanceFacet.Entry>  entries  =  Lists.newArrayList();  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  XContentParser.Token  token;  String  currentName  =  parser.currentName();  	DistanceUnit  unit  =  DistanceUnit.DEFAULT;  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  .put( "index.engine.robin.refreshInterval ",   "-1 ")  context:  static  long  COUNT  =  SizeValue.parseSizeValue( "1m ").singles();  static  int  CHILD_COUNT  =  5;  static  int  BATCH  =  100;  static  int  QUERY_COUNT  =  50;  static  String  indexName  =   "test ";  static  Random  random  =  new  Random();  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()                  .put( "index.engine.robin.refreshInterval ",   "-1 ")                  .put( "refresh_interval ",   "-1 ")  .put( "gateway.type ",   "local ")  .put(SETTING_NUMBER_OF_SHARDS,  1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)  .build();  String  clusterName  =  ChildSearchAndIndexingBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "node1 "))  .clusterName(clusterName)  	.put( "refresh_interval ",   "-1 ")  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);  context:  CountRequest  countRequest  =  new  CountRequest(RestActions.splitIndices(request.param( "index ")));  countRequest.listenerThreaded(false);  try  {  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);  if  (request.hasContent())  {                  countRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  true);                  countRequest.query(request.content(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  countRequest.query(source);  }  else  {  BytesReference  querySource  =  RestActions.parseQuerySource(request);  if  (querySource  !=  null)  {  countRequest.query(querySource,  false);  	countRequest.query(request.content(),  request.contentUnsafe());  
libgdx_304a52f855f3d24f385976d9fea435d11c6ed05c	buggy:  deps  =  new  Array<AssetDescriptor>();  context:  effect.load(file,  param.imagesDir);  else  effect.load(file,  file.parent());  return  effect;  }  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  file,  ParticleEffectParameter  param)  {  Array<AssetDescriptor>  deps  =  null;  if  (param  !=  null  &&  param.atlasFile  !=  null)  {  deps  =  new  Array<AssetDescriptor>();  deps  =  Array.of(AssetDescriptor.class);  deps.add(new  AssetDescriptor<TextureAtlas>(param.atlasFile,  TextureAtlas.class));  }  return  deps;  }  public  static  class  ParticleEffectParameter  extends  AssetLoaderParameters<ParticleEffect>  {  	deps  =  Array.of(AssetDescriptor.class);  
elasticsearch_1cbeaf6c4579bcab3310e4bacb543622d1859f0e	buggy:  return  new  SignificantLongTerms(subsetSize,  supersetSize,  getName(),  formatter,  requiredSize,  supersetSize,  buckets);  context:  }  public  Type  type()  {  return  TYPE;  }  InternalSignificantTerms  newAggregation(long  subsetSize,  long  supersetSize,  List<InternalSignificantTerms.Bucket>  buckets)  {          return  new  SignificantLongTerms(subsetSize,  supersetSize,  getName(),  formatter,  requiredSize,  supersetSize,  buckets);          return  new  SignificantLongTerms(subsetSize,  supersetSize,  getName(),  formatter,  requiredSize,  minDocCount,  buckets);  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  this.name  =  in.readString();  this.formatter  =  ValueFormatterStreams.readOptional(in);  this.requiredSize  =  readSize(in);  this.minDocCount  =  in.readVLong();  	return  new  SignificantLongTerms(subsetSize,  supersetSize,  getName(),  formatter,  requiredSize,  minDocCount,  buckets);  
libgdx_2c399fd1ca16e0a34e16e78abecea74a867c09b0	buggy:  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  stateTime  >  0.5f)  {  context:  state  =  FIXED;  return;  }  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  controlButton)  &&  state  ==  FIXED  &&  stateTime  >  0.5f)  {  stateTime  =  0;  state  =  CONTROLLED;  return;  }  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  stateTime  >  0.5f)  {  if((Gdx.input.isKeyPressed(Keys.F)  ||  followButton)  &&  stateTime  >  0.5f)  {  stateTime  =  0;  state  =  FOLLOW;  return;  }  boolean  touch0  =  Gdx.input.isTouched(0);  boolean  touch1  =  Gdx.input.isTouched(1);  boolean  left  =  (touch0  &&  x0  <  60)  ||  (touch1  &&  x1  <  60);  	if((Gdx.input.isKeyPressed(Keys.F)  ||  followButton)  &&  stateTime  >  0.5f)  {  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  },  cloudBlobStore.executorService());  context:  listener.onCompleted();  }  catch  (Exception  e)  {  try  {  is.close();  }  catch  (IOException  e1)  {  }  listener.onFailure(e);  }  }          },  cloudBlobStore.executorService());          },  cloudBlobStore.executor());  }  	},  cloudBlobStore.executor());  
elasticsearch_3a7f7664b61696141841a5d7e3166d69c28eab98	buggy:  Document  doc  =  docMapper.parse(json).doc();  context:  public  class  PathMatchDynamicTempalteTests  {  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json ");  DocumentMapper  docMapper  =  MapperTests.newParser().parse(mapping);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json ");          Document  doc  =  docMapper.parse(json).doc();          Document  doc  =  docMapper.parse(json).masterDoc();  Field  f  =  doc.getField( "name ");  assertThat(f.name(),  equalTo( "name "));  assertThat(f.stringValue(),  equalTo( "top_level "));  assertThat(f.isStored(),  equalTo(false));  FieldMappers  fieldMappers  =  docMapper.mappers().fullName( "name ");  assertThat(fieldMappers.mappers().size(),  equalTo(1));  	Document  doc  =  docMapper.parse(json).masterDoc();  
libgdx_e1a970bca924f6d9769efb4f5cdbcb269bf4ee09	buggy:  for  (int  i  =  0;  i  <  planes.length;  i++)  context:  return  true;  }  public  boolean  sphereInFrustumWithoutNearFar  (Vector3  center,  float  radius)  {  for  (int  i  =  0;  i  <  planes.length;  i++)  for  (int  i  =  2;  i  <  planes.length;  i++)  if  (planes[i].distance(center)  <  -radius)  return  false;  return  true;  }  	for  (int  i  =  2;  i  <  planes.length;  i++)  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execCount(countRequest,  new  ActionListener<CountResponse>()  {  context:  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }          client.execCount(countRequest,  new  ActionListener<CountResponse>()  {          client.count(countRequest,  new  ActionListener<CountResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "count ",  response.count());  buildBroadcastShardsHeader(builder,  response);  	client.count(countRequest,  new  ActionListener<CountResponse>()  {  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  this.threadPool  =  threadPool;  this.transportService  =  transportService;  this.clusterService  =  clusterService;  this.metaDataMappingService  =  metaDataMappingService;  transportService.registerHandler(NodeMappingRefreshTransportHandler.ACTION,  new  NodeMappingRefreshTransportHandler());  }  public  void  nodeMappingRefresh(final  NodeMappingRefreshRequest  request)  throws  ElasticSearchException  {  DiscoveryNodes  nodes  =  clusterService.state().nodes();  if  (nodes.localNodeMaster())  {              threadPool.cached().execute(new  Runnable()  {              threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  innerMappingRefresh(request);  }  });  }  else  {  transportService.sendRequest(clusterService.state().nodes().masterNode(),  NodeMappingRefreshTransportHandler.ACTION,  request,  VoidTransportResponseHandler.INSTANCE_SAME);  	threadPool.generic().execute(new  Runnable()  {  
libgdx_2a7e3ba6fd1218a387980584eb134f7d3a4cebe9	buggy:   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-Wl,--kill-at  -shared  -m32 ");  context:  this.cppFlags  =  cppFlags;  this.linkerFlags  =  linkerFlags;  }  public  static  BuildTarget  newDefaultTarget  (BuildTarget.TargetOs  type,  boolean  is64Bit)  {  if  (type  ==  TargetOs.Windows  &&  !is64Bit)  {  return  new  BuildTarget(TargetOs.Windows,  false,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   "i686-w64-mingw32- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-Wl,--kill-at  -shared  -m32 ");   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-Wl,--kill-at  -shared  -m32  -static-libgcc  -static-libstdc++ ");  }  if  (type  ==  TargetOs.Windows  &&  is64Bit)  {  return  new  BuildTarget(TargetOs.Windows,  true,  new  String[]  { "**/*.c "},  new  String[0],  new  String[]  { "**/*.cpp "},  new  String[0],  new  String[0],   "x86_64-w64-mingw32- ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m64 ",   "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m64 ",   "-Wl,--kill-at  -shared  -static-libgcc  -static-libstdc++  -m64 ");  	 "-c  -Wall  -O2  -mfpmath=sse  -msse2  -fmessage-length=0  -m32 ",   "-Wl,--kill-at  -shared  -m32  -static-libgcc  -static-libstdc++ ");  
libgdx_d93adf0eb732287cc79847b4c51890db015e3307	buggy:  .color.set(0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  1f);  context:  4,  5,  6,  5,  6,  7,  //  bottom  0,  2,  4,  4,  6,  2,  //  front  1,  3,  5,  5,  7,  3,  //  back  2,  3,  6,  6,  7,  3,  //  left  0,  1,  4,  4,  5,  1  //  right  });  world.constructors.put( "bar ",  new  Entity.ConstructInfo(barMesh,  0f));  //  mass  =  0:  static  body  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  1f);  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  Entity  bar  =  world.add( "bar ",  0f,  7f,  0f);  bar.color.set(0.75f  +  0.25f  *  (float)Math.random(),  0.75f  +  0.25f  *  (float)Math.random(),  0.75f  +  0.25f  *  (float)Math.random(),  1f);  Entity  box1  =  world.add( "box ",  -4.5f,  6f,  0f);  box1.color.set(0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  1f);  btPoint2PointConstraint  constraint  =  new  btPoint2PointConstraint(bar.body,  box1.body,  Vector3.tmp.set(-5,  -0.5f,  -0.5f),  Vector3.tmp2.set(-0.5f,  0.5f,  -0.5f));  world.dynamicsWorld.addConstraint(constraint,  false);  	.color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  
elasticsearch_1c2f25dd0f45a3281a229d7db54bf3fdefcc7a5f	buggy:  return  new  PlainShardsIterator(allShards,  Math.abs(counter.incrementAndGet()));  context:  for  (IndexShardRoutingTable  shardRoutingTable  :  this)  {  shards.addAll(shardRoutingTable.shardsWithState(states));  }  return  shards;  }  public  ShardsIterator  randomAllShardsIt()  {          return  new  PlainShardsIterator(allShards,  Math.abs(counter.incrementAndGet()));          return  new  PlainShardsIterator(allShards,  counter.incrementAndGet());  }  public  GroupShardsIterator  groupByShardsIt()  {  	return  new  PlainShardsIterator(allShards,  counter.incrementAndGet());  
libgdx_5a33ffe60b1fc64fefd0a17523492763562febd2	buggy:  if  (focusedActor  !=  null)  {  context:  return  true;  }  }  return  false;  }  if  (!touchable)  return  false;  if  (focusedActor  !=  null)  {  if  (focusedActor[pointer]  !=  null)  {  point.x  =  x;  point.y  =  y;  focusedActor[pointer].toLocalCoordinates(point);  focusedActor[pointer].touchUp(point.x,  point.y,  pointer);  return  true;  }  int  len  =  children.size()  -  1;  	if  (focusedActor[pointer]  !=  null)  {  
libgdx_d80c20b5268652ad702aed2ad8221b308582913a	buggy:  .key(Keys.ESCAPE,  false).show(stage,  0.4f);  context:  }  });  iconButton.addListener(new  ChangeListener()  {  public  void  changed  (ChangeEvent  event,  Actor  actor)  {  new  Dialog( "Some  Dialog ",  skin,   "dialog ")  {  protected  void  clicked  (Object  object)  {  }  }.text( "Are  you  enjoying  this  demo? ").button( "Yes ",  true).button( "No ",  false).key(Keys.ENTER,  true)  .key(Keys.ESCAPE,  false).show(stage,  0.4f);  .key(Keys.ESCAPE,  false).show(stage);  }  });  }  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  	.key(Keys.ESCAPE,  false).show(stage);  
elasticsearch_49d84cb47f8f543ce1fb067267d6fafa71f9c479	buggy:  cmp  =  Longs.compare(tmpId,  ids[node]);  context:  ids  =  new  long[1+capacity];  }  protected  int  compare(int  node)  {  final  double  centroid  =  mean(node);  int  cmp  =  Double.compare(tmpCentroid,  centroid);  if  (cmp  ==  0)  {              cmp  =  Longs.compare(tmpId,  ids[node]);              cmp  =  Long.compare(tmpId,  ids[node]);  }  return  cmp;  }  protected  void  copy(int  node)  {  centroids[node]  =  tmpCentroid;  counts[node]  =  tmpCount;  	cmp  =  Long.compare(tmpId,  ids[node]);  
libgdx_1a45313e2a9a5942bfa2689cccd89ee3d4fc88f2	buggy:  String  imageName  =  new  File(imagePath).getName();  context:  }  catch  (IOException  ex)  {  }  }  }  private  void  loadEmitterImages  (FileHandle  imagesDir)  {  for  (int  i  =  0,  n  =  emitters.size();  i  <  n;  i++)  {  ParticleEmitter  emitter  =  emitters.get(i);  String  imagePath  =  emitter.getImagePath();  if  (imagePath  ==  null)  continue;  String  imageName  =  new  File(imagePath).getName();  String  imageName  =  new  File(imagePath.replace('\\',  '/')).getName();  emitter.setTexture(loadTexture(imagesDir.child(imageName)));  }  }  protected  Texture  loadTexture  (FileHandle  file)  {  return  Gdx.graphics.newTexture(file,  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  }  	String  imageName  =  new  File(imagePath.replace('\\',  '/')).getName();  
libgdx_82cc28bc1830b173a6a92b4d3efeb602df97742e	buggy:  mesh.render(  GL10.GL_TRIANGLE_FAN,  0,  4  );  context:  public  void  render(Application  app)  {  GL10  gl  =  app.getGraphics().getGL10();  gl.glViewport(  0,  0,  app.getGraphics().getWidth(),  app.getGraphics().getHeight()  );  gl.glClearColor(  0.7f,  0.7f,  0.7f,  1  );  gl.glClear(  GL10.GL_COLOR_BUFFER_BIT  );  gl.glEnable(GL10.GL_TEXTURE_2D  );  texture.bind();  mesh.render(  GL10.GL_TRIANGLE_FAN,  0,  4  );  mesh.render(  GL10.GL_TRIANGLE_FAN  );  }  public  void  dispose(Application  app)  {  }  	mesh.render(  GL10.GL_TRIANGLE_FAN  );  
libgdx_738e6c3d38a557614447fdcdffd8d2f447e7e2a9	buggy:  System.out.println( "Wrote  target  ' "  +  target.os  +   "- "  +  (target.is64Bit? "64 ": " ")  +   "  build  script  ' "  +  config.jniDir.child( "build.xml ")  +   "' ");  context:  String  buildFile  =  generateBuildTargetTemplate(config,  target);  FileDescriptor  libsDir  =  new  FileDescriptor(getLibsDirectory(config,  target));  if(!libsDir.exists())  {  if(!libsDir.mkdirs())  throw  new  RuntimeException( "Couldn't  create  libs  directory  ' "  +  libsDir  +   "' ");  }  String  buildFileName  =   "build- "  +  target.os.toString().toLowerCase()  +  (target.is64Bit? "64 ": "32 ")  +   ".xml ";  if(target.buildFileName  !=  null)  buildFileName  =  target.buildFileName;  config.jniDir.child(buildFileName).writeString(buildFile,  false);  System.out.println( "Wrote  target  ' "  +  target.os  +   "- "  +  (target.is64Bit? "64 ": " ")  +   "  build  script  ' "  +  config.jniDir.child( "build.xml ")  +   "' ");  System.out.println( "Wrote  target  ' "  +  target.os  +  (target.is64Bit? "64 ": " ")  +   "'  build  script  ' "  +  config.jniDir.child(buildFileName)  +   "' ");  if(!target.excludeFromMasterBuildFile)  {  buildFiles.add(buildFileName);  sharedLibFiles.add(getSharedLibFilename(target.os,  target.is64Bit,  config.sharedLibName));  libsDirs.add( "../ "  +  libsDir.path().replace('\\',  '/'));  }  }  	System.out.println( "Wrote  target  ' "  +  target.os  +  (target.is64Bit? "64 ": " ")  +   "'  build  script  ' "  +  config.jniDir.child(buildFileName)  +   "' ");  
elasticsearch_f14af3599a81f11b5792f6cdb814a046e79eb3f0	buggy:  builder.field( "similariry ",  SimilarityLookupService.DEFAULT_SIMILARITY);  context:  String  format  =  defaultDocValuesFormat();  if  (format  ==  null)  {  format  =  DocValuesFormatService.DEFAULT_FORMAT;  }  builder.field(DOC_VALUES_FORMAT,  format);  }  if  (similarity()  !=  null)  {  builder.field( "similarity ",  similarity().name());  }  else  if  (includeDefaults)  {              builder.field( "similariry ",  SimilarityLookupService.DEFAULT_SIMILARITY);              builder.field( "similarity ",  SimilarityLookupService.DEFAULT_SIMILARITY);  }  if  (customFieldDataSettings  !=  null)  {  builder.field( "fielddata ",  (Map)  customFieldDataSettings.getAsMap());  }  else  if  (includeDefaults)  {  builder.field( "fielddata ",  (Map)  fieldDataType.getSettings().getAsMap());  }  multiFields.toXContent(builder,  params);  	builder.field( "similarity ",  SimilarityLookupService.DEFAULT_SIMILARITY);  
libgdx_0cb1fa427da187297481bfc2fdc4ee59f7512494	buggy:  byte[]  heightMap  =  PerlinNoiseGenerator.generateHeightMap(voxelWorld.voxelsX,  voxelWorld.voxelsZ,  min,  max,  8);  context:  byte  val  =  bytes[i];  pixmap.getPixels().put(idx++,  val);  pixmap.getPixels().put(idx++,  val);  pixmap.getPixels().put(idx++,  val);  pixmap.getPixels().put(idx++,  (byte)255);  }  return  pixmap;  }  public  static  void  generateVoxels(VoxelWorld  voxelWorld,  int  min,  int  max,  int  octaveCount)  {  byte[]  heightMap  =  PerlinNoiseGenerator.generateHeightMap(voxelWorld.voxelsX,  voxelWorld.voxelsZ,  min,  max,  8);  byte[]  heightMap  =  PerlinNoiseGenerator.generateHeightMap(voxelWorld.voxelsX,  voxelWorld.voxelsZ,  min,  max,  octaveCount);  int  idx  =  0;  for(int  z  =  0;  z  <  voxelWorld.voxelsZ;  z++)  {  for(int  x  =  0;  x  <  voxelWorld.voxelsX;  x++)  {  voxelWorld.setColumn(x,  heightMap[idx++],  z,  (byte)1);  }  }  }  	byte[]  heightMap  =  PerlinNoiseGenerator.generateHeightMap(voxelWorld.voxelsX,  voxelWorld.voxelsZ,  min,  max,  octaveCount);  
elasticsearch_46753122aa9610c04e766ded64f3a7261937c78e	buggy:  logger.debug( "Sending  mapping  updated  to  master:  index  [{}]  type  [{}] ",  request.index(),  request.type());  context:  private  void  updateMappingOnMaster(final  IndexRequest  request)  {  final  CountDownLatch  latch  =  new  CountDownLatch(1);  try  {  MapperService  mapperService  =  indicesService.indexServiceSafe(request.index()).mapperService();  final  DocumentMapper  documentMapper  =  mapperService.documentMapper(request.type());  if  (documentMapper  ==  null)  {  //  should  not  happen  return;  }  documentMapper.refreshSource();              logger.debug( "Sending  mapping  updated  to  master:  index  [{}]  type  [{}] ",  request.index(),  request.type());              logger.trace( "Sending  mapping  updated  to  master:  index  [{}]  type  [{}] ",  request.index(),  request.type());  mappingUpdatedAction.execute(new  MappingUpdatedAction.MappingUpdatedRequest(request.index(),  request.type(),  documentMapper.mappingSource()),  new  ActionListener<MappingUpdatedAction.MappingUpdatedResponse>()  {  public  void  onResponse(MappingUpdatedAction.MappingUpdatedResponse  mappingUpdatedResponse)  {  latch.countDown();  }  	logger.trace( "Sending  mapping  updated  to  master:  index  [{}]  type  [{}] ",  request.index(),  request.type());  
elasticsearch_fddb7420ae266378499ac51215ffe040f81ce31a	buggy:  }  catch  (Exception  e)  {  context:  .versionType(request.versionType())  .origin(Engine.Operation.Origin.PRIMARY);  indexShard.create(create);  version  =  create.version();  op  =  create;  created  =  true;  }  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh().force(false));              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  }  }  if  (op.parsedDoc().mappingsModified())  {  updateMappingOnMaster(request);  }  request.version(version);  	}  catch  (Throwable  e)  {  
elasticsearch_ab3be76644157eed6724dfe1f1937ee5f7e93a11	buggy:  +   "  to:   "  +  to  +   ":  target  file  already  exists ");  context:  public  void  renameFile(DirectoryService  directoryService,  String  from,  String  to)  throws  IOException  {  Directory  directory  =  getDirectory(from);  if  (nameDirMapping.putIfAbsent(to,  directory)  !=  null)  {  throw  new  IOException( "Can't  rename  file  from   "  +  from                      +   "  to:   "  +  to  +   ":  target  file  already  exists ");                      +   "  to:   "  +  to  +   "target  file  already  exists ");  }  boolean  success  =  false;  try  {  directoryService.renameFile(directory,  from,  to);  nameDirMapping.remove(from);  success  =  true;  }  finally  {  if  (!success)  {  	+   "  to:   "  +  to  +   "target  file  already  exists ");  
elasticsearch_4938f09d8da4afc14e8aa51288fdd6db8de6aed6	buggy:  throw  new  ElasticSearchParseException(DecayFunctionBuilder.SCALE  +   "must  be  set  for  geo  fields. ");  context:  }  else  {  throw  new  ElasticSearchParseException( "Parameter   "  +  parameterName  +   "  not  supported! ");  }  }  long  origin  =  SearchContext.current().nowInMillis();  if  (originString  !=  null)  {  origin  =  dateFieldMapper.value(originString).longValue();  }  if  (scaleString  ==  null)  {              throw  new  ElasticSearchParseException(DecayFunctionBuilder.SCALE  +   "must  be  set  for  geo  fields. ");              throw  new  ElasticSearchParseException(DecayFunctionBuilder.SCALE  +   "must  be  set  for  date  fields. ");  }  TimeValue  val  =  TimeValue.parseTimeValue(scaleString,  TimeValue.timeValueHours(24));  double  scale  =  val.getMillis();  val  =  TimeValue.parseTimeValue(offsetString,  TimeValue.timeValueHours(24));  double  offset  =  val.getMillis();  IndexNumericFieldData<?>  numericFieldData  =  parseContext.fieldData().getForField(dateFieldMapper);  return  new  NumericFieldDataScoreFunction(origin,  scale,  decay,  offset,  getDecayFunction(),  numericFieldData);  }  	throw  new  ElasticSearchParseException(DecayFunctionBuilder.SCALE  +   "must  be  set  for  date  fields. ");  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  DoubleArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  DoubleArrayAtomicFieldData.WithOrdinals(  values.toArray(new  double[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  DoubleValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_83d15740a7af0ac07f565d102238582cf1f3f4a5	buggy:  return  request.bufferForBody().arrayOffset();  context:  if  (!request.isSetBody())  {  return  Bytes.EMPTY_ARRAY;  }  return  request.bufferForBody().array();  }  if  (!request.isSetBody())  {  return  0;  }          return  request.bufferForBody().arrayOffset();          return  request.bufferForBody().arrayOffset()  +  request.bufferForBody().position();  }  if  (!request.isSetBody())  {  return  0;  }  return  request.bufferForBody().remaining();  }  	return  request.bufferForBody().arrayOffset()  +  request.bufferForBody().position();  
elasticsearch_eb68891ae5538511118a2f095579ff93e17e0c42	buggy:  .loadFromClasspath( "org/elasticsearch/util/settings/loader/test-settings.json ")  context:  public  class  JsonSettingsLoaderTests  {  Settings  settings  =  settingsBuilder()                  .loadFromClasspath( "org/elasticsearch/util/settings/loader/test-settings.json ")                  .loadFromClasspath( "org/elasticsearch/common/settings/loader/test-settings.json ")  .build();  assertThat(settings.get( "test1.value1 "),  equalTo( "value1 "));  assertThat(settings.get( "test1.test2.value2 "),  equalTo( "value2 "));  assertThat(settings.getAsInt( "test1.test2.value3 ",  -1),  equalTo(2));  assertThat(settings.get( "test1.test3.0 "),  equalTo( "test3-1 "));  	.loadFromClasspath( "org/elasticsearch/common/settings/loader/test-settings.json ")  
libgdx_89e261a8466b17dc4ca922a8c0e9cdc39217023a	buggy:  return  new  IOSApplication(new  PingPongSocketExample(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  class  InnerClass  {  }  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  return  new  IOSApplication(new  PingPongSocketExample(),  config);  return  new  IOSApplication(new  BulletTestCollection(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.drain();  }  }  	return  new  IOSApplication(new  BulletTestCollection(),  config);  
libgdx_f0e67a1474fab9528737cc703fde6c35fdd5e288	buggy:  if(len>  bits.length)  {  context:  public  void  flip(int  index)  {  final  int  word  =  index  >>>  6;  checkCapacity(word);  bits[word]  ^=  1L  <<  (index  &  0x3F);  }  private  void  checkCapacity(int  len)  {  if(len>  bits.length)  {  if(len>=bits.length)  {  long[]  newBits  =  new  long[len+1];  System.arraycopy(bits,  0,  newBits,  0,  bits.length);  bits  =  newBits;  }  }  	if(len>=bits.length)  {  
libgdx_f08f4f7b935930bf27a6461e7335d128e5919c1b	buggy:  boolean  handled  =  gui.handleMouse(x,  y,  0,  false);  context:  if  (handled)  lastPressConsumed  =  true;  return  handled;  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer,  int  button)  {  mouseDown  =  false;  if  (ignoreMouse)  {  ignoreMouse  =  false;  return  false;  }  boolean  handled  =  gui.handleMouse(x,  y,  0,  false);  boolean  handled  =  gui.handleMouse(x,  y,  button,  false);  if  (Gdx.app.getType()  ==  ApplicationType.Android)  {  gui.handleMouse(-9999,  -9999,  -1,  false);  }  return  handled;  }  public  boolean  touchDragged  (int  x,  int  y,  int  pointer)  {  	boolean  handled  =  gui.handleMouse(x,  y,  button,  false);  
elasticsearch_2eea99255dbe772007ca9b9367eca2786390d515	buggy:  XContentBuilder  builder  =  restContentBuilder(request);  context:  analyzeRequest.listenerThreaded(false);  analyzeRequest.preferLocal(request.paramAsBoolean( "prefer_local ",  analyzeRequest.preferLocalShard()));  analyzeRequest.analyzer(request.param( "analyzer "));  analyzeRequest.field(request.param( "field "));  analyzeRequest.tokenizer(request.param( "tokenizer "));  analyzeRequest.tokenFilters(request.paramAsStringArray( "token_filters ",  request.paramAsStringArray( "filters ",  null)));  client.admin().indices().analyze(analyzeRequest,  new  ActionListener<AnalyzeResponse>()  {  public  void  onResponse(AnalyzeResponse  response)  {  try  {                      XContentBuilder  builder  =  restContentBuilder(request);                      XContentBuilder  builder  =  restContentBuilder(request,  false);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  	XContentBuilder  builder  =  restContentBuilder(request,  false);  
elasticsearch_473c2fa8f41daac0f8627eb398819ce506b3a144	buggy:  indexShard.start();  context:  }  catch  (Exception  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId,   "failed  to  recover  commit_point  [ "  +  commitPoint.name()  +   "]/[ "  +  commitPoint.version()  +   "] ",  e);  }  }  throw  new  IndexShardGatewayRecoveryException(shardId,   "No  commit  point  data  is  available  in  gateway ",  null);  }  private  void  recoverTranslog(CommitPoint  commitPoint,  ImmutableMap<String,  BlobMetaData>  blobs)  throws  IndexShardGatewayRecoveryException  {  if  (commitPoint.translogFiles().isEmpty())  {              indexShard.start();              indexShard.start( "post  recovery  from  gateway,  no  translog ");  return;  }  try  {  indexShard.performRecoveryPrepareForTranslog();  final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);  	indexShard.start( "post  recovery  from  gateway,  no  translog ");  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  kerning.load(Gdx.files.readFile(ttfFileRef,  FileType.Internal),  font.getSize());  context:  allGlyphs.addAll(page.getGlyphs());  pageIndex++;  }  String  ttfFileRef  =  unicodeFont.getFontFile();  if  (ttfFileRef  ==  null)  else  {  Kerning  kerning  =  new  Kerning();  try  {  kerning.load(Gdx.files.readFile(ttfFileRef,  FileType.Internal),  font.getSize());  kerning.load(Gdx.files.internal(ttfFileRef).read(),  font.getSize());  }  catch  (IOException  ex)  {  }  Map  glyphCodeToCodePoint  =  new  HashMap();  for  (Iterator  iter  =  allGlyphs.iterator();  iter.hasNext();)  {  Glyph  glyph  =  (Glyph)iter.next();  glyphCodeToCodePoint.put(new  Integer(getGlyphCode(font,  glyph.getCodePoint())),  new  Integer(glyph.getCodePoint()));  	kerning.load(Gdx.files.internal(ttfFileRef).read(),  font.getSize());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.multiSearch(multiSearchRequest,  new  ActionListener<MultiSearchResponse>()  {  public  void  onResponse(MultiSearchResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_5e84464aa20fe219c583b8d26e4920e2c52dd53f	buggy:  ((LwjglGraphics)Gdx.graphics).setEnforcePotImages(false);  context:  private  boolean  mouseDown;  private  int  activeCount;  private  int  mouseX,  mouseY;  private  BitmapFont  font;  private  SpriteBatch  spriteBatch;  private  Sprite  bgImage;  //  BOZO  -  Add  setting  background  image  to  UI.  public  void  create  ()  {  if  (spriteBatch  !=  null)  return;  ((LwjglGraphics)Gdx.graphics).setEnforcePotImages(false);  Texture.setEnforcePotImages(false);  spriteBatch  =  new  SpriteBatch();  font  =  new  BitmapFont(Gdx.files.getFileHandle( "default.fnt ",  FileType.Internal),  Gdx.files.getFileHandle( "default.png ",  FileType.Internal),  true);  effectPanel.newEmitter( "Untitled ",  true);  Gdx.input.setInputProcessor(this);  	Texture.setEnforcePotImages(false);  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  return  newPixmap(file.getInputStream());  context:  public  Pixmap  newPixmap  (InputStream  in)  {  try  {  BufferedImage  img  =  (BufferedImage)ImageIO.read(in);  return  new  LwjglPixmap(img);  }  catch  (Exception  ex)  {  throw  new  GdxRuntimeException( "Couldn't  load  Pixmap  from  InputStream ",  ex);  }  }  public  Pixmap  newPixmap  (FileHandle  file)  {  return  newPixmap(file.getInputStream());  return  newPixmap(file.readFile());  }  public  Pixmap  newPixmap  (Object  nativePixmap)  {  return  new  LwjglPixmap((BufferedImage)nativePixmap);  }  private  static  boolean  isPowerOfTwo  (int  value)  {  return  ((value  !=  0)  &&  (value  &  (value  -  1))  ==  0);  	return  newPixmap(file.readFile());  
elasticsearch_33d5a722b332f8a9bacfd3d3b5779494eae3cda7	buggy:  boolean  skip  =  setupSection.getSkipSection().skipVersion(parseContext.getCurrentVersion());  context:  public  class  SetupSectionParser  implements  RestTestFragmentParser<SetupSection>  {  public  SetupSection  parse(RestTestSuiteParseContext  parseContext)  throws  IOException,  RestTestParseException  {  XContentParser  parser  =  parseContext.parser();  SetupSection  setupSection  =  new  SetupSection();  setupSection.setSkipSection(parseContext.parseSkipSection());          boolean  skip  =  setupSection.getSkipSection().skipVersion(parseContext.getCurrentVersion());          boolean  skip  =  setupSection.getSkipSection().skip(parseContext.getCurrentVersion());  while  (parser.currentToken()  !=  XContentParser.Token.END_ARRAY)  {  if  (skip)  {  assert  parser.currentToken()  ==  XContentParser.Token.START_OBJECT;  parser.skipChildren();  	boolean  skip  =  setupSection.getSkipSection().skip(parseContext.getCurrentVersion());  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  ExecutableScript  executable  =  scriptService.executable( "native ",   "my ",  null);  context:  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "script.native.my.type ",  MyNativeScriptFactory.class.getName())  .put( "name ",   "testNativeScript ")  .build();  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ScriptModule(settings)).createInjector();  ScriptService  scriptService  =  injector.getInstance(ScriptService.class);          ExecutableScript  executable  =  scriptService.executable( "native ",   "my ",  null);          ExecutableScript  executable  =  scriptService.executable( "native ",   "my ",  ScriptService.ScriptType.INLINE,  null);  assertThat(executable.run().toString(),  equalTo( "test "));  }  static  class  MyNativeScriptFactory  implements  NativeScriptFactory  {  public  ExecutableScript  newScript(@Nullable  Map<String,  Object>  params)  {  return  new  MyScript();  }  	ExecutableScript  executable  =  scriptService.executable( "native ",   "my ",  ScriptService.ScriptType.INLINE,  null);  
elasticsearch_b02e6dc996d3985a8a136f290c4a8810ce05aaab	buggy:  NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().clear().setPlugin(true).execute().actionGet();  context:  String  server2NodeId  =  startNodeWithPlugins(2);  String  server3NodeId  =  startNodeWithPlugins(3,TestPlugin.class.getName());  String  server4NodeId  =  startNodeWithPlugins(4,TestNoVersionPlugin.class.getName());  ClusterHealthResponse  clusterHealth  =  client().admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();          NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().clear().setPlugin(true).execute().actionGet();          NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().clear().setPlugins(true).execute().actionGet();  assertNodeContainsPlugins(response,  server1NodeId,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  //  No  JVM  Plugin  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST);//  No  Site  Plugin  assertNodeContainsPlugins(response,  server2NodeId,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  Collections.EMPTY_LIST,  //  No  JVM  Plugin  	NodesInfoResponse  response  =  client().admin().cluster().prepareNodesInfo().clear().setPlugins(true).execute().actionGet();  
elasticsearch_490c7103aea457c5afae17f65f0e0ed2f1259e77	buggy:  ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  source.routing(),  source.timestamp(),  source.ttl(),  context.docs(),  context.analyzer(),  context:  if  (field.fieldType().indexed()  &&  !field.fieldType().omitNorms())  {  if  (!encounteredFields.contains(field.name()))  {  ((Field)  field).setBoost(context.docBoost()  *  field.boost());  encounteredFields.add(field.name());  }  }  }  }  }          ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  source.routing(),  source.timestamp(),  source.ttl(),  context.docs(),  context.analyzer(),          ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.version(),  context.id(),  context.type(),  source.routing(),  source.timestamp(),  source.ttl(),  context.docs(),  context.analyzer(),  context.source(),  context.mappingsModified()).parent(source.parent());  context.reset(null,  null,  null,  null);  return  doc;  }  private  void  addFieldMappers(Collection<FieldMapper>  fieldMappers)  {  addFieldMappers(fieldMappers.toArray(new  FieldMapper[fieldMappers.size()]));  	ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.version(),  context.id(),  context.type(),  source.routing(),  source.timestamp(),  source.ttl(),  context.docs(),  context.analyzer(),  
elasticsearch_aff8a4407fdedbb70c90db00710b749245f4806c	buggy:  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "] ");  context:  if  (context.fieldNames().get(0).equals( "* "))  {  return  AllButSourceFieldSelector.INSTANCE;  }  FieldMappersFieldSelector  fieldSelector  =  new  FieldMappersFieldSelector();  for  (String  fieldName  :  context.fieldNames())  {  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);  if  (x  ==  null)  {                  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "] ");                  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "]  in  order  to  load  it ");  }  fieldSelector.add(x);  }  fieldSelector.add(UidFieldMapper.NAME);  return  fieldSelector;  }  }  	throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "]  in  order  to  load  it ");  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  indicesService.cleanIndex(index,   "created  for  alias  processing ");  context:  aliasOperationPerformedAction.add(new  CountDownListener(responseCount,  listener,  version),  request.timeout);  return  updatedState;  }  else  {  listener.onResponse(new  Response(true));  return  currentState;  }  }  finally  {  for  (String  index  :  indicesToClose)  {                          indicesService.cleanIndex(index,   "created  for  alias  processing ");                          indicesService.removeIndex(index,   "created  for  alias  processing ");  }  }  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  }  });  	indicesService.removeIndex(index,   "created  for  alias  processing ");  
libgdx_7feeb8e19ac71d0bd7c836ec3c141c3943b71c51	buggy:  if  (file.getName().startsWith(prefix))  file.delete();  context:  skip  =  true;  }  }  if  (!skip)  {  if  (outputDir.exists())  {  String  prefix  =  inputDir.getName();  for  (File  file  :  outputDir.listFiles())  if  (file.getName().startsWith(prefix))  file.delete();  if  (file.getName().startsWith(prefix)  &&  file.getName().endsWith( ".png "))  file.delete();  }  ArrayList<TextureFilter>  filters  =  new  ArrayList();  filters.add(null);  filters.addAll(Arrays.asList(TextureFilter.values()));  ArrayList<Format>  formats  =  new  ArrayList();  formats.add(null);  	if  (file.getName().startsWith(prefix)  &&  file.getName().endsWith( ".png "))  file.delete();  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());  context:  queryFetchResults.put(result.shardTarget(),  result);  }  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(EMPTY_DOCS,  queryFetchResults,  ImmutableMap.<SearchShardTarget,  FetchSearchResultProvider>of());  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());                  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values(),  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  searchCache.releaseQueryResults(queryFetchResults);  }  }  private  static  ShardDoc[]  EMPTY_DOCS  =  new  ShardDoc[0];  }  	scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values(),  null);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ArrayList<Client>  clientArray  =  new  ArrayList<Client>();  context:  createIndex( "test1 ",   "test2 ");  ensureYellow();  final  Throwable[]  threadException  =  new  Throwable[1];  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);  Thread[]  threads  =  new  Thread[3];  final  CyclicBarrier  barrier  =  new  CyclicBarrier(threads.length);          final  ArrayList<Client>  clientArray  =  new  ArrayList<Client>();          final  ArrayList<Client>  clientArray  =  new  ArrayList<>();  for  (Client  c  :  clients())  {  clientArray.add(c);  }  for  (int  j  =  0;  j  <  threads.length;  j++)  {  threads[j]  =  new  Thread(new  Runnable()  {  	final  ArrayList<Client>  clientArray  =  new  ArrayList<>();  
elasticsearch_4f4471483de7638880e81da935cc4a4a2f7da4bb	buggy:  RoutingNodes  routingNodes  =  routingTable.routingNodes(clusterState.metaData());  context:  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).primaryShard().state(),  equalTo(INITIALIZING));  assertThat(routingTable.index( "test ").shard(0).primaryShard().currentNodeId(),  equalTo( "node1 "));  assertThat(routingTable.index( "test ").shard(0).replicaShards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).replicaShards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).replicaShards().get(0).currentNodeId(),  nullValue());          RoutingNodes  routingNodes  =  routingTable.routingNodes(clusterState.metaData());          RoutingNodes  routingNodes  =  clusterState.routingNodes();  prevRoutingTable  =  routingTable;  routingTable  =  strategy.applyStartedShards(clusterState,  routingNodes.node( "node1 ").shardsWithState(INITIALIZING));  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  assertThat(prevRoutingTable  !=  routingTable,  equalTo(true));  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(2));  	RoutingNodes  routingNodes  =  clusterState.routingNodes();  
elasticsearch_616b09e9b4a650275e3e460c99c9c6556a8c21a0	buggy:  executor  =  EsExecutors.newScalingExecutorService(0,  concurrentConnects,  60,  TimeUnit.SECONDS,  threadFactory);  context:  return  this.id;  }  public  boolean  isClosed()  {  return  this.closed;  }  public  Executor  executor()  {  if  (executor  ==  null)  {  ThreadFactory  threadFactory  =  EsExecutors.daemonThreadFactory(settings,   "[unicast_connect] ");                  executor  =  EsExecutors.newScalingExecutorService(0,  concurrentConnects,  60,  TimeUnit.SECONDS,  threadFactory);                  executor  =  EsExecutors.newScaling(0,  concurrentConnects,  60,  TimeUnit.SECONDS,  threadFactory);  }  return  executor;  }  public  void  close()  {  closed  =  true;  if  (executor  !=  null)  {  executor.shutdownNow();  	executor  =  EsExecutors.newScaling(0,  concurrentConnects,  60,  TimeUnit.SECONDS,  threadFactory);  
libgdx_3065ef5006b71e1369756b451da4c0746ab20b8c	buggy:  for  (int  j  =  0;  j  <  isize;  i++)  context:  int  voffset  =  meshes[0].getNumVertices()  *  vertexSize;  int  ioffset  =  meshes[0].getNumIndices();  for  (int  i  =  1;  i  <  meshes.length;  i++)  {  final  Mesh  mesh  =  meshes[i];  final  int  vsize  =  mesh.getNumVertices()  *  vertexSize;  final  int  isize  =  mesh.getNumIndices();  mesh.getVertices(0,  vsize,  vertices,  voffset);  if  (transformations  !=  null)  transform(transformations[i],  vertices,  vertexSize,  offset,  numComponents,  voffset  /  vertexSize,  vsize  /  vertexSize);  mesh.getIndices(indices,  ioffset);  for  (int  j  =  0;  j  <  isize;  i++)  for  (int  j  =  0;  j  <  isize;  j++)  indices[ioffset+j]  =  (short)(indices[ioffset+j]  +  voffset);  voffset  +=  vsize;  ioffset  +=  isize;  }  final  Mesh  result  =  new  Mesh(isStatic,  vertices.length/vertexSize,  indices.length,  attributes);  result.setVertices(vertices);  result.setIndices(indices);  	for  (int  j  =  0;  j  <  isize;  j++)  
elasticsearch_1d39bb4d51796df342cc41eeb53af0be1f7418bf	buggy:  Store  store  =  new  RamStore(shardId,  settings);  context:  Settings  settings  =  EMPTY_SETTINGS;  Environment  environment  =  new  Environment(settings);  ShardId  shardId  =  new  ShardId( "test ",  1);  AnalysisService  analysisService  =  new  AnalysisService(shardId.index());  MapperService  mapperService  =  new  MapperService(shardId.index(),  settings,  environment,  analysisService);  IndexQueryParserService  queryParserService  =  new  IndexQueryParserService(shardId.index(),  mapperService,  new  IndexCache(shardId.index()),  new  RobinIndexEngine(shardId.index()),  analysisService);  IndexCache  indexCache  =  new  IndexCache(shardId.index());  SnapshotDeletionPolicy  policy  =  new  SnapshotDeletionPolicy(new  KeepOnlyLastDeletionPolicy(shardId,  settings));          Store  store  =  new  RamStore(shardId,  settings);          Store  store  =  new  RamStore(shardId,  settings,  null);  MemoryTranslog  translog  =  new  MemoryTranslog(shardId,  settings);  Engine  engine  =  new  RobinEngine(shardId,  settings,  store,  policy,  translog,  new  LogByteSizeMergePolicyProvider(store),  new  SerialMergeSchedulerProvider(shardId,  settings),  analysisService,  new  SimilarityService(shardId.index()));  threadPool  =  new  ScalingThreadPool();  indexShard  =  new  InternalIndexShard(shardId,  EMPTY_SETTINGS,  store,  engine,  translog,  threadPool,  mapperService,  queryParserService,  indexCache).start();  	Store  store  =  new  RamStore(shardId,  settings,  null);  
elasticsearch_a9e2433dab3ced5de25b8483d56cf293f110d38e	buggy:  MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mapping(request.type());  context:  innerExecute(request,  listener);  }  }  protected  boolean  resolveRequest(final  ClusterState  state,  final  DeleteRequest  request,  final  ActionListener<DeleteResponse>  listener)  {  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));  request.index(state.metaData().concreteIndex(request.index()));  if  (state.metaData().hasIndex(request.index()))  {              MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mapping(request.type());              MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mappingOrDefault(request.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required())  {  if  (request.routing()  ==  null)  {  indexDeleteAction.execute(new  IndexDeleteRequest(request),  new  ActionListener<IndexDeleteResponse>()  {  public  void  onResponse(IndexDeleteResponse  indexDeleteResponse)  {  long  version  =  0;  boolean  found  =  false;  	MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mappingOrDefault(request.type());  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  new  Nested(parentFilter,  childFilter));  context:  }  protected  IndexableField  createField(String  name,  int  value,  Field.Store  store)  {  return  new  FloatField(name,  value,  store);  }  protected  void  assertAvgScoreMode(Filter  parentFilter,  IndexSearcher  searcher,  IndexFieldData.XFieldComparatorSource  innerFieldComparator)  throws  IOException  {  MultiValueMode  sortMode  =  MultiValueMode.AVG;  Filter  childFilter  =  new  NotFilter(parentFilter);          XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  new  Nested(parentFilter,  childFilter));          XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  createNested(parentFilter,  childFilter));  Query  query  =  new  ToParentBlockJoinQuery(new  XFilteredQuery(new  MatchAllDocsQuery(),  childFilter),  new  FixedBitSetCachingWrapperFilter(parentFilter),  ScoreMode.None);  Sort  sort  =  new  Sort(new  SortField( "field2 ",  nestedComparatorSource));  TopDocs  topDocs  =  searcher.search(query,  5,  sort);  assertThat(topDocs.totalHits,  equalTo(7));  assertThat(topDocs.scoreDocs.length,  equalTo(5));  assertThat(topDocs.scoreDocs[0].doc,  equalTo(11));  assertThat(((Number)  ((FieldDoc)  topDocs.scoreDocs[0]).fields[0]).intValue(),  equalTo(2));  assertThat(topDocs.scoreDocs[1].doc,  equalTo(7));  	XFieldComparatorSource  nestedComparatorSource  =  createFieldComparator( "field2 ",  sortMode,  -127,  createNested(parentFilter,  childFilter));  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.byteSizeField(Fields.MEMORY_SIZE,  Fields.MEMORY_SIZE_IN_BYTES,  memorySize);  context:  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeVLong(memorySize);  out.writeVLong(evictions);  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  ToXContent.Params  params)  throws  IOException  {  builder.startObject(Fields.FILTER_CACHE);          builder.byteSizeField(Fields.MEMORY_SIZE,  Fields.MEMORY_SIZE_IN_BYTES,  memorySize);          builder.byteSizeField(Fields.MEMORY_SIZE_IN_BYTES,  Fields.MEMORY_SIZE,  memorySize);  builder.field(Fields.EVICTIONS,  getEvictions());  builder.endObject();  return  builder;  }  static  final  class  Fields  {  static  final  XContentBuilderString  FILTER_CACHE  =  new  XContentBuilderString( "filter_cache ");  static  final  XContentBuilderString  MEMORY_SIZE  =  new  XContentBuilderString( "memory_size ");  	builder.byteSizeField(Fields.MEMORY_SIZE_IN_BYTES,  Fields.MEMORY_SIZE,  memorySize);  
elasticsearch_4b2e4becc7c4541923a87c9be879ee0ce688bf20	buggy:  .startArray( "dynamic_template ")  context:  public  void  testPercolationWithDynamicTemplates()  throws  Exception  {  assertAcked(prepareCreate( "idx ").addMapping( "type ",  jsonBuilder().startObject().startObject( "type ")  .field( "dynamic ",  false)  .startObject( "properties ")  .startObject( "custom ")  .field( "dynamic ",  true)  .field( "type ",   "object ")  .field( "incude_in_all ",  false)  .endObject()  .endObject()                  .startArray( "dynamic_template ")                  .startArray( "dynamic_templates ")  .startObject()  .startObject( "custom_fields ")  .field( "path_match ",   "custom.* ")  .startObject( "mapping ")  .field( "index ",   "not_analyzed ")  .endObject()  .endObject()  .endObject()  	.startArray( "dynamic_templates ")  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  public  SeekStatus  seekCeil(BytesRef  text,  boolean  useCache)  throws  IOException  {  context:  }  }  }  public  Comparator<BytesRef>  getComparator()  {  return  BytesRef.getUTF8SortedAsUnicodeComparator();  }                      public  SeekStatus  seekCeil(BytesRef  text,  boolean  useCache)  throws  IOException  {                      public  SeekStatus  seekCeil(BytesRef  text)  throws  IOException  {  throw  new  UnsupportedOperationException();  }  public  void  seekExact(long  ord)  throws  IOException  {  throw  new  UnsupportedOperationException( "Seek  is  not  supported ");  }  	public  SeekStatus  seekCeil(BytesRef  text)  throws  IOException  {  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterStateRequest  clusterStateRequest  =  Requests.clusterState()  context:  super(settings,  client);  controller.registerHandler(GET,   "/_mapping ",  this);  controller.registerHandler(GET,   "/{index}/_mapping ",  this);  controller.registerHandler(GET,   "/{index}/{type}/_mapping ",  this);  }  final  String[]  indices  =  splitIndices(request.param( "index "));  final  Set<String>  types  =  ImmutableSet.copyOf(splitTypes(request.param( "type ")));          ClusterStateRequest  clusterStateRequest  =  Requests.clusterState()          ClusterStateRequest  clusterStateRequest  =  Requests.clusterStateRequest()  .filterRoutingTable(true)  .filterNodes(true)  .filteredIndices(indices);  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  try  {  MetaData  metaData  =  response.state().metaData();  	ClusterStateRequest  clusterStateRequest  =  Requests.clusterStateRequest()  
libgdx_8480b29e196d01a0b772edceea1dc31ab14e4988	buggy:  if  (knownType  ==  null)  knownType  =  OrderedMap.class;  context:  writeObjectStart(actualType,  knownType);  for  (Entry  entry  :  ((ObjectMap<?,  ?>)value).entries())  {  writer.name(convertToString(entry.key));  writeValue(entry.value,  elementType,  null);  }  writeObjectEnd();  return;  }  if  (value  instanceof  Map)  {  if  (knownType  ==  null)  knownType  =  OrderedMap.class;  if  (knownType  ==  null)  knownType  =  HashMap.class;  writeObjectStart(actualType,  knownType);  for  (Map.Entry  entry  :  ((Map<?,  ?>)value).entrySet())  {  writer.name(convertToString(entry.getKey()));  writeValue(entry.getValue(),  elementType,  null);  }  writeObjectEnd();  return;  }  	if  (knownType  ==  null)  knownType  =  HashMap.class;  
elasticsearch_8aeb589a42d9f742161dde05be755c3f5d58e01a	buggy:  void  onValue(String  value,  int  docId);  context:  public  abstract  void  forEachValue(StringValueProc  proc);  public  static  interface  StringValueProc  {  void  onValue(String  value,  int  freq);  }  public  abstract  void  forEachValueInDoc(int  docId,  StringValueInDocProc  proc);  public  static  interface  StringValueInDocProc  {          void  onValue(String  value,  int  docId);          void  onValue(int  docId,  String  value);  }  public  abstract  Type  type();  public  FieldDataOptions  options()  {  	void  onValue(int  docId,  String  value);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.searchScroll(searchScrollRequest,  new  ActionListener<SearchResponse>()  {  public  void  onResponse(SearchResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  response.status(),  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  index.equals(matches[i].getIndex().string());  context:  .execute().actionGet();  assertMatchCount(response,  0l);  }  public  static  String[]  convertFromTextArray(PercolateResponse.Match[]  matches,  String  index)  {  if  (matches.length  ==  0)  {  return  Strings.EMPTY_ARRAY;  }  String[]  strings  =  new  String[matches.length];  for  (int  i  =  0;  i  <  matches.length;  i++)  {              assert  index.equals(matches[i].getIndex().string());              assertEquals(index,  matches[i].getIndex().string());  strings[i]  =  matches[i].getId().string();  }  return  strings;  }  }  	assertEquals(index,  matches[i].getIndex().string());  
libgdx_76b37870539ba3ef57487269afe9b739149c726b	buggy:  effect.start();  context:  super(initialCapacity,  max);  this.effect  =  effect;  }  protected  PooledEffect  newObject  ()  {  return  new  PooledEffect(effect);  }  public  PooledEffect  obtain  ()  {  PooledEffect  effect  =  super.obtain();  effect.start();  effect.reset();  return  effect;  }  public  class  PooledEffect  extends  ParticleEffect  {  PooledEffect  (ParticleEffect  effect)  {  super(effect);  }  	effect.reset();  
libgdx_c5edc0976145a61a5551053dfda8a8c3394100ee	buggy:  Preferences  prefs  =  new  LwjglPreferences(name);  context:  return  getJavaHeap();  }  Map<String,  Preferences>  preferences  =  new  HashMap<String,  Preferences>();  public  Preferences  getPreferences  (String  name)  {  if  (preferences.containsKey(name))  {  return  preferences.get(name);  }  else  {  Preferences  prefs  =  new  LwjglPreferences(name);  Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  preferences.put(name,  prefs);  return  prefs;  }  }  public  Clipboard  getClipboard  ()  {  return  new  LwjglClipboard();  	Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper()  !=  null  &&  docMapper.parentFieldMapper().fieldType().stored())  {  context:  if  (gFields  !=  null  &&  gFields.length  >  0)  {  Map<String,  Object>  sourceAsMap  =  null;  for  (String  field  :  gFields)  {  if  (SourceFieldMapper.NAME.equals(field))  {  continue;  }  Object  value  =  null;  if  (field.equals(RoutingFieldMapper.NAME)  &&  docMapper.routingFieldMapper().fieldType().stored())  {  value  =  source.routing;                          }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper()  !=  null  &&  docMapper.parentFieldMapper().fieldType().stored())  {                          }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper().active()  &&  docMapper.parentFieldMapper().fieldType().stored())  {  value  =  source.parent;  }  else  if  (field.equals(TimestampFieldMapper.NAME)  &&  docMapper.timestampFieldMapper().fieldType().stored())  {  value  =  source.timestamp;  }  else  if  (field.equals(TTLFieldMapper.NAME)  &&  docMapper.TTLFieldMapper().fieldType().stored())  {  if  (source.ttl  >  0)  {  value  =  docMapper.TTLFieldMapper().valueForSearch(source.timestamp  +  source.ttl);  }  	}  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper().active()  &&  docMapper.parentFieldMapper().fieldType().stored())  {  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  highlighter  =  new  CustomPostingsHighlighter(passageFormatter,  values,  true,  Integer.MAX_VALUE  -  1,  atLeast(1));  context:  List<Object>  values  =  new  ArrayList<Object>();  values.add(firstValue);  BytesRef[]  filteredQueryTerms  =  filterTerms(queryTerms,   "body ",  true);  CustomPassageFormatter  passageFormatter  =  new  CustomPassageFormatter( "<b> ",   "</b> ",  new  DefaultEncoder());  CustomPostingsHighlighter  highlighter  =  new  CustomPostingsHighlighter(passageFormatter,  values,  true,  Integer.MAX_VALUE  -  1,  0);  Snippet[]  snippets  =  highlighter.highlightDoc( "body ",  filteredQueryTerms,  searcher,  docId,  5);  assertThat(snippets.length,  equalTo(0));          highlighter  =  new  CustomPostingsHighlighter(passageFormatter,  values,  true,  Integer.MAX_VALUE  -  1,  atLeast(1));          highlighter  =  new  CustomPostingsHighlighter(passageFormatter,  values,  true,  Integer.MAX_VALUE  -  1,  scaledRandomIntBetween(1,  10));  snippets  =  highlighter.highlightDoc( "body ",  filteredQueryTerms,  searcher,  docId,  5);  assertThat(snippets.length,  equalTo(1));  assertThat(snippets[0].getText(),  equalTo( "This  is  a  test. "));  ir.close();  dir.close();  }  	highlighter  =  new  CustomPostingsHighlighter(passageFormatter,  values,  true,  Integer.MAX_VALUE  -  1,  scaledRandomIntBetween(1,  10));  
libgdx_d167f7a5213f16d3588eb5688cf2e95b7f749391	buggy:  int  lastFrameNumber  =  (int)  ((stateTime  -  (stateTime  -  lastStateTime))  /  frameDuration);  context:  frameNumber  =  Math.min(keyFrames.length  -  1,  frameNumber);  break;  case  LOOP:  frameNumber  =  frameNumber  %  keyFrames.length;  break;  case  LOOP_PINGPONG:  frameNumber  =  frameNumber  %  ((keyFrames.length  *  2)  -  2);  if  (frameNumber  >=  keyFrames.length)  frameNumber  =  keyFrames.length  -  2  -  (frameNumber  -  keyFrames.length);  break;  case  LOOP_RANDOM:  int  lastFrameNumber  =  (int)  ((stateTime  -  (stateTime  -  lastStateTime))  /  frameDuration);  int  lastFrameNumber  =  (int)  ((lastStateTime)  /  frameDuration);  if  (lastFrameNumber  !=  frameNumber)  {  frameNumber  =  MathUtils.random(keyFrames.length  -  1);  }  else  {  frameNumber  =  this.lastFrameNumber;  }  break;  case  REVERSED:  frameNumber  =  Math.max(keyFrames.length  -  frameNumber  -  1,  0);  	int  lastFrameNumber  =  (int)  ((lastStateTime)  /  frameDuration);  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "precisionStep ",  precisionStep);  context:  return  text  ==  null;  }  super.doJsonBody(builder);          builder.field( "precisionStep ",  precisionStep);          builder.field( "precision_step ",  precisionStep);  }  	builder.field( "precision_step ",  precisionStep);  
elasticsearch_45956a5a270c4956755e43ebd9142705f367a196	buggy:  return  cacheValue.value();  context:  LongsLAB  longsLAB  =  null;  if  (cache.labEnabled)  {  longsLAB  =  new  LongsLAB(cache.labChunkSizeBytes,  cache.labMaxAllocBytes);  }  DocIdSet  docIdSet  =  filter.getDocIdSet(reader);  DocSet  docSet  =  FilterCacheValue.cacheable(reader,  longsLAB,  docIdSet);  cacheValue  =  new  FilterCacheValue<DocSet>(docSet,  longsLAB);  innerCache.putIfAbsent(cacheKey,  cacheValue);  }              return  cacheValue.value();              return  cacheValue.value()  ==  DocSet.EMPTY_DOC_SET  ?  null  :  cacheValue.value();  }  public  String  toString()  {  return   "FilterCacheFilterWrapper( "  +  filter  +   ") ";  }  public  boolean  equals(Object  o)  {  if  (!(o  instanceof  FilterCacheFilterWrapper))  return  false;  	return  cacheValue.value()  ==  DocSet.EMPTY_DOC_SET  ?  null  :  cacheValue.value();  
elasticsearch_3479f2a98151c7f1927758a62034f45ef4d58032	buggy:  throw  new  IllegalArgumentException( "df  for  term   "  +  term.text()  +   "  not  available ");  context:  if  (dfs.maxDoc()  >  Integer.MAX_VALUE)  {  maxDoc  =  Integer.MAX_VALUE;  }  else  {  maxDoc  =  (int)  dfs.maxDoc();  }  }  public  int  docFreq(Term  term)  {  int  df  =  dfs.dfMap().get(term);  if  (df  ==  -1)  {              throw  new  IllegalArgumentException( "df  for  term   "  +  term.text()  +   "  not  available ");              throw  new  IllegalArgumentException( "df  for  term   "  +  term  +   "  not  available ");  }  return  df;  }  public  int[]  docFreqs(Term[]  terms)  {  int[]  result  =  new  int[terms.length];  for  (int  i  =  0;  i  <  terms.length;  i++)  {  result[i]  =  docFreq(terms[i]);  	throw  new  IllegalArgumentException( "df  for  term   "  +  term  +   "  not  available ");  
libgdx_e2d8370eaf12f29bcf3365ad5e46ed2df382982f	buggy:  System.out.println( "up ");  context:  actor.setBounds(15,  15,  100,  100);  actor.setOrigin(50,  50);  stage.addActor(actor);  actor.addListener(new  ActorListener()  {  public  boolean  touchDown  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  return  true;  }  public  void  touchUp  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  System.out.println( "up ");  System.out.println( "up   "  +  event.getTarget());  }  });  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  TextButtonStyle  style  =  skin.getStyle(TextButtonStyle.class);  style.up  =  new  EmptyDrawable()  {  ShapeRenderer  renderer  =  new  ShapeRenderer();  	System.out.println( "up   "  +  event.getTarget());  
libgdx_21f035ca9203af80f1b5382eb7a9504ff89e96f6	buggy:  GdxTest  test  =  new  AlphaTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  AlphaTest();  GdxTest  test  =  new  AssetManagerTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  AssetManagerTest();  
libgdx_54664a1fef88fd0aeaffcdd12871aed7f369a53f	buggy:  if  (alphaRaster  ==  null  ||  !settings.stripWhitespace)  context:  }  }  return  images.isEmpty()  ?  -1  :  usedPixels;  }  private  Image  squeeze  (BufferedImage  source,  String  name)  {  if  (source  ==  null)  return  null;  if  (!filter.accept(source))  return  null;  uncompressedSize  +=  source.getWidth()  *  source.getHeight();  WritableRaster  alphaRaster  =  source.getAlphaRaster();  if  (alphaRaster  ==  null  ||  !settings.stripWhitespace)  if  (alphaRaster  ==  null  ||  !settings.stripWhitespace  ||  name.contains( "_ws "))  return  new  Image(name,  source,  0,  0,  source.getWidth(),  source.getHeight());  final  byte[]  a  =  new  byte[1];  int  top  =  0;  int  bottom  =  source.getHeight();  if  (!filter.direction.isY())  {  outer:  for  (int  y  =  0;  y  <  source.getHeight();  y++)  {  for  (int  x  =  0;  x  <  source.getWidth();  x++)  {  alphaRaster.getDataElements(x,  y,  a);  	if  (alphaRaster  ==  null  ||  !settings.stripWhitespace  ||  name.contains( "_ws "))  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  IndexWriterConfig  conf  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  new  KeywordAnalyzer());  //  use  keyword  analyzer  we  rely  on  the  stored  field  holding  the  exact  term.  context:  public  void  setUp()  throws  Exception  {  super.setUp();  referenceAll  =  Maps.newHashMap();  referenceNotDeleted  =  Maps.newHashMap();  referenceFilter  =  Maps.newHashMap();  Directory  dir  =  newDirectory();          IndexWriterConfig  conf  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  new  KeywordAnalyzer());  //  use  keyword  analyzer  we  rely  on  the  stored  field  holding  the  exact  term.          IndexWriterConfig  conf  =  newIndexWriterConfig(new  KeywordAnalyzer());  //  use  keyword  analyzer  we  rely  on  the  stored  field  holding  the  exact  term.  if  (frequently())  {  conf.setMergePolicy(NoMergePolicy.INSTANCE);  }  iw  =  new  IndexWriter(dir,  conf);  terms  =  new  String[scaledRandomIntBetween(10,  300)];  for  (int  i  =  0;  i  <  terms.length;  i++)  {  	IndexWriterConfig  conf  =  newIndexWriterConfig(new  KeywordAnalyzer());  //  use  keyword  analyzer  we  rely  on  the  stored  field  holding  the  exact  term.  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "queryExecution ",  queryExecution);  context:  if  (queryExecution  ==  null  &&  queryFacets  ==  null)  {  return;  }  builder.field( "facets ");  builder.startObject();  if  (queryExecution  !=  null)  {              builder.field( "queryExecution ",  queryExecution);              builder.field( "query_execution ",  queryExecution);  }  if  (queryFacets  !=  null)  {  for  (FacetQuery  facetQuery  :  queryFacets)  {  builder.startObject(facetQuery.name());  builder.field( "query ");  facetQuery.queryBuilder().toJson(builder,  params);  if  (facetQuery.global()  !=  null)  {  builder.field( "global ",  facetQuery.global());  	builder.field( "query_execution ",  queryExecution);  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.startObject(indexDeleteByQueryResponse.index());  context:  return;  }  client.deleteByQuery(deleteByQueryRequest,  new  ActionListener<DeleteByQueryResponse>()  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject().field( "ok ",  true);  builder.startObject( "_indices ");  for  (IndexDeleteByQueryResponse  indexDeleteByQueryResponse  :  result.indices().values())  {                          builder.startObject(indexDeleteByQueryResponse.index());                          builder.startObject(indexDeleteByQueryResponse.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.startObject( "_shards ");  builder.field( "total ",  indexDeleteByQueryResponse.totalShards());  builder.field( "successful ",  indexDeleteByQueryResponse.successfulShards());  builder.field( "failed ",  indexDeleteByQueryResponse.failedShards());  builder.endObject();  builder.endObject();  	builder.startObject(indexDeleteByQueryResponse.index(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_aec720218d0b685c60a2c31c2c766dda7da23c2b	buggy:  return  new  InternalHistogramFacet(facetName,  fieldName,  fieldName,  interval,  comparatorType,  histoProc.counts(),  histoProc.totals());  context:  fieldData.forEachValueInDoc(doc,  histoProc);  }  fieldData  =  (NumericFieldData)  fieldDataCache.cache(fieldDataType,  reader,  indexFieldName);  valueScript.setNextReader(reader);  }          return  new  InternalHistogramFacet(facetName,  fieldName,  fieldName,  interval,  comparatorType,  histoProc.counts(),  histoProc.totals());          return  new  InternalCountAndTotalHistogramFacet(facetName,  fieldName,  fieldName,  interval,  comparatorType,  histoProc.counts(),  histoProc.totals());  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  public  static  class  HistogramProc  implements  NumericFieldData.DoubleValueInDocProc  {  	return  new  InternalCountAndTotalHistogramFacet(facetName,  fieldName,  fieldName,  interval,  comparatorType,  histoProc.counts(),  histoProc.totals());  
libgdx_db3b817cbcd5c9551fdfbb99567b754e336018be	buggy:  return  (float)(track.getCurrentTime()  *  1000.0);  context:  public  void  setVolume  (float  volume)  {  track.setVolume(volume);  }  public  void  setPosition  (float  position)  {  track.setCurrentTime(position  /  1000);  }  public  float  getPosition  ()  {  return  (float)(track.getCurrentTime()  *  1000.0);  return  (float)(track.getCurrentTime());  }  public  void  dispose  ()  {  track.clear();  }  	return  (float)(track.getCurrentTime());  
elasticsearch_f301138e6f087b77fde342ac2e60849156422311	buggy:  int  BATCH  =  1000;  context:  Node  client  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "client ")).client(true).node();  Client  client1  =  client.client();  Thread.sleep(1000);  client1.admin().indices().create(createIndexRequest( "test ")).actionGet();  Thread.sleep(5000);  StopWatch  stopWatch  =  new  StopWatch().start();  int  COUNT  =  200000;          int  BATCH  =  1000;          int  BATCH  =  100;  int  ITERS  =  COUNT  /  BATCH;  int  i  =  1;  int  counter  =  0;  for  (;  i  <=  ITERS;  i++)  {  BulkRequestBuilder  request  =  client1.prepareBulk();  for  (int  j  =  0;  j  <  BATCH;  j++)  {  counter++;  	int  BATCH  =  100;  
libgdx_f4df2bef2344745c127e9be9fc6610282a01e5bd	buggy:  for  (JsonValue  value  =  indices.child();  value  !=  null;  value  =  value.next(),  j++)  {  context:  String  type  =  meshPart.getString( "type ",  null);  if(type  ==  null)  {  throw  new  GdxRuntimeException( "No  primitive  type  given  for  mesh  part  ' "  +  partId  +   "' ");  }  jsonPart.primitiveType  =  parseType(type);  JsonValue  indices  =  meshPart.require( "indices ");  short[]  partIndices  =  new  short[indices.size()];  int  k  =  0;  for  (JsonValue  value  =  indices.child();  value  !=  null;  value  =  value.next(),  j++)  {  for  (JsonValue  value  =  indices.child();  value  !=  null;  value  =  value.next(),  k++)  {  partIndices[k]  =  (short)indices.getInt(k);  }  jsonPart.indices  =  partIndices;  parts.add(jsonPart);  }  jsonMesh.parts  =  parts.toArray(ModelMeshPart.class);  model.meshes.add(jsonMesh);  }  	for  (JsonValue  value  =  indices.child();  value  !=  null;  value  =  value.next(),  k++)  {  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  public  class  TransportIndicesExistsAction  extends  TransportMasterNodeOperationAction<IndicesExistsRequest,  IndicesExistsResponse>  {  ThreadPool  threadPool)  {  super(settings,  transportService,  clusterService,  threadPool);  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.EXISTS;  }  return  new  IndicesExistsRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_3d84af2a4045c7c8cf84dbf20de2a7c452868e54	buggy:  RandomAccessFile  raf  =  null;  context:  public  class  FsImmutableBlobContainer  extends  AbstractFsBlobContainer  implements  ImmutableBlobContainer  {  public  FsImmutableBlobContainer(FsBlobStore  blobStore,  BlobPath  blobPath,  File  path)  {  super(blobStore,  blobPath,  path);  }  blobStore.executorService().execute(new  Runnable()  {  File  file  =  new  File(path,  blobName);                  RandomAccessFile  raf  =  null;                  RandomAccessFile  raf;  try  {  raf  =  new  RandomAccessFile(file,   "rw ");  }  catch  (FileNotFoundException  e)  {  listener.onFailure(e);  return;  }  try  {  try  {  	RandomAccessFile  raf;  
libgdx_015764fe472f9b7e2aee8ab616a883ad2996452d	buggy:  int  result  =  (int)type;  context:  copyFrom  ==  null  ?  GL20.GL_ONE_MINUS_SRC_ALPHA  :  copyFrom.destFunction,  copyFrom  ==  null  ?  1.f  :  copyFrom.opacity);  }  public  BlendingAttribute  copy  ()  {  return  new  BlendingAttribute(this);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  947  *  result  +  (blended  ?  1  :  0);  result  =  947  *  result  +  sourceFunction;  result  =  947  *  result  +  destFunction;  result  =  947  *  result  +  NumberUtils.floatToRawIntBits(opacity);  return  result;  }  }  	int  result  =  super.hashCode();  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Float.NaN;  context:  this.nullValueAsString  =  nullValue  ==  null  ?  null  :  nullValue.toString();  }  return  32;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Float.NaN;              return  null;  }  return  Numbers.bytesToFloat(value);  }  return  indexedValue(Float.parseFloat(value));  }  	return  null;  
libgdx_98712ec99d26ab9fe158cc1ab3b7deeb4f22fa90	buggy:  cube  =  ModelLoaderOld.loadObj(Gdx.files.internal( "data/cube.obj ").read());  context:  }  public  void  setupScene()  {  plane  =  new  Mesh(true,  4,  6,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(Usage.Normal,  3,   "a_Normal "));  plane.setVertices(new  float[]  {  -10,  -1,  10,  0,  1,  0,  10,  -1,  10,  0,  1,  0,  10,  -1,  -10,  0,  1,  0,  10,  -1,  -10,  0,  1,  0  });  plane.setIndices(new  short[]  {  3,  2,  1,  1,  0,  3  });  cube  =  ModelLoaderOld.loadObj(Gdx.files.internal( "data/cube.obj ").read());  cube  =  ModelLoaderOld.loadObj(Gdx.files.internal( "data/sphere.obj ").read());  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  Format.RGB565,  true);  texture.setFilter(TextureFilter.MipMap,  TextureFilter.Nearest);  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(0,  5,  10);  cam.lookAt(0,  0,  0);  cam.update();  controller  =  new  PerspectiveCamController(cam);  	cube  =  ModelLoaderOld.loadObj(Gdx.files.internal( "data/sphere.obj ").read());  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  null,  indexShard.searcher(),  indexService,  indexShard,  context:  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  boolean  valid;  String  explanation  =  null;  String  error  =  null;  if  (request.querySource().length()  ==  0)  {  valid  =  true;  }  else  {  SearchContext.setCurrent(new  DefaultSearchContext(0,  new  ShardSearchRequest().types(request.types()),                      null,  indexShard.searcher(),  indexService,  indexShard,                      null,  indexShard.acquireSearcher(),  indexService,  indexShard,  scriptService,  cacheRecycler));  try  {  ParsedQuery  parsedQuery  =  queryParserService.parse(request.querySource());  valid  =  true;  if  (request.explain())  {  explanation  =  parsedQuery.query().toString();  }  }  catch  (QueryParsingException  e)  {  	null,  indexShard.acquireSearcher(),  indexService,  indexShard,  
libgdx_464f6caf86eb77fba0db4b2c46eec0a22108e8bd	buggy:  cam.getPosition().set(WIDTH*32/2,  HEIGHT/2,0);  context:  SpriteCache[]  caches  =  new  SpriteCache[LAYERS];  Texture  texture;  int[]  layers  =  new  int[LAYERS];  OrthographicCamera  cam;  long  startTime  =  System.nanoTime();  public  void  create()  {  cam  =  new  OrthographicCamera();  cam.setViewport(480,  320);  cam.getPosition().set(WIDTH*32/2,  HEIGHT/2,0);  cam.getPosition().set(WIDTH*32/2,  HEIGHT*32/2,0);  texture  =  Gdx.graphics.newTexture(Gdx.files.internal( "data/tiles.png "),  TextureFilter.Nearest,  TextureFilter.Nearest,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  for(int  i  =  0;  i  <  LAYERS;  i++)  {  caches[i]  =  new  SpriteCache();  SpriteCache  cache  =  caches[i];  cache.beginCache();  for(int  y  =  0;  y  <  HEIGHT;  y++)  {  for(int  x  =  0;  x  <  WIDTH;  x++)  {  	cam.getPosition().set(WIDTH*32/2,  HEIGHT*32/2,0);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  cluster().startNodesAsync(settings,  ImmutableSettings.EMPTY).get();  context:  public  class  DedicatedMasterGetFieldMappingTests  extends  SimpleGetFieldMappingsTests  {  public  void  before1()  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "node.data ",  false)  .build();          cluster().startNodesAsync(settings,  ImmutableSettings.EMPTY).get();          internalCluster().startNodesAsync(settings,  ImmutableSettings.EMPTY).get();  }  }  	internalCluster().startNodesAsync(settings,  ImmutableSettings.EMPTY).get();  
elasticsearch_0b09fd0806364c0785fc649b6483f00fb8e8ebf4	buggy:  return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  context:  }  }  count++;  }          return  new  InternalStringTermsFacet(facetName,   "_index ",  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);          return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  }  }  	return  new  InternalStringTermsFacet(facetName,  comparatorType,  size,  Sets.newHashSet(new  InternalStringTermsFacet.StringEntry(indexName,  count)),  0);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  mltRequest.searchIndices(request.paramAsStringArray( "search_indices ",  null));  mltRequest.searchTypes(request.paramAsStringArray( "search_types ",  null));  mltRequest.searchQueryHint(request.param( "search_query_hint "));  mltRequest.searchSize(request.paramAsInt( "search_size ",  mltRequest.searchSize()));  mltRequest.searchFrom(request.paramAsInt( "search_from ",  mltRequest.searchFrom()));  String  searchScroll  =  request.param( "search_scroll ");  if  (searchScroll  !=  null)  {  mltRequest.searchScroll(new  Scroll(parseTimeValue(searchScroll,  null)));  }  if  (request.hasContent())  {                  mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());                  mltRequest.searchSource(request.content(),  request.contentUnsafe());  }  else  {  String  searchSource  =  request.param( "search_source ");  if  (searchSource  !=  null)  {  mltRequest.searchSource(searchSource);  }  }  }  catch  (Exception  e)  {  try  {  	mltRequest.searchSource(request.content(),  request.contentUnsafe());  
libgdx_ebfd2fac3157b88107476429145ed8aaa4208452	buggy:  cache.setColor(Color.BLUE,  1,  4);  context:  private  void  renderSingleLineCached  ()  {  String  text  =   "Single  Line  Cached ";  float  x  =  logoSprite.getX();  float  y  =  logoSprite.getY();  float  width  =  logoSprite.getWidth();  float  height  =  logoSprite.getHeight();  TextBounds  bounds  =  cache.setMultiLineText(text,  0,  0);  cache.setColor(Color.BLUE,  1,  4);  cache.setColors(Color.BLUE,  1,  4);  x  +=  width  /  2  -  bounds.width  /  2;  y  +=  height  /  2  +  bounds.height  /  2;  cache.setPosition(x,  y);  cache.draw(spriteBatch);  }  	cache.setColors(Color.BLUE,  1,  4);  
libgdx_57b5b0ba39a8ba0973c3be636374bc814d32f04a	buggy:  if  (glyph  ==  null)  continue;  context:  private  void  setGlyph  (int  ch,  Glyph  glyph)  {  Glyph[]  page  =  glyphs[ch  /  PAGE_SIZE];  if  (page  ==  null)  glyphs[ch  /  PAGE_SIZE]  =  page  =  new  Glyph[PAGE_SIZE];  page[ch  &  PAGE_SIZE  -  1]  =  glyph;  }  private  Glyph  getFirstGlyph  ()  {  for  (Glyph[]  page  :  this.glyphs)  {  if  (page  ==  null)  continue;  for  (Glyph  glyph  :  page)  {  if  (glyph  ==  null)  continue;  if  (glyph  ==  null  ||  glyph.height  ==  0  ||  glyph.width  ==  0)  continue;  return  glyph;  }  }  throw  new  GdxRuntimeException( "No  glyphs  found! ");  }  public  Glyph  getGlyph  (char  ch)  {  Glyph[]  page  =  glyphs[ch  /  PAGE_SIZE];  	if  (glyph  ==  null  ||  glyph.height  ==  0  ||  glyph.width  ==  0)  continue;  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  threadPool.execute(new  Runnable()  {  listener.onResponse(response);  }  });  }  else  {  listener.onResponse(response);  }  }                          @Override  public  void  handleException(RemoteTransportException  exp)  {                          @Override  public  void  handleException(TransportException  exp)  {  onFailure(shard,  exp);  }  return  false;  }  });  	@Override  public  void  handleException(TransportException  exp)  {  
libgdx_07c67589c8701dd6151f6fbd0373d32ecd1af22d	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  context:  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  config.useGL20  =  true;  config.vSyncEnabled  =  false;  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),  config);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),  config);  
elasticsearch_2cb40fcb1741ce1bf4c770aeec8b85717f2b5d98	buggy:  assertThat(deleteResponse.isNotFound(),  equalTo(false));  context:  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  searchResponse  =  client().prepareSearch( "test ").setQuery(nestedQuery( "type1.nested1 ",  boolQuery().must(termQuery( "nested1.n_field1 ",   "n_value1_1 ")).must(termQuery( "nested1.n_field2 ",   "n_value2_1 ")))).execute().actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  DeleteResponse  deleteResponse  =  client().prepareDelete( "test ",   "type1 ",   "2 ").execute().actionGet();          assertThat(deleteResponse.isNotFound(),  equalTo(false));          assertThat(deleteResponse.isFound(),  equalTo(true));  flush();  statusResponse  =  client().admin().indices().prepareStatus().execute().actionGet();  assertThat(statusResponse.getIndex( "test ").getDocs().getNumDocs(),  equalTo(3l));  searchResponse  =  client().prepareSearch( "test ").setQuery(nestedQuery( "nested1 ",  termQuery( "nested1.n_field1 ",   "n_value1_1 "))).execute().actionGet();  assertNoFailures(searchResponse);  	assertThat(deleteResponse.isFound(),  equalTo(true));  
elasticsearch_27b53b8edfac1844a33389af9e97bc062f8b69dc	buggy:  parseContext.addNamedQuery(filterName,  childrenConstantScoreQuery);  context:  Filter  nonNestedDocsFilter  =  null;  if  (parentDocMapper.hasNestedObjects())  {  nonNestedDocsFilter  =  parseContext.cacheFilter(NonNestedDocsFilter.INSTANCE,  null);  }  Filter  parentFilter  =  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null);  Query  childrenConstantScoreQuery  =  new  ChildrenConstantScoreQuery(query,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  nonNestedDocsFilter);  if  (filterName  !=  null)  {              parseContext.addNamedQuery(filterName,  childrenConstantScoreQuery);              parseContext.addNamedFilter(filterName,  new  CustomQueryWrappingFilter(childrenConstantScoreQuery));  }  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  if  (deleteByQuery)  {  return  new  DeleteByQueryWrappingFilter(childrenConstantScoreQuery);  }  else  {  return  new  CustomQueryWrappingFilter(childrenConstantScoreQuery);  }  	parseContext.addNamedFilter(filterName,  new  CustomQueryWrappingFilter(childrenConstantScoreQuery));  
libgdx_32c98da9f705b1881a0c7084fb0971f021c0ee32	buggy:  if(time  >  model.skeleton.animations.get(animation).duration)  {  context:  batch.end();  if(Gdx.input.justTouched())  {  currAnimIdx++;  if(currAnimIdx  ==  animNames.size())  currAnimIdx  =  0;  animation  =  animNames.get(currAnimIdx);  time  =  0;  }  time  +=  Gdx.graphics.getDeltaTime()  /  10;  if(time  >  model.skeleton.animations.get(animation).duration)  {  if(time  >  model.skeleton.animations.get(animation).totalDuration)  {  time  =  0;  }  }  Vector3  point1  =  new  Vector3();  Vector3  point2  =  new  Vector3();  private  void  renderSkeleton  ()  {  renderer.begin(GL10.GL_LINES);  	if(time  >  model.skeleton.animations.get(animation).totalDuration)  {  
elasticsearch_8ecf71ffb8a73a4b16f5b5c29b752fd094fa787a	buggy:  logger.info( "boundAddress  [{}],  publishAddress  [{}] ",  serviceUrl,  publishUrl);  context:  }  catch  (Exception  e)  {  lastException.set(e);  return  false;  }  return  true;  }  });  if  (!success)  {  throw  new  JmxConnectorCreationException( "Failed  to  bind  to  [ "  +  port  +   "] ",  lastException.get());  }              logger.info( "boundAddress  [{}],  publishAddress  [{}] ",  serviceUrl,  publishUrl);              logger.info( "bound_address[{}],  publish_address[{}] ",  serviceUrl,  publishUrl);  }  for  (ResourceDMBean  resource  :  constructionMBeans)  {  register(resource);  }  }  public  void  registerMBean(Object  instance)  {  	logger.info( "bound_address[{}],  publish_address[{}] ",  serviceUrl,  publishUrl);  
libgdx_79cd760a286cca04ecfd699a8a4d344693b35396	buggy:  font.drawMultiLineText(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  context:  handle.deleteDirectory();  }  private  void  fail  ()  {  throw  new  RuntimeException();  }  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  font.drawMultiLineText(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  batch.end();  }  return  false;  }  }  	font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  LongArrayAtomicFieldData.Single(new  long[0],  0);  context:  }  }  }  public  LongArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  LongArrayAtomicFieldData.Single(new  long[0],  0);              return  new  LongArrayAtomicFieldData.SingleFixedSet(new  long[1],  0,  new  FixedBitSet(1));  }  final  TLongArrayList  values  =  new  TLongArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  LongArrayAtomicFieldData.SingleFixedSet(new  long[1],  0,  new  FixedBitSet(1));  
libgdx_0167584ea8811ccceaf16f6bfccf5871e339aacd	buggy:  position.set(viewportWidth  /  2.0f,  viewportHeight  /  2.0f,  0);  context:  public  void  setToOrtho  (boolean  yDown,  float  viewportWidth,  float  viewportHeight)  {  if  (yDown)  {  up.set(0,  -1,  0);  direction.set(0,  0,  1);  }  position.set(viewportWidth  /  2.0f,  viewportHeight  /  2.0f,  0);  position.set(zoom  *  viewportWidth  /  2.0f,  zoom  *  viewportHeight  /  2.0f,  0);  this.viewportWidth  =  viewportWidth;  this.viewportHeight  =  viewportHeight;  update();  }  	position.set(zoom  *  viewportWidth  /  2.0f,  zoom  *  viewportHeight  /  2.0f,  0);  
libgdx_fbef43ca95617a93068852b688a6857d4f172193	buggy:  BufferUtils.freeMemory(byteBuffer);  context:  this.attributes  =  attributes;  byteBuffer  =  BufferUtils.newUnsafeByteBuffer(this.attributes.vertexSize  *  numVertices);  buffer  =  byteBuffer.asFloatBuffer();  buffer.flip();  byteBuffer.flip();  }  public  void  dispose  ()  {  BufferUtils.freeMemory(byteBuffer);  BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  }  public  FloatBuffer  getBuffer  ()  {  return  buffer;  }  	BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  protected  abstract  Request  newRequest();  protected  abstract  Response  newResponse();  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  void  resolveRequest(ClusterState  state,  Request  request)  {          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  }  protected  abstract  ShardIterator  shards(ClusterState  state,  Request  request)  throws  ElasticsearchException;  class  AsyncSingleAction  {  private  final  ActionListener<Response>  listener;  private  final  ShardIterator  shardIt;  	request.index(state.metaData().concreteSingleIndex(request.index()));  
elasticsearch_032184bd5eb63b9f5b4d2539b6d4e06e4716bfb0	buggy:  OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().setForce(randomBoolean()).execute().actionGet();  context:  assertNoFailures(actionGet);  }  return  actionGet;  }  protected  OptimizeResponse  optimize()  {  waitForRelocation();          OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().setForce(randomBoolean()).execute().actionGet();          OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().execute().actionGet();  assertNoFailures(actionGet);  return  actionGet;  }  protected  boolean  indexExists(String  index)  {  	OptimizeResponse  actionGet  =  client().admin().indices().prepareOptimize().execute().actionGet();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(NodesHotThreadsResponse  response)  {  try  {  StringBuilder  sb  =  new  StringBuilder();  for  (NodeHotThreads  node  :  response)  {  sb.append( ":::   ").append(node.getNode().toString()).append( "\n ");  Strings.spaceify(3,  node.getHotThreads(),  sb);  sb.append('\n');  }  channel.sendResponse(new  StringRestResponse(RestStatus.OK,  sb.toString()));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_8ddf026a154c892242f18c2b67db82b8a4da6aff	buggy:  return  Gdx.graphics.newTexture(Gdx.files.internal(file),  TextureFilter.Nearest,  TextureFilter.Nearest,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  context:  public  static  BitmapFont  font;  public  static  Music  music;  public  static  Sound  jumpSound;  public  static  Sound  highJumpSound;  public  static  Sound  hitSound;  public  static  Sound  coinSound;  public  static  Sound  clickSound;  public  static  Texture  loadTexture(String  file)  {      return  Gdx.graphics.newTexture(Gdx.files.internal(file),  TextureFilter.Nearest,  TextureFilter.Nearest,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);      return  new  Texture(Gdx.files.internal(file));  }  public  static  void  load()  {  background  =  loadTexture( "data/background.png ");  backgroundRegion  =  new  TextureRegion(background,  0,  0,  320,  480);  items  =  loadTexture( "data/items.png ");  mainMenu  =  new  TextureRegion(items,  0,  224,  300,  110);  	return  new  Texture(Gdx.files.internal(file));  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  font  =  new  BitmapFont(true);  context:  TextureRegion  region;  TextureAtlas  atlas;  Stage  stage;  MyActor  image;  OrthographicCamera  camera;  public  void  create  ()  {  font  =  new  BitmapFont(true);  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  true);  region  =  new  TextureRegion(new  Texture( "data/badlogic.jpg "));  region.flip(false,  true);  atlas  =  new  TextureAtlas(Gdx.files.internal( "data/pack "),  true);  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  true);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  return  builder.copiedBytes();  context:  builder.startObject( "translog_files ");  for  (CommitPoint.FileInfo  fileInfo  :  commitPoint.translogFiles())  {  builder.startObject(fileInfo.name());  builder.field( "physical_name ",  fileInfo.physicalName());  builder.field( "length ",  fileInfo.length());  builder.endObject();  }  builder.endObject();  builder.endObject();          return  builder.copiedBytes();          return  builder.bytes().toBytes();  }  public  static  CommitPoint  fromXContent(byte[]  data)  throws  Exception  {  XContentParser  parser  =  XContentFactory.xContent(XContentType.JSON).createParser(data);  try  {  String  currentFieldName  =  null;  XContentParser.Token  token  =  parser.nextToken();  if  (token  ==  null)  {  	return  builder.bytes().toBytes();  
elasticsearch_82d3693a916b6ae0d445d7f12328a7036dd87043	buggy:  }  catch  (Exception  e)  {  context:  }  Set<Integer>  shardIds  =  shardIds();  final  CountDownLatch  latch  =  new  CountDownLatch(shardIds.size());  for  (final  int  shardId  :  shardIds)  {  executor  =  executor  ==  null  ?  threadPool.generic()  :  executor;  executor.execute(new  Runnable()  {  public  void  run()  {  try  {  removeShard(shardId,  reason);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  }  finally  {  latch.countDown();  }  }  });  }  try  {  	}  catch  (Throwable  e)  {  
elasticsearch_b3e0e58094d02cdc9f98d63fa56cabe7b12f2966	buggy:  return  new  GeoPointBinaryDVAtomicFieldData(context.reader(),  context.reader().getBinaryDocValues(fieldNames.indexName()));  context:  }  public  final  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue,  SortMode  sortMode)  {  throw  new  ElasticsearchIllegalArgumentException( "can't  sort  on  geo_point  field  without  using  specific  sorting  feature,  like  geo_distance ");  }  public  AtomicGeoPointFieldData<ScriptDocValues>  load(AtomicReaderContext  context)  {  try  {              return  new  GeoPointBinaryDVAtomicFieldData(context.reader(),  context.reader().getBinaryDocValues(fieldNames.indexName()));              return  new  GeoPointBinaryDVAtomicFieldData(context.reader().getBinaryDocValues(fieldNames.indexName()));  }  catch  (IOException  e)  {  throw  new  ElasticsearchIllegalStateException( "Cannot  load  doc  values ",  e);  }  }  public  AtomicGeoPointFieldData<ScriptDocValues>  loadDirect(AtomicReaderContext  context)  throws  Exception  {  return  load(context);  	return  new  GeoPointBinaryDVAtomicFieldData(context.reader().getBinaryDocValues(fieldNames.indexName()));  
elasticsearch_932215d6fac6519706d9542721d9f18913f9a80d	buggy:  .put( "index.shard.check_index ",  true)  context:  }  }  }  public  static  void  main(String[]  args)  throws  Exception  {  System.setProperty( "es.logger.prefix ",   " ");  int  numberOfNodes  =  2;  Settings  settings  =  ImmutableSettings.settingsBuilder()                  .put( "index.shard.check_index ",  true)                  .put( "index.shard.check_on_startup ",  true)  .put( "gateway.type ",   "local ")  .put( "gateway.recover_after_nodes ",  numberOfNodes)  .put( "index.number_of_shards ",  1)  .put( "path.data ",   "data/data1,data/data2 ")  .build();  FullRestartStressTest  test  =  new  FullRestartStressTest()  .settings(settings)  	.put( "index.shard.check_on_startup ",  true)  
libgdx_c81d15a3d08d6d468e221dcfac6aa2f7e358fc19	buggy:  if  (currentlyLoading  ==  null  ||  currentlyLoading.isEmpty())  return;  context:  protected  void  onModelClicked  (final  String  name)  {  if  (name  ==  null)  return;  currentlyLoading  =   "data/ "  +  name;  assets.load(currentlyLoading,  Model.class);  loading  =  true;  }  protected  void  onLoaded  ()  {  if  (currentlyLoading  ==  null  ||  currentlyLoading.isEmpty())  return;  if  (currentlyLoading  ==  null  ||  currentlyLoading.length()  ==  0)  return;  instances.clear();  animationControllers.clear();  final  ModelInstance  instance  =  new  ModelInstance(assets.get(currentlyLoading,  Model.class));  instance.transform  =  transform;  instances.add(instance);  if  (instance.animations.size  >  0)  animationControllers.put(instance,  new  AnimationController(instance));  currentlyLoading  =  null;  	if  (currentlyLoading  ==  null  ||  currentlyLoading.length()  ==  0)  return;  
elasticsearch_93906903b6f0f813414e865ebece49ce2bb4e71c	buggy:  searchScript.setNextReader(context.reader());  context:  public  int  hashCode()  {  int  result  =  script  !=  null  ?  script.hashCode()  :  0;  result  =  31  *  result  +  (params  !=  null  ?  params.hashCode()  :  0);  return  result;  }  public  DocIdSet  getDocIdSet(AtomicReaderContext  context,  Bits  acceptDocs)  throws  IOException  {              searchScript.setNextReader(context.reader());              searchScript.setNextReader(context);  return  BitsFilteredDocIdSet.wrap(new  ScriptDocSet(context.reader(),  searchScript),  acceptDocs);  }  static  class  ScriptDocSet  extends  GetDocSet  {  private  final  SearchScript  searchScript;  	searchScript.setNextReader(context);  
libgdx_0530ea537aff4c964dc1c07accb3503631690ee5	buggy:  if(renderable.worldTransform.det()  ==  0)  return;  context:  final  int  n  =  attrs.size();  for  (int  i  =  0;  i  <  n;  i++)  {  tempArray.add(attributes.get(attrs.get(i).getKey(),  -1));  }  return  tempArray.items;  }  private  Attributes  combinedAttributes  =  new  Attributes();  public  void  render  (Renderable  renderable)  {  if(renderable.worldTransform.det()  ==  0)  return;  if(renderable.worldTransform.det3x3()  ==  0)  return;  combinedAttributes.clear();  if  (renderable.environment  !=  null)  combinedAttributes.set(renderable.environment);  if  (renderable.material  !=  null)  combinedAttributes.set(renderable.material);  render(renderable,  combinedAttributes);  }  	if(renderable.worldTransform.det3x3()  ==  0)  return;  
elasticsearch_371b071fb791a73f6757c813200877ff3b6c8824	buggy:  searchContext.addScopePhase(childQuery);  context:  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  null,  childType,  parentType,  scoreType,  factor,  incrementalFactor);          searchContext.addScopePhase(childQuery);          searchContext.addRewrite(childQuery);  return  childQuery;  }  }  	searchContext.addRewrite(childQuery);  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  metaDataBlobContainer.writeBlob(newMetaData,  new  ByteArrayInputStream(out.unsafeByteArray(),  0,  out.size()),  out.size());  context:  FastByteArrayOutputStream  out  =  new  FastByteArrayOutputStream();  OutputStream  os  =  out;  if  (compress)  {  os  =  new  LZFOutputStream(os);  }  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON,  os);  builder.startObject();  MetaData.Builder.toXContent(metaData,  builder,  ToXContent.EMPTY_PARAMS);  builder.endObject();  builder.close();              metaDataBlobContainer.writeBlob(newMetaData,  new  ByteArrayInputStream(out.unsafeByteArray(),  0,  out.size()),  out.size());              metaDataBlobContainer.writeBlob(newMetaData,  new  ByteArrayInputStream(out.underlyingBytes(),  0,  out.size()),  out.size());  }  catch  (IOException  e)  {  throw  new  GatewayException( "Failed  to  write  metadata  [ "  +  newMetaData  +   "] ",  e);  }  currentIndex++;  try  {  metaDataBlobContainer.deleteBlobsByFilter(new  BlobContainer.BlobNameFilter()  {  	metaDataBlobContainer.writeBlob(newMetaData,  new  ByteArrayInputStream(out.underlyingBytes(),  0,  out.size()),  out.size());  
libgdx_9844f1f930c6a1154871f9cc8489873f16063868	buggy:  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/uitexture.png ",  FileType.Internal  ),  context:  TextureAtlas  atlas;  Stage  ui;  public  void  surfaceCreated()  {  if(  uiTexture  ==  null  )  {  Gdx.input.addInputListener(  this  );  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/uitexture.png ",  FileType.Internal  ),  uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/ui.png ",  FileType.Internal  ),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge  );  ui  =  new  Stage(  480,  320,  false  );  atlas  =  new  TextureAtlas(  uiTexture  );  atlas.addRegion(   "blend ",  0,  0,  64,  32  );  	uiTexture  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle(   "data/ui.png ",  FileType.Internal  ),  
libgdx_30162f60dcd25645b47e6b0ead9f491406b48506	buggy:  if  (config.useGL20  &&  major  >=  2)  {  context:  }  }  }  }  private  void  initiateGLInstances  ()  {  String  version  =  org.lwjgl.opengl.GL11.glGetString(GL11.GL_VERSION);  major  =  Integer.parseInt( " "  +  version.charAt(0));  minor  =  Integer.parseInt( " "  +  version.charAt(2));  if  (config.useGL20  &&  major  >=  2)  {  if  (config.useGL20  &&  (major  >=  2  ||  version.contains( "2.1 ")))  {  //  special  case  for  MESA,  wtf...  gl20  =  new  LwjglGL20();  gl  =  gl20;  }  else  {  if  (major  ==  1  &&  minor  <  5)  {  gl10  =  new  LwjglGL10();  }  else  {  gl11  =  new  LwjglGL11();  	if  (config.useGL20  &&  (major  >=  2  ||  version.contains( "2.1 ")))  {  //  special  case  for  MESA,  wtf...  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  }  String[]  nodesIds  =  RestActions.splitNodes(request.param( "nodeId "));  final  boolean  includeSettings  =  request.paramAsBoolean( "settings ",  false);  NodesInfoRequest  nodesInfoRequest  =  new  NodesInfoRequest(nodesIds);  nodesInfoRequest.listenerThreaded(false);  client.admin().cluster().execNodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "clusterName ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeInfo  nodeInfo  :  result)  {  builder.startObject(nodeInfo.node().id());  builder.field( "name ",  nodeInfo.node().name());  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
libgdx_f222259d75c833f94262f2434c6cbbc6d000c513	buggy:  atlas  =  new  TextureAtlas(Gdx.files.internal( "data "));  context:  public  class  TextureAtlasTest  extends  GdxTest  {  SpriteBatch  batch;  Sprite  badlogic,  badlogicSmall,  star;  TextureAtlas  atlas;  BitmapFont  font;  public  void  create  ()  {  batch  =  new  SpriteBatch();  atlas  =  new  TextureAtlas(Gdx.files.internal( "data "));  atlas  =  new  TextureAtlas(Gdx.files.internal( "data/pack "));  badlogic  =  atlas.createSprite( "badlogicslice ");  badlogic.setPosition(50,  50);  badlogicSmall  =  atlas.createSprite( "badlogicsmall ");  badlogicSmall.setPosition(10,  10);  badlogicSmall.flip(true,  true);  	atlas  =  new  TextureAtlas(Gdx.files.internal( "data/pack "));  
libgdx_b8a6bebaa7dc7e0469fe7b19bc4b827200c0f57b	buggy:  writer.write( "  offset:   "  +  image.offsetX  +   ",   "  +  image.offsetY  +   "\n ");  context:  if  (matcher.matches())  index  =  Integer.parseInt(matcher.group(1));  int  underscoreIndex  =  imageName.indexOf('_');  if  (underscoreIndex  !=  -1)  imageName  =  imageName.substring(0,  underscoreIndex);  writer.write(imageName  +   "\n ");  writer.write( "  rotate:   "  +  image.rotate  +   "\n ");  writer.write( "  xy:   "  +  left  +   ",   "  +  top  +   "\n ");  writer.write( "  size:   "  +  image.getWidth()  +   ",   "  +  image.getHeight()  +   "\n ");  writer.write( "  orig:   "  +  image.originalWidth  +   ",   "  +  image.originalHeight  +   "\n ");  writer.write( "  offset:   "  +  image.offsetX  +   ",   "  +  image.offsetY  +   "\n ");  writer.write( "  offset:   "  +  image.offsetX  +   ",   "  +  (image.originalHeight  -  image.getHeight()  -  image.offsetY)  +   "\n ");  writer.write( "  index:   "  +  index  +   "\n ");  }  }  static  private  class  Image  extends  BufferedImage  {  final  String  name;  final  int  offsetX,  offsetY;  final  int  originalWidth,  originalHeight;  	writer.write( "    offset:   "  +  image.offsetX  +   ",   "  +  (image.originalHeight  -  image.getHeight()  -  image.offsetY)  +   "\n ");  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  context:  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  from,  to,  includeLower,  includeUpper);  }          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  
libgdx_d3151bcae8c112186bf127141eba9a2bfe6d46fc	buggy:  renderer.render(world);  context:  float  updateTime  =  (System.nanoTime()  -  startTime)  /  1000000000.0f;  startTime  =  System.nanoTime();  GL10  gl  =  Gdx.app.getGraphics().getGL10();  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  camera.update();  camera.apply(gl);  renderer.render(world);  renderer.render(world,  camera.combined);  float  renderTime  =  (System.nanoTime()  -  startTime)  /  1000000000.0f;  batch.begin();  font.draw(batch,   "fps: "  +  Gdx.graphics.getFramesPerSecond()  +   ",  update:   "  +  updateTime  +   ",  render:   "  +  renderTime,  0,  20);  batch.end();  }  	renderer.render(world,  camera.combined);  
libgdx_e94a7c9d4eb78d19371ca735169be78097754e2a	buggy:  config.height  =  240;  context:  GdxTest  test  =  new  PixelPerfectTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.width  =  320;  config.height  =  240;  config.height  =  241;  new  LwjglApplication(test,  config);  }  }  	config.height  =  241;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execIndex(indexRequest,  new  ActionListener<IndexResponse>()  {  context:  }  catch  (IOException  e1)  {  return;  }  }  }  indexRequest.listenerThreaded(false);  indexRequest.operationThreaded(true);          client.execIndex(indexRequest,  new  ActionListener<IndexResponse>()  {          client.index(indexRequest,  new  ActionListener<IndexResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "_index ",  result.index())  .field( "_type ",  result.type())  .field( "_id ",  result.id())  	client.index(indexRequest,  new  ActionListener<IndexResponse>()  {  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  return  cluster().clientNodeClient(name);  context:  do  {  blocks  =  nodeClient.admin().cluster().prepareState().setLocal(true).execute().actionGet()  .getState().blocks().global(ClusterBlockLevel.METADATA);  }  while  (!blocks.isEmpty()  &&  (System.currentTimeMillis()  -  start)  <  timeout.millis());  return  blocks;  }  public  Client  startNode(Settings.Builder  settings)  {  String  name  =  cluster().startNode(settings);          return  cluster().clientNodeClient(name);          return  cluster().client(name);  }  public  void  testRecoverAfterNodes()  throws  Exception  {  Client  clientNode1  =  startNode(settingsBuilder().put( "gateway.recover_after_nodes ",  3));  assertThat(clientNode1.admin().cluster().prepareState().setLocal(true).execute().actionGet()  .getState().blocks().global(ClusterBlockLevel.METADATA),  	return  cluster().client(name);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.filterCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  mltQuery.setAnalyzer(smartNameFieldMappers.mapper().searchAnalyzer());  }  }  if  (mltQuery.getAnalyzer()  ==  null)  {  mltQuery.setAnalyzer(parseContext.mapperService().searchAnalyzer());  }  mltQuery.setMoreLikeFields(new  String[]{fieldName});          return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(mltQuery,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();  context:  routingTableBuilder.addAsNew(cursor.value);  }  RoutingTable  routingTable  =  routingTableBuilder.build();  DiscoveryNodes.Builder  nodes  =  DiscoveryNodes.builder();  for  (int  i  =  0;  i  <  numberOfNodes;  i++)  {  nodes.put(newNode( "node "  +  i));  }          ClusterState  clusterState  =  ClusterState.builder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).nodes(nodes).metaData(metaData).routingTable(routingTable).build();  routingTable  =  service.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  RoutingNodes  routingNodes  =  clusterState.routingNodes();  routingNodes  =  clusterState.routingNodes();  routingTable  =  service.applyStartedShards(clusterState,  routingNodes.shardsWithState(INITIALIZING)).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).nodes(nodes).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_3d31c38f11b0ec27411d252ed59a0ab04035d4d7	buggy:  transportService.sendRequest(nodeToSend,  UnicastPingRequestHandler.ACTION,  pingRequest,  TimeValue.timeValueMillis((long)  (timeout.millis()  *  1.25)),  new  BaseTransportResponseHandler<UnicastPingResponse>()  {  context:  final  DiscoveryNode  nodeToSend  =  nodeToSendX;  try  {  transportService.connectToNode(nodeToSend);  }  catch  (ConnectTransportException  e)  {  latch.countDown();  continue;  }  final  boolean  disconnect  =  disconnectX;              transportService.sendRequest(nodeToSend,  UnicastPingRequestHandler.ACTION,  pingRequest,  TimeValue.timeValueMillis((long)  (timeout.millis()  *  1.25)),  new  BaseTransportResponseHandler<UnicastPingResponse>()  {              transportService.sendRequest(nodeToSend,  UnicastPingRequestHandler.ACTION,  pingRequest,  TransportRequestOptions.options().withTimeout((long)  (timeout.millis()  *  1.25)),  new  BaseTransportResponseHandler<UnicastPingResponse>()  {  return  new  UnicastPingResponse();  }  try  {  DiscoveryNodes  discoveryNodes  =  nodesProvider.nodes();  	transportService.sendRequest(nodeToSend,  UnicastPingRequestHandler.ACTION,  pingRequest,  TransportRequestOptions.options().withTimeout((long)  (timeout.millis()  *  1.25)),  new  BaseTransportResponseHandler<UnicastPingResponse>()  {  
elasticsearch_cfe7504d1cee2cffd3ed06c3b61d0c77de63b67f	buggy:  FetchSearchRequest  fetchSearchRequest  =  new  FetchSearchRequest(queryResults.get(shardTarget).id(),  docIds);  context:  if  (docIdsToLoad.isEmpty())  {  finishHim();  }  final  AtomicInteger  counter  =  new  AtomicInteger(docIdsToLoad.size());  for  (final  Map.Entry<SearchShardTarget,  ExtTIntArrayList>  entry  :  docIdsToLoad.entrySet())  {  SearchShardTarget  shardTarget  =  entry.getKey();  ExtTIntArrayList  docIds  =  entry.getValue();                  FetchSearchRequest  fetchSearchRequest  =  new  FetchSearchRequest(queryResults.get(shardTarget).id(),  docIds);                  FetchSearchRequest  fetchSearchRequest  =  new  FetchSearchRequest(request,  queryResults.get(shardTarget).id(),  docIds);  DiscoveryNode  node  =  nodes.get(shardTarget.nodeId());  searchService.sendExecuteFetch(node,  fetchSearchRequest,  new  SearchServiceListener<FetchSearchResult>()  {  public  void  onResult(FetchSearchResult  result)  {  result.shardTarget(entry.getKey());  fetchResults.put(result.shardTarget(),  result);  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  	FetchSearchRequest  fetchSearchRequest  =  new  FetchSearchRequest(request,  queryResults.get(shardTarget).id(),  docIds);  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  MetaData  parsedMetaData  =  MetaData.Builder.fromXContent(XContentFactory.xContent(XContentType.JSON).createParser(metaDataSource),  null);  context:  .settings(settingsBuilder().put( "setting1 ",   "value1 ").put( "setting2 ",   "value2 "))  .numberOfShards(1)  .numberOfReplicas(2)  .putMapping( "mapping1 ",  MAPPING_SOURCE1)  .putMapping( "mapping2 ",  MAPPING_SOURCE2))  .build();  String  metaDataSource  =  MetaData.Builder.toXContent(metaData);          MetaData  parsedMetaData  =  MetaData.Builder.fromXContent(XContentFactory.xContent(XContentType.JSON).createParser(metaDataSource),  null);          MetaData  parsedMetaData  =  MetaData.Builder.fromXContent(XContentFactory.xContent(XContentType.JSON).createParser(metaDataSource));  IndexMetaData  indexMetaData  =  parsedMetaData.index( "test1 ");  assertThat(indexMetaData.numberOfShards(),  equalTo(1));  assertThat(indexMetaData.numberOfReplicas(),  equalTo(2));  assertThat(indexMetaData.settings().getAsMap().size(),  equalTo(2));  assertThat(indexMetaData.mappings().size(),  equalTo(0));  indexMetaData  =  parsedMetaData.index( "test2 ");  	MetaData  parsedMetaData  =  MetaData.Builder.fromXContent(XContentFactory.xContent(XContentType.JSON).createParser(metaDataSource));  
elasticsearch_be4b2e2de618240a64524f5256ff857cf6f9d4ea	buggy:  SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  vars,  parseContext.scriptService());  context:  throw  new  QueryParsingException(index,   "[custom_score]  requires  'query'  field ");  }  if  (script  ==  null)  {  throw  new  QueryParsingException(index,   "[custom_score]  requires  'script'  field ");  }  SearchContext  context  =  SearchContext.current();  if  (context  ==  null)  {  throw  new  ElasticSearchIllegalStateException( "No  search  context  on  going... ");  }          SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  vars,  parseContext.scriptService());          SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  vars,  parseContext.scriptService());  FunctionScoreQuery  functionScoreQuery  =  new  FunctionScoreQuery(query,  new  ScriptScoreFunction(searchScript));  functionScoreQuery.setBoost(boost);  return  functionScoreQuery;  }  public  static  class  ScriptScoreFunction  implements  ScoreFunction  {  private  final  SearchScript  script;  	SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  vars,  parseContext.scriptService());  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  parseMultiField(builder,  name,  node,  parserContext,  fieldName,  fieldNode);  context:  builder.searchAnalyzer(getNamedAnalyzer(parserContext,  fieldNode.toString()));  }  else  if  (fieldName.equals(Fields.PAYLOADS))  {  builder.payloads(Boolean.parseBoolean(fieldNode.toString()));  }  else  if  (Fields.PRESERVE_SEPARATORS.match(fieldName))  {  builder.preserveSeparators(Boolean.parseBoolean(fieldNode.toString()));  }  else  if  (Fields.PRESERVE_POSITION_INCREMENTS.match(fieldName))  {  builder.preservePositionIncrements(Boolean.parseBoolean(fieldNode.toString()));  }  else  if  (Fields.MAX_INPUT_LENGTH.match(fieldName))  {  builder.maxInputLength(Integer.parseInt(fieldNode.toString()));  }  else  if  ( "fields ".equals(fieldName)  ||   "path ".equals(fieldName))  {                      parseMultiField(builder,  name,  node,  parserContext,  fieldName,  fieldNode);                      parseMultiField(builder,  name,  parserContext,  fieldName,  fieldNode);  }  else  if  (fieldName.equals(Fields.CONTEXT))  {  builder.contextMapping(ContextBuilder.loadMappings(fieldNode));  }  else  {  throw  new  MapperParsingException( "Unknown  field  [ "  +  fieldName  +   "] ");  }  }  if  (builder.searchAnalyzer  ==  null)  {  	parseMultiField(builder,  name,  parserContext,  fieldName,  fieldNode);  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  client( "node1 ").admin().indices().prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  2)).execute().actionGet();  context:  public  class  WriteConsistencyLevelTests  extends  AbstractNodesTests  {  public  void  closeNodes()  {  closeAllNodes();  }  public  void  testWriteConsistencyLevelReplication2()  throws  Exception  {  startNode( "node1 ");          client( "node1 ").admin().indices().prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  2)).execute().actionGet();          client( "node1 ").admin().indices().prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  2)).execute().actionGet();  ClusterHealthResponse  clusterHealth  =  client( "node1 ").admin().cluster().prepareHealth().setWaitForActiveShards(1).setWaitForYellowStatus().execute().actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  client( "node1 ").prepareIndex( "test ",   "type1 ",   "1 ").setSource(source( "1 ",   "test ")).setConsistencyLevel(WriteConsistencyLevel.ONE).execute().actionGet();  	client( "node1 ").admin().indices().prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  2)).execute().actionGet();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.startObject( "state ");  if  (request.param( "filter_metadata ")  ==  null)  {  request.params().put( "filter_metadata ",   "true ");  }  response.getState().settingsFilter(settingsFilter).toXContent(builder,  request);  builder.endObject();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  if  (logger.isDebugEnabled())  {  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  context:  }  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  chosenFilter);  }  return  chosenFilter;  }  protected  boolean  matchesIndices(String  currentIndex,  String...  indices)  {          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  for  (String  index  :  concreteIndices)  {  if  (Regex.simpleMatch(index,  currentIndex))  {  return  true;  }  }  return  false;  }  }  	final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  
elasticsearch_abf1855509f5c2c7de5f273941431bb1e9500e91	buggy:  logger.info( "ignoring  design  document  {} ",  id);  context:  }  if  (map.containsKey( "error "))  {  return  null;  }  String  seq  =  map.get( "seq ").toString();  String  id  =  map.get( "id ").toString();  if  (id.startsWith( "_design/ "))  {              logger.info( "ignoring  design  document  {} ",  id);              logger.trace( "ignoring  design  document  {} ",  id);  return  seq;  }  if  (map.containsKey( "delete ")  &&  map.get( "deleted ").equals( "true "))  {  bulk.add(deleteRequest(indexName).type(typeName).id(id));  }  else  if  (map.containsKey( "doc "))  {  Map<String,  Object>  doc  =  (Map<String,  Object>)  map.get( "doc ");  bulk.add(indexRequest(indexName).type(typeName).id(id).source(doc));  	logger.trace( "ignoring  design  document  {} ",  id);  
elasticsearch_b80eee305e2fc4b9c7e3dee0c0af797047dea891	buggy:  builder.field( "state ",  indexMetaData.state().toString().toLowerCase());  context:  }  }  return  new  IndexMetaData(index,  version,  state,  tmpSettings,  mappings.immutableMap(),  tmpAliases.immutableMap(),  customs.immutableMap());  }  public  static  void  toXContent(IndexMetaData  indexMetaData,  XContentBuilder  builder,  ToXContent.Params  params)  throws  IOException  {  builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "version ",  indexMetaData.version());              builder.field( "state ",  indexMetaData.state().toString().toLowerCase());              builder.field( "state ",  indexMetaData.state().toString().toLowerCase(Locale.ENGLISH));  boolean  binary  =  params.paramAsBoolean( "binary ",  false);  builder.startObject( "settings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.settings().getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  	builder.field( "state ",  indexMetaData.state().toString().toLowerCase(Locale.ENGLISH));  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  SuggestRequest  suggestRequest  =  new  SuggestRequest(RestActions.splitIndices(request.param( "index ")));  if  (request.hasParam( "ignore_indices "))  {  suggestRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }  suggestRequest.listenerThreaded(false);  try  {              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  suggestRequest.operationThreading(operationThreading);  if  (request.hasContent())  {  suggestRequest.suggest(request.content(),  request.contentUnsafe());  }  else  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_74287865b29c6aa29eaa51f8c119d3daa45f37cc	buggy:  Strings.randomBase64UUID(new  Random(Long.parseLong(seed)));  context:  public  void  publish(ClusterState  clusterState,  Discovery.AckListener  ackListener)  {  if  (lifecycle.started())  {  discovery.publish(clusterState,  ackListener);  }  }  public  static  String  generateNodeId(Settings  settings)  {  String  seed  =  settings.get( "discovery.id.seed ");  if  (seed  !=  null)  {              Strings.randomBase64UUID(new  Random(Long.parseLong(seed)));              return  Strings.randomBase64UUID(new  Random(Long.parseLong(seed)));  }  return  Strings.randomBase64UUID();  }  }  	return  Strings.randomBase64UUID(new  Random(Long.parseLong(seed)));  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  elements  =  atLeast(100);  context:  public  class  GroupTreeTests  extends  ElasticsearchTestCase  {  public  void  testDuel()  {  GroupTree  tree1  =  new  GroupTree();  GroupRedBlackTree  tree2  =  new  GroupRedBlackTree(randomInt(100));          final  int  elements  =  atLeast(100);          final  int  elements  =  scaledRandomIntBetween(100,  1000);  for  (int  i  =  0;  i  <  elements;  ++i)  {  final  double  centroid  =  randomDouble();  final  int  count  =  randomIntBetween(1,  5);  Group  g  =  new  Group(centroid,  i);  g.add(centroid,  count  -  1);  tree1.add(g);  tree2.addGroup(centroid,  count,  i);  }  	final  int  elements  =  scaledRandomIntBetween(100,  1000);  
elasticsearch_c1ab9f290fe80800317d2dbc93837dcb79bd5d82	buggy:  logger.info( "[partial_cluster_shutdown]:  done  shutting  down  [{}] ",  nodesIds);  context:  }  });  }  try  {  latch.await();  }  catch  (InterruptedException  e)  {  }                      logger.info( "[partial_cluster_shutdown]:  done  shutting  down  [{}] ",  nodesIds);                      logger.info( "[partial_cluster_shutdown]:  done  shutting  down  [{}] ",  ((Object)  nodesIds));  }  });  t.start();  }  return  new  NodesShutdownResponse(clusterName,  nodes.toArray(new  DiscoveryNode[nodes.size()]));  }  private  class  NodeShutdownRequestHandler  extends  BaseTransportRequestHandler<VoidStreamable>  {  	logger.info( "[partial_cluster_shutdown]:  done  shutting  down  [{}] ",  ((Object)  nodesIds));  
libgdx_c1baf8e9b5b4a182948e227e4befb09e2dba17a8	buggy:  if  (meshPart.primitiveType  !=  com.badlogic.gdx.graphics.GL10.GL_TRIANGLES)  context:  public  void  set(final  Mesh  mesh)  {  set(mesh,  0,  mesh.getNumIndices());  }  public  void  set(final  MeshPart  meshPart)  {  if  (meshPart.primitiveType  !=  com.badlogic.gdx.graphics.GL10.GL_TRIANGLES)  if  (meshPart.primitiveType  !=  com.badlogic.gdx.graphics.GL20.GL_TRIANGLES)  throw  new  com.badlogic.gdx.utils.GdxRuntimeException( "Mesh  must  be  indexed  and  triangulated ");  set(meshPart.mesh,  meshPart.indexOffset,  meshPart.numVertices);  this.meshPart  =  meshPart;  }  	if  (meshPart.primitiveType  !=  com.badlogic.gdx.graphics.GL20.GL_TRIANGLES)  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ObjectFloatOpenHashMap<String>  indices  =  new  ObjectFloatOpenHashMap<String>();  context:  }  catch  (Exception  e)  {  }  if  (nodesState.failures().length  >  0)  {  for  (FailedNodeException  failedNodeException  :  nodesState.failures())  {  }  }          ObjectFloatOpenHashMap<String>  indices  =  new  ObjectFloatOpenHashMap<String>();          ObjectFloatOpenHashMap<String>  indices  =  new  ObjectFloatOpenHashMap<>();  MetaData  electedGlobalState  =  null;  int  found  =  0;  for  (TransportNodesListGatewayMetaState.NodeLocalGatewayMetaState  nodeState  :  nodesState)  {  if  (nodeState.metaData()  ==  null)  {  continue;  }  found++;  if  (electedGlobalState  ==  null)  {  	ObjectFloatOpenHashMap<String>  indices  =  new  ObjectFloatOpenHashMap<>();  
libgdx_32b98412f7409d91e046a8ede5b988c00464e9c6	buggy:  public  void  purchase  (PurchaseListener  listener,  String  identifier)  {  context:  return  false;  }  public  void  dispose  ()  {  }  public  void  purchase  (PurchaseListener  listener,  String  identifier)  {  public  void  purchase  (String  identifier,  PurchaseListener  listener)  {  }  public  void  purchaseRestore  ()  {  	public  void  purchase  (String  identifier,  PurchaseListener  listener)  {  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  nextIndex  =  currentIndex;  context:  }  }  public  void  remove  ()  {  if  (currentIndex  ==  INDEX_ZERO  &&  map.hasZeroValue)  {  map.hasZeroValue  =  false;  }  else  if  (currentIndex  <  0)  {  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  }  else  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  EMPTY;  }  currentIndex  =  INDEX_ILLEGAL;  map.size--;  }  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  FieldDataType  fieldDataType  =  new  FieldDataType( "string ",  ImmutableSettings.builder().put( "global_values ",   "fixed "));  context:  while  (termsEnum.next()  !=  null)  {  size++;  }  assertThat(size,  equalTo(3));  }  public  void  testGlobalOrdinalsGetRemovedOnceIndexReaderCloses()  throws  Exception  {  fillExtendedMvSet();  refreshReader();          FieldDataType  fieldDataType  =  new  FieldDataType( "string ",  ImmutableSettings.builder().put( "global_values ",   "fixed "));          FieldDataType  fieldDataType  =  new  FieldDataType( "string ",  ImmutableSettings.builder().put( "global_values ",   "fixed ").put( "cache ",   "node "));  IndexFieldData.WithOrdinals  ifd  =  getForField(fieldDataType,   "value ");  IndexFieldData.WithOrdinals  globalOrdinals  =  ifd.loadGlobal(topLevelReader);  assertThat(ifd.loadGlobal(topLevelReader),  sameInstance(globalOrdinals));  assertThat(indicesFieldDataCache.getCache().size(),  equalTo(4l));  IndexFieldData.WithOrdinals  cachedInstace  =  null;  for  (Accountable  ramUsage  :  indicesFieldDataCache.getCache().asMap().values())  {  	FieldDataType  fieldDataType  =  new  FieldDataType( "string ",  ImmutableSettings.builder().put( "global_values ",   "fixed ").put( "cache ",   "node "));  
elasticsearch_d111e169a4d6aca4233ed147f75282dd5ab3bd91	buggy:  MetaData.Builder  mdBuilder  =  MetaData.builder().metaData(currentState.metaData());  context:  String[]  concreteIndices  =  metaData.concreteIndices(request.searchRequest().indices());  BytesReference  source  =  null;  if  (request.searchRequest().source()  !=  null  &&  request.searchRequest().source().length()  >  0)  {  source  =  request.searchRequest().source();  }  else  if  (request.searchRequest().extraSource()  !=  null  &&  request.searchRequest().extraSource().length()  >  0)  {  source  =  request.searchRequest().extraSource();  }                          MetaData.Builder  mdBuilder  =  MetaData.builder().metaData(currentState.metaData());                          MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  for  (String  index  :  concreteIndices)  {  IndexMetaData  indexMetaData  =  metaData.index(index);  if  (indexMetaData  ==  null)  {  throw  new  IndexMissingException(new  Index(index));  }  IndexWarmersMetaData  warmers  =  indexMetaData.custom(IndexWarmersMetaData.TYPE);  if  (warmers  ==  null)  {  	MetaData.Builder  mdBuilder  =  MetaData.builder(currentState.metaData());  
elasticsearch_fc0ee42c07ae615cfb3ac2461e6931256cf86845	buggy:  if  (Regex.simpleMatch(dynamicSetting,  setting.getKey()))  {  context:  for  (String  dynamicSetting  :  dynamicSettings.keySet())  {  if  (Regex.simpleMatch(dynamicSetting,  key))  {  return  true;  }  }  return  false;  }  public  String  validateDynamicSetting(String  dynamicSetting,  String  value)  {  for  (Map.Entry<String,  Validator>  setting  :  dynamicSettings.entrySet())  {              if  (Regex.simpleMatch(dynamicSetting,  setting.getKey()))  {              if  (Regex.simpleMatch(setting.getKey(),  dynamicSetting))  {  return  setting.getValue().validate(dynamicSetting,  value);  }  }  return  null;  }  public  synchronized  void  addDynamicSetting(String  setting,  Validator  validator)  {  MapBuilder<String,  Validator>  updatedSettings  =  MapBuilder.newMapBuilder(dynamicSettings);  	if  (Regex.simpleMatch(setting.getKey(),  dynamicSetting))  {  
elasticsearch_36edcef640b5213439e35f3da4b35321c85906c0	buggy:  options.withCompress();  context:  return  this.action;  }  sendResponse(message,  TransportResponseOptions.EMPTY);  }  if  (transport.compress)  {              options.withCompress();              options.withCompress(true);  }  byte[]  data  =  TransportStreams.buildResponse(requestId,  message,  options);  ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(data);  channel.write(buffer);  }  BytesStreamOutput  stream;  	options.withCompress(true);  
libgdx_709ac85ccaf5f2af98974a69d152b66f841972f4	buggy:  float  l2  =  tmp.sub(start.y,  start.y,  0).len2();  context:  public  static  float  distanceLinePoint  (Vector2  start,  Vector2  end,  Vector2  point)  {  tmp.set(end.x,  end.y,  0);  float  l2  =  tmp.sub(start.y,  start.y,  0).len2();  float  l2  =  tmp.sub(start.x,  start.y,  0).len2();  if  (l2  ==  0.0f)  //  start  ==  end  return  point.dst(start);  tmp.set(point.x,  point.y,  0);  tmp.sub(start.x,  start.y,  0);  tmp2.set(end.x,  end.y,  0);  tmp2.sub(start.x,  start.y,  0);  	float  l2  =  tmp.sub(start.x,  start.y,  0).len2();  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "At  least  one  filter  must  be  set  on  filter  aggregation  [ "  +  name  +   "] ");  context:  }  nonKeyedFilters.add(filter);  return  this;  }  protected  XContentBuilder  internalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject();  if  (keyedFilters  ==  null  &&  nonKeyedFilters  ==  null)  {              throw  new  SearchSourceBuilderException( "At  least  one  filter  must  be  set  on  filter  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "At  least  one  filter  must  be  set  on  filter  aggregation  [ "  +  getName()  +   "] ");  }  if  (keyedFilters  !=  null  &&  nonKeyedFilters  !=  null)  {  throw  new  SearchSourceBuilderException( "Cannot  add  both  keyed  and  non-keyed  filters  to  filters  aggregation ");  }  if  (keyedFilters  !=  null)  {  builder.startObject( "filters ");  for  (Map.Entry<String,  FilterBuilder>  entry  :  keyedFilters.entrySet())  {  	throw  new  SearchSourceBuilderException( "At  least  one  filter  must  be  set  on  filter  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_a09ed1468cec63e5d0fd32b78c9f181f80c45fb2	buggy:  for  (FormatDateTimeFormatter  dateTimeFormatter  :  context.root().dateTimeFormatters())  {  context:  }  BuilderContext  builderContext  =  new  BuilderContext(context.path());  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  String  text  =  context.parser().text();  boolean  resolved  =  false;  if  (context.root().dateDetection())  {  if  (text.contains( ": ")  ||  text.contains( "- ")  ||  text.contains( "/ "))  {                          for  (FormatDateTimeFormatter  dateTimeFormatter  :  context.root().dateTimeFormatters())  {                          for  (FormatDateTimeFormatter  dateTimeFormatter  :  context.root().dynamicDateTimeFormatters())  {  try  {  dateTimeFormatter.parser().parseMillis(text);  Mapper.Builder  builder  =  context.root().findTemplateBuilder(context,  currentFieldName,   "date ");  if  (builder  ==  null)  {  builder  =  dateField(currentFieldName).dateTimeFormatter(dateTimeFormatter);  }  mapper  =  builder.build(builderContext);  resolved  =  true;  	for  (FormatDateTimeFormatter  dateTimeFormatter  :  context.root().dynamicDateTimeFormatters())  {  
elasticsearch_7aa2d11cdd657f7ed2175a0f4ffecaf230ca449c	buggy:  createIndexAction.execute(new  CreateIndexRequest(index).cause( "auto(bulk  api) ").masterNodeTimeout(bulkRequest.timeout()),  new  ActionListener<CreateIndexResponse>()  {  context:  }  }  else  {  throw  new  ElasticsearchException( "Parsed  unknown  request  in  bulk  actions:   "  +  request.getClass().getSimpleName());  }  }  final  AtomicInteger  counter  =  new  AtomicInteger(indices.size());  ClusterState  state  =  clusterService.state();  for  (final  String  index  :  indices)  {  if  (autoCreateIndex.shouldAutoCreate(index,  state))  {                      createIndexAction.execute(new  CreateIndexRequest(index).cause( "auto(bulk  api) ").masterNodeTimeout(bulkRequest.timeout()),  new  ActionListener<CreateIndexResponse>()  {                      createIndexAction.execute(new  CreateIndexRequest(bulkRequest).index(index).cause( "auto(bulk  api) ").masterNodeTimeout(bulkRequest.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  if  (counter.decrementAndGet()  ==  0)  {  executeBulk(bulkRequest,  startTime,  listener,  responses);  }  }  	createIndexAction.execute(new  CreateIndexRequest(bulkRequest).index(index).cause( "auto(bulk  api) ").masterNodeTimeout(bulkRequest.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_3afe4da55078e7b14eb4f7ef38d897c7f0f7f13d	buggy:  querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceLength);  context:  super.operationThreading(operationThreading);  return  this;  }  if  (querySourceUnsafe)  {              querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceLength);              querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceOffset  +  querySourceLength);  querySourceOffset  =  0;  querySourceUnsafe  =  false;  }  }  	querySource  =  Arrays.copyOfRange(querySource,  querySourceOffset,  querySourceOffset  +  querySourceLength);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  hud  =  new  Stage(480,  320,  true);  context:  }  cameraController  =  new  CameraInputController(tests[testIndex].camera);  cameraController.activateKey  =  Keys.CONTROL_LEFT;  cameraController.autoUpdate  =  false;  cameraController.forwardTarget  =  false;  cameraController.translateTarget  =  false;  Gdx.input.setInputProcessor(new  InputMultiplexer(cameraController,  this,  new  GestureDetector(this)));  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  hud  =  new  Stage(480,  320,  true);  hud  =  new  Stage();  hud.addActor(fpsLabel  =  new  Label( "   ",  new  Label.LabelStyle(font,  Color.WHITE)));  fpsLabel.setPosition(0,  0);  hud.addActor(titleLabel  =  new  Label(tests[testIndex].getClass().getSimpleName(),  new  Label.LabelStyle(font,  Color.WHITE)));  titleLabel.setY(hud.getHeight()  -  titleLabel.getHeight());  hud.addActor(instructLabel  =  new  Label( "A\nB\nC\nD\nE\nF ",  new  Label.LabelStyle(font,  Color.WHITE)));  instructLabel.setY(titleLabel.getY()  -  instructLabel.getHeight());  instructLabel.setAlignment(Align.top  |  Align.left);  instructLabel.setText(tests[testIndex].instructions);  	hud  =  new  Stage();  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper);  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  ==  null  ||  !smartNameFieldMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  mapping  for  field  [ "  +  fieldName  +   "] ");  }  FieldMapper  mapper  =  smartNameFieldMappers.mapper();  if  (!(mapper  instanceof  NumberFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "Field  [ "  +  fieldName  +   "]  is  not  a  numeric  type ");  }          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper);          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  
elasticsearch_f9eeb372112dda10187f6e1394b23088c02eca0b	buggy:  XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(source);  context:  builder.copyCurrentStructure(parser);  }  finally  {  parser.close();  }  }  }  else  {  XContentType  contentType  =  XContentFactory.xContentType(source,  offset,  length);  if  (contentType  ==  builder.contentType())  {  builder.rawField( "_source ",  source,  offset,  length);  }  else  {                  XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(source);                  XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(source,  offset,  length);  try  {  parser.nextToken();  builder.field( "_source ");  builder.copyCurrentStructure(parser);  }  finally  {  parser.close();  }  }  	XContentParser  parser  =  XContentFactory.xContent(contentType).createParser(source,  offset,  length);  
elasticsearch_d1d3f8c4ca39471ff551330eea508d31d9aea2ea	buggy:  channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));  context:  builder.startObject( "nodes ");  for  (DiscoveryNode  node  :  response.nodes())  {  builder.startObject(node.id());  builder.field( "name ",  node.name());  builder.endObject();  }  builder.endObject();  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  
libgdx_cff4b2ae3ba995fba4b36118ba72352326411697	buggy:  if  (file.canWrite())  return  true;  //  File  exists  and  is  writable.  context:  file  =  new  File( ".temp/ "  +  dirName,  fileName);  if  (canWrite(file))  return  file;  return  idealFile;  //  Will  likely  fail,  but  we  did  our  best.  }  private  boolean  canWrite  (File  file)  {  if  (file.canWrite())  return  true;  //  File  exists  and  is  writable.  if  (file.canWrite()  &&  file.canExecute())  return  true;  //  File  exists  and  is  writable.  File  parent  =  file.getParentFile();  parent.mkdirs();  if  (!parent.isDirectory())  return  false;  try  {  new  FileOutputStream(file).close();  file.delete();  return  true;  }  catch  (Throwable  ex)  {  	if  (file.canWrite()  &&  file.canExecute())  return  true;  //  File  exists  and  is  writable.  
elasticsearch_d150ac2da418d30c5cfbabe47f27cc31e6f5b397	buggy:  invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));  context:  }  }  private  void  innerFinishHim()  {  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  dfsResults);  }              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_59ecfd67e89688467998b6e54139f0ff150efbe7	buggy:  builder.field( "index ",  fieldType.indexed());  context:  return  builder;  }  builder.startObject(contentType());  if  (includeDefaults  ||  !name().equals(Defaults.NAME))  {  builder.field( "name ",  name());  }  if  (includeDefaults  ||  nullValue  !=  null)  {  builder.field( "null_value ",  nullValue);  }  if  (includeDefaults  ||  fieldType.indexed()  !=  Defaults.FIELD_TYPE.indexed())  {              builder.field( "index ",  fieldType.indexed());              builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  }  if  (includeDefaults  ||  fieldType.stored()  !=  Defaults.FIELD_TYPE.stored())  {  builder.field( "store ",  fieldType.stored());  }  if  (customFieldDataSettings  !=  null)  {  builder.field( "fielddata ",  (Map)  customFieldDataSettings.getAsMap());  }  else  if  (includeDefaults)  {  builder.field( "fielddata ",  (Map)  fieldDataType.getSettings().getAsMap());  	builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(DeleteIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  DeleteIndexRequest  request,  final  ClusterState  state,  final  ActionListener<DeleteIndexResponse>  listener)  throws  ElasticsearchException  {          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  if  (request.indices().length  ==  0)  {  listener.onResponse(new  DeleteIndexResponse(true));  return;  }  final  CountDown  count  =  new  CountDown(request.indices().length);  for  (final  String  index  :  request.indices())  {  deleteIndexService.deleteIndex(new  MetaDataDeleteIndexService.Request(index).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataDeleteIndexService.Listener()  {  	request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  context:  snapshotsStatusResponse.masterNodeTimeout(request.paramAsTime( "master_timeout ",  snapshotsStatusResponse.masterNodeTimeout()));  client.admin().cluster().snapshotsStatus(snapshotsStatusResponse,  new  AbstractRestResponseActionListener<SnapshotsStatusResponse>(request,  channel,  logger)  {  public  void  onResponse(SnapshotsStatusResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                      channel.sendResponse(new  BytesRestResponse(OK,  builder));  }  catch  (IOException  e)  {  onFailure(e);  }  }  });  }  }  	channel.sendResponse(new  BytesRestResponse(OK,  builder));  
elasticsearch_95fc7a39a36f62a87676d16130fdcc68aaa6a393	buggy:  receivedResponses.put(sendPingsHandler.id(),  new  ConcurrentHashMap<DiscoveryNode,  PingResponse>());  context:  latch.await();  return  response.get();  }  catch  (InterruptedException  e)  {  return  null;  }  }  public  void  ping(final  PingListener  listener,  final  TimeValue  timeout)  throws  ElasticSearchException  {  final  SendPingsHandler  sendPingsHandler  =  new  SendPingsHandler(pingIdGenerator.incrementAndGet());          receivedResponses.put(sendPingsHandler.id(),  new  ConcurrentHashMap<DiscoveryNode,  PingResponse>());          receivedResponses.put(sendPingsHandler.id(),  ConcurrentCollections.<DiscoveryNode,  PingResponse>newConcurrentMap());  sendPings(timeout,  null,  sendPingsHandler);  threadPool.schedule(TimeValue.timeValueMillis(timeout.millis()  /  2),  ThreadPool.Names.GENERIC,  new  Runnable()  {  public  void  run()  {  sendPings(timeout,  null,  sendPingsHandler);  threadPool.schedule(TimeValue.timeValueMillis(timeout.millis()  /  2),  ThreadPool.Names.GENERIC,  new  Runnable()  {  public  void  run()  {  	receivedResponses.put(sendPingsHandler.id(),  ConcurrentCollections.<DiscoveryNode,  PingResponse>newConcurrentMap());  
elasticsearch_fb53784e3b6763cc47a6f5cc811989fd78ac56ee	buggy:  logger.trace( "{}:  {} ",  component,  message);  context:  public  final  class  LoggerInfoStream  extends  InfoStream  {  private  final  ESLogger  logger;  public  LoggerInfoStream(Settings  settings,  ShardId  shardId)  {  }  public  void  message(String  component,  String  message)  {          logger.trace( "{}:  {} ",  component,  message);          logger.trace( "{}  {}:  {} ",  Thread.currentThread().getName(),  component,  message);  }  public  boolean  isEnabled(String  component)  {  return  logger.isTraceEnabled()  &&  component.equals( "TP ")  ==  false;  }  	logger.trace( "{}  {}:  {} ",  Thread.currentThread().getName(),  component,  message);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<TextFragment>  fragsList  =  new  ArrayList<TextFragment>();  context:  entry  =  new  org.apache.lucene.search.highlight.Highlighter(formatter,  encoder,  queryScorer);  entry.setTextFragmenter(fragmenter);  entry.setMaxDocCharsToAnalyze(Integer.MAX_VALUE);  cache.put(mapper,  entry);  }  int  numberOfFragments  =  field.fieldOptions().numberOfFragments()  ==  0  ?  1  :  field.fieldOptions().numberOfFragments();          ArrayList<TextFragment>  fragsList  =  new  ArrayList<TextFragment>();          ArrayList<TextFragment>  fragsList  =  new  ArrayList<>();  List<Object>  textsToHighlight;  try  {  textsToHighlight  =  HighlightUtils.loadFieldValues(field,  mapper,  context,  hitContext);  for  (Object  textToHighlight  :  textsToHighlight)  {  String  text  =  textToHighlight.toString();  Analyzer  analyzer  =  context.mapperService().documentMapper(hitContext.hit().type()).mappers().indexAnalyzer();  	ArrayList<TextFragment>  fragsList  =  new  ArrayList<>();  
elasticsearch_e7a8da8236415000e0dcdeb5622eb01ab9b086d0	buggy:  indexShard.performRecoveryFinalization();  context:  class  FinalizeRecoveryRequestHandler  extends  BaseTransportRequestHandler<VoidStreamable>  {  return  VoidStreamable.INSTANCE;  }  receiveSnapshotRecoveryThread  =  Thread.currentThread();  try  {                  indexShard.performRecoveryFinalization();                  indexShard.performRecoveryFinalization(false);  channel.sendResponse(VoidStreamable.INSTANCE);  }  finally  {  receiveSnapshotRecoveryThread  =  null;  }  }  }  class  TranslogOperationsRequestHandler  extends  BaseTransportRequestHandler<TranslogOperationsRequest>  {  	indexShard.performRecoveryFinalization(false);  
elasticsearch_ec6fa83856654d33f5939cc6e530f6b70149b9ae	buggy:  if  (context.includeInAll(includeInAll))  {  context:  if  (value  !=  null)  {  LongFieldMapper.CustomLongNumericField  field  =  new  LongFieldMapper.CustomLongNumericField(this,  value);  field.setBoost(boost);  return  field;  }  if  (dateAsString  ==  null)  {  return  null;  }          if  (context.includeInAll(includeInAll))  {          if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  dateAsString,  boost);  }  value  =  parseStringValue(dateAsString);  LongFieldMapper.CustomLongNumericField  field  =  new  LongFieldMapper.CustomLongNumericField(this,  value);  field.setBoost(boost);  return  field;  }  	if  (context.includeInAll(includeInAll,  this))  {  
elasticsearch_c6683d23ef4f5c0bc2f53696b79304d3ab18fd4b	buggy:  rootObjectMapper.mergeMapping(jsonMergeWith.rootObjectMapper,  mergeFlags);  context:  fieldMapperListener.fieldMapper(typeFieldMapper);  fieldMapperListener.fieldMapper(idFieldMapper);  fieldMapperListener.fieldMapper(uidFieldMapper);  rootObjectMapper.traverse(fieldMapperListener);  }  }  }  JsonDocumentMapper  jsonMergeWith  =  (JsonDocumentMapper)  mergeWith;          rootObjectMapper.mergeMapping(jsonMergeWith.rootObjectMapper,  mergeFlags);          rootObjectMapper.mergeMapping(this,  jsonMergeWith.rootObjectMapper,  mergeFlags);  if  (!mergeFlags.simulate())  {  mappingSource  =  buildSource();  }  }  try  {  	rootObjectMapper.mergeMapping(this,  jsonMergeWith.rootObjectMapper,  mergeFlags);  
libgdx_7f8d8ae28dfeb1dbc59b86a741845809cf4013fb	buggy:  GdxTest  test  =  new  MD5Test();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  MD5Test();  GdxTest  test  =  new  InputTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  InputTest();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  =  new  ArrayList<TypeListenerBinding>(parentBindings.size()  +  1);  context:  return  matchingConverter;  }  public  void  addTypeListener(TypeListenerBinding  listenerBinding)  {  listenerBindings.add(listenerBinding);  }  public  List<TypeListenerBinding>  getTypeListenerBindings()  {  List<TypeListenerBinding>  parentBindings  =  parent.getTypeListenerBindings();  List<TypeListenerBinding>  result                  =  new  ArrayList<TypeListenerBinding>(parentBindings.size()  +  1);                  =  new  ArrayList<>(parentBindings.size()  +  1);  result.addAll(parentBindings);  result.addAll(listenerBindings);  return  result;  }  public  void  blacklist(Key<?>  key)  {  parent.blacklist(key);  blacklistedKeys.add(key);  	=  new  ArrayList<>(parentBindings.size()  +  1);  
libgdx_2d2f6ff1e3b1a4329ed6801920ce4c365cb529fb	buggy:  new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ",  null,  new  String[]  {   "**/BulletBuild.java "  });  context:  public  class  BulletBuild  {  public  static  void  main(String[]  args)  throws  Exception  {  new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ",  null,  new  String[]  {   "**/BulletBuild.java "  });  new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ");  String[]  excludes  =  {   "src/BulletMultiThreaded/GpuSoftBodySolvers/** "  };  String[]  headers  =  {   "src/ "  };  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  	new  NativeCodeGenerator().generate( "src ",   "bin ",   "jni ");  
elasticsearch_1eee7f381ae98744f1017ce3997798728e34c752	buggy:  builder.startObject(nodeStats.node().id());  context:  nodesStatsRequest.listenerThreaded(false);  client.admin().cluster().nodesStats(nodesStatsRequest,  new  ActionListener<NodesStatsResponse>()  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "cluster_name ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeStats  nodeStats  :  result)  {                          builder.startObject(nodeStats.node().id());                          builder.startObject(nodeStats.node().id(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "name ",  nodeStats.node().name());  if  (nodeStats.indices()  !=  null)  {  nodeStats.indices().toXContent(builder,  request);  }  if  (nodeStats.os()  !=  null)  {  	builder.startObject(nodeStats.node().id(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  if  ( "script_values_unique ".equals(currentFieldName))  {  context:  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {                  if  ( "script_values_unique ".equals(currentFieldName))  {                  if  ( "script_values_unique ".equals(currentFieldName)  ||   "scriptValuesUnique ".equals(currentFieldName))  {  assumeUnique  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  	if  ( "script_values_unique ".equals(currentFieldName)  ||   "scriptValuesUnique ".equals(currentFieldName))  {  
elasticsearch_e59b41398046371c7c2712d62098f8ed6ef02ef7	buggy:  TermsResponse  termsResponse  =  client.terms(termsRequest( "test ").fields( "value ")).actionGet();  context:  protected  Client  getClient()  {  return  client( "server2 ");  }  IndexStatus  indexStatus  =  client.admin().indices().status(indicesStatus( "test ")).actionGet().index( "test ");          TermsResponse  termsResponse  =  client.terms(termsRequest( "test ").fields( "value ")).actionGet();          TermsResponse  termsResponse  =  client.prepareTerms( "test ").setFields( "value ").execute().actionGet();  assertThat(termsResponse.successfulShards(),  equalTo(indexStatus.shards().size()));  assertThat(termsResponse.failedShards(),  equalTo(0));  assertThat(termsResponse.fieldsAsMap().isEmpty(),  equalTo(false));  assertThat( "no  term  freqs  for  the  'value'  since  nothing  is  indexed ",  termsResponse.field( "value ").iterator().hasNext(),  equalTo(false));  client.index(indexRequest( "test ").type( "type1 ").id( "1 ").source(jsonBuilder().startObject().field( "value ",   "aaa ").endObject())).actionGet();  	TermsResponse  termsResponse  =  client.prepareTerms( "test ").setFields( "value ").execute().actionGet();  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  Sound  sound;  float  volume  =  0.5f;  long  soundId  =  0;  Stage  ui;  Skin  skin;  public  void  create  ()  {  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.mp3 ",  FileType.Internal));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  TextButton  play  =  new  TextButton( "Play ",  skin);  TextButton  stop  =  new  TextButton( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  final  Slider  volume  =  new  Slider(0.1f,  1,  0.1f,  skin);  volume.setValue(1);  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_689fd15d786428869a7e311ef6c42f0094ae45a9	buggy:  GeoPoint.parse(parser,  point);  context:  DistanceUnit  unit  =  DistanceUnit.DEFAULT;  GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  String  optimizeBbox  =   "memory ";  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  fieldName  =  currentFieldName;                  GeoPoint.parse(parser,  point);                  GeoUtils.parseGeoPoint(parser,  point);  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  String  currentName  =  parser.currentName();  fieldName  =  currentFieldName;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentName  =  parser.currentName();  }  else  if  (token.isValue())  {  	GeoUtils.parseGeoPoint(parser,  point);  
libgdx_3b6392d290f3c31970b0dd65855b30e97907cc70	buggy:  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/test2_notwork.wav ",  FileType.Internal));  context:  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  font.draw(batch,   "Position:   "  +  music.getPosition(),  30,  146);  batch.end();  }  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/test2_notwork.wav ",  FileType.Internal));  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/sell_buy_item.wav ",  FileType.Internal));  music  =  Gdx.audio.newMusic(Gdx.files.getFileHandle( "data/threeofaperfectpair.mp3 ",  FileType.Internal));  music.setVolume(volume);  music.play();  music.setLooping(true);  Gdx.input.setInputProcessor(this);  	sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/sell_buy_item.wav ",  FileType.Internal));  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.com  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.com  <em>http</em>://<em>cnn</em>.com  <em>http</em>://<em>quora</em>.com "));  context:  );  ensureGreen();  client().prepareIndex( "test ",   "test ",   "1 ")  .setSource( "body ",   "Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature  Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature ")  .get();  refresh();  SearchResponse  search  =  client().prepareSearch().setQuery(matchQuery( "body ",   "Test:  http://www.facebook.com   ").type(Type.PHRASE)).addHighlightedField( "body ").execute().actionGet();  assertHighlight(search,  0,   "body ",  0,  startsWith( "<em>Test:  http://www.facebook.com</em> "));  search  =  client().prepareSearch().setQuery(matchQuery( "body ",   "Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature  Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature ").type(Type.PHRASE)).addHighlightedField( "body ").execute().actionGet();          assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.com  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.com  <em>http</em>://<em>cnn</em>.com  <em>http</em>://<em>quora</em>.com "));          assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http://www.facebook.com</em>  <em>http://elasticsearch.org</em>  <em>http://xing.com</em>  <em>http://cnn.com</em>  http://quora.com "));  }  public  void  testNgramHighlightingPreLucene42()  throws  ElasticsearchException,  IOException  {  assertAcked(prepareCreate( "test ")  .addMapping( "test ",   "name ",   "type=string,index_analyzer=name_index_analyzer,search_analyzer=name_search_analyzer, "  +  randomStoreField()  +   "term_vector=with_positions_offsets ",  	assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http://www.facebook.com</em>  <em>http://elasticsearch.org</em>  <em>http://xing.com</em>  <em>http://cnn.com</em>  http://quora.com "));  
libgdx_696cc6ec4009217cb4f4eb791a7fbb529b11743d	buggy:  int  total  =  count  =  Math.min(available,  count);  context:  copy  =  Math.min(buffer.length  -  available,  count);  System.arraycopy(buffer,  readPosition,  data,  offset,  copy);  readPosition  =  (readPosition  +  copy)  %  buffer.length;  available  -=  copy;  }  return  total;  }  public  int  skip(int  count)  {  int  total  =  count  =  Math.min(available,  count);  int  total  =  Math.min(available,  count);  available  -=  total;  readPosition  =  (readPosition  +  total)  %  buffer.length;  return  total;  }  public  void  clear  ()  {  for  (int  i  =  0,  n  =  buffer.length;  i  <  n;  i++)  buffer[i]  =  0;  	int  total  =  Math.min(available,  count);  
elasticsearch_7b2e1b7b4f88c1270c10d6062401efc40b37d362	buggy:  channel.sendResponse(new  XContentRestResponse(request,  foundAny  ?  OK  :  NOT_FOUND,  builder));  context:  builder.field(mappingMd.type());  builder.map(mappingMd.sourceAsMap());  }  builder.endObject();  }  }  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  foundAny  ?  OK  :  NOT_FOUND,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  foundAny  ||  indices.length  ==  0  ?  OK  :  NOT_FOUND,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  	channel.sendResponse(new  XContentRestResponse(request,  foundAny  ||  indices.length  ==  0  ?  OK  :  NOT_FOUND,  builder));  
elasticsearch_fb9143aac1f51f8582c093908e3e4a327cdea073	buggy:  injector.getInstance(MapperService.class).add( "person ",  mapping,  true);  context:  new  IndexNameModule(index),  new  AbstractModule()  {  protected  void  configure()  {  bind(ClusterService.class).toProvider(Providers.of((ClusterService)  null));  }  }  ).createInjector();  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/test/unit/index/query/mapping.json ");          injector.getInstance(MapperService.class).add( "person ",  mapping,  true);          injector.getInstance(MapperService.class).merge( "person ",  mapping,  true);  injector.getInstance(MapperService.class).documentMapper( "person ").parse(new  BytesArray(copyToBytesFromClasspath( "/org/elasticsearch/test/unit/index/query/data.json ")));  this.queryParser  =  injector.getInstance(IndexQueryParserService.class);  }  public  void  close()  {  injector.getInstance(ThreadPool.class).shutdownNow();  }  	injector.getInstance(MapperService.class).merge( "person ",  mapping,  true);  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  sb.append( "    translog  :  id      [ ").append(lastTranslogId).append( "],  number_of_operations  [ ").append(snapshotStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.translog().time())).append( "] ");  context:  return  snapshotStatus;  }  return  null;  }  });  if  (snapshotStatus  !=  null)  {  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "snapshot  ( ").append(reason).append( ")  completed  to   ").append(shardGateway).append( ",  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.time())).append( "]\n ");  sb.append( "    index    :  version  [ ").append(lastIndexVersion).append( "],  number_of_files  [ ").append(snapshotStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(snapshotStatus.index().totalSize())).append( "],  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.index().time())).append( "]\n ");                      sb.append( "    translog  :  id      [ ").append(lastTranslogId).append( "],  number_of_operations  [ ").append(snapshotStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.translog().time())).append( "] ");                      sb.append( "    translog  :  id      [ ").append(lastTranslogId).append( "],  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.translog().time())).append( "] ");  }  }  }  catch  (SnapshotFailedEngineException  e)  {  if  (e.getCause()  instanceof  IllegalStateException)  {  }  else  {  throw  new  IndexShardGatewaySnapshotFailedException(shardId,   "Failed  to  snapshot ",  e);  	sb.append( "        translog  :  id            [ ").append(lastTranslogId).append( "],  took  [ ").append(TimeValue.timeValueMillis(snapshotStatus.translog().time())).append( "] ");  
elasticsearch_eef3a95fa644eb09f3832da1bb19e52498b81154	buggy:  cache.clear();  context:  private  final  Object  creationMutex  =  new  Object();  protected  AbstractConcurrentMapFieldDataCache(Index  index,  @IndexSettings  Settings  indexSettings)  {  super(index,  indexSettings);  this.cache  =  new  MapMaker().weakKeys().makeMap();  }          cache.clear();          clear();  }  cache.clear();  }  ConcurrentMap<String,  FieldData>  map  =  cache.remove(reader.getFieldCacheKey());  	clear();  
elasticsearch_976152b23e2fe0b658b5b7c3ed225ff76b0a798b	buggy:  e.printStackTrace();  context:  public  void  run()  {  boolean  restartWithWrapper  =  false;  if  (System.getProperty( "elasticsearch-service ")  !=  null)  {  try  {  Class  wrapperManager  =  settings.getClassLoader().loadClass( "org.tanukisoftware.wrapper.WrapperManager ");  wrapperManager.getMethod( "restartAndReturn ").invoke(null);  restartWithWrapper  =  true;  }  catch  (Throwable  e)  {                          e.printStackTrace();                          logger.error( "failed  to  initial  restart  on  service  wrapper ",  e);  }  }  if  (!restartWithWrapper)  {  try  {  node.stop();  node.start();  }  catch  (Exception  e)  {  	logger.error( "failed  to  initial  restart  on  service  wrapper ",  e);  
libgdx_f47a4fb26ae465876ae0e62a89d199e760c88083	buggy:  ((Image)actor).color.a  =  (float)Math.random();  context:  gl.glViewport(  0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight()  );  gl.glClear(  GL10.GL_COLOR_BUFFER_BIT  );  if(  Gdx.input.isTouched()  )  {  Actor  actor  =  stage.hit(  Gdx.input.getX(),  Gdx.input.getY()  );  if(  actor  !=  null  )  {  if(  actor  instanceof  Image  )  {  ((Image)actor).color.a  =  (float)Math.random();  ((Image)actor).color.b  =  (float)Math.random();  }  }  }  stage.findActor(   "img2 "  ).rotation  +=  20  *  Gdx.graphics.getDeltaTime();  stage.render(  );  }  	((Image)actor).color.b  =  (float)Math.random();  
elasticsearch_e7a892f6f06105e78984a04d919523a8c6ef73e9	buggy:  if  (indexShard.routingEntry().primary()  &&  indexShard.state()  ==  IndexShardState.STARTED  &&  indexShard.routingEntry().started())  {  context:  boolean  hasTTLEnabled  =  false;  for  (FieldMapper  ttlFieldMapper  :  ttlFieldMappers)  {  if  (((TTLFieldMapper)  ttlFieldMapper).enabled())  {  hasTTLEnabled  =  true;  break;  }  }  if  (hasTTLEnabled)  {  for  (IndexShard  indexShard  :  indexService)  {                          if  (indexShard.routingEntry().primary()  &&  indexShard.state()  ==  IndexShardState.STARTED  &&  indexShard.routingEntry().started())  {                          if  (indexShard.state()  ==  IndexShardState.STARTED  &&  indexShard.routingEntry().primary()  &&  indexShard.routingEntry().started())  {  shardsToPurge.add(indexShard);  }  }  }  }  return  shardsToPurge;  }  }  	if  (indexShard.state()  ==  IndexShardState.STARTED  &&  indexShard.routingEntry().primary()  &&  indexShard.routingEntry().started())  {  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);  context:  }  }  }  if  (queryName  !=  null)  {  parseContext.addNamedQuery(queryName,  chosenQuery);  }  return  chosenQuery;  }  protected  boolean  matchesIndices(String  currentIndex,  String...  indices)  {          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  for  (String  index  :  concreteIndices)  {  if  (Regex.simpleMatch(index,  currentIndex))  {  return  true;  }  }  return  false;  }  }  	final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  
elasticsearch_41bcb3e0d31712bd5cb4540493b4862b701517b5	buggy:  cluster().stopRandomDataNode();  context:  do  {  numHits  +=  searchResponse.getHits().hits().length;  searchResponse  =  client()  .prepareSearchScroll(searchResponse.getScrollId()).setScroll(TimeValue.timeValueMinutes(1))  .get();  assertAllSuccessful(searchResponse);  }  while  (searchResponse.getHits().hits().length  >  0);  assertThat(numHits,  equalTo(100l));  clearScroll( "_all ");          cluster().stopRandomDataNode();          cluster().stopRandomNonMasterNode();  searchResponse  =  client().prepareSearch()  .setQuery(matchAllQuery())  .setSize(10)  .setScroll(TimeValue.timeValueMinutes(1))  .get();  assertThat(searchResponse.getSuccessfulShards(),  lessThan(searchResponse.getTotalShards()));  numHits  =  0;  	cluster().stopRandomNonMasterNode();  
elasticsearch_b7d3f8fc99b50f35461d26c9ece7682256a6eb2a	buggy:  replicaCounter  =  -100;  context:  postPrimaryOperation(request,  response);  listener.onResponse(response.response());  return;  }  if  (replicationType  ==  ReplicationType.ASYNC)  {  postPrimaryOperation(request,  response);  listener.onResponse(response.response());                  replicaCounter  =  -100;                  replicaCounter  =  Integer.MIN_VALUE;  }  replicaCounter++;  AtomicInteger  counter  =  new  AtomicInteger(replicaCounter);  shardIt.reset();  //  reset  the  iterator  ShardRouting  shard;  	replicaCounter  =  Integer.MIN_VALUE;  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  return  new  ScriptDocValues.Strings(getBytesValues(false));  context:  SortedSetDVBytesAtomicFieldData(AtomicReader  reader,  String  field)  {  super(reader,  field);  }  public  Strings  getScriptValues()  {          return  new  ScriptDocValues.Strings(getBytesValues(false));          return  new  ScriptDocValues.Strings(getBytesValues());  }  }  	return  new  ScriptDocValues.Strings(getBytesValues());  
elasticsearch_4ff3e1926b0b0a092a9fcb70f47fb49977ec2d70	buggy:  return  ScriptDocValues.EMPTY;  context:  return  BytesValues.EMPTY;  }  public  GeoPointValues  getGeoPointValues()  {  return  GeoPointValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {              return  ScriptDocValues.EMPTY;              return  ScriptDocValues.EMPTY_GEOPOINTS;  }  public  int  getNumDocs()  {  return  numDocs;  }  	return  ScriptDocValues.EMPTY_GEOPOINTS;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalTermsStatsStringFacet.StringEntry>  stringEntries  =  new  ArrayList<InternalTermsStatsStringFacet.StringEntry>();  context:  }  public  InternalFacet  buildFacet(String  facetName)  {  if  (entries.v().isEmpty())  {  entries.release();  return  new  InternalTermsStatsStringFacet(facetName,  comparatorType,  size,  ImmutableList.<InternalTermsStatsStringFacet.StringEntry>of(),  missing);  }  if  (size  ==  0)  {  //  all  terms              List<InternalTermsStatsStringFacet.StringEntry>  stringEntries  =  new  ArrayList<InternalTermsStatsStringFacet.StringEntry>();              List<InternalTermsStatsStringFacet.StringEntry>  stringEntries  =  new  ArrayList<>();  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  stringEntries.add((InternalTermsStatsStringFacet.StringEntry)  values[i]);  }  }  return  new  InternalTermsStatsStringFacet(facetName,  comparatorType,  0  /*  indicates  all  terms*/,  stringEntries,  missing);  	List<InternalTermsStatsStringFacet.StringEntry>  stringEntries  =  new  ArrayList<>();  
libgdx_08afc1a9bfdea372c2f0854de23fe293f3868637	buggy:  if  (anim  !=  null  &&  current.animation  ==  anim.animation)  context:  return  setAnimation(obtain(anim,  offset,  duration,  loopCount,  speed,  listener));  }  protected  AnimationDesc  setAnimation(final  AnimationDesc  anim)  {  if  (updating)  //  FIXME  Remove  this?  Just  intended  for  debugging  throw  new  GdxRuntimeException( "Cannot  change  animation  during  update ");  if  (current  ==  null)  current  =  anim;  else  {  if  (anim  !=  null  &&  current.animation  ==  anim.animation)  if  (!allowSameAnimation  &&  anim  !=  null  &&  current.animation  ==  anim.animation)  anim.time  =  current.time;  else  removeAnimation(current.animation);  animationPool.free(current);  current  =  anim;  }  justChangedAnimation  =  true;  return  anim;  	if  (!allowSameAnimation  &&  anim  !=  null  &&  current.animation  ==  anim.animation)  
elasticsearch_30c6f2fa23c9db62acdbc7d7bfb643e8182c4d67	buggy:  assertThat(routingNode.shards().size(),  equalTo(1));  context:  routingNodes  =  clusterState.routingNodes();  prevRoutingTable  =  routingTable;  routingTable  =  strategy.applyStartedShards(clusterState,  routingNodes.shardsWithState(INITIALIZING)).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  routingNodes  =  clusterState.routingNodes();  assertThat(routingTable.shardsWithState(STARTED).size(),  equalTo(10));  for  (RoutingNode  routingNode  :  routingNodes)  {              assertThat(routingNode.shards().size(),  equalTo(1));              assertThat(routingNode.size(),  equalTo(1));  }  }  }  	assertThat(routingNode.size(),  equalTo(1));  
elasticsearch_d1a4989e84365fbd280f383145a6a13e7fd6b615	buggy:  return  os.unsafeByteArray();  context:  }  }  }  }  private  byte[]  nodeMessagePayload()  throws  IOException  {  ByteArrayDataOutputStream  os  =  new  ByteArrayDataOutputStream();  localNode.writeTo(os);  os.close();          return  os.unsafeByteArray();          return  os.copiedByteArray();  }  private  void  sendInitialStateEventIfNeeded()  {  if  (initialStateSent.compareAndSet(false,  true))  {  for  (InitialStateDiscoveryListener  listener  :  initialStateListeners)  {  listener.initialStateProcessed();  }  }  	return  os.copiedByteArray();  
elasticsearch_3e430c2ca9015fc397043f79ccc74ae21ac51e32	buggy:  pipeline.addLast( "decoder ",  new  TextMemcachedDecoder());  context:  serverBootstrap  =  new  ServerBootstrap(new  NioServerSocketChannelFactory(  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcachedBoss ")),  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcachedIoWorker ")),  workerCount));  ChannelPipelineFactory  pipelineFactory  =  new  ChannelPipelineFactory()  {  ChannelPipeline  pipeline  =  Channels.pipeline();  pipeline.addLast( "openChannels ",  serverOpenChannels);                  pipeline.addLast( "decoder ",  new  TextMemcachedDecoder());                  pipeline.addLast( "decoder ",  new  MemcachedDecoder());  pipeline.addLast( "dispatcher ",  new  MemcachedDispatcher(restController));  return  pipeline;  }  };  serverBootstrap.setPipelineFactory(pipelineFactory);  if  (tcpNoDelay  !=  null)  {  	pipeline.addLast( "decoder ",  new  MemcachedDecoder());  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  indicesService.createIndex(request.index,  actualIndexSettings,  clusterService.state().nodes().localNode().id());  context:  indexSettingsBuilder.put(SETTING_AUTO_EXPAND_REPLICAS,  settings.get(SETTING_AUTO_EXPAND_REPLICAS));  }  indexSettingsBuilder.put(SETTING_VERSION_CREATED,  version);  Settings  actualIndexSettings  =  indexSettingsBuilder.build();                      indicesService.createIndex(request.index,  actualIndexSettings,  clusterService.state().nodes().localNode().id());                      indicesService.createIndex(request.index,  actualIndexSettings,  clusterService.localNode().id());  indexCreated  =  true;  IndexService  indexService  =  indicesService.indexServiceSafe(request.index);  MapperService  mapperService  =  indexService.mapperService();  if  (mappings.containsKey(MapperService.DEFAULT_MAPPING))  {  try  {  mapperService.merge(MapperService.DEFAULT_MAPPING,  XContentFactory.jsonBuilder().map(mappings.get(MapperService.DEFAULT_MAPPING)).string(),  false);  	indicesService.createIndex(request.index,  actualIndexSettings,  clusterService.localNode().id());  
elasticsearch_99d31cc8c84d0f55c9c052b2875bc2002b85d7b9	buggy:  this.serverOpenChannels  =  new  OpenChannelsHandler();  context:  this.reuseAddress  =  componentSettings.getAsBoolean( "reuse_address ",  settings.getAsBoolean(TCP_REUSE_ADDRESS,  NetworkUtils.defaultReuseAddress()));  this.tcpSendBufferSize  =  componentSettings.getAsBytesSize( "tcp_send_buffer_size ",  settings.getAsBytesSize(TCP_SEND_BUFFER_SIZE,  TCP_DEFAULT_SEND_BUFFER_SIZE));  this.tcpReceiveBufferSize  =  componentSettings.getAsBytesSize( "tcp_receive_buffer_size ",  settings.getAsBytesSize(TCP_RECEIVE_BUFFER_SIZE,  TCP_DEFAULT_RECEIVE_BUFFER_SIZE));  }  return  boundAddress;  }          this.serverOpenChannels  =  new  OpenChannelsHandler();          this.serverOpenChannels  =  new  OpenChannelsHandler(logger);  if  (blockingServer)  {  serverBootstrap  =  new  ServerBootstrap(new  OioServerSocketChannelFactory(  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcached_server_boss ")),  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "memcached_server_worker "))  ));  }  else  {  serverBootstrap  =  new  ServerBootstrap(new  NioServerSocketChannelFactory(  	this.serverOpenChannels  =  new  OpenChannelsHandler(logger);  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  public  class  TextButtonTest  extends  GdxTest  {  private  Stage  stage;  private  Skin  skin;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false,  new  SpriteBatch());  Gdx.input.setInputProcessor(stage);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  for  (int  i  =  0;  i  <  500;  i++)  {  TextButton  t  =  new  TextButton( "Button "+i,  skin);  t.setX(MathUtils.random(0,  Gdx.graphics.getWidth()));  t.setY(MathUtils.random(0,  Gdx.graphics.getHeight()));  t.setWidth(MathUtils.random(50,  200));  t.setHeight(MathUtils.random(0,  100));  stage.addActor(t);  }  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  dir.mul(-1);  context:  this.maxDist  =  maxDist;  platform.setTransform(pos,  0);  platform.getFixtureList().get(0).setUserData( "p ");  platform.setAngularVelocity(da);  platform.setUserData(this);  }  public  void  update  (float  deltaTime)  {  dist  +=  dir.len()  *  deltaTime;  if  (dist  >  maxDist)  {  dir.mul(-1);  dir.scl(-1);  dist  =  0;  }  platform.setLinearVelocity(dir);  }  }  }  	dir.scl(-1);  
libgdx_777834757f63b7171f81abd206b1b316a39528ff	buggy:  if  (keyCode  ==  Input.Keys.KEYCODE_COMMA)  {  context:  body.createFixture(fd);  }  shape.dispose();  }  m_bullet  =  null;  }  if  (keyCode  ==  Input.Keys.KEYCODE_COMMA)  {  if  (keyCode  ==  Input.Keys.COMMA)  {  if  (m_bullet  !=  null)  {  world.destroyBody(m_bullet);  m_bullet  =  null;  }  {  CircleShape  shape  =  new  CircleShape();  shape.setRadius(0.25f);  	if  (keyCode  ==  Input.Keys.COMMA)  {  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (ByteFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
libgdx_0503f9f5a79595161970794e1c02e0d1634cc99e	buggy:  return  null;  context:  return  0;  }  public  long  getNativeHeap  ()  {  return  0;  }  public  Preferences  getPreferences  (String  name)  {  return  null;  return  new  IOSPreferences();  }  public  void  postRunnable  (Runnable  runnable)  {  }  public  void  exit  ()  {  	return  new  IOSPreferences();  
elasticsearch_2eeb609353070fd518b5a9a0774c63c8892bc110	buggy:  return  ThreadPool.Names.MANAGEMENT;  context:  public  TransportRefreshAction(Settings  settings,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }  protected  String  executor()  {          return  ThreadPool.Names.MANAGEMENT;          return  ThreadPool.Names.REFRESH;  }  protected  String  transportAction()  {  return  RefreshAction.NAME;  }  	return  ThreadPool.Names.REFRESH;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ObjectIntOpenHashMap<String>  nodeCounts  =  new  ObjectIntOpenHashMap<String>();  context:  changed  =  true;  break;  }  }  return  changed;  }  private  RoutingNode[]  sortedNodesLeastToHigh(RoutingAllocation  allocation)  {          final  ObjectIntOpenHashMap<String>  nodeCounts  =  new  ObjectIntOpenHashMap<String>();          final  ObjectIntOpenHashMap<String>  nodeCounts  =  new  ObjectIntOpenHashMap<>();  for  (RoutingNode  node  :  allocation.routingNodes())  {  for  (int  i  =  0;  i  <  node.size();  i++)  {  ShardRouting  shardRouting  =  node.get(i);  String  nodeId  =  shardRouting.relocating()  ?  shardRouting.relocatingNodeId()  :  shardRouting.currentNodeId();  nodeCounts.addTo(nodeId,  1);  }  }  RoutingNode[]  nodes  =  allocation.routingNodes().toArray();  	final  ObjectIntOpenHashMap<String>  nodeCounts  =  new  ObjectIntOpenHashMap<>();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<Token>  result  =  new  ArrayList<TermSuggester.Token>();  context:  return  new  String[]  { "term "};  }  public  SuggestContextParser  getContextParser()  {  return  new  TermSuggestParser(this);  }  private  List<Token>  queryTerms(SuggestionContext  suggestion,  CharsRef  spare)  throws  IOException  {          final  List<Token>  result  =  new  ArrayList<TermSuggester.Token>();          final  List<Token>  result  =  new  ArrayList<>();  final  String  field  =  suggestion.getField();  SuggestUtils.analyze(suggestion.getAnalyzer(),  suggestion.getText(),  field,  new  SuggestUtils.TokenConsumer()  {  public  void  nextToken()  {  Term  term  =  new  Term(field,  BytesRef.deepCopyOf(fillBytesRef(new  BytesRef())));  result.add(new  Token(term,  offsetAttr.startOffset(),  offsetAttr.endOffset()));  }  },  spare);  	final  List<Token>  result  =  new  ArrayList<>();  
elasticsearch_ede60df804a883d31379937e6eec9fa0afe67de4	buggy:  for  (float  v  :  (short[])  value)  {  context:  }  generator.writeEndArray();  }  else  if  (value  instanceof  float[])  {  generator.writeStartArray();  for  (float  v  :  (float[])  value)  {  generator.writeNumber(v);  }  generator.writeEndArray();  }  else  if  (value  instanceof  short[])  {  generator.writeStartArray();              for  (float  v  :  (short[])  value)  {              for  (short  v  :  (short[])  value)  {  generator.writeNumber(v);  }  generator.writeEndArray();  }  else  {  generator.writeString(value.toString());  	for  (short  v  :  (short[])  value)  {  
elasticsearch_3202af0dc15835f3980a3c357dbdfd14d45c129a	buggy:  logger.debug(shardIt.shardId()  +   ":  Failed  to  get  [{}] ",  failure,  request);  context:  }  private  void  perform(@Nullable  final  Exception  lastException)  {  final  ShardRouting  shardRouting  =  shardIt.nextOrNull();  if  (shardRouting  ==  null)  {  Exception  failure  =  lastException;  if  (failure  ==  null)  {  failure  =  new  NoShardAvailableActionException(shardIt.shardId(),   "No  shard  available  for  [ "  +  request  +   "] ");  }  else  {  if  (logger.isDebugEnabled())  {                          logger.debug(shardIt.shardId()  +   ":  Failed  to  get  [{}] ",  failure,  request);                          logger.debug(shardIt.shardId()  +   ":  Failed  to  execute  [{}] ",  failure,  request);  }  }  listener.onFailure(failure);  return;  }  if  (shardRouting.currentNodeId().equals(nodes.localNodeId()))  {  if  (request.operationThreaded())  {  	logger.debug(shardIt.shardId()  +   ":  Failed  to  execute  [{}] ",  failure,  request);  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  DoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  DoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  DoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  0,  new  FixedBitSet(1));              return  DoubleArrayAtomicFieldData.EMPTY;  }  final  TDoubleArrayList  values  =  new  TDoubleArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  DoubleArrayAtomicFieldData.EMPTY;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "  +  i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i  *  2)  .field( "location ",   "52.0945,  5.116 ")  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(geoDistance( "geo_dist ").field( "location ").point( "52.3760,  4.894 ").addRange( "0-100 ",  0.0,  100.0)))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/state ",  this);  }  client.admin().cluster().execState(new  ClusterStateRequest(),  new  ActionListener<ClusterStateResponse>()  {  try  {  ClusterState  state  =  response.state();                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.startObject( "metadata ");  builder.field( "maxNumberOfShardsPerNode ",  state.metaData().maxNumberOfShardsPerNode());  builder.startObject( "indices ");  for  (IndexMetaData  indexMetaData  :  state.metaData())  {  builder.startObject(indexMetaData.index());  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_09528610c1dcbd1f4cee78fa8549fde19783c897	buggy:  Document  doc  =  docMapper.parse(json).masterDoc();  context:  public  class  GenericStoreDynamicTemplateTests  {  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json ");  DocumentMapper  docMapper  =  MapperTests.newParser().parse(mapping);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json ");          Document  doc  =  docMapper.parse(json).masterDoc();          Document  doc  =  docMapper.parse(json).rootDoc();  Fieldable  f  =  doc.getFieldable( "name ");  assertThat(f.name(),  equalTo( "name "));  assertThat(f.stringValue(),  equalTo( "some  name "));  assertThat(f.isStored(),  equalTo(true));  FieldMappers  fieldMappers  =  docMapper.mappers().fullName( "name ");  assertThat(fieldMappers.mappers().size(),  equalTo(1));  	Document  doc  =  docMapper.parse(json).rootDoc();  
elasticsearch_7feb742a9b3e8a5bceaaf77e2767d116a858d07d	buggy:  max( "max_score ").script( "_doc.score() ")  context:  .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)  .setQuery(matchQuery( "text ",   "term  rare "))  .addAggregation(terms( "terms ")  .executionHint(randomExecutionHint())  .field( "group ")  .order(Terms.Order.aggregation( "max_score ",  false))  .subAggregation(  topHits( "hits ").setSize(1)  )  .subAggregation(                                          max( "max_score ").script( "_doc.score() ")                                          max( "max_score ").script( "_score.doubleValue() ")  )  )  .get();  assertSearchResponse(response);  Terms  terms  =  response.getAggregations().get( "terms ");  assertThat(terms,  notNullValue());  assertThat(terms.getName(),  equalTo( "terms "));  	max( "max_score ").script( "_score.doubleValue() ")  
libgdx_cb553906a6e25ef0073f29ba1bad66a1cca01cb1	buggy:  Table  table  =  new  Table( "ui ");  context:  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  Button  play  =  new  Button( "Play ",  skin);  Button  stop  =  new  Button( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  final  Slider  volume  =  new  Slider(0.1f,  1,  0.1f,  skin);  volume.setValue(1);  final  Label  volumeValue  =  new  Label( "1.0 ",  skin);  Table  table  =  new  Table( "ui ");  Table  table  =  new  Table();  final  Slider  pan  =  new  Slider(-1f,  1f,  0.1f,  skin);  pan.setValue(0);  final  Label  panValue  =  new  Label( "0.0 ",  skin);  table.width  =  Gdx.graphics.getWidth();  table.height  =  Gdx.graphics.getHeight();  table.align(Align.CENTER  |  Align.TOP);  table.add(play);  	Table  table  =  new  Table();  
elasticsearch_9becdb814a723e0cdc66ea52244035a5017fa1ca	buggy:  clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  context:  assertThat(shardDirectory( "server1 ",   "test ",  0).exists(),  equalTo(true));  assertThat(server2Shard.exists(),  equalTo(true));  assertThat(shardDirectory( "server3 ",   "test ",  0).exists(),  equalTo(true));  startNode( "server2 ");          clusterHealth  =  client1.admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();          clusterHealth  =  client( "server2 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  assertThat(shardDirectory( "server1 ",   "test ",  0).exists(),  equalTo(true));  assertThat(shardDirectory( "server2 ",   "test ",  0).exists(),  equalTo(false));  assertThat(shardDirectory( "server3 ",   "test ",  0).exists(),  equalTo(true));  }  	clusterHealth  =  client( "server2 ").admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  
elasticsearch_655cbb94409770c0c163d1be513e03c3eb259e01	buggy:  return  null;  context:  public  DocumentMapper  documentMapper(String  type)  {  return  mappers.get(type);  }  public  DocumentMapper  documentMapperWithAutoCreate(String  type)  {  DocumentMapper  mapper  =  mappers.get(type);  if  (mapper  !=  null)  {  return  mapper;  }  if  (!dynamic)  {              return  null;              throw  new  TypeMissingException(index,  type,   "typing  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");  }  synchronized  (mutex)  {  mapper  =  mappers.get(type);  if  (mapper  !=  null)  {  return  mapper;  }  add(type,  null);  	throw  new  TypeMissingException(index,  type,   "typing  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  builder.dateTimeFormatter(parseDateTimeFormatter(builder.name(),  fieldNode.toString()));  context:  parseField(builder,  builder.name,  node,  parserContext);  for  (Map.Entry<String,  Object>  entry  :  node.entrySet())  {  String  fieldName  =  Strings.toUnderscoreCase(entry.getKey());  Object  fieldNode  =  entry.getValue();  if  (fieldName.equals( "enabled "))  {  EnabledAttributeMapper  enabledState  =  nodeBooleanValue(fieldNode)  ?  EnabledAttributeMapper.ENABLED  :  EnabledAttributeMapper.DISABLED;  builder.enabled(enabledState);  }  else  if  (fieldName.equals( "path "))  {  builder.path(fieldNode.toString());  }  else  if  (fieldName.equals( "format "))  {                      builder.dateTimeFormatter(parseDateTimeFormatter(builder.name(),  fieldNode.toString()));                      builder.dateTimeFormatter(parseDateTimeFormatter(fieldNode.toString()));  }  else  if  (fieldName.equals( "default "))  {  builder.defaultTimestamp(fieldNode  ==  null  ?  null  :  fieldNode.toString());  }  }  return  builder;  }  }  	builder.dateTimeFormatter(parseDateTimeFormatter(fieldNode.toString()));  
elasticsearch_fef647cb92926c97107f506831bfbdc0b838e80c	buggy:  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());  context:  }  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices());                  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());                  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  MetaData.Builder  metaDataBuilder  =  MetaData.builder(currentState.metaData());  Set<String>  openIndices  =  Sets.newHashSet();  Set<String>  closeIndices  =  Sets.newHashSet();  for  (String  index  :  actualIndices)  {  if  (currentState.metaData().index(index).state()  ==  IndexMetaData.State.OPEN)  {  	RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  new  ShardSearchRequest().types(request.types()).nowInMillis(request.nowInMillis())  context:  protected  ShardValidateQueryResponse  shardOperation(ShardValidateQueryRequest  request)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.shardId().getIndex());  IndexQueryParserService  queryParserService  =  indexService.queryParserService();  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  boolean  valid;  String  explanation  =  null;  String  error  =  null;  DefaultSearchContext  searchContext  =  new  DefaultSearchContext(0,                  new  ShardSearchRequest().types(request.types()).nowInMillis(request.nowInMillis())                  new  ShardSearchRequest(request).types(request.types()).nowInMillis(request.nowInMillis())  .filteringAliases(request.filteringAliases()),  null,  indexShard.acquireSearcher( "validate_query "),  indexService,  indexShard,  scriptService,  cacheRecycler,  pageCacheRecycler,  bigArrays  );  SearchContext.setCurrent(searchContext);  try  {  if  (request.source()  !=  null  &&  request.source().length()  >  0)  {  searchContext.parsedQuery(queryParserService.parseQuery(request.source()));  	new  ShardSearchRequest(request).types(request.types()).nowInMillis(request.nowInMillis())  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test1 ").numberOfShards(10).numberOfReplicas(0))  .put(IndexMetaData.builder( "test2 ").numberOfShards(10).numberOfReplicas(0))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test1 "))  .addAsNew(metaData.index( "test2 "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode( "node1 ")).put(newNode( "node2 "))).build();  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  while  (!clusterState.routingNodes().shardsWithState(INITIALIZING).isEmpty())  {  routingTable  =  strategy.applyStartedShards(clusterState,  clusterState.routingNodes().shardsWithState(INITIALIZING)).routingTable();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_297a97cd2369dc576e2a09fb791370c604921825	buggy:  .indexShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing());  context:  private  void  innerExecute(final  UpdateRequest  request,  final  ActionListener<UpdateResponse>  listener)  {  super.doExecute(request,  listener);  }  protected  ShardIterator  shards(ClusterState  clusterState,  UpdateRequest  request)  throws  ElasticsearchException  {  if  (request.shardId()  !=  -1)  {  return  clusterState.routingTable().index(request.index()).shard(request.shardId()).primaryShardIt();  }  ShardIterator  shardIterator  =  clusterService.operationRouting()                  .indexShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing());                  .indexShards(clusterState,  request.index(),  request.type(),  request.id(),  request.routing());  ShardRouting  shard;  while  ((shard  =  shardIterator.nextOrNull())  !=  null)  {  if  (shard.primary())  {  return  new  PlainShardIterator(shardIterator.shardId(),  ImmutableList.of(shard));  }  }  return  new  PlainShardIterator(shardIterator.shardId(),  ImmutableList.<ShardRouting>of());  }  	.indexShards(clusterState,  request.index(),  request.type(),  request.id(),  request.routing());  
elasticsearch_42b20d601fe2bcece29332a116031616b90d1323	buggy:  assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.<em>com</em>  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.<em>com</em>  <em>http</em>://<em>cnn</em>.<em>com</em>  <em>http</em>://<em>quora</em>.com "));  context:  );  ensureGreen();  client().prepareIndex( "test ",   "test ",   "1 ")  .setSource( "body ",   "Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature  Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature ")  .get();  refresh();  SearchResponse  search  =  client().prepareSearch().setQuery(matchQuery( "body ",   "Test:  http://www.facebook.com   ").type(Type.PHRASE)).addHighlightedField( "body ").execute().actionGet();  assertHighlight(search,  0,   "body ",  0,  startsWith( "<em>Test:  http://www.facebook.com</em> "));  search  =  client().prepareSearch().setQuery(matchQuery( "body ",   "Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature  Test:  http://www.facebook.com  http://elasticsearch.org  http://xing.com  http://cnn.com  http://quora.com  http://twitter.com  this  is  a  test  for  highlighting  feature ").type(Type.PHRASE)).addHighlightedField( "body ").execute().actionGet();          assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.<em>com</em>  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.<em>com</em>  <em>http</em>://<em>cnn</em>.<em>com</em>  <em>http</em>://<em>quora</em>.com "));          assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.com  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.com  <em>http</em>://<em>cnn</em>.com  <em>http</em>://<em>quora</em>.com "));  }  public  void  testNgramHighlightingPreLucene42()  throws  ElasticsearchException,  IOException  {  assertAcked(prepareCreate( "test ")  .addMapping( "test ",   "name ",   "type=string,index_analyzer=name_index_analyzer,search_analyzer=name_search_analyzer, "  +  randomStoreField()  +   "term_vector=with_positions_offsets ",  	assertHighlight(search,  0,   "body ",  0,  equalTo( "<em>Test</em>:  <em>http</em>://<em>www</em>.<em>facebook</em>.com  <em>http</em>://<em>elasticsearch</em>.<em>org</em>  <em>http</em>://<em>xing</em>.com  <em>http</em>://<em>cnn</em>.com  <em>http</em>://<em>quora</em>.com "));  
libgdx_f5add43d88e4f9b7fa7db145b3432556bb70f7df	buggy:  super.setY(y  +  region.offetY);  context:  public  void  setPosition  (float  x,  float  y)  {  super.setPosition(x  +  region.offsetX,  y  +  region.offsetY);  }  public  void  setX  (float  x)  {  super.setX(x  +  region.offsetX);  }  public  void  setY  (float  y)  {  super.setY(y  +  region.offetY);  super.setY(y  +  region.offsetY);  }  public  void  setBounds  (float  x,  float  y,  float  width,  float  height)  {  float  widthRatio  =  width  /  region.originalWidth;  float  heightRatio  =  height  /  region.originalHeight;  region.offsetX  =  originalOffsetX  *  widthRatio;  region.offsetY  =  originalOffsetY  *  heightRatio;  int  packedWidth  =  region.rotate  ?  region.packedHeight  :  region.packedWidth;  	super.setY(y  +  region.offsetY);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Document>  docs  =  new  ArrayList<Document>();  context:  public  abstract  class  AbstractNumberNestedSortingTests  extends  AbstractFieldDataTests  {  public  void  testNestedSorting()  throws  Exception  {          List<Document>  docs  =  new  ArrayList<Document>();          List<Document>  docs  =  new  ArrayList<>();  Document  document  =  new  Document();  document.add(createField( "field2 ",  3,  Field.Store.NO));  document.add(new  StringField( "filter_1 ",   "T ",  Field.Store.NO));  docs.add(document);  document  =  new  Document();  document.add(createField( "field2 ",  3,  Field.Store.NO));  document.add(new  StringField( "filter_1 ",   "T ",  Field.Store.NO));  docs.add(document);  	List<Document>  docs  =  new  ArrayList<>();  
elasticsearch_a7190ea8a3bd7fbf774a8431e88b46c79daf7a4c	buggy:  this.location.mkdirs();  context:  return;  }  initialized  =  true;  if  (!clusterService.localNode().masterNode()  &&  !clusterService.localNode().dataNode())  {  location  =  null;  }  else  {  this.location  =  new  File(nodeEnv.nodeDataLocation(),   "_state ");              this.location.mkdirs();              FileSystemUtils.mkdirs(this.location);  if  (clusterService.localNode().masterNode())  {  try  {  long  version  =  findLatestMetaStateVersion();  if  (version  !=  -1)  {  this.currentMetaState  =  readMetaState(Streams.copyToByteArray(new  FileInputStream(new  File(location,   "metadata- "  +  version))));  }  }  catch  (Exception  e)  {  	FileSystemUtils.mkdirs(this.location);  
libgdx_a796233dee600d6acf20bb488c15a613eb6de386	buggy:  texture  =  new  Texture(Gdx.files.internal( "data/resource1.png "));  context:  void  setModeString()  {  modeString  =  (mode%2==0? "Sprite ": "Atlas ")  +   "   "  +  filterNames[mode/2];  }  public  void  create  ()  {  batch  =  new  SpriteBatch();  sceneMatrix  =  new  Matrix4().setToOrtho2D(0,  0,  480,  320);  textMatrix  =  new  Matrix4().setToOrtho2D(0,  0,  480,  320);  atlas  =  new  TextureAtlas(Gdx.files.internal( "data/issue_pack "),  Gdx.files.internal( "data/ "));  texture  =  new  Texture(Gdx.files.internal( "data/resource1.png "));  texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "));  texture.setFilter(TextureFilter.MipMap,  TextureFilter.Nearest);  setTextureFilter(0);  setModeString();  sprite  =  atlas.createSprite( "map ");  sprite2  =  new  Sprite(texture,  0,  0,  855,  480);  font  =  new  BitmapFont(Gdx.files.internal( "data/font.fnt "),  Gdx.files.internal( "data/font.png "),  false);  	texture  =  new  Texture(Gdx.files.internal( "data/resource1.jpg "));  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  for  (SearchHit  hit  :  searchResponse.hits())  {  context:  final  CountDownLatch  latch  =  new  CountDownLatch(threads.length);  for  (int  i  =  0;  i  <  threads.length;  i++)  {  threads[i]  =  new  Thread(new  Runnable()  {  public  void  run()  {  for  (int  i  =  0;  i  <  1000;  i++)  {  SearchResponse  searchResponse  =  client.prepareSearch( "test ")  .setQuery(QueryBuilders.matchAllQuery())  .setSize(i  %  100)  .execute().actionGet();                          for  (SearchHit  hit  :  searchResponse.hits())  {                          for  (SearchHit  hit  :  searchResponse.getHits())  {  try  {  if  (!hit.sourceAsMap().get( "field ").equals(data))  {  System.err.println( "Field  not  equal! ");  }  }  catch  (Exception  e)  {  e.printStackTrace();  }  }  	for  (SearchHit  hit  :  searchResponse.getHits())  {  
libgdx_8a6812e16e8f6b101845e9b65e112b34a1aa36c1	buggy:  audio  =  new  OpenALAudio(config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  context:  }  }  else  {  initialize(listener,  config);  }  }  void  initialize  (ApplicationListener  listener,  JoglApplicationConfiguration  config)  {  JoglNativesLoader.load();  graphics  =  new  JoglGraphics(listener,  config);  input  =  new  JoglInput(graphics.getCanvas());  audio  =  new  OpenALAudio(config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  audio  =  new  OpenALAudio(16,  config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  files  =  new  JoglFiles();  Gdx.app  =  JoglApplication.this;  Gdx.graphics  =  JoglApplication.this.getGraphics();  Gdx.input  =  JoglApplication.this.getInput();  Gdx.audio  =  JoglApplication.this.getAudio();  Gdx.files  =  JoglApplication.this.getFiles();  	audio  =  new  OpenALAudio(16,  config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  
elasticsearch_c9dab6991eff5c01c7b0c36aecaf0f061267e030	buggy:  prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.mapping.date.parse_upper_inclusive ",  false)).execute().actionGet();  context:  SearchResponse  searchResponse  =  client().prepareSearch( "test ").setQuery(QueryBuilders.rangeQuery( "field ").gte( "2010-01-05 ").lte( "2010-01-06 ")).execute().actionGet();  assertHitCount(searchResponse,  2l);  searchResponse  =  client().prepareSearch( "test ").setQuery(QueryBuilders.rangeQuery( "field ").gte( "2010-01-05 ").lt( "2010-01-06 ")).execute().actionGet();  assertHitCount(searchResponse,  1l);  }  public  void  simpleDateRangeWithUpperInclusiveDisabledTests()  throws  Exception  {          prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.mapping.date.parse_upper_inclusive ",  false)).execute().actionGet();          prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.mapping.date.round_ceil ",  false)).execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field ",   "2010-01-05T02:00 ").execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "2 ").setSource( "field ",   "2010-01-06T02:00 ").execute().actionGet();  ensureGreen();  refresh();  SearchResponse  searchResponse  =  client().prepareSearch( "test ").setQuery(QueryBuilders.rangeQuery( "field ").gte( "2010-01-05 ").lte( "2010-01-06 ")).execute().actionGet();  assertNoFailures(searchResponse);  assertHitCount(searchResponse,  1l);  	prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.mapping.date.round_ceil ",  false)).execute().actionGet();  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.longToPrefixCoded(longValue,  precisionStep(),  bytesRef);  context:  if  (value  instanceof  BytesRef)  {  return  Numbers.bytesToDouble((BytesRef)  value);  }  return  Double.parseDouble(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  long  longValue  =  NumericUtils.doubleToSortableLong(parseValue(value));  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.longToPrefixCoded(longValue,  precisionStep(),  bytesRef);          NumericUtils.longToPrefixCoded(longValue,  0,  bytesRef);    //  0  because  of  exact  match  return  bytesRef;  }  private  double  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).doubleValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.longToPrefixCoded(longValue,  0,  bytesRef);      //  0  because  of  exact  match  
elasticsearch_a3af3d2f47590c859cac1dbc9f6fa273fc6bbd22	buggy:  if  (Queries.isMatchAllQuery(fQuery.getQuery()))  {  context:  public  Facet  facet()  {  return  new  InternalQueryFacet(facetName,  count);  }  private  Filter  extractFilterIfApplicable(Query  query)  {  if  (query  instanceof  FilteredQuery)  {  FilteredQuery  fQuery  =  (FilteredQuery)  query;              if  (Queries.isMatchAllQuery(fQuery.getQuery()))  {              if  (Queries.isConstantMatchAllQuery(fQuery.getQuery()))  {  return  fQuery.getFilter();  }  }  else  if  (query  instanceof  DeletionAwareConstantScoreQuery)  {  return  ((DeletionAwareConstantScoreQuery)  query).getFilter();  }  else  if  (query  instanceof  ConstantScoreQuery)  {  ConstantScoreQuery  constantScoreQuery  =  (ConstantScoreQuery)  query;  if  (constantScoreQuery.getFilter()  !=  null)  {  return  constantScoreQuery.getFilter();  	if  (Queries.isConstantMatchAllQuery(fQuery.getQuery()))  {  
elasticsearch_2865ceef85011c42b03356e6e1b45994d80f370e	buggy:  for  (RoutingNode  routingNode  :  routingNodes.nodesToShards().values())  {  context:  for  (Iterator<MutableShardRouting>  it  =  routingNodes.unassigned().iterator();  it.hasNext();)  {  MutableShardRouting  shard  =  it.next();  if  (!shard.primary())  {  MutableShardRouting  primary  =  routingNodes.findPrimaryForReplica(shard);  if  (primary  ==  null  ||  !primary.active())  {  continue;  }  }              for  (RoutingNode  routingNode  :  routingNodes.nodesToShards().values())  {              for  (RoutingNode  routingNode  :  routingNodes.sortedNodesLeastToHigh())  {  if  (routingNode.canAllocate(routingNodes)  &&  routingNode.canAllocate(shard))  {  changed  =  true;  routingNode.add(shard);  it.remove();  break;  }  }  }  	for  (RoutingNode  routingNode  :  routingNodes.sortedNodesLeastToHigh())  {  
elasticsearch_2ed6ea25ccad74105eebc8c93748265a84233d52	buggy:  logger.debug( "[{}]  deleting  index  that  is  no  longer  part  of  the  metadata ");  context:  if  (nodeEnv.hasNodeFile())  {  if  (currentMetaData  !=  null)  {  for  (IndexMetaData  current  :  currentMetaData)  {  if  (danglingIndices.containsKey(current.index()))  {  continue;  }  if  (!newMetaData.hasIndex(current.index()))  {                          logger.debug( "[{}]  deleting  index  that  is  no  longer  part  of  the  metadata ");                          logger.debug( "[{}]  deleting  index  that  is  no  longer  part  of  the  metadata  (indices:  [{}]) ",  current.index(),  newMetaData.indices().keySet());  FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(current.index())));  }  }  }  }  if  (nodeEnv.hasNodeFile())  {  	logger.debug( "[{}]  deleting  index  that  is  no  longer  part  of  the  metadata  (indices:  [{}]) ",  current.index(),  newMetaData.indices().keySet());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(FlushResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_6560a9ec7bc33de0912d23143f167a8cbecb6a36	buggy:  SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  context:  return  context;  }  private  SearchContext  createContext(InternalSearchRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());  Engine.Searcher  engineSearcher  =  indexShard.searcher();          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.nowInMillis(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  SearchContext.setCurrent(context);  try  {  context.scroll(request.scroll());  parseSource(context,  request.source(),  request.sourceOffset(),  request.sourceLength());  parseSource(context,  request.extraSource(),  request.extraSourceOffset(),  request.extraSourceLength());  	SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.searchType(),  request.numberOfShards(),  request.nowInMillis(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  
libgdx_6620f79c4c31affb77c99834ddd677e570bd678d	buggy:  camera  =  new  OrthographicCamera(  );  context:  score  =   "0  :  0 ";  spriteBatch  =  new  SpriteBatch(  app.getGraphics()  );  camera  =  new  OrthographicCamera(  );  camera  =  new  OrthographicCamera(  app.getGraphics()  );  camera.setViewport(  480,  320  );  }  	camera  =  new  OrthographicCamera(  app.getGraphics()  );  
elasticsearch_f029a24d53f3881724f9297e372b4120f1692179	buggy:  clusterService.submitStateUpdateTask( "indices_store ",  new  ClusterStateUpdateTask()  {  context:  return;  }  ClusterState  latestClusterState  =  clusterService.state();  if  (clusterState.getVersion()  !=  latestClusterState.getVersion())  {  return;  }              clusterService.submitStateUpdateTask( "indices_store ",  new  ClusterStateUpdateTask()  {              clusterService.submitStateUpdateTask( "indices_store ",  new  ClusterStateNonMasterUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  throws  Exception  {  if  (clusterState.getVersion()  !=  currentState.getVersion())  {  return  currentState;  }  IndexService  indexService  =  indicesService.indexService(shardId.getIndex());  	clusterService.submitStateUpdateTask( "indices_store ",  new  ClusterStateNonMasterUpdateTask()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<SnapshotId>  snapshots  =  new  ArrayList<SnapshotId>();  context:  protected  ImmutableList<SnapshotId>  readSnapshotList()  throws  IOException  {  byte[]  data  =  snapshotsBlobContainer.readBlobFully(SNAPSHOTS_FILE);          ArrayList<SnapshotId>  snapshots  =  new  ArrayList<SnapshotId>();          ArrayList<SnapshotId>  snapshots  =  new  ArrayList<>();  XContentParser  parser  =  null;  try  {  parser  =  XContentHelper.createParser(data,  0,  data.length);  if  (parser.nextToken()  ==  XContentParser.Token.START_OBJECT)  {  if  (parser.nextToken()  ==  XContentParser.Token.FIELD_NAME)  {  String  currentFieldName  =  parser.currentName();  if  ( "snapshots ".equals(currentFieldName))  {  if  (parser.nextToken()  ==  XContentParser.Token.START_ARRAY)  {  	ArrayList<SnapshotId>  snapshots  =  new  ArrayList<>();  
elasticsearch_991b5abdf43447782a5d815b5f2d6c2ea1ec9711	buggy:  Key  cacheKey();  context:  public  boolean  equals(Object  obj)  {  return  filter.equals(obj);  }  public  String  toString()  {  return  filter.toString();  }  }      Key  cacheKey();      Object  cacheKey();  }  	Object  cacheKey();  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");  context:  public  String  minimumShouldMatch()  {  return  this.minimumShouldMatch;  }  public  MoreLikeThisRequest  percentTermsToMatch(float  percentTermsToMatch)  {          return  minimumShouldMatch((int)  (percentTermsToMatch  *  100)  +   "% ");          return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  }  public  float  percentTermsToMatch()  {  if  (minimumShouldMatch.endsWith( "% "))  {  	return  minimumShouldMatch(Math.round(percentTermsToMatch  *  100)  +   "% ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  SortedMap<Character,  Byte>  typeMap  =  new  TreeMap<Character,  Byte>();  context:  return  0;  }  private  static  Pattern  typePattern  =  Pattern.compile( "(.*)\\s*=>\\s*(.*)\\s*$ ");  private  byte[]  parseTypes(Collection<String>  rules)  {          SortedMap<Character,  Byte>  typeMap  =  new  TreeMap<Character,  Byte>();          SortedMap<Character,  Byte>  typeMap  =  new  TreeMap<>();  for  (String  rule  :  rules)  {  Matcher  m  =  typePattern.matcher(rule);  if  (!m.find())  throw  new  RuntimeException( "Invalid  Mapping  Rule  :  [ "  +  rule  +   "] ");  String  lhs  =  parseString(m.group(1).trim());  Byte  rhs  =  parseType(m.group(2).trim());  if  (lhs.length()  !=  1)  throw  new  RuntimeException( "Invalid  Mapping  Rule  :  [ "  +  rule  +   "].  Only  a  single  character  is  allowed. ");  	SortedMap<Character,  Byte>  typeMap  =  new  TreeMap<>();  
elasticsearch_018351622152246b6adc27bbfb4edacf8e7316ac	buggy:  throw  new  ElasticSearchIllegalStateException( "Can't  create  an  index  [ "  +  sIndexName  +   "]  is  closed ");  context:  IndexService  indexService  =  indexService(index);  if  (indexService  ==  null)  {  throw  new  IndexMissingException(new  Index(index));  }  return  indexService;  }  public  synchronized  IndexService  createIndex(String  sIndexName,  Settings  settings,  String  localNodeId)  throws  ElasticSearchException  {  if  (!lifecycle.started())  {              throw  new  ElasticSearchIllegalStateException( "Can't  create  an  index  [ "  +  sIndexName  +   "]  is  closed ");              throw  new  ElasticSearchIllegalStateException( "Can't  create  an  index  [ "  +  sIndexName  +   "],  node  is  closed ");  }  Index  index  =  new  Index(sIndexName);  if  (indicesInjectors.containsKey(index.name()))  {  throw  new  IndexAlreadyExistsException(index);  }  indicesLifecycle.beforeIndexCreated(index);  	throw  new  ElasticSearchIllegalStateException( "Can't  create  an  index  [ "  +  sIndexName  +   "],  node  is  closed ");  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iters  =  atLeast(10);  context:  for  (int  i  =  0;  i  <  numIndices;  i++)  {  rtBuilder.addAsNew(metaData.index( "test_ "  +  i));  }  RoutingTable  routingTable  =  rtBuilder.build();  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.shardsWithState(UNASSIGNED).size(),  equalTo(routingTable.allShards().size()));  List<DiscoveryNode>  nodes  =  new  ArrayList<DiscoveryNode>();  int  nodeIdx  =  0;          int  iters  =  atLeast(10);          int  iters  =  scaledRandomIntBetween(10,  100);  for  (int  i  =  0;  i  <  iters;  i++)  {  DiscoveryNodes.Builder  nodesBuilder  =  DiscoveryNodes.builder();  int  numNodes  =  between(1,  20);  if  (nodes.size()  >  numNodes)  {  Collections.shuffle(nodes,  getRandom());  nodes  =  nodes.subList(0,  numNodes);  }  else  {  for  (int  j  =  nodes.size();  j  <  numNodes;  j++)  {  	int  iters  =  scaledRandomIntBetween(10,  100);  
elasticsearch_e059a7b37f1a023c5110aece90e5a7f5b8269be4	buggy:  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy ",   "MergePolicyProvider "))  context:  public  class  MergePolicyModule  extends  AbstractModule  {  private  final  Settings  settings;  public  MergePolicyModule(Settings  settings)  {  this.settings  =  settings;  }  bind(MergePolicyProvider.class)                  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy ",   "MergePolicyProvider "))                  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy. ",   "MergePolicyProvider "))  .asEagerSingleton();  }  }  	.to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy. ",   "MergePolicyProvider "))  
elasticsearch_b2769b108619551f25390d4aeeb4378a9a39a2ac	buggy:  add(new  Item(defaultIndex,  defaultType,  parser.text()));  context:  }  else  {  aFields  =  defaultFields;  }  add(new  Item(index,  type,  id).routing(routing).fields(aFields));  }  }  else  if  ( "ids ".equals(currentFieldName))  {  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  if  (!token.isValue())  {  throw  new  ElasticSearchIllegalArgumentException( "ids  array  element  should  only  contain  ids ");  }                              add(new  Item(defaultIndex,  defaultType,  parser.text()));                              add(new  Item(defaultIndex,  defaultType,  parser.text()).fields(defaultFields));  }  }  }  }  }  finally  {  parser.close();  }  }  	add(new  Item(defaultIndex,  defaultType,  parser.text()).fields(defaultFields));  
elasticsearch_5706858722452b13465b15930e4f4cb2e8286449	buggy:  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());  context:  protected  GetResponse  shardOperation(GetRequest  request,  int  shardId)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_get ").force(REFRESH_FORCE));  }  GetResult  result  =  indexShard.getService().get(request.type(),  request.id(),  request.fields(),                  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext());                  request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext(),  request.ignoreErrorsOnGeneratedFields());  return  new  GetResponse(result);  }  protected  GetRequest  newRequest()  {  return  new  GetRequest();  }  	request.realtime(),  request.version(),  request.versionType(),  request.fetchSourceContext(),  request.ignoreErrorsOnGeneratedFields());  
elasticsearch_d36f376a8e13c69c3bd78b4d43f554b44b692ed1	buggy:  builder.startObject( "mapping ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();  context:  builder.startObject(indexMetaData.index());  builder.startObject( "settings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.settings().getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  builder.startObject( "mappings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.mappings().entrySet())  {                              builder.startObject( "mapping ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();                              builder.startObject(entry.getKey()).field( "source ",  entry.getValue()).endObject();  }  builder.endObject();  builder.endObject();  }  builder.endObject();  builder.endObject();  	builder.startObject(entry.getKey()).field( "source ",  entry.getValue()).endObject();  
elasticsearch_ea96359d82a9a82da336e9dadbcb2ee0e9389a44	buggy:  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false,  null);  context:  protected  final  void  addShardFailure(final  int  shardIndex,  ShardSearchFailure  failure)  {  if  (shardFailures  ==  null)  {  shardFailures  =  new  AtomicArray<>(scrollId.getContext().length);  }  shardFailures.set(shardIndex,  failure);  }  public  void  start()  {  if  (scrollId.getContext().length  ==  0)  {                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false,  null);                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  false,  null);  listener.onResponse(new  SearchResponse(internalResponse,  request.scrollId(),  0,  0,  0l,  buildShardFailures()));  return;  }  Tuple<String,  Long>[]  context  =  scrollId.getContext();  for  (int  i  =  0;  i  <  context.length;  i++)  {  Tuple<String,  Long>  target  =  context[i];  DiscoveryNode  node  =  nodes.get(target.v1());  	final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  false,  null);  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  }  public  void  publish(ClusterState  clusterState)  {  DiscoveryNode  localNode  =  nodesProvider.nodes().localNode();  for  (final  DiscoveryNode  node  :  clusterState.nodes())  {  if  (node.equals(localNode))  {  continue;  }  transportService.sendRequest(node,  PublishClusterStateRequestHandler.ACTION,  new  PublishClusterStateRequest(clusterState),  new  VoidTransportResponseHandler(false)  {                  @Override  public  void  handleException(RemoteTransportException  exp)  {                  @Override  public  void  handleException(TransportException  exp)  {  }  });  }  }  private  class  PublishClusterStateRequest  implements  Streamable  {  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  item.index(clusterState.metaData().concreteSingleIndex(item.index()));  context:  if  (!clusterState.metaData().hasConcreteIndex(item.index()))  {  responses.set(i,  new  MultiGetItemResponse(null,  new  MultiGetResponse.Failure(item.index(),  item.type(),  item.id(),   "[ "  +  item.index()  +   "]  missing ")));  continue;  }  if  (item.routing()  ==  null  &&  clusterState.getMetaData().routingRequired(item.index(),  item.type()))  {  responses.set(i,  new  MultiGetItemResponse(null,  new  MultiGetResponse.Failure(item.index(),  item.type(),  item.id(),   "routing  is  required,  but  hasn't  been  specified ")));  continue;  }  item.routing(clusterState.metaData().resolveIndexRouting(item.routing(),  item.index()));              item.index(clusterState.metaData().concreteSingleIndex(item.index()));              item.index(clusterState.metaData().concreteSingleIndex(item.index(),  item.indicesOptions()));  ShardId  shardId  =  clusterService.operationRouting()  .getShards(clusterState,  item.index(),  item.type(),  item.id(),  item.routing(),  null).shardId();  MultiGetShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiGetShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequest.realtime(request.realtime);  shardRequest.refresh(request.refresh);  	item.index(clusterState.metaData().concreteSingleIndex(item.index(),  item.indicesOptions()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReferenceArray<ShardActionResult>  shardsResponses  =  new  AtomicReferenceArray<ShardActionResult>(groups.size());  context:  GroupShardsIterator  groups;  try  {  groups  =  shards(request);  }  catch  (Throwable  e)  {  listener.onFailure(e);  return;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  failureCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(groups.size());          final  AtomicReferenceArray<ShardActionResult>  shardsResponses  =  new  AtomicReferenceArray<ShardActionResult>(groups.size());          final  AtomicReferenceArray<ShardActionResult>  shardsResponses  =  new  AtomicReferenceArray<>(groups.size());  for  (final  ShardIterator  shardIt  :  groups)  {  ShardRequest  shardRequest  =  newShardRequestInstance(request,  shardIt.shardId().id());  shardRequest.beforeLocalFork();  //  optimize  for  local  fork  shardRequest.operationThreaded(true);  	final  AtomicReferenceArray<ShardActionResult>  shardsResponses  =  new  AtomicReferenceArray<>(groups.size());  
libgdx_d9318c7097ad93eae2588b9b03698d4d4cdd6ea4	buggy:  return  new  IOSApplication(new  GcTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  config.useAccelerometer  =  false;  return  new  IOSApplication(new  GcTest(),  config);  return  new  IOSApplication(new  BulletTestCollection(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  BulletTestCollection(),  config);  
libgdx_21c209669e25d242d7386b0c1bf962af26d535aa	buggy:  badlogicSmall.getTextureRegion().flip(true,  true);  context:  public  void  create  ()  {  batch  =  new  SpriteBatch();  atlas  =  new  TextureAtlas(Gdx.files.internal( "data "));  badlogic  =  atlas.getSprite( "badlogicslice ");  badlogic.setPosition(50,  50);  badlogicSmall  =  atlas.getSprite( "badlogicsmall ");  badlogicSmall.setPosition(10,  10);  badlogicSmall.getTextureRegion().flip(true,  true);  badlogicSmall.getRegion().flip(true,  true);  AtlasRegion  region  =  atlas.getRegion( "badlogicsmall ");  star  =  atlas.getSprite( "particle-star ");  star.setPosition(10,  70);  	badlogicSmall.getRegion().flip(true,  true);  
elasticsearch_5e9e2cf50c8eba23f7f1f99b47c95e54e8c51904	buggy:  logger.debug( "{}:  failed  to  executed  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  context:  if  (!TransportActions.isShardNotAvailableException(t))  {  }  }  }  performOperation(shardIt,  nextShard,  shardIndex);  }  else  {  if  (logger.isDebugEnabled())  {  if  (t  !=  null)  {  if  (!TransportActions.isShardNotAvailableException(t))  {                              logger.debug( "{}:  failed  to  executed  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);                              logger.debug( "{}:  failed  to  execute  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  }  }  }  if  (expectedOps  ==  counterOps.incrementAndGet())  {  finishHim();  }  }  }  	logger.debug( "{}:  failed  to  execute  [{}] ",  t,  shard  !=  null  ?  shard.shortSummary()  :  shardIt.shardId(),  request);  
elasticsearch_b7cd8a64cd2d776115532b8f2ae37cfa7ea36da2	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  context:  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  valueBytes  =  smartNameFieldMappers.mapper().indexedValueForSearch(value);  }  }  if  (valueBytes  ==  null)  {  valueBytes  =  new  BytesRef(value);  }  SpanTermQuery  query  =  new  SpanTermQuery(new  Term(fieldName,  valueBytes));  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);          return  query;  }  }  	return  query;  
libgdx_0c6a387f7b0b4f5180014459b3dafaac486d61d4	buggy:  nextIndex  =  currentIndex;  context:  hasNext  =  true;  break;  }  }  }  public  void  remove  ()  {  if  (currentIndex  <  0)  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  advance();  }  else  {  map.keyTable[currentIndex]  =  null;  map.valueTable[currentIndex]  =  null;  }  currentIndex  =  -1;  map.size--;  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_cb8faaa13f34f8340eb9050fbbfcc21cc44d7af7	buggy:  sb.append( "query[ ").append(context.query()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  context:  super(context.shardTarget(),  buildMessage(context,  msg));  }  public  SearchContextException(SearchContext  context,  String  msg,  Throwable  t)  {  super(context.shardTarget(),  buildMessage(context,  msg),  t);  }  private  static  String  buildMessage(SearchContext  context,  String  msg)  {  StringBuilder  sb  =  new  StringBuilder();  sb.append('[').append(context.shardTarget().index()).append( "][ ").append(context.shardTarget().shardId()).append( "]:   ");          sb.append( "query[ ").append(context.query()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");          sb.append( "query[ ").append(context.originalQuery()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  if  (context.sort()  !=  null)  {  sb.append( ",sort[ ").append(context.sort()).append( "] ");  }  return  sb.append( ":   ").append(msg).toString();  }  }  	sb.append( "query[ ").append(context.originalQuery()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  routingTableBuilder.add(indexMetaData,  false  /*  not  from  API  */);  context:  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState)  .blocks(blocks)  .metaData(metaDataBuilder)  .build();  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable());  for  (IndexMetaData  indexMetaData  :  updatedState.metaData().indices().values())  {                          routingTableBuilder.add(indexMetaData,  false  /*  not  from  API  */);                          routingTableBuilder.addAsRecovery(indexMetaData);  }  routingTableBuilder.version(0);  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());  return  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  	routingTableBuilder.addAsRecovery(indexMetaData);  
elasticsearch_5bd4c16a0cf830b309c5b3a46241240cb6e52f65	buggy:  requestBuilder.field( "document.simple ");  context:   "                \ "type\ ":\ "string\ ",\n "  +   "                \ "analyzer\ ":  \ "simple\ "\n "  +   "            }\n "  +   "        }\n "  +   "    }\n "  +   "} "  ).execute().actionGet();  for  (int  i  =  0;  i  <  10;  i++)  {  final  AnalyzeRequestBuilder  requestBuilder  =  client.admin().indices().prepareAnalyze( "test ",   "THIS  IS  A  TEST ");              requestBuilder.field( "document.simple ");              requestBuilder.setField( "document.simple ");  AnalyzeResponse  analyzeResponse  =  requestBuilder.execute().actionGet();  assertThat(analyzeResponse.tokens().size(),  equalTo(4));  AnalyzeResponse.AnalyzeToken  token  =  analyzeResponse.tokens().get(3);  assertThat(token.term(),  equalTo( "test "));  assertThat(token.startOffset(),  equalTo(10));  assertThat(token.endOffset(),  equalTo(14));  }  }  	requestBuilder.setField( "document.simple ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<InternalSignificantTerms.Bucket>(size);  context:  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  this.name  =  in.readString();  this.requiredSize  =  readSize(in);  this.minDocCount  =  in.readVLong();  this.subsetSize  =  in.readVLong();  this.supersetSize  =  in.readVLong();  int  size  =  in.readVInt();          List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<InternalSignificantTerms.Bucket>(size);          List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  BytesRef  term  =  in.readBytesRef();  long  subsetDf  =  in.readVLong();  long  supersetDf  =  in.readVLong();  buckets.add(new  Bucket(term,  subsetDf,  subsetSize,  supersetDf,  supersetSize,  InternalAggregations.readAggregations(in)));  }  this.buckets  =  buckets;  this.bucketMap  =  null;  	List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<>(size);  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  public  class  HdfsImmutableBlobContainer  extends  AbstractHdfsBlobContainer  implements  ImmutableBlobContainer  {  public  HdfsImmutableBlobContainer(HdfsBlobStore  blobStore,  BlobPath  blobPath,  Path  path)  {  super(blobStore,  blobPath,  path);  }          blobStore.executorService().execute(new  Runnable()  {          blobStore.executor().execute(new  Runnable()  {  Path  file  =  new  Path(path,  blobName);  FSDataOutputStream  fileStream;  try  {  fileStream  =  blobStore.fileSystem().create(file,  true);  }  catch  (IOException  e)  {  listener.onFailure(e);  	blobStore.executor().execute(new  Runnable()  {  
libgdx_23c28eb6c5bc2e6b032cee45c3c94382a3299eba	buggy:  return  byteBuffer.capacity()  /  attributes.vertexSize;  context:  public  int  getNumVertices()  {  return  buffer.limit();  }  public  int  getNumMaxVertices()  {  return  byteBuffer.capacity()  /  attributes.vertexSize;  return  buffer.capacity();  }  public  FloatBuffer  getBuffer()  {  isDirty  =  true;  	return  buffer.capacity();  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  PercolateShardRequest  shardRequest  =  new  PercolateShardRequest(index(),  shardId);  context:  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  shardId  =  in.readVInt();  preference  =  in.readOptionalString();  int  size  =  in.readVInt();  items  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  int  slot  =  in.readVInt();                  PercolateShardRequest  shardRequest  =  new  PercolateShardRequest(index(),  shardId);                  PercolateShardRequest  shardRequest  =  new  PercolateShardRequest(new  ShardId(index,  shardId));  shardRequest.documentType(in.readString());  shardRequest.source(in.readBytesReference());  shardRequest.docSource(in.readBytesReference());  shardRequest.onlyCount(in.readBoolean());  Item  item  =  new  Item(slot,  shardRequest);  items.add(item);  }  }  	PercolateShardRequest  shardRequest  =  new  PercolateShardRequest(new  ShardId(index,  shardId));  
elasticsearch_fd5719b2324367e73df6e09fa8a592381a3f8b44	buggy:  valueBytes  =  smartNameFieldMappers.mapper().indexedValue(value);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  prefix  query ");  }  BytesRef  valueBytes;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();              valueBytes  =  smartNameFieldMappers.mapper().indexedValue(value);              valueBytes  =  smartNameFieldMappers.mapper().indexedValueForSearch(value);  }  else  {  valueBytes  =  new  BytesRef(value);  }  WildcardQuery  query  =  new  WildcardQuery(new  Term(fieldName,  valueBytes));  QueryParsers.setRewriteMethod(query,  rewriteMethod);  query.setRewriteMethod(QueryParsers.parseRewriteMethod(rewriteMethod));  query.setBoost(boost);  	valueBytes  =  smartNameFieldMappers.mapper().indexedValueForSearch(value);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  return  new  UpdateSettingsRequest();  }  protected  UpdateSettingsResponse  newResponse()  {  return  new  UpdateSettingsResponse();  }  protected  void  doExecute(UpdateSettingsRequest  request,  ActionListener<UpdateSettingsResponse>  listener)  {          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  super.doExecute(request,  listener);  }  protected  void  masterOperation(final  UpdateSettingsRequest  request,  final  ClusterState  state,  final  ActionListener<UpdateSettingsResponse>  listener)  throws  ElasticsearchException  {  UpdateSettingsClusterStateUpdateRequest  clusterStateUpdateRequest  =  new  UpdateSettingsClusterStateUpdateRequest()  .indices(request.indices())  .settings(request.settings())  	request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  messageReceived(final  MultiGetRequest  request,  final  TransportChannel  channel)  throws  Exception  {  request.listenerThreaded(false);  execute(request,  new  ActionListener<MultiGetResponse>()  {  public  void  onResponse(MultiGetResponse  response)  {  try  {  channel.sendResponse(response);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
libgdx_7970b18a7777501be8290f7fff70e1ad1cf172ad	buggy:  files  =  new  AndroidFiles(this.getService().getAssets());  context:  public  AndroidLiveWallpaper(WallpaperService  service,  Engine  engine)  {  this.service  =  service;  this.engine  =  engine;  }  public  void  initialize(ApplicationListener  listener,  AndroidApplicationConfiguration  config)  {  graphics  =  new  AndroidGraphicsLiveWallpaper(this,  config.useGL20,  config.resolutionStrategy==null?new  FillResolutionStrategy():config.resolutionStrategy);  input  =  AndroidInputFactory.newAndroidInput(this,  this.getService(),  null,  config);  audio  =  new  AndroidAudio(this.getService(),  config);  files  =  new  AndroidFiles(this.getService().getAssets());  files  =  new  AndroidFiles(this.getService().getAssets(),  this.getService().getFilesDir().getAbsolutePath());  this.listener  =  listener;  Gdx.app  =  this;  Gdx.input  =  this.getInput();  Gdx.audio  =  this.getAudio();  Gdx.files  =  this.getFiles();  Gdx.graphics  =  this.getGraphics();  }  	files  =  new  AndroidFiles(this.getService().getAssets(),  this.getService().getFilesDir().getAbsolutePath());  
elasticsearch_947c5f69207d3442c5f51667e7f09b99dde60343	buggy:  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults);  context:  if  (logger.isDebugEnabled())  {  }  listener.onFailure(failure);  }  finally  {  }  }  void  innerFinishHim()  throws  Exception  {              sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults);              sortedShardList  =  searchPhaseController.sortDocs(request,  useSlowScroll,  queryFetchResults);  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  firstResults,  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  	sortedShardList  =  searchPhaseController.sortDocs(request,  useSlowScroll,  queryFetchResults);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  .endObject().copiedBytes())  context:  for  (int  i  =  0;  i  <  numberOfRuns();  i++)  {  SearchResponse  searchResponse  =  client.prepareSearch()  .setSearchType(SearchType.COUNT)  .setFacets(XContentFactory.jsonBuilder().startObject()  .startObject( "facet1 ")  .startObject( "terms ")  .field( "field ",   "tag ")  .endObject()  .endObject()                              .endObject().copiedBytes())                              .endObject().bytes())  .execute().actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(2l));  assertThat(searchResponse.hits().hits().length,  equalTo(0));  TermsFacet  facet  =  searchResponse.facets().facet( "facet1 ");  assertThat(facet.name(),  equalTo( "facet1 "));  assertThat(facet.entries().size(),  equalTo(2));  assertThat(facet.entries().get(0).term(),  anyOf(equalTo( "green "),  equalTo( "blue ")));  	.endObject().bytes())  
elasticsearch_1d7e20b7121537fb32cc3f1e3300e85bad3a014e	buggy:  return  indexSettings.get(IndexMetaData.SETTING_UUID);  context:  public  Injector  shardInjectorSafe(int  shardId)  throws  IndexShardMissingException  {  Injector  shardInjector  =  shardInjector(shardId);  if  (shardInjector  ==  null)  {  throw  new  IndexShardMissingException(new  ShardId(index,  shardId));  }  return  shardInjector;  }  public  String  indexUUID()  {          return  indexSettings.get(IndexMetaData.SETTING_UUID);          return  indexSettings.get(IndexMetaData.SETTING_UUID,  IndexMetaData.INDEX_UUID_NA_VALUE);  }  public  synchronized  IndexShard  createShard(int  sShardId)  throws  ElasticSearchException  {  	return  indexSettings.get(IndexMetaData.SETTING_UUID,  IndexMetaData.INDEX_UUID_NA_VALUE);  
elasticsearch_206799662c7bbfa5633c54bfc7298afa4f06d1e8	buggy:  assertThat( "ClusterHealthResponse  has  timed  out ",  response.isTimedOut(),  is(false));  context:  public  static  void  assertAcked(AcknowledgedRequestBuilder<?,  ?,  ?>  builder)  {  assertAcked(builder.get());  }  public  static  void  assertNoTimeout(ClusterHealthRequestBuilder  requestBuilder)  {  assertNoTimeout(requestBuilder.get());  }  public  static  void  assertNoTimeout(ClusterHealthResponse  response)  {          assertThat( "ClusterHealthResponse  has  timed  out ",  response.isTimedOut(),  is(false));          assertThat( "ClusterHealthResponse  has  timed  out  -  returned  status:  [ "  +  response.getStatus()  +   "] ",  response.isTimedOut(),  is(false));  }  public  static  void  assertAcked(AcknowledgedResponse  response)  {  assertThat(response.getClass().getSimpleName()  +   "  failed  -  not  acked ",  response.isAcknowledged(),  equalTo(true));  assertVersionSerializable(response);  }  public  static  void  assertAcked(DeleteIndexRequestBuilder  builder)  {  	assertThat( "ClusterHealthResponse  has  timed  out  -  returned  status:  [ "  +  response.getStatus()  +   "] ",  response.isTimedOut(),  is(false));  
elasticsearch_b8b4cbbb46176e7d0b3a9b9d161cbd02a0faa71e	buggy:  .mappingsCompressed(indexMetaData.mappings())  context:  return  newClusterStateBuilder().state(currentState).metaData(metaDataBuilder).build();  }  for  (final  IndexMetaData  indexMetaData  :  fMetaData)  {  try  {  createIndexService.createIndex(new  MetaDataCreateIndexService.Request( "gateway ",  indexMetaData.index())  .settings(indexMetaData.settings())                                  .mappingsCompressed(indexMetaData.mappings())                                  .mappingsMetaData(indexMetaData.mappings())  .state(indexMetaData.state())  .blocks(ImmutableSet.of(GatewayService.INDEX_NOT_RECOVERED_BLOCK))  .timeout(timeValueSeconds(30)),  new  MetaDataCreateIndexService.Listener()  {  if  (indicesCounter.decrementAndGet()  ==  0)  {  listener.onSuccess();  	.mappingsMetaData(indexMetaData.mappings())  
elasticsearch_7ef65688cd7c2be3d19425f4d652d973159a4a62	buggy:  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  context:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(searchContext,  query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  searchContext.addRewrite(childQuery);  return  childQuery;  }  }  	TopChildrenQuery  childQuery  =  new  TopChildrenQuery(searchContext,  query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  
elasticsearch_8b295b53d0ec023e3a71448bf33050f60c00f123	buggy:  indexShard.refresh(new  Engine.Refresh(false));  context:  lastIndexVersion  =  recoveryStatus.index().version();  lastTranslogId  =  -1;  lastTranslogLength  =  0;  lastTotalTranslogOperations  =  recoveryStatus.translog().currentTranslogOperations();  if  (indexShard.state()  !=  IndexShardState.STARTED)  {  indexShard.start( "post  recovery  from  gateway ");  }                      indexShard.refresh(new  Engine.Refresh(false));                      indexShard.refresh(new  Engine.Refresh().force(true));  recoveryStatus.time(System.currentTimeMillis()  -  recoveryStatus.startTime());  recoveryStatus.updateStage(RecoveryStatus.Stage.DONE);  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(timeValueMillis(recoveryStatus.time())).append( "]\n ");  sb.append( "    index    :  files            [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");  	indexShard.refresh(new  Engine.Refresh().force(true));  
libgdx_27fe2140b061d2fbc6ece654d264901bac9d5fc7	buggy:  if(peripheral  ==  Peripheral.MultitouchScreen)  return  touchHandler  instanceof  AndroidMultiTouchHandler;  context:  return  this.processor;  }  if(peripheral  ==  Peripheral.Accelerometer)  return  accelerometerAvailable;  if(peripheral  ==  Peripheral.Compass)  return  compassAvailable;  if(peripheral  ==  Peripheral.HardwareKeyboard)  return  keyboardAvailable;  if(peripheral  ==  Peripheral.OnscreenKeyboard)  return  true;  if(peripheral  ==  Peripheral.Vibrator)  return  vibrator  !=  null;  if(peripheral  ==  Peripheral.MultitouchScreen)  return  touchHandler  instanceof  AndroidMultiTouchHandler;  if(peripheral  ==  Peripheral.MultitouchScreen)  return  hasMultitouch;  return  false;  }  }  	if(peripheral  ==  Peripheral.MultitouchScreen)  return  hasMultitouch;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<String>  list  =  new  ArrayList<String>();  context:  from  =  nextMarker  +  1;  add(searchRequest);  }  return  this;  }  private  String[]  parseArray(XContentParser  parser)  throws  IOException  {          final  List<String>  list  =  new  ArrayList<String>();          final  List<String>  list  =  new  ArrayList<>();  assert  parser.currentToken()  ==  XContentParser.Token.START_ARRAY;  while  (parser.nextToken()  !=  XContentParser.Token.END_ARRAY)  {  list.add(parser.text());  }  return  list.toArray(new  String[list.size()]);  }  private  int  findNextMarker(byte  marker,  int  from,  BytesReference  data,  int  length)  {  	final  List<String>  list  =  new  ArrayList<>();  
libgdx_08fe91a0cb56ee633252cd8abc4cd20f777f64b0	buggy:  return  bitmapFont.draw(renderer.spriteBatch,  str,  x,  y,  color);  context:  public  int  drawText  (AnimationState  as,  int  x,  int  y,  CharSequence  str)  {  return  drawText(as,  x,  y,  str,  0,  str.length());  }  public  int  drawText  (AnimationState  as,  int  x,  int  y,  CharSequence  str,  int  start,  int  end)  {  FontState  fontState  =  evalFontState(as);  x  +=  fontState.offsetX;  y  +=  fontState.offsetY  +  yOffset;  com.badlogic.gdx.graphics.Color  color  =  renderer.getColor(fontState.color);  return  bitmapFont.draw(renderer.spriteBatch,  str,  x,  y,  color);  return  bitmapFont.draw(renderer.spriteBatch,  str,  x,  y,  color,  start,  end);  }  public  int  drawMultiLineText  (AnimationState  as,  int  x,  int  y,  CharSequence  str,  int  width,  de.matthiasmann.twl.HAlignment  align)  {  FontState  fontState  =  evalFontState(as);  x  +=  fontState.offsetX;  y  +=  fontState.offsetY  +  yOffset;  com.badlogic.gdx.graphics.Color  color  =  renderer.getColor(fontState.color);  	return  bitmapFont.draw(renderer.spriteBatch,  str,  x,  y,  color,  start,  end);  
elasticsearch_f2710c16ebd918f646be9d0ab64b4871c25be4c2	buggy:  .addPartialField( "partial2 ",  null,   "obj1.* ")  context:  .startObject().startObject( "obj2 ").field( "field2 ",   "value22 ").endObject().endObject()  .endArray()  .endObject()  .endObject())  .execute().actionGet();  client().admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  response  =  client().prepareSearch( "test ")  .addPartialField( "partial1 ",   "obj1.arr1.* ",  null)                  .addPartialField( "partial2 ",  null,   "obj1.* ")                  .addPartialField( "partial2 ",  null,   "obj1 ")  .execute().actionGet();  assertThat( "Failures   "  +  Arrays.toString(response.getShardFailures()),  response.getShardFailures().length,  equalTo(0));  Map<String,  Object>  partial1  =  response.getHits().getAt(0).field( "partial1 ").value();  assertThat(partial1,  notNullValue());  assertThat(partial1.containsKey( "field1 "),  equalTo(false));  assertThat(partial1.containsKey( "obj1 "),  equalTo(true));  assertThat(((Map)  partial1.get( "obj1 ")).get( "arr1 "),  instanceOf(List.class));  	.addPartialField( "partial2 ",  null,   "obj1 ")  
elasticsearch_5da14a7ed1ed6ef2c1817491e3f8cd8a8107948a	buggy:  builder.startArray(fieldName).value(lat).value(lon).endArray();  context:  this.order  =  order;  return  this;  }  builder.startObject( "_geo_distance ");  if  (geohash  !=  null)  {  builder.field(fieldName,  geohash);  }  else  {              builder.startArray(fieldName).value(lat).value(lon).endArray();              builder.startArray(fieldName).value(lon).value(lat).endArray();  }  if  (unit  !=  null)  {  builder.field( "unit ",  unit);  }  if  (geoDistance  !=  null)  {  builder.field( "distance_type ",  geoDistance.name().toLowerCase());  }  	builder.startArray(fieldName).value(lon).value(lat).endArray();  
elasticsearch_e735ff49d69951c756db260967cc2527869ed18c	buggy:  Settings  updated  =  settingsBuilder().putAll(tuple.v1()).putBoolean(JmxService.SettingsConstants.CREATE_CONNECTOR,  true).build();  context:  }  catch  (NoClassDefFoundError  e)  {  }  catch  (Exception  e)  {  System.err.println( "Failed  to  configure  logging... ");  e.printStackTrace();  }  if  (tuple.v1().get(JmxService.SettingsConstants.CREATE_CONNECTOR)  ==  null)  {              Settings  updated  =  settingsBuilder().putAll(tuple.v1()).putBoolean(JmxService.SettingsConstants.CREATE_CONNECTOR,  true).build();              Settings  updated  =  settingsBuilder().put(tuple.v1()).put(JmxService.SettingsConstants.CREATE_CONNECTOR,  true).build();  tuple  =  new  Tuple<Settings,  Environment>(updated,  tuple.v2());  }  ServerBuilder  serverBuilder  =  ServerBuilder.serverBuilder().settings(tuple.v1()).loadConfigSettings(false);  server  =  serverBuilder.build();  if  (addShutdownHook)  {  Runtime.getRuntime().addShutdownHook(new  Thread()  {  	Settings  updated  =  settingsBuilder().put(tuple.v1()).put(JmxService.SettingsConstants.CREATE_CONNECTOR,  true).build();  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.startObject(indexStats.index());  context:  builder.startObject( "primaries ");  primaries().toXContent(builder,  params);  builder.endObject();  builder.startObject( "total ");  primaries().toXContent(builder,  params);  builder.endObject();  builder.startObject(Fields.INDICES);  for  (IndexStats  indexStats  :  indices().values())  {              builder.startObject(indexStats.index());              builder.startObject(indexStats.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.startObject( "primaries ");  indexStats.primaries().toXContent(builder,  params);  builder.endObject();  builder.startObject( "total ");  indexStats.total().toXContent(builder,  params);  builder.endObject();  	builder.startObject(indexStats.index(),  XContentBuilder.FieldCaseConversion.NONE);  
libgdx_9e0c03b6f617f1efb3bfba507f40031b1b362164	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_38991d07d265355562bc63b431495779a8a787ce	buggy:  return  null;  context:  musics.get(i).play();  }  }  public  AudioDevice  newAudioDevice(boolean  isMono)  {  return  null;  return  new  AndroidAudioDevice(  isMono  );  }  public  Music  newMusic(FileHandle  file)  {  	return  new  AndroidAudioDevice(  isMono  );  
libgdx_32b98412f7409d91e046a8ede5b988c00464e9c6	buggy:  public  void  purchase  (final  PurchaseListener  listener,  final  String  identifier)  {  context:  helper  =  null;  inventory  =  null;  observer  =  null;  config  =  null;  }  }  public  void  purchase  (final  PurchaseListener  listener,  final  String  identifier)  {  public  void  purchase  (final  String  identifier,  final  PurchaseListener  listener)  {  String  payload  =  null;  helper.launchPurchaseFlow(activity,  identifier,  IabHelper.ITEM_TYPE_INAPP,  requestCode,  new  IabHelper.OnIabPurchaseFinishedListener()  {  public  void  onIabPurchaseFinished  (IabResult  result,  Purchase  purchase)  {  if  (result.isFailure())  {  	public  void  purchase  (final  String  identifier,  final  PurchaseListener  listener)  {  
elasticsearch_f3219f7098bd2a572ef63c17d06c4a62697e46c3	buggy:  stats.add(terms(name,  fieldName,   "global_ordinals "));  context:  updateThresholdInMapping(threshold);  for  (int  fieldSuffix  =  FIELD_START;  fieldSuffix  <=  FIELD_LIMIT;  fieldSuffix  <<=  1)  {  String  fieldName  =   "field_ "  +  fieldSuffix;  String  name  =   "global_ordinals- "  +  fieldName;  if  (USE_DOC_VALUES)  {  fieldName  =  fieldName  +   ".doc_values ";  name  =  name  +   "_doc_values ";  //  can't  have  .  in  agg  name  }                  stats.add(terms(name,  fieldName,   "global_ordinals "));                  stats.add(terms(name,  fieldName,   "global_ordinals_low_cardinality "));  }  }  for  (int  fieldSuffix  =  FIELD_START;  fieldSuffix  <=  FIELD_LIMIT;  fieldSuffix  <<=  1)  {  String  fieldName  =   "field_ "  +  fieldSuffix;  String  name  =   "ordinals- "  +  fieldName;  if  (USE_DOC_VALUES)  {  fieldName  =  fieldName  +   ".doc_values ";  	stats.add(terms(name,  fieldName,   "global_ordinals_low_cardinality "));  
elasticsearch_d4f03239179cdc8f29cd81fe457236c60e21de07	buggy:  if  (used  >=  0  &&  avail  >  0)  {  context:  int  shardCount  =  0;  if  (allocs.containsKey(node.id()))  {  shardCount  =  allocs.lget();  }  long  used  =  nodeStats.getFs().getTotal().getTotal().bytes()  -  nodeStats.getFs().getTotal().getAvailable().bytes();  long  avail  =  nodeStats.getFs().getTotal().getAvailable().bytes();  short  diskPercent  =  -1;              if  (used  >=  0  &&  avail  >  0)  {              if  (used  >=  0  &&  avail  >=  0)  {  diskPercent  =  (short)  (used  *  100  /  (used  +  avail));  }  table.startRow();  table.addCell(shardCount);  table.addCell(used  <  0  ?  null  :  new  ByteSizeValue(used));  table.addCell(avail  <  0  ?  null  :  new  ByteSizeValue(avail));  table.addCell(nodeStats.getFs().getTotal().getTotal());  	if  (used  >=  0  &&  avail  >=  0)  {  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(HistogramFacetCollectorParser.NAME);  context:  if  (keyScript  ==  null  &&  keyFieldName  ==  null)  {  throw  new  SearchSourceBuilderException( "key_script  or  key_field  must  be  set  on  histogram  script  facet  for  facet  [ "  +  name  +   "] ");  }  if  (valueScript  ==  null)  {  throw  new  SearchSourceBuilderException( "value_script  must  be  set  on  histogram  script  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(HistogramFacetCollectorParser.NAME);          builder.startObject(HistogramFacet.TYPE);  if  (keyFieldName  !=  null)  {  builder.field( "key_field ",  keyFieldName);  }  else  if  (keyScript  !=  null)  {  builder.field( "key_script ",  keyScript);  }  builder.field( "value_script ",  valueScript);  if  (lang  !=  null)  {  builder.field( "lang ",  lang);  	builder.startObject(HistogramFacet.TYPE);  
elasticsearch_fbae6e940b0f7932022ea3da727079219e2dc3bb	buggy:  .persistentSettings().getAsMap().size(),  equalTo(0));  context:  try  {  Scope  currentClusterScope  =  getCurrentClusterScope();  if  (currentClusterScope  ==  Scope.TEST)  {  clearClusters();  //  it  is  ok  to  leave  persistent  /  transient  cluster  state  behind  if  scope  is  TEST  }  else  {  MetaData  metaData  =  client().admin().cluster().prepareState().execute().actionGet().getState().getMetaData();  assertThat( "test  leaves  persistent  cluster  metadata  behind:   "  +  metaData.persistentSettings().getAsMap(),  metaData  .persistentSettings().getAsMap().size(),  equalTo(0));  assertThat( "test  leaves  transient  cluster  metadata  behind:   "  +  metaData.transientSettings().getAsMap(),  metaData                          .persistentSettings().getAsMap().size(),  equalTo(0));                          .transientSettings().getAsMap().size(),  equalTo(0));  }  wipeIndices();  //  wipe  after  to  make  sure  we  fail  in  the  test  that  wipeTemplates();  ensureAllSearchersClosed();  ensureAllFilesClosed();  	.transientSettings().getAsMap().size(),  equalTo(0));  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false  :   "should  fail ";  context:  .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS,  1)  .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS,  0)  .build();  public  void  testIndicesBoost()  throws  Exception  {  ElasticsearchAssertions.assertHitCount(client().prepareSearch().setQuery(termQuery( "test ",   "value ")).get(),  0);  try  {  client().prepareSearch( "test ").setQuery(termQuery( "test ",   "value ")).execute().actionGet();              assert  false  :   "should  fail ";              fail( "should  fail ");  }  catch  (Exception  e)  {  }  client().admin().indices().create(createIndexRequest( "test1 ").settings(DEFAULT_SETTINGS)).actionGet();  client().admin().indices().create(createIndexRequest( "test2 ").settings(DEFAULT_SETTINGS)).actionGet();  client().index(indexRequest( "test1 ").type( "type1 ").id( "1 ")  .source(jsonBuilder().startObject().field( "test ",   "value  check ").endObject())).actionGet();  	fail( "should  fail ");  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  super(settings,  client);  controller.registerHandler(POST,   "/_refresh ",  this);  controller.registerHandler(POST,   "/{index}/_refresh ",  this);  }  RefreshRequest  refreshRequest  =  new  RefreshRequest(RestActions.splitIndices(request.param( "index ")));  refreshRequest.listenerThreaded(false);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  refreshRequest.operationThreading(operationThreading);  client.admin().indices().refresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  try  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  
elasticsearch_d6f1ff0150b8b2bb877868ee616906bcf3fae3e4	buggy:  assertThat(failure.reason(),  containsString( "[test]  [has_child]  unsupported  in  delete_by_query  api "));  context:  NumShards  twitter  =  getNumShards( "test ");  assertThat(response.status(),  equalTo(RestStatus.BAD_REQUEST));  assertThat(response.getIndex( "test ").getSuccessfulShards(),  equalTo(0));  assertThat(response.getIndex( "test ").getFailedShards(),  equalTo(twitter.numPrimaries));  assertThat(response.getIndices().size(),  equalTo(1));  assertThat(response.getIndices().get( "test ").getFailedShards(),  equalTo(twitter.numPrimaries));  assertThat(response.getIndices().get( "test ").getFailures().length,  equalTo(twitter.numPrimaries));  for  (ShardOperationFailedException  failure  :  response.getIndices().get( "test ").getFailures())  {              assertThat(failure.reason(),  containsString( "[test]  [has_child]  unsupported  in  delete_by_query  api "));              assertThat(failure.reason(),  containsString( "[test]  [has_child]  query  and  filter  unsupported  in  delete_by_query  api "));  assertThat(failure.status(),  equalTo(RestStatus.BAD_REQUEST));  assertThat(failure.shardId(),  greaterThan(-1));  }  }  public  void  testDeleteByFieldQuery()  throws  Exception  {  assertAcked(prepareCreate( "test ").addAlias(new  Alias( "alias ")));  	assertThat(failure.reason(),  containsString( "[test]  [has_child]  query  and  filter  unsupported  in  delete_by_query  api "));  
elasticsearch_645ce26287582d21541df2428fa0a17294e1f1cf	buggy:  return  RestStatus.CONFLICT;  context:  public  class  IndexPrimaryShardNotAllocatedException  extends  IndexException  {  public  IndexPrimaryShardNotAllocatedException(Index  index)  {  super(index,   "primary  not  allocated  post  api ");  }  public  RestStatus  status()  {          return  RestStatus.CONFLICT;          return  RestStatus.INTERNAL_SERVER_ERROR;  }  }  	return  RestStatus.INTERNAL_SERVER_ERROR;  
elasticsearch_18ff92662e032aaee268211bb02a3ec6a496d74b	buggy:  indexShard.bulk(new  Engine.Bulk(ops));  context:  }  else  if  (item.request()  instanceof  DeleteRequest)  {  DeleteRequest  deleteRequest  =  (DeleteRequest)  item.request();  try  {  ops[i]  =  indexShard.prepareDelete(deleteRequest.type(),  deleteRequest.id(),  deleteRequest.version()).origin(Engine.Operation.Origin.REPLICA);  }  catch  (Exception  e)  {  }  }  }          indexShard.bulk(new  Engine.Bulk(ops));          indexShard.bulk(new  Engine.Bulk(ops).refresh(request.refresh()));  }  private  void  updateMappingOnMaster(final  IndexRequest  request)  {  try  {  MapperService  mapperService  =  indicesService.indexServiceSafe(request.index()).mapperService();  final  DocumentMapper  documentMapper  =  mapperService.documentMapper(request.type());  if  (documentMapper  ==  null)  {  //  should  not  happen  return;  	indexShard.bulk(new  Engine.Bulk(ops).refresh(request.refresh()));  
elasticsearch_e01f8c250d9c79911180b2e383fb184f4d278222	buggy:  return  new  ThreadLocalRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));  context:  package  org.elasticsearch.common.recycler;  public  class  ThreadLocalRecyclerTests  extends  AbstractRecyclerTests  {  protected  Recycler<byte[]>  newRecycler()  {          return  new  ThreadLocalRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));          return  Recyclers.threadLocal(Recyclers.dequeFactory(RECYCLER_C,  10));  }  }  	return  Recyclers.threadLocal(Recyclers.dequeFactory(RECYCLER_C,  10));  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  return  newPixmap(file.getInputStream());  context:  Bitmap  bitmap  =  BitmapFactory.decodeStream(in);  if  (bitmap  ==  null)  throw  new  GdxRuntimeException( "Couldn't  load  Pixmap  from  InputStream ");  return  new  AndroidPixmap(bitmap);  }  return  newPixmap(file.getInputStream());  return  newPixmap(file.readFile());  }  return  new  AndroidPixmap((Bitmap)nativePixmap);  }  	return  newPixmap(file.readFile());  
elasticsearch_36efde8c1d4e3e8e5cc2c4e909c838bc439a0b01	buggy:  invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  context:  queryFetchResults.put(result.shardTarget(),  result);  }  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  queryFetchResults.values());  }              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  searchCache.releaseQueryFetchResults(queryFetchResults);  }  }  }  	listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices( "test ");  context:  final  String  fieldName  =   "field ";  final  String  mapping  =   "{  \ " "  +  mappingType  +   "\ ":  { "  +   "\ "dynamic_templates\ ":  [ "   "{  \ " "  +  fieldName  +   "\ ":  { "  +   "\ "path_match\ ":  \ "*\ ", "  +   "\ "mapping\ ":  { "  +   "\ "type\ ":  \ "string\ ", "  +   "\ "store\ ":  \ "yes\ ", "   "\ "index\ ":  \ "analyzed\ ",  \ "analyzer\ ":  \ "whitespace\ "  }  }  }  ]  }  } ";  int  iters  =  scaledRandomIntBetween(5,  15);  for  (int  i  =  0;  i  <  iters;  i++)  {              cluster().wipeIndices( "test ");              immutableCluster().wipeIndices( "test ");  assertAcked(prepareCreate( "test ")  .addMapping(mappingType,  mapping));  ensureYellow();  int  numDocs  =  scaledRandomIntBetween(10,  100);  final  CountDownLatch  latch  =  new  CountDownLatch(numDocs);  final  List<Throwable>  throwable  =  new  CopyOnWriteArrayList<>();  int  currentID  =  0;  for  (int  j  =  0;  j  <  numDocs;  j++)  {  	immutableCluster().wipeIndices( "test ");  
elasticsearch_861e33ee3d45143aa9f4efbd1225f44e9aeefdc2	buggy:  builder.put( "index.store ",  storeType);  context:  if  (between(0,  5)  ==  0)  {  builder.put( "gateway.fs.buffer_size ",  between(1,  100)  +   "kb ");  }  if  (between(0,  5)  ==  0)  {  builder.put( "gateway.fs.chunk_size ",  between(1,  100)  +   "kb ");  }  builder.put( "index.number_of_replicas ",   "1 ");  builder.put( "index.number_of_shards ",  rarely()  ?  Integer.toString(between(2,  6))  :   "1 ");  storeType  =  rarely()  ?   "ram "  :   "fs ";          builder.put( "index.store ",  storeType);          builder.put( "index.store.type ",  storeType);  defaultSettings  =  builder.build();  buildNode( "server1 ");  ((InternalNode)  node( "server1 ")).injector().getInstance(Gateway.class).reset();  closeAllNodes();  }  	builder.put( "index.store.type ",  storeType);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.value(match);  }  builder.endArray();  }  builder.endObject();  RestStatus  status  =  OK;  if  (response.getVersion()  ==  1)  {  status  =  CREATED;  }  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_ff5990daec993cfcfbadafeb3fae4e460e77c7b1	buggy:  .listenerThreaded(false)  context:  if  (request.fields()  !=  null)  {  Collections.addAll(getFields,  request.fields());  }  getFields.add(SourceFieldMapper.NAME);  GetRequest  getRequest  =  getRequest(request.index())  .fields(getFields.toArray(new  String[getFields.size()]))  .type(request.type())  .id(request.id())                  .listenerThreaded(false)                  .listenerThreaded(true)  .operationThreaded(true);  request.beforeLocalFork();  getAction.execute(getRequest,  new  ActionListener<GetResponse>()  {  if  (!getResponse.exists())  {  listener.onFailure(new  ElasticSearchException( "document  missing "));  return;  	.listenerThreaded(true)  
elasticsearch_ebcc1e0bf5b0afcf76d7889bea94e9c8ff165535	buggy:  }  else  if  ( "id ".equals(currentFieldName))  {  context:  boolean  ignoreException  =  false;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  params  =  parser.map();  }  else  if  (token.isValue())  {  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INLINE;                          }  else  if  ( "id ".equals(currentFieldName))  {                          }  else  if  ( "script_id ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.INDEXED;  }  else  if  ( "file ".equals(currentFieldName))  {  script  =  parser.text();  scriptType  =  ScriptService.ScriptType.FILE;  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "ignore_failure ".equals(currentFieldName))  {  	}  else  if  ( "script_id ".equals(currentFieldName))  {  
elasticsearch_e1fe89389c4e6f81a59bbb4b6790ee18410ae895	buggy:  return  new  Response(matches,  request.doc().mappersAdded());  context:  }  finally  {  percolatorSearcher.release();  }  }  }  finally  {  indexCache.clear(searcher.getIndexReader());  }          return  new  Response(matches,  request.doc().mappersAdded());          return  new  Response(matches,  request.doc().mappingsModified());  }  private  IndexService  percolatorIndexServiceSafe()  {  IndexService  indexService  =  indicesService.indexService(PercolatorService.INDEX_NAME);  if  (indexService  ==  null)  {  throw  new  PercolateIndexUnavailable(new  Index(PercolatorService.INDEX_NAME));  }  return  indexService;  	return  new  Response(matches,  request.doc().mappingsModified());  
elasticsearch_03402c7ed8356241ac2407ad691709ee585b0bee	buggy:  indexRandom(true,  context:  return  FilterBuilders.rangeFilter(field).from(from).to(to).setExecution( "fielddata ");  }  }  else  {  return  FilterBuilders.numericRangeFilter(field).from(from).to(to);  }  }  public  void  testSimpleQueryString()  throws  ExecutionException,  InterruptedException  {  createIndex( "test ");          indexRandom(true,          indexRandom(true,  false,  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "body ",   "foo "),  client().prepareIndex( "test ",   "type1 ",   "2 ").setSource( "body ",   "bar "),  client().prepareIndex( "test ",   "type1 ",   "3 ").setSource( "body ",   "foo  bar "),  client().prepareIndex( "test ",   "type1 ",   "4 ").setSource( "body ",   "quux  baz  eggplant "),  client().prepareIndex( "test ",   "type1 ",   "5 ").setSource( "body ",   "quux  baz  spaghetti "),  client().prepareIndex( "test ",   "type1 ",   "6 ").setSource( "otherbody ",   "spaghetti "));  SearchResponse  searchResponse  =  client().prepareSearch().setQuery(simpleQueryString( "foo  bar ")).get();  	indexRandom(true,  false,  
elasticsearch_db6f5a71464cac7ecb405decaced6d7d19f51775	buggy:  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  context:  }  return;  }  client.search(searchRequest,  new  ActionListener<SearchResponse>()  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  response.status(),  builder));  }  catch  (Exception  e)  {  if  (logger.isDebugEnabled())  {  }  onFailure(e);  }  }  	channel.sendResponse(new  XContentRestResponse(request,  response.status(),  builder));  
libgdx_08381b421c08cb22df8f6725da269fc81e5548b1	buggy:  long  currentFrame  =  (lastTiledMapRenderTime  /  (long)animationInterval)  %  frameCount;  context:  return  blendMode;  }  public  void  setBlendMode  (BlendMode  blendMode)  {  this.blendMode  =  blendMode;  }  public  TextureRegion  getTextureRegion  ()  {  long  currentFrame  =  (lastTiledMapRenderTime  /  (long)animationInterval)  %  frameCount;  long  currentFrame  =  (lastTiledMapRenderTime  /  (long)(animationInterval  *  1000f))  %  frameCount;  return  frameTiles.get((int)currentFrame).getTextureRegion();  }  public  MapProperties  getProperties  ()  {  if  (properties  ==  null)  {  properties  =  new  MapProperties();  }  	long  currentFrame  =  (lastTiledMapRenderTime  /  (long)(animationInterval  *  1000f))  %  frameCount;  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  this.shardsState  =  shardsState;  return  this;  }  public  ActionFuture<NodesLocalGatewayStartedShards>  list(ShardId  shardId,  Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {  return  execute(new  Request(shardId,  nodesIds).timeout(timeout));  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return   "/gateway/local/started-shards ";  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execPutMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  context:  controller.registerHandler(PUT,   "/{index}/_mapping ",  this);  controller.registerHandler(PUT,   "/{index}/{type}/_mapping ",  this);  }  PutMappingRequest  putMappingRequest  =  putMappingRequest(splitIndices(request.param( "index ")));  putMappingRequest.type(request.param( "type "));  putMappingRequest.mappingSource(request.contentAsString());  putMappingRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));  putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignoreConflicts ",  putMappingRequest.ignoreConflicts()));          client.admin().indices().execPutMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {          client.admin().indices().putMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.acknowledged());  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  	client.admin().indices().putMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  nodes  =  new  HashSet<String>();  context:  }  }  assertThat(num,  greaterThan(0));  }  private  Set<String>  nodeIdsWithIndex(String...  indices)  {  ClusterState  state  =  client().admin().cluster().prepareState().execute().actionGet().getState();  GroupShardsIterator  allAssignedShardsGrouped  =  state.routingTable().allAssignedShardsGrouped(indices,  true);          Set<String>  nodes  =  new  HashSet<String>();          Set<String>  nodes  =  new  HashSet<>();  for  (ShardIterator  shardIterator  :  allAssignedShardsGrouped)  {  for  (ShardRouting  routing  :  shardIterator.asUnordered())  {  if  (routing.active())  {  nodes.add(routing.currentNodeId());  }  }  }  	Set<String>  nodes  =  new  HashSet<>();  
elasticsearch_bae3203e3beee284ca79ef9e004dd7abb1cb5b94	buggy:  assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(cluster().size()));  context:  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().clear().get();  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "foo "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "fuu "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "baz "),  is(false));  assertThat(clusterStateResponse.getState().routingTable().hasIndex( "non-existent "),  is(false));  }  public  void  testNodes()  throws  Exception  {  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().clear().setNodes(true).get();          assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(cluster().size()));          assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(immutableCluster().size()));  ClusterStateResponse  clusterStateResponseFiltered  =  client().admin().cluster().prepareState().clear().get();  assertThat(clusterStateResponseFiltered.getState().nodes().nodes().size(),  is(0));  }  public  void  testMetadata()  throws  Exception  {  ClusterStateResponse  clusterStateResponseUnfiltered  =  client().admin().cluster().prepareState().clear().setMetaData(true).get();  	assertThat(clusterStateResponse.getState().nodes().nodes().size(),  is(immutableCluster().size()));  
elasticsearch_7edafcf9a0813df24e3b7bdbe9c739cc9d70002d	buggy:  for  (int  i  =  0;  i  <  NUMBER_OF_ITERATIONS;  i++)  {  context:  }).txGet();  }  latch.countDown();  }  }).start();  }  new  Thread(new  Runnable()  {  public  void  run()  {                  for  (int  i  =  0;  i  <  NUMBER_OF_ITERATIONS;  i++)  {                  for  (int  i  =  0;  i  <  1;  i++)  {  BenchmarkMessage  message  =  new  BenchmarkMessage(2,  Bytes.EMPTY_ARRAY);  long  start  =  System.currentTimeMillis();  transportServiceClient.submitRequest(smallNode,   "benchmark ",  message,  options().withHighType(),  new  BaseTransportResponseHandler<BenchmarkMessage>()  {  public  BenchmarkMessage  newInstance()  {  return  new  BenchmarkMessage();  }  	for  (int  i  =  0;  i  <  1;  i++)  {  
elasticsearch_a3e355d40e2dd05ffbd7861d821e0d0116f32ced	buggy:  Snippet[]  fieldSnippets  =  highlighter.highlightDoc(highlighterContext.fieldName,  mapperHighlighterEntry.filteredQueryTerms,  context.searcher(),  hitContext.docId(),  numberOfFragments);  context:  if  (field.numberOfFragments()  ==  0)  {  highlighter.setBreakIterator(new  WholeBreakIterator());  numberOfFragments  =  1;  //1  per  value  since  we  highlight  per  value  }  else  {  numberOfFragments  =  field.numberOfFragments();  }  int  values  =  mergeValues  ?  1  :  textsToHighlight.size();  for  (int  i  =  0;  i  <  values;  i++)  {                  Snippet[]  fieldSnippets  =  highlighter.highlightDoc(highlighterContext.fieldName,  mapperHighlighterEntry.filteredQueryTerms,  context.searcher(),  hitContext.docId(),  numberOfFragments);                  Snippet[]  fieldSnippets  =  highlighter.highlightDoc(highlighterContext.fieldName,  mapperHighlighterEntry.filteredQueryTerms,  context.searcher(),  hitContext.topLevelDocId(),  numberOfFragments);  if  (fieldSnippets  !=  null)  {  for  (Snippet  fieldSnippet  :  fieldSnippets)  {  if  (Strings.hasText(fieldSnippet.getText()))  {  snippets.add(fieldSnippet);  }  }  }  }  	Snippet[]  fieldSnippets  =  highlighter.highlightDoc(highlighterContext.fieldName,  mapperHighlighterEntry.filteredQueryTerms,  context.searcher(),  hitContext.topLevelDocId(),  numberOfFragments);  
elasticsearch_1a1df06411455d2ac483963c1b617b8722265305	buggy:  return  numDocs  +  1;  context:  return  false;  }  public  int  getNumDocs()  {  return  numDocs;  }  public  int  getNumOrds()  {          return  numDocs  +  1;          return  numDocs;  }  public  Ordinals.Docs  ordinals()  {  return  new  Docs(this);  }  public  static  class  Docs  implements  Ordinals.Docs  {  	return  numDocs;  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Float  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  .bytes());  assertThat(doc.rootDoc().get(UidFieldMapper.NAME),  notNullValue());  assertThat(doc.rootDoc().get(IdFieldMapper.NAME),  nullValue());  try  {  docMapper.parse( "type ",  null,  XContentFactory.jsonBuilder()  .startObject()  .endObject()  .bytes());              assert  false;              fail();  }  catch  (MapperParsingException  e)  {  }  doc  =  docMapper.parse( "type ",  null,  XContentFactory.jsonBuilder()  .startObject()  .field( "_id ",  1)  .endObject()  .bytes());  	fail();  
elasticsearch_1780a2a06704a45c88e449476065951e70ff3b79	buggy:  logger.warn( "suspect  illegal  state:  trying  to  move  shard  from  primary  mode  to  backup  mode ");  context:  return  this.shardRouting;  }  public  InternalIndexShard  routingEntry(ShardRouting  shardRouting)  {  ShardRouting  currentRouting  =  this.shardRouting;  if  (!shardRouting.shardId().equals(shardId()))  {  throw  new  ElasticSearchIllegalArgumentException( "Trying  to  set  a  routing  entry  with  shardId  [ "  +  shardRouting.shardId()  +   "]  on  a  shard  with  shardId  [ "  +  shardId()  +   "] ");  }  if  (currentRouting  !=  null)  {  if  (!shardRouting.primary()  &&  currentRouting.primary())  {                  logger.warn( "suspect  illegal  state:  trying  to  move  shard  from  primary  mode  to  backup  mode ");                  logger.warn( "suspect  illegal  state:  trying  to  move  shard  from  primary  mode  to  replica  mode ");  }  if  (currentRouting.equals(shardRouting))  {  return  this;  }  }  this.shardRouting  =  shardRouting;  indicesLifecycle.shardRoutingChanged(this,  currentRouting,  shardRouting);  	logger.warn( "suspect  illegal  state:  trying  to  move  shard  from  primary  mode  to  replica  mode ");  
elasticsearch_69ef822da6277d56d5fd6be42a2450fca95ee941	buggy:  filter.addShould(new  PrefixFilter(new  Term(UidFieldMapper.NAME,  Uid.createUid(queryType,  value))));  context:  public  Filter  prefixFilter(String  value,  @Nullable  QueryParseContext  context)  {  if  (indexed()  ||  context  ==  null)  {  return  super.prefixFilter(value,  context);  }  Collection<String>  queryTypes  =  context.queryTypes();  if  (queryTypes.size()  ==  1)  {  return  new  PrefixFilter(new  Term(UidFieldMapper.NAME,  Uid.createUid(Iterables.getFirst(queryTypes,  null),  value)));  }  XBooleanFilter  filter  =  new  XBooleanFilter();  for  (String  queryType  :  queryTypes)  {              filter.addShould(new  PrefixFilter(new  Term(UidFieldMapper.NAME,  Uid.createUid(queryType,  value))));              filter.add(new  PrefixFilter(new  Term(UidFieldMapper.NAME,  Uid.createUid(queryType,  value))),  BooleanClause.Occur.SHOULD);  }  return  filter;  }  public  void  preParse(ParseContext  context)  throws  IOException  {  if  (context.sourceToParse().id()  !=  null)  {  context.id(context.sourceToParse().id());  	filter.add(new  PrefixFilter(new  Term(UidFieldMapper.NAME,  Uid.createUid(queryType,  value))),  BooleanClause.Occur.SHOULD);  
libgdx_046cbdba425a117a558e6867ed30efc9b4f681e8	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleAnimationTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleAnimationTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.EdgeDetectionTest(),   "Debug  Test ",  480,  320,  true);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.EdgeDetectionTest(),   "Debug  Test ",  480,  320,  true);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Not<T>(p);  context:  return  any();  }  private  static  final  long  serialVersionUID  =  0;  }  public  static  <T>  Matcher<T>  not(final  Matcher<?  super  T>  p)  {          return  new  Not<T>(p);          return  new  Not<>(p);  }  private  static  class  Not<T>  extends  AbstractMatcher<T>  implements  Serializable  {  final  Matcher<?  super  T>  delegate;  private  Not(Matcher<?  super  T>  delegate)  {  this.delegate  =  checkNotNull(delegate,   "delegate ");  }  	return  new  Not<>(p);  
libgdx_a41179fbba2512dfa51a1057f5b32edbdba12c26	buggy:  pixmap.drawCircle(x,  y,  radius,  color);  context:  }  public  void  fillCircle  (int  x,  int  y,  int  radius)  {  pixmap.drawCircle(x,  y,  radius,  color);  pixmap.fillCircle(x,  y,  radius,  color);  }  	pixmap.fillCircle(x,  y,  radius,  color);  
libgdx_76215a01d2536765bf33361bbc79862ed413ee01	buggy:  sound  =  app.getAudio().newSound(  app.getFiles().getInternalFileHandle(   "data/shotgun44k.ogg "  )  );  context:  {  }  public  void  surfaceCreated(Application  app)  {  if(  music  ==  null  )  {  app.getInput().addInputListener(  this  );  sound  =  app.getAudio().newSound(  app.getFiles().getInternalFileHandle(   "data/shotgun44k.ogg "  )  );  sound  =  app.getAudio().newSound(  app.getFiles().getInternalFileHandle(   "data/shotgun.wav "  )  );  music  =  app.getAudio().newMusic(  app.getFiles().getInternalFileHandle(   "data/cloudconnected.ogg "  )  );  music.play();  music.setLooping(  true  );  }  }  	sound  =  app.getAudio().newSound(  app.getFiles().getInternalFileHandle(   "data/shotgun.wav "  )  );  
elasticsearch_6f0904c7f155b49ec581fcf5007862867ec9691e	buggy:  assert  sizeInBytes  >  0  :   "When  reducing  circuit  breaker,  it  should  be  adjusted  with  a  positive  number  and  not  [ "  +  sizeInBytes  +   "] ";  context:  public  IndicesFieldDataCacheListener(CircuitBreakerService  circuitBreakerService)  {  this.circuitBreakerService  =  circuitBreakerService;  }  public  void  onLoad(FieldMapper.Names  fieldNames,  FieldDataType  fieldDataType,  AtomicFieldData  fieldData)  {  }  public  void  onUnload(FieldMapper.Names  fieldNames,  FieldDataType  fieldDataType,  boolean  wasEvicted,  long  sizeInBytes,  @Nullable  AtomicFieldData  fieldData)  {          assert  sizeInBytes  >  0  :   "When  reducing  circuit  breaker,  it  should  be  adjusted  with  a  positive  number  and  not  [ "  +  sizeInBytes  +   "] ";          assert  sizeInBytes  >=  0  :   "When  reducing  circuit  breaker,  it  should  be  adjusted  with  a  number  higher  or  equal  to  0  and  not  [ "  +  sizeInBytes  +   "] ";  circuitBreakerService.getBreaker().addWithoutBreaking(-sizeInBytes);  }  }  	assert  sizeInBytes  >=  0  :   "When  reducing  circuit  breaker,  it  should  be  adjusted  with  a  number  higher  or  equal  to  0  and  not  [ "  +  sizeInBytes  +   "] ";  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  fieldsBoosts  =  new  ObjectFloatOpenHashMap<String>();  context:  public  QueryStringQueryBuilder  field(String  field,  float  boost)  {  if  (fields  ==  null)  {  fields  =  newArrayList();  }  fields.add(field);  if  (fieldsBoosts  ==  null)  {              fieldsBoosts  =  new  ObjectFloatOpenHashMap<String>();              fieldsBoosts  =  new  ObjectFloatOpenHashMap<>();  }  fieldsBoosts.put(field,  boost);  return  this;  }  	fieldsBoosts  =  new  ObjectFloatOpenHashMap<>();  
libgdx_8a73f12ac1fbb80e42b2694e5fefc1df68d2bb95	buggy:  listener.error(assetDesc.fileName,  assetDesc.type,  t);  context:  for  (AssetDescriptor  desc  :  task.dependencies)  {  unload(desc.fileName);  }  }  tasks.clear();  if  (listener  !=  null)  {  listener.error(assetDesc.fileName,  assetDesc.type,  t);  listener.error(assetDesc,  t);  }  else  {  throw  new  GdxRuntimeException(t);  }  }  	listener.error(assetDesc,  t);  
libgdx_377f58dae051295b0b98a6ef508599d389fe549e	buggy:  return  buffer.limit()  *  4  /  attributes.vertexSize;  context:  public  VertexAttributes  getAttributes  ()  {  return  attributes;  }  public  int  getNumVertices  ()  {  return  buffer.limit()  *  4  /  attributes.vertexSize;  return  buffer.limit()  /  (attributes.vertexSize  /  4);  }  public  int  getNumMaxVertices  ()  {  return  buffer.capacity()  /  (attributes.vertexSize  /  4);  }  	return  buffer.limit()  /  (attributes.vertexSize  /  4);  
libgdx_6b1f6e2e139683a01b4f19b1765b466de095cb9a	buggy:  int  result  =  (int)type;  context:  this(copyFrom.type,  copyFrom.color);  }  public  Attribute  copy  ()  {  return  new  ColorAttribute(this);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  953  *  result  +  color.hashCode();  return  result;  }  }  	int  result  =  super.hashCode();  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  context:  }  public  void  onResponse(T  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject()  .field(Fields.ACKNOWLEDGED,  response.isAcknowledged());  addCustomFields(builder,  response);  builder.endObject();              channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));              channel.sendResponse(new  BytesRestResponse(OK,  builder));  }  catch  (IOException  e)  {  onFailure(e);  }  }  	channel.sendResponse(new  BytesRestResponse(OK,  builder));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(IndicesStatusResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  response.toXContent(builder,  request,  settingsFilter);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_284a35131cd6a96baba14b31c827e5f6dab7b4ad	buggy:  if  (minimumNumberShouldMatch  ==  -1)  {  context:  builder.field( "should ");  clause.queryBuilder.toJson(builder,  params);  }  }  if  (boost  !=  -1)  {  builder.field( "boost ",  boost);  }  if  (disableCoord  !=  null)  {  builder.field( "disableCoord ",  disableCoord);  }          if  (minimumNumberShouldMatch  ==  -1)  {          if  (minimumNumberShouldMatch  !=  -1)  {  builder.field( "minimumNumberShouldMatch ",  minimumNumberShouldMatch);  }  builder.endObject();  }  private  static  class  Clause  {  final  JsonQueryBuilder  queryBuilder;  final  BooleanClause.Occur  occur;  	if  (minimumNumberShouldMatch  !=  -1)  {  
elasticsearch_49c74e08859736d09add31436554dfa76e395dd8	buggy:  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  context:  }  protected  void  moveToSecondPhase()  throws  Exception  {  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(SearchPhaseController.EMPTY_DOCS,  firstResults,  (AtomicArray<?  extends  FetchSearchResultProvider>)  AtomicArray.empty());  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  buildScrollId(request.searchType(),  firstResults,  null);  }              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));              listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successfulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(settings),  context:  .put( "index.queryparser.filter.my.type ",  MyJsonFilterParser.class)  .put( "index.queryparser.filter.my.param2 ",   "value2 ")  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),  new  ScriptModule(settings),                  new  IndexSettingsModule(settings),                  new  IndexSettingsModule(index,  settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index)  ).createInjector();  IndexQueryParserService  indexQueryParserService  =  injector.getInstance(IndexQueryParserService.class);  	new  IndexSettingsModule(index,  settings),  
elasticsearch_7aa2d11cdd657f7ed2175a0f4ffecaf230ca449c	buggy:  createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(update  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  context:  throw  new  RoutingMissingException(request.concreteIndex(),  request.request().type(),  request.request().id());  }  return  true;  }  protected  void  doExecute(final  UpdateRequest  request,  final  ActionListener<UpdateResponse>  listener)  {  if  (autoCreateIndex.shouldAutoCreate(request.index(),  clusterService.state()))  {  request.beforeLocalFork();  //  we  fork  on  another  thread...              createIndexAction.execute(new  CreateIndexRequest(request.index()).cause( "auto(update  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {              createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(update  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  	createIndexAction.execute(new  CreateIndexRequest(request).index(request.index()).cause( "auto(update  api) ").masterNodeTimeout(request.timeout()),  new  ActionListener<CreateIndexResponse>()  {  
elasticsearch_f4f26d2118b1bc6f0d895ba990ede22b02e731b4	buggy:  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));  context:  }  SearchSourceBuilder  sourceBuilder  =  searchSource()  .query(termQuery( "multi ",   "test "))  .from(0).size(20).explain(true)                  .facets(facets().facet( "all ",  termQuery( "multi ",   "test ")).facet( "test1 ",  termQuery( "name ",   "test1 ")));                  .facets(facets().facet( "all ",  termQuery( "multi ",   "test "),  true).facet( "test1 ",  termQuery( "name ",   "test1 ")));  SearchResponse  searchResponse  =  client.search(searchRequest( "test ").source(sourceBuilder)).actionGet();  assertThat(searchResponse.hits().totalHits(),  equalTo(100l));  assertThat(searchResponse.facets().countFacet( "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().countFacet( "all ").count(),  equalTo(100l));  }  	.facets(facets().facet( "all ",  termQuery( "multi ",   "test "),  true).facet( "test1 ",  termQuery( "name ",   "test1 ")));  
elasticsearch_398382f6e7da2dae90c64f5a3a8264485b01df4d	buggy:  if  (metaData.index(index)  ==  null)  {  context:  }  }  RoutingNode  routingNodes  =  event.state().readOnlyRoutingNodes().nodesToShards().get(event.state().nodes().localNodeId());  if  (routingNodes  !=  null)  {  applyShards(routingNodes,  routingTable,  event.state().nodes());  }  for  (final  String  index  :  indicesService.indices())  {              if  (metaData.index(index)  ==  null)  {              if  (!metaData.hasIndex(index))  {  if  (logger.isDebugEnabled())  {  }  indicesService.deleteIndex(index);  threadPool.execute(new  Runnable()  {  nodeIndexDeletedAction.nodeIndexDeleted(index,  event.state().nodes().localNodeId());  }  	if  (!metaData.hasIndex(index))  {  
elasticsearch_c3e84eb63953ce34f17b166c967e51e6ca7ebebb	buggy:  threadPool  =  new  ThreadPool();  context:  protected  DiscoveryNode  nodeA;  protected  MockTransportService  serviceA;  protected  static  final  Version  version1  =  Version.fromId(199);  protected  DiscoveryNode  nodeB;  protected  MockTransportService  serviceB;  public  void  setUp()  throws  Exception  {  super.setUp();          threadPool  =  new  ThreadPool();          threadPool  =  new  ThreadPool(getClass().getName());  serviceA  =  build(ImmutableSettings.builder().put( "name ",   "TS_A ").build(),  version0);  nodeA  =  new  DiscoveryNode( "TS_A ",   "TS_A ",  serviceA.boundAddress().publishAddress(),  ImmutableMap.<String,  String>of(),  version0);  serviceB  =  build(ImmutableSettings.builder().put( "name ",   "TS_B ").build(),  version1);  nodeB  =  new  DiscoveryNode( "TS_B ",   "TS_B ",  serviceB.boundAddress().publishAddress(),  ImmutableMap.<String,  String>of(),  version1);  final  CountDownLatch  latch  =  new  CountDownLatch(4);  	threadPool  =  new  ThreadPool(getClass().getName());  
elasticsearch_f1467dbde256a968bfffed6ce470f162ac307655	buggy:  assertThat(fieldData.getNumDocs(),  equalTo(0));  context:  assertThat(doubleValuesIter.next(),  equalTo(3d));  assertThat(doubleValuesIter.hasNext(),  equalTo(false));  }  public  void  testMissingValueForAll()  throws  Exception  {  fillAllMissing();  IndexNumericFieldData  indexFieldData  =  getForField( "value ");  AtomicNumericFieldData  fieldData  =  indexFieldData.load(refreshReader());          assertThat(fieldData.getNumDocs(),  equalTo(0));          assertThat(fieldData.getNumDocs(),  equalTo(3));  LongValues  longValues  =  fieldData.getLongValues();  assertThat(longValues.isMultiValued(),  equalTo(false));  assertThat(longValues.hasValue(0),  equalTo(false));  	assertThat(fieldData.getNumDocs(),  equalTo(3));  
elasticsearch_ee33ee457a4d36986fcbea4b75fc153f9b6ab2ef	buggy:  options.withCompress();  context:  }  TransportAddress  wrapAddress(SocketAddress  socketAddress)  {  return  new  InetSocketTransportAddress((InetSocketAddress)  socketAddress);  }  Channel  targetChannel  =  nodeChannel(node);  if  (compress)  {              options.withCompress();              options.withCompress(true);  }  byte[]  data  =  TransportStreams.buildRequest(requestId,  action,  message,  options);  ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(data);  ChannelFuture  channelFuture  =  targetChannel.write(buffer);  	options.withCompress(true);  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  1000  *  (ElasticsearchIntegrationTest.CHILD_VM_ID.hashCode()  %  60)  +  //  up  to  60  jvms  context:  }  public  UnicastZen(int  numOfNodes,  Settings  extraSettings,  int[]  unicastHostOrdinals)  {  super(numOfNodes,  extraSettings);  this.unicastHostOrdinals  =  unicastHostOrdinals;  this.basePort  =  calcBasePort();  }  private  final  static  int  calcBasePort()  {  return  10000  +                      1000  *  (ElasticsearchIntegrationTest.CHILD_VM_ID.hashCode()  %  60)  +  //  up  to  60  jvms                      1000  *  (ElasticsearchIntegrationTest.CHILD_JVM_ID  %  60)  +  //  up  to  60  jvms  100  *  portRangeCounter.incrementAndGet();  //  up  to  100  nodes  }  public  Settings  node(int  nodeOrdinal)  {  ImmutableSettings.Builder  builder  =  ImmutableSettings.builder()  .put( "discovery.zen.ping.multicast.enabled ",  false);  	1000  *  (ElasticsearchIntegrationTest.CHILD_JVM_ID  %  60)  +  //  up  to  60  jvms  
elasticsearch_8e17d636ef441a9be80977d34acfaabc12982eb7	buggy:  final  Query  rewritten  =  new  XLuceneConstantScoreQuery(delegate.getFilter());  context:  public  Query  rewrite(IndexReader  reader)  throws  IOException  {  Query  query  =  delegate.getQuery();  final  Query  queryRewritten  =  query.rewrite(reader);  if  (queryRewritten  instanceof  MatchAllDocsQuery  ||  Queries.isConstantMatchAllQuery(queryRewritten))  {              final  Query  rewritten  =  new  XLuceneConstantScoreQuery(delegate.getFilter());              final  Query  rewritten  =  new  ConstantScoreQuery(delegate.getFilter());  rewritten.setBoost(delegate.getBoost()  *  queryRewritten.getBoost());  return  rewritten;  }  if  (queryRewritten  !=  query)  {  final  Query  rewritten  =  new  XFilteredQuery(queryRewritten,  rawFilter,  strategy);  	final  Query  rewritten  =  new  ConstantScoreQuery(delegate.getFilter());  
elasticsearch_683be6fc645fe3e917caeb883d3f29c63a6763a2	buggy:  UidFilter  filter  =  new  UidFilter(types,  ids,  parseContext.indexCache().bloomCache());  context:  if  (ids.size()  ==  0)  {  throw  new  QueryParsingException(parseContext.index(),   "[ids]  query,  no  ids  values  provided ");  }  if  (types  ==  null  ||  types.isEmpty())  {  types  =  parseContext.queryTypes();  }  else  if  (types.size()  ==  1  &&  Iterables.getFirst(types,  null).equals( "_all "))  {  types  =  parseContext.mapperService().types();  }          UidFilter  filter  =  new  UidFilter(types,  ids,  parseContext.indexCache().bloomCache());          UidFilter  filter  =  new  UidFilter(types,  ids);  ConstantScoreQuery  query  =  new  ConstantScoreQuery(filter);  query.setBoost(boost);  return  query;  }  }  	UidFilter  filter  =  new  UidFilter(types,  ids);  
elasticsearch_80062fbe10b574cd1a9723caf197254a5c54e752	buggy:  multiGetRequest.realtime(request.paramAsBoolean( "realtime ",  null));  context:  controller.registerHandler(POST,   "/{index}/_mget ",  this);  controller.registerHandler(GET,   "/{index}/{type}/_mget ",  this);  controller.registerHandler(POST,   "/{index}/{type}/_mget ",  this);  }  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest();  multiGetRequest.listenerThreaded(false);  multiGetRequest.refresh(request.paramAsBoolean( "refresh ",  multiGetRequest.refresh()));  multiGetRequest.preference(request.param( "preference "));          multiGetRequest.realtime(request.paramAsBoolean( "realtime ",  null));          multiGetRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  try  {  multiGetRequest.add(request.param( "index "),  request.param( "type "),  request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  	multiGetRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  executor  =  executor  ==  null  ?  threadPool.cached()  :  executor;  context:  return  indexEngine;  }  public  void  close(final  boolean  delete,  final  String  reason,  @Nullable  Executor  executor)  {  synchronized  (this)  {  closed  =  true;  }  Set<Integer>  shardIds  =  shardIds();  final  CountDownLatch  latch  =  new  CountDownLatch(shardIds.size());  for  (final  int  shardId  :  shardIds)  {              executor  =  executor  ==  null  ?  threadPool.cached()  :  executor;              executor  =  executor  ==  null  ?  threadPool.generic()  :  executor;  executor.execute(new  Runnable()  {  public  void  run()  {  try  {  deleteShard(shardId,  delete,  !delete,  delete,  reason);  }  catch  (Exception  e)  {  }  finally  {  	executor  =  executor  ==  null  ?  threadPool.generic()  :  executor;  
libgdx_131b328d19fb1a12b3c301e2fae640dbdf21710d	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.ShaderMultitextureTest(),   "Debug  Test ",  480,  320,  true);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.ShaderMultitextureTest(),   "Debug  Test ",  480,  320,  true);  new  JoglApplication(new  com.badlogic.gdx.tests.SpritePerformanteTest2(),   "Debug  Test ",  800,  600,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.SpritePerformanteTest2(),   "Debug  Test ",  800,  600,  false);  
elasticsearch_f29744cc2fd9607fa3f4761872b7b42b7d5cd960	buggy:  if  (!DocIdSets.isFastIterator(docIdSet))  {  context:  if  (filterAcceptDocs  !=  null)  {  return  weight.scorer(context,  filterAcceptDocs);  }  else  {  return  FilteredQuery.LEAP_FROG_QUERY_FIRST_STRATEGY.filteredScorer(context,  weight,  docIdSet);  }  }  if  (threshold  ==  -1)  {                  if  (!DocIdSets.isFastIterator(docIdSet))  {                  if  (!DocIdSets.isFastIterator(ApplyAcceptedDocsFilter.unwrap(docIdSet)))  {  return  FilteredQuery.QUERY_FIRST_FILTER_STRATEGY.filteredScorer(context,  weight,  docIdSet);  }  }  return  super.filteredScorer(context,  weight,  docIdSet);  }  	if  (!DocIdSets.isFastIterator(ApplyAcceptedDocsFilter.unwrap(docIdSet)))  {  
elasticsearch_13c88da9f8bee083b9c2414ac2cdabefa456dbc2	buggy:  .path(restApi.getFinalPath(pathParts));  context:  if  (restApi.getPathParts().contains(entry.getKey()))  {  pathParts.put(entry.getKey(),  entry.getValue());  }  else  {  httpRequestBuilder.addParam(entry.getKey(),  entry.getValue());  }  }  }  return  httpRequestBuilder.method(RandomizedTest.randomFrom(restApi.getSupportedMethods(pathParts.keySet())))                  .path(restApi.getFinalPath(pathParts));                  .path(RandomizedTest.randomFrom(restApi.getFinalPaths(pathParts)));  }  private  RestApi  restApi(String  apiName)  {  RestApi  restApi  =  restSpec.getApi(apiName);  if  (restApi  ==  null)  {  throw  new  IllegalArgumentException( "rest  api  [ "  +  apiName  +   "]  doesn't  exist  in  the  rest  spec ");  }  return  restApi;  	.path(RandomizedTest.randomFrom(restApi.getFinalPaths(pathParts)));  
elasticsearch_770bac252ac54b89f0a9d5242cb837040277b1c0	buggy:  listener.onFailure(exp);  context:  }  }  clusterService.remove(this);  listener.onFailure(new  NodeClosedException(nodes.localNode()));  }  clusterService.remove(this);                                  listener.onFailure(exp);                                  listener.onFailure(new  MasterNotDiscoveredException());  }  if  (event.nodesDelta().masterNodeChanged())  {  clusterService.remove(this);  innerExecute(request,  listener,  false);  }  }  	listener.onFailure(new  MasterNotDiscoveredException());  
elasticsearch_4e4495ff1d27f65d4acdcc239998a463151fe561	buggy:  return  new  Field(names.indexName(),  value,  Field.Store.YES);  context:  byte[]  value;  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  return  null;  }  else  {  value  =  context.parser().binaryValue();  }  if  (value  ==  null)  {  return  null;  }          return  new  Field(names.indexName(),  value,  Field.Store.YES);          return  new  Field(names.indexName(),  value);  }  return  CONTENT_TYPE;  }  builder.startObject(names.name());  	return  new  Field(names.indexName(),  value);  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  protected  ShardIterator  shards(ClusterState  state,  TermVectorRequest  request)  {  return  clusterService.operationRouting().getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  }  protected  void  resolveRequest(ClusterState  state,  TermVectorRequest  request)  {  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  }  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_de013babf847bdedf89bf9744d7a5ab1bb807b40	buggy:  Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  ==  null  ||  !smartNameFieldMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  mapping  for  field  [ "  +  fieldName  +   "] ");  }  FieldMapper  mapper  =  smartNameFieldMappers.mapper();  if  (!(mapper  instanceof  NumberFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "Field  [ "  +  fieldName  +   "]  is  not  a  numeric  type ");  }          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.indexCache().fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  position.set(camPos.mul(30));  context:  mid  =  start  +  (end  -  start)  /  2;  }  position.set(calculateDirection(mid));  position.y  =  -position.y;  lookAt(0,  0,  0);  normalizeUp();  }  private  float  calculateAngle  (float  a)  {  Vector3  camPos  =  calculateDirection(a);  position.set(camPos.mul(30));  position.set(camPos.scl(30));  lookAt(0,  0,  0);  normalizeUp();  update();  Vector3  orig  =  new  Vector3(0,  0,  0);  Vector3  vec  =  new  Vector3(1,  0,  0);  project(orig);  project(vec);  	position.set(camPos.scl(30));  
elasticsearch_0b09fd0806364c0785fc649b6483f00fb8e8ebf4	buggy:  return  new  InternalCountAndTotalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);  context:  counts.adjustOrPutValue(bucket,  1,  1);  totals.adjustOrPutValue(bucket,  value,  value);  }  keyScript.setNextReader(reader);  valueScript.setNextReader(reader);  }          return  new  InternalCountAndTotalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);          return  new  InternalCountAndTotalHistogramFacet(facetName,  comparatorType,  counts,  totals);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  }  	return  new  InternalCountAndTotalHistogramFacet(facetName,  comparatorType,  counts,  totals);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  this.filter  =  new  CompressedString(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());  context:  }  }  public  Builder  filter(Map<String,  Object>  filter)  {  if  (filter  ==  null  ||  filter.isEmpty())  {  this.filter  =  null;  return  this;  }  try  {  XContentBuilder  builder  =  XContentFactory.jsonBuilder().map(filter);                  this.filter  =  new  CompressedString(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());                  this.filter  =  new  CompressedString(builder.bytes());  return  this;  }  catch  (IOException  e)  {  throw  new  ElasticSearchGenerationException( "Failed  to  build  json  for  alias  request ",  e);  }  }  public  Builder  filter(XContentBuilder  filterBuilder)  {  try  {  	this.filter  =  new  CompressedString(builder.bytes());  
elasticsearch_d72de60b6f77b147ca3ec9ac0cb407c5be5ead07	buggy:  return  new  XContentDocumentMapperParser(new  AnalysisService(new  Index( "test ")));  context:  public  class  XContentMapperTests  {  public  static  XContentDocumentMapperParser  newParser()  {          return  new  XContentDocumentMapperParser(new  AnalysisService(new  Index( "test ")));          return  new  XContentDocumentMapperParser(new  Index( "test "),  new  AnalysisService(new  Index( "test ")));  }  public  static  MapperService  newMapperService()  {  return  new  MapperService(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS,  new  Environment(),  new  AnalysisService(new  Index( "test ")));  }  }  	return  new  XContentDocumentMapperParser(new  Index( "test "),  new  AnalysisService(new  Index( "test ")));  
elasticsearch_a6a993ff084a8226d44b700215d32146ed87c495	buggy:  }  catch  (IOException  e)  {  context:  throw  (IndexShardGatewaySnapshotFailedException)  e;  }  throw  new  IndexShardGatewaySnapshotFailedException(shardId(),   "Failed  to  finalize  index  snapshot  into  [ "  +  snapshotIndexCommit.getSegmentsFileName()  +   "] ",  e);  }  }  if  (snapshot.newTranslogCreated())  {  try  {  translogContainer.deleteBlob( "translog- "  +  snapshot.lastTranslogId());              }  catch  (IOException  e)  {              }  catch  (Exception  e)  {  }  }  if  (indexDirty)  {  for  (BlobMetaData  md  :  virtualIndicesBlobs.values())  {  boolean  found  =  false;  	}  catch  (Exception  e)  {  
elasticsearch_fe0f9ebc9d9abbbdc4df5df305a247ae3450c218	buggy:  assertThat(doc.doc().getField( "ip1 "),  notNullValue());  context:  XContentDocumentMapper  defaultMapper  =  MapperTests.newParser().parse(mapping);  ParsedDocument  doc  =  defaultMapper.parse( "type ",   "1 ",  XContentFactory.jsonBuilder()  .startObject()  .field( "ip1 ",   "127.0.0.1 ")  .field( "ip2 ",   "0.1 ")  .field( "ip3 ",   "127.0.0.1.2 ")  .endObject()  .copiedBytes());          assertThat(doc.doc().getField( "ip1 "),  notNullValue());          assertThat(doc.doc().getFieldable( "ip1 "),  notNullValue());  assertThat(doc.doc().get( "ip1 "),  nullValue());  //  its  numeric  assertThat(doc.doc().get( "ip2 "),  equalTo( "0.1 "));  assertThat(doc.doc().get( "ip3 "),  equalTo( "127.0.0.1.2 "));  }  }  	assertThat(doc.doc().getFieldable( "ip1 "),  notNullValue());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  IndexQueryParserService  indexQueryParser  =  indexService.queryParserService();  try  {  XContentParser  parser  =  XContentFactory.xContent(filter).createParser(filter);  try  {  indexQueryParser.parseInnerFilter(parser);  }  finally  {  parser.close();  }                                  }  catch  (Exception  e)  {                                  }  catch  (Throwable  e)  {  listener.onFailure(new  ElasticSearchIllegalArgumentException( "failed  to  parse  filter  for  [ "  +  aliasAction.alias()  +   "] ",  e));  return  currentState;  }  }  AliasMetaData  newAliasMd  =  AliasMetaData.newAliasMetaDataBuilder(  aliasAction.alias())  .filter(filter)  .indexRouting(aliasAction.indexRouting())  	}  catch  (Throwable  e)  {  
elasticsearch_637c6d1606f8a63a1c296c9fa0952b52c97c4f26	buggy:  indicesLifecycle.afterIndexShardClosed(sId);  context:  }  try  {  shardInjector.getInstance(PercolatorQueriesRegistry.class).close();  }  catch  (Throwable  e)  {  }          indicesLifecycle.afterIndexShardClosed(sId);          indicesLifecycle.afterIndexShardClosed(sId,  indexShard);  Store  store  =  shardInjector.getInstance(Store.class);  try  {  store.close();  }  catch  (Throwable  e)  {  }  	indicesLifecycle.afterIndexShardClosed(sId,  indexShard);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(clusterState.metaData().concreteIndex(request.index()));  context:  }  protected  void  doExecute(final  Request  request,  final  ActionListener<Response>  listener)  {  ClusterState  clusterState  =  clusterService.state();  ClusterBlockException  blockException  =  checkGlobalBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }          request.index(clusterState.metaData().concreteIndex(request.index()));          request.index(clusterState.metaData().concreteSingleIndex(request.index()));  blockException  =  checkRequestBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }  GroupShardsIterator  groups;  try  {  groups  =  shards(request);  	request.index(clusterState.metaData().concreteSingleIndex(request.index()));  
libgdx_ebe5a1e0b3536a1366e94fee87eb3e1040a1fd12	buggy:  Method  mMul  =  ClassReflection.getMethod(Vector2.class,   "mul ",  float.class);  context:  println( "From  default  constructor:   "  +  fromDefaultConstructor);  Method  mSet  =  ClassReflection.getMethod(Vector2.class,   "set ",  float.class,  float.class);  mSet.invoke(fromDefaultConstructor,  10,  11);  println( "Set  to  10/11:   "  +  fromDefaultConstructor);  Constructor  copyConstroctor  =  ClassReflection.getConstructor(Vector2.class,  Vector2.class);  Vector2  fromCopyConstructor  =  (Vector2)copyConstroctor.newInstance(fromDefaultConstructor);  println( "From  copy  constructor:   "  +  fromCopyConstructor);  Method  mMul  =  ClassReflection.getMethod(Vector2.class,   "mul ",  float.class);  Method  mMul  =  ClassReflection.getMethod(Vector2.class,   "scl ",  float.class);  println( "Multiplied  by  2;   "  +  mMul.invoke(fromCopyConstructor,  2));  Method  mNor  =  ClassReflection.getMethod(Vector2.class,   "nor ");  println( "Normalized:   "  +  mNor.invoke(fromCopyConstructor));  Vector2  fieldCopy  =  new  Vector2();  Field  fx  =  ClassReflection.getField(Vector2.class,   "x ");  Field  fy  =  ClassReflection.getField(Vector2.class,   "y ");  	Method  mMul  =  ClassReflection.getMethod(Vector2.class,   "scl ",  float.class);  
libgdx_0c6a387f7b0b4f5180014459b3dafaac486d61d4	buggy:  nextIndex  =  currentIndex;  context:  hasNext  =  true;  break;  }  }  }  public  void  remove  ()  {  if  (currentIndex  <  0)  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  if  (currentIndex  >=  set.capacity)  {  set.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  set.keyTable[currentIndex]  =  null;  }  currentIndex  =  -1;  set.size--;  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_9d2fe162fad94b5b4c941d28440409ffd1d4132d	buggy:  throw  new  ElasticSearchParseException( "failed  to  parse  mapping  form  compressed  string ",  e);  context:  }  return  new  MappingUpdatedResponse();  }  try  {  metaDataMappingService.updateMapping(request.index(),  request.type(),  request.mappingSource());  }  catch  (Exception  e)  {              throw  new  ElasticSearchParseException( "failed  to  parse  mapping  form  compressed  string ",  e);              throw  new  ElasticSearchParseException( "failed  to  update  mapping ",  e);  }  return  new  MappingUpdatedResponse();  }  public  static  class  MappingUpdatedResponse  implements  ActionResponse  {  }  	throw  new  ElasticSearchParseException( "failed  to  update  mapping ",  e);  
libgdx_bf3681013ba0adf647d9f59cde4456c865272541	buggy:  System.arraycopy(value,  0,  value,  length,  value.length);  context:  chars[length++]  =  'u';  chars[length++]  =  'l';  chars[length++]  =  'l';  }  final  void  append0  (char[]  value)  {  int  newSize  =  length  +  value.length;  if  (newSize  >  chars.length)  {  enlargeBuffer(newSize);  }  System.arraycopy(value,  0,  value,  length,  value.length);  System.arraycopy(value,  0,  chars,  length,  value.length);  length  =  newSize;  }  final  void  append0  (char[]  value,  int  offset,  int  length)  {  if  (offset  >  value.length  ||  offset  <  0)  {  throw  new  ArrayIndexOutOfBoundsException( "Offset  out  of  bounds:   "  +  offset);  }  	System.arraycopy(value,  0,  chars,  length,  value.length);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataMappingService  metaDataMappingService;  ThreadPool  threadPool,  MetaDataMappingService  metaDataMappingService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.metaDataMappingService  =  metaDataMappingService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.Mapping.PUT;  }  return  new  PutMappingRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  values  =  indexFieldData.load(context).getBytesValues(false);  context:  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  if  (current  !=  null)  {  missing  +=  current.missing;  total  +=  current.total;  if  (current.values.ordinals().getMaxOrd()  >  Ordinals.MIN_ORDINAL)  {  aggregators.add(current);  }  else  {  Releasables.close(current);  }  }              values  =  indexFieldData.load(context).getBytesValues(false);              values  =  indexFieldData.load(context).getBytesValues();  current  =  new  ReaderAggregator(values,  ordinalsCacheAbove,  cacheRecycler);  ordinals  =  values.ordinals();  }  public  void  collect(int  doc)  throws  IOException  {  final  int  length  =  ordinals.setDocument(doc);  int  missing  =  1;  	values  =  indexFieldData.load(context).getBytesValues();  
elasticsearch_b11f81d744a5c23bf7c20d696939e226905c60e7	buggy:  Query  query  =  Queries.MATCH_ALL_QUERY;  context:  public  String[]  names()  {  return  new  String[]{NAME};  }  public  Query  parse(QueryParseContext  parseContext)  throws  IOException,  QueryParsingException  {  XContentParser  parser  =  parseContext.parser();          Query  query  =  Queries.MATCH_ALL_QUERY;          Query  query  =  Queries.newMatchAllQuery();  Filter  filter  =  null;  boolean  filterFound  =  false;  float  boost  =  1.0f;  boolean  cache  =  false;  CacheKeyFilter.Key  cacheKey  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;  	Query  query  =  Queries.newMatchAllQuery();  
libgdx_68d33369a29e0299799835ce68a87108d6f84812	buggy:  return  getTopHeight()  +  getBottomHeight()  +  patches[MIDDLE_LEFT].getRegionHeight();  context:  public  float  getTopHeight  ()  {  return  patches[TOP_RIGHT].getRegionHeight();  }  public  float  getBottomHeight  ()  {  return  patches[BOTTOM_RIGHT].getRegionHeight();  }  public  float  getTotalHeight  ()  {  return  getTopHeight()  +  getBottomHeight()  +  patches[MIDDLE_LEFT].getRegionHeight();  return  getTopHeight()  +  getBottomHeight()  +  patches[MIDDLE_CENTER].getRegionHeight();  }  public  float  getTotalWidth  ()  {  return  getLeftWidth()  +  getRightWidth()  +  patches[MIDDLE_CENTER].getRegionWidth();  }  public  TextureRegion[]  getPatches  ()  {  return  patches;  	return  getTopHeight()  +  getBottomHeight()  +  patches[MIDDLE_CENTER].getRegionHeight();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<IndexWarmersMetaData.Entry>  entries  =  new  ArrayList<IndexWarmersMetaData.Entry>(warmers.entries().size()  +  1);  context:  IndexMetaData  indexMetaData  =  metaData.index(index);  if  (indexMetaData  ==  null)  {  throw  new  IndexMissingException(new  Index(index));  }  IndexWarmersMetaData  warmers  =  indexMetaData.custom(IndexWarmersMetaData.TYPE);  if  (warmers  ==  null)  {  warmers  =  new  IndexWarmersMetaData(new  IndexWarmersMetaData.Entry(request.name(),  request.searchRequest().types(),  source));  }  else  {  boolean  found  =  false;                                  List<IndexWarmersMetaData.Entry>  entries  =  new  ArrayList<IndexWarmersMetaData.Entry>(warmers.entries().size()  +  1);                                  List<IndexWarmersMetaData.Entry>  entries  =  new  ArrayList<>(warmers.entries().size()  +  1);  for  (IndexWarmersMetaData.Entry  entry  :  warmers.entries())  {  if  (entry.name().equals(request.name()))  {  found  =  true;  entries.add(new  IndexWarmersMetaData.Entry(request.name(),  request.searchRequest().types(),  source));  }  else  {  entries.add(entry);  }  }  	List<IndexWarmersMetaData.Entry>  entries  =  new  ArrayList<>(warmers.entries().size()  +  1);  
libgdx_594662cc9d754ba5e344160420e30e51e9bde712	buggy:  act(Gdx.graphics.getDeltaTime());  context:  camera.update();  if  (!root.isVisible())  return;  batch.setProjectionMatrix(camera.combined);  batch.begin();  root.draw(batch,  1);  batch.end();  }  public  void  act  ()  {  act(Gdx.graphics.getDeltaTime());  act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30f));  }  public  void  act  (float  delta)  {  for  (int  pointer  =  0,  n  =  pointerOverActors.length;  pointer  <  n;  pointer++)  {  	act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30f));  
elasticsearch_5ae12368574b33a8fad215ef104108fbf5435eb3	buggy:  return  mins.get(owningBucketOrd);  context:  long  from  =  mins.size();  mins  =  bigArrays.grow(mins,  owningBucketOrdinal  +  1);  mins.fill(from,  mins.size(),  Double.POSITIVE_INFINITY);  }  mins.set(owningBucketOrdinal,  Math.min(values.nextValue(),  mins.get(owningBucketOrdinal)));  }  public  double  metric(long  owningBucketOrd)  {          return  mins.get(owningBucketOrd);          return  valuesSource  ==  null  ?  Double.POSITIVE_INFINITY  :  mins.get(owningBucketOrd);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  if  (valuesSource  ==  null)  {  return  new  InternalMin(name,  Double.POSITIVE_INFINITY);  }  assert  owningBucketOrdinal  <  mins.size();  	return  valuesSource  ==  null  ?  Double.POSITIVE_INFINITY  :  mins.get(owningBucketOrd);  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  4,  6,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,   "a_pos "),  context:  int  mode  =  0;  float  mean  =  0;  float  frames  =  0;  if  (texture  ==  null)  {  Gdx.input.addInputListener(this);  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogicsmall.jpg ",  FileType.Internal),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  mesh  =  new  Mesh(true,  false,  4,  6,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,   "a_pos "),  mesh  =  new  Mesh(true,  4,  6,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,   "a_pos "),  new  VertexAttribute(VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoords "));  float[]  vertices  =  new  float[4  *  4];  int  idx  =  0;  vertices[idx++]  =  -1;  vertices[idx++]  =  -1;  vertices[idx++]  =  0;  	mesh  =  new  Mesh(true,  4,  6,  new  VertexAttribute(VertexAttributes.Usage.Position,  2,   "a_pos "),  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  .ignoreIndices(request.ignoreIndices())  context:  protected  ClusterBlockException  checkBlock(CreateSnapshotRequest  request,  ClusterState  state)  {  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,   " ");  }  protected  void  masterOperation(final  CreateSnapshotRequest  request,  ClusterState  state,  final  ActionListener<CreateSnapshotResponse>  listener)  throws  ElasticSearchException  {  SnapshotsService.SnapshotRequest  snapshotRequest  =  new  SnapshotsService.SnapshotRequest( "create_snapshot[ "  +  request.snapshot()  +   "] ",  request.snapshot(),  request.repository())  .indices(request.indices())                          .ignoreIndices(request.ignoreIndices())                          .indicesOptions(request.indicesOptions())  .settings(request.settings())  .includeGlobalState(request.includeGlobalState())  .masterNodeTimeout(request.masterNodeTimeout());  snapshotsService.createSnapshot(snapshotRequest,  new  SnapshotsService.CreateSnapshotListener()  {  public  void  onResponse()  {  if  (request.waitForCompletion())  {  snapshotsService.addListener(new  SnapshotsService.SnapshotCompletionListener()  {  	.indicesOptions(request.indicesOptions())  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  mltRequest.searchType(SearchType.fromString(request.param( "search_type ")));  mltRequest.searchIndices(request.paramAsStringArray( "search_indices ",  null));  mltRequest.searchTypes(request.paramAsStringArray( "search_types ",  null));  mltRequest.searchQueryHint(request.param( "search_query_hint "));  String  searchScroll  =  request.param( "search_scroll ");  if  (searchScroll  !=  null)  {  mltRequest.searchScroll(new  Scroll(parseTimeValue(searchScroll,  null)));  }  if  (request.hasContent())  {                  mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());                  mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  }  else  {  String  searchSource  =  request.param( "search_source ");  if  (searchSource  !=  null)  {  mltRequest.searchSource(searchSource);  }  }  }  catch  (Exception  e)  {  try  {  	mltRequest.searchSource(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  
elasticsearch_ebd6316db9be1ef69ddc0a929bb225ec6d9b7ed6	buggy:  builder.startObject(indexMetaData.index());  context:  public  Builder  state(State  state)  {  this.state  =  state;  return  this;  }  public  IndexMetaData  build()  {  return  new  IndexMetaData(index,  state,  settings,  mappings.immutableMap());  }  public  static  void  toXContent(IndexMetaData  indexMetaData,  XContentBuilder  builder,  ToXContent.Params  params)  throws  IOException  {              builder.startObject(indexMetaData.index());              builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "state ",  indexMetaData.state().toString().toLowerCase());  builder.startObject( "settings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.settings().getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  	builder.startObject(indexMetaData.index(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_e735ff49d69951c756db260967cc2527869ed18c	buggy:  client  =  new  TransportClient(ImmutableSettings.settingsBuilder().putBoolean( "discovery.enabled ",  true).build());  context:  if  (client  !=  null)  {  client.close();  }  closeAllServers();  }  public  void  testWithDiscovery()  throws  Exception  {  startServer( "server1 ");          client  =  new  TransportClient(ImmutableSettings.settingsBuilder().putBoolean( "discovery.enabled ",  true).build());          client  =  new  TransportClient(ImmutableSettings.settingsBuilder().put( "discovery.enabled ",  true).build());  Thread.sleep(1000);  client.admin().indices().create(createIndexRequest( "test ")).actionGet();  Thread.sleep(500);  client.admin().cluster().ping(pingSingleRequest( "test ").type( "person ").id( "1 ")).actionGet();  startServer( "server2 ");  Thread.sleep(1000);  	client  =  new  TransportClient(ImmutableSettings.settingsBuilder().put( "discovery.enabled ",  true).build());  
elasticsearch_b3d51df4934f2d676082d7d29f580d46c86d5b6b	buggy:  logger.debug( "{}  Refresh  request  executed.  Force:  [{}]. ",  indexShard.shardId(),  request.force());  context:  protected  ShardRefreshResponse  newShardResponse()  {  return  new  ShardRefreshResponse();  }  protected  ShardRefreshResponse  shardOperation(ShardRefreshRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.refresh(new  Engine.Refresh().force(request.force()));          logger.debug( "{}  Refresh  request  executed.  Force:  [{}]. ",  indexShard.shardId(),  request.force());          logger.trace( "{}  refresh  request  executed,  force:  [{}] ",  indexShard.shardId(),  request.force());  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  RefreshRequest  request,  String[]  concreteIndices)  {  	logger.trace( "{}  refresh  request  executed,  force:  [{}] ",  indexShard.shardId(),  request.force());  
elasticsearch_ffbc2a9d8daf636d0e92ae754f542b6a662a30e5	buggy:  result.toJson(builder);  context:  }  catch  (IOException  e1)  {  }  return;  }  client.execSearch(searchRequest,  new  ActionListener<SearchResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  builder.startObject();                      result.toJson(builder);                      result.toJson(builder,  request);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  	result.toJson(builder,  request);  
elasticsearch_9a2d27a03574446e7a2554848d6b28eeb7e48a06	buggy:  builder.field( "prefix_length ",  prefixLength);  context:  if  (maxEdits  !=  null)  {  builder.field( "max_edits ",  maxEdits);  }  if  (maxInspections  !=  null)  {  builder.field( "max_inspections ",  maxInspections);  }  if  (maxTermFreq  !=  null)  {  builder.field( "max_term_freq ",  maxTermFreq);  }  if  (prefixLength  !=  null)  {                  builder.field( "prefix_length ",  prefixLength);                  builder.field( "prefix_len ",  prefixLength);  }  if  (minWordLength  !=  null)  {  builder.field( "min_word_len ",  minWordLength);  }  if  (minDocFreq  !=  null)  {  builder.field( "min_doc_freq ",  minDocFreq);  }  if  (preFilter  !=  null)  {  	builder.field( "prefix_len ",  prefixLength);  
elasticsearch_7ba1ad2d7b1ba3a97b866bc3e53e4556f46a62fd	buggy:  return  new  ShardCountRequest(shard.index(),  shard.id(),  request.querySource(),  request.minScore(),  request.queryParserName(),  request.types());  context:  return  new  CountRequest();  }  return  new  ShardCountRequest();  }          return  new  ShardCountRequest(shard.index(),  shard.id(),  request.querySource(),  request.minScore(),  request.queryParserName(),  request.types());          return  new  ShardCountRequest(shard.index(),  shard.id(),  request);  }  return  new  ShardCountResponse();  }  return  indicesService.searchShards(clusterState,  request.indices(),  request.queryHint());  	return  new  ShardCountRequest(shard.index(),  shard.id(),  request);  
libgdx_c156c090ee26fe34e8494273eee5bc84cdbd0828	buggy:  super.draw(batch,  parentAlpha);  context:  this.fillParent  =  fillParent;  }  public  void  layout  ()  {  }  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  validate();  super.draw(batch,  parentAlpha);  super.drawChildren(batch,  parentAlpha);  }  }  	super.drawChildren(batch,  parentAlpha);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  values  =  new  ArrayList<Object>(2);  context:  uid  =  null;  }  private  void  addValue(String  name,  Object  value)  {  if  (fieldsValues  ==  null)  {  fieldsValues  =  newHashMap();  }  List<Object>  values  =  fieldsValues.get(name);  if  (values  ==  null)  {              values  =  new  ArrayList<Object>(2);              values  =  new  ArrayList<>(2);  fieldsValues.put(name,  values);  }  values.add(value);  }  }  	values  =  new  ArrayList<>(2);  
libgdx_4772e3cd7ca3ec00cb9fb1e1adbd115c906c81a4	buggy:  setVerticalSynch(false);  context:  for(  RenderListener  listener:  listeners  )  listener.render(  );  }  public  void  init(GLAutoDrawable  arg0)  {  for(  RenderListener  listener:  listeners  )  listener.surfaceCreated(  );  setVerticalSynch(false);  setVerticalSynch(true);  }  public  void  reshape(GLAutoDrawable  arg0,  int  arg1,  int  arg2,  int  arg3,  int  arg4)  {  deltaTime  =  (System.nanoTime()  -  frameStart  )  /  1000000000.0f;  frameStart  =  System.nanoTime();  	setVerticalSynch(true);  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  ret.length  =  value.offset;  context:  }  public  BytesRef  getValueScratchByOrd(int  ord,  BytesRef  ret)  {  BytesRef  value  =  values[ord];  if  (value  ==  null)  {  ret.length  =  0;  }  else  {  ret.bytes  =  value.bytes;  ret.offset  =  value.offset;                  ret.length  =  value.offset;                  ret.length  =  value.length;  }  return  ret;  }  public  BytesRef  getSafeValueByOrd(int  ord)  {  return  values[ord];  }  	ret.length  =  value.length;  
elasticsearch_673655cc7b7ab115257f75e64be4c9d918fc9144	buggy:  MapperService.SmartNameObjectMapper  mapper  =  parseContext.mapperService().smartNameObjectMapper(path);  context:  if  (path  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  requires  'path'  field ");  }  if  (filter  !=  null)  {  query  =  new  DeletionAwareConstantScoreQuery(filter);  }  query.setBoost(boost);          MapperService.SmartNameObjectMapper  mapper  =  parseContext.mapperService().smartNameObjectMapper(path);          MapperService.SmartNameObjectMapper  mapper  =  parseContext.smartObjectMapper(path);  if  (mapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  failed  to  find  nested  object  under  path  [ "  +  path  +   "] ");  }  ObjectMapper  objectMapper  =  mapper.mapper();  if  (objectMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  failed  to  find  nested  object  under  path  [ "  +  path  +   "] ");  }  if  (!objectMapper.nested().isNested())  {  	MapperService.SmartNameObjectMapper  mapper  =  parseContext.smartObjectMapper(path);  
libgdx_62ea7a809b0c463f020324b841286d6dfe92d282	buggy:  int  result  =  chooser.showSaveDialog(null);  context:  JFileChooser  chooser  =  new  JFileChooser();  chooser.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY);  chooser.setDialogTitle( "Chose  destination ");  int  result  =  chooser.showSaveDialog(null);  int  result  =  chooser.showOpenDialog(null);  if(result  ==  JFileChooser.APPROVE_OPTION)  {  File  dir  =  chooser.getSelectedFile();  if(dir  ==  null)  return;  if(dir.getAbsolutePath().trim().length()  ==  0)  return;  destinationText.setText(dir.getAbsolutePath());  }  }  	int  result  =  chooser.showOpenDialog(null);  
elasticsearch_66825ac851a2578686eefca08f1900bf86f3d443	buggy:  addDocValue(context,  value);  context:  context.allEntries().addText(names.fullName(),  ipAsString,  boost);  }  final  long  value  =  ipToLong(ipAsString);  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              addDocValue(context,  value);              addDocValue(context,  fields,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  fields,  value);  
elasticsearch_4e17543bee5583093f027677f7907319be68b732	buggy:  client(request,  listener)  context:  moreLikeThis(request)  }  GActionFuture<SearchResponse>  moreLikeThis(MoreLikeThisRequest  request)  {  GActionFuture<SearchResponse>  future  =  new  GActionFuture<SearchResponse>(internalClient.threadPool(),  request)  client.moreLikeThis(request,  future)  return  future  }  void  moreLikeThis(MoreLikeThisRequest  request,  ActionListener<SearchResponse>  listener)  {          client(request,  listener)          client.moreLikeThis(request,  listener)  }  }  	client.moreLikeThis(request,  listener)  
elasticsearch_77b6d1d8b8d304578fd97ea159b7109671eaacc6	buggy:  return   "none ";  context:  return   "none ";  }  return  NoneIndexShardGateway.class;  }          return   "none ";          return   "_none_ ";  }  }  }  	return   "_none_ ";  
libgdx_cfd67486c3b1b287313fcdf1261ea46a0091161c	buggy:  return  false;  context:  public  class  ShapeRendererTest  extends  GdxTest  {  public  boolean  needsGL20  ()  {  return  false;  return  true;  }  ShapeRenderer  renderer;  PerspectiveCamera  cam;  PerspectiveCamController  controller;  SpriteBatch  batch;  BitmapFont  font;  	return  true;  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  short  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
elasticsearch_c3ecd6fd1b5d36f94a43dd50d068a31f7944ae73	buggy:  builder.prettyPrint();  context:  if  (autoDetectSource  !=  null)  {  contentType  =  XContentFactory.xContentType(autoDetectSource);  }  }  if  (contentType  ==  null)  {  contentType  =  XContentType.JSON;  }  XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  new  BytesStreamOutput());  if  (request.paramAsBoolean( "pretty ",  false))  {              builder.prettyPrint();              builder.prettyPrint().lfAtEnd();  }  builder.humanReadable(request.paramAsBoolean( "human ",  builder.humanReadable()));  String  casing  =  request.param( "case ");  if  (casing  !=  null  &&   "camelCase ".equals(casing))  {  builder.fieldCaseConversion(XContentBuilder.FieldCaseConversion.CAMELCASE);  }  else  {  	builder.prettyPrint().lfAtEnd();  
elasticsearch_8a90f4b5ffafdfb63a313d8bd3f7fb78acb34273	buggy:  return  out.toString().trim();  context:  Cell  cell  =  col.getCell(i);  boolean  headerRowWhenNotWantingHeaders  =  i  ==  0  &&  !withHeaders  &&  col.hasHeader();  if  (!  headerRowWhenNotWantingHeaders)  {  row.append(cell.toString(col.width(),  col.align()));  row.append( "   ");  }  }  out.append(row.toString().trim());  out.append( "\n ");  }          return  out.toString().trim();          return  out.toString();  }  private  class  Column  {  private  boolean  hasHeader;  private  ArrayList<Cell>  cells;  private  byte  width;  	return  out.toString();  
elasticsearch_eb3f8b2f7952718217a8cbbbf3d988afaa1eb52f	buggy:  logger.info( "{ElasticSearch/{}}:  Stopping  ... ",  Version.full());  context:  return  this;  }  if  (!lifecycle.moveToStopped())  {  return  this;  }          logger.info( "{ElasticSearch/{}}:  Stopping  ... ",  Version.full());          logger.info( "{{}}:  Stopping  ... ",  Version.full());  if  (settings.getAsBoolean( "http.enabled ",  true))  {  injector.getInstance(HttpServer.class).stop();  }  injector.getInstance(RoutingService.class).stop();  injector.getInstance(ClusterService.class).stop();  injector.getInstance(DiscoveryService.class).stop();  injector.getInstance(MonitorService.class).stop();  	logger.info( "{{}}:  Stopping  ... ",  Version.full());  
elasticsearch_15bdba30e5901361a0408d8e8b4068bef66169ec	buggy:  if  (propName.equals( "nullValue "))  {  context:  public  static  class  TypeParser  implements  JsonTypeParser  {  ObjectNode  doubleNode  =  (ObjectNode)  node;  JsonDoubleFieldMapper.Builder  builder  =  doubleField(name);  parseNumberField(builder,  name,  doubleNode,  parserContext);  for  (Iterator<Map.Entry<String,  JsonNode>>  propsIt  =  doubleNode.getFields();  propsIt.hasNext();)  {  Map.Entry<String,  JsonNode>  entry  =  propsIt.next();  String  propName  =  entry.getKey();  JsonNode  propNode  =  entry.getValue();                  if  (propName.equals( "nullValue "))  {                  if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  builder.nullValue(nodeDoubleValue(propNode));  }  }  return  builder;  }  }  	if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  
elasticsearch_b928e7490413a191fbe64c5288a4fc98fd42e100	buggy:  return  SourceFieldVisitor.INSTANCE;  context:  this.excludes  =  excludes;  this.format  =  format;  this.formatContentType  =  format  ==  null  ?  null  :  XContentType.fromRestContentType(format);  }  public  boolean  enabled()  {  return  this.enabled;  }  public  BaseFieldVisitor  fieldSelector()  {          return  SourceFieldVisitor.INSTANCE;          return  new  SourceFieldVisitor();  }  public  void  preParse(ParseContext  context)  throws  IOException  {  super.parse(context);  }  	return  new  SourceFieldVisitor();  
elasticsearch_79368bb221253a94adabe96d2420845f918e3791	buggy:  document.add(new  StoredField( "_uid ",  uid));  context:  public  Status  needsField(FieldInfo  fieldInfo)  throws  IOException  {  if  (UidFieldMapper.NAME.equals(fieldInfo.name))  {  return  Status.YES;  }  return  uid  !=  null  ?  Status.STOP  :  Status.NO;  }  public  Document  createDocument()  {  Document  document  =  new  Document();          document.add(new  StoredField( "_uid ",  uid));          document.add(new  StoredField(UidFieldMapper.NAME,  uid));  return  document;  }  public  String  uid()  {  return  uid;  }  	document.add(new  StoredField(UidFieldMapper.NAME,  uid));  
libgdx_a52d449d0330348fbafd9ebcceeddeec901b78fc	buggy:  position.y  =  -y  +  48;  context:  spriteBatch.begin();  TextureRegion  frame  =  currentWalk.getKeyFrame(currentFrameTime,  true);  spriteBatch.draw(frame,  position.x,  position.y);  spriteBatch.end();  }  public  boolean  touchDown(int  x,  int  y,  int  pointer,  int  button)  {  position.x  =  x;        position.y  =  -y  +  48;        position.y  =  y;  return  true;  }  return  false;  }  	position.y  =  y;  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iter  =  atLeast(2);  context:  public  void  testMatchedWithShould()  throws  Exception  {  createIndex( "test ");  ensureGreen();  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "content ",   "Lorem  ipsum  dolor  sit  amet ").get();  client().prepareIndex( "test ",   "type1 ",   "2 ").setSource( "content ",   "consectetur  adipisicing  elit ").get();  refresh();          int  iter  =  atLeast(2);          int  iter  =  scaledRandomIntBetween(2,  10);  for  (int  i  =  0;  i  <  iter;  i++)  {  SearchResponse  searchResponse  =  client().prepareSearch()  .setQuery(  boolQuery()  .minimumNumberShouldMatch(1)  .should(queryString( "dolor ").queryName( "dolor "))  .should(queryString( "elit ").queryName( "elit "))  )  	int  iter  =  scaledRandomIntBetween(2,  10);  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  controller.registerHandler(GET,   "/{index}/_refresh ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  RefreshRequest  refreshRequest  =  new  RefreshRequest(RestActions.splitIndices(request.param( "index ")));  refreshRequest.listenerThreaded(false);  if  (request.hasParam( "ignore_indices "))  {  refreshRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  refreshRequest.operationThreading(operationThreading);  client.admin().indices().refresh(refreshRequest,  new  ActionListener<RefreshResponse>()  {  public  void  onResponse(RefreshResponse  response)  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_723a40ef34b634e0f7d8c0e77490ffa5cc004817	buggy:  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta))  {  context:  throw  new  ElasticsearchIllegalArgumentException( "Doc  values  field  data  doesn't  support  filters  [ "  +  fieldNames.name()  +   "] ");  }  if  (BINARY_INDEX_FIELD_NAMES.contains(fieldNames.indexName()))  {  assert  numericType  ==  null;  return  new  BinaryDVIndexFieldData(index,  fieldNames,  mapper.fieldDataType());  }  else  if  (NUMERIC_INDEX_FIELD_NAMES.contains(fieldNames.indexName()))  {  assert  !numericType.isFloatingPoint();  return  new  NumericDVIndexFieldData(index,  fieldNames,  mapper.fieldDataType());  }  else  if  (numericType  !=  null)  {                  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta))  {                  if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta1))  {  return  new  SortedNumericDVIndexFieldData(index,  fieldNames,  numericType,  mapper.fieldDataType());  }  else  {  return  new  BinaryDVNumericIndexFieldData(index,  fieldNames,  numericType,  mapper.fieldDataType());  }  }  else  {  return  new  SortedSetDVOrdinalsIndexFieldData(index,  cache,  indexSettings,  fieldNames,  breakerService,  mapper.fieldDataType());  }  	if  (Version.indexCreated(indexSettings).onOrAfter(Version.V_1_4_0_Beta1))  {  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  context:  request.index(clusterState.metaData().concreteIndex(request.index()));  return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.underlyingSource(),  request.underlyingSourceOffset(),  request.underlyingSourceLength()));  return  new  PercolateResponse(percolate.matches());  }  }  	PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.underlyingSource(),  request.underlyingSourceOffset(),  request.underlyingSourceLength()));  
elasticsearch_a16d1142a3fc47dc3e34fe9e2fe69dc329e60154	buggy:  }  catch  (IOException  e)  {  context:  public  static  boolean  safeClose(IndexWriter  writer)  {  if  (writer  ==  null)  {  return  true;  }  try  {  writer.close();  return  true;          }  catch  (IOException  e)  {          }  catch  (Throwable  e)  {  return  false;  }  }  public  static  TopDocs  readTopDocs(StreamInput  in)  throws  IOException  {  if  (!in.readBoolean())  {  return  null;  	}  catch  (Throwable  e)  {  
libgdx_965fb949573cf82be9c2bf43d9e0e7a7856be79b	buggy:  vboBatch  =  new  SpriteBatch(1000);  context:  long  startTime;  int  frames;  String[]  modes  =  {   "SpriteBatch  blended ",   "SpriteBatch  not  blended ",   "SpriteBatch  animated  blended ",   "SpriteBatch  animated  not  blended ",   "SpriteBatch  VBO  blended ",   "SpriteBatch  VBO  not  blended ",   "SpriteBatch  VBO  animated  blended ",   "SpriteBatch  VBO  animated  not  blended ",   "SpriteCache  blended ",   "SpriteCache  not  blended "  };  int  mode  =  0;  public  void  create()  {  texture  =  Gdx.graphics.newTexture(Gdx.files.internal( "data/badlogicsmall.jpg "),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  vaBatch  =  new  SpriteBatch(1000);  vboBatch  =  new  SpriteBatch(1000);  vboBatch  =  new  SpriteBatch(1000,  VertexDataType.VertexBufferObject);  cache  =  new  SpriteCache();  sprites  =  new  Sprite[SPRITES];  for(int  i  =  0;  i  <  SPRITES;  i++)  {  int  x  =  (int)(Math.random()  *  (Gdx.graphics.getWidth()  -  32));  int  y  =  (int)(Math.random()  *  (Gdx.graphics.getHeight()  -  32));  sprites[i]  =  new  Sprite(texture);  	vboBatch  =  new  SpriteBatch(1000,  VertexDataType.VertexBufferObject);  
libgdx_d32a5e0fed31ba373f4f867d417bb8154cfca5b8	buggy:  verticesBuffer.position(0);  context:  }  public  void  updateVertexBufferFromArray(  int  numVertices  )  {  verticesBuffer.position(0);  verticesBuffer.clear();  verticesBuffer.put(  verticesArray,  0,  numVertices  *  vertexSize  /  4  );  verticesBuffer.flip();  }  	verticesBuffer.clear();  
elasticsearch_fd15b6278b78be0057fad1357c1c2f511a6413d2	buggy:  int  count  =  0;  context:  public  long  getCount()  {  return  count;  }  public  Facet  reduce(ReduceContext  context)  {  List<Facet>  facets  =  context.facets();  if  (facets.size()  ==  1)  {  return  facets.get(0);  }          int  count  =  0;          long  count  =  0;  for  (Facet  facet  :  facets)  {  count  +=  ((FilterFacet)  facet).getCount();  }  return  new  InternalFilterFacet(getName(),  count);  }  static  final  class  Fields  {  static  final  XContentBuilderString  _TYPE  =  new  XContentBuilderString( "_type ");  	long  count  =  0;  
elasticsearch_f8afa4d67b374a3712782b4e95fe377877f0e0ab	buggy:  return  new  JsonXContentParser(smileFactory.createJsonParser(reader));  context:  public  XContentParser  createParser(BytesReference  bytes)  throws  IOException  {  if  (bytes.hasArray())  {  return  createParser(bytes.array(),  bytes.arrayOffset(),  bytes.length());  }  return  createParser(bytes.streamInput());  }  public  XContentParser  createParser(Reader  reader)  throws  IOException  {          return  new  JsonXContentParser(smileFactory.createJsonParser(reader));          return  new  JsonXContentParser(smileFactory.createParser(reader));  }  }  	return  new  JsonXContentParser(smileFactory.createParser(reader));  
libgdx_9a457051627dc3781fa42622df02b1c3768d71e4	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.ProjectiveTextureTest(),  config);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  config.useGL20  =  true;  new  JoglApplication(new  com.badlogic.gdx.tests.ProjectiveTextureTest(),  config);  new  JoglApplication(new  com.badlogic.gdx.tests.ETC1Test(),  config);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.ETC1Test(),  config);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  ArrayList<InternalFullDateHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullDateHistogramFacet.FullEntry  value  =  (InternalFullDateHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }          entries.release();          entries.close();  return  new  InternalFullDateHistogramFacet(facetName,  comparatorType,  entries1);  }  class  Collector  extends  FacetExecutor.Collector  {  private  final  DateHistogramProc  histoProc;  private  LongValues  keyValues;  	entries.close();  
elasticsearch_bb6fb6e08341d7c2156327ed80354ca827f19a1a	buggy:  clusterHealth  =  client( "node2 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForActiveShards(4)).actionGet();  context:  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  for  (int  i  =  0;  i  <  10;  i++)  {  assertThat(node1.client().prepareCount().setQuery(matchAllQuery()).execute().actionGet().count(),  equalTo(2l));  }  closeNode( "node1 ");          clusterHealth  =  client( "node2 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForActiveShards(4)).actionGet();          clusterHealth  =  client( "node2 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForNodes( "2 ").waitForActiveShards(4)).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  node2.client().prepareIndex( "test ",   "type1 ",   "3 ").setSource(jsonBuilder().startObject().field( "field ",   "value3 ").endObject()).execute().actionGet();  node2.client().admin().indices().prepareRefresh().execute().actionGet();  for  (int  i  =  0;  i  <  10;  i++)  {  	clusterHealth  =  client( "node2 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus().waitForNodes( "2 ").waitForActiveShards(4)).actionGet();  
elasticsearch_fe4ba2ad559451ba1cdf61cb7832855e10a93b6e	buggy:  List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  context:  this.searchContext  =  searchContext;  }  protected  Field[]  getFields(IndexReader  reader,  int  docId,  String  fieldName)  throws  IOException  {  SearchLookup  lookup  =  searchContext.lookup();  lookup.setNextReader(reader);  lookup.setNextDocId(docId);          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().sourcePath());  Field[]  fields  =  new  Field[values.size()];  for  (int  i  =  0;  i  <  values.size();  i++)  {  fields[i]  =  new  Field(mapper.names().indexName(),  values.get(i).toString(),  Field.Store.NO,  Field.Index.ANALYZED);  }  return  fields;  }  }  	List<Object>  values  =  lookup.source().extractRawValues(mapper.names().sourcePath());  
elasticsearch_c3cb5a3e349e36d4cd0f948331253032051a623a	buggy:  indexRequest.id(UUID.randomUUID().toString());  context:  }  private  void  executeBulk(final  BulkRequest  bulkRequest,  final  ActionListener<BulkResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();  for  (ActionRequest  request  :  bulkRequest.requests)  {  if  (request  instanceof  IndexRequest)  {  IndexRequest  indexRequest  =  (IndexRequest)  request;  indexRequest.index(clusterState.metaData().concreteIndex(indexRequest.index()));  if  (allowIdGeneration)  {  if  (indexRequest.id()  ==  null)  {                          indexRequest.id(UUID.randomUUID().toString());                          indexRequest.id(UUID.randomBase64UUID());  indexRequest.opType(IndexRequest.OpType.CREATE);  }  }  }  else  if  (request  instanceof  DeleteRequest)  {  DeleteRequest  deleteRequest  =  (DeleteRequest)  request;  deleteRequest.index(clusterState.metaData().concreteIndex(deleteRequest.index()));  }  	indexRequest.id(UUID.randomBase64UUID());  
libgdx_af5287684aa4acdb40715b85593d008435d4741a	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  context:  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  new  JoglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),  config);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),  config);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper);  }  }  if  (query  ==  null)  {  query  =  new  TermRangeQuery(fieldName,  from,  to,  includeLower,  includeUpper);  }  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  
libgdx_b432442fda59f17f4c481c8cab34cf0b49e3aa6e	buggy:  return  false;  context:  return  tests[testIndex].touchDragged(x,  y,  pointer);  }  public  boolean  touchUp  (int  x,  int  y,  int  pointer,  int  button)  {  return  tests[testIndex].touchUp(x,  y,  pointer,  button);  }  public  boolean  needsGL20  ()  {  return  false;  return  true;  }  public  boolean  mouseMoved  (int  x,  int  y)  {  return  tests[testIndex].mouseMoved  (x,  y);  }  	return  true;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  new  HashSet<AllocationDecider>(Arrays.asList(new  SameShardAllocationDecider(ImmutableSettings.EMPTY),  context:  public  void  testRandomDecisions()  {  RandomAllocationDecider  randomAllocationDecider  =  new  RandomAllocationDecider(getRandom());  AllocationService  strategy  =  new  AllocationService(settingsBuilder().build(),  new  AllocationDeciders(ImmutableSettings.EMPTY,                  new  HashSet<AllocationDecider>(Arrays.asList(new  SameShardAllocationDecider(ImmutableSettings.EMPTY),                  new  HashSet<>(Arrays.asList(new  SameShardAllocationDecider(ImmutableSettings.EMPTY),  randomAllocationDecider))),  new  ShardsAllocators(),  ClusterInfoService.EMPTY);  int  indices  =  between(1,  20);  Builder  metaBuilder  =  MetaData.builder();  int  maxNumReplicas  =  1;  int  totalNumShards  =  0;  for  (int  i  =  0;  i  <  indices;  i++)  {  int  replicas  =  between(0,  6);  maxNumReplicas  =  Math.max(maxNumReplicas,  replicas  +  1);  	new  HashSet<>(Arrays.asList(new  SameShardAllocationDecider(ImmutableSettings.EMPTY),  
elasticsearch_a4f974dcaacf656b3062c89a9050f9e67873021f	buggy:  InternalIndexShard  indexShard  =  (InternalIndexShard)  (indicesService.indexService(index).shard(shardId));  context:  Set<String>  nodes  =  internalCluster().nodesInclude( "test ");  assertThat(nodes.isEmpty(),  equalTo(false));  NodeEnvironment  env  =  internalCluster().getInstance(NodeEnvironment.class,  nodes.iterator().next());  return  env.nodeDataLocations();  }  private  Directory  getStoreDirectory(String  index,  int  shardId)  {  Set<String>  nodes  =  internalCluster().nodesInclude( "test ");  assertThat(nodes.isEmpty(),  equalTo(false));  IndicesService  indicesService  =  internalCluster().getInstance(IndicesService.class,  nodes.iterator().next());          InternalIndexShard  indexShard  =  (InternalIndexShard)  (indicesService.indexService(index).shard(shardId));          InternalIndexShard  indexShard  =  (InternalIndexShard)  (indicesService.indexService(index).shardSafe(shardId));  return  indexShard.store().directory();  }  }  	InternalIndexShard  indexShard  =  (InternalIndexShard)  (indicesService.indexService(index).shardSafe(shardId));  
libgdx_04c6d4b40ba09830ae9cfc756bf49af430a4db19	buggy:  gui  =  TwlRenderer.createGUI(layout,  Gdx.files.getFileHandle( "data/widgets.xml ",  FileType.Internal));  context:  .setHtml( "<div  style='font-family:heading;text-align:center'>TWL  TextAreaTest</div><a  href='badlogic'><img  src='badlogic'  id='badlogic'  style='float:right;  margin:10px'/></a>Lorem  ipsum  dolor  sit  amet,  douchebagus  joglus.  Sed  fermentum  gravida  turpis,  sit  amet  gravida  justo  laoreet  non.  Donec  ultrices  suscipit  metus  a  mollis.  Mollis  varius  egestas  quisque  feugiat  pellentesque  mi,  quis  scelerisque  velit  bibendum  eget.  Nulla  orci  in  enim  nisl  mattis  varius  dignissim  fringilla.<br/><br/><img  src='twllogo'  style='float:left;  margin:10px'/>Curabitur  purus  leo,  ultricies  ut  cursus  eget,  adipiscing  in  quam.  Duis  non  velit  vel  mauris  vulputate  fringilla  et  quis.<br/><br/><div>Suspendisse  lobortis  iaculis  tellus  id  fermentum.  Integer  fermentum  varius  pretium.  Nullam  libero  magna,  mattis  vel  placerat  ac,  dignissim  sed  lacus.  Mauris  varius  libero  id  neque  auctor  a  auctor  odio  fringilla.</div><br/><div>Mauris  orci  arcu,  porta  eget  porttitor  luctus,  malesuada  nec  metus.  Nunc  fermentum  viverra  leo  eu  pretium.  Curabitur  vitae  nibh  massa,  imperdiet  egestas  lectus.  Nulla  odio  quam,  lobortis  eget  fermentum  non,  faucibus  ac  mi.  Morbi  et  libero  nulla.  Pellentesque  habitant  morbi  tristique  senectus  et  netus  et  malesuada  fames  ac  turpis  egestas.  Aliquam  sit  amet  rhoncus  nulla.  Morbi  consectetur  ante  convallis  ante  tristique  et  porta  ligula  hendrerit.  Donec  rhoncus  ornare  augue,  sit  amet  lacinia  nulla  auctor  venenatis.</div><br/><div>Etiam  semper  egestas  porta.  Proin  luctus  porta  faucibus.  Curabitur  sagittis,  lorem  nec  imperdiet  ullamcorper,  sem  risus  consequat  purus,  non  faucibus  turpis  lorem  ut  arcu.  Nunc  tempus  lobortis  enim  vitae  facilisis.  Morbi  posuere  quam  nec  sem  aliquam  eleifend.</div> ");  ScrollPane  scrollPane  =  new  ScrollPane(textArea);  scrollPane.setFixed(ScrollPane.Fixed.HORIZONTAL);  FPSCounter  fpsCounter  =  new  FPSCounter(4,  2);  DialogLayout  layout  =  new  DialogLayout();  layout.setTheme( " ");  layout.setHorizontalGroup(layout.createParallelGroup().addWidgets(scrollPane,  fpsCounter));  layout.setVerticalGroup(layout.createSequentialGroup().addWidget(scrollPane).addGap(5).addWidget(fpsCounter).addGap(5));  gui  =  TwlRenderer.createGUI(layout,  Gdx.files.getFileHandle( "data/widgets.xml ",  FileType.Internal));  gui  =  TwlRenderer.createGUI(layout,   "data/widgets.xml ",  FileType.Internal);  textArea.addCallback(new  TextArea.Callback()  {  Timer  timer;  int  speed  =  8,  size  =  256;  public  void  handleLinkClicked  (String  href)  {  final  Element  element  =  htmlText.getElementById( "badlogic ");  if  (timer  ==  null)  {  	gui  =  TwlRenderer.createGUI(layout,   "data/widgets.xml ",  FileType.Internal);  
libgdx_43a1b81f49d45e9fc06152a426946b1ece248e58	buggy:  if  (isDisabled  &&  style.imageDisabled  !=  null)  context:  this.style  =  (ImageButtonStyle)style;  if  (image  !=  null)  updateImage();  }  public  ImageButtonStyle  getStyle  ()  {  return  style;  }  private  void  updateImage  ()  {  boolean  isPressed  =  isPressed();  if  (isDisabled  &&  style.imageDisabled  !=  null)  if  (isDisabled()  &&  style.imageDisabled  !=  null)  image.setDrawable(style.imageDisabled);  else  if  (isPressed  &&  style.imageDown  !=  null)  image.setDrawable(style.imageDown);  else  if  (isChecked  &&  style.imageChecked  !=  null)  image.setDrawable((style.imageCheckedOver  !=  null  &&  isOver())  ?  style.imageCheckedOver  :  style.imageChecked);  else  if  (isOver()  &&  style.imageOver  !=  null)  image.setDrawable(style.imageOver);  else  if  (style.imageUp  !=  null)  //  	if  (isDisabled()  &&  style.imageDisabled  !=  null)  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.indexCache());  context:  }  if  (analyzer  ==  null)  {  analyzer  =  parseContext.mapperService().searchAnalyzer();  }  if  (queryString  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }          MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.indexCache());          MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext);  queryParser.setEnablePositionIncrements(enablePositionIncrements);  queryParser.setLowercaseExpandedTerms(lowercaseExpandedTerms);  queryParser.setPhraseSlop(phraseSlop);  queryParser.setDefaultOperator(defaultOperator);  queryParser.setFuzzyMinSim(fuzzyMinSim);  queryParser.setFuzzyPrefixLength(fuzzyPrefixLength);  if  (escape)  {  	MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext);  
elasticsearch_89e6b9cfc49a34e944abb0a7834ce1a3c9be4731	buggy:  routingNode.add(shardRouting);  context:  Decision  decision  =  allocation.deciders().canAllocate(shardRouting,  routingNode,  allocation);  if  (decision.type()  ==  Decision.Type.NO)  {  throw  new  ElasticSearchIllegalArgumentException( "[allocate]  allocation  of   "  +  shardId  +   "  on  node   "  +  discoNode  +   "  is  not  allowed,  reason:   "  +  decision);  }  for  (Iterator<MutableShardRouting>  it  =  allocation.routingNodes().unassigned().iterator();  it.hasNext();  )  {  if  (it.next()  !=  shardRouting)  {  continue;  }  it.remove();              routingNode.add(shardRouting);              allocation.routingNodes().assign(shardRouting,  routingNode.nodeId());  if  (shardRouting.primary())  {  allocation.routingNodes().addClearPostAllocationFlag(shardRouting.shardId());  }  break;  }  }  	allocation.routingNodes().assign(shardRouting,  routingNode.nodeId());  
elasticsearch_fd5d754fe63dc8cf3dc12212a478ed3071eca684	buggy:  throw  new  TypeMissingException(index,  type,   "typing  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");  context:  public  DocumentMapper  documentMapper(String  type)  {  return  mappers.get(type);  }  public  DocumentMapper  documentMapperWithAutoCreate(String  type)  {  DocumentMapper  mapper  =  mappers.get(type);  if  (mapper  !=  null)  {  return  mapper;  }  if  (!dynamic)  {              throw  new  TypeMissingException(index,  type,   "typing  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");              throw  new  TypeMissingException(index,  type,   "trying  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");  }  synchronized  (mutex)  {  mapper  =  mappers.get(type);  if  (mapper  !=  null)  {  return  mapper;  }  add(type,  null);  	throw  new  TypeMissingException(index,  type,   "trying  to  auto  create  mapping,  but  dynamic  mapping  is  disabled ");  
elasticsearch_2f910fbf7e8586eaa8f191d91d85a5b7f29a9275	buggy:  }  else  if  ( "default_operator ".equals(currentFieldName))  {  context:  }  else  if  (token.isValue())  {  if  ( "query ".equals(currentFieldName))  {  queryBody  =  parser.text();  }  else  if  ( "analyzer ".equals(currentFieldName))  {  analyzer  =  parseContext.analysisService().analyzer(parser.text());  if  (analyzer  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[ "  +  NAME  +   "]  analyzer  [ "  +  parser.text()  +   "]  not  found ");  }  }  else  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();                  }  else  if  ( "default_operator ".equals(currentFieldName))  {                  }  else  if  ( "default_operator ".equals(currentFieldName)  ||   "defaultOperator ".equals(currentFieldName))  {  String  op  =  parser.text();  if  ( "or ".equalsIgnoreCase(op))  {  defaultOperator  =  BooleanClause.Occur.SHOULD;  }  else  if  ( "and ".equalsIgnoreCase(op))  {  defaultOperator  =  BooleanClause.Occur.MUST;  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[ "  +  NAME  +   "]  default  operator  [ "  +  op  +   "]  is  not  allowed ");  	}  else  if  ( "default_operator ".equals(currentFieldName)  ||   "defaultOperator ".equals(currentFieldName))  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  super(settings,  threadPool);  this.clusterService  =  clusterService;  this.shardAction  =  shardAction;  this.transportAction  =  GetFieldMappingsAction.NAME;  transportService.registerHandler(transportAction,  new  TransportHandler());  }  protected  void  doExecute(GetFieldMappingsRequest  request,  final  ActionListener<GetFieldMappingsResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {  listener.onResponse(new  GetFieldMappingsResponse());  }  else  {  boolean  probablySingleFieldRequest  =  concreteIndices.length  ==  1  &&  request.types().length  ==  1  &&  request.fields().length  ==  1;  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(double  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  DoubleFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  DoubleFieldMapper  fieldMapper  =  new  DoubleFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  searcher.release();  context:  List<DocToPurge>  docsToPurge  =  expiredDocsCollector.getDocsToPurge();  BulkRequestBuilder  bulkRequest  =  client.prepareBulk();  for  (DocToPurge  docToPurge  :  docsToPurge)  {  bulkRequest.add(new  DeleteRequest().index(shardToPurge.routingEntry().index()).type(docToPurge.type).id(docToPurge.id).version(docToPurge.version).routing(docToPurge.routing));  bulkRequest  =  processBulkIfNeeded(bulkRequest,  false);  }  processBulkIfNeeded(bulkRequest,  true);  }  catch  (Exception  e)  {  }  finally  {                  searcher.release();                  searcher.close();  }  }  }  private  static  class  DocToPurge  {  public  final  String  type;  public  final  String  id;  public  final  long  version;  	searcher.close();  
libgdx_0e597ee397058f4b418d5509df27ffb332929ef1	buggy:  final  float  localY2Cos  =  localX2  *  cos;  context:  }  if  (rotation  !=  0)  {  final  float  cos  =  MathUtils.cosDeg(rotation);  final  float  sin  =  MathUtils.sinDeg(rotation);  final  float  localXCos  =  localX  *  cos;  final  float  localXSin  =  localX  *  sin;  final  float  localYCos  =  localY  *  cos;  final  float  localYSin  =  localY  *  sin;  final  float  localX2Cos  =  localX2  *  cos;  final  float  localX2Sin  =  localX2  *  sin;  final  float  localY2Cos  =  localX2  *  cos;  final  float  localY2Cos  =  localY2  *  cos;  final  float  localY2Sin  =  localY2  *  sin;  final  float  x1  =  localXCos  -  localYSin  +  worldOriginX;  final  float  y1  =  localYCos  +  localXSin  +  worldOriginY;  vertices[X1]  =  x1;  vertices[Y1]  =  y1;  final  float  x2  =  localXCos  -  localY2Sin  +  worldOriginX;  	final  float  localY2Cos  =  localY2  *  cos;  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  targetPosition.set(x  -  10,  Gdx.graphics.getHeight()  -  y  -  10);  timer  =  0;  return  true;  }  }));  root  =  new  Table();  stage.addActor(root);  root.pad(10).top().left();  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  list  =  new  List(interpolators,  skin);  root.add(new  ScrollPane(list)).expandY().fillY().prefWidth((int)list.getPrefWidth());  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  root.setSize(width,  height);  	Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_9a13763315e8da781bf7f7b6e12c8819f9271513	buggy:  textsToHighlight  =  lookup.source().getValues(mapper.names().fullName());  context:  textsToHighlight.add(docField.stringValue());  }  }  }  catch  (Exception  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  highlight  field  [ "  +  field.field()  +   "] ",  e);  }  }  else  {  SearchLookup  lookup  =  context.lookup();  lookup.setNextReader(hitContext.reader());  lookup.setNextDocId(hitContext.docId());                          textsToHighlight  =  lookup.source().getValues(mapper.names().fullName());                          textsToHighlight  =  lookup.source().extractRawValues(mapper.names().fullName());  }  int  numberOfFragments  =  field.numberOfFragments()  ==  0  ?  1  :  field.numberOfFragments();  ArrayList<TextFragment>  fragsList  =  new  ArrayList<TextFragment>();  try  {  for  (Object  textToHighlight  :  textsToHighlight)  {  String  text  =  textToHighlight.toString();  	textsToHighlight  =  lookup.source().extractRawValues(mapper.names().fullName());  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  script.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  super.doSetNextReader(context);          script.setNextReader(context.reader());          script.setNextReader(context);  }  protected  void  doCollect(int  doc)  throws  IOException  {  script.setNextDocId(doc);  this.scriptAggregator.scriptValue  =  script.runAsDouble();  super.doCollect(doc);  }  	script.setNextReader(context);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  filteringAliases  =  new  String[aliasesSize];  for  (int  i  =  0;  i  <  aliasesSize;  i++)  {  filteringAliases[i]  =  in.readUTF();  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(shardId);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  if  (routing  !=  null)  {  out.writeVInt(routing.size());  for  (String  r  :  routing)  {  	out.writeBytesReference(querySource);  
elasticsearch_0eaccd483f486e17f02711802327298f3493f188	buggy:  return  TransportActions.Admin.Indices.CLOSE;  context:  ThreadPool  threadPool)  {  super(settings,  transportService,  clusterService,  threadPool);  }  return  ThreadPool.Names.CACHED;  }          return  TransportActions.Admin.Indices.CLOSE;          return  TransportActions.Admin.Indices.EXISTS;  }  return  new  IndicesExistsRequest();  }  return  new  IndicesExistsResponse();  	return  TransportActions.Admin.Indices.EXISTS;  
libgdx_e27bf5855b908ced39e2238ddeec39284513753e	buggy:  ModelInstance  instance  =  new  ModelInstance(model,  nodeName,  true,  true,  true);  context:  }  public  btRigidBody  createRigidBody  (boolean  isDynamic,  float  mass,  Matrix4  startTransform,  btCollisionShape  shape,  String  bodyName)  {  Vector3  localInertia  =  new  Vector3();  if  (mass  >  0f)  shape.calculateLocalInertia(mass,  localInertia);  btRigidBody  result  =  new  btRigidBody(mass,  null,  shape,  localInertia);  String  nodeName  =  bodyName.split( "_ ",  2)[0]+ "_model ";  ModelInstance  instance  =  new  ModelInstance(model,  nodeName,  true,  true,  true);  ModelInstance  instance  =  new  ModelInstance(model,  nodeName,  true,  true);  instance.transform.set(startTransform);  BulletEntity  entity  =  new  BulletEntity(instance,  result);  ImportTest.this.world.add(entity);  return  result;  }  }  	ModelInstance  instance  =  new  ModelInstance(model,  nodeName,  true,  true);  
elasticsearch_eccc7d5ef21dade9bd14d3a3adaf60e664582ac0	buggy:  sb.append( "query[ ").append(context.originalQuery()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  context:  super(context.shardTarget(),  buildMessage(context,  msg));  }  public  SearchContextException(SearchContext  context,  String  msg,  Throwable  t)  {  super(context.shardTarget(),  buildMessage(context,  msg),  t);  }  private  static  String  buildMessage(SearchContext  context,  String  msg)  {  StringBuilder  sb  =  new  StringBuilder();  sb.append('[').append(context.shardTarget().index()).append( "][ ").append(context.shardTarget().shardId()).append( "]:   ");          sb.append( "query[ ").append(context.originalQuery()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");          sb.append( "query[ ").append(context.parsedQuery().query()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  if  (context.sort()  !=  null)  {  sb.append( ",sort[ ").append(context.sort()).append( "] ");  }  return  sb.append( ":   ").append(msg).toString();  }  }  	sb.append( "query[ ").append(context.parsedQuery().query()).append( "],from[ ").append(context.from()).append( "],size[ ").append(context.size()).append( "] ");  
elasticsearch_6c7d260770047e70473571d68f4e2879a2e40152	buggy:  logger.debug( "recovery  completed  from  [{}],  took  [{}] ",  request.shardId(),  request.sourceNode(),  stopWatch.totalTime());  context:  .append( "\n ");  sb.append( "          :  reusing_files    [ ").append(recoveryResponse.phase1ExistingFileNames.size()).append( "]  with  total_size  of  [ ").append(new  ByteSizeValue(recoveryResponse.phase1ExistingTotalSize)).append( "]\n ");  sb.append( "    phase2:  start  took  [ ").append(timeValueMillis(recoveryResponse.startTime)).append( "]\n ");  sb.append( "          :  recovered  [ ").append(recoveryResponse.phase2Operations).append( "] ").append( "  transaction  log  operations ")  .append( ",  took  [ ").append(timeValueMillis(recoveryResponse.phase2Time)).append( "] ")  .append( "\n ");  sb.append( "    phase3:  recovered  [ ").append(recoveryResponse.phase3Operations).append( "] ").append( "  transaction  log  operations ")  .append( ",  took  [ ").append(timeValueMillis(recoveryResponse.phase3Time)).append( "] ");  }  else  if  (logger.isDebugEnabled())  {                  logger.debug( "recovery  completed  from  [{}],  took  [{}] ",  request.shardId(),  request.sourceNode(),  stopWatch.totalTime());                  logger.debug( "{}  recovery  completed  from  [{}],  took  [{}] ",  request.shardId(),  request.sourceNode(),  stopWatch.totalTime());  }  removeAndCleanOnGoingRecovery(recoveryStatus);  listener.onRecoveryDone();  }  catch  (Throwable  e)  {  if  (recoveryStatus.isCanceled())  {  listener.onIgnoreRecovery(false,   "canceled  recovery ");  	logger.debug( "{}  recovery  completed  from  [{}],  took  [{}] ",  request.shardId(),  request.sourceNode(),  stopWatch.totalTime());  
elasticsearch_c69b94d76923d025a6554b01b81005d35352ced9	buggy:  if  (fieldName.equals( "field "))  {  context:  IdFieldMapper.Builder  builder  =  id();  parseField(builder,  builder.name,  idNode,  parserContext);  return  builder;  }  private  AnalyzerMapper.Builder  parseAnalyzerField(Map<String,  Object>  analyzerNode,  XContentMapper.TypeParser.ParserContext  parserContext)  {  AnalyzerMapper.Builder  builder  =  analyzer();  for  (Map.Entry<String,  Object>  entry  :  analyzerNode.entrySet())  {  String  fieldName  =  Strings.toUnderscoreCase(entry.getKey());  Object  fieldNode  =  entry.getValue();              if  (fieldName.equals( "field "))  {              if  (fieldName.equals( "path "))  {  builder.field(fieldNode.toString());  }  }  return  builder;  }  private  AllFieldMapper.Builder  parseAllField(Map<String,  Object>  allNode,  XContentMapper.TypeParser.ParserContext  parserContext)  {  AllFieldMapper.Builder  builder  =  all();  	if  (fieldName.equals( "path "))  {  
elasticsearch_7709c68f6312703b60b40f9ded1bd6121daa1d58	buggy:  return  fixNegativeQueryIfNeeded(query);  context:  }  BooleanQuery  query  =  new  BooleanQuery(disableCoord);  for  (BooleanClause  clause  :  clauses)  {  query.add(clause);  }  query.setBoost(boost);  if  (minimumNumberShouldMatch  !=  -1)  {  query.setMinimumNumberShouldMatch(minimumNumberShouldMatch);  }          return  fixNegativeQueryIfNeeded(query);          return  optimizeQuery(fixNegativeQueryIfNeeded(query));  }  }  	return  optimizeQuery(fixNegativeQueryIfNeeded(query));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  stats  =  new  ArrayList<Stats>(size);  context:  public  static  ThreadPoolStats  readThreadPoolStats(StreamInput  in)  throws  IOException  {  ThreadPoolStats  stats  =  new  ThreadPoolStats();  stats.readFrom(in);  return  stats;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  int  size  =  in.readVInt();          stats  =  new  ArrayList<Stats>(size);          stats  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  Stats  stats1  =  new  Stats();  stats1.readFrom(in);  stats.add(stats1);  }  }  	stats  =  new  ArrayList<>(size);  
elasticsearch_16cd159a381979e9d92288d6c9bada8483fea520	buggy:  assertThat(fragment,  equalTo( "e  big  <b>bad</b>  dog   "));  context:  IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  TopDocs  topDocs  =  searcher.search(new  TermQuery(new  Term( "_id ",   "1 ")),  1);  assertThat(topDocs.totalHits,  equalTo(1));  FastVectorHighlighter  highlighter  =  new  FastVectorHighlighter();  String  fragment  =  highlighter.getBestFragment(highlighter.getFieldQuery(new  TermQuery(new  Term( "content ",   "bad "))),  reader,  topDocs.scoreDocs[0].doc,   "content ",  30);  assertThat(fragment,  notNullValue());          assertThat(fragment,  equalTo( "e  big  <b>bad</b>  dog   "));          assertThat(fragment,  equalTo( "the  big  <b>bad</b>  dog "));  }  public  void  testVectorHighlighterPrefixQuery()  throws  Exception  {  Directory  dir  =  new  RAMDirectory();  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  indexWriter.addDocument(doc().add(field( "_id ",   "1 ")).add(field( "content ",   "the  big  bad  dog ",  Field.Store.YES,  Field.Index.ANALYZED,  Field.TermVector.WITH_POSITIONS_OFFSETS)).build());  	assertThat(fragment,  equalTo( "the  big  <b>bad</b>  dog "));  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);  context:  WarmerStats  refreshStats  =  new  WarmerStats();  refreshStats.readFrom(in);  return  refreshStats;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(Fields.WARMER);  builder.field(Fields.CURRENT,  current);  builder.field(Fields.TOTAL,  total);          builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);          builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  builder.endObject();  return  builder;  }  static  final  class  Fields  {  static  final  XContentBuilderString  WARMER  =  new  XContentBuilderString( "warmer ");  static  final  XContentBuilderString  CURRENT  =  new  XContentBuilderString( "current ");  static  final  XContentBuilderString  TOTAL  =  new  XContentBuilderString( "total ");  	builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  values  =  idFieldData.load(context).getBytesValues();  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (facetCollector  !=  null)  {  facetCollector.setScorer(scorer);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {          values  =  idFieldData.load(context).getBytesValues();          values  =  idFieldData.load(context).getBytesValues(true);  if  (facetCollector  !=  null)  {  facetCollector.setNextReader(context);  }  }  public  boolean  acceptsDocsOutOfOrder()  {  return  true;  	values  =  idFieldData.load(context).getBytesValues(true);  
libgdx_08c2c7522a4f0bafea490484dd0635aee932f1ad	buggy:  BufferedReader  reader  =  new  BufferedReader(new  InputStreamReader(Gdx.files.readFile( "data/level.map ",  FileType.Internal)));  context:  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge  );  TextureAtlas  atlas  =  new  TextureAtlas(tiles);  for(  int  i  =  0;  i  <  12;  i++  )  {  TextureRegion  region  =  new  TextureRegion(tiles,  i  %  4  *  64  +  1,  i  /  4  *  64  +  1,  64,  64);  atlas.addRegion( " "  +  i,  region);  }  float  uSize  =  62.0f  /  256.0f;  float  vSize  =  62.0f  /  256.0f;  BufferedReader  reader  =  new  BufferedReader(new  InputStreamReader(Gdx.files.readFile( "data/level.map ",  FileType.Internal)));  BufferedReader  reader  =  new  BufferedReader(new  InputStreamReader(Gdx.files.internal( "data/level.map ").read()));  String  line  =  reader.readLine();  String  tokens[]  =  line.split( ", ");  camera.getPosition().set(Float.parseFloat(tokens[0]),  0,  Float.parseFloat(tokens[1]));  int  floors  =  Integer.parseInt(reader.readLine());  int  walls  =  Integer.parseInt(reader.readLine());  float[]  floorVertices  =  new  float[floors*20];  float[]  wallVertices  =  new  float[walls*20];  short[]  floorIndices  =  new  short[floors*6];  	BufferedReader  reader  =  new  BufferedReader(new  InputStreamReader(Gdx.files.internal( "data/level.map ").read()));  
libgdx_3d4955a7d8f15ff69c4e4dc698dbffb91f774ca6	buggy:  throw  new  GdxRuntimeException( "Texture  dimensions  must  be  a  power  of  two ");  context:  if  (!isPowerOfTwo(pixmap.getHeight())  ||  !isPowerOfTwo(pixmap.getWidth()))  throw  new  GdxRuntimeException( "Texture  dimensions  must  be  a  power  of  two ");  return  new  LwjglTexture((BufferedImage)pixmap.getNativePixmap(),  minFilter,  magFilter,  uWrap,  vWrap,  false);  }  public  Texture  newTexture  (FileHandle  file,  TextureFilter  minFilter,  TextureFilter  magFilter,  TextureWrap  uWrap,  TextureWrap  vWrap)  {  Pixmap  pixmap  =  newPixmap(file);  if  (!isPowerOfTwo(pixmap.getHeight())  ||  !isPowerOfTwo(pixmap.getWidth()))  throw  new  GdxRuntimeException( "Texture  dimensions  must  be  a  power  of  two ");  throw  new  GdxRuntimeException( "Texture  dimensions  must  be  a  power  of  two:   "  +  file);  return  new  LwjglTexture((BufferedImage)pixmap.getNativePixmap(),  minFilter,  magFilter,  uWrap,  vWrap,  false);  }  public  void  setRenderListener  (RenderListener  listener)  {  app.listeners.add(listener);  }  	throw  new  GdxRuntimeException( "Texture  dimensions  must  be  a  power  of  two:   "  +  file);  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  t.getMessage()).endObject()));  context:  channel.sendResponse(new  JsonHttpResponse(request,  OK,  builder));  }  catch  (IOException  e)  {  onFailure(e);  }  }  try  {  Throwable  t  =  unwrapCause(e);  if  (t  instanceof  IndexMissingException  ||  t  instanceof  InvalidTypeNameException)  {                          channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  t.getMessage()).endObject()));                          channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  t.getMessage()).endObject()));  }  else  {  channel.sendResponse(new  JsonThrowableHttpResponse(request,  e));  }  }  catch  (IOException  e1)  {  }  }  });  	channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  t.getMessage()).endObject()));  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  context:  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;  Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {                  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);                  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  }  }  if  (parentChildIndexFieldData  ==  null)  {  	parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  
elasticsearch_ec481159d62b09151648fe98cc92e94555b4c9f7	buggy:  Scorer  subQueryScorer  =  subQueryWeight.scorer(reader,  true,  false);  context:  }  public  void  normalize(float  norm)  {  norm  *=  getBoost();  subQueryWeight.normalize(norm);  }  public  Scorer  scorer(IndexReader  reader,  boolean  scoreDocsInOrder,  boolean  topScorer)  throws  IOException  {              Scorer  subQueryScorer  =  subQueryWeight.scorer(reader,  true,  false);              Scorer  subQueryScorer  =  subQueryWeight.scorer(reader,  scoreDocsInOrder,  false);  if  (subQueryScorer  ==  null)  {  return  null;  }  return  new  CustomBoostFactorScorer(getSimilarity(searcher),  reader,  this,  subQueryScorer);  }  public  Explanation  explain(IndexReader  reader,  int  doc)  throws  IOException  {  	Scorer  subQueryScorer  =  subQueryWeight.scorer(reader,  scoreDocsInOrder,  false);  
libgdx_3d5b25c4b1602fa62ab235181aa612ba877e0e20	buggy:  BufferUtils.copy(vertices,  sourceOffset,  buffer,  count);  context:  buffer.position(0);  buffer.limit(count);  bufferChanged();  }  public  void  updateVertices  (int  targetOffset,  float[]  vertices,  int  sourceOffset,  int  count)  {  isDirty  =  true;  final  int  pos  =  buffer.position();  buffer.position(targetOffset);  BufferUtils.copy(vertices,  sourceOffset,  buffer,  count);  BufferUtils.copy(vertices,  sourceOffset,  count,  buffer);  buffer.position(pos);  bufferChanged();  }  public  void  bind  ()  {  GL11  gl  =  Gdx.gl11;  	BufferUtils.copy(vertices,  sourceOffset,  count,  buffer);  
libgdx_4ee9e8b65b5d2a5d558eaacfa92bc1c684917088	buggy:  if  (position  ==  buffer.length)  {  context:  int  length  =  (int)length();  if  (length  ==  0)  length  =  512;  byte[]  buffer  =  new  byte[length];  int  position  =  0;  InputStream  input  =  read();  try  {  while  (true)  {  int  count  =  input.read(buffer,  position,  buffer.length  -  position);  if  (count  ==  -1)  break;  position  +=  count;  if  (position  ==  buffer.length)  {  if  (count  ==  0  &&  position  ==  buffer.length)  {  byte[]  newBuffer  =  new  byte[buffer.length  *  2];  System.arraycopy(buffer,  0,  newBuffer,  0,  position);  buffer  =  newBuffer;  }  }  }  catch  (IOException  ex)  {  throw  new  GdxRuntimeException( "Error  reading  file:   "  +  this,  ex);  	if  (count  ==  0  &&  position  ==  buffer.length)  {  
elasticsearch_f8a08a46ac4bb34f9df23a22baae2021cbe0b541	buggy:  new  Term(UidFieldMapper.NAME,  hitContext.fieldVisitor().uid().toString())  context:  return  context.version();  }  public  void  hitExecute(SearchContext  context,  HitContext  hitContext)  throws  ElasticSearchException  {  long  version  =  UidField.loadVersion(  hitContext.readerContext(),                  new  Term(UidFieldMapper.NAME,  hitContext.fieldVisitor().uid().toString())                  new  Term(UidFieldMapper.NAME,  hitContext.fieldVisitor().uid().toBytesRef())  );  if  (version  <  0)  {  version  =  -1;  }  hitContext.hit().version(version);  }  }  	new  Term(UidFieldMapper.NAME,  hitContext.fieldVisitor().uid().toBytesRef())  
elasticsearch_02c8706c3352ff9e6cdc8ec416eba650d01f07d0	buggy:  logger.warn( "Received  an  existing  node  [{}] ",  node);  context:  throw  new  ElasticSearchIllegalStateException( "Node  [ "  +  localNode  +   "]  not  master  for  join  request  from  [ "  +  node  +   "] ");  }  if  (!transportService.addressSupported(node.address().getClass()))  {  }  else  {  clusterService.submitStateUpdateTask( "zen-disco-receive(from  node[ "  +  node  +   "]) ",  new  ClusterStateUpdateTask()  {  if  (currentState.nodes().nodeExists(node.id()))  {                          logger.warn( "Received  an  existing  node  [{}] ",  node);                          logger.warn( "Received  a  join  request  for  an  existing  node  [{}] ",  node);  return  currentState;  }  return  newClusterStateBuilder().state(currentState).nodes(currentState.nodes().newNode(node)).build();  }  });  }  }  	logger.warn( "Received  a  join  request  for  an  existing  node  [{}] ",  node);  
elasticsearch_5fe2615ba7d41dd6596c020db4bd7fb7f248d58f	buggy:  IndicesStats  stats();  context:  public  interface  IndicesService  extends  Iterable<IndexService>,  LifecycleComponent<IndicesService>  {  public  boolean  changesAllowed();      IndicesStats  stats();      NodeIndicesStats  stats();  boolean  hasIndex(String  index);  IndicesLifecycle  indicesLifecycle();  Set<String>  indices();  IndexService  indexService(String  index);  	NodeIndicesStats  stats();  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  searcher.release();  context:  )  );  QueriesLoaderCollector  queryCollector  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  mapperService,  indexFieldDataService);  searcher.searcher().search(query,  queryCollector);  Map<HashedBytesRef,  Query>  queries  =  queryCollector.queries();  for  (Map.Entry<HashedBytesRef,  Query>  entry  :  queries.entrySet())  {  Query  previousQuery  =  percolateQueries.put(entry.getKey(),  entry.getValue());  shardPercolateService.addedQuery(entry.getKey(),  previousQuery,  entry.getValue());  }  }  finally  {                      searcher.release();                      searcher.close();  }  }  catch  (Exception  e)  {  throw  new  PercolatorException(shardId.index(),   "failed  to  load  queries  from  percolator  index ",  e);  }  }  }  	searcher.close();  
elasticsearch_e913b6626f45338629751b8d994a6f38de01acc1	buggy:  throw  new  ElasticsearchIllegalArgumentException( "the  field  [ "  +  field.field()  +   "]  should  be  indexed  with  positions  and  offsets  in  the  postings  list  to  be  used  with  postings  highlighter ");  context:  public  String[]  names()  {  return  new  String[]{ "postings ",   "postings-highlighter "};  }  public  HighlightField  highlight(HighlighterContext  highlighterContext)  {  FieldMapper<?>  fieldMapper  =  highlighterContext.mapper;  SearchContextHighlight.Field  field  =  highlighterContext.field;  if  (fieldMapper.fieldType().indexOptions()  !=  FieldInfo.IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS)  {              throw  new  ElasticsearchIllegalArgumentException( "the  field  [ "  +  field.field()  +   "]  should  be  indexed  with  positions  and  offsets  in  the  postings  list  to  be  used  with  postings  highlighter ");              throw  new  ElasticsearchIllegalArgumentException( "the  field  [ "  +  highlighterContext.fieldName  +   "]  should  be  indexed  with  positions  and  offsets  in  the  postings  list  to  be  used  with  postings  highlighter ");  }  SearchContext  context  =  highlighterContext.context;  FetchSubPhase.HitContext  hitContext  =  highlighterContext.hitContext;  if  (!hitContext.cache().containsKey(CACHE_KEY))  {  Query  query;  	throw  new  ElasticsearchIllegalArgumentException( "the  field  [ "  +  highlighterContext.fieldName  +   "]  should  be  indexed  with  positions  and  offsets  in  the  postings  list  to  be  used  with  postings  highlighter ");  
libgdx_3f07abf70771f92672835f1e05b579d08625f8b9	buggy:  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  context:  public  void  update  (float  delta)  {  if  (Gdx.input.isTouched())  {  isDone  =  true;  }  }  public  void  draw  (float  delta)  {  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  viewMatrix.setToOrtho2D(0,  0,  480,  320);  spriteBatch.setProjectionMatrix(viewMatrix);  spriteBatch.setTransformMatrix(transformMatrix);  spriteBatch.begin();  spriteBatch.disableBlending();  spriteBatch.setColor(Color.WHITE);  spriteBatch.draw(background,  0,  0,  480,  320,  0,  0,  512,  512,  false,  false);  	Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  
elasticsearch_0ef4000842b86b947c27d1052a8e1ed981d03fcb	buggy:  putMappingRequest.ignoreDuplicates(request.paramAsBoolean( "ignoreDuplicates ",  putMappingRequest.ignoreDuplicates()));  context:  super(settings,  client);  controller.registerHandler(PUT,   "/{index}/_mapping ",  this);  controller.registerHandler(PUT,   "/{index}/{type}/_mapping ",  this);  }  PutMappingRequest  putMappingRequest  =  putMappingRequest(splitIndices(request.param( "index ")));  putMappingRequest.type(request.param( "type "));  putMappingRequest.mappingSource(request.contentAsString());  putMappingRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));          putMappingRequest.ignoreDuplicates(request.paramAsBoolean( "ignoreDuplicates ",  putMappingRequest.ignoreDuplicates()));          putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignoreConflicts ",  putMappingRequest.ignoreConflicts()));  client.admin().indices().execPutMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.acknowledged());  builder.endObject();  	putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignoreConflicts ",  putMappingRequest.ignoreConflicts()));  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  return  fileHandle.readFile();  context:  return  new  URLConnection(url)  {  public  void  connect  ()  {  }  public  Object  getContent  ()  {  return  fileHandle;  }  public  InputStream  getInputStream  ()  {  if  (!path.endsWith( ".xml "))  return  null;  //  Only  theme  files  are  loaded  through  the  URL.  return  fileHandle.readFile();  return  fileHandle.read();  }  };  }  });  }  }  	return  fileHandle.read();  
elasticsearch_90a339ad5e4a61e750d0342be6326de46f45bedc	buggy:  InternalCountAndTotalDateHistogramFacet.registerStreams();  context:  public  abstract  class  InternalDateHistogramFacet  implements  DateHistogramFacet,  InternalFacet  {  public  static  void  registerStreams()  {  InternalCountDateHistogramFacet.registerStreams();          InternalCountAndTotalDateHistogramFacet.registerStreams();          InternalFullDateHistogramFacet.registerStreams();  }  public  abstract  Facet  reduce(String  name,  List<Facet>  facets);  }  	InternalFullDateHistogramFacet.registerStreams();  
elasticsearch_4b85407f5e8d134c9dba67bbabf0339aae8c7324	buggy:  IndexStatus  indexStatus  =  client.admin().indices().status(indicesStatus( "test ")).actionGet().index( "test ");  context:  client.close();  closeAllNodes();  }  protected  Client  getClient()  {  return  client( "server2 ");  }          IndexStatus  indexStatus  =  client.admin().indices().status(indicesStatus( "test ")).actionGet().index( "test ");          IndexStatus  indexStatus  =  client.admin().indices().prepareStatus( "test ").execute().actionGet().index( "test ");  TermsResponse  termsResponse  =  client.prepareTerms( "test ").setFields( "value ").execute().actionGet();  assertThat(termsResponse.successfulShards(),  equalTo(indexStatus.shards().size()));  assertThat(termsResponse.failedShards(),  equalTo(0));  assertThat(termsResponse.fieldsAsMap().isEmpty(),  equalTo(false));  assertThat( "no  term  freqs  for  the  'value'  since  nothing  is  indexed ",  termsResponse.field( "value ").iterator().hasNext(),  equalTo(false));  	IndexStatus  indexStatus  =  client.admin().indices().prepareStatus( "test ").execute().actionGet().index( "test ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<CandidateSet>  candidateSetsList  =  new  ArrayList<DirectCandidateGenerator.CandidateSet>();  context:  public  NoisyChannelSpellChecker(double  nonErrorLikelihood,  boolean  requireUnigram,  int  tokenLimit)  {  this.realWordLikelihood  =  nonErrorLikelihood;  this.requireUnigram  =  requireUnigram;  this.tokenLimit  =  tokenLimit;  }  public  Result  getCorrections(TokenStream  stream,  final  CandidateGenerator  generator,  float  maxErrors,  int  numCorrections,  IndexReader  reader,  WordScorer  wordScorer,  BytesRef  separator,  float  confidence,  int  gramSize)  throws  IOException  {          final  List<CandidateSet>  candidateSetsList  =  new  ArrayList<DirectCandidateGenerator.CandidateSet>();          final  List<CandidateSet>  candidateSetsList  =  new  ArrayList<>();  SuggestUtils.analyze(stream,  new  SuggestUtils.TokenConsumer()  {  CandidateSet  currentSet  =  null;  private  TypeAttribute  typeAttribute;  private  final  BytesRef  termsRef  =  new  BytesRef();  private  boolean  anyUnigram  =  false;  private  boolean  anyTokens  =  false;  public  void  reset(TokenStream  stream)  {  	final  List<CandidateSet>  candidateSetsList  =  new  ArrayList<>();  
elasticsearch_04c16b7ba5658c928b9bdd7201ef41ab151540ae	buggy:  if(locations  ==  null  |  locations.size()  ==  0)  {  context:  public  GeoConfig(GeolocationContextMapping  mapping,  Collection<String>  locations)  {  this.locations  =  locations;  this.mapping  =  mapping;  }  protected  TokenStream  wrapTokenStream(Document  doc,  TokenStream  stream)  {  Collection<String>  geohashes;              if(locations  ==  null  |  locations.size()  ==  0)  {              if  (locations  ==  null  ||  locations.size()  ==  0)  {  if(mapping.fieldName  !=  null)  {  IndexableField[]  fields  =  doc.getFields(mapping.fieldName);  if(fields.length  >  0)  {  geohashes  =  new  ArrayList<>(fields.length);  GeoPoint  spare  =  new  GeoPoint();  for  (IndexableField  field  :  fields)  {  spare.resetFromString(field.stringValue());  geohashes.add(spare.geohash());  	if  (locations  ==  null  ||  locations.size()  ==  0)  {  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "keyed ".equals(currentFieldName))  {  keyed  =  parser.booleanValue();                  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {                  }  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  {  throw  new  SearchParseException(context,   "Unexpected  token   "  +  token  +   "  in  [ "  +  aggregationName  +   "]. ");  }  }  	}  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  out.writeBoolean(true);  out.writeUTF(queryHint);  }  if  (routing  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  out.writeUTF(routing);  }          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  }  	out.writeBytesReference(querySource);  
elasticsearch_b5adc877ca6253d461a46990a79fc51cba167122	buggy:  return  new  RamAccountingTermsEnum(filteredEnum,  breaker,  this);  context:  }  return  2  *  term.length;  }  public  TermsEnum  beforeLoad(Terms  terms)  throws  IOException  {              return  new  RamAccountingTermsEnum(filteredEnum,  breaker,  this);              return  new  RamAccountingTermsEnum(filteredEnum,  breaker,  this,   "parent/child  id  cache ");  }  public  void  afterLoad(TermsEnum  termsEnum,  long  actualUsed)  {  	return  new  RamAccountingTermsEnum(filteredEnum,  breaker,  this,   "parent/child  id  cache ");  
elasticsearch_c69c66bb7ae69e2e0629c1b7182269443b3b8135	buggy:  if  (!indicesOptions.allowNoIndices()  &&  actualLst  ==  null)  {  context:  }  aliasesOrIndices  =  convertFromWildcards(aliasesOrIndices,  indicesOptions);  if  (aliasesOrIndices.length  ==  1)  {  String  aliasOrIndex  =  aliasesOrIndices[0];  if  (this.indices.containsKey(aliasOrIndex))  {  return  aliasesOrIndices;  }  String[]  actualLst  =  aliasAndIndexToIndexMap.getOrDefault(aliasOrIndex,  Strings.EMPTY_ARRAY);              if  (!indicesOptions.allowNoIndices()  &&  actualLst  ==  null)  {              if  (actualLst.length  ==  0  &&  !indicesOptions.allowNoIndices())  {  throw  new  IndexMissingException(new  Index(aliasOrIndex));  }  else  {  return  actualLst;  }  }  	if  (actualLst.length  ==  0  &&  !indicesOptions.allowNoIndices())  {  
elasticsearch_47b3a81bec33a94380f9567af6346fda3c61346f	buggy:  return  new  InternalStatisticalFacet(facetName,  statsProc.min(),  statsProc.max(),  statsProc.total(),  statsProc.sumOfSquares(),  statsProc.count());  context:  fieldData.forEachValueInDoc(doc,  statsProc);  }  fieldData  =  (NumericFieldData)  fieldDataCache.cache(fieldDataType,  reader,  fieldName,  fieldDataOptions().withFreqs(false));  }          return  new  InternalStatisticalFacet(facetName,  statsProc.min(),  statsProc.max(),  statsProc.total(),  statsProc.sumOfSquares(),  statsProc.count());          return  new  InternalStatisticalFacet(facetName,  fieldName,  statsProc.min(),  statsProc.max(),  statsProc.total(),  statsProc.sumOfSquares(),  statsProc.count());  }  public  static  class  StatsProc  implements  NumericFieldData.DoubleValueInDocProc  {  private  double  min  =  Double.NaN;  private  double  max  =  Double.NaN;  	return  new  InternalStatisticalFacet(facetName,  fieldName,  statsProc.min(),  statsProc.max(),  statsProc.total(),  statsProc.sumOfSquares(),  statsProc.count());  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  context:  public  class  PrimaryElectionRoutingTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(PrimaryElectionRoutingTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  
elasticsearch_6c552b4187e49696e81c12f10baa75304114dae0	buggy:  @Override  public  boolean  get(int  doc)  throws  IOException  {  context:  this.inclusiveUpperPoint  =  inclusiveUpperPoint;  }  return  false;  }          @Override  public  boolean  get(int  doc)  throws  IOException  {          @Override  public  boolean  get(int  doc)  {  if  (!fieldData.hasValue(doc))  {  return  false;  }  if  (fieldData.multiValued())  {  double[]  lats  =  fieldData.latValues(doc);  double[]  lons  =  fieldData.lonValues(doc);  for  (int  i  =  0;  i  <  lats.length;  i++)  {  	@Override  public  boolean  get(int  doc)  {  
libgdx_41cadccfaa7b7767c664f473826aefc2bf042d9d	buggy:  spriteSheet  =  new  SpriteSheet(Gdx.files.internal( "data/pack "),  Gdx.files.internal( "data "));  context:  public  class  SpriteSheetTest  extends  GdxTest  {  SpriteBatch  batch;  Sprite  badlogic,  badlogicSmall,  star;  SpriteSheet  spriteSheet;  public  void  create  ()  {  batch  =  new  SpriteBatch();  spriteSheet  =  new  SpriteSheet(Gdx.files.internal( "data/pack "),  Gdx.files.internal( "data "));  spriteSheet  =  new  SpriteSheet(Gdx.files.internal( "data "));  badlogic  =  spriteSheet.get( "badlogicslice ");  badlogicSmall  =  spriteSheet.get( "badlogicsmall ");  star  =  spriteSheet.get( "particle-star ");  badlogic.setPosition(50,  50);  badlogicSmall.setPosition(10,  10);  star.setPosition(10,  70);  	spriteSheet  =  new  SpriteSheet(Gdx.files.internal( "data "));  
elasticsearch_e9d9ade10f9947dd35f9ccf095c3d36698f0de8c	buggy:  assertThat(facet.getCount(),  equalTo(0l));  context:  SearchResponse  searchResponse  =  client().prepareSearch()  .setSearchType(SearchType.COUNT)  .setFacets(new  BytesArray(   "{\ "facet1\ ":{\ "filter\ ":{  }}} ").array())  .get();  assertHitCount(searchResponse,  1l);  assertThat(searchResponse.getHits().hits().length,  equalTo(0));  FilterFacet  facet  =  searchResponse.getFacets().facet( "facet1 ");  assertThat(facet.getName(),  equalTo( "facet1 "));          assertThat(facet.getCount(),  equalTo(0l));          assertThat(facet.getCount(),  equalTo(1l));  }  public  void  testSimpleFacetEmptyFilterFacet()  throws  Exception  {  createIndex( "test ");  ensureGreen();  client().prepareIndex( "test ",   "type1 ").setSource(jsonBuilder().startObject()  .field( "tag ",   "green ")  	assertThat(facet.getCount(),  equalTo(1l));  
elasticsearch_042af200e80930aafedb8a6f85eab12d06501189	buggy:  node  =  nodeBuilder().local(true).node();  context:  public  class  SimpleAttachmentIntegrationTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(getClass());  private  Node  node;          node  =  nodeBuilder().local(true).node();          node  =  nodeBuilder().local(true).settings(settingsBuilder().put( "gateway.type ",   "none ")).node();  }  node.close();  }  	node  =  nodeBuilder().local(true).settings(settingsBuilder().put( "gateway.type ",   "none ")).node();  
libgdx_8d90add399e0b0ff98cf20243cfea80f0c3609b4	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.ActionTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_c00120b8184799e124a66ede5766a965026149b4	buggy:  SinglePassStatistics  single  =  new  SinglePassStatistics();  context:  this.totalTime  =  totalTime;  this.sumTotalHits  =  sumTotalHits;  this.slowRequests  =  slowestRequests;  this.numQueries  =  numQueries;  this.iterationData  =  iterationData;  this.millisPerHit  =  totalTime  /  (double)sumTotalHits;  }  public  void  computeStatistics()  {          SinglePassStatistics  single  =  new  SinglePassStatistics();          final  SinglePassStatistics  single  =  new  SinglePassStatistics();  for  (long  datum  :  iterationData.data())  {  if  (datum  >  -1)  {    //  ignore  unset  values  in  the  underlying  array  single.push(datum);  }  }  sum  =  single.sum();  	final  SinglePassStatistics  single  =  new  SinglePassStatistics();  
elasticsearch_476e28f4ce5923bd95d2f7170a04edf319c20d92	buggy:  service.abortBenchmark(request.benchmarkName(),  listener);  context:  return  new  AbortBenchmarkRequest();  }  protected  AbortBenchmarkResponse  newResponse()  {  return  new  AbortBenchmarkResponse();  }  protected  void  masterOperation(AbortBenchmarkRequest  request,  ClusterState  state,  final  ActionListener<AbortBenchmarkResponse>  listener)  throws  ElasticsearchException  {          service.abortBenchmark(request.benchmarkName(),  listener);          service.abortBenchmark(request.benchmarkNames(),  listener);  }  }  	service.abortBenchmark(request.benchmarkNames(),  listener);  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (!docMapper.typeMapper().indexed())  {  context:  return  docMapper.typeFilter();  }  boolean  useTermsFilter  =  true;  for  (String  type  :  types)  {  DocumentMapper  docMapper  =  documentMapper(type);  if  (docMapper  ==  null)  {  useTermsFilter  =  false;  break;  }              if  (!docMapper.typeMapper().indexed())  {              if  (!docMapper.typeMapper().fieldType().indexed())  {  useTermsFilter  =  false;  break;  }  }  if  (useTermsFilter)  {  Term[]  typesTerms  =  new  Term[types.length];  for  (int  i  =  0;  i  <  typesTerms.length;  i++)  {  typesTerms[i]  =  new  Term(TypeFieldMapper.NAME,  types[i]);  	if  (!docMapper.typeMapper().fieldType().indexed())  {  
libgdx_36a4ac8ffe5f7c2bcbf1ff6678778c8e5ddcc1f0	buggy:  root.add(new  FlickScrollPane(list,  stage)).expandY().fillY().prefWidth((int)list.getPrefWidth());  context:  }  }));  root  =  new  Table();  stage.addActor(root);  root.pad(10).top().left();  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  list  =  new  List(interpolators,  skin);  root.add(new  FlickScrollPane(list,  stage)).expandY().fillY().prefWidth((int)list.getPrefWidth());  root.add(new  FlickScrollPane(list)).expandY().fillY().prefWidth((int)list.getPrefWidth());  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  root.width  =  width;  root.height  =  height;  root.invalidate();  }  	root.add(new  FlickScrollPane(list)).expandY().fillY().prefWidth((int)list.getPrefWidth());  
libgdx_0d560643c720ea2ee7bc89d6fb04a0668aa3d91c	buggy:  return  96.0  /  160;  context:  public  void  setTitle  (String  title)  {  }  public  void  setVSync  (boolean  vsync)  {  }  public  float  getDensity  ()  {  return  96.0  /  160;  return  96.0f  /  160;  }  public  void  setContinuousRendering  (boolean  isContinuous)  {  }  public  boolean  isContinuousRendering  ()  {  	return  96.0f  /  160;  
elasticsearch_ab2a655a5974593d65cf3d7f1388196a709e29dc	buggy:  Query  query  =  indexQueryParser.parse(qSourceParser);  context:  public  class  QueryBinaryParseElement  implements  SearchParseElement  {  XContentIndexQueryParser  indexQueryParser  =  (XContentIndexQueryParser)  context.queryParser();  byte[]  querySource  =  parser.binaryValue();  XContentParser  qSourceParser  =  XContentFactory.xContent(querySource).createParser(querySource);          Query  query  =  indexQueryParser.parse(qSourceParser);          Query  query  =  indexQueryParser.parse(qSourceParser).query();  context.query(query);  }  }  	Query  query  =  indexQueryParser.parse(qSourceParser).query();  
elasticsearch_76e1a6b1bf7588970c5a0ac896e06299e5fbbf1f	buggy:  if  (numberOfShardsToAllocate  ==  0)  {  context:  for  (int  i  =  0;  i  <  nodes.size();  i++)  {  RoutingNode  node  =  nodes.get(lastNode);  lastNode++;  if  (lastNode  ==  nodes.size())  lastNode  =  0;  if  (node.canAllocate(routingNodes)  &&  node.canAllocate(shard))  {  int  numberOfShardsToAllocate  =  routingNodes.requiredAverageNumberOfShardsPerNode()  -  node.shards().size();                      if  (numberOfShardsToAllocate  ==  0)  {                      if  (numberOfShardsToAllocate  <=  0)  {  continue;  }  changed  =  true;  node.add(shard);  unassignedIterator.remove();  break;  }  	if  (numberOfShardsToAllocate  <=  0)  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(RefreshResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_0de30e1798505ecc6ee8a2636b5d86474d3677f8	buggy:  String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";  context:  builders.clear();  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "1 ").setSource( "{\ "theField\ ":\ "foo\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "2 ").setSource( "{\ "theField\ ":\ "foo  2\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "3 ").setSource( "{\ "theField\ ":\ "foo  3\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "4 ").setSource( "{\ "theField\ ":\ "foo  4\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "5 ").setSource( "{\ "theField\ ":\ "bar\ "} "));  indexRandom(true,builders);  SearchResponse  searchResponse;          String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";          String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "script_id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "script_id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";  searchResponse  =  client().prepareSearch().setSource(query).setIndices( "test ").setTypes( "scriptTest ").get();  assertHitCount(searchResponse,5);  assertTrue(searchResponse.getHits().hits().length  ==  1);  SearchHit  sh  =  searchResponse.getHits().getAt(0);  assertThat((Integer)sh.field( "test1 ").getValue(),  equalTo(2));  assertThat((Integer)sh.field( "test2 ").getValue(),  equalTo(6));  }  }  	String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "script_id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "script_id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}    }},  size:1} ";  
libgdx_7783ad3e5eb7217c317a281ececc62517270d259	buggy:  particleCount  =  (int)(emitter.getEmission().getHighMax()  *  emitter.getLife().getHighMax());  context:  public  boolean  keyDown  (int  keycode)  {  ParticleEmitter  emitter  =  emitters.get(emitterIndex);  if  (keycode  ==  Input.Keys.KEYCODE_DPAD_UP)  particleCount  +=  5;  else  if  (keycode  ==  Input.Keys.KEYCODE_DPAD_DOWN)  particleCount  -=  5;  else  if  (keycode  ==  Input.Keys.KEYCODE_SPACE)  {  emitterIndex  =  (emitterIndex  +  1)  %  emitters.size();  emitter  =  emitters.get(emitterIndex);  particleCount  =  (int)(emitter.getEmission().getHighMax()  *  emitter.getLife().getHighMax());  particleCount  =  (int)(emitter.getEmission().getHighMax()  *  emitter.getLife().getHighMax()  /  1000f);  }  else  return  false;  particleCount  =  Math.max(0,  particleCount);  if  (particleCount  >  emitter.getMaxParticleCount())  emitter.setMaxParticleCount(particleCount  *  2);  emitter.getEmission().setHigh(particleCount  /  emitter.getLife().getHighMax()  *  1000);  effect.getEmitters().clear();  effect.getEmitters().add(emitter);  return  false;  	particleCount  =  (int)(emitter.getEmission().getHighMax()  *  emitter.getLife().getHighMax()  /  1000f);  
elasticsearch_051e6a02a7f54c4ad00276f093b78054b0e3f3d1	buggy:  if  ( "cluster ".equals( "sLevel "))  {  context:  clusterHealthRequest.timeout(request.paramAsTime( "timeout ",  clusterHealthRequest.timeout()));  String  waitForStatus  =  request.param( "wait_for_status ");  if  (waitForStatus  !=  null)  {  clusterHealthRequest.waitForStatus(ClusterHealthStatus.valueOf(waitForStatus.toUpperCase()));  }  clusterHealthRequest.waitForRelocatingShards(request.paramAsInt( "wait_for_relocating_shards ",  clusterHealthRequest.waitForRelocatingShards()));  clusterHealthRequest.waitForActiveShards(request.paramAsInt( "wait_for_active_shards ",  clusterHealthRequest.waitForActiveShards()));  clusterHealthRequest.waitForNodes(request.param( "wait_for_nodes ",  clusterHealthRequest.waitForNodes()));  String  sLevel  =  request.param( "level ");  if  (sLevel  !=  null)  {                  if  ( "cluster ".equals( "sLevel "))  {                  if  ( "cluster ".equals(sLevel))  {  level  =  0;  }  else  if  ( "indices ".equals(sLevel))  {  level  =  1;  }  else  if  ( "shards ".equals(sLevel))  {  level  =  2;  }  }  }  catch  (Exception  e)  {  	if  ( "cluster ".equals(sLevel))  {  
libgdx_1b5fcb406e9caabac0b9cf3fb0efea6d378de387	buggy:  ETC1.encodeImage(pixmap).write(new  FileHandle(inputFile.outputFile));  context:  protected  void  processFile  (InputFile  inputFile)  throws  Exception  {  Pixmap  pixmap  =  new  Pixmap(new  FileHandle(inputFile.inputFile));  if  (pixmap.getFormat()  !=  Format.RGB888  &&  pixmap.getFormat()  !=  Format.RGB565)  {  Pixmap  tmp  =  new  Pixmap(pixmap.getWidth(),  pixmap.getHeight(),  Format.RGB888);  tmp.drawPixmap(pixmap,  0,  0,  0,  0,  pixmap.getWidth(),  pixmap.getHeight());  pixmap.dispose();  pixmap  =  tmp;  }  ETC1.encodeImage(pixmap).write(new  FileHandle(inputFile.outputFile));  ETC1.encodeImagePKM(pixmap).write(new  FileHandle(inputFile.outputFile));  pixmap.dispose();  }  protected  void  processDir  (InputFile  inputDir,  ArrayList<InputFile>  value)  throws  Exception  {  if  (!inputDir.outputDir.exists())  {  if  (!inputDir.outputDir.mkdirs())  throw  new  Exception( "Couldn't  create  output  directory  ' "  +  inputDir.outputDir  +   "' ");  	ETC1.encodeImagePKM(pixmap).write(new  FileHandle(inputFile.outputFile));  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  testScroll(atLeast(100),  between(1,  300),  getRandom().nextBoolean(),  getRandom().nextBoolean());  context:  public  class  SearchScanScrollingTests  extends  ElasticsearchIntegrationTest  {  public  void  testRandomized()  throws  Exception  {          testScroll(atLeast(100),  between(1,  300),  getRandom().nextBoolean(),  getRandom().nextBoolean());          testScroll(scaledRandomIntBetween(100,  200),  between(1,  300),  getRandom().nextBoolean(),  getRandom().nextBoolean());  }  private  void  testScroll(long  numberOfDocs,  int  size,  boolean  unbalanced,  boolean  trackScores)  throws  Exception  {  createIndex( "test ");  ensureGreen();  Set<String>  ids  =  Sets.newHashSet();  Set<String>  expectedIds  =  Sets.newHashSet();  	testScroll(scaledRandomIntBetween(100,  200),  between(1,  300),  getRandom().nextBoolean(),  getRandom().nextBoolean());  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  BytesStreamOutput  os  =  cachedEntry.cachedBytes();  context:  return  this;  }  public  ClusterState  build()  {  return  new  ClusterState(version,  metaData,  routingTable,  nodes,  blocks,  allocationExplanation);  }  public  static  byte[]  toBytes(ClusterState  state)  throws  IOException  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {                  BytesStreamOutput  os  =  cachedEntry.cachedBytes();                  BytesStreamOutput  os  =  cachedEntry.bytes();  writeTo(state,  os);  return  os.copiedByteArray();  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  }  }  public  static  ClusterState  fromBytes(byte[]  data,  DiscoveryNode  localNode)  throws  IOException  {  	BytesStreamOutput  os  =  cachedEntry.bytes();  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  }  if  (value  instanceof  BytesRef)  {  return  Numbers.bytesToShort((BytesRef)  value);  }  return  Short.parseShort(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  short  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).shortValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);    //  0  because  of  exact  match  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  scriptService,  pageCacheRecycler,  bigArrays);  context:  protected  ShardCountResponse  shardOperation(ShardCountRequest  request)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.shardId().getIndex());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.shardId().getIndex(),  request.shardId().id());  SearchContext  context  =  new  DefaultSearchContext(0,  new  ShardSearchRequest(request).types(request.types())  .filteringAliases(request.filteringAliases())  .nowInMillis(request.nowInMillis()),  shardTarget,  indexShard.acquireSearcher( "count "),  indexService,  indexShard,                  scriptService,  pageCacheRecycler,  bigArrays);                  scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  SearchContext.setCurrent(context);  try  {  if  (request.minScore()  !=  -1)  {  context.minimumScore(request.minScore());  }  BytesReference  source  =  request.querySource();  	scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  double  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
elasticsearch_ec6539df37f6bdd74165441a6e54627707431747	buggy:  indexShard.acquireSearcher( "delete_by_query "),  indexService,  indexShard,  scriptService,  cacheRecycler));  context:  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  ShardDeleteByQueryRequest  request  =  shardRequest.request;  IndexService  indexService  =  indicesService.indexServiceSafe(shardRequest.request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardRequest.shardId);  SearchContext.setCurrent(new  DefaultSearchContext(0,  new  ShardSearchRequest().types(request.types()),  null,                  indexShard.acquireSearcher( "delete_by_query "),  indexService,  indexShard,  scriptService,  cacheRecycler));                  indexShard.acquireSearcher( "delete_by_query ",  IndexShard.Mode.WRITE),  indexService,  indexShard,  scriptService,  cacheRecycler));  try  {  Engine.DeleteByQuery  deleteByQuery  =  indexShard.prepareDeleteByQuery(request.querySource(),  request.filteringAliases(),  request.types())  .origin(Engine.Operation.Origin.REPLICA);  SearchContext.current().parsedQuery(new  ParsedQuery(deleteByQuery.query(),  ImmutableMap.<String,  Filter>of()));  indexShard.deleteByQuery(deleteByQuery);  }  finally  {  SearchContext  searchContext  =  SearchContext.current();  searchContext.clearAndRelease();  	indexShard.acquireSearcher( "delete_by_query ",  IndexShard.Mode.WRITE),  indexService,  indexShard,  scriptService,  cacheRecycler));  
elasticsearch_1e14a30d4c7c795f7f2511083b450c7e8a1dc020	buggy:  return  this.refresh();  context:  public  MergeStats  merge()  {  return  this.mergeStats;  }  public  MergeStats  getMerge()  {  return  this.mergeStats;  }  public  RefreshStats  refresh()  {          return  this.refresh();          return  this.refreshStats;  }  public  RefreshStats  getRefresh()  {  return  this.refresh();  }  public  FlushStats  flush()  {  return  this.flushStats;  	return  this.refreshStats;  
elasticsearch_1f50b07406d0fa5f10a733445a622044671ccabe	buggy:  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  null,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  context:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  null,  childType,  parentType,  scoreType,  factor,  incrementalFactor);          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  searchContext.addRewrite(childQuery);  return  childQuery;  }  }  	TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  
elasticsearch_ef1866aed4730471257f893c20c9254109cb7df9	buggy:  logger.trace( "Flush ");  context:  writeAllowed();  if  (logger.isTraceEnabled())  {  }  engine.refresh(refresh);  }  writeAllowed();  if  (logger.isTraceEnabled())  {              logger.trace( "Flush ");              logger.trace( "Flush  with  {} ",  flush);  }  engine.flush(flush);  }  writeAllowed();  if  (logger.isTraceEnabled())  {  	logger.trace( "Flush  with  {} ",  flush);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  query  =  smartNameFieldMappers.mapper().fieldQuery(value);  }  }  if  (query  ==  null)  {  query  =  new  TermQuery(new  Term(fieldName,  value));  }  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_7bcee7660a0c43f4692b6965db3bd5ab95cf5868	buggy:  listener.onFailure(new  MasterNotDiscoveredException());  context:  public  void  onClose()  {  clusterService.remove(this);  listener.onFailure(new  NodeClosedException(nodes.localNode()));  }  public  void  onTimeout(TimeValue  timeout)  {  clusterService.remove(this);                              listener.onFailure(new  MasterNotDiscoveredException());                              listener.onFailure(new  MasterNotDiscoveredException( "waited  for  [ "  +  timeout  +   "] "));  }  public  void  clusterChanged(ClusterChangedEvent  event)  {  if  (event.nodesDelta().masterNodeChanged())  {  clusterService.remove(this);  innerExecute(request,  listener,  true);  }  	listener.onFailure(new  MasterNotDiscoveredException( "waited  for  [ "  +  timeout  +   "] "));  
libgdx_9342bc7d93397d3f4915f4bda17f3376a70e27c1	buggy:  new  JoglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/r2skin.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  context:  }  }  public  static  void  main(String[]  argv)  {  new  JoglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/r2skin.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  new  JoglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  }  }  	new  JoglApplication(new  SkeletonModelViewer( "data/robot-mesh.xml ",   "data/robot.jpg "),   "SkeletonModel  Viewer ",  800,  480,  false);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().current()  ==  0)  {  context:  continue;  }  if  (status.translogId  ==  translog.currentId()  &&  translog.estimatedNumberOfOperations()  ==  0)  {  if  (status.time  ==  -1)  {  //  first  time  status.time  =  time;  }  if  (!status.inactiveIndexing)  {                                  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().current()  ==  0)  {                                  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().getCurrent()  ==  0)  {  activeToInactiveIndexingShards.add(indexShard);  status.inactiveIndexing  =  true;  activeInactiveStatusChanges  =  true;  }  }  }  else  {  	if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().getCurrent()  ==  0)  {  
elasticsearch_5b4846b0b68af6d4893322ac51a87d6283930497	buggy:  shardStatus.translogOperations  =  indexShard.translog().size();  context:  ShardStatus  shardStatus  =  new  ShardStatus(indexShard.routingEntry());  shardStatus.state  =  indexShard.state();  try  {  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  shardStatus.translogId  =  indexShard.translog().currentId();              shardStatus.translogOperations  =  indexShard.translog().size();              shardStatus.translogOperations  =  indexShard.translog().numberOfOperations();  Engine.Searcher  searcher  =  indexShard.searcher();  try  {  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {  searcher.release();  	shardStatus.translogOperations  =  indexShard.translog().numberOfOperations();  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(cachedEntry.bytes().unsafeByteArray(),  0,  cachedEntry.bytes().size());  context:  Channel  targetChannel  =  nodeChannel(node,  options);  if  (compress)  {  options.withCompress(true);  }  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  TransportStreams.buildRequest(cachedEntry,  requestId,  action,  message,  options);          ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(cachedEntry.bytes().unsafeByteArray(),  0,  cachedEntry.bytes().size());          ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(cachedEntry.bytes().underlyingBytes(),  0,  cachedEntry.bytes().size());  ChannelFuture  future  =  targetChannel.write(buffer);  future.addListener(new  CacheFutureListener(cachedEntry));  	ChannelBuffer  buffer  =  ChannelBuffers.wrappedBuffer(cachedEntry.bytes().underlyingBytes(),  0,  cachedEntry.bytes().size());  
elasticsearch_c0a7dc327c547e22f45dfc9f25090255969bb3f6	buggy:  return  new  InternalRangeDistanceFacet(facetName,  keyFieldName,  valueFieldName,  entries);  context:  if  (key  >=  entry.getFrom()  &&  key  <  entry.getTo())  {  entry.count++;  entry.total  +=  value;  }  }  }  }  }          return  new  InternalRangeDistanceFacet(facetName,  keyFieldName,  valueFieldName,  entries);          return  new  InternalRangeFacet(facetName,  keyFieldName,  valueFieldName,  entries);  }  }  	return  new  InternalRangeFacet(facetName,  keyFieldName,  valueFieldName,  entries);  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  WildcardQuery  query  =  new  WildcardQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "script_values_sorted ".equals(currentFieldName))  {  	}  else  if  ( "lang ".equals(currentFieldName))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<Integer,  Long>  controlDocToOrdinal  =  new  HashMap<Integer,  Long>();  context:  public  class  SingleOrdinalsTests  extends  ElasticsearchTestCase  {  public  void  testSvValues()  throws  IOException  {  int  numDocs  =  1000000;  int  numOrdinals  =  numDocs  /  4;          Map<Integer,  Long>  controlDocToOrdinal  =  new  HashMap<Integer,  Long>();          Map<Integer,  Long>  controlDocToOrdinal  =  new  HashMap<>();  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(numDocs);  long  ordinal  =  builder.nextOrdinal();  for  (int  doc  =  0;  doc  <  numDocs;  doc++)  {  if  (doc  %  numOrdinals  ==  0)  {  ordinal  =  builder.nextOrdinal();  }  controlDocToOrdinal.put(doc,  ordinal);  builder.addDoc(doc);  	Map<Integer,  Long>  controlDocToOrdinal  =  new  HashMap<>();  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  this.childrenIterator  =  childrenIterator;  this.typeCache  =  typeCache;  }  public  float  score()  throws  IOException  {  return  currentScore;  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  1;  }  public  int  docID()  {  return  currentChildDoc;  	public  int  freq()  throws  IOException  {  
elasticsearch_9c0b25dcce63f5ba7cbda224d0f250956a232465	buggy:  String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";  context:  builders.clear();  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "1 ").setSource( "{\ "theField\ ":\ "foo\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "2 ").setSource( "{\ "theField\ ":\ "foo  2\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "3 ").setSource( "{\ "theField\ ":\ "foo  3\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "4 ").setSource( "{\ "theField\ ":\ "foo  4\ "} "));  builders.add(client().prepareIndex( "test ",   "scriptTest ",   "5 ").setSource( "{\ "theField\ ":\ "bar\ "} "));  indexRandom(true,builders);  SearchResponse  searchResponse;          String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";          String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}  }},  size:1} ";  searchResponse  =  client().prepareSearch().setSource(query).setIndices( "test ").setTypes( "scriptTest ").get();  assertHitCount(searchResponse,5);  assertTrue(searchResponse.getHits().hits().length  ==  1);  SearchHit  sh  =  searchResponse.getHits().getAt(0);  assertThat((Integer)sh.field( "test1 ").getValue(),  equalTo(2));  assertThat((Integer)sh.field( "test2 ").getValue(),  equalTo(6));  }  }  	String  query  =   "{  \ "query\ "  :  {  \ "match_all\ ":  {}}  ,  \ "script_fields\ "  :  {  \ "test1\ "  :  {  \ "id\ "  :  \ "script1\ ",  \ "lang\ ":\ "groovy\ "  },  \ "test2\ "  :  {  \ "id\ "  :  \ "script2\ ",  \ "lang\ ":\ "groovy\ ",  \ "params\ ":{\ "factor\ ":3}    }},  size:1} ";  
elasticsearch_53bfe44e19f4ba6ad235845f2901c5c22d1abc4b	buggy:  logger.debug( "failed  to  delete  template  [{}] ",  t,  request.name());  context:  .masterTimeout(request.masterNodeTimeout()),  new  MetaDataIndexTemplateService.PutListener()  {  public  void  onResponse(MetaDataIndexTemplateService.PutResponse  response)  {  listener.onResponse(new  PutIndexTemplateResponse(response.acknowledged()));  }  public  void  onFailure(Throwable  t)  {                          logger.debug( "failed  to  delete  template  [{}] ",  t,  request.name());                          logger.debug( "failed  to  put  template  [{}] ",  t,  request.name());  listener.onFailure(t);  }  });  }  }  	logger.debug( "failed  to  put  template  [{}] ",  t,  request.name());  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  filter  =  smartNameFieldMappers.mapper().fieldFilter(value);  }  }  if  (filter  ==  null)  {  filter  =  new  TermFilter(new  Term(fieldName,  value));  }  filter  =  parseContext.cacheFilterIfPossible(filter);          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_311520d14682a1f3096dc9307da3e5fcb82936ab	buggy:  shardStatus.peerRecoveryStatus  =  new  ShardStatus.PeerRecoveryStatus(stage,  peerRecoveryStatus.startTime(),  peerRecoveryStatus.took(),  context:  break;  case  FINALIZE:  stage  =  ShardStatus.PeerRecoveryStatus.Stage.FINALIZE;  break;  case  DONE:  stage  =  ShardStatus.PeerRecoveryStatus.Stage.DONE;  break;  default:  stage  =  ShardStatus.PeerRecoveryStatus.Stage.INIT;  }              shardStatus.peerRecoveryStatus  =  new  ShardStatus.PeerRecoveryStatus(stage,  peerRecoveryStatus.startTime(),  peerRecoveryStatus.took(),              shardStatus.peerRecoveryStatus  =  new  ShardStatus.PeerRecoveryStatus(stage,  peerRecoveryStatus.startTime(),  peerRecoveryStatus.time(),  peerRecoveryStatus.retryTime(),  peerRecoveryStatus.phase1TotalSize(),  peerRecoveryStatus.phase1ExistingTotalSize(),  peerRecoveryStatus.currentFilesSize(),  peerRecoveryStatus.currentTranslogOperations());  }  return  shardStatus;  }  	shardStatus.peerRecoveryStatus  =  new  ShardStatus.PeerRecoveryStatus(stage,  peerRecoveryStatus.startTime(),  peerRecoveryStatus.time(),  
elasticsearch_da953700f47924f4948ec3775eb1f42f3109aac7	buggy:  terms.trimExcessEntries();  context:  public  Type  type()  {  return  TYPE;  }  public  InternalTerms  reduce(ReduceContext  reduceContext)  {  List<InternalAggregation>  aggregations  =  reduceContext.aggregations();  if  (aggregations.size()  ==  1)  {  InternalTerms  terms  =  (InternalTerms)  aggregations.get(0);              terms.trimExcessEntries();              terms.trimExcessEntries(reduceContext.cacheRecycler());  return  terms;  }  InternalTerms  reduced  =  null;  Recycler.V<DoubleObjectOpenHashMap<List<Bucket>>>  buckets  =  null;  for  (InternalAggregation  aggregation  :  aggregations)  {  InternalTerms  terms  =  (InternalTerms)  aggregation;  if  (terms  instanceof  UnmappedTerms)  {  	terms.trimExcessEntries(reduceContext.cacheRecycler());  
libgdx_9342bc7d93397d3f4915f4bda17f3376a70e27c1	buggy:  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/World_blobbie_blocks.png "),  Format.RGB565,  true);  context:  model[0]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_01.dae.g3d "));  lightMaps[0]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_01.jpg "),  Format.RGB565,  true);  model[1]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_02.dae.g3d "));  lightMaps[1]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_02.jpg "),  Format.RGB565,  true);  model[2]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_03.dae.g3d "));  lightMaps[2]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_03.jpg "),  Format.RGB565,  true);  model[3]  =  G3dLoader.loadStillModel(Gdx.files.internal( "data/qbob/test_section_04.dae.g3d "));  lightMaps[3]  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_lm_04.jpg "),  Format.RGB565,  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/World_blobbie_blocks.png "),  Format.RGB565,  true);  diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_blocks.png "),  Format.RGB565,  true);  cam  =  new  PerspectiveCamera(60,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(30,  10,  85f);  cam.direction.set(0,0,-1);  cam.up.set(0,1,0);  cam.near  =  10f;  cam.far  =  1000;  	diffuse  =  new  Texture(Gdx.files.internal( "data/qbob/world_blobbie_blocks.png "),  Format.RGB565,  true);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  return  execute(new  Request(shardId,  nodesIds).timeout(timeout));  context:  public  TransportNodesListGatewayStartedShards(Settings  settings,  ClusterName  clusterName,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  }  TransportNodesListGatewayStartedShards  initGateway(LocalGatewayShardsState  shardsState)  {  this.shardsState  =  shardsState;  return  this;  }  public  ActionFuture<NodesLocalGatewayStartedShards>  list(ShardId  shardId,  Set<String>  nodesIds,  @Nullable  TimeValue  timeout)  {          return  execute(new  Request(shardId,  nodesIds).timeout(timeout));          return  execute(new  Request(shardId,  nodesIds).setTimeout(timeout));  }  protected  String  executor()  {  return  ThreadPool.Names.GENERIC;  }  	return  execute(new  Request(shardId,  nodesIds).setTimeout(timeout));  
elasticsearch_33608c333f19c0db9f91bc299ea3fc2a8c2738f9	buggy:  }  else  if  ( "order ".equals(innerJsonName))  {  context:  }  else  {  if  (parsers.containsKey(fieldName))  {  sortFields.add(parsers.get(fieldName).parse(parser,  context));  }  else  {  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  innerJsonName  =  parser.currentName();  }  else  if  (token.isValue())  {  if  ( "reverse ".equals(innerJsonName))  {  reverse  =  parser.booleanValue();                                  }  else  if  ( "order ".equals(innerJsonName))  {                                  }  else  if  ( "order ".equals(innerJsonName)  ||   "sort_order ".equals(innerJsonName)  ||   "sortOrder ".equals(innerJsonName))  {  if  ( "asc ".equals(parser.text()))  {  reverse  =  SCORE_FIELD_NAME.equals(fieldName);  }  else  if  ( "desc ".equals(parser.text()))  {  reverse  =  !SCORE_FIELD_NAME.equals(fieldName);  }  }  else  if  ( "missing ".equals(innerJsonName))  {  missing  =  parser.textOrNull();  }  else  if  ( "ignore_unmapped ".equals(innerJsonName)  ||   "ignoreUnmapped ".equals(innerJsonName))  {  	}  else  if  ( "order ".equals(innerJsonName)  ||   "sort_order ".equals(innerJsonName)  ||   "sortOrder ".equals(innerJsonName))  {  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  builder.rawField( "_source ",  XContentFactory.unCachedContentBuilder(type).startObject().field( "s_field ",   "s_value ").endObject().copiedBytes());  context:  }  testRawField(XContentType.SMILE);  }  private  void  testRawField(XContentType  type)  throws  IOException  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(type);  builder.startObject();  builder.field( "field1 ",   "value1 ");          builder.rawField( "_source ",  XContentFactory.unCachedContentBuilder(type).startObject().field( "s_field ",   "s_value ").endObject().copiedBytes());          builder.rawField( "_source ",  XContentFactory.contentBuilder(type).startObject().field( "s_field ",   "s_value ").endObject().copiedBytes());  builder.field( "field2 ",   "value2 ");  builder.endObject();  XContentParser  parser  =  XContentFactory.xContent(type).createParser(builder.copiedBytes());  assertThat(parser.nextToken(),  equalTo(XContentParser.Token.START_OBJECT));  assertThat(parser.nextToken(),  equalTo(XContentParser.Token.FIELD_NAME));  assertThat(parser.currentName(),  equalTo( "field1 "));  assertThat(parser.nextToken(),  equalTo(XContentParser.Token.VALUE_STRING));  	builder.rawField( "_source ",  XContentFactory.contentBuilder(type).startObject().field( "s_field ",   "s_value ").endObject().copiedBytes());  
elasticsearch_5d987ad5e29cdd00bb710fad0a10e95c3611130e	buggy:  createIndexBasedOnFieldSettings( "test ",  testFieldSettings);  context:  public  class  MultiTermVectorsTests  extends  AbstractTermVectorTests  {  public  void  testDuelESLucene()  throws  Exception  {  AbstractTermVectorTests.TestFieldSetting[]  testFieldSettings  =  getFieldSettings();          createIndexBasedOnFieldSettings( "test ",  testFieldSettings);          createIndexBasedOnFieldSettings( "test ",   "alias ",  testFieldSettings);  TestDoc[]  testDocs  =  generateTestDocs(getNumShards( "test ").numPrimaries,  testFieldSettings);  DirectoryReader  directoryReader  =  indexDocsWithLucene(testDocs);  AbstractTermVectorTests.TestConfig[]  testConfigs  =  generateTestConfigs(20,  testDocs,  testFieldSettings);  MultiTermVectorsRequestBuilder  requestBuilder  =  client().prepareMultiTermVectors();  for  (AbstractTermVectorTests.TestConfig  test  :  testConfigs)  {  	createIndexBasedOnFieldSettings( "test ",   "alias ",  testFieldSettings);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<LongOpenHashSet>  values  =  new  ArrayList<LongOpenHashSet>(numDocs);  context:  }  prev  =  current;  }  assertThat(doubleSet,  equalTo(doubleV));  }  }  private  void  test(Data  data)  throws  Exception  {  Random  r  =  getRandom();  final  int  numDocs  =  1000  +  r.nextInt(19000);          final  List<LongOpenHashSet>  values  =  new  ArrayList<LongOpenHashSet>(numDocs);          final  List<LongOpenHashSet>  values  =  new  ArrayList<>(numDocs);  for  (int  i  =  0;  i  <  numDocs;  ++i)  {  final  int  numValues  =  data.numValues(r);  final  LongOpenHashSet  vals  =  new  LongOpenHashSet(numValues);  for  (int  j  =  0;  j  <  numValues;  ++j)  {  vals.add(data.nextValue(r));  }  values.add(vals);  }  	final  List<LongOpenHashSet>  values  =  new  ArrayList<>(numDocs);  
elasticsearch_2880cd01720455bcd8fffea23034ec6e8b220bfd	buggy:  public  float  freq()  throws  IOException  {  context:  return  docs[index].maxScore;  }  else  if  (scoreType  ==  ScoreType.AVG)  {  return  docs[index].sumScores  /  docs[index].count;  }  else  if  (scoreType  ==  ScoreType.SUM)  {  return  docs[index].sumScores;  }  throw  new  ElasticSearchIllegalStateException( "No  support  for  score  type  [ "  +  scoreType  +   "] ");  }          public  float  freq()  throws  IOException  {          public  int  freq()  throws  IOException  {  return  docs[index].count;  //  The  number  of  matches  in  the  child  doc,  which  is  propagated  to  parent  }  }  }  	public  int  freq()  throws  IOException  {  
elasticsearch_040030dac8594a13f912f21fbe12c801a2400c68	buggy:  assertThat( "10b ",  is(new  SizeValue(10,  SizeUnit.BYTES).toString()));  context:  public  class  SizeValueTests  {  assertThat(SizeUnit.BYTES.toBytes(10),  is(new  SizeValue(10,  SizeUnit.BYTES).bytes()));  assertThat(SizeUnit.KB.toKB(10),  is(new  SizeValue(10,  SizeUnit.KB).kb()));  assertThat(SizeUnit.MB.toMB(10),  is(new  SizeValue(10,  SizeUnit.MB).mb()));  assertThat(SizeUnit.GB.toGB(10),  is(new  SizeValue(10,  SizeUnit.GB).gb()));  }          assertThat( "10b ",  is(new  SizeValue(10,  SizeUnit.BYTES).toString()));          assertThat( "10 ",  is(new  SizeValue(10,  SizeUnit.BYTES).toString()));  assertThat( "1.5k ",  is(new  SizeValue((long)  (1024  *  1.5),  SizeUnit.BYTES).toString()));  assertThat( "1.5m ",  is(new  SizeValue((long)  (1024  *  1.5),  SizeUnit.KB).toString()));  assertThat( "1.5g ",  is(new  SizeValue((long)  (1024  *  1.5),  SizeUnit.MB).toString()));  assertThat( "1536g ",  is(new  SizeValue((long)  (1024  *  1.5),  SizeUnit.GB).toString()));  }  }  	assertThat( "10 ",  is(new  SizeValue(10,  SizeUnit.BYTES).toString()));  
libgdx_23c37c1feaa1bc09d5adc19aedc4ea7af148f9a7	buggy:  public  void  handle  (Event  event);  context:  ++  libgdx_23c37c1feaa1bc09d5adc19aedc4ea7af148f9a7_6089.java  package  com.badlogic.gdx.scenes.scene2d;  public  interface  EventListener  {  public  void  handle  (Event  event);  public  boolean  handle  (Event  event);  }  	public  boolean  handle  (Event  event);  
libgdx_71144438e64c1b7579be49521104d5f0425c5f09	buggy:  return  name  +   "   "  +  x  +   ", "  +  y  +   "   "  +  width  +   "x "  +  height;  context:  return  parentCoords;  }  public  String  toString  ()  {  String  name  =  this.name;  if  (name  ==  null)  {  name  =  getClass().getName();  int  dotIndex  =  name.lastIndexOf('.');  if  (dotIndex  !=  -1)  name  =  name.substring(dotIndex  +  1);  }  return  name  +   "   "  +  x  +   ", "  +  y  +   "   "  +  width  +   "x "  +  height;  return  name;  }  }  	return  name;  
elasticsearch_bbd63f0ffef611842315044f4275a341ce7110cf	buggy:  return  new  DeletionAwareConstantScoreQuery(filter,  true);  context:  }  filter  =  parseContext.cacheFilter(filter);  filter  =  new  NotFilter(filter);  filter  =  parseContext.cacheFilter(filter);  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);          return  new  DeletionAwareConstantScoreQuery(filter,  true);          return  new  DeletionAwareConstantScoreQuery(filter);  }  }  	return  new  DeletionAwareConstantScoreQuery(filter);  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  Analyzer  analyzer  =  analysisService.analyzer( "custom1 ");  context:  private  void  testSimpleConfiguration(Settings  settings)  {  Index  index  =  new  Index( "test ");  Injector  injector  =  Guice.createInjector(  new  IndexSettingsModule(settings),  new  IndexNameModule(index),  new  AnalysisModule(settings));  AnalysisService  analysisService  =  injector.getInstance(AnalysisService.class);          Analyzer  analyzer  =  analysisService.analyzer( "custom1 ");          Analyzer  analyzer  =  analysisService.analyzer( "custom1 ").analyzer();  assertThat(analyzer,  instanceOf(CustomAnalyzer.class));  CustomAnalyzer  custom1  =  (CustomAnalyzer)  analyzer;  assertThat(custom1.tokenizerFactory(),  instanceOf(StandardTokenizerFactory.class));  assertThat(custom1.tokenFilters().length,  equalTo(2));  StopTokenFilterFactory  stop1  =  (StopTokenFilterFactory)  custom1.tokenFilters()[0];  assertThat(stop1.stopWords().size(),  equalTo(1));  	Analyzer  analyzer  =  analysisService.analyzer( "custom1 ").analyzer();  
elasticsearch_c2ee6dd120ab7cf5b81df103ebc2522675d2a4bd	buggy:  createIndexService.createIndex(new  MetaDataCreateIndexService.Request(MetaDataCreateIndexService.Request.Origin.API,  cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  context:  String  cause  =  request.cause();  if  (cause.length()  ==  0)  {  cause  =   "api ";  }  final  AtomicReference<CreateIndexResponse>  responseRef  =  new  AtomicReference<CreateIndexResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          createIndexService.createIndex(new  MetaDataCreateIndexService.Request(MetaDataCreateIndexService.Request.Origin.API,  cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {          createIndexService.createIndex(new  MetaDataCreateIndexService.Request(cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  responseRef.set(new  CreateIndexResponse(response.acknowledged()));  latch.countDown();  }  failureRef.set(t);  latch.countDown();  	createIndexService.createIndex(new  MetaDataCreateIndexService.Request(cause,  request.index()).settings(request.settings()).mappings(request.mappings()).timeout(request.timeout()),  new  MetaDataCreateIndexService.Listener()  {  
elasticsearch_9daa72941abacb049fa3cc879e27b7c940ce894a	buggy:  .put( "discovery.zen.ping_timeout ",   "200ms ")  context:  for  (int  i  =  0;  i  <  10;  i++)  {  assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(),  equalTo(100l));  }  }  public  void  dynamicUpdateMinimumMasterNodes()  throws  InterruptedException  {  Settings  settings  =  settingsBuilder()  .put( "discovery.type ",   "zen ")                  .put( "discovery.zen.ping_timeout ",   "200ms ")                  .put( "discovery.zen.ping_timeout ",   "400ms ")  .put( "discovery.initial_state_timeout ",   "500ms ")  .put( "gateway.type ",   "local ")  .build();  cluster().startNode(settings);  cluster().startNode(settings);  	.put( "discovery.zen.ping_timeout ",   "400ms ")  
elasticsearch_ab2a655a5974593d65cf3d7f1388196a709e29dc	buggy:  Query  query  =  indexQueryParser.parse(parser);  context:  public  class  QueryParseElement  implements  SearchParseElement  {  XContentIndexQueryParser  indexQueryParser  =  (XContentIndexQueryParser)  context.queryParser();          Query  query  =  indexQueryParser.parse(parser);          Query  query  =  indexQueryParser.parse(parser).query();  context.query(query);  }  }  	Query  query  =  indexQueryParser.parse(parser).query();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  parentTypes  =  new  HashSet<String>(5);  context:  }  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  filter  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));          Set<String>  parentTypes  =  new  HashSet<String>(5);          Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  if  (parentTypeDocumentMapper  ==  null)  {  	Set<String>  parentTypes  =  new  HashSet<>(5);  
elasticsearch_7ae8d4c669d6afdcc8c5d1fb1773374bf523874e	buggy:  return  ImmutableList.of(Modules.createModule(settings.getAsClass( "transport.type ",  CachedThreadPoolModule.class,   "org.elasticsearch.threadpool. ",   "ThreadPoolModule "),  settings));  context:  public  class  ThreadPoolModule  extends  AbstractModule  implements  SpawnModules  {  private  final  Settings  settings;  public  ThreadPoolModule(Settings  settings)  {  this.settings  =  settings;  }          return  ImmutableList.of(Modules.createModule(settings.getAsClass( "transport.type ",  CachedThreadPoolModule.class,   "org.elasticsearch.threadpool. ",   "ThreadPoolModule "),  settings));          return  ImmutableList.of(Modules.createModule(settings.getAsClass( "threadpool.type ",  CachedThreadPoolModule.class,   "org.elasticsearch.threadpool. ",   "ThreadPoolModule "),  settings));  }  }  }  	return  ImmutableList.of(Modules.createModule(settings.getAsClass( "threadpool.type ",  CachedThreadPoolModule.class,   "org.elasticsearch.threadpool. ",   "ThreadPoolModule "),  settings));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(OptimizeResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_7783ad3e5eb7217c317a281ececc62517270d259	buggy:  cache.add(texture,  x  <<  5,  y  <<  5,  1  +  tileX  *  33,  1  +  tileY  *  33,  32,  32,  Color.WHITE);  context:  Random  rand  =  new  Random();  for(int  i  =  0;  i  <  LAYERS;  i++)  {  caches[i]  =  new  SpriteCache();  SpriteCache  cache  =  caches[i];  cache.beginCache();  for(int  y  =  0;  y  <  HEIGHT;  y++)  {  for(int  x  =  0;  x  <  WIDTH;  x++)  {  int  tileX  =  rand.nextInt(5);  int  tileY  =  rand.nextInt(5);  cache.add(texture,  x  <<  5,  y  <<  5,  1  +  tileX  *  33,  1  +  tileY  *  33,  32,  32,  Color.WHITE);  cache.add(texture,  x  <<  5,  y  <<  5,  1  +  tileX  *  33,  1  +  tileY  *  33,  32,  32);  }  }  layers[i]  =  cache.endCache();  }  }  	cache.add(texture,  x  <<  5,  y  <<  5,  1  +  tileX  *  33,  1  +  tileY  *  33,  32,  32);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[atLeast(50)];  context:  public  class  SearchScanTests  extends  ElasticsearchIntegrationTest  {  public  void  testNarrowingQuery()  throws  Exception  {  createIndex( "test ");  ensureGreen();  Set<String>  ids  =  Sets.newHashSet();  Set<String>  expectedIds  =  Sets.newHashSet();          IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[atLeast(50)];          IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[scaledRandomIntBetween(50,  100)];  for  (int  i  =  0;  i  <  builders.length/2;  i++)  {  expectedIds.add(Integer.toString(i));  builders[i]  =  client().prepareIndex( "test ",   "tweet ",  Integer.toString(i)).setSource(  jsonBuilder().startObject().field( "user ",   "kimchy1 ").field( "postDate ",  System.currentTimeMillis()).field( "message ",   "test ").endObject());  }  for  (int  i  =  builders.length/2;  i  <  builders.length;  i++)  {  builders[i]  =  client().prepareIndex( "test ",   "tweet ",  Integer.toString(i)).setSource(  	IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[scaledRandomIntBetween(50,  100)];  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  Long  val  =  value(value);  if  (val  ==  null)  {  return  null;  }  return  longToIp(val);  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  long  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).longValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  
elasticsearch_5049f60b6ccb0203ca01c828082ec153d662e9d3	buggy:  if  (indexMetaData.readOnly())  {  context:  if  (recoveredState.metaData().settings().getAsBoolean(MetaData.SETTING_READ_ONLY,  false)  ||  currentState.metaData().settings().getAsBoolean(MetaData.SETTING_READ_ONLY,  false))  {  blocks.addGlobalBlock(MetaData.CLUSTER_READ_ONLY_BLOCK);  }  for  (IndexMetaData  indexMetaData  :  recoveredState.metaData())  {  metaDataBuilder.put(indexMetaData);  if  (indexMetaData.state()  ==  IndexMetaData.State.CLOSE)  {  blocks.addIndexBlock(indexMetaData.index(),  MetaDataStateIndexService.INDEX_CLOSED_BLOCK);  }                          if  (indexMetaData.readOnly())  {                          if  (indexMetaData.settings().getAsBoolean(IndexMetaData.SETTING_READ_ONLY,  false))  {  blocks.addIndexBlock(indexMetaData.index(),  IndexMetaData.INDEX_READ_ONLY_BLOCK);  }  }  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState)  .version(recoveredState.version())  .blocks(blocks)  	if  (indexMetaData.settings().getAsBoolean(IndexMetaData.SETTING_READ_ONLY,  false))  {  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  scriptService,  pageCacheRecycler,  bigArrays  context:  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  boolean  valid;  String  explanation  =  null;  String  error  =  null;  DefaultSearchContext  searchContext  =  new  DefaultSearchContext(0,  new  ShardSearchRequest(request).types(request.types()).nowInMillis(request.nowInMillis())  .filteringAliases(request.filteringAliases()),  null,  indexShard.acquireSearcher( "validate_query "),  indexService,  indexShard,                  scriptService,  pageCacheRecycler,  bigArrays                  scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter()  );  SearchContext.setCurrent(searchContext);  try  {  if  (request.source()  !=  null  &&  request.source().length()  >  0)  {  searchContext.parsedQuery(queryParserService.parseQuery(request.source()));  }  searchContext.preProcess();  	scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter()  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  String  dateAsString  =  null;  Long  value  =  null;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  instanceof  Number)  {  value  =  ((Number)  externalValue).longValue();  }  else  {  dateAsString  =  (String)  externalValue;  if  (dateAsString  ==  null)  {  dateAsString  =  nullValue;  	float  boost  =  this.boost;  
libgdx_ff3ff99c437ce475e73b840e6f3b2e2040349701	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.MeshMultitextureTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.MeshMultitextureTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.StagePerformanceTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.StagePerformanceTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_6f9efed67c550675db27ce834917d5e0cf947d36	buggy:  final  Model  barModel  =  ModelBuilder.createBox(10f,  1f,  1f,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  context:  public  class  ConstraintsTest  extends  BaseBulletTest  {  final  Array<btTypedConstraint>  constraints  =  new  Array<btTypedConstraint>();  public  void  create  ()  {  super.create();  final  Model  barModel  =  ModelBuilder.createBox(10f,  1f,  1f,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  final  Model  barModel  =  modelBuilder.createBox(10f,  1f,  1f,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  new  float[]  {5f,  0.5f,  0.5f,  5f,  0.5f,  -0.5f,  -5f,  0.5f,  0.5f,  -5f,  0.5f,  -0.5f,  5f,  -0.5f,  0.5f,  5f,  -0.5f,  -0.5f,  -5f,  -0.5f,  0.5f,  -5f,  -0.5f,  -0.5f},  new  short[]  {0,  1,  2,  1,  2,  3,  //  top  4,  5,  6,  5,  6,  7,  //  bottom  0,  2,  4,  4,  6,  2,  //  front  1,  3,  5,  5,  7,  3,  //  back  2,  3,  6,  6,  7,  3,  //  left  	final  Model  barModel  =  modelBuilder.createBox(10f,  1f,  1f,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (!indexed()  &&  !stored())  {  context:  }  if  (value  ==  null)  {  return  null;  }  if  (ignoreAbove  >  0  &&  value.length()  >  ignoreAbove)  {  return  null;  }  if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  value,  boost);  }          if  (!indexed()  &&  !stored())  {          if  (!fieldType().indexed()  &&  !fieldType().stored())  {  context.ignoredValue(names.indexName(),  value);  return  null;  }  Field  field  =  new  StringField(names.indexName(),  value,  fieldType);  field.setBoost(boost);  return  field;  }  	if  (!fieldType().indexed()  &&  !fieldType().stored())  {  
elasticsearch_5c6d28240f82fba3bd9ee580a01820951d8f89d8	buggy:  max( "max_score ").script( "_doc.score ")  context:  .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)  .setQuery(matchQuery( "text ",   "term  rare "))  .addAggregation(terms( "terms ")  .executionHint(randomExecutionHint())  .field( "group ")  .order(Terms.Order.aggregation( "max_score ",  false))  .subAggregation(  topHits( "hits ").setSize(1)  )  .subAggregation(                                          max( "max_score ").script( "_doc.score ")                                          max( "max_score ").script( "_doc.score() ")  )  )  .get();  assertSearchResponse(response);  Terms  terms  =  response.getAggregations().get( "terms ");  assertThat(terms,  notNullValue());  assertThat(terms.getName(),  equalTo( "terms "));  	max( "max_score ").script( "_doc.score() ")  
elasticsearch_6c552b4187e49696e81c12f10baa75304114dae0	buggy:  @Override  public  boolean  get(int  doc)  throws  IOException  {  context:  this.distance  =  distance;  }  return  false;  }          @Override  public  boolean  get(int  doc)  throws  IOException  {          @Override  public  boolean  get(int  doc)  {  if  (!fieldData.hasValue(doc))  {  return  false;  }  if  (fieldData.multiValued())  {  double[]  lats  =  fieldData.latValues(doc);  double[]  lons  =  fieldData.lonValues(doc);  for  (int  i  =  0;  i  <  lats.length;  i++)  {  	@Override  public  boolean  get(int  doc)  {  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  nextIndex  =  currentIndex;  context:  hasNext  =  true;  break;  }  }  }  public  void  remove  ()  {  if  (currentIndex  <  0)  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  null;  }  currentIndex  =  -1;  map.size--;  }  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_343c80b100c982ff9103ee9a6c192fa756dda6f2	buggy:  return  defaultFactory.newInstance(prefix.intern(),  name.intern());  context:  public  static  void  setDefaultFactory(ESLoggerFactory  defaultFactory)  {  if  (defaultFactory  ==  null)  {  throw  new  NullPointerException( "defaultFactory ");  }  ESLoggerFactory.defaultFactory  =  defaultFactory;  }  public  static  ESLogger  getLogger(String  prefix,  String  name)  {          return  defaultFactory.newInstance(prefix.intern(),  name.intern());          return  defaultFactory.newInstance(prefix  ==  null  ?  null  :  prefix.intern(),  name.intern());  }  public  static  ESLogger  getLogger(String  name)  {  return  defaultFactory.newInstance(name.intern());  }  public  ESLogger  newInstance(String  name)  {  return  newInstance(null,  name);  	return  defaultFactory.newInstance(prefix  ==  null  ?  null  :  prefix.intern(),  name.intern());  
elasticsearch_2c4b9d9ba2ba14e881ea7c75f5dc2ddb14e384c9	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  request.queryHint(),  routingMap,  null);  context:  }  protected  ShardCountResponse  newShardResponse()  {  return  new  ShardCountResponse();  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  CountRequest  request,  String[]  concreteIndices)  {  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(request.routing(),  request.indices());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  request.queryHint(),  routingMap,  null);          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  null);  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  CountRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.READ);  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  null);  
elasticsearch_4ff3e1926b0b0a092a9fcb70f47fb49977ec2d70	buggy:  return  ScriptDocValues.EMPTY;  context:  return  0;  }  public  BytesValues  getBytesValues(boolean  needsHashes)  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {              return  ScriptDocValues.EMPTY;              return  ScriptDocValues.EMPTY_LONGS;  }  }  public  static  class  WithOrdinals  extends  PackedArrayAtomicFieldData  {  private  final  MonotonicAppendingLongBuffer  values;  private  final  Ordinals  ordinals;  	return  ScriptDocValues.EMPTY_LONGS;  
elasticsearch_41b4a14933194de30f512ecf6eb29404202804f8	buggy:  return  Math.max(0.0,  (scale  -  Math.abs(value))  /  scale);  context:  public  DecayFunction  getDecayFunction()  {  return  decayFunction;  }  final  static  class  LinearDecayScoreFunction  implements  DecayFunction  {  public  double  evaluate(double  value,  double  scale)  {              return  Math.max(0.0,  (scale  -  Math.abs(value))  /  scale);              return  Math.max(0.0,  (scale  -  value)  /  scale);  }  public  Explanation  explainFunction(String  valueExpl,  double  value,  double  scale)  {  ComplexExplanation  ce  =  new  ComplexExplanation();  ce.setValue((float)  evaluate(value,  scale));  ce.setDescription( "max(0.0,  (( "  +  scale  +   "  -  abs( "  +  valueExpl  +   "))/ "  +  scale  +   ") ");  return  ce;  	return  Math.max(0.0,  (scale  -  value)  /  scale);  
elasticsearch_3afe4da55078e7b14eb4f7ef38d897c7f0f7f13d	buggy:  searchSource  =  Arrays.copyOfRange(searchSource,  searchSourceOffset,  searchSourceLength);  context:  public  float  boostTerms()  {  return  this.boostTerms;  }  void  beforeLocalFork()  {  if  (searchSourceUnsafe)  {              searchSource  =  Arrays.copyOfRange(searchSource,  searchSourceOffset,  searchSourceLength);              searchSource  =  Arrays.copyOfRange(searchSource,  searchSourceOffset,  searchSourceOffset  +  searchSourceLength);  searchSourceOffset  =  0;  searchSourceUnsafe  =  false;  }  }  	searchSource  =  Arrays.copyOfRange(searchSource,  searchSourceOffset,  searchSourceOffset  +  searchSourceLength);  
libgdx_eb6357b22bfe90d1c37fd4c279a28b771b1f2822	buggy:  Gdx2DPixmap  pixmap  =  new  Gdx2DPixmap(32,  32,  formats[i]);  context:  Gdx2DPixmap[]  testPixmaps()  {  int[]  formats  =  {  Gdx2DPixmap.GDX2D_FORMAT_ALPHA,  Gdx2DPixmap.GDX2D_FORMAT_LUMINANCE_ALPHA,  Gdx2DPixmap.GDX2D_FORMAT_RGB565,  Gdx2DPixmap.GDX2D_FORMAT_RGB888,  Gdx2DPixmap.GDX2D_FORMAT_RGBA4444,  Gdx2DPixmap.GDX2D_FORMAT_RGBA8888  };  Gdx2DPixmap[]  pixmaps  =  new  Gdx2DPixmap[formats.length];  for(int  i  =  0;  i  <  pixmaps.length;  i++)  {  Gdx2DPixmap  pixmap  =  new  Gdx2DPixmap(32,  32,  formats[i]);  Gdx2DPixmap  pixmap  =  new  Gdx2DPixmap(64,  32,  formats[i]);  drawToPixmap(pixmap);  pixmaps[i]  =  pixmap;  }  return  pixmaps;  }  batch  =  new  SpriteBatch();  	Gdx2DPixmap  pixmap  =  new  Gdx2DPixmap(64,  32,  formats[i]);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  idsSet  =  new  HashSet<String>(Arrays.asList(ids));  context:  fail( "Hit  count  is   "  +  searchResponse.getHits().totalHits()  +   "  but   "  +  expectedHitCount  +   "  was  expected.   "  formatShardStatus(searchResponse));  }  assertVersionSerializable(searchResponse);  }  public  static  void  assertSearchHits(SearchResponse  searchResponse,  String...  ids)  {  String  shardStatus  =  formatShardStatus(searchResponse);  assertThat( "Expected  different  hit  count.   "  +  shardStatus,  searchResponse.getHits().hits().length,  equalTo(ids.length));          Set<String>  idsSet  =  new  HashSet<String>(Arrays.asList(ids));          Set<String>  idsSet  =  new  HashSet<>(Arrays.asList(ids));  for  (SearchHit  hit  :  searchResponse.getHits())  {  assertThat( "Expected  id:   "  +  hit.getId()  +   "  in  the  result  but  wasn't. "  +  shardStatus,  idsSet.remove(hit.getId()),  equalTo(true));  }  assertThat( "Expected  ids:   "  +  Arrays.toString(idsSet.toArray(new  String[idsSet.size()]))  +   "  in  the  result  -  result  size  differs. "  shardStatus,  idsSet.size(),  equalTo(0));  assertVersionSerializable(searchResponse);  }  	Set<String>  idsSet  =  new  HashSet<>(Arrays.asList(ids));  
libgdx_58ae7e94a5e662e1cbbc65226a2d9ac9b1482bae	buggy:  },  0,  1);  context:  public  class  TimerTest  extends  GdxTest  {  public  void  create  ()  {  new  Timer().scheduleTask(new  Task()  {  public  void  run  ()  {  Gdx.app.log( "TimerTest ",   "ping ");  }  },  0,  1);  },  1,  1);  }  }  	},  1,  1);  
libgdx_36a4ac8ffe5f7c2bcbf1ff6678778c8e5ddcc1f0	buggy:  root.add(new  ScrollPane(labels,  stage,  skin)).expand().fill();  context:  public  void  create  ()  {  stage  =  new  Stage(0,  0,  true);  Gdx.input.setInputProcessor(stage);  root  =  new  Table();  stage.addActor(root);  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  Table  labels  =  new  Table();  root.add(new  ScrollPane(labels,  stage,  skin)).expand().fill();  root.add(new  ScrollPane(labels,  skin)).expand().fill();  root.row();  root.add(drawnLabel  =  new  Label( " ",  skin));  for  (int  i  =  0;  i  <  count;  i++)  {  labels.add(new  Label( "Label:   "  +  i,  skin)  {  public  void  draw  (SpriteBatch  batch,  float  parentAlpha)  {  super.draw(batch,  parentAlpha);  drawn++;  	root.add(new  ScrollPane(labels,  skin)).expand().fill();  
elasticsearch_e913b6626f45338629751b8d994a6f38de01acc1	buggy:  throw  new  ElasticsearchIllegalArgumentException( "source  is  forced  for  field  [ "  +  field.field()  +   "]  but  type  [ "  +  hitContext.hit().type()  +   "]  has  disabled  _source ");  context:  if  (Regex.isSimpleMatchPattern(field.field()))  {  DocumentMapper  documentMapper  =  context.mapperService().documentMapper(hitContext.hit().type());  fieldNamesToHighlight  =  documentMapper.mappers().simpleMatchToFullName(field.field());  }  else  {  fieldNamesToHighlight  =  ImmutableSet.of(field.field());  }  if  (field.forceSource())  {  SourceFieldMapper  sourceFieldMapper  =  context.mapperService().documentMapper(hitContext.hit().type()).sourceMapper();  if  (!sourceFieldMapper.enabled())  {                      throw  new  ElasticsearchIllegalArgumentException( "source  is  forced  for  field  [ "  +  field.field()  +   "]  but  type  [ "  +  hitContext.hit().type()  +   "]  has  disabled  _source ");                      throw  new  ElasticsearchIllegalArgumentException( "source  is  forced  for  fields   "  +  fieldNamesToHighlight  +   "  but  type  [ "  +  hitContext.hit().type()  +   "]  has  disabled  _source ");  }  }  for  (String  fieldName  :  fieldNamesToHighlight)  {  FieldMapper<?>  fieldMapper  =  getMapperForField(fieldName,  context,  hitContext);  if  (fieldMapper  ==  null)  {  continue;  }  	throw  new  ElasticsearchIllegalArgumentException( "source  is  forced  for  fields   "  +    fieldNamesToHighlight  +   "  but  type  [ "  +  hitContext.hit().type()  +   "]  has  disabled  _source ");  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  ((Releasable)  content).release();  context:  ChannelFuture  future  =  channel.write(resp);  if  (response.contentThreadSafe()  &&  content  instanceof  Releasable)  {  future.addListener(new  ReleaseChannelFutureListener((Releasable)  content));  addedReleaseListener  =  true;  }  if  (close)  {  future.addListener(ChannelFutureListener.CLOSE);  }  }  finally  {  if  (!addedReleaseListener  &&  content  instanceof  Releasable)  {                  ((Releasable)  content).release();                  ((Releasable)  content).close();  }  }  }  private  HttpResponseStatus  getStatus(RestStatus  status)  {  switch  (status)  {  case  CONTINUE:  return  HttpResponseStatus.CONTINUE;  	((Releasable)  content).close();  
elasticsearch_0ef4000842b86b947c27d1052a8e1ed981d03fcb	buggy:  mergeContext.addFailure( "Can't  merge  a  non  object  mapping  [ "  +  mergeWith.name()  +   "]  with  an  object  mapping  [ "  +  name()  +   "] ");  context:  putMapper(mapper);  jsonContext.docMapper().addFieldMapper((FieldMapper)  mapper);  mapper.parse(jsonContext);  jsonContext.addedMapper();  }  }  if  (!(mergeWith  instanceof  JsonObjectMapper))  {              mergeContext.addFailure( "Can't  merge  a  non  object  mapping  [ "  +  mergeWith.name()  +   "]  with  an  object  mapping  [ "  +  name()  +   "] ");              mergeContext.addConflict( "Can't  merge  a  non  object  mapping  [ "  +  mergeWith.name()  +   "]  with  an  object  mapping  [ "  +  name()  +   "] ");  return;  }  JsonObjectMapper  mergeWithObject  =  (JsonObjectMapper)  mergeWith;  synchronized  (mutex)  {  for  (JsonMapper  mergeWithMapper  :  mergeWithObject.mappers.values())  {  JsonMapper  mergeIntoMapper  =  mappers.get(mergeWithMapper.name());  if  (mergeIntoMapper  ==  null)  {  	mergeContext.addConflict( "Can't  merge  a  non  object  mapping  [ "  +  mergeWith.name()  +   "]  with  an  object  mapping  [ "  +  name()  +   "] ");  
libgdx_d103ee209438a74cd1c1fed2b3e471fb653174c9	buggy:  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  context:  Mesh  mesh;  Texture  texture;  float  angleY  =  0;  float  angleX  =  0;  float[]  lightColor  =  {1,  1,  1,  0};  float[]  lightPosition  =  {2,  5,  10,  0};  float  touchStartX  =  0;  float  touchStartY  =  0;  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  mesh  =  ModelLoader.loadObj(Gdx.files.internal( "data/cube.obj ").read());  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  cam  =  new  PerspectiveCamera();  cam.getPosition().set(2,  2,  2);  cam.getDirection().set(-1,  -1,  -1);  Gdx.input.setInputProcessor(this);  }  	mesh  =  ModelLoader.loadObj(Gdx.files.internal( "data/cube.obj ").read());  
libgdx_5130db1764fc4aea5f1faa1cb9d784508d8659b7	buggy:  dst.set(  x,  y,  x  +  this.bitmap.getWidth(),  y  +  this.bitmap.getHeight()  );  context:  gl10.glBindTexture(  GL10.GL_TEXTURE_2D,  textureHandle  );  else  gl20.glBindTexture(  GL10.GL_TEXTURE_2D,  textureHandle  );  Bitmap  bitmap  =  (Bitmap)bmp.getNativePixmap();  if(  isManaged  )  {  Canvas  canvas  =  new  Canvas(  this.bitmap  );  Rect  src  =  new  Rect(  );  RectF  dst  =  new  RectF(  );  dst.set(  x,  y,  x  +  this.bitmap.getWidth(),  y  +  this.bitmap.getHeight()  );  dst.set(  x,  y,  x  +  bitmap.getWidth(),  y  +  bitmap.getHeight()  );  src.set(  0,  0,  bitmap.getWidth(),  bitmap.getHeight()  );  canvas.drawBitmap(bitmap,  src,  dst,  null);  }  int  level  =  0;  int  height  =  bitmap.getHeight();  int  width  =  bitmap.getWidth();  	dst.set(  x,  y,  x  +  bitmap.getWidth(),  y  +  bitmap.getHeight()  );  
elasticsearch_9194d36a64b3a00e1408c340c0305b201d05331c	buggy:  this.mappingSource  =  new  CompressedString(builder.string());  context:  }  return  new  MergeResult(mergeContext.buildConflicts());  }  public  void  refreshSource()  throws  FailedToGenerateSourceMapperException  {  try  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON);  builder.startObject();  toXContent(builder,  ToXContent.EMPTY_PARAMS);  builder.endObject();              this.mappingSource  =  new  CompressedString(builder.string());              this.mappingSource  =  new  CompressedString(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());  }  catch  (Exception  e)  {  throw  new  FailedToGenerateSourceMapperException(e.getMessage(),  e);  }  }  public  void  close()  {  cache.remove();  rootObjectMapper.close();  	this.mappingSource  =  new  CompressedString(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<CandidateGenerator>  gens  =  new  ArrayList<CandidateGenerator>(generators.size());  context:  public  Suggestion<?  extends  Entry<?  extends  Option>>  innerExecute(String  name,  PhraseSuggestionContext  suggestion,  IndexReader  indexReader,  CharsRef  spare)  throws  IOException  {  double  realWordErrorLikelihood  =  suggestion.realworldErrorLikelyhood();  final  PhraseSuggestion  response  =  new  PhraseSuggestion(name,  suggestion.getSize());  List<PhraseSuggestionContext.DirectCandidateGenerator>  generators  =  suggestion.generators();  final  int  numGenerators  =  generators.size();          final  List<CandidateGenerator>  gens  =  new  ArrayList<CandidateGenerator>(generators.size());          final  List<CandidateGenerator>  gens  =  new  ArrayList<>(generators.size());  for  (int  i  =  0;  i  <  numGenerators;  i++)  {  PhraseSuggestionContext.DirectCandidateGenerator  generator  =  generators.get(i);  DirectSpellChecker  directSpellChecker  =  SuggestUtils.getDirectSpellChecker(generator);  Terms  terms  =  MultiFields.getTerms(indexReader,  generator.field());  if  (terms  !=  null)  {  gens.add(new  DirectCandidateGenerator(directSpellChecker,  generator.field(),  generator.suggestMode(),  indexReader,  realWordErrorLikelihood,  generator.size(),  generator.preFilter(),  generator.postFilter(),  terms));  }  	final  List<CandidateGenerator>  gens  =  new  ArrayList<>(generators.size());  
elasticsearch_4f96b3637643ea2b9e4ddf58b1858c04aea27388	buggy:  if  (defaultTTL  !=  Defaults.DEFAULT)  {  context:  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (enabledState  ==  Defaults.ENABLED_STATE  &&  defaultTTL  ==  Defaults.DEFAULT)  {  return  builder;  }  builder.startObject(CONTENT_TYPE);  if  (enabledState  !=  Defaults.ENABLED_STATE)  {  builder.field( "enabled ",  enabledState.enabled);  }          if  (defaultTTL  !=  Defaults.DEFAULT)  {          if  (defaultTTL  !=  Defaults.DEFAULT  &&  enabledState.enabled)  {  builder.field( "default ",  defaultTTL);  }  builder.endObject();  return  builder;  }  public  void  merge(Mapper  mergeWith,  MergeContext  mergeContext)  throws  MergeMappingException  {  	if  (defaultTTL  !=  Defaults.DEFAULT  &&  enabledState.enabled)  {  
elasticsearch_6c8aa5fa6c58db1d3919a40c9c3ce73f8d433b9e	buggy:  request  =  new  RecoveryFileChunkRequest(req.recoveryId(),  req.shardId(),  req.metadata(),  req.position(),  array);  context:  for  (NodeStats  dataNode  :  dataNodeStats)  {  MockTransportService  mockTransportService  =  ((MockTransportService)  internalCluster().getInstance(TransportService.class,  dataNode.getNode().name()));  mockTransportService.addDelegate(internalCluster().getInstance(Discovery.class,  unluckyNode.getNode().name()).localNode(),  new  MockTransportService.DelegateTransport(mockTransportService.original())  {  public  void  sendRequest(DiscoveryNode  node,  long  requestId,  String  action,  TransportRequest  request,  TransportRequestOptions  options)  throws  IOException,  TransportException  {  if  (action.equals(RecoveryTarget.Actions.FILE_CHUNK))  {  RecoveryFileChunkRequest  req  =  (RecoveryFileChunkRequest)  request;  if  (truncate  &&  req.length()  >  1)  {  BytesArray  array  =  new  BytesArray(req.content().array(),  req.content().arrayOffset(),  (int)req.length()-1);                              request  =  new  RecoveryFileChunkRequest(req.recoveryId(),  req.shardId(),  req.metadata(),  req.position(),  array);                              request  =  new  RecoveryFileChunkRequest(req.recoveryId(),  req.shardId(),  req.metadata(),  req.position(),  array,  req.lastChunk());  }  else  {  byte[]  array  =  req.content().array();  int  i  =  randomIntBetween(0,  req.content().length()  -  1);  array[i]  =  (byte)  ~array[i];  //  flip  one  byte  in  the  content  }  }  super.sendRequest(node,  requestId,  action,  request,  options);  }  	request  =  new  RecoveryFileChunkRequest(req.recoveryId(),  req.shardId(),  req.metadata(),  req.position(),  array,  req.lastChunk());  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  }  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  scriptParams  =  parser.map();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "keyed ".equals(currentFieldName))  {  keyed  =  parser.booleanValue();                  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {                  }  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  {  throw  new  SearchParseException(context,   "Unexpected  token   "  +  token  +   "  in  [ "  +  aggregationName  +   "]. ");  }  }  	}  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
libgdx_410739d563d39da1439a0a5d4f9e3ddcd7b7c982	buggy:  if  (title  ==  null)  glfwSetWindowTitle(window,   " ");  context:  glfwMakeContextCurrent(newWindow);  window  =  newWindow;  this.fullscreen  =  fullscreen;  if  (!mouseCaptured)  glfwSetInputMode(window,  GLFW_CURSOR_MODE,  GLFW_CURSOR_NORMAL);  //  Prevent  fullscreen  from  taking  mouse.  return  true;  }  public  void  setTitle  (String  title)  {  if  (title  ==  null)  glfwSetWindowTitle(window,   " ");  if  (title  ==  null)  title  =   " ";  glfwSetWindowTitle(window,  title);  this.title  =  title;  }  public  void  setVSync  (boolean  vsync)  {  this.sync  =  vsync;  glfwSwapInterval(vsync  ?  1  :  0);  }  	if  (title  ==  null)  title  =   " ";  
libgdx_7b813ad9c1676821ef0b737c2a16cac3f05f58f3	buggy:  effect.loadEmitters(Gdx.files.getFileHandle(new  File(dir,  file).getAbsolutePath(),  FileType.Absolute));  context:  void  openEffect  ()  {  FileDialog  dialog  =  new  FileDialog(editor,   "Open  Effect ",  FileDialog.LOAD);  if  (lastDir  !=  null)  dialog.setDirectory(lastDir);  dialog.setVisible(true);  final  String  file  =  dialog.getFile();  final  String  dir  =  dialog.getDirectory();  if  (dir  ==  null  ||  file  ==  null  ||  file.trim().length()  ==  0)  return;  lastDir  =  dir;  ParticleEffect  effect  =  new  ParticleEffect();  try  {  effect.loadEmitters(Gdx.files.getFileHandle(new  File(dir,  file).getAbsolutePath(),  FileType.Absolute));  effect.loadEmitters(Gdx.files.absolute(new  File(dir,  file).getAbsolutePath()));  editor.effect  =  effect;  emitterTableModel.getDataVector().removeAllElements();  editor.particleData.clear();  }  catch  (Exception  ex)  {  ex.printStackTrace();  JOptionPane.showMessageDialog(editor,   "Error  opening  effect. ");  return;  	effect.loadEmitters(Gdx.files.absolute(new  File(dir,  file).getAbsolutePath()));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(querySource,  true);  context:  filteringAliases[i]  =  in.readUTF();  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeFloat(minScore);          out.writeBytesReference(querySource,  true);          out.writeBytesReference(querySource);  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  if  (filteringAliases  !=  null)  {  out.writeVInt(filteringAliases.length);  for  (String  alias  :  filteringAliases)  {  	out.writeBytesReference(querySource);  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()  context:  public  class  PrimaryNotRelocatedWhileBeingRecoveredTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(PrimaryNotRelocatedWhileBeingRecoveredTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()          AllocationService  strategy  =  new  AllocationService(settingsBuilder()  .put( "cluster.routing.allocation.node_concurrent_recoveries ",  10)  .put( "cluster.routing.allocation.node_initial_primaries_recoveries ",  10)  .build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(5).numberOfReplicas(1))  	AllocationService  strategy  =  new  AllocationService(settingsBuilder()  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);  context:  public  static  RefreshStats  readRefreshStats(StreamInput  in)  throws  IOException  {  RefreshStats  refreshStats  =  new  RefreshStats();  refreshStats.readFrom(in);  return  refreshStats;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(Fields.REFRESH);  builder.field(Fields.TOTAL,  total);          builder.timeValueField(Fields.TOTAL_TIME,  Fields.TOTAL_TIME_IN_MILLIS,  totalTimeInMillis);          builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  builder.endObject();  return  builder;  }  static  final  class  Fields  {  static  final  XContentBuilderString  REFRESH  =  new  XContentBuilderString( "refresh ");  static  final  XContentBuilderString  TOTAL  =  new  XContentBuilderString( "total ");  static  final  XContentBuilderString  TOTAL_TIME  =  new  XContentBuilderString( "total_time ");  	builder.timeValueField(Fields.TOTAL_TIME_IN_MILLIS,  Fields.TOTAL_TIME,  totalTimeInMillis);  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));  context:  countRequest.querySource(HttpActions.parseQuerySource(request));  countRequest.queryParserName(request.param( "queryParserName "));  countRequest.queryHint(request.param( "queryHint "));  countRequest.minScore(HttpActions.paramAsFloat(request.param( "minScore "),  DEFAULT_MIN_SCORE));  String  typesParam  =  request.param( "type ");  if  (typesParam  !=  null)  {  countRequest.types(splitTypes(typesParam));  }  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.cached().startObject().field( "error ",  e.getMessage()).endObject()));                  channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }  client.execCount(countRequest,  new  ActionListener<CountResponse>()  {  	channel.sendResponse(new  JsonHttpResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  ==  null  ||  !smartNameFieldMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  mapping  for  field  [ "  +  fieldName  +   "] ");  }  FieldMapper  mapper  =  smartNameFieldMappers.mapper();  if  (!(mapper  instanceof  NumberFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "Field  [ "  +  fieldName  +   "]  is  not  a  numeric  type ");  }          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext.fieldData(),  from,  to,  includeLower,  includeUpper,  parseContext);          Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext,  from,  to,  includeLower,  includeUpper,  parseContext);  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartNameFieldMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	Filter  filter  =  ((NumberFieldMapper)  mapper).rangeFilter(parseContext,  from,  to,  includeLower,  includeUpper,  parseContext);  
elasticsearch_7f6f001d15a24e9df13f212413734d26b2ce4697	buggy:  notifyMasterFailure(masterToPing,   "no  longer  master ");  context:  }  synchronized  (masterNodeMutex)  {  if  (masterToPing.equals(MasterFaultDetection.this.masterNode()))  {  if  (exp.getCause()  instanceof  NoLongerMasterException)  {  notifyMasterFailure(masterToPing,   "no  longer  master ");  return;  }  else  if  (exp.getCause()  instanceof  NotMasterException)  {                                          notifyMasterFailure(masterToPing,   "no  longer  master ");                                          notifyMasterFailure(masterToPing,   "not  master ");  return;  }  else  if  (exp.getCause()  instanceof  NodeDoesNotExistOnMasterException)  {  notifyMasterFailure(masterToPing,   "do  not  exists  on  master,  act  as  master  failure ");  return;  }  int  retryCount  =  ++MasterFaultDetection.this.retryCount;  	notifyMasterFailure(masterToPing,   "not  master ");  
libgdx_c0265954da445c7fcd40358c45cfe2f8850014d7	buggy:  layout.getDefaults().spaceBottom(10);  context:  final  ScrollPane  scrollPane  =  skin.newScrollPane( "scroll ",  ui,  imageActor,  100,  100);  final  List  list  =  skin.newList( "list ",  listEntries);  final  ScrollPane  scrollPane2  =  skin.newScrollPane( "scroll2 ",  ui,  list,  100,  100);  final  SplitPane  splitPane  =  skin.newSplitPane( "split ",  ui,  scrollPane,  scrollPane2,  false,  0,  0,   "default-horizontal ");  final  Label  label  =  skin.newLabel( "label ",   "fps: ");  imgButton.setImageSize(16,  20);  imgToggleButton.setImageSize(10,  10);  TableLayout  layout  =  window.getTableLayout();  layout.getDefaults().spaceBottom(10);  layout.defaults().spaceBottom(10);  layout.row().fill().expandX();  layout.add(button);  layout.add(buttonMulti);  layout.add(imgButton);  layout.add(imgToggleButton);  layout.row();  layout.add(checkBox);  layout.add(slider).fillX().colspan(3);  	layout.defaults().spaceBottom(10);  
libgdx_3d5b25c4b1602fa62ab235181aa612ba877e0e20	buggy:  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  context:  public  void  setVertices  (float[]  vertices,  int  offset,  int  count)  {  BufferUtils.copy(vertices,  byteBuffer,  count,  offset);  buffer.position(0);  buffer.limit(count);  }  public  void  updateVertices  (int  targetOffset,  float[]  vertices,  int  sourceOffset,  int  count)  {  final  int  pos  =  byteBuffer.position();  byteBuffer.position(targetOffset  *  4);  BufferUtils.copy(vertices,  sourceOffset,  byteBuffer,  count);  BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  byteBuffer.position(pos);  }  public  void  bind  ()  {  GL10  gl  =  Gdx.gl10;  int  textureUnit  =  0;  int  numAttributes  =  attributes.size();  	BufferUtils.copy(vertices,  sourceOffset,  count,  byteBuffer);  
elasticsearch_0dbc83e7b08e53d4268becd1af0933ee3c408cfe	buggy:  byte[]  bulkAction  =  unZipData( "/org/elasticsearch/search/geo/gzippedmap.json ");  context:  result  =  client().prepareSearch()  .setQuery(matchAllQuery())  .setPostFilter(FilterBuilders.geoIntersectionFilter( "area ",  ShapeBuilder.newPoint(180,  -6)))  .execute().actionGet();  assertHitCount(result,  1);  }  public  void  bulktest()  throws  Exception  {          byte[]  bulkAction  =  unZipData( "/org/elasticsearch/search/geo/gzippedmap.json ");          byte[]  bulkAction  =  unZipData( "/org/elasticsearch/search/geo/gzippedmap.gz ");  String  mapping  =  XContentFactory.jsonBuilder()  .startObject()  .startObject( "country ")  .startObject( "properties ")  .startObject( "pin ")  .field( "type ",   "geo_point ")  .field( "lat_lon ",  true)  	byte[]  bulkAction  =  unZipData( "/org/elasticsearch/search/geo/gzippedmap.gz ");  
libgdx_f86b424b6a2af76c8cd503d27e6206369835e098	buggy:  if  ((format  !=  WebGLRenderingContext.UNSIGNED_BYTE)  ||  (type  !=  WebGLRenderingContext.RGBA))  {  context:  }  public  void  glPolygonOffset  (float  factor,  float  units)  {  gl.polygonOffset(factor,  units);  }  public  void  glReadPixels  (int  x,  int  y,  int  width,  int  height,  int  format,  int  type,  Buffer  pixels)  {  if  ((format  !=  WebGLRenderingContext.UNSIGNED_BYTE)  ||  (type  !=  WebGLRenderingContext.RGBA))  {  if  ((format  !=  WebGLRenderingContext.RGBA)  ||  (type  !=  WebGLRenderingContext.UNSIGNED_BYTE))  {  throw  new  GdxRuntimeException( "Only  format  UNSIGNED_BYTE  for  type  RGBA  is  currently  supported. ");  }  if  (!(pixels  instanceof  ByteBuffer))  {  throw  new  GdxRuntimeException( "Inputed  pixels  buffer  needs  to  be  of  type  ByteBuffer. ");  }  int  size  =  4  *  width  *  height;  	if  ((format  !=  WebGLRenderingContext.RGBA)  ||  (type  !=  WebGLRenderingContext.UNSIGNED_BYTE))  {  
libgdx_9338408afcc3bc23745749fd6efdf95be3d25ef3	buggy:  int  width  =  font.getBounds(text).width;  context:  spriteBatch.setProjectionMatrix(viewMatrix);  spriteBatch.setTransformMatrix(transformMatrix);  spriteBatch.begin();  spriteBatch.disableBlending();  spriteBatch.setColor(Color.WHITE);  spriteBatch.draw(background,  0,  0,  480,  320,  0,  0,  512,  512,  false,  false);  spriteBatch.enableBlending();  spriteBatch.draw(logo,  0,  320-128,  480,  128,  0,  0,  512,  256,  false,  false);  spriteBatch.setBlendFunction(GL10.GL_ONE,  GL10.GL_ONE_MINUS_SRC_ALPHA);  String  text  =   "Touch  screen  to  start! ";  int  width  =  font.getBounds(text).width;  float  width  =  font.getBounds(text).width;  font.draw(spriteBatch,  text,  240  -  width  /  2,  128);  spriteBatch.end();  }  isDone  =  app.getInput().isTouched();  }  	float  width  =  font.getBounds(text).width;  
libgdx_d555a6abd1a539702e854ff3d5ce3d82b1a93a1b	buggy:  new  AngleApplication(new  com.badlogic.gdx.tests.VertexBufferObjectShaderTest(),   "Angle  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.angle;  public  class  AngleDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  AngleApplication(new  com.badlogic.gdx.tests.VertexBufferObjectShaderTest(),   "Angle  Test ",  480,  320,  false);  new  AngleApplication(new  com.badlogic.gdx.tests.MeshShaderTest(),   "Angle  Test ",  480,  320,  false);  }  }  	new  AngleApplication(new  com.badlogic.gdx.tests.MeshShaderTest(),   "Angle  Test ",  480,  320,  false);  
elasticsearch_679f3758b7ff9ce5fa4fe59ff8d54663ae60544e	buggy:  }  catch  (IOException  e1)  {  context:  threadPool.cached().execute(new  Runnable()  {  try  {  RecoveryResponse  response  =  recover(request);  channel.sendResponse(response);  }  catch  (Exception  e)  {  try  {  channel.sendResponse(e);                          }  catch  (IOException  e1)  {                          }  catch  (Exception  e1)  {  }  }  }  });  }  	}  catch  (Exception  e1)  {  
libgdx_11224e0a455232d1dab6550455a9d7df9a10c860	buggy:  if  (debugRects  ==  null)  return;  context:  }  else  {  drawDebugRects(shapes);  super.drawDebug(shapes);  }  }  protected  void  drawDebugBounds  (ShapeRenderer  shapes)  {  }  private  void  drawDebugRects  (ShapeRenderer  shapes)  {  if  (debugRects  ==  null)  return;  if  (debugRects  ==  null  ||  !getDebug())  return;  shapes.set(ShapeType.Line);  shapes.setColor(getStage().getDebugColor());  for  (int  i  =  0,  n  =  debugRects.size;  i  <  n;  i++)  {  DebugRect  debugRect  =  debugRects.get(i);  shapes.setColor(debugRect.color);  shapes.rect(getX()  +  debugRect.x,  getY()  +  debugRect.y,  debugRect.width,  debugRect.height);  }  }  	if  (debugRects  ==  null  ||  !getDebug())  return;  
elasticsearch_4ea5b7d51f02dc9582e208b008b39fb73126da6a	buggy:  if  (boost  ==  -1  &&  rewrite  !=  null)  {  context:  public  WildcardQueryBuilder  boost(float  boost)  {  this.boost  =  boost;  return  this;  }  public  void  doXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(WildcardQueryParser.NAME);          if  (boost  ==  -1  &&  rewrite  !=  null)  {          if  (boost  ==  -1  &&  rewrite  ==  null)  {  builder.field(name,  wildcard);  }  else  {  builder.startObject(name);  builder.field( "wildcard ",  wildcard);  if  (boost  !=  -1)  {  builder.field( "boost ",  boost);  }  if  (rewrite  !=  null)  {  	if  (boost  ==  -1  &&  rewrite  ==  null)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  return  new  PutMappingRequest();  }  protected  PutMappingResponse  newResponse()  {  return  new  PutMappingResponse();  }  protected  void  doExecute(PutMappingRequest  request,  ActionListener<PutMappingResponse>  listener)  {          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(PutMappingRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  	request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_7d6c567e6f879cc502c05cc433f2af9631d7bc5c	buggy:  return  DocIdSet.EMPTY_DOCIDSET;  context:  public  DocIdSet  getDocIdSet(IndexReader  reader)  throws  IOException  {  if  (collectedUids  ==  null)  {  throw  new  ElasticSearchIllegalStateException( "has_child  filter/query  hasn't  executed  properly ");  }  IdReaderTypeCache  idReaderTypeCache  =  searchContext.idCache().reader(reader).type(parentType);  if  (idReaderTypeCache  !=  null)  {  return  new  ParentDocSet(reader,  collectedUids,  idReaderTypeCache);  }  else  {                  return  DocIdSet.EMPTY_DOCIDSET;                  return  null;  }  }  public  void  clear()  {  if  (collectedUids  !=  null)  {  CacheRecycler.pushHashSet(collectedUids);  }  collectedUids  =  null;  	return  null;  
elasticsearch_3f3a95668b789593b3748af3d1113fb568ee1c17	buggy:  fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);  context:  builder  =  this;  }  public  Builder  nullValue(float  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  FloatFieldMapper  build(BuilderContext  context)  {              fieldType.setOmitNorms(fieldType.omitNorms()  ||  boost  !=  1.0f);              fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  FloatFieldMapper  fieldMapper  =  new  FloatFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  boost,  fieldType,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  	fieldType.setOmitNorms(fieldType.omitNorms()  &&  boost  ==  1.0f);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  keys.release();  context:  for  (Iterator<WeightedFilterCache.FilterCacheKey>  it  =  cache.asMap().keySet().iterator();  it.hasNext();  )  {  WeightedFilterCache.FilterCacheKey  filterCacheKey  =  it.next();  if  (keys.v().contains(filterCacheKey.readerKey()))  {  it.remove();  }  }  }  schedule();  }  finally  {                              keys.release();                              keys.close();  }  }  });  }  catch  (EsRejectedExecutionException  ex)  {  }  }  	keys.close();  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  valueScript.setNextReader(context.reader());  context:  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  valueScript.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (LongFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);          valueScript.setNextReader(context.reader());          valueScript.setNextReader(context);  }  public  Facet  facet()  {  return  new  InternalFullDateHistogramFacet(facetName,  comparatorType,  histoProc.entries,  true);  }  public  static  class  DateHistogramProc  implements  LongFieldData.LongValueInDocProc  {  	valueScript.setNextReader(context);  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  public  class  ImageTest  extends  GdxTest  {  Skin  skin;  Stage  ui;  Table  root;  TextureRegion  image2;  public  void  create  ()  {  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  image2  =  new  TextureRegion(new  Texture(Gdx.files.internal( "data/badlogic.jpg ")));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  Gdx.input.setInputProcessor(ui);  root  =  new  Table();  ui.addActor(root);  root.debug();  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_5706858722452b13465b15930e4f4cb2e8286449	buggy:  get,  request.id(),  request.type(),  validFields.toArray(Strings.EMPTY_ARRAY),  null);  context:  }  Engine.GetResult  get  =  indexShard.get(new  Engine.Get(realTime,  uidTerm));  Fields  generatedTermVectors;  try  {  if  (!get.exists())  {  return  termVectorsByField;  }  GetResult  getResult  =  indexShard.getService().get(                      get,  request.id(),  request.type(),  validFields.toArray(Strings.EMPTY_ARRAY),  null);                      get,  request.id(),  request.type(),  validFields.toArray(Strings.EMPTY_ARRAY),  null,  false);  generatedTermVectors  =  generateTermVectors(getResult.getFields().values(),  request.offsets());  }  finally  {  get.release();  }  if  (termVectorsByField  ==  null)  {  return  generatedTermVectors;  }  else  {  return  mergeFields(request.selectedFields().toArray(Strings.EMPTY_ARRAY),  termVectorsByField,  generatedTermVectors);  	get,  request.id(),  request.type(),  validFields.toArray(Strings.EMPTY_ARRAY),  null,  false);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(source,  true);  context:  out.writeBoolean(true);  out.writeUTF(parent);  }  if  (timestamp  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  out.writeUTF(timestamp);  }  out.writeLong(ttl);          out.writeBytesReference(source,  true);          out.writeBytesReference(source);  out.writeByte(opType.id());  out.writeBoolean(refresh);  out.writeLong(version);  if  (percolate  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  out.writeUTF(percolate);  	out.writeBytesReference(source);  
elasticsearch_f6fc390f7a491f2d4f89bf05d47b5226f7833497	buggy:  allInterfaces.add(interfaces.nextElement());  context:  }  public  static  List<NetworkInterface>  getAllAvailableInterfaces()  throws  SocketException  {  List<NetworkInterface>  allInterfaces  =  new  ArrayList<NetworkInterface>();  for  (Enumeration<NetworkInterface>  interfaces  =  NetworkInterface.getNetworkInterfaces();  interfaces.hasMoreElements();  )  {  NetworkInterface  intf  =  interfaces.nextElement();              allInterfaces.add(interfaces.nextElement());              allInterfaces.add(intf);  Enumeration<NetworkInterface>  subInterfaces  =  intf.getSubInterfaces();  if  (subInterfaces  !=  null  &&  subInterfaces.hasMoreElements())  {  while  (subInterfaces.hasMoreElements())  {  allInterfaces.add(subInterfaces.nextElement());  }  }  }  	allInterfaces.add(intf);  
elasticsearch_eccc7d5ef21dade9bd14d3a3adaf60e664582ac0	buggy:  if  (original  ==  searchContext.query()  ||  original  ==  searchContext.originalQuery())  {  context:  public  List<Collector>  globalCollectors()  {  return  globalCollectors;  }  public  void  useGlobalCollectors(boolean  useGlobalCollectors)  {  this.useGlobalCollectors  =  useGlobalCollectors;  }          if  (original  ==  searchContext.query()  ||  original  ==  searchContext.originalQuery())  {          if  (original  ==  searchContext.query()  ||  original  ==  searchContext.parsedQuery().query())  {  if  (searchContext.queryRewritten())  {  return  searchContext.query();  }  Query  rewriteQuery  =  super.rewrite(original);  searchContext.updateRewriteQuery(rewriteQuery);  return  rewriteQuery;  }  else  {  	if  (original  ==  searchContext.query()  ||  original  ==  searchContext.parsedQuery().query())  {  
elasticsearch_39cb08fc1c713835af3061c3a0360c2f76559724	buggy:  return  new  NonBlockingVersionedMap();  context:  package  org.elasticsearch.util.lucene.versioned;  public  class  NonBlockingVersionedMapTests  extends  AbstractVersionedMapTests  {          return  new  NonBlockingVersionedMap();          return  new  ConcurrentVersionedMapLong();  }  }  	return  new  ConcurrentVersionedMapLong();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  setBinding(new  InstanceBindingImpl<T>(  context:  }  else  if  (base.getKey().getAnnotationType()  !=  null)  {  key  =  Key.get(typeAsClassT,  base.getKey().getAnnotationType());  }  else  {  key  =  Key.get(typeAsClassT);  }  if  (instanceAsT  ==  null)  {  binder.addError(BINDING_TO_NULL);  }          setBinding(new  InstanceBindingImpl<T>(          setBinding(new  InstanceBindingImpl<>(  base.getSource(),  key,  base.getScoping(),  ImmutableSet.<InjectionPoint>of(),  instanceAsT));  }  public  String  toString()  {  return   "ConstantBindingBuilder ";  }  }  	setBinding(new  InstanceBindingImpl<>(  
elasticsearch_7709c68f6312703b60b40f9ded1bd6121daa1d58	buggy:  return  fixNegativeQueryIfNeeded(query);  context:  queryParser.setFuzzyMinSim(fuzzyMinSim);  queryParser.setFuzzyPrefixLength(fuzzyPrefixLength);  if  (escape)  {  queryString  =  QueryParser.escape(queryString);  }  try  {  Query  query  =  queryParser.parse(queryString);  query.setBoost(boost);              return  fixNegativeQueryIfNeeded(query);              return  optimizeQuery(fixNegativeQueryIfNeeded(query));  }  catch  (ParseException  e)  {  throw  new  QueryParsingException(index,   "Failed  to  parse  query  [ "  +  queryString  +   "] ",  e);  }  }  }  	return  optimizeQuery(fixNegativeQueryIfNeeded(query));  
libgdx_842e645b9e863dc2f4f310afb34142a7b1214355	buggy:  initialize(new  Bouncy(),  false,  new  FillResolutionStrategy(),  16);  context:  public  class  BouncyAndroid  extends  AndroidApplication  {  super.onCreate(savedInstanceState);  initialize(new  Bouncy(),  false,  new  FillResolutionStrategy(),  16);  initialize(new  Bouncy(),  false);  }  }  	initialize(new  Bouncy(),  false);  
elasticsearch_036febe110f0ea87d96bfe2dce71f97469d5f317	buggy:  assertThat(response.mappings(),  hasKey( "index "));  context:  public  class  SimpleGetMappingsTests  extends  ElasticsearchIntegrationTest  {  public  void  getMappingsWhereThereAreNone()  {  createIndex( "index ");  GetMappingsResponse  response  =  client().admin().indices().prepareGetMappings().execute().actionGet();          assertThat(response.mappings(),  hasKey( "index "));          assertThat(response.mappings().containsKey( "index "),  equalTo(true));  assertThat(response.mappings().get( "index ").size(),  equalTo(0));  }  private  XContentBuilder  getMappingForType(String  type)  throws  IOException  {  return  jsonBuilder().startObject().startObject(type).startObject( "properties ")  .startObject( "field1 ").field( "type ",   "string ").endObject()  .endObject().endObject().endObject();  	assertThat(response.mappings().containsKey( "index "),  equalTo(true));  
elasticsearch_743dc19acbfe69b3c64cda69d4d77b3c6efc58d7	buggy:  table.addCell(info  ==  null  ?  null  :  info.getVersion().number());  context:  table.addCell(fullId  ?  node.id()  :  Strings.substring(node.getId(),  0,  4));  table.addCell(info  ==  null  ?  null  :  info.getProcess().id());  table.addCell(node.getHostName());  table.addCell(node.getHostAddress());  if  (node.address()  instanceof  InetSocketTransportAddress)  {  table.addCell(((InetSocketTransportAddress)  node.address()).address().getPort());  }  else  {  table.addCell( "- ");  }              table.addCell(info  ==  null  ?  null  :  info.getVersion().number());              table.addCell(node.getVersion().number());  table.addCell(info  ==  null  ?  null  :  info.getBuild().hashShort());  table.addCell(info  ==  null  ?  null  :  info.getJvm().version());  table.addCell(stats  ==  null  ?  null  :  stats.getFs()  ==  null  ?  null  :  stats.getFs().total().getAvailable());  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().getMem().getHeapUsedPrecent());  table.addCell(info  ==  null  ?  null  :  info.getJvm().getMem().getHeapMax());  table.addCell(stats  ==  null  ?  null  :  stats.getOs().mem()  ==  null  ?  null  :  stats.getOs().mem().usedPercent());  table.addCell(info  ==  null  ?  null  :  info.getOs().mem()  ==  null  ?  null  :  info.getOs().mem().total());  //  sigar  fails  to  load  in  IntelliJ  	table.addCell(node.getVersion().number());  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  context:  }  protected  NodeInfo  newNodeResponse()  {  return  new  NodeInfo();  }  protected  NodeInfo  nodeOperation(NodeInfoRequest  nodeRequest)  throws  ElasticSearchException  {  NodesInfoRequest  request  =  nodeRequest.request;          return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());          return  nodeService.info(request.isSettings(),  request.isOs(),  request.isProcess(),  request.isJvm(),  request.isThreadPool(),  request.isNetwork(),  request.isTransport(),  request.isHttp());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeInfoRequest  extends  NodeOperationRequest  {  	return  nodeService.info(request.isSettings(),  request.isOs(),  request.isProcess(),  request.isJvm(),  request.isThreadPool(),  request.isNetwork(),  request.isTransport(),  request.isHttp());  
elasticsearch_25b49dd50b2e72a0d74374bffa51a27f22d5c5f7	buggy:   "tests.assertion.disabled ");  context:  return  this;  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TestCluster.TESTS_ENABLE_MOCK_MODULES,                       "tests.assertion.disabled ");                       "tests.assertion.disabled ",   "tests.security.manager ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  return  this;  }  protected  ReproduceErrorMessageBuilder  appendProperties(String...  properties)  {  for  (String  sysPropName  :  properties)  {  	 "tests.assertion.disabled ",   "tests.security.manager ");  
libgdx_d32a5e0fed31ba373f4f867d417bb8154cfca5b8	buggy:  if(  mesh.getMesh().getMaximumVertices()  /  6  <  text.length()  )  context:  private  void  rebuild(  )  {  if(  mesh  ==  null  )  {  FloatMesh  m  =  new  FloatMesh(  6  *  text.length(),  3,  false,  false,  true,  1,  2,  false,  0  );  mesh  =  new  MeshRenderer(  graphics.getGL10(),  m,  false,  font.isManaged()  );  }  if(  mesh.getMesh().getMaximumVertices()  /  6  <  text.length()  )  if(  mesh.getMesh().getMaximumVertices()  /  6  <=  text.length()  )  {  mesh.dispose();  FloatMesh  m  =  new  FloatMesh(  6  *  text.length(),  3,  false,  false,  true,  1,  2,  false,  0  );  mesh  =  new  MeshRenderer(  graphics.getGL10(),  m,  false,  font.isManaged()  );  }  float[]  vertices  =  ((FloatMesh)mesh.getMesh()).getVerticesArray();  int  vertIdx  =  0;  	if(  mesh.getMesh().getMaximumVertices()  /  6  <=  text.length()  )  
libgdx_0155cc6f737713defe34b6f09c01fd05334d6303	buggy:  emitter.setSprite(new  Sprite(Gdx.graphics.newTexture(file,  TextureFilter.Linear,  TextureFilter.Linear,  context:  private  void  loadImage  (ParticleEmitter  emitter)  {  final  String  imagePath  =  emitter.getImagePath();  String  imageName  =  new  File(imagePath.replace('\\',  '/')).getName();  try  {  FileHandle  file;  if  (imagePath.equals( "particle.png "))  file  =  Gdx.files.classpath(imagePath);  else  file  =  Gdx.files.absolute(imagePath);  emitter.setSprite(new  Sprite(Gdx.graphics.newTexture(file,  TextureFilter.Linear,  TextureFilter.Linear,  emitter.setSprite(new  Sprite(Gdx.graphics.newTexture(file,  TextureFilter.Nearest,  TextureFilter.Nearest,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge)));  }  catch  (GdxRuntimeException  ex)  {  ex.printStackTrace();  EventQueue.invokeLater(new  Runnable()  {  public  void  run  ()  {  JOptionPane.showMessageDialog(ParticleEditor.this,   "Error  loading  image:\n "  +  imagePath);  }  });  	emitter.setSprite(new  Sprite(Gdx.graphics.newTexture(file,  TextureFilter.Nearest,  TextureFilter.Nearest,  
libgdx_257c6d91ac15303c3897932ac0358a7b8da33c01	buggy:  effectPanel.newEmitter( "Untitled ",  true);  context:  zoomLevel  =  new  NumericValue();  zoomLevel.setValue(1.0f);  zoomLevel.setAlwaysActive(true);  deltaMultiplier  =  new  NumericValue();  deltaMultiplier.setValue(1.0f);  deltaMultiplier.setAlwaysActive(true);  font  =  new  BitmapFont(Gdx.files.getFileHandle( "default.fnt ",  FileType.Internal),  Gdx.files.getFileHandle( "default.png ",  FileType.Internal),  true);  effectPanel.newEmitter( "Untitled ",  true);  effectPanel.newExampleEmitter( "Untitled ",  true);  Gdx.input.setInputProcessor(this);  }  public  void  resize  (int  width,  int  height)  {  Gdx.gl.glViewport(0,  0,  width,  height);  	effectPanel.newExampleEmitter( "Untitled ",  true);  
elasticsearch_fd15b6278b78be0057fad1357c1c2f511a6413d2	buggy:  int  count  =  0;  context:  public  long  getCount()  {  return  count;  }  public  Facet  reduce(ReduceContext  context)  {  List<Facet>  facets  =  context.facets();  if  (facets.size()  ==  1)  {  return  facets.get(0);  }          int  count  =  0;          long  count  =  0;  for  (Facet  facet  :  facets)  {  count  +=  ((QueryFacet)  facet).getCount();  }  return  new  InternalQueryFacet(getName(),  count);  }  static  final  class  Fields  {  static  final  XContentBuilderString  _TYPE  =  new  XContentBuilderString( "_type ");  	long  count  =  0;  
elasticsearch_f8afa4d67b374a3712782b4e95fe377877f0e0ab	buggy:  return  new  JsonXContentParser(jsonFactory.createJsonParser(reader));  context:  public  XContentParser  createParser(BytesReference  bytes)  throws  IOException  {  if  (bytes.hasArray())  {  return  createParser(bytes.array(),  bytes.arrayOffset(),  bytes.length());  }  return  createParser(bytes.streamInput());  }  public  XContentParser  createParser(Reader  reader)  throws  IOException  {          return  new  JsonXContentParser(jsonFactory.createJsonParser(reader));          return  new  JsonXContentParser(jsonFactory.createParser(reader));  }  }  	return  new  JsonXContentParser(jsonFactory.createParser(reader));  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  counts.release();  context:  InternalCountHistogramFacet.CountEntry[]  entries  =  new  InternalCountHistogramFacet.CountEntry[counts.v().size()];  final  boolean[]  states  =  counts.v().allocated;  final  long[]  keys  =  counts.v().keys;  final  long[]  values  =  counts.v().values;  int  entryIndex  =  0;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  entries[entryIndex++]  =  new  InternalCountHistogramFacet.CountEntry(keys[i],  values[i]);  }  }          counts.release();          counts.close();  return  new  InternalCountHistogramFacet(facetName,  comparatorType,  entries);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  class  Collector  extends  FacetExecutor.Collector  {  	counts.close();  
libgdx_1b63ab824068d43cdfdc870fd015c9324c96a954	buggy:  String[]  headers  =  { "src/bullet/ ",   "src/custom/ "};  context:  cppFlags  +=   "  -fno-rtti ";  cppFlags  +=   "  -DBT_NO_PROFILE ";  String[]  excludes  =  { "src/bullet/BulletMultiThreaded/GpuSoftBodySolvers/** "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ "};  String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize/ "};  BuildTarget  win32home  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  win32home.compilerPrefix  =   " ";  win32home.buildFileName  =   "build-windows32home.xml ";  win32home.excludeFromMasterBuildFile  =  true;  win32home.cExcludes  =  win32home.cppExcludes  =  excludes;  win32home.headerDirs  =  headers;  win32home.cppFlags  +=  cppFlags;  	String[]  headers  =  { "src/bullet/ ",   "src/custom/ ",   "src/extras/serialize/ "};  
elasticsearch_ef55e4feecaf90e1c20880e7cc6a5a2e7853204a	buggy:  throw  new  MapperParsingException( "Failed  to  parse  [ "  +  names.fullName()  +   "] ",  e);  context:  if  (field  ==  null)  {  return;  }  if  (!customBoost())  {  field.setBoost(boost);  }  if  (context.listener().beforeFieldAdded(this,  field,  context))  {  context.doc().add(field);  }  }  catch  (Exception  e)  {              throw  new  MapperParsingException( "Failed  to  parse  [ "  +  names.fullName()  +   "] ",  e);              throw  new  MapperParsingException( "failed  to  parse  [ "  +  names.fullName()  +   "] ",  e);  }  }  protected  abstract  Field  parseCreateField(ParseContext  context)  throws  IOException;  	throw  new  MapperParsingException( "failed  to  parse  [ "  +  names.fullName()  +   "] ",  e);  
elasticsearch_4f91152b3de6fd60936ece1d39e96498e2dc3aa7	buggy:  query  =  smartNameFieldMappers.mapper().termQuery(value);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().termQuery(value);                  query  =  smartNameFieldMappers.mapper().fieldQuery(value);  }  }  if  (query  ==  null)  {  query  =  new  TermQuery(new  Term(fieldName,  value));  }  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  	query  =  smartNameFieldMappers.mapper().fieldQuery(value);  
elasticsearch_821c3524a22e17fd9b0e696a2c5595ca12c9d0c6	buggy:  ).sourceField(source()).build(mapperParser);  context:  public  class  SimpleMapperTests  {  DocumentMapperParser  mapperParser  =  MapperTests.newParser();  DocumentMapper  docMapper  =  doc( "test ",  rootObject( "person ")  .add(object( "name ").add(stringField( "first ").store(YES).index(Field.Index.NO)))          ).sourceField(source()).build(mapperParser);          ).build(mapperParser);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/simple/test1.json ");  Document  doc  =  docMapper.parse( "person ",   "1 ",  json).rootDoc();  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().names().indexName()),  equalTo( "shay "));  assertThat(docMapper.mappers().name( "first ").mapper().names().fullName(),  equalTo( "name.first "));  	).build(mapperParser);  
elasticsearch_3a52296358f28ed7dd465d525e6cb3e85f055f3b	buggy:  if  (request.searchType()  !=  SearchType.COUNT)  {  context:  public  boolean  canCache(ShardSearchRequest  request,  SearchContext  context)  {  if  (hasLength(request.templateSource()))  {  return  false;  }          if  (request.searchType()  !=  SearchType.COUNT)  {          if  (context.searchType()  !=  SearchType.COUNT)  {  return  false;  }  IndexMetaData  index  =  clusterService.state().getMetaData().index(request.index());  if  (index  ==  null)  {  //  in  case  we  didn't  yet  have  the  cluster  state,  or  it  just  got  deleted  return  false;  }  if  (request.queryCache()  ==  null)  {  	if  (context.searchType()  !=  SearchType.COUNT)  {  
elasticsearch_fe4ba2ad559451ba1cdf61cb7832855e10a93b6e	buggy:  List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());  context:  public  static  final  Field[]  EMPTY_FIELDS  =  new  Field[0];  protected  Field[]  getFields(IndexReader  reader,  int  docId,  String  fieldName)  throws  IOException  {  SearchLookup  lookup  =  searchContext.lookup();  lookup.setNextReader(reader);  lookup.setNextDocId(docId);          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().fullName());          List<Object>  values  =  lookup.source().extractRawValues(mapper.names().sourcePath());  if  (values.isEmpty())  {  return  EMPTY_FIELDS;  }  Field[]  fields  =  new  Field[values.size()];  for  (int  i  =  0;  i  <  values.size();  i++)  {  fields[i]  =  new  Field(mapper.names().indexName(),  values.get(i).toString(),  Field.Store.NO,  Field.Index.ANALYZED);  }  return  fields;  	List<Object>  values  =  lookup.source().extractRawValues(mapper.names().sourcePath());  
elasticsearch_c3cb5a3e349e36d4cd0f948331253032051a623a	buggy:  indexRequest.id(UUID.randomUUID().toString());  context:  super(settings,  transportService,  clusterService,  indicesService,  threadPool,  shardStateAction);  this.createIndexAction  =  createIndexAction;  this.mappingUpdatedAction  =  mappingUpdatedAction;  this.autoCreateIndex  =  settings.getAsBoolean( "action.auto_create_index ",  true);  this.allowIdGeneration  =  settings.getAsBoolean( "action.allow_id_generation ",  true);  }  if  (allowIdGeneration)  {  if  (indexRequest.id()  ==  null)  {                  indexRequest.id(UUID.randomUUID().toString());                  indexRequest.id(UUID.randomBase64UUID());  indexRequest.opType(IndexRequest.OpType.CREATE);  }  }  if  (autoCreateIndex  &&  !clusterService.state().metaData().hasConcreteIndex(indexRequest.index()))  {  createIndexAction.execute(new  CreateIndexRequest(indexRequest.index()).cause( "auto(index  api) "),  new  ActionListener<CreateIndexResponse>()  {  TransportIndexAction.super.doExecute(indexRequest,  listener);  	indexRequest.id(UUID.randomBase64UUID());  
elasticsearch_d094042b08bb99bffa1744bac1dd2df1da6a37ff	buggy:  GetResponse  getResponse  =  client.get(new  GetRequest(lookup.getIndex(),  lookup.getType(),  lookup.getId()).preference( "_local ")).actionGet();  context:  public  Filter  lookupTermsFilter(final  CacheKeyFilter.Key  cacheKey,  final  TermsLookup  lookup)  {  return  new  LookupTermsFilter(lookup,  cacheKey,  this);  }  private  Filter  termsFilter(final  CacheKeyFilter.Key  cacheKey,  final  TermsLookup  lookup)  throws  RuntimeException  {  try  {  return  cache.get(cacheKey,  new  Callable<TermsFilterValue>()  {  public  TermsFilterValue  call()  throws  Exception  {                      GetResponse  getResponse  =  client.get(new  GetRequest(lookup.getIndex(),  lookup.getType(),  lookup.getId()).preference( "_local ")).actionGet();                      GetResponse  getResponse  =  client.get(new  GetRequest(lookup.getIndex(),  lookup.getType(),  lookup.getId()).preference( "_local ").routing(lookup.getRouting())).actionGet();  if  (!getResponse.isExists())  {  return  NO_TERMS;  }  List<Object>  values  =  XContentMapValues.extractRawValues(lookup.getPath(),  getResponse.getSourceAsMap());  if  (values.isEmpty())  {  return  NO_TERMS;  }  Filter  filter  =  lookup.getFieldMapper().termsFilter(values,  lookup.getQueryParseContext());  	GetResponse  getResponse  =  client.get(new  GetRequest(lookup.getIndex(),  lookup.getType(),  lookup.getId()).preference( "_local ").routing(lookup.getRouting())).actionGet();  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  SpanTermQuery  query  =  new  SpanTermQuery(new  Term(fieldName,  value));  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_9a8e033424e1fe9300599f6af2be40e547e2cab8	buggy:  newBq.add(new  MatchAllDocsQuery(),  BooleanClause.Occur.MUST);  context:  }  for  (BooleanClause  clause  :  clauses)  {  if  (!clause.isProhibited())  return  false;  }  return  true;  }  public  static  Query  fixNegativeQueryIfNeeded(Query  q)  {  if  (isNegativeQuery(q))  {  BooleanQuery  newBq  =  (BooleanQuery)  q.clone();              newBq.add(new  MatchAllDocsQuery(),  BooleanClause.Occur.MUST);              newBq.add(MATCH_ALL_QUERY,  BooleanClause.Occur.MUST);  return  newBq;  }  return  q;  }  }  	newBq.add(MATCH_ALL_QUERY,  BooleanClause.Occur.MUST);  
elasticsearch_167d35807c5ce4b8e10228180dcf58b14f3ce826	buggy:  return  new  String[]{NAME};  context:  public  class  TermsFilterParser  extends  AbstractIndexComponent  implements  XContentFilterParser  {  public  static  final  String  NAME  =   "terms ";  super(index,  settings);  }          return  new  String[]{NAME};          return  new  String[]{NAME,   "in "};  }  XContentParser  parser  =  parseContext.parser();  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  null;  boolean  cache  =  true;  TermsFilter  termsFilter  =  new  PublicTermsFilter();  	return  new  String[]{NAME,   "in "};  
libgdx_b432442fda59f17f4c481c8cab34cf0b49e3aa6e	buggy:  modelBatch.render(instance,  lights);  context:  texture  =  null;  }  protected  void  renderWorld  ()  {  softBody.getVertices(mesh.getVerticesBuffer(),  softBody.getNodeCount(),  mesh.getVertexSize(),  0);  softBody.getWorldTransform(instance.transform);  modelBatch.begin(camera);  world.render(modelBatch,  lights);  modelBatch.render(instance,  lights);  modelBatch.render(lights,  instance);  modelBatch.end();  }  public  void  render  ()  {  super.render();  if  (world.renderMeshes)  {  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  	modelBatch.render(lights,  instance);  
elasticsearch_54880c576b2643da1a436e81e4e06922c09e6cee	buggy:  indexWriter.close();  context:  }  if  (disableFlushCounter  >  0)  {  throw  new  FlushNotAllowedEngineException(shardId,   "Recovery  is  in  progress,  flush  is  not  allowed ");  }  dirty  =  false;  try  {                          indexWriter.close();                          indexWriter.close(false);  indexWriter  =  createWriter();  if  (flushNeeded)  {  flushNeeded  =  false;  long  translogId  =  translogIdGenerator.incrementAndGet();  indexWriter.commit(MapBuilder.<String,  String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY,  Long.toString(translogId)).map());  translog.newTranslog(translogId);  }  	indexWriter.close(false);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<DiscoveryNode>  nodes  =  new  ArrayList<DiscoveryNode>();  context:  }  MetaData  metaData  =  builder.build();  for  (int  i  =  0;  i  <  numIndices;  i++)  {  rtBuilder.addAsNew(metaData.index( "test_ "  +  i));  }  RoutingTable  routingTable  =  rtBuilder.build();  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.shardsWithState(UNASSIGNED).size(),  equalTo(routingTable.allShards().size()));          List<DiscoveryNode>  nodes  =  new  ArrayList<DiscoveryNode>();          List<DiscoveryNode>  nodes  =  new  ArrayList<>();  int  nodeIdx  =  0;  int  iters  =  scaledRandomIntBetween(10,  100);  for  (int  i  =  0;  i  <  iters;  i++)  {  DiscoveryNodes.Builder  nodesBuilder  =  DiscoveryNodes.builder();  int  numNodes  =  between(1,  20);  if  (nodes.size()  >  numNodes)  {  Collections.shuffle(nodes,  getRandom());  nodes  =  nodes.subList(0,  numNodes);  	List<DiscoveryNode>  nodes  =  new  ArrayList<>();  
libgdx_04c6d4b40ba09830ae9cfc756bf49af430a4db19	buggy:  gui  =  TwlRenderer.createGUI(layout,  Gdx.files.getFileHandle( "data/widgets.xml ",  FileType.Internal));  context:  if  (gui  !=  null)  return;  Button  button  =  new  Button( "Click  Me ");  FPSCounter  fpsCounter  =  new  FPSCounter(4,  2);  DialogLayout  layout  =  new  DialogLayout();  layout.setTheme( " ");  layout.setHorizontalGroup(layout.createParallelGroup().addWidgets(button,  fpsCounter));  layout.setVerticalGroup(layout.createSequentialGroup().addWidget(button).addGap(5).addWidget(fpsCounter).addGap(5));  gui  =  TwlRenderer.createGUI(layout,  Gdx.files.getFileHandle( "data/widgets.xml ",  FileType.Internal));  gui  =  TwlRenderer.createGUI(layout,   "data/widgets.xml ",  FileType.Internal);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  gui.update();  }  public  void  surfaceChanged  (int  width,  int  height)  {  	gui  =  TwlRenderer.createGUI(layout,   "data/widgets.xml ",  FileType.Internal);  
elasticsearch_2f1aba962c69b067e3ad7d4098df325bf90d1e05	buggy:  logger.warn( "failed  to  set  [{}],  wrong  format  [{}] ",  IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS,  autoExpandReplicas);  context:  int  max;  try  {  min  =  Integer.parseInt(autoExpandReplicas.substring(0,  autoExpandReplicas.indexOf('-')));  String  sMax  =  autoExpandReplicas.substring(autoExpandReplicas.indexOf('-')  +  1);  if  (sMax.equals( "all "))  {  max  =  event.state().nodes().dataNodes().size()  -  1;  }  else  {  max  =  Integer.parseInt(sMax);  }  }  catch  (Exception  e)  {                          logger.warn( "failed  to  set  [{}],  wrong  format  [{}] ",  IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS,  autoExpandReplicas);                          logger.warn( "failed  to  set  [{}],  wrong  format  [{}] ",  e,  IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS,  autoExpandReplicas);  continue;  }  if  (numberOfReplicas  ==  indexMetaData.numberOfReplicas())  {  continue;  }  	logger.warn( "failed  to  set  [{}],  wrong  format  [{}] ",  e,  IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS,  autoExpandReplicas);  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  FuzzyLikeThisQuery  query  =  new  FuzzyLikeThisQuery(maxNumTerms,  analyzer);  query.addTerms(likeText,  fieldName,  minSimilarity,  prefixLength);  query.setBoost(boost);  query.setIgnoreTF(ignoreTF);  token  =  parser.nextToken();  assert  token  ==  XContentParser.Token.END_OBJECT;          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
libgdx_a3a87f5b108bf3e0f3141eb1649475a2b214e18c	buggy:  return  (float)Math.atan2(crs(reference),  dot(reference))  *  MathUtils.radiansToDegrees;  context:  }  public  float  angleRad  ()  {  return  (float)Math.atan2(y,  x);  }  public  float  angleRad(Vector  reference)  {  return  (float)Math.atan2(crs(reference),  dot(reference))  *  MathUtils.radiansToDegrees;  return  (float)Math.atan2(crs(reference),  dot(reference));  }  public  Vector2  setAngle  (float  degrees)  {  return  setAngleRad(degrees  *  MathUtils.degreesToRadians);  }  	return  (float)Math.atan2(crs(reference),  dot(reference));  
elasticsearch_57169d42334d39659bfcd8db2b062c7f6001a668	buggy:  return  new  RecoveryStatus.Index(version,  filesMetaDatas.size(),  new  ByteSizeValue(totalSize,  ByteSizeUnit.BYTES),  TimeValue.timeValueMillis(throttlingWaitTime.get()));  context:  long  version  =  -1;  try  {  if  (IndexReader.indexExists(store.directory()))  {  version  =  IndexReader.getCurrentVersion(store.directory());  }  }  catch  (IOException  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "Failed  to  fetch  index  version  after  copying  it  over ",  e);  }          return  new  RecoveryStatus.Index(version,  filesMetaDatas.size(),  new  ByteSizeValue(totalSize,  ByteSizeUnit.BYTES),  TimeValue.timeValueMillis(throttlingWaitTime.get()));          return  new  RecoveryStatus.Index(version,  filesMetaDatas.size(),  new  ByteSizeValue(totalSize),  0,  new  ByteSizeValue(0),  TimeValue.timeValueMillis(throttlingWaitTime.get()));  }  private  RecoveryStatus.Translog  recoverTranslog()  throws  IndexShardGatewayRecoveryException  {  final  Map<String,  StorageMetadata>  allMetaDatas  =  listAllMetadatas(container,  shardTranslogDirectory);  long  latestTranslogId  =  -1;  for  (String  name  :  allMetaDatas.keySet())  {  String  translogName  =  name.substring(shardTranslogDirectory.length()  +  1);  	return  new  RecoveryStatus.Index(version,  filesMetaDatas.size(),  new  ByteSizeValue(totalSize),  0,  new  ByteSizeValue(0),  TimeValue.timeValueMillis(throttlingWaitTime.get()));  
elasticsearch_9a2d27a03574446e7a2554848d6b28eeb7e48a06	buggy:  builder.field( "prefix_length ",  prefixLength);  context:  if  (maxEdits  !=  null)  {  builder.field( "max_edits ",  maxEdits);  }  if  (maxInspections  !=  null)  {  builder.field( "max_inspections ",  maxInspections);  }  if  (maxTermFreq  !=  null)  {  builder.field( "max_term_freq ",  maxTermFreq);  }  if  (prefixLength  !=  null)  {              builder.field( "prefix_length ",  prefixLength);              builder.field( "prefix_len ",  prefixLength);  }  if  (minWordLength  !=  null)  {  builder.field( "min_word_len ",  minWordLength);  }  if  (minDocFreq  !=  null)  {  builder.field( "min_doc_freq ",  minDocFreq);  }  return  builder;  	builder.field( "prefix_len ",  prefixLength);  
libgdx_d968cf678325dbc2ffe2b48e32e6d6b9ebccdcef	buggy:  animTime  +=  Gdx.graphics.getDeltaTime();  context:  }  if  (texture  !=  null)  {  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  Gdx.gl.glEnable(GL10.GL_BLEND);  Gdx.gl.glBlendFunc(GL10.GL_SRC_ALPHA,  GL10.GL_ONE_MINUS_SRC_ALPHA);  }  angle  +=  45  *  Gdx.graphics.getDeltaTime();  Gdx.gl10.glRotatef(angle,  0,  1,  0);  animTime  +=  Gdx.graphics.getDeltaTime();  animTime  +=  Gdx.graphics.getDeltaTime()  /  10;  if  (animTime  >  anim.totalDuration)  {  animTime  =  0;  }  model.setAnimation(anim.name,  animTime,  false);  model.render();  if  (texture  !=  null)  {  Gdx.gl.glDisable(GL10.GL_TEXTURE_2D);  	animTime  +=  Gdx.graphics.getDeltaTime()  /  10;  
elasticsearch_e639ffbc935b00b3d017931022548382676f92bf	buggy:  return  new  ParsedQuery(query,  parseContext.copyNamedFilters(),  parseContext.copyScopePhases());  context:  public  Query  parseInnerQuery(XContentParser  parser)  throws  IOException  {  QueryParseContext  context  =  cache.get().get();  context.reset(parser);  return  context.parseInnerQuery();  }  private  ParsedQuery  parse(QueryParseContext  parseContext,  XContentParser  parser)  throws  IOException,  QueryParsingException  {  parseContext.reset(parser);  Query  query  =  parseContext.parseInnerQuery();          return  new  ParsedQuery(query,  parseContext.copyNamedFilters(),  parseContext.copyScopePhases());          return  new  ParsedQuery(query,  parseContext.copyNamedFilters());  }  private  void  add(Map<String,  XContentFilterParser>  map,  XContentFilterParser  filterParser)  {  for  (String  name  :  filterParser.names())  {  map.put(name.intern(),  filterParser);  }  }  	return  new  ParsedQuery(query,  parseContext.copyNamedFilters());  
elasticsearch_53935f078a73c828be301a2c850e139ba9c2a8c9	buggy:  List<StringEntry>  ordered  =  new  ArrayList<StringEntry>();  context:  }  if  (requiredSize  ==  0)  {  //  all  terms  StringEntry[]  entries1  =  map.values().toArray(new  StringEntry[map.size()]);  Arrays.sort(entries1,  comparatorType.comparator());  return  new  InternalTermsStatsStringFacet(name,  comparatorType,  requiredSize,  Arrays.asList(entries1),  missing);  }  else  {  Object[]  values  =  map.internalValues();  Arrays.sort(values,  (Comparator)  comparatorType.comparator());              List<StringEntry>  ordered  =  new  ArrayList<StringEntry>();              List<StringEntry>  ordered  =  new  ArrayList<StringEntry>(map.size());  for  (int  i  =  0;  i  <  requiredSize;  i++)  {  StringEntry  value  =  (StringEntry)  values[i];  if  (value  ==  null)  {  break;  }  ordered.add(value);  }  return  new  InternalTermsStatsStringFacet(name,  comparatorType,  requiredSize,  ordered,  missing);  	List<StringEntry>  ordered  =  new  ArrayList<StringEntry>(map.size());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  values  =  new  ArrayList<Object>(size);  context:  public  static  GetField  readGetField(StreamInput  in)  throws  IOException  {  GetField  result  =  new  GetField();  result.readFrom(in);  return  result;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  name  =  in.readString();  int  size  =  in.readVInt();          values  =  new  ArrayList<Object>(size);          values  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  values.add(in.readGenericValue());  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeString(name);  	values  =  new  ArrayList<>(size);  
libgdx_5ac0dcd1b04e38a3dbe11a94897cc0a34ef2d5ec	buggy:  public  void  log  (String  tag,  String  message,  Exception  exception);  context:  public  Files  getFiles  ();  public  Net  getNet  ();  public  void  log  (String  tag,  String  message);  public  void  log  (String  tag,  String  message,  Exception  exception);  public  void  log  (String  tag,  String  message,  Throwable  exception);  public  void  error  (String  tag,  String  message);  public  void  error  (String  tag,  String  message,  Throwable  exception);  	public  void  log  (String  tag,  String  message,  Throwable  exception);  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  DoubleArrayAtomicFieldData.Single(new  double[0],  0);  context:  }  }  }  public  DoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  DoubleArrayAtomicFieldData.Single(new  double[0],  0);              return  new  DoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  0,  new  FixedBitSet(1));  }  final  TDoubleArrayList  values  =  new  TDoubleArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  DoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  0,  new  FixedBitSet(1));  
elasticsearch_723d2e8b153cbcf94ff3b63fe87915b8465fbb97	buggy:  context.lookup().setNextDocId(docId);  context:  }  hitField.values().add(value);  }  int  readerIndex  =  context.searcher().readerIndex(docId);  IndexReader  subReader  =  context.searcher().subReaders()[readerIndex];  int  subDoc  =  docId  -  context.searcher().docStarts()[readerIndex];  context.lookup().setNextReader(subReader);              context.lookup().setNextDocId(docId);              context.lookup().setNextDocId(subDoc);  if  (extractFieldNames  !=  null)  {  for  (String  extractFieldName  :  extractFieldNames)  {  Object  value  =  context.lookup().source().extractValue(extractFieldName);  if  (value  !=  null)  {  if  (searchHit.fieldsOrNull()  ==  null)  {  searchHit.fields(new  HashMap<String,  SearchHitField>(2));  }  	context.lookup().setNextDocId(subDoc);  
libgdx_3dbb63b7f29cca9795e10d9d5bde0d95cf132491	buggy:  if  (type  ==  FileType.Classpath  ||  (type  ==  FileType.Internal  &&  !file.exists()))  {  context:  public  File  file  ()  {  if  (type  ==  FileType.External)  return  new  File(Gdx.files.getExternalStoragePath(),  file.getPath());  return  file;  }  public  InputStream  read  ()  {  if  (type  ==  FileType.Classpath  ||  (type  ==  FileType.Internal  &&  !file.exists()))  {  if  (type  ==  FileType.Classpath  ||  (type  ==  FileType.Internal  &&  !file.exists())  ||  (type  ==  FileType.Local  &&  !file.exists()))  {  InputStream  input  =  FileHandle.class.getResourceAsStream( "/ "  +  file.getPath().replace('\\',  '/'));  if  (input  ==  null)  throw  new  GdxRuntimeException( "File  not  found:   "  +  file  +   "  ( "  +  type  +   ") ");  return  input;  }  try  {  return  new  FileInputStream(file());  }  catch  (Exception  ex)  {  if  (file().isDirectory())  	if  (type  ==  FileType.Classpath  ||  (type  ==  FileType.Internal  &&  !file.exists())  ||  (type  ==  FileType.Local  &&  !file.exists()))  {  
libgdx_cb42e3df8e1782c3946fcecf0554172dde98dd30	buggy:  gui.setSize();  context:  }  });  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  gui.update();  }  public  void  surfaceChanged  (int  width,  int  height)  {  gui.setSize();  TwlRenderer.updateSize(gui);  }  public  void  dispose  ()  {  gui.destroy();  }  }  	TwlRenderer.updateSize(gui);  
elasticsearch_e222d38b84c9add6d34141f47c9d85cae33572a7	buggy:  long  collectionTime  =  currentJvmStats.gcCollectionTime().millis()  -  lastJvmStats.gcCollectionTime().millis();  context:  public  JvmMonitor()  {  }  monitorDeadlock();  monitorLongGc();  }  private  void  monitorLongGc()  {  JvmStats  currentJvmStats  =  jvmStats();              long  collectionTime  =  currentJvmStats.gcCollectionTime().millis()  -  lastJvmStats.gcCollectionTime().millis();              long  collectionTime  =  currentJvmStats.gc().collectionTime().millis()  -  lastJvmStats.gc().collectionTime().millis();  if  (collectionTime  >  gcCollectionWarning.millis())  {  }  lastJvmStats  =  currentJvmStats;  }  private  void  monitorDeadlock()  {  DeadlockAnalyzer.Deadlock[]  deadlocks  =  deadlockAnalyzer().findDeadlocks();  	long  collectionTime  =  currentJvmStats.gc().collectionTime().millis()  -  lastJvmStats.gc().collectionTime().millis();  
elasticsearch_e33dbcd93e3b1d0beac7e1629a790a28e5cab749	buggy:  return  new  FuzzyQuery(termFactory.createTerm(value),  (float)  minSim,  prefixLength,  maxExpansions);  context:  iSim  =  (long)  Double.parseDouble(minSim);  }  }  return  NumericRangeQuery.newLongRange(names.indexName(),  precisionStep,  iValue  -  iSim,  iValue  +  iSim,  true,  true);  }          return  new  FuzzyQuery(termFactory.createTerm(value),  (float)  minSim,  prefixLength,  maxExpansions);          return  new  FuzzyQuery(names().createIndexNameTerm(value),  (float)  minSim,  prefixLength,  maxExpansions);  }  return  NumericRangeQuery.newLongRange(names.indexName(),  precisionStep,  lowerTerm  ==  null  ?  null  :  ipToLong(lowerTerm),  upperTerm  ==  null  ?  null  :  ipToLong(upperTerm),  includeLower,  includeUpper);  }  	return  new  FuzzyQuery(names().createIndexNameTerm(value),  (float)  minSim,  prefixLength,  maxExpansions);  
libgdx_cfd67486c3b1b287313fcdf1261ea46a0091161c	buggy:  GdxTest  test  =  new  com.badlogic.gdx.tests.StbTrueTypeTest();  context:  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  com.badlogic.gdx.tests.StbTrueTypeTest();  GdxTest  test  =  new  com.badlogic.gdx.tests.ImmediateModeRendererTest();  JoglApplicationConfiguration  config  =  new  JoglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  JoglApplication(test,  config);  }  }  	GdxTest  test  =  new  com.badlogic.gdx.tests.ImmediateModeRendererTest();  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_90da268237525dcc89d2e09a3f77b5a3262cf6f7	buggy:  float  boost  =  context.fieldBoost(this);  context:  }  protected  boolean  customBoost()  {  return  true;  }  protected  void  innerParseCreateField(ParseContext  context,  List<Field>  fields)  throws  IOException  {  long  value;          float  boost  =  context.fieldBoost(this);          float  boost  =  this.boost;  if  (context.externalValueSet())  {  Object  externalValue  =  context.externalValue();  if  (externalValue  ==  null)  {  if  (nullValue  ==  null)  {  return;  }  value  =  nullValue;  }  else  if  (externalValue  instanceof  String)  {  	float  boost  =  this.boost;  
elasticsearch_25bd9cecd066e7920776eef0885b1c4a905a3156	buggy:  if  (!response.getShardFailures().isEmpty())  {  context:  return  Long.parseLong(ifMatch);  }  return  0;  }  public  static  void  buildBroadcastShardsHeader(XContentBuilder  builder,  BroadcastOperationResponse  response)  throws  IOException  {  builder.startObject( "_shards ");  builder.field( "total ",  response.getTotalShards());  builder.field( "successful ",  response.getSuccessfulShards());  builder.field( "failed ",  response.getFailedShards());          if  (!response.getShardFailures().isEmpty())  {          if  (response.getShardFailures()!=null  &&  response.getShardFailures().length>0)  {  builder.startArray( "failures ");  for  (ShardOperationFailedException  shardFailure  :  response.getShardFailures())  {  builder.startObject();  if  (shardFailure.index()  !=  null)  {  builder.field( "index ",  shardFailure.index(),  XContentBuilder.FieldCaseConversion.NONE);  }  if  (shardFailure.shardId()  !=  -1)  {  builder.field( "shard ",  shardFailure.shardId());  	if  (response.getShardFailures()!=null  &&  response.getShardFailures().length>0)  {  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  return  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  null);  context:  public  Settings  indexSettings()  {  return  this.indexSettings;  }  public  Version  indexCreatedVersion()  {  if  (indexSettings  ==  null)  {  return  null;  }              return  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  null);              return  Version.indexCreated(indexSettings);  }  }  public  static  abstract  class  Builder<T  extends  Builder,  Y  extends  Mapper>  {  public  String  name;  protected  T  builder;  	return  Version.indexCreated(indexSettings);  
elasticsearch_15bdba30e5901361a0408d8e8b4068bef66169ec	buggy:  if  (propName.equals( "nullValue "))  {  context:  public  static  class  TypeParser  implements  JsonTypeParser  {  ObjectNode  dateNode  =  (ObjectNode)  node;  JsonDateFieldMapper.Builder  builder  =  dateField(name);  parseNumberField(builder,  name,  dateNode,  parserContext);  for  (Iterator<Map.Entry<String,  JsonNode>>  propsIt  =  dateNode.getFields();  propsIt.hasNext();)  {  Map.Entry<String,  JsonNode>  entry  =  propsIt.next();  String  propName  =  entry.getKey();  JsonNode  propNode  =  entry.getValue();                  if  (propName.equals( "nullValue "))  {                  if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  builder.nullValue(propNode.getValueAsText());  }  else  if  (propName.equals( "format "))  {  builder.dateTimeFormatter(parseDateTimeFormatter(propName,  propNode));  }  }  return  builder;  }  }  	if  (propName.equals( "nullValue ")  ||  propName.equals( "null_value "))  {  
elasticsearch_79368bb221253a94adabe96d2420845f918e3791	buggy:  document.add(new  StoredField( "_source ",  source));  context:  }  public  void  binaryField(FieldInfo  fieldInfo,  byte[]  value)  throws  IOException  {  source  =  new  BytesRef(value);  }  public  Document  createDocument()  {  Document  document  =  new  Document();          document.add(new  StoredField( "_source ",  source));          document.add(new  StoredField(SourceFieldMapper.NAME,  source));  return  document;  }  public  BytesRef  source()  {  return  source;  }  	document.add(new  StoredField(SourceFieldMapper.NAME,  source));  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  if  (request.hasParam( "ignore_indices "))  {  optimizeRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }  try  {  optimizeRequest.waitForMerge(request.paramAsBoolean( "wait_for_merge ",  optimizeRequest.waitForMerge()));  optimizeRequest.maxNumSegments(request.paramAsInt( "max_num_segments ",  optimizeRequest.maxNumSegments()));  optimizeRequest.onlyExpungeDeletes(request.paramAsBoolean( "only_expunge_deletes ",  optimizeRequest.onlyExpungeDeletes()));  optimizeRequest.flush(request.paramAsBoolean( "flush ",  optimizeRequest.flush()));  optimizeRequest.refresh(request.paramAsBoolean( "refresh ",  optimizeRequest.refresh()));              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  optimizeRequest.operationThreading(operationThreading);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_911ef6a058acf16b9605db3f0bb680df4ba30834	buggy:  iterateAssertCount(5,  indexCounter.get(),  10);  context:  stopLatch.await();  allowNodes( "test ",  3);  assertAcked(client().admin().indices().prepareUpdateSettings( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "number_of_replicas ",  1)).get());  assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "1m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));  refreshAndAssert();          iterateAssertCount(5,  indexCounter.get(),  10);          iterateAssertCount(numShards,  indexCounter.get(),  10);  }  private  void  iterateAssertCount(final  int  numberOfShards,  final  long  numberOfDocs,  final  int  iterations)  throws  Exception  {  SearchResponse[]  iterationResults  =  new  SearchResponse[iterations];  boolean  error  =  false;  for  (int  i  =  0;  i  <  iterations;  i++)  {  SearchResponse  searchResponse  =  client().prepareSearch().setSearchType(SearchType.COUNT).setQuery(matchAllQuery()).get();  logSearchResponse(numberOfShards,  numberOfDocs,  i,  searchResponse);  	iterateAssertCount(numShards,  indexCounter.get(),  10);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(20);  context:  .startObject( "field1 ").field( "type ",   "string ").field( "index_options ",   "offsets ").field( "term_vector ",   "with_positions_offsets ").endObject()  .startObject( "field2 ").field( "type ",   "string ").field( "index_options ",   "offsets ").field( "term_vector ",   "with_positions_offsets ").endObject()  .endObject()  .endObject().endObject();  assertAcked(prepareCreate( "test ").addMapping( "type1 ",  mapping));  ensureGreen();  client().prepareIndex( "test ",   "type1 ")  .setSource( "field1 ",   "The  quick  brown  fox  jumps  over ",   "field2 ",   "The  quick  brown  fox  jumps  over ").get();  refresh();          final  int  iters  =  atLeast(20);          final  int  iters  =  scaledRandomIntBetween(20,  30);  for  (int  i  =  0;  i  <  iters;  i++)  {  MultiMatchQueryBuilder.Type  matchQueryType  =  rarely()  ?  null  :  RandomPicks.randomFrom(getRandom(),  MultiMatchQueryBuilder.Type.values());  final  MultiMatchQueryBuilder  multiMatchQueryBuilder  =  multiMatchQuery( "the  quick  brown  fox ",   "field1 ",   "field2 ").type(matchQueryType);  String  type  =  rarely()  ?  null  :  RandomPicks.randomFrom(getRandom(),highlighterTypes);  SearchSourceBuilder  source  =  searchSource()  .query(multiMatchQueryBuilder)  .highlight(highlight().highlightQuery(randomBoolean()  ?  multiMatchQueryBuilder  :  null).highlighterType(type)  .field(new  Field( "field1 ").requireFieldMatch(true).preTags( "<field1> ").postTags( "</field1> ")));  	final  int  iters  =  scaledRandomIntBetween(20,  30);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  onValue(docId,  value,  values.currentValueHash(),  values);  context:  public  HashedAggregator()  {  hash  =  new  BytesRefHashHashCount(new  BytesRefHash(10,  BigArrays.NON_RECYCLING_INSTANCE));  }  public  void  onDoc(int  docId,  BytesValues  values)  {  final  int  length  =  values.setDocument(docId);  int  pendingMissing  =  1;  total  +=  length;  for  (int  i  =  0;  i  <  length;  i++)  {  final  BytesRef  value  =  values.nextValue();              onValue(docId,  value,  values.currentValueHash(),  values);              onValue(docId,  value,  value.hashCode(),  values);  pendingMissing  =  0;  }  missing  +=  pendingMissing;  }  public  void  addValue(BytesRef  value,  int  hashCode,  BytesValues  values)  {  final  boolean  added  =  hash.addNoCount(value,  hashCode,  values);  assert  assertHash.addNoCount(value,  hashCode,  values)  ==  added  :   "asserting  counter  diverged  from  current  counter  -  value:   "  	onValue(docId,  value,  value.hashCode(),  values);  
elasticsearch_7f943f0296b6fe4e0b448f358da3e3ab761eac85	buggy:  final  InternalAggregations  aggs  =  InternalAggregations.reduce(subAggregationsList,  reduceContext.bigArrays());  context:  public  InternalAggregation  reduce(ReduceContext  reduceContext)  {  List<InternalAggregation>  aggregations  =  reduceContext.aggregations();  long  docCount  =  0L;  List<InternalAggregations>  subAggregationsList  =  new  ArrayList<>(aggregations.size());  for  (InternalAggregation  aggregation  :  aggregations)  {  assert  aggregation.getName().equals(getName());  docCount  +=  ((InternalSingleBucketAggregation)  aggregation).docCount;  subAggregationsList.add(((InternalSingleBucketAggregation)  aggregation).aggregations);  }          final  InternalAggregations  aggs  =  InternalAggregations.reduce(subAggregationsList,  reduceContext.bigArrays());          final  InternalAggregations  aggs  =  InternalAggregations.reduce(subAggregationsList,  reduceContext);  return  newAggregation(getName(),  docCount,  aggs);  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  name  =  in.readString();  docCount  =  in.readVLong();  aggregations  =  InternalAggregations.readAggregations(in);  	final  InternalAggregations  aggs  =  InternalAggregations.reduce(subAggregationsList,  reduceContext);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  ThreadPool  threadPool,  MetaDataMappingService  metaDataMappingService,  TransportDeleteByQueryAction  deleteByQueryAction,  TransportRefreshAction  refreshAction)  {  super(settings,  transportService,  clusterService,  threadPool);  this.metaDataMappingService  =  metaDataMappingService;  this.deleteByQueryAction  =  deleteByQueryAction;  this.refreshAction  =  refreshAction;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.Mapping.DELETE;  }  return  new  DeleteMappingRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_b11f81d744a5c23bf7c20d696939e226905c60e7	buggy:  return  zeroTermsQuery  ==  ZeroTermsQuery.NONE  ?  MatchNoDocsQuery.INSTANCE  :  Queries.MATCH_ALL_QUERY;  context:  return  new  TermQuery(term);  }  private  static  BytesRef  termToByteRef(CharTermAttribute  attr)  {  final  BytesRef  ref  =  new  BytesRef();  UnicodeUtil.UTF16toUTF8(attr.buffer(),  0,  attr.length(),  ref);  return  ref;  }  protected  Query  zeroTermsQuery()  {          return  zeroTermsQuery  ==  ZeroTermsQuery.NONE  ?  MatchNoDocsQuery.INSTANCE  :  Queries.MATCH_ALL_QUERY;          return  zeroTermsQuery  ==  ZeroTermsQuery.NONE  ?  MatchNoDocsQuery.INSTANCE  :  Queries.newMatchAllQuery();  }  }  	return  zeroTermsQuery  ==  ZeroTermsQuery.NONE  ?  MatchNoDocsQuery.INSTANCE  :  Queries.newMatchAllQuery();  
elasticsearch_ba1042e7d19b2d197c7c9f449f97d2edf1b1ed91	buggy:  topDocsCollector  =  sort  !=  null  ?  TopFieldCollector.create(sort,  topN,  true,  topHitsContext.trackScores(),  true,  false)  :  TopScoreDocCollector.create(topN,  false)  context:  }  public  void  collect(int  docId,  long  bucketOrdinal)  throws  IOException  {  TopDocsCollector  topDocsCollector  =  topDocsCollectors.get(bucketOrdinal);  if  (topDocsCollector  ==  null)  {  Sort  sort  =  topHitsContext.sort();  int  topN  =  topHitsContext.from()  +  topHitsContext.size();  topDocsCollectors.put(  bucketOrdinal,                      topDocsCollector  =  sort  !=  null  ?  TopFieldCollector.create(sort,  topN,  true,  topHitsContext.trackScores(),  true,  false)  :  TopScoreDocCollector.create(topN,  false)                      topDocsCollector  =  sort  !=  null  ?  TopFieldCollector.create(sort,  topN,  true,  topHitsContext.trackScores(),  topHitsContext.trackScores(),  false)  :  TopScoreDocCollector.create(topN,  false)  );  topDocsCollector.setNextReader(currentContext);  topDocsCollector.setScorer(currentScorer);  }  topDocsCollector.collect(docId);  }  	topDocsCollector  =  sort  !=  null  ?  TopFieldCollector.create(sort,  topN,  true,  topHitsContext.trackScores(),  topHitsContext.trackScores(),  false)  :  TopScoreDocCollector.create(topN,  false)  
elasticsearch_df4f4f056a7024ffe6907d190c0fbbc2d622cee5	buggy:  if  (gc.lastGc()  !=  null)  {  context:  monitorLongGc();  }  private  void  monitorLongGc()  {  JvmStats  currentJvmStats  =  jvmStats();  for  (int  i  =  0;  i  <  currentJvmStats.gc().collectors().length;  i++)  {  GarbageCollector  gc  =  currentJvmStats.gc().collectors()[i];                  if  (gc.lastGc()  !=  null)  {                  if  (gc.lastGc()  !=  null  &&  lastJvmStats.gc.collectors()[i].lastGc()  !=  null)  {  GarbageCollector.LastGc  lastGc  =  gc.lastGc();  if  (lastGc.startTime  ==  lastJvmStats.gc.collectors()[i].lastGc().startTime())  {  continue;  }  if  (lastGc.duration().millis()  >  gcThreshold.millis())  {  }  else  if  (logger.isDebugEnabled())  {  	if  (gc.lastGc()  !=  null  &&  lastJvmStats.gc.collectors()[i].lastGc()  !=  null)  {  
libgdx_9b524508612276c8f9a92c97e261fb1f0da219f9	buggy:  new  JoglApplication(new  KeyframedModelViewer( "data/knight.md2 ",   "data/knight.jpg "),   "KeframedModel  Viewer ",  800,  480,  false);  context:  public  void  pause  ()  {  }  public  void  dispose  ()  {  }  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  KeyframedModelViewer( "data/knight.md2 ",   "data/knight.jpg "),   "KeframedModel  Viewer ",  800,  480,  false);  new  JoglApplication(new  KeyframedModelViewer( "data/models/knight.md2 ",   "data/models/knight.jpg "),   "KeframedModel  Viewer ",  800,  480,  false);  }  }  	new  JoglApplication(new  KeyframedModelViewer( "data/models/knight.md2 ",   "data/models/knight.jpg "),   "KeframedModel  Viewer ",  800,  480,  false);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  payloads  =  new  ArrayList<Object>(requests.size()  +  10);  context:  addPayload(payload);  sizeInBytes  +=  REQUEST_OVERHEAD;  return  this;  }  private  void  addPayload(Object  payload)  {  if  (payloads  ==  null)  {  if  (payload  ==  null)  {  return;  }              payloads  =  new  ArrayList<Object>(requests.size()  +  10);              payloads  =  new  ArrayList<>(requests.size()  +  10);  for  (int  i  =  1;  i  <  requests.size();  i++)  {  payloads.add(null);  }  }  payloads.add(payload);  }  	payloads  =  new  ArrayList<>(requests.size()  +  10);  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  3,  0,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(  context:  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true);  spriteBatch.end();  }  }  if  (mesh  ==  null)  {  mesh  =  new  Mesh(true,  false,  3,  0,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(  mesh  =  new  Mesh(true,  3,  0,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(  Usage.ColorPacked,  4,   "a_Color "),  new  VertexAttribute(Usage.TextureCoordinates,  2,   "a_texCoords "));  float  c1  =  Color.toFloatBits(255,  0,  0,  255);  float  c2  =  Color.toFloatBits(255,  0,  0,  255);  ;  float  c3  =  Color.toFloatBits(0,  0,  255,  255);  ;  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  c1,  0,  0,  0.5f,  -0.5f,  0,  c2,  1,  0,  0,  0.5f,  0,  c3,  0.5f,  1});  	mesh  =  new  Mesh(true,  3,  0,  new  VertexAttribute(Usage.Position,  3,   "a_Position "),  new  VertexAttribute(  
elasticsearch_5ae12368574b33a8fad215ef104108fbf5435eb3	buggy:  return  sums.get(owningBucketOrd);  context:  final  int  valuesCount  =  values.setDocument(doc);  double  sum  =  0;  for  (int  i  =  0;  i  <  valuesCount;  i++)  {  sum  +=  values.nextValue();  }  sums.increment(owningBucketOrdinal,  sum);  }  public  double  metric(long  owningBucketOrd)  {          return  sums.get(owningBucketOrd);          return  valuesSource  ==  null  ?  0  :  sums.get(owningBucketOrd);  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  if  (valuesSource  ==  null)  {  return  new  InternalSum(name,  0);  }  return  new  InternalSum(name,  sums.get(owningBucketOrdinal));  	return  valuesSource  ==  null  ?  0  :  sums.get(owningBucketOrd);  
elasticsearch_644fdfc4aad4065375dce5098746a7e0e36c1646	buggy:  return  new  JtsGeometry(geometry,  SPATIAL_CONTEXT,  true);  context:  geometry  =  FACTORY.createMultiLineString(lineStrings);  }  }  else  {  LineString[]  lineStrings  =  new  LineString[lines.size()];  Iterator<BaseLineStringBuilder<?>>  iterator  =  lines.iterator();  for  (int  i  =  0;  iterator.hasNext();  i++)  {  lineStrings[i]  =  FACTORY.createLineString(iterator.next().coordinates(false));  }  geometry  =  FACTORY.createMultiLineString(lineStrings);  }          return  new  JtsGeometry(geometry,  SPATIAL_CONTEXT,  true);          return  jtsGeometry(geometry);  }  public  static  class  InternalLineStringBuilder  extends  BaseLineStringBuilder<InternalLineStringBuilder>  {  private  final  MultiLineStringBuilder  collection;  public  InternalLineStringBuilder(MultiLineStringBuilder  collection)  {  super();  	return  jtsGeometry(geometry);  
elasticsearch_342563a864c659ba9a2d5a4db2f8b7d13f55666e	buggy:  logger.warn( "[{}]:  failed  to  state ",  lastFailure,  indexMetaData.index());  context:  fos.close();  wroteAtLeastOnce  =  true;  }  catch  (Throwable  e)  {  lastFailure  =  e;  }  finally  {  IOUtils.closeWhileHandlingException(fos);  }  }  if  (!wroteAtLeastOnce)  {              logger.warn( "[{}]:  failed  to  state ",  lastFailure,  indexMetaData.index());              logger.warn( "[{}]:  failed  to  write  index  state ",  lastFailure,  indexMetaData.index());  throw  new  IOException( "failed  to  write  state  for  [ "  +  indexMetaData.index()  +   "] ",  lastFailure);  }  if  (previousIndexMetaData  !=  null  &&  previousIndexMetaData.version()  !=  indexMetaData.version())  {  for  (File  indexLocation  :  nodeEnv.indexLocations(new  Index(indexMetaData.index())))  {  File[]  files  =  new  File(indexLocation,   "_state ").listFiles();  if  (files  ==  null)  {  	logger.warn( "[{}]:  failed  to  write  index  state ",  lastFailure,  indexMetaData.index());  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  .ignoreIndices(request.ignoreIndices())  context:  protected  ClusterBlockException  checkBlock(RestoreSnapshotRequest  request,  ClusterState  state)  {  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,   " ");  }  protected  void  masterOperation(final  RestoreSnapshotRequest  request,  ClusterState  state,  final  ActionListener<RestoreSnapshotResponse>  listener)  throws  ElasticSearchException  {  RestoreService.RestoreRequest  restoreRequest  =  new  RestoreService.RestoreRequest( "restore_snapshot[ "  +  request.snapshot()  +   "] ",  request.repository(),  request.snapshot())  .indices(request.indices())                          .ignoreIndices(request.ignoreIndices())                          .indicesOptions(request.indicesOptions())  .renamePattern(request.renamePattern())  .renameReplacement(request.renameReplacement())  .includeGlobalState(request.includeGlobalState())  .settings(request.settings())  .masterNodeTimeout(request.masterNodeTimeout());  restoreService.restoreSnapshot(restoreRequest,  new  RestoreSnapshotListener()  {  public  void  onResponse(RestoreInfo  restoreInfo)  {  	.indicesOptions(request.indicesOptions())  
elasticsearch_4723c2a2ee264390227a089c59d1930469d8b5e5	buggy:  buckets.add(new  SignificantLongTerms.Bucket(1,  2,  3,  4,  123,  InternalAggregations.EMPTY));  context:  }  else  {  assertTrue(sigTerms[1].significanceHeuristic  instanceof  JLHScore);  }  }  InternalSignificantTerms[]  getRandomSignificantTerms(SignificanceHeuristic  heuristic)  {  InternalSignificantTerms[]  sTerms  =  new  InternalSignificantTerms[2];  ArrayList<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<>();  if  (randomBoolean())  {  BytesRef  term  =  new  BytesRef( "123.0 ");              buckets.add(new  SignificantLongTerms.Bucket(1,  2,  3,  4,  123,  InternalAggregations.EMPTY));              buckets.add(new  SignificantLongTerms.Bucket(1,  2,  3,  4,  123,  InternalAggregations.EMPTY,  null));  sTerms[0]  =  new  SignificantLongTerms(10,  20,   "some_name ",  null,  1,  1,  heuristic,  buckets);  sTerms[1]  =  new  SignificantLongTerms();  }  else  {  BytesRef  term  =  new  BytesRef( "someterm ");  buckets.add(new  SignificantStringTerms.Bucket(term,  1,  2,  3,  4,  InternalAggregations.EMPTY));  sTerms[0]  =  new  SignificantStringTerms(10,  20,   "some_name ",  1,  1,  heuristic,  buckets);  sTerms[1]  =  new  SignificantStringTerms();  	buckets.add(new  SignificantLongTerms.Bucket(1,  2,  3,  4,  123,  InternalAggregations.EMPTY,  null));  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  final  class  CreateHandler  implements  RestHandler  {  request.params().put( "op_type ",   "create ");  RestIndexAction.this.handleRequest(request,  channel);  }  }  IndexRequest  indexRequest  =  new  IndexRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));          indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());          indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  indexRequest.timeout(request.paramAsTime( "timeout ",  IndexRequest.DEFAULT_TIMEOUT));  String  sOpType  =  request.param( "op_type ");  if  (sOpType  !=  null)  {  if  ( "index ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.INDEX);  }  else  if  ( "create ".equals(sOpType))  {  indexRequest.opType(IndexRequest.OpType.CREATE);  }  else  {  	indexRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  
libgdx_aa62a3f81989ac63555b8b8fc11f67e8bd27380b	buggy:  GdxTest  test  =  new  InputTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  GdxTest  test  =  new  InputTest();  GdxTest  test  =  new  FreeTypeTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.width  =  640;  config.height  =  640;  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  FreeTypeTest();  
libgdx_1c0785322058616aae1c7f0bc7a9ab63215e400b	buggy:  samples[offset  +  j]  =  (short)((buffer[i]  <<  8)  |  (buffer[i  +  1]  &  0xff));  context:  public  void  read  (short[]  samples,  int  offset,  int  numSamples)  {  if  (buffer.length  <  numSamples  *  2)  buffer  =  new  byte[numSamples  *  2];  int  toRead  =  numSamples  *  2;  int  read  =  0;  while  (read  !=  toRead)  read  +=  line.read(buffer,  read,  toRead  -  read);  for  (int  i  =  0,  j  =  0;  i  <  numSamples  *  2;  i  +=  2,  j++)  samples[offset  +  j]  =  (short)((buffer[i]  <<  8)  |  (buffer[i  +  1]  &  0xff));  samples[offset  +  j]  =  (short)((buffer[i  +  1]  <<  8)  |  (buffer[i]  &  0xff));  }  public  void  dispose  ()  {  line.close();  }  }  	samples[offset  +  j]  =  (short)((buffer[i  +  1]  <<  8)  |  (buffer[i]  &  0xff));  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(metaData.concreteSingleIndex(request.index()));  context:  protected  boolean  retryOnFailure(Throwable  e)  {  return  TransportActions.isShardNotAvailableException(e);  }  protected  boolean  resolveRequest(ClusterState  state,  UpdateRequest  request,  ActionListener<UpdateResponse>  listener)  {  MetaData  metaData  =  clusterService.state().metaData();  String  aliasOrIndex  =  request.index();  request.routing((metaData.resolveIndexRouting(request.routing(),  aliasOrIndex)));          request.index(metaData.concreteSingleIndex(request.index()));          request.index(metaData.concreteSingleIndex(request.index(),  request.indicesOptions()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  return  true;  }  	request.index(metaData.concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<Integer,  List<String>>  nrReplicasChanged  =  new  HashMap<Integer,  List<String>>();  context:  this.dynamicSettings  =  dynamicSettings;  }  public  void  clusterChanged(ClusterChangedEvent  event)  {  if  (!event.state().nodes().localNodeMaster())  {  return;  }          Map<Integer,  List<String>>  nrReplicasChanged  =  new  HashMap<Integer,  List<String>>();          Map<Integer,  List<String>>  nrReplicasChanged  =  new  HashMap<>();  for  (final  IndexMetaData  indexMetaData  :  event.state().metaData())  {  String  autoExpandReplicas  =  indexMetaData.settings().get(IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS);  if  (autoExpandReplicas  !=  null  &&  Booleans.parseBoolean(autoExpandReplicas,  true))  {  //  Booleans  only  work  for  false  values,  just  as  we  want  it  here  try  {  int  min;  int  max;  	Map<Integer,  List<String>>  nrReplicasChanged  =  new  HashMap<>();  
elasticsearch_012797a82c7ee448c12ae45b63e349b610494d6d	buggy:  return  ESLoggerFactory.getLogger(s);  context:  prefixesList.addAll(asList(prefixes));  }  return  getLogger(getLoggerName(loggerName),  prefixesList.toArray(new  String[prefixesList.size()]));  }  public  static  ESLogger  getLogger(ESLogger  parentLogger,  String  s)  {  return  ESLoggerFactory.getLogger(parentLogger.getPrefix(),  getLoggerName(parentLogger.getName()  +  s));  }  public  static  ESLogger  getLogger(String  s)  {          return  ESLoggerFactory.getLogger(s);          return  ESLoggerFactory.getLogger(getLoggerName(s));  }  public  static  ESLogger  getLogger(Class  clazz)  {  return  ESLoggerFactory.getLogger(getLoggerName(buildClassLoggerName(clazz)));  }  public  static  ESLogger  getLogger(Class  clazz,  String...  prefixes)  {  return  getLogger(buildClassLoggerName(clazz),  prefixes);  	return  ESLoggerFactory.getLogger(getLoggerName(s));  
elasticsearch_e5b829303eb508d32ca6b4edb5705dca7539a122	buggy:  String  name  =  buildNodeName();  context:  }  public  Set<String>  nRandomNodes(int  numNodes)  {  assert  numNodes()  >=  numNodes;  return  Sets.newHashSet(Iterators.limit(this.nodes.keySet().iterator(),  numNodes));  }  public  Client  nodeClient()  {  ensureOpen();  if  (clientNode  ==  null)  {              String  name  =  buildNodeName();              String  name  =   "client_ "  +  buildNodeName();  String  settingsSource  =  getClass().getName().replace('.',  '/')  +   ".yml ";  Settings  finalSettings  =  settingsBuilder().loadFromClasspath(settingsSource).put(defaultSettings).put( "node.client ",  true).put( "name ",  name)  .build();  Node  node  =  nodeBuilder().settings(finalSettings).build();  node.start();  this.clientNode  =  new  NodeAndClient(name,  node,  clientFactory);  }  	String  name  =   "client_ "  +  buildNodeName();  
elasticsearch_0b09fd0806364c0785fc649b6483f00fb8e8ebf4	buggy:  return  new  InternalRangeFacet(facetName,   "_na ",   "_na ",  entries);  context:  for  (RangeFacet.Entry  entry  :  entries)  {  if  (key  >=  entry.getFrom()  &&  key  <  entry.getTo())  {  entry.count++;  entry.total  +=  value;  }  }  }          return  new  InternalRangeFacet(facetName,   "_na ",   "_na ",  entries);          return  new  InternalRangeFacet(facetName,  entries);  }  }  	return  new  InternalRangeFacet(facetName,  entries);  
elasticsearch_de013babf847bdedf89bf9744d7a5ab1bb807b40	buggy:  return  new  FieldDataType( "string ");  context:  Lucene.KEYWORD_ANALYZER,  Lucene.KEYWORD_ANALYZER,  postingsFormat,  null);  }  public  FieldType  defaultFieldType()  {  return  Defaults.FIELD_TYPE;  }  public  org.elasticsearch.index.fielddata.FieldDataType  fieldDataType2()  {          return  new  FieldDataType( "string ");          return  new  FieldDataType( "string ",   "paged_bytes ");  }  protected  String  defaultPostingFormat()  {  return   "bloom_default ";  }  	return  new  FieldDataType( "string ",   "paged_bytes ");  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  this.mul(tmpMat.setToTranslation(position.tmp().mul(-1)));  context:  public  Matrix4  setToLookAt  (Vector3  position,  Vector3  target,  Vector3  up)  {  tmpVec.set(target).sub(position);  setToLookAt(tmpVec,  up);  this.mul(tmpMat.setToTranslation(position.tmp().mul(-1)));  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  return  this;  }  static  final  Vector3  right  =  new  Vector3();  static  final  Vector3  tmpForward  =  new  Vector3();  static  final  Vector3  tmpUp  =  new  Vector3();  	this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  protected  abstract  Map<String,  Set<String>>  resolveRouting(ClusterState  clusterState,  Request  request)  throws  ElasticsearchException;  protected  void  doExecute(final  Request  request,  final  ActionListener<Response>  listener)  {  ClusterState  clusterState  =  clusterService.state();  ClusterBlockException  blockException  =  checkGlobalBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  blockException  =  checkRequestBlock(clusterState,  request,  concreteIndices);  if  (blockException  !=  null)  {  throw  blockException;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  }  ClusterState  updatedState  =  ClusterState.builder().state(currentState).metaData(metaDataBuilder).routingTable(routingTableBuilder).blocks(blocks).build();  RoutingAllocation.Result  routingResult  =  allocationService.reroute(updatedState);  updatedState  =  newClusterStateBuilder().state(updatedState).routingResult(routingResult).build();  return  updatedState;                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  listener.onFailure(e);  return  currentState;  }  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  listener.onSuccess();  	}  catch  (Throwable  e)  {  
libgdx_6b2f1b83ffe9b397fc3378dc2dbe35c064649924	buggy:  textBounds.height  =  data.capHeight  -  data.descent  +  (numLines  -  1)  *  data.lineHeight;  context:  int  numLines  =  0;  int  length  =  str.length();  while  (start  <  length)  {  int  lineEnd  =  indexOf(str,  '\n',  start);  float  lineWidth  =  getBounds(str,  start,  lineEnd).width;  maxWidth  =  Math.max(maxWidth,  lineWidth);  start  =  lineEnd  +  1;  numLines++;  }  textBounds.width  =  maxWidth;  textBounds.height  =  data.capHeight  -  data.descent  +  (numLines  -  1)  *  data.lineHeight;  textBounds.height  =  data.capHeight  +  (numLines  -  1)  *  data.lineHeight;  return  textBounds;  }  public  TextBounds  getWrappedBounds  (CharSequence  str,  float  wrapWidth)  {  	textBounds.height  =  data.capHeight  +  (numLines  -  1)  *  data.lineHeight;  
elasticsearch_c55341bf515fec6d4135cee8a6e9a7a9764da17f	buggy:  fixedBitSetFilterCache.clear( "close ");  context:  public  QueryParserCache  queryParserCache()  {  return  this.queryParserCache;  }  public  void  close()  throws  ElasticsearchException  {  filterCache.close();  queryParserCache.close();  docSetCache.clear( "close ");          fixedBitSetFilterCache.clear( "close ");          fixedBitSetFilterCache.close();  if  (clusterService  !=  null)  {  clusterService.remove(this);  }  }  public  void  clear(String  reason)  {  filterCache.clear(reason);  queryParserCache.clear();  	fixedBitSetFilterCache.close();  
libgdx_e9a1dfe46d1f3d865715b2f4827908c7ba17e28e	buggy:  if  (isModal  &&  stage.getRoot().getChildren().peek()  ==  Dialog.this)  {  //  This  dialog  is  the  top  most  actor.  context:  public  void  keyboardFocusChanged  (FocusEvent  event,  Actor  actor,  boolean  focused)  {  if  (!focused)  focusChanged(event);  }  public  void  scrollFocusChanged  (FocusEvent  event,  Actor  actor,  boolean  focused)  {  if  (!focused)  focusChanged(event);  }  private  void  focusChanged  (FocusEvent  event)  {  Stage  stage  =  getStage();  if  (isModal  &&  stage.getRoot().getChildren().peek()  ==  Dialog.this)  {  //  This  dialog  is  the  top  most  actor.  if  (isModal  &&  stage  !=  null  &&  stage.getRoot().getChildren().peek()  ==  Dialog.this)  {  //  Dialog  is  top  most  actor.  Actor  newFocusedActor  =  event.getRelatedActor();  if  (newFocusedActor  ==  null  ||  !newFocusedActor.isDescendantOf(Dialog.this))  event.cancel();  }  }  });  }  public  Table  getContentTable  ()  {  	if  (isModal  &&  stage  !=  null  &&  stage.getRoot().getChildren().peek()  ==  Dialog.this)  {  //  Dialog  is  top  most  actor.  
elasticsearch_5db5b9f4b213f429f7c56ae445a117a3722f642c	buggy:  logger.debug( "Adding  {}/{} ",  nodeMetadata.getName(),  nodeMetadata.getPrivateAddresses());  context:  }  }  }  else  {  filteredByLocation  =  false;  }  if  (filteredByLocation)  {  continue;  }  if  (nodeMetadata.getState()  ==  NodeState.PENDING  ||  nodeMetadata.getState()  ==  NodeState.RUNNING)  {                  logger.debug( "Adding  {}/{} ",  nodeMetadata.getName(),  nodeMetadata.getPrivateAddresses());                  logger.debug( "Adding  {},  addresses  {} ",  nodeMetadata.getName(),  nodeMetadata.getPrivateAddresses());  for  (InetAddress  inetAddress  :  nodeMetadata.getPrivateAddresses())  {  for  (int  port  :  new  PortsRange(ports).ports())  {  discoNodes.add(new  DiscoveryNode( "#cloud- "  +  inetAddress.getHostAddress()  +   "- "  +  port,  new  InetSocketTransportAddress(inetAddress,  port)));  }  }  }  }  return  discoNodes;  	logger.debug( "Adding  {},  addresses  {} ",  nodeMetadata.getName(),  nodeMetadata.getPrivateAddresses());  
elasticsearch_fe52c5665fd70fb1d628cb8108947c74e543e615	buggy:  BytesStreamOutput  out  =  CachedStreamOutput.cachedBytes();  context:  public  class  BytesStreamsTests  {          BytesStreamOutput  out  =  CachedStreamOutput.cachedBytes();          BytesStreamOutput  out  =  CachedStreamOutput.popEntry().cachedBytes();  out.writeBoolean(false);  out.writeByte((byte)  1);  out.writeShort((short)  -1);  out.writeInt(-1);  out.writeVInt(2);  out.writeLong(-3);  out.writeVLong(4);  out.writeFloat(1.1f);  	BytesStreamOutput  out  =  CachedStreamOutput.popEntry().cachedBytes();  
libgdx_32c98da9f705b1881a0c7084fb0971f021c0ee32	buggy:  animation.duration  =  frames.length  *  0.2f;  context:  newVerts[idx++]  =  frame.vertices[vIdx.vIdx  *  3  +  1];  newVerts[idx++]  =  frame.vertices[vIdx.vIdx  *  3  +  2];  }  frame.vertices  =  newVerts;  }  header.numVertices  =  vertCombos.size();  KeyframedSubMesh  subMesh  =  new  KeyframedSubMesh();  KeyframedAnimation  animation  =  new  KeyframedAnimation();  animation.duration  =  frames.length  *  0.2f;  animation.totalDuration  =  frames.length  *  0.2f;  animation.keyframes  =  new  Keyframe[frames.length];  for  (int  frameNum  =  0;  frameNum  <  frames.length;  frameNum++)  {  MD2Frame  frame  =  frames[frameNum];  float[]  vertices  =  new  float[header.numVertices  *  5];  idx  =  0;  int  idxV  =  0;  int  idxT  =  0;  	animation.totalDuration  =  frames.length  *  0.2f;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<BytesValuesSource>  config  =  new  ValuesSourceConfig<BytesValuesSource>(BytesValuesSource.class);  context:  public  class  ValueCountParser  implements  Aggregator.Parser  {  public  String  type()  {  return  InternalValueCount.TYPE.name();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          ValuesSourceConfig<BytesValuesSource>  config  =  new  ValuesSourceConfig<BytesValuesSource>(BytesValuesSource.class);          ValuesSourceConfig<BytesValuesSource>  config  =  new  ValuesSourceConfig<>(BytesValuesSource.class);  String  field  =  null;  String  script  =  null;  String  scriptLang  =  null;  Map<String,  Object>  scriptParams  =  null;  boolean  assumeUnique  =  false;  XContentParser.Token  token;  	ValuesSourceConfig<BytesValuesSource>  config  =  new  ValuesSourceConfig<>(BytesValuesSource.class);  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(settings),  context:  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),  new  ScriptModule(settings),  new  MapperServiceModule(),                  new  IndexSettingsModule(settings),                  new  IndexSettingsModule(index,  settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index)  ).createInjector();  	new  IndexSettingsModule(index,  settings),  
libgdx_0a3f624e70321614373a2ab6c7c0f513fb4d7495	buggy:  MaterialAttribute  c3  =  new  ColorAttribute(new  Color(0.2f,  0.15f,  0.15f,  1.0f),  ColorAttribute.rim);  context:  model2.getBoundingBox(box);  instance2.radius  =  box.getDimensions().len()  /  2;  instance2.matrix.scale(2,  1,  2);  protoRenderer  =  new  PrototypeRendererGL20(lightManager);  protoRenderer.cam  =  cam;  MaterialAttribute  c1  =  new  ColorAttribute(new  Color(0.75f,  0.75f,  0.75f,  0.6f),  ColorAttribute.diffuse);  MaterialAttribute  c2  =  new  ColorAttribute(new  Color(0.35f,  0.35f,  0.35f,  0.35f),  ColorAttribute.specular);  MaterialAttribute  c3  =  new  ColorAttribute(new  Color(0.2f,  0.15f,  0.15f,  1.0f),  ColorAttribute.rim);  MaterialAttribute  c3  =  new  ColorAttribute(new  Color(0.2f,  1f,  0.15f,  1.0f),  ColorAttribute.rim);  MaterialAttribute  t1  =  new  TextureAttribute(texture,  0,  TextureAttribute.diffuseTexture);  MaterialAttribute  t2  =  new  TextureAttribute(texture2,  1,  TextureAttribute.specularTexture);  MaterialAttribute  b  =  new  BlendingAttribute(BlendingAttribute.translucent);  Material  material2  =  new  Material( "basic ",  c2,  t1);  model2.setMaterial(material2);  	MaterialAttribute  c3  =  new  ColorAttribute(new  Color(0.2f,  1f,  0.15f,  1.0f),  ColorAttribute.rim);  
elasticsearch_c4d75f3844d5259bb133555471ffbe73c7834f0f	buggy:  return  RestStatus.CONFLICT;  context:  public  class  DocumentMissingException  extends  EngineException  {  public  DocumentMissingException(ShardId  shardId,  String  type,  String  id)  {  super(shardId,   "[ "  +  type  +   "][ "  +  id  +   "]:  document  missing ");  }  public  RestStatus  status()  {          return  RestStatus.CONFLICT;          return  RestStatus.NOT_FOUND;  }  }  	return  RestStatus.NOT_FOUND;  
elasticsearch_f1467dbde256a968bfffed6ce470f162ac307655	buggy:  return  PackedArrayAtomicFieldData.EMPTY;  context:  throw  new  ElasticSearchException(e.getMessage(),  e);  }  }  }  public  AtomicNumericFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  PackedArrayAtomicFieldData.EMPTY;              return  PackedArrayAtomicFieldData.empty(reader.maxDoc());  }  final  MonotonicAppendingLongBuffer  values  =  new  MonotonicAppendingLongBuffer();  final  float  acceptableTransientOverheadRatio  =  fieldDataType.getSettings().getAsFloat( "acceptable_transient_overhead_ratio ",  OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO);  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(-1,  reader.maxDoc(),  acceptableTransientOverheadRatio);  	return  PackedArrayAtomicFieldData.empty(reader.maxDoc());  
elasticsearch_cb9548f81147e8fb0540fcd54f276406cf11165c	buggy:  final  long  bucketDocCount  =  bucketOrd  <  0  ?  0  :  bucketDocCount(bucketOrd);  context:  long  supersetSize  =  termsAggFactory.prepareBackground(context);  long  subsetSize  =  numCollectedDocs;  BucketSignificancePriorityQueue  ordered  =  new  BucketSignificancePriorityQueue(size);  SignificantStringTerms.Bucket  spare  =  null;  for  (long  globalTermOrd  =  Ordinals.MIN_ORDINAL;  globalTermOrd  <  globalOrdinals.getMaxOrd();  ++globalTermOrd)  {  if  (includeExclude  !=  null  &&  !acceptedGlobalOrdinals.get(globalTermOrd))  {  continue;  }  final  long  bucketOrd  =  getBucketOrd(globalTermOrd);              final  long  bucketDocCount  =  bucketOrd  <  0  ?  0  :  bucketDocCount(bucketOrd);              final  int  bucketDocCount  =  bucketOrd  <  0  ?  0  :  bucketDocCount(bucketOrd);  if  (bucketCountThresholds.getMinDocCount()  >  0  &&  bucketDocCount  ==  0)  {  continue;  }  if  (spare  ==  null)  {  spare  =  new  SignificantStringTerms.Bucket(new  BytesRef(),  0,  0,  0,  0,  null);  }  spare.bucketOrd  =  bucketOrd;  copy(globalValues.getValueByOrd(globalTermOrd),  spare.termBytes);  	final  int  bucketDocCount  =  bucketOrd  <  0  ?  0  :  bucketDocCount(bucketOrd);  
elasticsearch_93b56eb0048a988eb880f73296b700f7e68f4f34	buggy:  FlushResponse  flushResponse  =  client().admin().indices().prepareFlush( "my-index ").get();  context:  assertThat(getResponse.getField(field).getValues().get(0).toString(),  equalTo( "value1 "));  assertThat(getResponse.getField(field).getValues().get(1).toString(),  equalTo( "value2 "));  getResponse  =  client().prepareGet( "my-index ",   "my-type2 ",   "1 ").setFields(field).get();  assertThat(getResponse.isExists(),  equalTo(true));  assertThat(getResponse.getField(field).isMetadataField(),  equalTo(false));  assertThat(getResponse.getField(field).getValues().size(),  equalTo(2));  assertThat(getResponse.getField(field).getValues().get(0).toString(),  equalTo( "value1 "));  assertThat(getResponse.getField(field).getValues().get(1).toString(),  equalTo( "value2 "));          FlushResponse  flushResponse  =  client().admin().indices().prepareFlush( "my-index ").get();          FlushResponse  flushResponse  =  client().admin().indices().prepareFlush( "my-index ").setForce(true).get();  assertThat(flushResponse.getSuccessfulShards(),  greaterThanOrEqualTo(1));  getResponse  =  client().prepareGet( "my-index ",   "my-type1 ",   "1 ").setFields(field).get();  assertThat(getResponse.isExists(),  equalTo(true));  assertThat(getResponse.getField(field).isMetadataField(),  equalTo(false));  assertThat(getResponse.getField(field).getValues().size(),  equalTo(2));  assertThat(getResponse.getField(field).getValues().get(0).toString(),  equalTo( "value1 "));  	FlushResponse  flushResponse  =  client().admin().indices().prepareFlush( "my-index ").setForce(true).get();  
elasticsearch_6d214d69b9f6b144dec0b3ad9d231a873a5638d7	buggy:  ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  context.doc(),  context.analyzer(),  source.source(),  context.mappersAdded());  context:  }  analyzerMapper.parse(context);  allFieldMapper.parse(context);  }  catch  (IOException  e)  {  throw  new  MapperParsingException( "Failed  to  parse ",  e);  }  finally  {  if  (parser  !=  null)  {  parser.close();  }  }          ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  context.doc(),  context.analyzer(),  source.source(),  context.mappersAdded());          ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  source.routing(),  context.doc(),  context.analyzer(),  source.source(),  context.mappersAdded());  context.reset(null,  null,  null,  null,  null);  return  doc;  }  void  addFieldMapper(FieldMapper  fieldMapper)  {  synchronized  (mutex)  {  fieldMappers  =  fieldMappers.concat(this,  fieldMapper);  	ParsedDocument  doc  =  new  ParsedDocument(context.uid(),  context.id(),  context.type(),  source.routing(),  context.doc(),  context.analyzer(),  source.source(),  context.mappersAdded());  
elasticsearch_b00424aba76926dcae07929d56cd63d29ab616b6	buggy:  .put(BalancedShardsAllocator.SETTING_THRESHOLD,  1.1f).build();  //  use  less  aggressive  settings  context:  public  class  RecoveryBackwardsCompatibilityTests  extends  ElasticsearchBackwardsCompatIntegrationTest  {  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.builder()  .put(super.nodeSettings(nodeOrdinal))  .put( "action.admin.cluster.node.shutdown.delay ",   "10ms ")  .put( "gateway.recover_after_nodes ",  2)                  .put(BalancedShardsAllocator.SETTING_THRESHOLD,  1.1f).build();  //  use  less  aggressive  settings                  .put(BalancedShardsAllocator.SETTING_THRESHOLD,  100.0f).build();  //  use  less  aggressive  settings  }  protected  int  minExternalNodes()  {  return  2;  }  protected  int  maxExternalNodes()  {  return  3;  	.put(BalancedShardsAllocator.SETTING_THRESHOLD,  100.0f).build();  //  use  less  aggressive  settings  
elasticsearch_551b98f2f8cf4c8a37a61dca2b642e23f56ede4e	buggy:  throw  new  QueryParsingException(parseContext.index(),   "spanNear  [clauses]  must  be  of  type  span  query ");  context:  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "clauses ".equals(currentFieldName))  {  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  Query  query  =  parseContext.parseInnerQuery();  if  (!(query  instanceof  SpanQuery))  {                              throw  new  QueryParsingException(parseContext.index(),   "spanNear  [clauses]  must  be  of  type  span  query ");                              throw  new  QueryParsingException(parseContext.index(),   "spanOr  [clauses]  must  be  of  type  span  query ");  }  clauses.add((SpanQuery)  query);  }  }  }  else  {  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  	throw  new  QueryParsingException(parseContext.index(),   "spanOr  [clauses]  must  be  of  type  span  query ");  
elasticsearch_1d39bb4d51796df342cc41eeb53af0be1f7418bf	buggy:  Store  store  =  new  ByteBufferStore(shardId,  settings,  new  ByteBufferCache(settings));  context:  latch.countDown();  }  }  }  public  static  void  main(String[]  args)  throws  Exception  {  ShardId  shardId  =  new  ShardId(new  Index( "index "),  1);  Settings  settings  =  EMPTY_SETTINGS;          Store  store  =  new  ByteBufferStore(shardId,  settings,  new  ByteBufferCache(settings));          Store  store  =  new  ByteBufferStore(shardId,  settings,  null,  new  ByteBufferCache(settings));  store.deleteContent();  ThreadPool  threadPool  =  new  ScalingThreadPool();  SnapshotDeletionPolicy  deletionPolicy  =  new  SnapshotDeletionPolicy(new  KeepOnlyLastDeletionPolicy(shardId,  settings));  Engine  engine  =  new  RobinEngine(shardId,  settings,  store,  deletionPolicy,  new  MemoryTranslog(shardId,  settings),  new  LogByteSizeMergePolicyProvider(store),  new  ConcurrentMergeSchedulerProvider(shardId,  settings),  new  AnalysisService(shardId.index()),  new  SimilarityService(shardId.index()));  	Store  store  =  new  ByteBufferStore(shardId,  settings,  null,  new  ByteBufferCache(settings));  
elasticsearch_72d6d822ae1f630849baa4cc4c053f1e65af1e4d	buggy:  currentSet  =  new  CandidateSet(Candidate.EMPTY,  generator.createCandidate(BytesRef.deepCopyOf(term)));  context:  if  (posIncAttr.getPositionIncrement()  ==  0  &&  typeAttribute.type()  ==  SynonymFilter.TYPE_SYNONYM)  {  assert  currentSet  !=  null;  long  freq  =  0;  if  ((freq  =  generator.frequency(term))  >  0)  {  currentSet.addOneCandidate(generator.createCandidate(BytesRef.deepCopyOf(term),  freq,  realWordLikelihood));  }  }  else  {  if  (currentSet  !=  null)  {  candidateSetsList.add(currentSet);  }                      currentSet  =  new  CandidateSet(Candidate.EMPTY,  generator.createCandidate(BytesRef.deepCopyOf(term)));                      currentSet  =  new  CandidateSet(Candidate.EMPTY,  generator.createCandidate(BytesRef.deepCopyOf(term),  true));  }  }  public  void  end()  {  if  (currentSet  !=  null)  {  candidateSetsList.add(currentSet);  }  	currentSet  =  new  CandidateSet(Candidate.EMPTY,  generator.createCandidate(BytesRef.deepCopyOf(term),  true));  
elasticsearch_8e17d636ef441a9be80977d34acfaabc12982eb7	buggy:  return  new  XLuceneConstantScoreQuery(termFilter(value,  context));  context:  public  boolean  useTermQueryWithQueryString()  {  return  true;  }  public  Query  termQuery(Object  value,  @Nullable  QueryParseContext  context)  {  if  (fieldType.indexed()  ||  context  ==  null)  {  return  super.termQuery(value,  context);  }          return  new  XLuceneConstantScoreQuery(termFilter(value,  context));          return  new  ConstantScoreQuery(termFilter(value,  context));  }  public  Filter  termFilter(Object  value,  @Nullable  QueryParseContext  context)  {  if  (fieldType.indexed()  ||  context  ==  null)  {  return  super.termFilter(value,  context);  }  return  new  TermsFilter(UidFieldMapper.NAME,  Uid.createTypeUids(context.queryTypes(),  value));  	return  new  ConstantScoreQuery(termFilter(value,  context));  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Short  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_b2c48766266db13241b8fc1503453012570238c0	buggy:  }  else  if  (indexShouldExists)  {  context:  translogId  =  version;  }  }  else  {  IndexWriter  writer  =  new  IndexWriter(indexShard.store().directory(),  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER).setOpenMode(IndexWriterConfig.OpenMode.CREATE));  writer.close();  }              }  else  if  (indexShouldExists)  {              }  else  if  (indexShouldExists  &&  indexShard.store().indexStore().persistent())  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "shard  allocated  for  local  recovery  (post  api),  should  exists,  but  doesn't ");  }  }  catch  (IOException  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "Failed  to  fetch  index  version  after  copying  it  over ",  e);  }  recoveryStatus.index().updateVersion(version);  recoveryStatus.index().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  	}  else  if  (indexShouldExists  &&  indexShard.store().indexStore().persistent())  {  
libgdx_0351df265cc85cebb5bd943920ac30c3eb0cf64e	buggy:  TextureAtlas  textureAtlas  =  atlas.generateTextureAtlas(TextureFilter.Nearest,  TextureFilter.Nearest);  context:  char  secondChar  =  characters.charAt(j);  Glyph  second  =  data.getGlyph(secondChar);  if  (second  ==  null)  continue;  int  kerning  =  FreeType.getKerning(face,  FreeType.getCharIndex(face,  firstChar),  FreeType.getCharIndex(face,  secondChar),  0);  if  (kerning  ==  0)  continue;  first.setKerning(secondChar,  FreeType.toInt(kerning));  }  }  TextureAtlas  textureAtlas  =  atlas.generateTextureAtlas(TextureFilter.Nearest,  TextureFilter.Nearest);  TextureAtlas  textureAtlas  =  atlas.generateTextureAtlas(TextureFilter.Nearest,  TextureFilter.Nearest,  false);  data.region  =  new  TextureRegion(textureAtlas.getRegions().get(0).getTexture());  return  data;  }  	TextureAtlas  textureAtlas  =  atlas.generateTextureAtlas(TextureFilter.Nearest,  TextureFilter.Nearest,  false);  
elasticsearch_80062fbe10b574cd1a9723caf197254a5c54e752	buggy:  getRequest.realtime(request.paramAsBoolean( "realtime ",  null));  context:  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);  getRequest.operationThreaded(true);  getRequest.refresh(request.paramAsBoolean( "refresh ",  getRequest.refresh()));  getRequest.routing(request.param( "routing "));  getRequest.preference(request.param( "preference "));          getRequest.realtime(request.paramAsBoolean( "realtime ",  null));          getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  String[]  sFields  =  Strings.splitStringByCommaToArray(sField);  if  (sFields  !=  null)  {  getRequest.fields(sFields);  }  }  	getRequest.realtime(request.paramAsBooleanOptional( "realtime ",  null));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  return;  }  try  {  indexShard.recovering( "from  gateway ");  }  catch  (IllegalIndexShardStateException  e)  {  listener.onIgnoreRecovery( "already  in  recovering  process,   "  +  e.getMessage());  return;  }          threadPool.cached().execute(new  Runnable()  {          threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  recoveryStatus  =  new  RecoveryStatus();  recoveryStatus.updateStage(RecoveryStatus.Stage.INIT);  try  {  shardGateway.recover(indexShouldExists,  recoveryStatus);  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_0d3410a837f0ff592cfdf84e34c3fac2cb08201d	buggy:  filter  =   "cached( "  +  filter  +   ") ";  context:  assertThat(client().admin().indices().prepareValidateQuery( "test ").setQuery(QueryBuilders.queryString( "bar:hey ")).execute().actionGet().isValid(),  equalTo(false));  assertThat(client().admin().indices().prepareValidateQuery( "test ").setQuery(QueryBuilders.queryString( "nonexistent:hello ")).execute().actionGet().isValid(),  equalTo(true));  assertThat(client().admin().indices().prepareValidateQuery( "test ").setQuery(QueryBuilders.queryString( "foo:1  AND ")).execute().actionGet().isValid(),  equalTo(false));  }  private  static  String  filter(String  uncachedFilter)  {  String  filter  =  uncachedFilter;  if  (cluster().hasFilterCache())  {              filter  =   "cached( "  +  filter  +   ") ";              filter  =   "cache( "  +  filter  +   ") ";  }  return  filter;  }  public  void  explainValidateQuery()  throws  Exception  {  createIndex( "test ");  ensureGreen();  	filter  =   "cache( "  +  filter  +   ") ";  
elasticsearch_5a8ebab96e00e0be8bc5a2bafe14f38e300e5119	buggy:  equalTo( "5.999996  =  (MATCH)  function  score,  product  of:\n  1.0  =  (MATCH)  ConstantScore(text_field:value),  product  of:\n    1.0  =  boost\n    1.0  =  queryNorm\n  5.999996  =  (MATCH)  Math.min  of\n    5.999996  =  (MATCH)  function  score,  score  mode  [multiply]\n      1.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.0  =  (MATCH)  Function  for  field  geo_point_field:\n          1.0  =  -exp(-0.5*pow(MIN  of:  [Math.max(arcDistance([10.0,  20.0](=doc  value),[10.0,  20.0](=origin))  -  0.0(=offset),  0)],2.0)/7.213475204444817E11)\n      1.9999987  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.9999987  =  (MATCH)  product  of:\n          0.99999934  =  field  value  function:  ln(doc['float_field'].value  *  factor=1.0)\n          2.0  =  weight\n      3.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        3.0  =  (MATCH)  product  of:\n          1.0  =  script  score  function,  computed  with  script:\ "_index['text_field']['value'].tf()\n          3.0  =  weight\n    3.4028235E38  =  maxBoost\n  1.0  =  queryBoost\n ")  context:  SearchResponse  responseWithWeights  =  client().search(  searchRequest().source(  searchSource().query(  functionScoreQuery(termFilter(TEXT_FIELD,   "value ").cache(false))  .add(gaussDecayFunction(GEO_POINT_FIELD,  new  GeoPoint(10,  20),   "1000km "))  .add(fieldValueFactorFunction(FLOAT_FIELD).modifier(FieldValueFactorFunction.Modifier.LN).setWeight(2))  .add(scriptFunction( "_index[' "  +  TEXT_FIELD  +   "']['value'].tf() ").setWeight(3))  ).explain(true))).actionGet();  assertThat(responseWithWeights.getHits().getAt(0).getExplanation().toString(),                  equalTo( "5.999996  =  (MATCH)  function  score,  product  of:\n  1.0  =  (MATCH)  ConstantScore(text_field:value),  product  of:\n    1.0  =  boost\n    1.0  =  queryNorm\n  5.999996  =  (MATCH)  Math.min  of\n    5.999996  =  (MATCH)  function  score,  score  mode  [multiply]\n      1.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.0  =  (MATCH)  Function  for  field  geo_point_field:\n          1.0  =  -exp(-0.5*pow(MIN  of:  [Math.max(arcDistance([10.0,  20.0](=doc  value),[10.0,  20.0](=origin))  -  0.0(=offset),  0)],2.0)/7.213475204444817E11)\n      1.9999987  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.9999987  =  (MATCH)  product  of:\n          0.99999934  =  field  value  function:  ln(doc['float_field'].value  *  factor=1.0)\n          2.0  =  weight\n      3.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        3.0  =  (MATCH)  product  of:\n          1.0  =  script  score  function,  computed  with  script:\ "_index['text_field']['value'].tf()\n          3.0  =  weight\n    3.4028235E38  =  maxBoost\n  1.0  =  queryBoost\n ")                  equalTo( "5.999996  =  (MATCH)  function  score,  product  of:\n  1.0  =  (MATCH)  ConstantScore(text_field:value),  product  of:\n    1.0  =  boost\n    1.0  =  queryNorm\n  5.999996  =  (MATCH)  Math.min  of\n    5.999996  =  (MATCH)  function  score,  score  mode  [multiply]\n      1.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.0  =  (MATCH)  Function  for  field  geo_point_field:\n          1.0  =  exp(-0.5*pow(MIN  of:  [Math.max(arcDistance([10.0,  20.0](=doc  value),[10.0,  20.0](=origin))  -  0.0(=offset),  0)],2.0)/7.213475204444817E11)\n      1.9999987  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        1.9999987  =  (MATCH)  product  of:\n          0.99999934  =  field  value  function:  ln(doc['float_field'].value  *  factor=1.0)\n          2.0  =  weight\n      3.0  =  (MATCH)  function  score,  product  of:\n        1.0  =  match  filter:  *:*\n        3.0  =  (MATCH)  product  of:\n          1.0  =  script  score  function,  computed  with  script:\ "_index['text_field']['value'].tf()\n          3.0  =  weight\n    3.4028235E38  =  maxBoost\n  1.0  =  queryBoost\n ")  );  responseWithWeights  =  client().search(  searchRequest().source(  searchSource().query(  functionScoreQuery(termFilter(TEXT_FIELD,   "value ").cache(false))  .add(weightFactorFunction(4.0f))  ).explain(true))).actionGet();  assertThat(responseWithWeights.getHits().getAt(0).getExplanation().toString(),  	equalTo( "5.999996  =  (MATCH)  function  score,  product  of:\n    1.0  =  (MATCH)  ConstantScore(text_field:value),  product  of:\n        1.0  =  boost\n        1.0  =  queryNorm\n    5.999996  =  (MATCH)  Math.min  of\n        5.999996  =  (MATCH)  function  score,  score  mode  [multiply]\n            1.0  =  (MATCH)  function  score,  product  of:\n                1.0  =  match  filter:  *:*\n                1.0  =  (MATCH)  Function  for  field  geo_point_field:\n                    1.0  =  exp(-0.5*pow(MIN  of:  [Math.max(arcDistance([10.0,  20.0](=doc  value),[10.0,  20.0](=origin))  -  0.0(=offset),  0)],2.0)/7.213475204444817E11)\n            1.9999987  =  (MATCH)  function  score,  product  of:\n                1.0  =  match  filter:  *:*\n                1.9999987  =  (MATCH)  product  of:\n                    0.99999934  =  field  value  function:  ln(doc['float_field'].value  *  factor=1.0)\n                    2.0  =  weight\n            3.0  =  (MATCH)  function  score,  product  of:\n                1.0  =  match  filter:  *:*\n                3.0  =  (MATCH)  product  of:\n                    1.0  =  script  score  function,  computed  with  script:\ "_index['text_field']['value'].tf()\n                    3.0  =  weight\n        3.4028235E38  =  maxBoost\n    1.0  =  queryBoost\n ")  
elasticsearch_2fd36fdbf8d46ad53d8223f4450b2eaea2b50d2a	buggy:  node  =  nodeBuilder().settings(settingsBuilder().put( "node.local ",  true)).node();  context:  public  class  SimpleAttachmentIntegrationTests  {  private  final  Logger  logger  =  Loggers.getLogger(getClass());  private  Node  node;          node  =  nodeBuilder().settings(settingsBuilder().put( "node.local ",  true)).node();          node  =  nodeBuilder().local(true).node();  }  node.close();  }  	node  =  nodeBuilder().local(true).node();  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  }  public  void  testParseLocal()  {  assertThat(Locale.GERMAN,  equalTo(DateFieldMapper.parseLocale( "de ")));  assertThat(Locale.GERMANY,  equalTo(DateFieldMapper.parseLocale( "de_DE ")));  assertThat(new  Locale( "de ", "DE ", "DE "),  equalTo(DateFieldMapper.parseLocale( "de_DE_DE ")));  try  {  DateFieldMapper.parseLocale( "de_DE_DE_DE ");              assert  false;              fail();  }  catch(ElasticsearchIllegalArgumentException  ex)  {  }  assertThat(Locale.ROOT,  equalTo(DateFieldMapper.parseLocale( " ")));  assertThat(Locale.ROOT,  equalTo(DateFieldMapper.parseLocale( "ROOT ")));  }  	fail();  
elasticsearch_841c2d1e14d36e38d49220974c66a6677c4d9203	buggy:  builder.field( "locale ",  dateTimeFormatter.format());  context:  if  (nullValue  !=  null)  {  builder.field( "null_value ",  nullValue);  }  if  (includeInAll  !=  null)  {  builder.field( "include_in_all ",  includeInAll);  }  if  (timeUnit  !=  Defaults.TIME_UNIT)  {  builder.field( "numeric_resolution ",  timeUnit.name().toLowerCase(Locale.ROOT));  }  if  (dateTimeFormatter.locale()  !=  null)  {              builder.field( "locale ",  dateTimeFormatter.format());              builder.field( "locale ",  dateTimeFormatter.locale());  }  }  private  long  parseStringValue(String  value)  {  try  {  return  dateTimeFormatter.parser().parseMillis(value);  }  catch  (RuntimeException  e)  {  try  {  	builder.field( "locale ",  dateTimeFormatter.locale());  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  transportService.sendRequest(listedNode,  TransportActions.Admin.Cluster.Node.INFO,  Requests.nodesInfo( "_local "),  new  BaseTransportResponseHandler<NodesInfoResponse>()  {  context:  ImmutableList<DiscoveryNode>  listedNodes  =  TransportClientNodesService.this.listedNodes;  final  CountDownLatch  latch  =  new  CountDownLatch(listedNodes.size());  final  CopyOnWriteArrayList<NodesInfoResponse>  nodesInfoResponses  =  new  CopyOnWriteArrayList<NodesInfoResponse>();  for  (final  DiscoveryNode  listedNode  :  listedNodes)  {  threadPool.execute(new  Runnable()  {  try  {  transportService.connectToNode(listedNode);  //  make  sure  we  are  connected  to  it                              transportService.sendRequest(listedNode,  TransportActions.Admin.Cluster.Node.INFO,  Requests.nodesInfo( "_local "),  new  BaseTransportResponseHandler<NodesInfoResponse>()  {                              transportService.sendRequest(listedNode,  TransportActions.Admin.Cluster.Node.INFO,  Requests.nodesInfoRequest( "_local "),  new  BaseTransportResponseHandler<NodesInfoResponse>()  {  return  new  NodesInfoResponse();  }  nodesInfoResponses.add(response);  latch.countDown();  	transportService.sendRequest(listedNode,  TransportActions.Admin.Cluster.Node.INFO,  Requests.nodesInfoRequest( "_local "),  new  BaseTransportResponseHandler<NodesInfoResponse>()  {  
elasticsearch_b2918d7c2b9fd94d0b0485ccdffe5a0fa1e2ff7e	buggy:  String  language  =  (parts.length  >  0  ?  parts[0]  :   " ");  context:  public  static  Locale  parseLocaleString(String  localeString)  {  String[]  parts  =  tokenizeToStringArray(localeString,   "_   ",  false,  false);          String  language  =  (parts.length  >  0  ?  parts[0]  :   " ");          String  language  =  (parts.length  !=  0  ?  parts[0]  :   " ");  String  country  =  (parts.length  >  1  ?  parts[1]  :   " ");  String  variant  =   " ";  if  (parts.length  >=  2)  {  int  endIndexOfCountryCode  =  localeString.indexOf(country)  +  country.length();  variant  =  trimLeadingWhitespace(localeString.substring(endIndexOfCountryCode));  	String  language  =  (parts.length  !=  0  ?  parts[0]  :   " ");  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  this.channel  =  channel;  this.logger  =  logger;  }  public  abstract  void  onResponse(T  t);  public  void  onFailure(Throwable  e)  {  try  {              channel.sendResponse(new  XContentThrowableRestResponse(request,  e));              channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  }  }  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.admin().indices().updateSettings(updateSettingsRequest,  new  ActionListener<UpdateSettingsResponse>()  {  public  void  onResponse(UpdateSettingsResponse  updateSettingsResponse)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject()  .field( "ok ",  true)  .endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_4df6017eda2cfc409aba80c42319bc80f3c871f2	buggy:  while  (tokenizer.hasMoreElements())  {  context:  }  private  static  FileHandle  getRelativeFileHandle(FileHandle  path,  String  relativePath)  {  if  (relativePath.trim().length()  ==  0)  {  return  path;  }  FileHandle  child  =  path;  StringTokenizer  tokenizer  =  new  StringTokenizer(relativePath,   "\\/ ");          while  (tokenizer.hasMoreElements())  {          while  (tokenizer.hasMoreTokens())  {  String  token  =  tokenizer.nextToken();  if  (token.equals( ".. "))  {  child  =  child.parent();  }  else  {  child  =  child.child(token);  }  }  	while  (tokenizer.hasMoreTokens())  {  
libgdx_4643b615735176e00d9731ddc08105227ec915e3	buggy:  int  size  =  0;  context:  return  buffer.asLongBuffer();  }  #include  <stdio.h>  #include  <stdlib.h>  #include  <string.h>  public  static  void  disposeUnsafeByteBuffer(ByteBuffer  buffer)  {  int  size  =  0;  int  size  =  buffer.capacity();  synchronized(unsafeBuffers)  {  if(!unsafeBuffers.removeValue(buffer,  true))  throw  new  IllegalArgumentException( "buffer  not  allocated  with  newUnsafeByteBuffer  or  already  disposed ");  }  allocatedUnsafe  -=  size;  freeMemory(buffer);  }  	int  size  =  buffer.capacity();  
elasticsearch_d820bfe11be547ac2778f3a6feb9ba1d6f348876	buggy:  if  (excluded  !=  null  &&  excluded.contains(value))  {  context:  facets.adjustOrPutValue(new  BytesRef(value),  1,  1);  total++;  }  else  {  missing++;  }  }  }  private  boolean  match(String  value)  {          if  (excluded  !=  null  &&  excluded.contains(value))  {          if  (excluded  !=  null  &&  excluded.contains(new  BytesRef(value)))  {  return  false;  }  if  (matcher  !=  null  &&  !matcher.reset(value).matches())  {  return  false;  }  return  true;  }  	if  (excluded  !=  null  &&  excluded.contains(new  BytesRef(value)))  {  
elasticsearch_797a9b07efde2c4f740daea9e310614e92fe3194	buggy:  lockFactory  =  new  NativeFSLockFactory();  context:  public  final  StoreRateLimiting  rateLimiting()  {  return  indexStore.rateLimiting();  }  protected  final  LockFactory  buildLockFactory()  throws  IOException  {  String  fsLock  =  componentSettings.get( "lock ",  componentSettings.get( "fs_lock ",   "native "));  LockFactory  lockFactory  =  NoLockFactory.getNoLockFactory();  if  (fsLock.equals( "native "))  {              lockFactory  =  new  NativeFSLockFactory();              lockFactory  =  new  XNativeFSLockFactory();  }  else  if  (fsLock.equals( "simple "))  {  lockFactory  =  new  SimpleFSLockFactory();  }  else  if  (fsLock.equals( "none "))  {  lockFactory  =  NoLockFactory.getNoLockFactory();  }  return  lockFactory;  }  	lockFactory  =  new  XNativeFSLockFactory();  
elasticsearch_284a35131cd6a96baba14b31c827e5f6dab7b4ad	buggy:  public  MoreLikeThisFieldJsonQueryBuilder  boostTerms(boolean  boostTerms)  {  context:  public  MoreLikeThisFieldJsonQueryBuilder  minWordLen(int  minWordLen)  {  this.minWordLen  =  minWordLen;  return  this;  }  public  MoreLikeThisFieldJsonQueryBuilder  maxWordLen(int  maxWordLen)  {  this.maxWordLen  =  maxWordLen;  return  this;  }      public  MoreLikeThisFieldJsonQueryBuilder  boostTerms(boolean  boostTerms)  {      public  MoreLikeThisFieldJsonQueryBuilder  boostTerms(Boolean  boostTerms)  {  this.boostTerms  =  boostTerms;  return  this;  }  public  MoreLikeThisFieldJsonQueryBuilder  boostTermsFactor(float  boostTermsFactor)  {  this.boostTermsFactor  =  boostTermsFactor;  return  this;  }  	public  MoreLikeThisFieldJsonQueryBuilder  boostTerms(Boolean  boostTerms)  {  
libgdx_0dd949b2ecf030ecef7e83e5d070f734cf983a5d	buggy:  button.action(Forever.$(RotateBy.$(360,  4)));  context:  Image  img2  =  new  Image( "image2 ",  new  TextureRegion(badlogic,  0,  0,  256,  256));  img2.width  =  img2.height  =  64;  img2.originX  =  img2.originY  =  32;  img2.action(Repeat.$(Sequence.$(MoveBy.$(50,  0,  1),  MoveBy.$(0,  50,  1),  MoveBy.$(-50,  0,  1),  MoveBy.$(0,  -50,  1)),  3));  ui.addActor(img2);  Button  button  =  new  Button( "button ",  buttonRegion,  buttonDownRegion);  button.action(Forever.$(RotateBy.$(360,  4)));  button.action(Parallel.$(Sequence.$(FadeOut.$(2),  FadeIn.$(2)),  Sequence.$(ScaleTo.$(0.1f,  0.1f,  1.5f),  ScaleTo.$(1.0f,  1.0f,  1.5f))));  button.clickListener  =  new  ClickListener()  {  public  void  clicked(Button  button)  {  if  (Gdx.input.supportsOnscreenKeyboard())  Gdx.input.setOnscreenKeyboardVisible(true);  }  };  	button.action(Parallel.$(Sequence.$(FadeOut.$(2),  FadeIn.$(2)),  Sequence.$(ScaleTo.$(0.1f,  0.1f,  1.5f),  ScaleTo.$(1.0f,  1.0f,  1.5f))));  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execGatewaySnapshot(gatewaySnapshotRequest,  new  ActionListener<GatewaySnapshotResponse>()  {  context:  super(settings,  client);  controller.registerHandler(POST,   "/_gateway/snapshot ",  this);  controller.registerHandler(POST,   "/{index}/_gateway/snapshot ",  this);  }  GatewaySnapshotRequest  gatewaySnapshotRequest  =  new  GatewaySnapshotRequest(RestActions.splitIndices(request.param( "index ")));  gatewaySnapshotRequest.timeout(request.paramAsTime( "timeout ",  DEFAULT_TIMEOUT));  gatewaySnapshotRequest.listenerThreaded(false);          client.admin().indices().execGatewaySnapshot(gatewaySnapshotRequest,  new  ActionListener<GatewaySnapshotResponse>()  {          client.admin().indices().gatewaySnapshot(gatewaySnapshotRequest,  new  ActionListener<GatewaySnapshotResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  builder.startObject( "indices ");  for  (IndexGatewaySnapshotResponse  indexResponse  :  result.indices().values())  {  builder.startObject(indexResponse.index())  	client.admin().indices().gatewaySnapshot(gatewaySnapshotRequest,  new  ActionListener<GatewaySnapshotResponse>()  {  
elasticsearch_0fdfa5a58153611eb26f8cb61447a379f7d69a27	buggy:  return  new  EnglishPossessiveFilter(tokenStream);  context:  return  new  SnowballFilter(tokenStream,  new  RussianStemmer());  }  else  if  ( "spanish ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  SpanishStemmer());  }  else  if  ( "swedish ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  SwedishStemmer());  }  else  if  ( "turkish ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  TurkishStemmer());  }  else  if  ( "minimal_english ".equalsIgnoreCase(language)  ||   "minimalEnglish ".equalsIgnoreCase(language))  {  return  new  EnglishMinimalStemFilter(tokenStream);  }  else  if  ( "possessive_english ".equalsIgnoreCase(language)  ||   "possessiveEnglish ".equalsIgnoreCase(language))  {              return  new  EnglishPossessiveFilter(tokenStream);              return  new  EnglishPossessiveFilter(version,  tokenStream);  }  else  if  ( "light_finish ".equalsIgnoreCase(language)  ||   "lightFinish ".equalsIgnoreCase(language))  {  return  new  FinnishLightStemFilter(tokenStream);  }  else  if  ( "light_french ".equalsIgnoreCase(language)  ||   "lightFrench ".equalsIgnoreCase(language))  {  return  new  FrenchLightStemFilter(tokenStream);  }  else  if  ( "minimal_french ".equalsIgnoreCase(language)  ||   "minimalFrench ".equalsIgnoreCase(language))  {  return  new  FrenchMinimalStemFilter(tokenStream);  }  else  if  ( "light_german ".equalsIgnoreCase(language)  ||   "lightGerman ".equalsIgnoreCase(language))  {  return  new  GermanLightStemFilter(tokenStream);  	return  new  EnglishPossessiveFilter(version,  tokenStream);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  writeStateExecutor.shutdown();  try  {  writeStateExecutor.awaitTermination(10,  TimeUnit.SECONDS);  }  catch  (InterruptedException  e)  {  }  }  public  void  performStateRecovery(final  GatewayStateRecoveredListener  listener)  throws  GatewayException  {          threadPool.cached().execute(new  Runnable()  {          threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  StopWatch  stopWatch  =  new  StopWatch().start();  MetaData  metaData;  try  {  metaData  =  read();  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  String>  prefixes  =  new  HashMap<String,  String>(COUNT);  context:  }  }  public  void  testPostingsHighlighterManyDocs()  throws  Exception  {  assertAcked(prepareCreate( "test ").addMapping( "type1 ",  type1PostingsffsetsMapping()));  ensureGreen();  int  COUNT  =  between(20,  100);          Map<String,  String>  prefixes  =  new  HashMap<String,  String>(COUNT);          Map<String,  String>  prefixes  =  new  HashMap<>(COUNT);  IndexRequestBuilder[]  indexRequestBuilders  =  new  IndexRequestBuilder[COUNT];  for  (int  i  =  0;  i  <  COUNT;  i++)  {  String  prefix  =  randomAsciiOfLengthBetween(5,  30);  prefixes.put(String.valueOf(i),  prefix);  indexRequestBuilders[i]  =  client().prepareIndex( "test ",   "type1 ",  Integer.toString(i)).setSource( "field1 ",   "Sentence   "  +  prefix  	Map<String,  String>  prefixes  =  new  HashMap<>(COUNT);  
libgdx_bd31915dc4a1d95d3592a82f6373a1820686dc3e	buggy:  emitter.setImagePath( "data/particle.png ");  context:  emitter.getVelocity().setHigh(80,  80);  emitter.getVelocity().setActive(true);  emitter.getTransparency().setHigh(1,  1);  emitter.getTransparency().setTimeline(new  float[]  {0,  0.2f,  0.8f,  1});  emitter.getTransparency().setScaling(new  float[]  {0,  1,  1,  0});  emitter.setFlip(false,  true);  emitter.setMaxParticleCount(15);  emitter.setImagePath( "data/particle.png ");  emitter.setImagePath( "particle.png ");  ArrayList<ParticleEmitter>  emitters  =  editor.effect.getEmitters();  if  (emitters.isEmpty())  emitter.setPosition(Gdx.graphics.getWidth()  /  2,  Gdx.graphics.getHeight()  /  2);  else  {  ParticleEmitter  p  =  emitters.get(0);  emitter.setPosition(p.getX(),  p.getY());  }  	emitter.setImagePath( "particle.png ");  
elasticsearch_bae3203e3beee284ca79ef9e004dd7abb1cb5b94	buggy:  return  cluster().size();  context:  return  ImmutableSettings.builder()  .put(DiscoverySettings.PUBLISH_TIMEOUT,  0)  .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES,  5)  .build();  }  protected  int  minimumNumberOfShards()  {          return  cluster().size();          return  immutableCluster().size();  }  protected  int  numberOfReplicas()  {  return  0;  }  	return  immutableCluster().size();  
elasticsearch_2a588dc1f109022331ae43959ac8e2e46ee69168	buggy:  .filteredIndices( "_na ");  context:  controller.registerHandler(GET,   "/_template/{name} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  ClusterStateRequest  clusterStateRequest  =  Requests.clusterStateRequest()  .filterRoutingTable(true)  .filterNodes(true)  .filteredIndexTemplates(request.param( "name "))                  .filteredIndices( "_na ");                  .filterOutIndices();  clusterStateRequest.listenerThreaded(false);  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  public  void  onResponse(ClusterStateResponse  response)  {  try  {  MetaData  metaData  =  response.getState().metaData();  	.filterOutIndices();  
elasticsearch_1a1df06411455d2ac483963c1b617b8722265305	buggy:  return  1;  context:  return  false;  }  public  int  getNumDocs()  {  return  this.numDocs;  }  public  int  getNumOrds()  {          return  1;          return  0;  }  public  Docs  ordinals()  {  return  new  Docs(this);  }  public  static  class  Docs  implements  Ordinals.Docs  {  	return  0;  
elasticsearch_66c9f2f8344bdf9e58e0bc8a9fb59a527ec547cf	buggy:  .facets(facets().facet( "all ",  termQuery( "multi ",   "test "),  true).facet( "test1 ",  termQuery( "name ",   "test1 ")));  context:  assertThat( "make  sure  we  don't  have  duplicates ",  expectedIds.remove(hit.id()),  notNullValue());  }  assertThat( "make  sure  we  got  all  [ "  +  expectedIds  +   "] ",  expectedIds.size(),  equalTo(0));  }  SearchSourceBuilder  sourceBuilder  =  searchSource()  .query(termQuery( "multi ",   "test "))  .from(0).size(20).explain(true)                  .facets(facets().facet( "all ",  termQuery( "multi ",   "test "),  true).facet( "test1 ",  termQuery( "name ",   "test1 ")));                  .facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test "),  true).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  SearchResponse  searchResponse  =  client.search(searchRequest( "test ").source(sourceBuilder)).actionGet();  assertThat( "Failures   "  +  Arrays.toString(searchResponse.shardFailures()),  searchResponse.shardFailures().length,  equalTo(0));  assertThat(searchResponse.hits().totalHits(),  equalTo(100l));  assertThat(searchResponse.facets().countFacet( "test1 ").count(),  equalTo(1l));  assertThat(searchResponse.facets().countFacet( "all ").count(),  equalTo(100l));  }  	.facets(facets().queryFacet( "all ",  termQuery( "multi ",   "test "),  true).queryFacet( "test1 ",  termQuery( "name ",   "test1 ")));  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  size()  !=  0;  context:  }  }  public  int  size()  {  return  end  -  start;  }  public  boolean  isEmpty()  {          return  size()  !=  0;          return  size()  ==  0;  }  public  Double  get(int  index)  {  assert  index  <  size();  return  values[start  +  index];  }  	return  size()  ==  0;  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  }  else  if  ( "scope ".equals(currentFieldName))  {  context:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "query ".equals(currentFieldName))  {  query  =  parseContext.parseInnerQuery();  }  }  else  if  (token.isValue())  {  if  ( "type ".equals(currentFieldName))  {  childType  =  parser.text();                  }  else  if  ( "scope ".equals(currentFieldName))  {                  }  else  if  ( "_scope ".equals(currentFieldName))  {  scope  =  parser.text();  }  else  if  ( "score ".equals(currentFieldName))  {  scoreType  =  TopChildrenQuery.ScoreType.fromString(parser.text());  }  else  if  ( "boost ".equals(currentFieldName))  {  boost  =  parser.floatValue();  }  else  if  ( "factor ".equals(currentFieldName))  {  factor  =  parser.intValue();  }  else  if  ( "incremental_factor ".equals(currentFieldName)  ||   "incrementalFactor ".equals(currentFieldName))  {  	}  else  if  ( "_scope ".equals(currentFieldName))  {  
libgdx_6ff0a388a0b267078607bdfdf92434943aee1b32	buggy:  target.rotation  =  rotation;  context:  this.target  =  actor;  this.startRotation  =  target.rotation;  this.deltaRotation  =  rotation;  this.taken  =  0;  this.done  =  false;  }  float  alpha  =  createInterpolatedAlpha(delta);  if  (done)  {  target.rotation  =  rotation;  target.rotation  =  startRotation  +  rotation;  }  else  {  target.rotation  =  startRotation  +  deltaRotation  *  alpha;  }  }  super.finish();  pool.free(this);  	target.rotation  =  startRotation  +  rotation;  
elasticsearch_25f19f8b8786af461b76608d57f6566bba250909	buggy:  ensureYellow();  context:  .put( "analysis.analyzer.name_search_analyzer.tokenizer ",   "whitespace "))  .execute().actionGet();  client().prepareIndex( "test ",   "test ",   "1 ")  .setSource(XContentFactory.jsonBuilder()  .startObject()  .field( "name ",   "logicacmg  ehemals  avinci  -  the  know  how  company ")  .field( "name2 ",   "logicacmg  ehemals  avinci  -  the  know  how  company ")  .endObject())  .execute().actionGet();  refresh();          ensureYellow();          ensureGreen();  SearchResponse  search  =  client().prepareSearch().setQuery(matchQuery( "name ",   "logica  m ")).addHighlightedField( "name ").execute().actionGet();  assertHighlight(search,  0,   "name ",  0,  equalTo( "<em>logica</em>c<em>m</em>g  ehe<em>m</em>als  avinci  -  the  know  how  co<em>m</em>pany "));  search  =  client().prepareSearch().setQuery(matchQuery( "name ",   "logica  ma ")).addHighlightedField( "name ").execute()  .actionGet();  assertHighlight(search,  0,   "name ",  0,  equalTo( "<em>logica</em>cmg  ehe<em>ma</em>ls  avinci  -  the  know  how  company "));  search  =  client().prepareSearch().setQuery(matchQuery( "name ",   "logica ")).addHighlightedField( "name ").execute().actionGet();  	ensureGreen();  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  newMapper  =  indexService.mapperService().parse(request.type(),  new  CompressedString(request.source()));  context:  Map<String,  DocumentMapper>  existingMappers  =  newHashMap();  for  (String  index  :  request.indices())  {  IndexService  indexService  =  indicesService.indexServiceSafe(index);  DocumentMapper  newMapper;  DocumentMapper  existingMapper  =  indexService.mapperService().documentMapper(request.type());  if  (MapperService.DEFAULT_MAPPING.equals(request.type()))  {  newMapper  =  indexService.mapperService().parse(request.type(),  new  CompressedString(request.source()),  false);  }  else  {                              newMapper  =  indexService.mapperService().parse(request.type(),  new  CompressedString(request.source()));                              newMapper  =  indexService.mapperService().parse(request.type(),  new  CompressedString(request.source()),  existingMapper  ==  null);  if  (existingMapper  !=  null)  {  DocumentMapper.MergeResult  mergeResult  =  existingMapper.merge(newMapper,  mergeFlags().simulate(true));  if  (!request.ignoreConflicts()  &&  mergeResult.hasConflicts())  {  throw  new  MergeMappingException(mergeResult.conflicts());  }  }  	newMapper  =  indexService.mapperService().parse(request.type(),  new  CompressedString(request.source()),  existingMapper  ==  null);  
elasticsearch_3925c0b4e11625955c0af3092df0d0d2e9348117	buggy:  WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE,  context:  this.stemEnglishPossessive  =  settings.getAsBoolean( "stem_english_possessive ",  true);  Set<?>  protectedWords  =  Analysis.getWordSet(env,  settings,   "protected_words ",  version);  this.protoWords  =  protectedWords  ==  null  ?  null  :  CharArraySet.copy(Lucene.VERSION,  protectedWords);  }  public  TokenStream  create(TokenStream  tokenStream)  {  return  new  WordDelimiterFilter(tokenStream,                  WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE,                  charTypeTable,  generateWordParts  ?  1  :  0,  generateNumberParts  ?  1  :  0,  catenateWords  ?  1  :  0,  catenateNumbers  ?  1  :  0,  catenateAll  ?  1  :  0,  splitOnCaseChange  ?  1  :  0,  preserveOriginal  ?  1  :  0,  splitOnNumerics  ?  1  :  0,  	charTypeTable,  
elasticsearch_fc812a306bbc7471ff1a74a0fc24411d7f4f31c8	buggy:  logger.debug( "Applying  started  shard  {},  reason  [{}] ",  shardRouting,  reason);  context:  for  (ShardRouting  entry  :  indexShardRoutingTable)  {  if  (shardRouting.currentNodeId().equals(entry.currentNodeId()))  {  if  (entry.started())  {  return  currentState;  }  }  }  if  (logger.isDebugEnabled())  {                      logger.debug( "Applying  started  shard  {},  reason  [{}] ",  shardRouting,  reason);                      logger.debug( "applying  started  shard  {},  reason  [{}] ",  shardRouting,  reason);  }  RoutingTable  newRoutingTable  =  shardsAllocation.applyStartedShards(currentState,  newArrayList(shardRouting));  if  (routingTable  ==  newRoutingTable)  {  return  currentState;  }  return  newClusterStateBuilder().state(currentState).routingTable(newRoutingTable).build();  }  });  	logger.debug( "applying  started  shard  {},  reason  [{}] ",  shardRouting,  reason);  
elasticsearch_29e981d28d2a568ab778b0618dc8e479c8771f32	buggy:  sb.append( "    translog  :  number_of_operations  [ ").append(recoveryStatus.translog().numberOfOperations()).append( "],  took  [ ").append(recoveryStatus.translog().took()).append( "] ");  context:  if  (indexShard.state()  !=  IndexShardState.STARTED)  {  indexShard.start();  }  stopWatch.stop();  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(stopWatch.totalTime()).append( "],  throttling_wait  [ ").append(throttlingWaitTime.totalTime()).append( "]\n ");  sb.append( "    index    :  recovered_files  [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().totalSize()).append( "],  took  [ ").append(recoveryStatus.index().took()).append( "],  throttling_wait  [ ").append(recoveryStatus.index().throttlingWaitTime()).append( "]\n ");  sb.append( "              :  reusing_files    [ ").append(recoveryStatus.index().numberOfExistingFiles()).append( "]  with  total_size  [ ").append(recoveryStatus.index().existingTotalSize()).append( "]\n ");                          sb.append( "    translog  :  number_of_operations  [ ").append(recoveryStatus.translog().numberOfOperations()).append( "],  took  [ ").append(recoveryStatus.translog().took()).append( "] ");                          sb.append( "    translog  :  number_of_operations  [ ").append(recoveryStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(recoveryStatus.translog().took()).append( "] ");  }  indexShard.refresh(new  Engine.Refresh(false));  listener.onRecoveryDone();  scheduleSnapshotIfNeeded();  }  catch  (IndexShardGatewayRecoveryException  e)  {  if  ((e.getCause()  instanceof  IndexShardClosedException)  ||  (e.getCause()  instanceof  IndexShardNotStartedException))  {  	sb.append( "        translog  :  number_of_operations  [ ").append(recoveryStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(recoveryStatus.translog().took()).append( "] ");  
libgdx_f707d7a105a9aea84576aff3120e7363208bb55b	buggy:  ((LwjglInput)Gdx.input).processEvents();  context:  }  input.update();  int  width  =  Math.max(1,  graphics.getWidth());  int  height  =  Math.max(1,  graphics.getHeight());  if  (lastWidth  !=  width  ||  lastHeight  !=  height)  {  lastWidth  =  width;  lastHeight  =  height;  listener.resize(width,  height);  }  ((LwjglInput)Gdx.input).processEvents();  input.processEvents();  listener.render();  audio.update();  Display.update();  Display.sync(60);  }  };  new  Thread( "LWJGL  Canvas ")  {  	input.processEvents();  
elasticsearch_51656552a5f85493f8d73d496283a71478f05291	buggy:  shardEntry.moveToBackup();  context:  boolean  elected  =  false;  for  (RoutingNode  routingNode  :  routingNodes.nodesToShards().values())  {  for  (MutableShardRouting  shardEntry2  :  routingNode.shards())  {  if  (shardEntry.shardId().equals(shardEntry2.shardId()))  {  assert  shardEntry2.assignedToNode();  assert  !shardEntry2.primary();  changed  =  true;                              shardEntry.moveToBackup();                              shardEntry.moveFromPrimary();  shardEntry2.moveToPrimary();  elected  =  true;  break;  }  }  if  (elected)  {  break;  	shardEntry.moveFromPrimary();  
elasticsearch_f01ce61f710a906d360a956a48f096f540123867	buggy:  builder.add(new  BytesRef(parser.text()));  context:  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "params ".equals(currentFieldName))  {  params  =  parser.map();  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "exclude ".equals(currentFieldName))  {  ImmutableSet.Builder<BytesRef>  builder  =  ImmutableSet.builder();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {                          builder.add(new  BytesRef(parser.text()));                          builder.add(parser.bytes());  }  excluded  =  builder.build();  }  else  if  ( "fields ".equals(currentFieldName))  {  List<String>  fields  =  Lists.newArrayListWithCapacity(4);  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  fields.add(parser.text());  }  fieldsNames  =  fields.toArray(new  String[fields.size()]);  	builder.add(parser.bytes());  
elasticsearch_2c150419ce565ed8a0d3d83af25b2bbcba323eae	buggy:  indexShard.flush(new  Engine.Flush().refresh(request.refresh()).full(request.full()).force(request.force()));  context:  }  protected  ShardFlushResponse  newShardResponse()  {  return  new  ShardFlushResponse();  }  protected  ShardFlushResponse  shardOperation(ShardFlushRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          indexShard.flush(new  Engine.Flush().refresh(request.refresh()).full(request.full()).force(request.force()));          indexShard.flush(new  Engine.Flush().refresh(request.refresh()).type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  return  new  ShardFlushResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  FlushRequest  request,  String[]  concreteIndices)  {  	indexShard.flush(new  Engine.Flush().refresh(request.refresh()).type(request.full()  ?  Engine.Flush.Type.NEW_WRITER  :  Engine.Flush.Type.COMMIT_TRANSLOG).force(request.force()));  
elasticsearch_1d1ca3befc8bbe57bc58f32633c02d47922e651d	buggy:  return  new  FieldDataType( "float ");  context:  public  class  FloatFieldDataTests  extends  AbstractNumericFieldDataTests  {  protected  FieldDataType  getFieldDataType()  {          return  new  FieldDataType( "float ");          return  new  FieldDataType( "float ",  getFieldDataSettings());  }  protected  String  one()  {  return   "1.0 ";  }  protected  String  two()  {  return   "2.0 ";  	return  new  FieldDataType( "float ",  getFieldDataSettings());  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(HistogramFacetCollectorParser.NAME);  context:  if  (keyFieldName  ==  null)  {  throw  new  SearchSourceBuilderException( "field  must  be  set  on  histogram  facet  for  facet  [ "  +  name  +   "] ");  }  if  (interval  <  0)  {  throw  new  SearchSourceBuilderException( "interval  must  be  set  on  histogram  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(HistogramFacetCollectorParser.NAME);          builder.startObject(HistogramFacet.TYPE);  if  (valueFieldName  !=  null  &&  !keyFieldName.equals(valueFieldName))  {  builder.field( "key_field ",  keyFieldName);  builder.field( "value_field ",  valueFieldName);  }  else  {  builder.field( "field ",  keyFieldName);  }  builder.field( "interval ",  interval);  if  (comparatorType  !=  null)  {  	builder.startObject(HistogramFacet.TYPE);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false  :   "search  should  fail ";  context:  public  void  testFailedSearchWithWrongQuery()  throws  Exception  {  prepareData();  try  {  SearchResponse  searchResponse  =  client().search(searchRequest( "test ").source( "{  xxx  } ".getBytes(Charsets.UTF_8))).actionGet();  assertThat(searchResponse.getTotalShards(),  equalTo(3));  assertThat(searchResponse.getSuccessfulShards(),  equalTo(0));  assertThat(searchResponse.getFailedShards(),  equalTo(3));              assert  false  :   "search  should  fail ";              fail( "search  should  fail ");  }  catch  (ElasticsearchException  e)  {  assertThat(e.unwrapCause(),  instanceOf(SearchPhaseExecutionException.class));  }  }  	fail( "search  should  fail ");  
libgdx_36868d3b896215171b2a08bd7e6587d728489a63	buggy:  actor.addAction(parallel(moveBy(0,  250,  2),  moveBy(250,  0,  2)));  context:  return  true;  }  });  button.setPosition(100,  100);  stage.addActor(button);  meow.setDuration(2);  actor.addAction(parallel(moveBy(0,  250,  2),  moveBy(250,  0,  2)));  actor.addAction(parallel(rotateBy(90,  2),  rotateBy(90,  2)));  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  	actor.addAction(parallel(rotateBy(90,  2),  rotateBy(90,  2)));  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignoreConflicts ",  putMappingRequest.ignoreConflicts()));  context:  super(settings,  client);  controller.registerHandler(PUT,   "/{index}/_mapping ",  this);  controller.registerHandler(PUT,   "/{index}/{type}/_mapping ",  this);  }  PutMappingRequest  putMappingRequest  =  putMappingRequest(splitIndices(request.param( "index ")));  putMappingRequest.type(request.param( "type "));  putMappingRequest.mappingSource(request.contentAsString());  putMappingRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));          putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignoreConflicts ",  putMappingRequest.ignoreConflicts()));          putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignore_conflicts ",  putMappingRequest.ignoreConflicts()));  client.admin().indices().putMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.acknowledged());  builder.endObject();  	putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignore_conflicts ",  putMappingRequest.ignoreConflicts()));  
elasticsearch_e01f8c250d9c79911180b2e383fb184f4d278222	buggy:  return  new  SoftThreadLocalRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));  context:  package  org.elasticsearch.common.recycler;  public  class  SoftThreadLocalRecyclerTests  extends  AbstractRecyclerTests  {  protected  Recycler<byte[]>  newRecycler()  {          return  new  SoftThreadLocalRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));          return  Recyclers.threadLocal(Recyclers.softFactory(Recyclers.dequeFactory(RECYCLER_C,  10)));  }  }  	return  Recyclers.threadLocal(Recyclers.softFactory(Recyclers.dequeFactory(RECYCLER_C,  10)));  
libgdx_cb7ea54d31d0735d0bb4d2727d043a858b3905a7	buggy:  model.setAnimation( "all ",  0);  context:  Mesh  mesh  =  new  Mesh(false,  header.numTriangles  *  3,  indices.length,  new  VertexAttribute(Usage.Position,  3,   "a_pos "),  new  VertexAttribute(Usage.TextureCoordinates,  2,   "a_tex0 "));  mesh.setIndices(indices);  ObjectMap<String,  KeyframedAnimation>  animations  =  new  ObjectMap<String,  KeyframedAnimation>();  animations.put( "all ",  animation);  KeyframedSubMesh  subMesh  =  new  KeyframedSubMesh( "md2-mesh ",  mesh,  null  /**  FIXME  **/,  animations,  GL10.GL_TRIANGLES);  KeyframedModel  model  =  new  KeyframedModel(new  KeyframedSubMesh[]  {subMesh});  model.setAnimation( "all ",  0);  model.setAnimation( "all ",  0,  false);  return  model;  }  private  float[]  buildTexCoords  (MD2Header  header,  MD2Triangle[]  triangles,  float[]  texCoords)  {  float[]  uvs  =  new  float[header.numVertices  *  2];  for  (int  i  =  0;  i  <  triangles.length;  i++)  {  MD2Triangle  triangle  =  triangles[i];  	model.setAnimation( "all ",  0,  false);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  return;  }  client.multiGet(multiGetRequest,  new  ActionListener<MultiGetResponse>()  {  public  void  onResponse(MultiGetResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  response.toXContent(builder,  request);  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices(getConcreteIndexName());  context:  public  class  DocumentActionsTests  extends  ElasticsearchIntegrationTest  {  protected  void  createIndex()  {          cluster().wipeIndices(getConcreteIndexName());          immutableCluster().wipeIndices(getConcreteIndexName());  createIndex(getConcreteIndexName());  }  protected  String  getConcreteIndexName()  {  return   "test ";  }  	immutableCluster().wipeIndices(getConcreteIndexName());  
elasticsearch_b8b4cbbb46176e7d0b3a9b9d161cbd02a0faa71e	buggy:  .mappingsCompressed(indexMetaData.mappings())  context:  .metaData(metaDataBuilder).build();  }  for  (final  IndexMetaData  indexMetaData  :  state.metaData())  {  try  {  createIndexService.createIndex(new  MetaDataCreateIndexService.Request( "gateway ",  indexMetaData.index())  .settings(indexMetaData.settings())                                  .mappingsCompressed(indexMetaData.mappings())                                  .mappingsMetaData(indexMetaData.mappings())  .state(indexMetaData.state())  .blocks(ImmutableSet.of(GatewayService.INDEX_NOT_RECOVERED_BLOCK))  .timeout(timeValueSeconds(30)),  new  MetaDataCreateIndexService.Listener()  {  if  (indicesCounter.decrementAndGet()  ==  0)  {  listener.onSuccess();  	.mappingsMetaData(indexMetaData.mappings())  
elasticsearch_48ca7b874d8e1838764823e2f6a9fa837f1ceab4	buggy:  nodeIndexDeletedAction.nodeIndexStoreDeleted(current.index(),  event.state().nodes().masterNodeId());  context:  for  (IndexMetaData  current  :  currentMetaData)  {  if  (danglingIndices.containsKey(current.index()))  {  continue;  }  if  (!newMetaData.hasIndex(current.index()))  {  if  (nodeEnv.hasNodeFile())  {  FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(current.index())));  }  try  {                          nodeIndexDeletedAction.nodeIndexStoreDeleted(current.index(),  event.state().nodes().masterNodeId());                          nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  current.index(),  event.state().nodes().localNodeId());  }  catch  (Throwable  e)  {  }  }  }  }  	nodeIndexDeletedAction.nodeIndexStoreDeleted(event.state(),  current.index(),  event.state().nodes().localNodeId());  
elasticsearch_8b295b53d0ec023e3a71448bf33050f60c00f123	buggy:  shard.refresh(new  Engine.Refresh(true));  context:  }  }  private  boolean  hasPercolatorType(IndexShard  indexShard)  {  ShardId  otherShardId  =  indexShard.shardId();  return  shardId.equals(otherShardId)  &&  mapperService.hasMapping(PercolatorService.Constants.TYPE_NAME);  }  private  void  loadQueries(IndexShard  shard)  {  try  {                  shard.refresh(new  Engine.Refresh(true));                  shard.refresh(new  Engine.Refresh().force(true));  Engine.Searcher  searcher  =  shard.searcher();  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.Constants.TYPE_NAME))  )  );  QueriesLoaderCollector  queries  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  	shard.refresh(new  Engine.Refresh().force(true));  
libgdx_27fe2140b061d2fbc6ece654d264901bac9d5fc7	buggy:  if(peripheral  ==  Peripheral.MultitouchScreen)  return  touchHandler  instanceof  AndroidMultiTouchHandler;  context:  updateOrientation();  return  roll;  }  if(peripheral  ==  Peripheral.Accelerometer)  return  accelerometerAvailable;  if(peripheral  ==  Peripheral.Compass)  return  compassAvailable;  if(peripheral  ==  Peripheral.HardwareKeyboard)  return  keyboardAvailable;  if(peripheral  ==  Peripheral.OnscreenKeyboard)  return  true;  if(peripheral  ==  Peripheral.Vibrator)  return  vibrator  !=  null;  if(peripheral  ==  Peripheral.MultitouchScreen)  return  touchHandler  instanceof  AndroidMultiTouchHandler;  if(peripheral  ==  Peripheral.MultitouchScreen)  return  hasMultitouch;  return  false;  }  }  	if(peripheral  ==  Peripheral.MultitouchScreen)  return  hasMultitouch;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicArray<MultiSearchResponse.Item>  responses  =  new  AtomicArray<MultiSearchResponse.Item>(request.requests().size());  context:  this.searchAction  =  searchAction;  transportService.registerHandler(MultiSearchAction.NAME,  new  TransportHandler());  }  protected  void  doExecute(final  MultiSearchRequest  request,  final  ActionListener<MultiSearchResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();  clusterState.blocks().globalBlockedRaiseException(ClusterBlockLevel.READ);          final  AtomicArray<MultiSearchResponse.Item>  responses  =  new  AtomicArray<MultiSearchResponse.Item>(request.requests().size());          final  AtomicArray<MultiSearchResponse.Item>  responses  =  new  AtomicArray<>(request.requests().size());  final  AtomicInteger  counter  =  new  AtomicInteger(responses.length());  for  (int  i  =  0;  i  <  responses.length();  i++)  {  final  int  index  =  i;  searchAction.execute(request.requests().get(i),  new  ActionListener<SearchResponse>()  {  public  void  onResponse(SearchResponse  searchResponse)  {  responses.set(index,  new  MultiSearchResponse.Item(searchResponse,  null));  if  (counter.decrementAndGet()  ==  0)  {  	final  AtomicArray<MultiSearchResponse.Item>  responses  =  new  AtomicArray<>(request.requests().size());  
elasticsearch_7e341cefd0051163b6d0e6e539a95ff622f9df27	buggy:  percolateRequestBuilder.setSort(true).setSize(numQueries);  context:  percolateRequestBuilder.addFacet(FacetBuilders.termsFacet( "a ").field( "field2 "));  }  if  (randomBoolean())  {  percolateRequestBuilder.setPercolateQuery(matchAllQuery());  }  if  (randomBoolean())  {  percolateRequestBuilder.setScore(true);  }  else  {                  percolateRequestBuilder.setSort(true).setSize(numQueries);                  percolateRequestBuilder.setSortByScore(true).setSize(numQueries);  }  boolean  countOnly  =  randomBoolean();  if  (countOnly)  {  percolateRequestBuilder.setOnlyCount(countOnly);  }  PercolateResponse  response  =  percolateRequestBuilder.execute().actionGet();  	percolateRequestBuilder.setSortByScore(true).setSize(numQueries);  
elasticsearch_720954d8a699d773dbbcb893e304972287394aa5	buggy:  System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   "JVM:   "  +  JvmInfo.jvmInfo().vmVersion());  context:  sb.append(major).append('.').append(minor).append('.').append(revision);  if  (build  <  50)  {  sb.append( ".Beta ").append(build);  }  else  if  (build  <  99)  {  sb.append( ".RC ").append(build  -  50);  }  return  sb.toString();  }  public  static  void  main(String[]  args)  {          System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   "JVM:   "  +  JvmInfo.jvmInfo().vmVersion());          System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().vmVersion());  }  StringBuilder  sb  =  new  StringBuilder();  sb.append(number());  if  (snapshot())  {  sb.append( "-SNAPSHOT ");  }  	System.out.println( "ElasticSearch  Version:   "  +  Version.CURRENT  +   ",  JVM:   "  +  JvmInfo.jvmInfo().vmVersion());  
elasticsearch_2bb31fe74037a7ee2a04c9a994bc4bacbc8e8102	buggy:  return  new  TermsResponse(successfulShards,  failedShards,  shardFailures,  resultFreqs,  numDocs,  maxDoc,  numDeletedDocs);  context:  }  }  }  FieldTermsFreq[]  resultFreqs  =  new  FieldTermsFreq[fieldTermsFreqs.size()];  int  index  =  0;  for  (Map.Entry<String,  NavigableSet<TermFreq>>  entry  :  fieldTermsFreqs.entrySet())  {  TermFreq[]  freqs  =  entry.getValue().toArray(new  TermFreq[entry.getValue().size()]);  resultFreqs[index++]  =  new  FieldTermsFreq(entry.getKey(),  freqs);  }          return  new  TermsResponse(successfulShards,  failedShards,  shardFailures,  resultFreqs,  numDocs,  maxDoc,  numDeletedDocs);          return  new  TermsResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,  resultFreqs,  numDocs,  maxDoc,  numDeletedDocs);  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  shard  =  indexService.shard(request.shardId());  Engine.Searcher  searcher  =  shard.searcher();  ShardTermsResponse  response  =  new  ShardTermsResponse(request.index(),  request.shardId(),  	return  new  TermsResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,  resultFreqs,  numDocs,  maxDoc,  numDeletedDocs);  
elasticsearch_28f56262bc3667dc7c990e927344565479525d24	buggy:  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  ((InternalIndexShard)  indexShard).mergeScheduler().stats().current()  ==  0)  {  context:  continue;  }  if  (status.translogId  ==  translog.currentId()  &&  translog.estimatedNumberOfOperations()  ==  0)  {  if  (status.time  ==  -1)  {  //  first  time  status.time  =  time;  }  if  (!status.inactive)  {                                  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  ((InternalIndexShard)  indexShard).mergeScheduler().stats().current()  ==  0)  {                                  if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().current()  ==  0)  {  try  {  ((InternalIndexShard)  indexShard).engine().updateIndexingBufferSize(Engine.INACTIVE_SHARD_INDEXING_BUFFER);  }  catch  (EngineClosedException  e)  {  continue;  }  catch  (FlushNotAllowedEngineException  e)  {  continue;  	if  ((time  -  status.time)  >  inactiveTime.millis()  &&  indexShard.mergeStats().current()  ==  0)  {  
elasticsearch_e735ff49d69951c756db260967cc2527869ed18c	buggy:  ImmutableSettings.Builder  settingsBuilder  =  settingsBuilder().putAll(settings);  context:  .put( "ttcc ",   "org.apache.log4j.TTCCLayout ")  .put( "xml ",   "org.apache.log4j.XMLLayout ")  .immutableMap();  public  static  void  configure(Settings  settings)  {  if  (loaded)  {  return;  }  loaded  =  true;  Environment  environment  =  new  Environment(settings);          ImmutableSettings.Builder  settingsBuilder  =  settingsBuilder().putAll(settings);          ImmutableSettings.Builder  settingsBuilder  =  settingsBuilder().put(settings);  try  {  settingsBuilder.loadFromUrl(environment.resolveConfig( "logging.yml "));  }  catch  (FailedToResolveConfigException  e)  {  }  catch  (NoClassDefFoundError  e)  {  }  try  {  	ImmutableSettings.Builder  settingsBuilder  =  settingsBuilder().put(settings);  
elasticsearch_2c2cc844dc79671cbe74cb8e2bf23dd684a7dff0	buggy:  DirectoryReader  reader  =  IndexReader.open(indexWriter,  true);  context:  public  void  testNoCache()  throws  Exception  {  verifyCache(new  NoneFilterCache(new  Index( "test "),  EMPTY_SETTINGS));  }  private  void  verifyCache(FilterCache  filterCache)  throws  Exception  {  Directory  dir  =  new  RAMDirectory();  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));          DirectoryReader  reader  =  IndexReader.open(indexWriter,  true);          DirectoryReader  reader  =  DirectoryReader.open(indexWriter,  true);  for  (int  i  =  0;  i  <  100;  i++)  {  Document  document  =  new  Document();  document.add(new  TextField( "id ",  Integer.toString(i),  Field.Store.YES));  indexWriter.addDocument(document);  }  reader  =  refreshReader(reader);  	DirectoryReader  reader  =  DirectoryReader.open(indexWriter,  true);  
libgdx_9e0c03b6f617f1efb3bfba507f40031b1b362164	buggy:  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/stone2.png "));  context:  int  width  =  0;  int  height  =  0;  public  void  load()  {  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/stone2.png "));  Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/t8890.png "));  Gdx.gl.glTexImage2D(GL10.GL_TEXTURE_2D,  0,  pixmap.getGLInternalFormat(),  pixmap.getWidth(),  pixmap.getHeight(),  0,  pixmap.getGLFormat(),  pixmap.getGLType(),  pixmap.getPixels());  width  =  pixmap.getWidth();  height  =  pixmap.getHeight();  pixmap.dispose();  }  public  int  getWidth()  {  return  width;  	Pixmap  pixmap  =  new  Pixmap(Gdx.files.internal( "data/t8890.png "));  
elasticsearch_5706858722452b13465b15930e4f4cb2e8286449	buggy:  GetResult  getResult  =  indexShard.getService().get(result,  request.id(),  request.type(),  request.fields(),  request.fetchSourceContext());  context:  int  topLevelDocId  =  result.docIdAndVersion().docId  +  result.docIdAndVersion().context.docBase;  Explanation  explanation  =  context.searcher().explain(context.query(),  topLevelDocId);  for  (RescoreSearchContext  ctx  :  context.rescore())  {  Rescorer  rescorer  =  ctx.rescorer();  explanation  =  rescorer.explain(topLevelDocId,  context,  ctx,  explanation);  }  if  (request.fields()  !=  null  ||  (request.fetchSourceContext()  !=  null  &&  request.fetchSourceContext().fetchSource()))  {                  GetResult  getResult  =  indexShard.getService().get(result,  request.id(),  request.type(),  request.fields(),  request.fetchSourceContext());                  GetResult  getResult  =  indexShard.getService().get(result,  request.id(),  request.type(),  request.fields(),  request.fetchSourceContext(),  false);  return  new  ExplainResponse(true,  explanation,  getResult);  }  else  {  return  new  ExplainResponse(true,  explanation);  }  }  catch  (IOException  e)  {  throw  new  ElasticsearchException( "Could  not  explain ",  e);  }  finally  {  context.close();  	GetResult  getResult  =  indexShard.getService().get(result,  request.id(),  request.type(),  request.fields(),  request.fetchSourceContext(),  false);  
elasticsearch_d9979f8dfeceb3ef31e38fa74f928514c17c44c7	buggy:  shardInjector.getInstance(Translog.class).close();  context:  }  catch  (Exception  e)  {  }  try  {  shardInjector.getInstance(IndexShardGatewayService.class).close(deleteGateway);  }  catch  (Exception  e)  {  }  try  {              shardInjector.getInstance(Translog.class).close();              shardInjector.getInstance(Translog.class).close(delete);  }  catch  (Exception  e)  {  }  indicesLifecycle.afterIndexShardClosed(sId,  delete);  	shardInjector.getInstance(Translog.class).close(delete);  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  }  else  {  responses.put(pingResponse.target(),  pingResponse);  }  }  }  finally  {  latch.countDown();  }  }                  @Override  public  void  handleException(RemoteTransportException  exp)  {                  @Override  public  void  handleException(TransportException  exp)  {  latch.countDown();  if  (exp  instanceof  ConnectTransportException)  {  }  else  {  if  (disconnect)  {  transportService.disconnectFromNode(nodeToSend);  }  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);  context:  }  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.indicesOptions());  blockException  =  checkRequestBlock(clusterState,  request,  concreteIndices);  if  (blockException  !=  null)  {  throw  blockException;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);          final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);          final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  final  long  startTimeInMillis  =  System.currentTimeMillis();  Map<String,  Set<String>>  routingMap  =  resolveRouting(clusterState,  request);  if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {  listener.onResponse(newResponseInstance(request,  indexResponses));  }  else  {  for  (final  String  index  :  concreteIndices)  {  Set<String>  routing  =  null;  	final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(metaData.concreteSingleIndex(request.index()));  context:  });  }  else  {  innerExecute(request,  listener);  }  }  protected  boolean  resolveRequest(ClusterState  state,  IndexRequest  request,  ActionListener<IndexResponse>  indexResponseActionListener)  {  MetaData  metaData  =  clusterService.state().metaData();  String  aliasOrIndex  =  request.index();          request.index(metaData.concreteSingleIndex(request.index()));          request.index(metaData.concreteSingleIndex(request.index(),  request.indicesOptions()));  MappingMetaData  mappingMd  =  null;  if  (metaData.hasIndex(request.index()))  {  mappingMd  =  metaData.index(request.index()).mappingOrDefault(request.type());  }  request.process(metaData,  aliasOrIndex,  mappingMd,  allowIdGeneration);  return  true;  }  	request.index(metaData.concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_5e9e2cf50c8eba23f7f1f99b47c95e54e8c51904	buggy:  +   "  to:   "  +  to  +   "target  file  already  exists ");  context:  public  void  renameFile(DirectoryService  directoryService,  String  from,  String  to)  throws  IOException  {  Directory  directory  =  getDirectory(from);  if  (nameDirMapping.putIfAbsent(to,  directory)  !=  null)  {  throw  new  IOException( "Can't  rename  file  from   "  +  from                      +   "  to:   "  +  to  +   "target  file  already  exists ");                      +   "  to:   "  +  to  +   ":  target  file  already  exists ");  }  boolean  success  =  false;  try  {  directoryService.renameFile(directory,  from,  to);  nameDirMapping.remove(from);  success  =  true;  }  finally  {  if  (!success)  {  	+   "  to:   "  +  to  +   ":  target  file  already  exists ");  
elasticsearch_7924115b907c55fa689f6e37d3d58f2098f5dc05	buggy:  .add(updatedState.metaData().index(request.index),  false);  context:  MetaData.Builder  mdBuilder  =  MetaData.builder()  .metaData(currentState.metaData())  .put(IndexMetaData.newIndexMetaDataBuilder(currentState.metaData().index(request.index)).state(IndexMetaData.State.OPEN));  ClusterBlocks.Builder  blocks  =  ClusterBlocks.builder().blocks(currentState.blocks())  .removeIndexBlock(request.index,  INDEX_CLOSED_BLOCK);  ClusterState  updatedState  =  ClusterState.builder().state(currentState).metaData(mdBuilder).blocks(blocks).build();  RoutingTable.Builder  rtBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable())                          .add(updatedState.metaData().index(request.index),  false);                          .addAsRecovery(updatedState.metaData().index(request.index));  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).routingTable(rtBuilder).build());  return  ClusterState.builder().state(updatedState).routingResult(routingResult).build();  }  public  void  clusterStateProcessed(ClusterState  clusterState)  {  	.addAsRecovery(updatedState.metaData().index(request.index));  
elasticsearch_237e936884f326585c141af483814eb533dc9ee9	buggy:  return  false;  context:  }  else  if  (consistencyLevel  ==  WriteConsistencyLevel.ALL)  {  requiredNumber  =  shardIt.size();  }  if  (shardIt.sizeActive()  <  requiredNumber)  {  retry(fromClusterEvent,  shard.shardId());  return  false;  }  }  if  (!primaryOperationStarted.compareAndSet(false,  true))  {                      return  false;                      return  true;  }  foundPrimary  =  true;  if  (shard.currentNodeId().equals(nodes.localNodeId()))  {  if  (request.operationThreaded())  {  request.beforeLocalFork();  threadPool.execute(new  Runnable()  {  	return  true;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<InternalSignificantTerms.Bucket>(size);  context:  public  void  readFrom(StreamInput  in)  throws  IOException  {  this.name  =  in.readString();  this.valueFormatter  =  ValueFormatterStreams.readOptional(in);  this.requiredSize  =  readSize(in);  this.minDocCount  =  in.readVLong();  this.subsetSize  =  in.readVLong();  this.supersetSize  =  in.readVLong();  int  size  =  in.readVInt();          List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<InternalSignificantTerms.Bucket>(size);          List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<>(size);  for  (int  i  =  0;  i  <  size;  i++)  {  long  subsetDf  =  in.readVLong();  long  supersetDf  =  in.readVLong();  long  term  =  in.readLong();  buckets.add(new  Bucket(subsetDf,  subsetSize,  supersetDf,supersetSize,  term,  InternalAggregations.readAggregations(in)));  }  this.buckets  =  buckets;  this.bucketMap  =  null;  	List<InternalSignificantTerms.Bucket>  buckets  =  new  ArrayList<>(size);  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  private  final  DataOutputStreamOutput  out;  public  HdfsAppendableBlob(Path  file)  throws  IOException  {  this.file  =  file;  this.fsDataStream  =  blobStore.fileSystem().create(file,  true);  this.out  =  new  DataOutputStreamOutput(fsDataStream);  }              blobStore.executorService().execute(new  Runnable()  {              blobStore.executor().execute(new  Runnable()  {  try  {  listener.withStream(out);  out.flush();  fsDataStream.flush();  fsDataStream.sync();  listener.onCompleted();  }  catch  (IOException  e)  {  	blobStore.executor().execute(new  Runnable()  {  
elasticsearch_6fc0b83e0746e98feb07307ddccace864e7ff18a	buggy:  Geometry  geometry  =  ((JtsGeometry)  shape).geo;  context:  public  static  void  serialize(Shape  shape,  XContentBuilder  builder)  throws  IOException  {  if  (shape  instanceof  JtsGeometry)  {              Geometry  geometry  =  ((JtsGeometry)  shape).geo;              Geometry  geometry  =  ((JtsGeometry)  shape).getGeom();  if  (geometry  instanceof  Point)  {  serializePoint((Point)  geometry,  builder);  }  else  if  (geometry  instanceof  LineString)  {  serializeLineString((LineString)  geometry,  builder);  }  else  if  (geometry  instanceof  Polygon)  {  serializePolygon((Polygon)  geometry,  builder);  }  else  if  (geometry  instanceof  MultiPoint)  {  serializeMultiPoint((MultiPoint)  geometry,  builder);  	Geometry  geometry  =  ((JtsGeometry)  shape).getGeom();  
elasticsearch_5c085c12049094f90a7171baf47f948348fb058e	buggy:  assert  false  :   "AVG  has  it's  own  collector ";  context:  if  (uidToScore.containsKey(parentUid))  {  float  previousScore  =  uidToScore.lget();  if  (currentScore  >  previousScore)  {  uidToScore.lset(currentScore);  }  }  else  {  uidToScore.put(parentUid,  currentScore);  }  break;  case  AVG:                      assert  false  :   "AVG  has  it's  own  collector ";                      assert  false  :   "AVG  has  its  own  collector ";  default:  assert  false  :   "Are  we  missing  a  score  type  here?  --   "  +  scoreType;  break;  }  }  }  	assert  false  :   "AVG  has  its  own  collector ";  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  PercolateShardRequest(shard.index(),  shard.id(),  numShards,  request);  context:  }  }  protected  PercolateShardRequest  newShardRequest()  {  return  new  PercolateShardRequest();  }  protected  PercolateShardRequest  newShardRequest(int  numShards,  ShardRouting  shard,  PercolateRequest  request)  {          return  new  PercolateShardRequest(shard.index(),  shard.id(),  numShards,  request);          return  new  PercolateShardRequest(shard.shardId(),  numShards,  request);  }  protected  PercolateShardResponse  newShardResponse()  {  return  new  PercolateShardResponse();  }  	return  new  PercolateShardRequest(shard.shardId(),  numShards,  request);  
libgdx_8a28ffbd8419d885c07da59e3356aa47cfe0a5fd	buggy:  classifyVertex(earTipIndex);  context:  while  (vertexCount  >  3)  {  int  earTipIndex  =  findEarTip();  cutEarTip(earTipIndex);  classifyVertex(computePreviousIndex(earTipIndex));  classifyVertex(earTipIndex);  classifyVertex(earTipIndex  ==  vertexCount  ?  0  :  earTipIndex);  }  if  (vertexCount  ==  3)  {  triangles.addAll(vertices);  	classifyVertex(earTipIndex  ==  vertexCount  ?  0  :  earTipIndex);  
elasticsearch_4180a7f73ab4d32f001a1d0bdc17aebd3073be76	buggy:  RoutingNode  routingNode  =  new  RoutingNode(node.id());  context:  private  void  applyNewNodes(RoutingNodes  routingNodes,  Iterable<DiscoveryNode>  liveNodes)  {  for  (DiscoveryNode  node  :  liveNodes)  {  if  (!routingNodes.nodesToShards().containsKey(node.id()))  {                  RoutingNode  routingNode  =  new  RoutingNode(node.id());                  RoutingNode  routingNode  =  new  RoutingNode(node);  routingNodes.nodesToShards().put(node.id(),  routingNode);  }  }  }  private  boolean  deassociateDeadNodes(RoutingNodes  routingNodes,  Iterable<DiscoveryNode>  liveNodes)  {  boolean  changed  =  false;  Set<String>  liveNodeIds  =  newHashSet();  	RoutingNode  routingNode  =  new  RoutingNode(node);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e1)  {  context:  public  void  onResponse(CreateIndexResponse  result)  {  innerExecute(request,  listener);  }  public  void  onFailure(Throwable  e)  {  if  (ExceptionsHelper.unwrapCause(e)  instanceof  IndexAlreadyExistsException)  {  try  {  innerExecute(request,  listener);                          }  catch  (Exception  e1)  {                          }  catch  (Throwable  e1)  {  listener.onFailure(e1);  }  }  else  {  listener.onFailure(e);  }  }  });  }  else  {  	}  catch  (Throwable  e1)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  }  protected  DeleteWarmerResponse  newResponse()  {  return  new  DeleteWarmerResponse();  }  protected  void  doExecute(DeleteWarmerRequest  request,  ActionListener<DeleteWarmerResponse>  listener)  {          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(DeleteWarmerRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  	request.indices(clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_c1ca21f4d5b683ad03180fa7e5b8673c51221aee	buggy:  Directory  build()  throws  IOException;  context:  package  org.elasticsearch.index.store;  public  interface  DirectoryService  {      Directory  build()  throws  IOException;      Directory[]  build()  throws  IOException;  void  renameFile(Directory  dir,  String  from,  String  to)  throws  IOException;  void  fullDelete(Directory  dir)  throws  IOException;  }  	Directory[]  build()  throws  IOException;  
elasticsearch_fe50a6f64e59fa84aa270388217fcba67dc6f1a8	buggy:  changed  |=  preferUnallocatedShardUnassignedStrategy.allocateUnassigned(routingNodes);  context:  applyNewNodes(routingNodes,  dataNodes);  changed  |=  electPrimaries(routingNodes);  if  (routingNodes.hasUnassigned())  {  if  (preferUnallocatedShardUnassignedStrategy  !=  null)  {                  changed  |=  preferUnallocatedShardUnassignedStrategy.allocateUnassigned(routingNodes);                  changed  |=  preferUnallocatedShardUnassignedStrategy.allocateUnassigned(routingNodes,  nodes);  }  changed  |=  allocateUnassigned(routingNodes);  changed  |=  electPrimaries(routingNodes);  }  changed  |=  rebalance(routingNodes);  	changed  |=  preferUnallocatedShardUnassignedStrategy.allocateUnassigned(routingNodes,  nodes);  
libgdx_57818538a4bb62dfdc944b3aa81eb26a366df801	buggy:  cam.position.set(bounds.getCenter().cpy().add(len*2,  len*2,  len*2));  context:  if(fileName.endsWith( ".dae "))  model  =  ColladaLoader.loadStillModel(Gdx.files.internal(fileName));  else  throw  new  GdxRuntimeException( "Unknown  file  format  ' "  +  fileName  +   "' ");  if(textureFileName  !=  null)  texture  =  new  Texture(Gdx.files.internal(textureFileName));  hasNormals  =  hasNormals();  model.getBoundingBox(bounds);  float  len  =  bounds.getDimensions().len();  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(bounds.getCenter().cpy().add(len*2,  len*2,  len*2));  cam.position.set(bounds.getCenter().cpy().add(len,  len,  len));  cam.lookAt(bounds.getCenter().x,  bounds.getCenter().y,  bounds.getCenter().z);  cam.near  =  0.1f;  cam.far  =  1000;  renderer  =  new  ImmediateModeRenderer();  }  private  boolean  hasNormals()  {  	cam.position.set(bounds.getCenter().cpy().add(len,  len,  len));  
libgdx_36db44ba11e8c272ff4a37a92dc463760de6b985	buggy:  Actor  hit  =  actor.hit(x,  y);  context:  }  public  void  drag  (InputEvent  event,  float  x,  float  y,  int  pointer)  {  }  public  void  dragStop  (InputEvent  event,  float  x,  float  y,  int  pointer)  {  }  public  boolean  isOver  (Actor  actor,  float  x,  float  y)  {  Actor  hit  =  actor.hit(x,  y);  Actor  hit  =  actor.hit(x,  y,  true);  if  (hit  ==  null  ||  !hit.isDescendant(actor))  {  if  (touchDownX  ==  -1  &&  touchDownY  ==  -1)  return  false;  return  Math.abs(x  -  touchDownX)  <  tapSquareSize  &&  Math.abs(y  -  touchDownY)  <  tapSquareSize;  }  return  true;  }  	Actor  hit  =  actor.hit(x,  y,  true);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray(),  false);  context:  DiscoveryNodes  nodes  =  DiscoveryNodes.newNodesBuilder().put(newNode( "node1 ")).put(newNode( "node2 ")).put(newNode( "node3 ")).build();  ClusterState  clusterState  =  newClusterStateBuilder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();  AllocationService  strategy  =  new  AllocationService();  RoutingTable  source  =  strategy.reroute(clusterState).routingTable();  BytesStreamOutput  outStream  =  new  BytesStreamOutput();  RoutingTable.Builder.writeTo(source,  outStream);          BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.copiedByteArray(),  false);          BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.bytes().toBytes(),  false);  RoutingTable  target  =  RoutingTable.Builder.readFrom(inStream);  assertThat(target.prettyPrint(),  equalTo(source.prettyPrint()));  }  private  DiscoveryNode  newNode(String  nodeId)  {  return  new  DiscoveryNode(nodeId,  DummyTransportAddress.INSTANCE);  }  	BytesStreamInput  inStream  =  new  BytesStreamInput(outStream.bytes().toBytes(),  false);  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.intToPrefixCoded(intValue,  precisionStep(),  bytesRef);  context:  if  (value  instanceof  BytesRef)  {  return  Numbers.bytesToFloat((BytesRef)  value);  }  return  Float.parseFloat(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  int  intValue  =  NumericUtils.floatToSortableInt(parseValue(value));  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.intToPrefixCoded(intValue,  precisionStep(),  bytesRef);          NumericUtils.intToPrefixCoded(intValue,  0,  bytesRef);    //  0  because  of  exact  match  return  bytesRef;  }  private  float  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).floatValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.intToPrefixCoded(intValue,  0,  bytesRef);      //  0  because  of  exact  match  
elasticsearch_a3af3d2f47590c859cac1dbc9f6fa273fc6bbd22	buggy:  if  (Queries.isMatchAllQuery(query))  {  context:  return  Queries.NO_MATCH_QUERY;  }  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }          if  (Queries.isMatchAllQuery(query))  {          if  (Queries.isConstantMatchAllQuery(query))  {  Query  q  =  new  DeletionAwareConstantScoreQuery(filter);  q.setBoost(boost);  return  q;  }  	if  (Queries.isConstantMatchAllQuery(query))  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  }  client.admin().indices().typesExists(typesExistsRequest,  new  ActionListener<TypesExistsResponse>()  {  public  void  onResponse(TypesExistsResponse  response)  {  try  {  if  (response.isExists())  {  channel.sendResponse(new  StringRestResponse(OK));  }  else  {  channel.sendResponse(new  StringRestResponse(NOT_FOUND));  }                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  StringRestResponse(ExceptionsHelper.status(e)));  	}  catch  (Throwable  e)  {  
libgdx_38f3a6e681f806da6ce882db8b369b7737b9a338	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.VertexBufferObjectShaderTest(),   "Debug  Test ",  480,  320,  true  );  context:  ++  libgdx_38f3a6e681f806da6ce882db8b369b7737b9a338_836.java  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.VertexBufferObjectShaderTest(),   "Debug  Test ",  480,  320,  true  );  new  JoglApplication(  new  com.badlogic.gdx.tests.MeshTest(),   "Debug  Test ",  480,  320,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.MeshTest(),   "Debug  Test ",  480,  320,  false  );  
elasticsearch_90bd82ac5082dcc22ab40df3e8464f60e2f99d02	buggy:  Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  topScorer,  acceptDocs);  context:  return  sum;  }  public  void  normalize(float  norm,  float  topLevelBoost)  {  subQueryWeight.normalize(norm,  topLevelBoost  *  getBoost());  }  public  Scorer  scorer(AtomicReaderContext  context,  boolean  scoreDocsInOrder,  boolean  topScorer,  Bits  acceptDocs)  throws  IOException  {              Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  topScorer,  acceptDocs);              Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  false,  acceptDocs);  if  (subQueryScorer  ==  null)  {  return  null;  }  for  (int  i  =  0;  i  <  filterFunctions.length;  i++)  {  FilterFunction  filterFunction  =  filterFunctions[i];  filterFunction.function.setNextReader(context);  docSets[i]  =  DocIdSets.toSafeBits(context.reader(),  filterFunction.filter.getDocIdSet(context,  acceptDocs));  }  	Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  false,  acceptDocs);  
libgdx_a5a72fa9c48510ae9957d1082fc0f9188eff4066	buggy:  BuildConfig  config  =  new  BuildConfig( "gdx ",   "native ",  LIBS_DIR,  JNI_DIR);  context:  includes  =  new  String[]  {   "**/ETC1.java "  };  new  NativeCodeGenerator().generate( "src ",   "bin ",  JNI_DIR  +   "/etc1/ ",  includes,  null);  includes  =  new  String[]  {   "**/Gdx2DPixmap.java "  };  new  NativeCodeGenerator().generate( "src ",   "bin ",  JNI_DIR  +   "/gdx2d/ ",  includes,  null);  String[]  headerDirs  =  {   "./ ",   "etc1/ ",   "gdx2d/ "  };  BuildConfig  config  =  new  BuildConfig( "gdx ",   "native ",  LIBS_DIR,  JNI_DIR);  BuildConfig  config  =  new  BuildConfig( "gdx ",   "../target/native ",  LIBS_DIR,  JNI_DIR);  BuildTarget  target  =  BuildTarget.newDefaultTarget(TargetOs.Windows,  false);  target.compilerPrefix  =   " ";  target.excludeFromMasterBuildFile  =  true;  target.headerDirs  =  headerDirs;  new  AntScriptGenerator().generate(config,  target);  BuildExecutor.executeAnt(JNI_DIR  +   "/build-windows32.xml ",   "clean  link  -v ");  }  	BuildConfig  config  =  new  BuildConfig( "gdx ",   "../target/native ",  LIBS_DIR,  JNI_DIR);  
libgdx_0db3a15ee3c7c686db393cec1a940dc9ca1e11d4	buggy:  InputStream  input  =  FileHandle.class.getResourceAsStream( "/ "  +  file().getPath().replace('\\',  '/'));  context:  public  File  file  ()  {  if  (type  ==  FileType.External)  return  new  File(Gdx.files.getExternalStoragePath(),  file.getPath());  return  file;  }  public  InputStream  read  ()  {  if  (type  ==  FileType.Classpath  ||  (type  ==  FileType.Internal  &&  !file().exists())  ||  (type  ==  FileType.Local  &&  !file().exists()))  {  InputStream  input  =  FileHandle.class.getResourceAsStream( "/ "  +  file().getPath().replace('\\',  '/'));  InputStream  input  =  FileHandle.class.getResourceAsStream( "/ "  +  file.getPath().replace('\\',  '/'));  if  (input  ==  null)  throw  new  GdxRuntimeException( "File  not  found:   "  +  file  +   "  ( "  +  type  +   ") ");  return  input;  }  try  {  return  new  FileInputStream(file());  }  catch  (Exception  ex)  {  if  (file().isDirectory())  throw  new  GdxRuntimeException( "Cannot  open  a  stream  to  a  directory:   "  +  file  +   "  ( "  +  type  +   ") ",  ex);  	InputStream  input  =  FileHandle.class.getResourceAsStream( "/ "  +  file.getPath().replace('\\',  '/'));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ObjectIntOpenHashMap<String>  allocs  =  new  ObjectIntOpenHashMap<String>();  context:  table.addCell( "disk.total ",   "alias:dt,diskTotal;text-align:right;desc:total  capacity  of  all  volumes ");  table.addCell( "disk.percent ",   "alias:dp,diskPercent;text-align:right;desc:percent  disk  used ");  table.addCell( "host ",   "alias:h;desc:host  of  node ");  table.addCell( "ip ",   "desc:ip  of  node ");  table.addCell( "node ",   "alias:n;desc:name  of  node ");  table.endHeaders();  return  table;  }  private  Table  buildTable(RestRequest  request,  final  ClusterStateResponse  state,  final  NodesStatsResponse  stats)  {          final  ObjectIntOpenHashMap<String>  allocs  =  new  ObjectIntOpenHashMap<String>();          final  ObjectIntOpenHashMap<String>  allocs  =  new  ObjectIntOpenHashMap<>();  for  (ShardRouting  shard  :  state.getState().routingTable().allShards())  {  String  nodeId  =   "UNASSIGNED ";  if  (shard.assignedToNode())  {  nodeId  =  shard.currentNodeId();  }  	final  ObjectIntOpenHashMap<String>  allocs  =  new  ObjectIntOpenHashMap<>();  
elasticsearch_0f6c24d0c5bd9197de4397e5ddd1dd3edeb9b524	buggy:  return  XContentHelper.convertToMap(source.array(),  source.arrayOffset(),  source.length(),  true).v2();  context:  this.fullName  =  fullName;  this.source  =  source;  }  public  String  fullName()  {  return  fullName;  }  public  Map<String,  Object>  sourceAsMap()  {              return  XContentHelper.convertToMap(source.array(),  source.arrayOffset(),  source.length(),  true).v2();              return  XContentHelper.convertToMap(source,  true).v2();  }  public  boolean  isNull()  {  return  NULL.fullName().equals(fullName)  &&  NULL.source.length()  ==  source.length();  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  	return  XContentHelper.convertToMap(source,  true).v2();  
elasticsearch_6a0a9ff374454acfa65a01c62271af1eb864ace8	buggy:  Query  query  =  queryParser.parse(querySource).query();  context:  readAllowed();  IndexQueryParser  queryParser  =  queryParserService.defaultIndexQueryParser();  if  (queryParserName  !=  null)  {  queryParser  =  queryParserService.indexQueryParser(queryParserName);  if  (queryParser  ==  null)  {  throw  new  IndexQueryParserMissingException(queryParserName);  }  }          Query  query  =  queryParser.parse(querySource).query();          Query  query  =  queryParser.parse(querySource,  querySourceOffset,  querySourceLength).query();  query  =  filterByTypesIfNeeded(query,  types);  Engine.Searcher  searcher  =  engine.searcher();  try  {  long  count  =  Lucene.count(searcher.searcher(),  query,  minScore);  if  (logger.isTraceEnabled())  {  	Query  query  =  queryParser.parse(querySource,  querySourceOffset,  querySourceLength).query();  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iters  =  atLeast(1000);  context:  DiskUsage  du  =  new  DiskUsage( "node1 ",  100,  40);  assertThat(du.getFreeDiskAsPercentage(),  equalTo(40.0));  assertThat(du.getFreeBytes(),  equalTo(40L));  assertThat(du.getUsedBytes(),  equalTo(60L));  assertThat(du.getTotalBytes(),  equalTo(100L));  }  public  void  randomDiskUsageTest()  {          int  iters  =  atLeast(1000);          int  iters  =  scaledRandomIntBetween(1000,  10000);  for  (int  i  =  1;  i  <  iters;  i++)  {  long  total  =  between(Integer.MIN_VALUE,  Integer.MAX_VALUE);  long  free  =  between(Integer.MIN_VALUE,  Integer.MAX_VALUE);  if  (free  >  total  ||  total  <=  0)  {  try  {  new  DiskUsage( "random ",  total,  free);  fail( "should  never  reach  this ");  }  catch  (IllegalStateException  e)  {  	int  iters  =  scaledRandomIntBetween(1000,  10000);  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(terms( "terms ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  FloatArrayAtomicFieldData.SingleFixedSet(new  float[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  FloatArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  FloatArrayAtomicFieldData.SingleFixedSet(new  float[1],  0,  new  FixedBitSet(1));              return  FloatArrayAtomicFieldData.EMPTY;  }  final  TFloatArrayList  values  =  new  TFloatArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  FloatArrayAtomicFieldData.EMPTY;  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  flushRequest.operationThreading(operationThreading);  flushRequest.refresh(request.paramAsBoolean( "refresh ",  flushRequest.refresh()));  client.admin().indices().execFlush(flushRequest,  new  ActionListener<FlushResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_9a49629d17e50517de5014ee569ac693b930bb49	buggy:  logger.warn( "No  handler  found  for  action  [{}] ",  action);  context:  }  }  private  void  handleRequest(MessageEvent  event,  StreamInput  buffer,  long  requestId)  throws  IOException  {  final  String  action  =  buffer.readUTF();  final  NettyTransportChannel  transportChannel  =  new  NettyTransportChannel(transport,  action,  event.getChannel(),  requestId);  try  {  final  TransportRequestHandler  handler  =  transportServiceAdapter.handler(action);  if  (handler  ==  null)  {                  logger.warn( "No  handler  found  for  action  [{}] ",  action);                  throw  new  ActionNotFoundTransportException(action);  }  final  Streamable  streamable  =  handler.newInstance();  streamable.readFrom(buffer);  if  (handler.spawn())  {  threadPool.execute(new  Runnable()  {  try  {  handler.messageReceived(streamable,  transportChannel);  	throw  new  ActionNotFoundTransportException(action);  
elasticsearch_df5d22c7d7a5f50ba8f63e90d4678375ffe976b1	buggy:  parseMultiField(builder,  name,  node,  parserContext,  fieldName,  fieldNode);  context:  }  else  if  (fieldName.equals( "validate_lat "))  {  builder.validateLat  =  XContentMapValues.nodeBooleanValue(fieldNode);  }  else  if  (fieldName.equals( "normalize "))  {  builder.normalizeLat  =  XContentMapValues.nodeBooleanValue(fieldNode);  builder.normalizeLon  =  XContentMapValues.nodeBooleanValue(fieldNode);  }  else  if  (fieldName.equals( "normalize_lat "))  {  builder.normalizeLat  =  XContentMapValues.nodeBooleanValue(fieldNode);  }  else  if  (fieldName.equals( "normalize_lon "))  {  builder.normalizeLon  =  XContentMapValues.nodeBooleanValue(fieldNode);  }  else  {                      parseMultiField(builder,  name,  node,  parserContext,  fieldName,  fieldNode);                      parseMultiField(builder,  name,  parserContext,  fieldName,  fieldNode);  }  }  return  builder;  }  }  	parseMultiField(builder,  name,  parserContext,  fieldName,  fieldNode);  
elasticsearch_6d966837d17065aaa1e0b5bd0645af9715cd96c7	buggy:  assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "1m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));  context:  assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "1m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));  }  indexer.stop();  allowNodes( "test ",  3);  assertAcked(client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "number_of_replicas ",  1)).get());              assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "1m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));              assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "5m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));  refreshAndAssert();  iterateAssertCount(numShards,  indexer.totalIndexedDocs(),  10);  }  }  	assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout( "5m ").setWaitForGreenStatus().execute().actionGet().isTimedOut(),  equalTo(false));  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));  context:  if  (requestsByShard.isEmpty())  {  listener.onResponse(new  BulkResponse(responses.toArray(new  BulkItemResponse[responses.length()]),  System.currentTimeMillis()  -  startTime));  return;  }  final  AtomicInteger  counter  =  new  AtomicInteger(requestsByShard.size());  for  (Map.Entry<ShardId,  List<BulkItemRequest>>  entry  :  requestsByShard.entrySet())  {  final  ShardId  shardId  =  entry.getKey();  final  List<BulkItemRequest>  requests  =  entry.getValue();              BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));              BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(bulkRequest,  shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));  bulkShardRequest.replicationType(bulkRequest.replicationType());  bulkShardRequest.consistencyLevel(bulkRequest.consistencyLevel());  bulkShardRequest.timeout(bulkRequest.timeout());  shardBulkAction.execute(bulkShardRequest,  new  ActionListener<BulkShardResponse>()  {  public  void  onResponse(BulkShardResponse  bulkShardResponse)  {  for  (BulkItemResponse  bulkItemResponse  :  bulkShardResponse.getResponses())  {  responses.set(bulkItemResponse.getItemId(),  bulkItemResponse);  	BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(bulkRequest,  shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));  
elasticsearch_fef647cb92926c97107f506831bfbdc0b838e80c	buggy:  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable());  context:  blocks.addBlocks(indexMetaData);  }  ClusterState  updatedState  =  newClusterStateBuilder().state(currentState)  .blocks(blocks)  .metaData(metaDataBuilder)  .build();                      RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(updatedState.routingTable());                      RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(updatedState.routingTable());  for  (IndexMetaData  indexMetaData  :  updatedState.metaData().indices().values())  {  routingTableBuilder.addAsRecovery(indexMetaData);  }  routingTableBuilder.version(0);  RoutingAllocation.Result  routingResult  =  allocationService.reroute(newClusterStateBuilder().state(updatedState).routingTable(routingTableBuilder).build());  	RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(updatedState.routingTable());  
libgdx_d73d6cacd1e2eeded2e2b405889ae037c45976c0	buggy:  GdxTest  test  =  new  MusicTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-stb-truetype/libs/gdx-stb-truetype-natives.jar ").load( "gdx-stb-truetype ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  GdxTest  test  =  new  MusicTest();  GdxTest  test  =  new  FreeTypeTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.width  =  800;  config.height  =  480;  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  	GdxTest  test  =  new  FreeTypeTest();  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test1 ").numberOfShards(numberOfShards).numberOfReplicas(0))  .put(IndexMetaData.builder( "test2 ").numberOfShards(numberOfShards).numberOfReplicas(0))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test1 "))  .addAsNew(metaData.index( "test2 "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()  .put(newNode( "node1 ",  ImmutableMap.of( "tag1 ",   "value1 ")))  .put(newNode( "node2 ",  ImmutableMap.of( "tag1 ",   "value2 ")))).build();  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_910ad2a408af1ecc41be466ecb5c2e6f5df3779c	buggy:  if  (searchContext.sort().getSort().length  >  0)  {  context:  TopDocs  topDocs;  int  numDocs  =  searchContext.from()  +  searchContext.size();  if  (numDocs  ==  0)  {  numDocs  =  1;  }  boolean  sort  =  false;  if  (searchContext.sort()  !=  null)  {                  if  (searchContext.sort().getSort().length  >  0)  {                  if  (searchContext.sort().getSort().length  >  1)  {  sort  =  true;  }  else  {  SortField  sortField  =  searchContext.sort().getSort()[0];  if  (sortField.getType()  ==  SortField.SCORE  &&  !sortField.getReverse())  {  sort  =  false;  }  else  {  sort  =  true;  }  	if  (searchContext.sort().getSort().length  >  1)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  Object>  vars  =  new  HashMap<String,  Object>();  context:  public  class  TemplateQueryBuilderTest  extends  ElasticsearchTestCase  {  public  void  testJSONGeneration()  throws  IOException  {          Map<String,  Object>  vars  =  new  HashMap<String,  Object>();          Map<String,  Object>  vars  =  new  HashMap<>();  vars.put( "template ",   "filled ");  TemplateQueryBuilder  builder  =  new  TemplateQueryBuilder( "I  am  a  $template  string ",  vars);  XContentBuilder  content  =  XContentFactory.jsonBuilder();  content.startObject();  builder.doXContent(content,  null);  content.endObject();  content.close();  assertEquals(content.string(),   "{\ "template\ ":{\ "query\ ":\ "I  am  a  $template  string\ ",\ "params\ ":{\ "template\ ":\ "filled\ "}}} ");  	Map<String,  Object>  vars  =  new  HashMap<>();  
elasticsearch_9b5497f6cac67dbfd3e5c1cf09efbc096049c3a6	buggy:  float  functionScore  =  weights[i]  *  scores[i];  context:  expectedScore  =  1.0;  }  if  ( "max ".equals(scoreMode))  {  expectedScore  =  Float.MAX_VALUE  *  -1.0;  }  if  ( "min ".equals(scoreMode))  {  expectedScore  =  Float.MAX_VALUE;  }  for  (int  i  =  0;  i  <  weights.length;  i++)  {              float  functionScore  =  weights[i]  *  scores[i];              double  functionScore  =  (double)  weights[i]  *  scores[i];  if  ( "avg ".equals(scoreMode))  {  expectedScore  +=  functionScore;  }  else  if  ( "max ".equals(scoreMode))  {  expectedScore  =  Math.max(functionScore,  expectedScore);  }  else  if  ( "min ".equals(scoreMode))  {  expectedScore  =  Math.min(functionScore,  expectedScore);  }  else  if  ( "sum ".equals(scoreMode))  {  	double  functionScore  =  (double)  weights[i]  *  scores[i];  
libgdx_a796233dee600d6acf20bb488c15a613eb6de386	buggy:  tex2  =  new  Texture(Gdx.files.internal( "data/planet_heavyclouds.png "));  context:  new  VertexAttribute(VertexAttributes.Usage.TextureCoordinates,  2,   "a_texCoords2 "));  mesh.setVertices(new  float[]  {  -0.5f,  -0.5f,  0,  0,  1,  0,  1,  0.5f,  -0.5f,  0,  1,  1,  1,  1,  0.5f,  0.5f,  0,  1,  0,  1,  0,  0.5f,  0.5f,  0,  0,  0,  0,  0  });  mesh.setIndices(new  short[]  {  0,  1,  2,  2,  3,  0  });  tex1  =  new  Texture(Gdx.files.internal( "data/planet_earth.png "));  tex2  =  new  Texture(Gdx.files.internal( "data/planet_heavyclouds.png "));  tex2  =  new  Texture(Gdx.files.internal( "data/planet_heavyclouds.jpg "));  }  return  false;  }  }  	tex2  =  new  Texture(Gdx.files.internal( "data/planet_heavyclouds.jpg "));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalTermsStatsLongFacet.LongEntry>  longEntries  =  new  ArrayList<InternalTermsStatsLongFacet.LongEntry>(entries.v().size());  context:  }  public  InternalFacet  buildFacet(String  facetName)  {  if  (entries.v().isEmpty())  {  entries.release();  return  new  InternalTermsStatsLongFacet(facetName,  comparatorType,  size,  ImmutableList.<InternalTermsStatsLongFacet.LongEntry>of(),  missing);  }  if  (size  ==  0)  {  //  all  terms              List<InternalTermsStatsLongFacet.LongEntry>  longEntries  =  new  ArrayList<InternalTermsStatsLongFacet.LongEntry>(entries.v().size());              List<InternalTermsStatsLongFacet.LongEntry>  longEntries  =  new  ArrayList<>(entries.v().size());  boolean[]  states  =  entries.v().allocated;  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  longEntries.add((InternalTermsStatsLongFacet.LongEntry)  values[i]);  }  }  	List<InternalTermsStatsLongFacet.LongEntry>  longEntries  =  new  ArrayList<>(entries.v().size());  
elasticsearch_30c6f2fa23c9db62acdbc7d7bfb643e8182c4d67	buggy:  assertThat(clusterState.getRoutingNodes().node( "NODE_ "  +  i).shards().size(),  Matchers.anyOf(  context:  assertThat(clusterState.routingNodes().shardsWithState(ShardRoutingState.UNASSIGNED).size(),  equalTo(0));  int  shards  =  clusterState.routingNodes().shardsWithState(ShardRoutingState.STARTED).size();  assertThat(shards,  equalTo(totalNumShards));  final  int  numNodes  =  clusterState.nodes().size();  final  int  upperBound  =  (int)  Math.round(((shards  /  numNodes)  *  1.10));  final  int  lowerBound  =  (int)  Math.round(((shards  /  numNodes)  *  0.90));  for  (int  i  =  0;  i  <  nodeIdCounter;  i++)  {  if  (clusterState.getRoutingNodes().node( "NODE_ "  +  i)  ==  null)  {  continue;  }              assertThat(clusterState.getRoutingNodes().node( "NODE_ "  +  i).shards().size(),  Matchers.anyOf(              assertThat(clusterState.getRoutingNodes().node( "NODE_ "  +  i).size(),  Matchers.anyOf(  Matchers.anyOf(equalTo((shards  /  numNodes)  +  1),  equalTo((shards  /  numNodes)  -  1),  equalTo((shards  /  numNodes))),  Matchers.allOf(Matchers.greaterThanOrEqualTo(lowerBound),  Matchers.lessThanOrEqualTo(upperBound))));  }  }  private  static  final  class  RandomAllocationDecider  extends  AllocationDecider  {  private  final  Random  random;  	assertThat(clusterState.getRoutingNodes().node( "NODE_ "  +  i).size(),  Matchers.anyOf(  
elasticsearch_f40959cc304bc7d56a00a2edbaea499b17335140	buggy:  String[]  sAttrs  =  Strings.split(attributes,   "; ");  context:  }  else  {  mAttr  =  headers.get(currentCells.size()).attr;  }  }  else  {  mAttr  =  new  HashMap<String,  String>();  if  (!inHeaders)  {  mAttr.putAll(headers.get(currentCells.size()).attr);  }              String[]  sAttrs  =  Strings.split(attributes,   "; ");              String[]  sAttrs  =  Strings.splitStringToArray(attributes,  ';');  for  (String  sAttr  :  sAttrs)  {  if  (sAttr.length()  ==  0)  {  continue;  }  int  idx  =  sAttr.indexOf(':');  mAttr.put(sAttr.substring(0,  idx),  sAttr.substring(idx  +  1));  }  }  	String[]  sAttrs  =  Strings.splitStringToArray(attributes,  ';');  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  Stage  ui;  Table  container;  Skin  skin;  BitmapFont  font;  GdxTest  test;  boolean  dispose;  public  void  create  ()  {  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  container  =  new  Table();  ui.addActor(container);  container.debug();  Table  table  =  new  Table();  ScrollPane  scroll  =  new  ScrollPane(table);  container.add(scroll).expand().fill();  table.pad(10).defaults().expandX().space(4);  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_27b973830d2c65359e9a54e4d12c221d163d4de2	buggy:  indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  currentState.nodes().localNode().id());  context:  if  (aliasAction.actionType()  ==  AliasAction.Type.ADD)  {  String  filter  =  aliasAction.filter();  if  (Strings.hasLength(filter))  {  IndexService  indexService  =  indices.get(indexMetaData.index());  if  (indexService  ==  null)  {  indexService  =  indicesService.indexService(indexMetaData.index());  if  (indexService  ==  null)  {  try  {                                              indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  currentState.nodes().localNode().id());                                              indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  clusterService.localNode().id());  }  catch  (Exception  e)  {  continue;  }  indicesToClose.add(indexMetaData.index());  }  indices.put(indexMetaData.index(),  indexService);  }  	indexService  =  indicesService.createIndex(indexMetaData.index(),  indexMetaData.settings(),  clusterService.localNode().id());  
elasticsearch_5d90abf7014fdf2e5e4813a0f6a60a3a4125bd31	buggy:  multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  defaultFetchSource,  request.content(),  allowExplicitIndex);  context:  String[]  sFields  =  null;  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  sFields  =  Strings.splitStringByCommaToArray(sField);  }  FetchSourceContext  defaultFetchSource  =  FetchSourceContext.parseFromRestRequest(request);  try  {              multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  defaultFetchSource,  request.content(),  allowExplicitIndex);              multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  defaultFetchSource,  request.param( "routing "),  request.content(),  allowExplicitIndex);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  	multiGetRequest.add(request.param( "index "),  request.param( "type "),  sFields,  defaultFetchSource,  request.param( "routing "),  request.content(),  allowExplicitIndex);  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  camera.position.set(0,  2,  3).nor().mul(10);  context:  PerspectiveCamera  camera2;  OrthographicCamera  camera3;  PerspectiveCamController  controller;  Mesh  plane;  StillModel  sphere;  ImmediateModeRenderer10  renderer;  public  void  create  ()  {  camera  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  camera.position.set(0,  2,  3).nor().mul(10);  camera.position.set(0,  2,  3).nor().scl(10);  camera.lookAt(0,  0,  0);  camera2  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  camera2.position.set(-3,  2,  0);  camera2.lookAt(0,  0,  0);  camera2.near  =  0.5f;  camera2.far  =  6;  	camera.position.set(0,  2,  3).nor().scl(10);  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  count++;  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  script.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {          script.setNextReader(context.reader());          script.setNextReader(context);  }  public  Facet  facet()  {  return  new  InternalStatisticalFacet(facetName,  min,  max,  total,  sumOfSquares,  count);  }  }  	script.setNextReader(context);  
libgdx_777834757f63b7171f81abd206b1b316a39528ff	buggy:  if  (keycode  !=  Input.Keys.KEYCODE_SPACE)  return  false;  context:  sprites3[i].setRotation(angle);  sprites3[i].setScale(scale);  spriteCache.add(sprites3[i]);  }  spriteCacheID  =  spriteCache.endCache();  Gdx.input.setInputProcessor(this);  }  if  (keycode  !=  Input.Keys.KEYCODE_SPACE)  return  false;  if  (keycode  !=  Input.Keys.SPACE)  return  false;  float  scale  =  MathUtils.random(0.75f,  1.25f);  float  angle  =  MathUtils.random(1,  360);  spriteCache.beginCache(normalCacheID);  for  (int  i  =  0;  i  <  sprites2.length;  i  +=  6)  spriteCache.add(texture2,  sprites2[i],  sprites2[i  +  1],  16,  16,  32,  32,  scale,  scale,  angle,  0,  0,  32,  32,  false,  false);  for  (int  i  =  0;  i  <  sprites.length;  i  +=  6)  spriteCache.add(texture,  sprites[i],  sprites[i  +  1],  16,  16,  32,  32,  scale,  scale,  angle,  0,  0,  32,  32,  false,  false);  spriteCache.endCache();  	if  (keycode  !=  Input.Keys.SPACE)  return  false;  
elasticsearch_728e0e2a2eb4cbb93b87fc22a3e84fddea2a0635	buggy:  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {  context:  }  else  if  ( "interval ".equals(currentFieldName))  {  interval  =  parser.text();  }  else  if  ( "format ".equals(currentFieldName))  {  format  =  parser.text();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_BOOLEAN)  {  if  ( "keyed ".equals(currentFieldName))  {  keyed  =  parser.booleanValue();                  }  else  if  ( "script_values_sorted ".equals(currentFieldName))  {                  }  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  assumeSorted  =  parser.booleanValue();  }  else  {  throw  new  SearchParseException(context,   "Unknown  key  for  a   "  +  token  +   "  in  [ "  +  aggregationName  +   "]:  [ "  +  currentFieldName  +   "]. ");  }  }  else  if  (token  ==  XContentParser.Token.VALUE_NUMBER)  {  if  ( "min_doc_count ".equals(currentFieldName)  ||   "minDocCount ".equals(currentFieldName))  {  minDocCount  =  parser.longValue();  }  else  {  	}  else  if  ( "script_values_sorted ".equals(currentFieldName)  ||   "scriptValuesSorted ".equals(currentFieldName))  {  
elasticsearch_48f6df3f8e9e72e695061b39afb3f29961e9ca11	buggy:  int  shardSize  =  numberOfShards()  >  5  ?  20  :  10;  context:  .field( "float ",  (float)  i)  .field( "double ",  (double)  i)  .endObject()).execute().actionGet();  }  for  (int  i  =  0;  i  <  10;  i++)  {  client().prepareIndex( "test ",   "type ",   " "  +  (i  +  100)).setSource(jsonBuilder().startObject()  .field( "foo ",   " "  +  i)  .endObject()).execute().actionGet();  }          int  shardSize  =  numberOfShards()  >  5  ?  20  :  10;          int  shardSize  =  getNumShards( "test ").numPrimaries  >  5  ?  20  :  10;  String[]  execHint  =  new  String[]{ "map ",  null};  for  (String  hint  :  execHint)  {  flushAndRefresh();  SearchResponse  searchResponse  =  client().prepareSearch()  .setQuery(matchAllQuery())  .addFacet(termsFacet( "double ").shardSize(shardSize).executionHint(hint).field( "double ").size(10))  .addFacet(termsFacet( "float ").shardSize(shardSize).executionHint(hint).field( "float ").size(10))  	int  shardSize  =  getNumShards( "test ").numPrimaries  >  5  ?  20  :  10;  
libgdx_205f903d933663f56b903b40a450baea6c8bb324	buggy:  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.wav ",  FileType.Internal));  context:  public  class  SoundTest  extends  GdxTest  {  Sound  sound;  float  volume  =  0.5f;  long  soundId  =  0;  Stage  ui;  Skin  skin;  public  void  create  ()  {  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.wav ",  FileType.Internal));  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.mp3 ",  FileType.Internal));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  TextButton  play  =  new  TextButton( "Play ",  skin);  TextButton  stop  =  new  TextButton( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  	sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.mp3 ",  FileType.Internal));  
libgdx_57eae20f8108456a8c07d8f13ce732e837b64990	buggy:  return  cnt;  context:  public  Vector3  getCenter  ()  {  return  cnt;  }  public  Vector3  getCenter  (Vector3  out)  {  return  cnt;  return  out.set(cnt);  }  public  float  getCenterX  ()  {  return  cnt.x;  }  public  float  getCenterY  ()  {  return  cnt.y;  	return  out.set(cnt);  
elasticsearch_6678da8c2892849891d5609f6d06d9b0720c2b4d	buggy:  cluster2  =  new  TestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0);  context:  private  static  TestCluster  cluster2;  private  Node  tribeNode;  private  Client  tribeClient;  public  static  void  setupSecondCluster()  throws  Exception  {  ElasticsearchIntegrationTest.beforeClass();          cluster2  =  new  TestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0);          cluster2  =  new  TestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false);  cluster2.beforeTest(getRandom(),  0.1);  cluster2.ensureAtLeastNumDataNodes(2);  }  public  static  void  tearDownSecondCluster()  {  if  (cluster2  !=  null)  {  try  {  	cluster2  =  new  TestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false);  
libgdx_34df86db858d325c9ae6951ae9e69c2fae914be7	buggy:  for  (int  row  =  row1;  row  <  row2;  row++)  {  context:  final  int  row1  =  Math.max(0,  (int)(cacheBounds.y  /  layerTileHeight));  final  int  row2  =  Math.min(layerHeight,  (int)((cacheBounds.y  +  cacheBounds.height  +  layerTileHeight)  /  layerTileHeight));  canCacheMoreN  =  row2  <  layerHeight;  canCacheMoreE  =  col2  <  layerWidth;  canCacheMoreW  =  col1  >  0;  canCacheMoreS  =  row1  >  0;  float[]  vertices  =  this.vertices;  for  (int  row  =  row1;  row  <  row2;  row++)  {  for  (int  row  =  row2;  row  >=  row1;  row--)  {  for  (int  col  =  col1;  col  <  col2;  col++)  {  final  TiledMapTileLayer.Cell  cell  =  layer.getCell(col,  row);  if  (cell  ==  null)  continue;  final  TiledMapTile  tile  =  cell.getTile();  if  (tile  ==  null)  continue;  count++;  	for  (int  row  =  row2;  row  >=  row1;  row--)  {  
libgdx_4aaa53af08724e317a87ea1b162cc2ef0e37c289	buggy:  if  (t  >=  0  &&  t  <=  1  &&  intersection  !=  null)  intersection.set(origin).add(direction.scl(t));  context:  public  static  float  intersectLinePlane  (float  x,  float  y,  float  z,  float  x2,  float  y2,  float  z2,  Plane  plane,  Vector3  intersection)  {  Vector3  direction  =  tmp.set(x2,  y2,  z2).sub(x,  y,  z);  Vector3  origin  =  tmp2.set(x,  y,  z);  float  denom  =  direction.dot(plane.getNormal());  if  (denom  !=  0)  {  float  t  =  -(origin.dot(plane.getNormal())  +  plane.getD())  /  denom;  if  (t  >=  0  &&  t  <=  1  &&  intersection  !=  null)  intersection.set(origin).add(direction.scl(t));  if  (intersection  !=  null)  intersection.set(origin).add(direction.scl(t));  return  t;  }  else  if  (plane.testPoint(origin)  ==  Plane.PlaneSide.OnPlane)  {  if  (intersection  !=  null)  intersection.set(origin);  return  0;  }  return  -1;  }  	if  (intersection  !=  null)  intersection.set(origin).add(direction.scl(t));  
elasticsearch_10e2528cceb404165822862602eb1326ccb1fba5	buggy:  List<Object>  textsToHighlight  =  HighlightUtils.loadFieldValues(fieldMapper,  context,  hitContext);  context:  mapperHighlighterEntry  =  new  MapperHighlighterEntry(passageFormatter,  filteredQueryTerms);  }  boolean  mergeValues  =  field.numberOfFragments()  !=  0;  List<Snippet>  snippets  =  new  ArrayList<Snippet>();  int  numberOfFragments;  try  {              List<Object>  textsToHighlight  =  HighlightUtils.loadFieldValues(fieldMapper,  context,  hitContext);              List<Object>  textsToHighlight  =  HighlightUtils.loadFieldValues(fieldMapper,  context,  hitContext,  field.forceSource());  CustomPostingsHighlighter  highlighter  =  new  CustomPostingsHighlighter(mapperHighlighterEntry.passageFormatter,  textsToHighlight,  mergeValues,  Integer.MAX_VALUE-1,  field.noMatchSize());  if  (field.numberOfFragments()  ==  0)  {  highlighter.setBreakIterator(new  WholeBreakIterator());  numberOfFragments  =  1;  //1  per  value  since  we  highlight  per  value  }  else  {  numberOfFragments  =  field.numberOfFragments();  }  	List<Object>  textsToHighlight  =  HighlightUtils.loadFieldValues(fieldMapper,  context,  hitContext,  field.forceSource());  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  builder.put(file.getName(),  new  PlainBlobMetaData(file.getName(),  file.length(),  null));  context:  this.path  =  path;  }  public  ImmutableMap<String,  BlobMetaData>  listBlobs()  throws  IOException  {  File[]  files  =  path.listFiles();  if  (files  ==  null  ||  files.length  ==  0)  {  return  ImmutableMap.of();  }  ImmutableMap.Builder<String,  BlobMetaData>  builder  =  ImmutableMap.builder();  for  (File  file  :  files)  {              builder.put(file.getName(),  new  PlainBlobMetaData(file.getName(),  file.length(),  null));              builder.put(file.getName(),  new  PlainBlobMetaData(file.getName(),  file.length()));  }  return  builder.build();  }  public  boolean  deleteBlob(String  blobName)  throws  IOException  {  return  new  File(path,  blobName).delete();  }  	builder.put(file.getName(),  new  PlainBlobMetaData(file.getName(),  file.length()));  
elasticsearch_6edf3447b1bfca04fe2cdcf6bfdf3f00a69fb187	buggy:  .field( "content ",  bytes)  context:  assertThat(doc.rootDoc().getField( "file.content_length "),  notNullValue());  assertThat(doc.rootDoc().getField( "file.content_length ").numericValue().intValue(),  is(originalText.length()));  assertThat(doc.rootDoc().getField( "file.suggest "),  notNullValue());  assertThat(doc.rootDoc().getField( "file.suggest ").stringValue(),  is(originalText  +   "\n "));  doc  =  documentMapper.parse( "person ",   "1 ",  XContentFactory.jsonBuilder()  .startObject()  .startObject( "file ")                          .field( "content ",  bytes)                          .field( "_content ",  bytes)  .field( "_name ",  forcedName)  .endObject()  .endObject()  .bytes());  assertThat(doc.rootDoc().getField( "file "),  notNullValue());  assertThat(doc.rootDoc().getField( "file ").stringValue(),  is(originalText  +   "\n "));  	.field( "_content ",  bytes)  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  .indicesOptions(IndicesOptions.fromRequest(request,  IndicesOptions.strict()))  context:  controller.registerHandler(GET,   "/{index}/_settings/{name} ",  this);  controller.registerHandler(GET,   "/_settings/{name} ",  this);  controller.registerHandler(GET,   "/{index}/_setting/{name} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  String[]  names  =  request.paramAsStringArrayOrEmptyIfAll( "name ");  GetSettingsRequest  getSettingsRequest  =  new  GetSettingsRequest()  .indices(Strings.splitStringByCommaToArray(request.param( "index ")))                  .indicesOptions(IndicesOptions.fromRequest(request,  IndicesOptions.strict()))                  .indicesOptions(IndicesOptions.fromRequest(request,  IndicesOptions.strictExpandOpen()))  .names(names);  getSettingsRequest.local(request.paramAsBoolean( "local ",  getSettingsRequest.local()));  client.admin().indices().getSettings(getSettingsRequest,  new  RestBuilderListener<GetSettingsResponse>(channel)  {  public  RestResponse  buildResponse(GetSettingsResponse  getSettingsResponse,  XContentBuilder  builder)  throws  Exception  {  builder.startObject();  	.indicesOptions(IndicesOptions.fromRequest(request,  IndicesOptions.strictExpandOpen()))  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray()));  context:  HandlesStreamOutput  out  =  new  HandlesStreamOutput(bytesOut,  5);  String  lowerThresholdValue  =   "test ";  String  higherThresholdValue  =   "something  that  is  higher  than  5 ";  out.writeUTF(lowerThresholdValue);  out.writeUTF(higherThresholdValue);  out.writeInt(1);  out.writeUTF( "else ");  out.writeUTF(higherThresholdValue);  out.writeUTF(lowerThresholdValue);          HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray()));          HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray(),  false));  assertThat(in.readUTF(),  equalTo(lowerThresholdValue));  assertThat(in.readUTF(),  equalTo(higherThresholdValue));  assertThat(in.readInt(),  equalTo(1));  assertThat(in.readUTF(),  equalTo( "else "));  assertThat(in.readUTF(),  equalTo(higherThresholdValue));  assertThat(in.readUTF(),  equalTo(lowerThresholdValue));  }  }  	HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray(),  false));  
libgdx_0124e6dde9484f4cbc804ba0bd52ff308cf746b6	buggy:  ((JoglInput)Gdx.input).processEvents();  context:  synchronized  (this)  {  if  (!paused)  {  updateTimes();  synchronized  (((JoglApplication)Gdx.app).runnables)  {  List<Runnable>  runnables  =  ((JoglApplication)Gdx.app).runnables;  for(int  i  =  0;  i  <  runnables.size();  i++)  {  runnables.get(i).run();  }  runnables.clear();  }  ((JoglInput)Gdx.input).processEvents();  ((JoglInput)((JoglApplication)Gdx.app).getInput()).processEvents();  listener.render();  ((OpenALAudio)Gdx.audio).update();  }  }  }  	((JoglInput)((JoglApplication)Gdx.app).getInput()).processEvents();  
elasticsearch_b46d017e5c20538bf8f753935a80a081ed93d1fb	buggy:  responses[requestIndex]  =  new  BulkItemResponse(item.id(),  indexRequest.opType().lowercase(),  context:  }  else  {  switch  (updateResult.result.operation())  {  case  UPSERT:  case  INDEX:  IndexRequest  indexRequest  =  updateResult.request();  if  (t  instanceof  ElasticsearchException  &&  ((ElasticsearchException)  t).status()  ==  RestStatus.CONFLICT)  {  }  else  {  }                                          responses[requestIndex]  =  new  BulkItemResponse(item.id(),  indexRequest.opType().lowercase(),                                          responses[requestIndex]  =  new  BulkItemResponse(item.id(),   "update ",  new  BulkItemResponse.Failure(indexRequest.index(),  indexRequest.type(),  indexRequest.id(),  t));  break;  case  DELETE:  DeleteRequest  deleteRequest  =  updateResult.request();  if  (t  instanceof  ElasticsearchException  &&  ((ElasticsearchException)  t).status()  ==  RestStatus.CONFLICT)  {  }  else  {  	responses[requestIndex]  =  new  BulkItemResponse(item.id(),   "update ",  
elasticsearch_d0441857cd6853975d83c612bbd2778b51007db8	buggy:  logger.debug( "Loading  huspell  dictionary  [{}]... ",  locale);  context:  private  Dictionary  loadDictionary(String  locale,  Settings  nodeSettings,  Environment  env)  throws  Exception  {  if  (logger.isDebugEnabled())  {              logger.debug( "Loading  huspell  dictionary  [{}]... ",  locale);              logger.debug( "Loading  hunspell  dictionary  [{}]... ",  locale);  }  File  dicDir  =  new  File(hunspellDir,  locale);  if  (!dicDir.exists()  ||  !dicDir.isDirectory())  {  throw  new  ElasticsearchException(String.format(Locale.ROOT,   "Could  not  find  hunspell  dictionary  [%s] ",  locale));  }  nodeSettings  =  loadDictionarySettings(dicDir,  nodeSettings.getByPrefix( "indices.analysis.hunspell.dictionary. "  +  locale  +   ". "));  	logger.debug( "Loading  hunspell  dictionary  [{}]... ",  locale);  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  public  BytesValues  getBytesValues(boolean  needsHashes)  {  context:  public  long  getMemorySizeInBytes()  {  return  0;  }  public  long  getNumberUniqueValues()  {  return  0;  }          public  BytesValues  getBytesValues(boolean  needsHashes)  {          public  BytesValues  getBytesValues()  {  return  BytesValues.EMPTY;  }  public  ScriptDocValues  getScriptValues()  {  return  ScriptDocValues.EMPTY_LONGS;  }  }  	public  BytesValues  getBytesValues()  {  
libgdx_51e632aa18ecd248fdad371f82f7cb315477a042	buggy:  -  textBounds.height  -  font.getDescent()  /  2,  cursorPatch.getTotalWidth(),  textBounds.height);  context:  if  (hasSelection)  {  batch.draw(selection,  x  +  selectionX  +  background.getLeftWidth()  +  renderOffset,  y  +  textY  -  textBounds.height  -  font.getDescent()  /  2,  selectionWidth,  textBounds.height);  }  font.draw(batch,  text,  x  +  background.getLeftWidth()  +  textOffset,  y  +  textY,  visibleTextStart,  visibleTextEnd);  if  (parent.keyboardFocusedActor  ==  this)  {  blink();  if  (cursorOn)  {  cursorPatch.draw(batch,  x  +  background.getLeftWidth()  +  glyphPositions.get(cursor)  +  renderOffset  -  1,  y  +  textY  -  textBounds.height  -  font.getDescent()  /  2,  cursorPatch.getTotalWidth(),  textBounds.height);  -  textBounds.height  -  font.getDescent(),  cursorPatch.getTotalWidth(),  textBounds.height  +  font.getDescent()  /  2);  }  }  }  public  boolean  touchDown  (float  x,  float  y,  int  pointer)  {  if  (pointer  !=  0)  return  false;  parent.keyboardFocus(this);  	-  textBounds.height  -  font.getDescent(),  cursorPatch.getTotalWidth(),  textBounds.height  +  font.getDescent()  /  2);  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper);  context:  }  if  (fieldName  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  field  specified  for  range  filter ");  }  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper);                  filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper,  parseContext);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  from,  to,  includeLower,  includeUpper);  }  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(from,  to,  includeLower,  includeUpper,  parseContext);  
elasticsearch_d1d3f8c4ca39471ff551330eea508d31d9aea2ea	buggy:  channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));  context:  builder.startObject( "nodes ");  for  (NodesRestartResponse.NodeRestartResponse  nodeInfo  :  result)  {  builder.startObject(nodeInfo.node().id());  builder.field( "name ",  nodeInfo.node().name());  builder.endObject();  }  builder.endObject();  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  
elasticsearch_a4992545665bcf6af99c39c7365f6e63696c0b2e	buggy:  logger.debug( "Can  not  run  threaded  action,  exectuion  rejected  [{}]  running  on  current  thread ",  listener);  context:  public  void  run()  {  try  {  listener.onResponse(response);  }  catch  (Throwable  e)  {  listener.onFailure(e);  }  }  });  }  catch  (EsRejectedExecutionException  ex)  {                  logger.debug( "Can  not  run  threaded  action,  exectuion  rejected  [{}]  running  on  current  thread ",  listener);                  logger.debug( "Can  not  run  threaded  action,  execution  rejected  [{}]  running  on  current  thread ",  listener);  try  {  listener.onResponse(response);  }  catch  (Throwable  e)  {  listener.onFailure(e);  }  }  	logger.debug( "Can  not  run  threaded  action,  execution  rejected  [{}]  running  on  current  thread ",  listener);  
elasticsearch_269a6dfb400f662e4a63ed94a56bbc3a73590dcc	buggy:  ensureGreen( "test ");  context:  ensureYellow( "test ");  IndicesStatsResponse  indicesStatsResponse  =  client().admin().indices().prepareStats().all().get();  assertThat(indicesStatsResponse.getIndices().size(),  equalTo(1));  assertThat(indicesStatsResponse.getIndices().containsKey( "test "),  equalTo(true));  }  public  void  testMultiGet()  throws  ExecutionException,  InterruptedException  {  assertAcked(prepareCreate( "test ").addAlias(new  Alias( "alias ")));          ensureGreen( "test ");          ensureYellow( "test ");  int  numDocs  =  iterations(10,  50);  IndexRequestBuilder[]  indexRequestBuilders  =  new  IndexRequestBuilder[numDocs];  for  (int  i  =  0;  i  <  numDocs;  i++)  {  indexRequestBuilders[i]  =  client().prepareIndex( "test ",   "type ",  Integer.toString(i)).setSource( "field ",   "value "  +  Integer.toString(i));  }  indexRandom(false,  indexRequestBuilders);  	ensureYellow( "test ");  
elasticsearch_d150ac2da418d30c5cfbabe47f27cc31e6f5b397	buggy:  invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));  context:  searchCache.releaseFetchResults(fetchResults);  }  }  private  void  innerFinishHim()  {  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  dfsResults);  }              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildShardFailures()));              invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	invokeListener(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  
elasticsearch_8d867dc24c9c0a6cf964e18e9b0d4591ae0e9b5f	buggy:  return  new  JdkESLogger(prefix,  logger);  context:  public  class  JdkESLoggerFactory  extends  ESLoggerFactory  {  final  java.util.logging.Logger  logger  =  java.util.logging.Logger.getLogger(name);          return  new  JdkESLogger(prefix,  logger);          return  new  JdkESLogger(prefix,  name,  logger);  }  }  	return  new  JdkESLogger(prefix,  name,  logger);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  protected  ClusterBlockException  checkBlock(IndicesExistsRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  IndicesExistsRequest  request,  final  ClusterState  state,  final  ActionListener<IndicesExistsResponse>  listener)  throws  ElasticsearchException  {  boolean  exists;  try  {              clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions());              clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices());  exists  =  true;  }  catch  (IndexMissingException  e)  {  exists  =  false;  }  listener.onResponse(new  IndicesExistsResponse(exists));  }  }  	clusterService.state().metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  indicesAliasesRequest.addAliasAction(aliasAction);  }  else  if  (type  ==  AliasAction.Type.REMOVE)  {  indicesAliasesRequest.removeAlias(index,  alias);  }  }  }  }  }  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                  channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  return;  }  client.admin().indices().aliases(indicesAliasesRequest,  new  AcknowledgedRestResponseActionListener<IndicesAliasesResponse>(request,  channel,  logger));  }  }  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_adb5c198491fc3dce97778ed935a0c2b1efc12ea	buggy:  ((IndicesAdminClient)  client).aliasesExist(request,  listener);  context:  public  class  AliasesExistRequestBuilder  extends  BaseAliasesRequestBuilder<AliasesExistResponse,  AliasesExistRequestBuilder>  {  public  AliasesExistRequestBuilder(IndicesAdminClient  client,  String...  aliases)  {  super(client,  aliases);  }  protected  void  doExecute(ActionListener<AliasesExistResponse>  listener)  {          ((IndicesAdminClient)  client).aliasesExist(request,  listener);          client.aliasesExist(request,  listener);  }  }  	client.aliasesExist(request,  listener);  
elasticsearch_3a0f9c6ea3068e75918d62a6b546ea3e714485b3	buggy:  indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {  context:  protected  ClusterBlockException  checkBlock(DeleteIndexTemplateRequest  request,  ClusterState  state)  {  return  state.blocks().indexBlockedException(ClusterBlockLevel.METADATA,   " ");  }  protected  DeleteIndexTemplateResponse  masterOperation(DeleteIndexTemplateRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<DeleteIndexTemplateResponse>  responseRef  =  new  AtomicReference<DeleteIndexTemplateResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          indexTemplateService.removeTemplate(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {          indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {  public  void  onResponse(MetaDataIndexTemplateService.RemoveResponse  response)  {  responseRef.set(new  DeleteIndexTemplateResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	indexTemplateService.removeTemplates(new  MetaDataIndexTemplateService.RemoveRequest(request.name()),  new  MetaDataIndexTemplateService.RemoveListener()  {  
elasticsearch_bf3ebc715e9a4ff590b315f20b64c44ee33536cf	buggy:  add(new  DeleteRequest(index,  type,  id).parent(parent).versionType(versionType).routing(routing));  context:  version  =  parser.longValue();  }  else  if  ( "_version_type ".equals(currentFieldName)  ||   "_versionType ".equals(currentFieldName)  ||   "version_type ".equals(currentFieldName)  ||   "versionType ".equals(currentFieldName))  {  versionType  =  VersionType.fromString(parser.text());  }  else  if  ( "percolate ".equals(currentFieldName))  {  percolate  =  parser.textOrNull();  }  }  }  if  ( "delete ".equals(action))  {                  add(new  DeleteRequest(index,  type,  id).parent(parent).versionType(versionType).routing(routing));                  add(new  DeleteRequest(index,  type,  id).parent(parent).version(version).versionType(versionType).routing(routing));  }  else  {  nextMarker  =  findNextMarker(marker,  from,  data,  length);  if  (nextMarker  ==  -1)  {  break;  }  if  ( "index ".equals(action))  {  if  (opType  ==  null)  {  	add(new  DeleteRequest(index,  type,  id).parent(parent).version(version).versionType(versionType).routing(routing));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  hitField  =  new  InternalSearchHitField(scriptField.name(),  new  ArrayList<Object>(2));  context:  }  throw  e;  }  if  (hitContext.hit().fieldsOrNull()  ==  null)  {  hitContext.hit().fields(new  HashMap<String,  SearchHitField>(2));  }  SearchHitField  hitField  =  hitContext.hit().fields().get(scriptField.name());  if  (hitField  ==  null)  {                  hitField  =  new  InternalSearchHitField(scriptField.name(),  new  ArrayList<Object>(2));                  hitField  =  new  InternalSearchHitField(scriptField.name(),  new  ArrayList<>(2));  hitContext.hit().fields().put(scriptField.name(),  hitField);  }  hitField.values().add(value);  }  }  }  	hitField  =  new  InternalSearchHitField(scriptField.name(),  new  ArrayList<>(2));  
elasticsearch_e7a8da8236415000e0dcdeb5622eb01ab9b086d0	buggy:  indexShard.performRecoveryFinalization();  context:  InputStreamStreamInput  streamInput  =  new  InputStreamStreamInput(blob.getContent());  int  numberOfOperations  =  streamInput.readInt();  for  (int  i  =  0;  i  <  numberOfOperations;  i++)  {  operations.add(readTranslogOperation(streamInput));  }  index++;  }  currentTranslogPartToWrite  =  index;  indexShard.performRecoveryPrepareForTranslog();              indexShard.performRecoveryFinalization();              indexShard.performRecoveryFinalization(true);  return  new  RecoveryStatus.Translog(operations.size());  }  catch  (Exception  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "Failed  to  perform  recovery  of  translog ",  e);  }  }  private  Map<String,  StorageMetadata>  listAllMetadatas(String  container,  String  directory)  {  	indexShard.performRecoveryFinalization(true);  
elasticsearch_ec6fa83856654d33f5939cc6e530f6b70149b9ae	buggy:  if  (context.includeInAll(includeInAll))  {  context:  }  }  }  }  else  {  value  =  parser.textOrNull();  }  }  if  (value  ==  null)  {  return  null;  }          if  (context.includeInAll(includeInAll))  {          if  (context.includeInAll(includeInAll,  this))  {  context.allEntries().addText(names.fullName(),  value,  boost);  }  if  (!indexed()  &&  !stored())  {  context.ignoredValue(names.indexName(),  value);  return  null;  }  Field  field  =  new  Field(names.indexName(),  false,  value,  store,  index,  termVector);  field.setBoost(boost);  	if  (context.includeInAll(includeInAll,  this))  {  
elasticsearch_8c25be6dee4f4c33ed5d737b1be14b31e3de319f	buggy:  return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "] ";  context:  id  =  in.readUTF();  }  super.writeTo(out);  out.writeUTF(type);  out.writeUTF(id);  }          return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "] ";          return   "delete  {[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]} ";  }  }  	return   "delete  {[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]} ";  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  InjectableReference<T>  initializable  =  new  InjectableReference<T>(injector,  instance,  source);  context:  public  <T>  Initializable<T>  requestInjection(InjectorImpl  injector,  T  instance,  Object  source,  Set<InjectionPoint>  injectionPoints)  {  checkNotNull(source);  if  (instance  ==  null  ||  (injectionPoints.isEmpty()  &&  !injector.membersInjectorStore.hasTypeListeners()))  {  return  Initializables.of(instance);  }          InjectableReference<T>  initializable  =  new  InjectableReference<T>(injector,  instance,  source);          InjectableReference<T>  initializable  =  new  InjectableReference<>(injector,  instance,  source);  pendingInjection.put(instance,  initializable);  return  initializable;  }  	InjectableReference<T>  initializable  =  new  InjectableReference<>(injector,  instance,  source);  
elasticsearch_1eee7f381ae98744f1017ce3997798728e34c752	buggy:  builder.startObject(nodeInfo.node().id());  context:  nodesInfoRequest.listenerThreaded(false);  client.admin().cluster().nodesInfo(nodesInfoRequest,  new  ActionListener<NodesInfoResponse>()  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "cluster_name ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeInfo  nodeInfo  :  result)  {                          builder.startObject(nodeInfo.node().id());                          builder.startObject(nodeInfo.node().id(),  XContentBuilder.FieldCaseConversion.NONE);  builder.field( "name ",  nodeInfo.node().name());  builder.field( "transport_address ",  nodeInfo.node().address().toString());  builder.startObject( "attributes ");  for  (Map.Entry<String,  String>  attr  :  nodeInfo.node().attributes().entrySet())  {  builder.field(attr.getKey(),  attr.getValue());  }  	builder.startObject(nodeInfo.node().id(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_741b8dd70b5d92155f8d3eaa7feb6af07ec103ab	buggy:  }  else  if  ( "score ".equals(fieldName))  {  context:  }  }  else  if  (token.isValue())  {  if  ( "fragment_size ".equals(fieldName)  ||   "fragmentSize ".equals(fieldName))  {  field.fragmentCharSize(parser.intValue());  }  else  if  ( "number_of_fragments ".equals(fieldName)  ||   "numberOfFragments ".equals(fieldName))  {  field.numberOfFragments(parser.intValue());  }  else  if  ( "fragment_offset ".equals(fieldName)  ||   "fragmentOffset ".equals(fieldName))  {  field.fragmentOffset(parser.intValue());  }  else  if  ( "highlight_filter ".equals(fieldName)  ||   "highlightFilter ".equals(fieldName))  {  field.highlightFilter(parser.booleanValue());                                      }  else  if  ( "score ".equals(fieldName))  {                                      }  else  if  ( "order ".equals(fieldName))  {  field.scoreOrdered( "score ".equals(parser.text()));  }  }  }  fields.add(field);  }  }  }  	}  else  if  ( "order ".equals(fieldName))  {  
libgdx_b6021a23bbcf5b41d830905505367d49356decf6	buggy:  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.readFile()));  context:  buffer  =  new  byte[10000  *  ain.getFormat().getFrameSize()];  ain.close();  ain  =  null;  thread  =  new  Thread(this);  thread.setDaemon(true);  thread.start();  }  private  void  openAudioInputStream  ()  throws  UnsupportedAudioFileException,  IOException  {  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.readFile()));  ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.read()));  AudioFormat  baseFormat  =  ain.getFormat();  AudioFormat  decodedFormat  =  new  AudioFormat(AudioFormat.Encoding.PCM_SIGNED,  baseFormat.getSampleRate(),  16,  baseFormat.getChannels(),  baseFormat.getChannels()  *  2,  baseFormat.getSampleRate(),  false);  ain  =  AudioSystem.getAudioInputStream(decodedFormat,  ain);  }  	ain  =  AudioSystem.getAudioInputStream(new  BufferedInputStream(handle.read()));  
elasticsearch_e59b41398046371c7c2712d62098f8ed6ef02ef7	buggy:  NodesInfoResponse  response  =  client( "server1 ").admin().cluster().nodesInfo(nodesInfo()).actionGet();  context:  closeAllNodes();  }  startNode( "server1 ");  startNode( "server2 ");  String  server1NodeId  =  ((InternalNode)  node( "server1 ")).injector().getInstance(ClusterService.class).state().nodes().localNodeId();  String  server2NodeId  =  ((InternalNode)  node( "server2 ")).injector().getInstance(ClusterService.class).state().nodes().localNodeId();          NodesInfoResponse  response  =  client( "server1 ").admin().cluster().nodesInfo(nodesInfo()).actionGet();          NodesInfoResponse  response  =  client( "server1 ").admin().cluster().prepareNodesInfo().execute().actionGet();  assertThat(response.nodes().length,  equalTo(2));  assertThat(response.nodesMap().get(server1NodeId),  notNullValue());  assertThat(response.nodesMap().get(server2NodeId),  notNullValue());  response  =  client( "server2 ").admin().cluster().nodesInfo(nodesInfo()).actionGet();  assertThat(response.nodes().length,  equalTo(2));  assertThat(response.nodesMap().get(server1NodeId),  notNullValue());  assertThat(response.nodesMap().get(server2NodeId),  notNullValue());  	NodesInfoResponse  response  =  client( "server1 ").admin().cluster().prepareNodesInfo().execute().actionGet();  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  final  TextButton  flickBbutton  =  new  TextButton( "Flick  Scroll ",  skin.getStyle( "toggle ",  TextButtonStyle.class));  context:  }  });  Slider  slider  =  new  Slider(skin);  slider.addListener(stopTouchDown);  //  Stops  touchDown  events  from  propagating  to  the  FlickScrollPane.  table.add(slider);  table.add(new  Label(i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9  long10  long11  long12 ",  skin));  }  final  TextButton  flickBbutton  =  new  TextButton( "Flick  Scroll ",  skin.getStyle( "toggle ",  TextButtonStyle.class));  final  TextButton  flickBbutton  =  new  TextButton( "Flick  Scroll ",  skin.get( "toggle ",  TextButtonStyle.class));  flickBbutton.setChecked(true);  flickBbutton.addListener(new  ChangeListener()  {  public  void  changed  (ChangeEvent  event,  Actor  actor)  {  scroll.setFlickScroll(flickBbutton.isChecked());  }  });  container.add(scroll).expand().fill();  	final  TextButton  flickBbutton  =  new  TextButton( "Flick  Scroll ",  skin.get( "toggle ",  TextButtonStyle.class));  
libgdx_a50afa290c624ca4b37efbce80369c70b2656a22	buggy:  nextIndex  =  currentIndex;  context:  }  public  void  remove  ()  {  if  (currentIndex  ==  INDEX_ZERO  &&  map.hasZeroValue)  {  map.zeroValue  =  null;  map.hasZeroValue  =  false;  }  else  if  (currentIndex  <  0)  {  throw  new  IllegalStateException( "next  must  be  called  before  remove. ");  }  else  if  (currentIndex  >=  map.capacity)  {  map.removeStashIndex(currentIndex);  nextIndex  =  currentIndex;  nextIndex  =  currentIndex  -  1;  findNextIndex();  }  else  {  map.keyTable[currentIndex]  =  EMPTY;  map.valueTable[currentIndex]  =  null;  }  currentIndex  =  INDEX_ILLEGAL;  map.size--;  }  	nextIndex  =  currentIndex  -  1;  
elasticsearch_8989d062cd9c90956a3c8a3c03445491f2c57453	buggy:  assertThat(mgetResponse.getResponses()[1].getFailure().getMessage(),  equalTo( "routing  is  required,  but  hasn't  been  specified "));  context:  .add(new  MultiGetRequest.Item( "test ",   "test ",   "1 ").parent( "4 "))  .add(new  MultiGetRequest.Item( "test ",   "test ",   "1 "))  .execute().actionGet();  assertThat(mgetResponse.getResponses().length,  is(2));  assertThat(mgetResponse.getResponses()[0].isFailed(),  is(false));  assertThat(mgetResponse.getResponses()[0].getResponse().isExists(),  is(true));  assertThat(mgetResponse.getResponses()[1].isFailed(),  is(true));  assertThat(mgetResponse.getResponses()[1].getResponse(),  nullValue());          assertThat(mgetResponse.getResponses()[1].getFailure().getMessage(),  equalTo( "routing  is  required,  but  hasn't  been  specified "));          assertThat(mgetResponse.getResponses()[1].getFailure().getMessage(),  equalTo( "routing  is  required  for  [test]/[test]/[1] "));  }  public  void  testThatSourceFilteringIsSupported()  throws  Exception  {  createIndex( "test ");  ensureYellow();  BytesReference  sourceBytesRef  =  jsonBuilder().startObject()  	assertThat(mgetResponse.getResponses()[1].getFailure().getMessage(),  equalTo( "routing  is  required  for  [test]/[test]/[1] "));  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  assertThat(percolate.getFailedShards(),  equalTo(0));  context:  .endObject())  .setRefresh(true)  .execute().actionGet();  PercolateResponse  percolate  =  client().preparePercolate()  .setIndices( "test ").setDocumentType( "doc ")  .setSource(jsonBuilder().startObject()  .startObject( "doc ").field( "message ",   "A  new  bonsai  tree   ").endObject()  .endObject())  .execute().actionGet();          assertThat(percolate.getFailedShards(),  equalTo(0));          assertNoFailures(percolate);  assertMatchCount(percolate,  0l);  }  public  void  testNestedPercolation()  throws  IOException  {  initNestedIndexAndPercolation();  PercolateResponse  response  =  client().preparePercolate().setPercolateDoc(new  PercolateSourceBuilder.DocBuilder().setDoc(getNotMatchingNestedDoc())).setIndices( "nestedindex ").setDocumentType( "company ").get();  assertEquals(response.getMatches().length,  0);  	assertNoFailures(percolate);  
elasticsearch_d111e169a4d6aca4233ed147f75282dd5ab3bd91	buggy:  MetaData.Builder  metaDataBuilder  =  MetaData.newMetaDataBuilder().metaData(currentState.metaData());  context:  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices());  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder().routingTable(currentState.routingTable());                  MetaData.Builder  metaDataBuilder  =  MetaData.newMetaDataBuilder().metaData(currentState.metaData());                  MetaData.Builder  metaDataBuilder  =  MetaData.builder(currentState.metaData());  Set<String>  openIndices  =  Sets.newHashSet();  Set<String>  closeIndices  =  Sets.newHashSet();  for  (String  index  :  actualIndices)  {  if  (currentState.metaData().index(index).state()  ==  IndexMetaData.State.OPEN)  {  openIndices.add(index);  	MetaData.Builder  metaDataBuilder  =  MetaData.builder(currentState.metaData());  
elasticsearch_6a4f61a7d2d2555716c18d3252225fd6df04d330	buggy:  assertThat( "ClusterHealthResponse  has  timed  out  -  returned  status:  [ "  +  response.getStatus()  +   "] ",  response.isTimedOut(),  is(false));  context:  public  static  void  assertAcked(AcknowledgedRequestBuilder<?,  ?,  ?,  ?>  builder)  {  assertAcked(builder.get());  }  public  static  void  assertNoTimeout(ClusterHealthRequestBuilder  requestBuilder)  {  assertNoTimeout(requestBuilder.get());  }  public  static  void  assertNoTimeout(ClusterHealthResponse  response)  {          assertThat( "ClusterHealthResponse  has  timed  out  -  returned  status:  [ "  +  response.getStatus()  +   "] ",  response.isTimedOut(),  is(false));          assertThat( "ClusterHealthResponse  has  timed  out  -  returned:  [ "  +  response  +   "] ",  response.isTimedOut(),  is(false));  }  public  static  void  assertAcked(AcknowledgedResponse  response)  {  assertThat(response.getClass().getSimpleName()  +   "  failed  -  not  acked ",  response.isAcknowledged(),  equalTo(true));  assertVersionSerializable(response);  }  public  static  void  assertAcked(DeleteIndexRequestBuilder  builder)  {  	assertThat( "ClusterHealthResponse  has  timed  out  -  returned:  [ "  +  response  +   "] ",  response.isTimedOut(),  is(false));  
elasticsearch_cfafb52bebbd5bb50b4fc74b1aebc121a9e91548	buggy:  indexShard.refresh(true);  context:  return  new  SnapshotWrapper();  }  if  (!snapshot.phase3)  {  cleanOpenIndex();  }  indexShard.performRecovery(snapshot.snapshot,  snapshot.phase3);  if  (snapshot.phase3)  {                  indexShard.refresh(true);                  indexShard.refresh(new  Engine.Refresh(true));  }  channel.sendResponse(VoidStreamable.INSTANCE);  }  }  private  static  class  SnapshotWrapper  implements  Streamable  {  	indexShard.refresh(new  Engine.Refresh(true));  
elasticsearch_7400c30eba6f945dd8c32b447081b8e5fc5fc957	buggy:  return  new  SerialMergeSchedulerProvider(shardId,  EMPTY_SETTINGS);  context:  protected  SnapshotDeletionPolicy  createSnapshotDeletionPolicy()  {  return  new  SnapshotDeletionPolicy(createIndexDeletionPolicy());  }  protected  MergePolicyProvider  createMergePolicy()  {  return  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(new  Index( "test "),  EMPTY_SETTINGS));  }  protected  MergeSchedulerProvider  createMergeScheduler()  {          return  new  SerialMergeSchedulerProvider(shardId,  EMPTY_SETTINGS);          return  new  SerialMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool);  }  protected  abstract  Engine  createEngine(Store  store,  Translog  translog);  protected  static  final  BytesReference  B_1  =  new  BytesArray(new  byte[]{1});  protected  static  final  BytesReference  B_2  =  new  BytesArray(new  byte[]{2});  protected  static  final  BytesReference  B_3  =  new  BytesArray(new  byte[]{3});  	return  new  SerialMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool);  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "filter  must  be  set  on  filter  aggregation  [ "  +  name  +   "] ");  context:  }  public  FilterAggregationBuilder  filter(FilterBuilder  filter)  {  this.filter  =  filter;  return  this;  }  protected  XContentBuilder  internalXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (filter  ==  null)  {              throw  new  SearchSourceBuilderException( "filter  must  be  set  on  filter  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "filter  must  be  set  on  filter  aggregation  [ "  +  getName()  +   "] ");  }  filter.toXContent(builder,  params);  return  builder;  }  }  	throw  new  SearchSourceBuilderException( "filter  must  be  set  on  filter  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_4f7792e64b4ce29197e21486afd090f7187a23c4	buggy:  assertThat(corrections[2].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "gorr  the  god  jewel "));  context:  assertThat(corrections.length,  equalTo(0));  //  only  use  forward  with  constant  prefix  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "america  cae "),  generator,  2,  1,  ir,   "body ",  wordScorer,  1,  2).corrections;  assertThat(corrections.length,  equalTo(1));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "american  ace "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Zorr  the  Got-Jewel "),  generator,  0.5f,  4,  ir,   "body ",  wordScorer,  0,  2).corrections;  assertThat(corrections.length,  equalTo(4));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "xorr  the  god  jewel "));  assertThat(corrections[1].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "zorr  the  god  jewel "));          assertThat(corrections[2].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "gorr  the  god  jewel "));          assertThat(corrections[2].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "four  the  god  jewel "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Zorr  the  Got-Jewel "),  generator,  0.5f,  1,  ir,   "body ",  wordScorer,  1.5f,  2).corrections;  assertThat(corrections.length,  equalTo(1));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "xorr  the  god  jewel "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Xor  the  Got-Jewel "),  generator,  0.5f,  1,  ir,   "body ",  wordScorer,  1.5f,  2).corrections;  assertThat(corrections.length,  equalTo(1));  	assertThat(corrections[2].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "four  the  god  jewel "));  
elasticsearch_da98aab13f4a2f5293ce29dddfb0fb5f7b1155d8	buggy:  }  else  if  ( "percolate ".equals(currentFieldName))  {  context:  ttl  =  TimeValue.parseTimeValue(parser.text(),  null).millis();  }  else  {  ttl  =  parser.longValue();  }  }  else  if  ( "op_type ".equals(currentFieldName)  ||   "opType ".equals(currentFieldName))  {  opType  =  parser.text();  }  else  if  ( "_version ".equals(currentFieldName)  ||   "version ".equals(currentFieldName))  {  version  =  parser.longValue();  }  else  if  ( "_version_type ".equals(currentFieldName)  ||   "_versionType ".equals(currentFieldName)  ||   "version_type ".equals(currentFieldName)  ||   "versionType ".equals(currentFieldName))  {  versionType  =  VersionType.fromString(parser.text());                      }  else  if  ( "percolate ".equals(currentFieldName))  {                      }  else  if  ( "percolate ".equals(currentFieldName)  ||   "_percolate ".equals(currentFieldName))  {  percolate  =  parser.textOrNull();  }  }  }  if  ( "delete ".equals(action))  {  add(new  DeleteRequest(index,  type,  id).parent(parent).version(version).versionType(versionType).routing(routing));  }  else  {  	}  else  if  ( "percolate ".equals(currentFieldName)  ||   "_percolate ".equals(currentFieldName))  {  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage  =  new  Stage(480,  320,  true);  context:  public  class  ComplexActionTest  extends  GdxTest  {  Stage  stage;  Texture  texture;  public  void  create  ()  {  stage  =  new  Stage(480,  320,  true);  stage  =  new  Stage();  Action  complexAction  =  forever(sequence(parallel(rotateBy(180,  2),  scaleTo(1.4f,  1.4f,  2),  alpha(0.7f,  2)),  parallel(rotateBy(180,  2),  scaleTo(1.0f,  1.0f,  2),  alpha(1.0f,  2))));  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "),  false);  texture.setFilter(TextureFilter.Linear,  TextureFilter.Linear);  final  Image  img1  =  new  Image(new  TextureRegion(texture));  	stage  =  new  Stage();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Tuple<Settings,  Environment>(v1,  environment);  context:  Settings  v1  =  settingsBuilder.build();  environment  =  new  Environment(v1);  settingsBuilder  =  settingsBuilder().put(v1);  settingsBuilder.put( "path.logs ",  cleanPath(environment.logsFile().getAbsolutePath()));  v1  =  settingsBuilder.build();          return  new  Tuple<Settings,  Environment>(v1,  environment);          return  new  Tuple<>(v1,  environment);  }  }  	return  new  Tuple<>(v1,  environment);  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  .setSettings(settingsBuilder().put( "number_of_shards ",  numberOfShards))  context:  public  void  testFacetsMultiShards()  throws  Exception  {  testFacets(3);  }  private  void  testFacets(int  numberOfShards)  throws  Exception  {  client.admin().indices().prepareDelete().execute().actionGet();  client.admin().indices().prepareCreate( "test ")                  .setSettings(settingsBuilder().put( "number_of_shards ",  numberOfShards))                  .setSettings(settingsBuilder().put( "index.number_of_shards ",  numberOfShards))  .addMapping( "type1 ",  jsonBuilder().startObject().startObject( "type1 ").startObject( "properties ")  .startObject( "nested1 ")  .field( "type ",   "nested ").startObject( "properties ")  .startObject( "nested2 ").field( "type ",   "nested ").endObject()  .endObject().endObject()  .endObject().endObject().endObject())  .execute().actionGet();  	.setSettings(settingsBuilder().put( "index.number_of_shards ",  numberOfShards))  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.strictExpand());  context:  return  request.masterNodeTimeout();  }  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(ClusterState  currentState)  {                  String[]  actualIndices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.strictExpand());                  String[]  actualIndices  =  currentState.metaData().concreteIndices(IndicesOptions.strictExpand(),  request.indices());  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder(currentState.routingTable());  MetaData.Builder  metaDataBuilder  =  MetaData.builder(currentState.metaData());  Set<String>  openIndices  =  Sets.newHashSet();  Set<String>  closeIndices  =  Sets.newHashSet();  for  (String  index  :  actualIndices)  {  	String[]  actualIndices  =  currentState.metaData().concreteIndices(IndicesOptions.strictExpand(),  request.indices());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  nodesStatsRequest.listenerThreaded(false);  client.admin().cluster().nodesStats(nodesStatsRequest,  new  ActionListener<NodesStatsResponse>()  {  public  void  onResponse(NodesStatsResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_7783ad3e5eb7217c317a281ececc62517270d259	buggy:  spriteBatch.draw(font.getTextureRegion().getTexture(),  vertices,  0,  idx);  context:  int  intBits  =  ((int)(255  *  a)  <<  24)  |  ((int)(255  *  b)  <<  16)  |  ((int)(255  *  g)  <<  8)  |  ((int)(255  *  r));  float  color  =  Float.intBitsToFloat(intBits);  if  (color  ==  this.color)  return;  this.color  =  color;  float[]  vertices  =  this.vertices;  for  (int  i  =  2,  n  =  idx;  i  <  n;  i  +=  5)  vertices[i]  =  color;  }  public  void  draw  (SpriteBatch  spriteBatch)  {  spriteBatch.draw(font.getTextureRegion().getTexture(),  vertices,  0,  idx);  spriteBatch.draw(font.getRegion().getTexture(),  vertices,  0,  idx);  }  private  void  reset  (int  glyphCount)  {  x  =  0;  y  =  0;  idx  =  0;  int  vertexCount  =  glyphCount  *  20;  	spriteBatch.draw(font.getRegion().getTexture(),  vertices,  0,  idx);  
libgdx_79d9ced76e9c1d81f7b775b879335635493089f2	buggy:  if  (System.getenv( "ANDROID_HOME ")  !=  null)  {  context:  return  params;  }  public  static  void  main  (String[]  args)  {  Map<String,  String>  params  =  parseArgs(args);  if(!params.containsKey( "dir ")  ||  !params.containsKey( "name ")  ||  !params.containsKey( "package ")  ||  !params.containsKey( "mainClass ")  ||  ((!params.containsKey( "sdkLocation ")  &&  System.getenv( "ANDROID_HOME ")  ==  null)))  {  new  GdxSetupUI();  printHelp();  }  else  {  String  sdkLocation  =   " ";  if  (System.getenv( "ANDROID_HOME ")  !=  null)  {  if  (System.getenv( "ANDROID_HOME ")  !=  null  &&  !params.containsKey( "sdkLocation "))  {  sdkLocation  =  System.getenv( "ANDROID_HOME ");  }  else  {  sdkLocation  =  params.get( "sdkLocation ");  }  new  GdxSetup().build(params.get( "dir "),  params.get( "name "),  params.get( "package "),  params.get( "mainClass "),  sdkLocation,  new  CharCallback()  {  public  void  character  (char  c)  {  	if  (System.getenv( "ANDROID_HOME ")  !=  null  &&  !params.containsKey( "sdkLocation "))  {  
elasticsearch_4c8978237fdb07ed81fc7cb0255f43cfe7c1f490	buggy:  .setSearchType(QUERY_THEN_FETCH)  context:  closeAllNodes();  }  protected  Client  getClient()  {  return  client( "server1 ");  }  SearchResponse  searchResponse  =  client.prepareSearch()  .setIndices( "test ")                  .setSearchType(QUERY_THEN_FETCH)                  .setSearchType(DFS_QUERY_THEN_FETCH)  .setQuery(termQuery( "_all ",   "test "))  .setFrom(0).setSize(60)  .addHighlightedField( "_all ").setHighlighterOrder( "score ").setHighlighterPreTags( "<xxx> ").setHighlighterPostTags( "</xxx> ")  .setScroll(timeValueMinutes(10))  .execute().actionGet();  assertThat( "Failures   "  +  Arrays.toString(searchResponse.shardFailures()),  searchResponse.shardFailures().length,  equalTo(0));  assertThat(searchResponse.hits().totalHits(),  equalTo(100l));  	.setSearchType(DFS_QUERY_THEN_FETCH)  
elasticsearch_09a6907ccac3f33eb429e943cb242821c451845a	buggy:  return  ImmutableSet.copyOf(shards.keySet());  context:  public  IndexShard  shardSafe(int  shardId)  throws  IndexShardMissingException  {  IndexShard  indexShard  =  shard(shardId);  if  (indexShard  ==  null)  {  throw  new  IndexShardMissingException(new  ShardId(index,  shardId));  }  return  indexShard;  }  public  ImmutableSet<Integer>  shardIds()  {          return  ImmutableSet.copyOf(shards.keySet());          return  shards.keySet();  }  public  Injector  injector()  {  return  injector;  }  	return  shards.keySet();  
libgdx_935f499cb48f96d29e4395d09458d86b9f80bc9a	buggy:  getTable().prefSizeInvalid  =  true;  context:  layout.invalidate();  layout.layout();  }  }  }  public  void  invalidate  ()  {  needsLayout  =  true;  getTable().prefSizeInvalid  =  true;  getTable().sizeInvalid  =  true;  }  public  void  invalidateHierarchy  ()  {  invalidate();  Actor  parent  =  getTable().parent;  while  (parent  !=  null)  {  if  (parent  instanceof  Layout)  ((Layout)parent).invalidate();  	getTable().sizeInvalid  =  true;  
elasticsearch_b80eee305e2fc4b9c7e3dee0c0af797047dea891	buggy:  responses[request.id()]  =  new  BulkItemResponse(request.id(),  indexRequest.opType().toString().toLowerCase(),  context:  }  public  void  onFailure(Throwable  e)  {  String  message  =  ExceptionsHelper.detailedMessage(e);  synchronized  (responses)  {  for  (BulkItemRequest  request  :  requests)  {  if  (request.request()  instanceof  IndexRequest)  {  IndexRequest  indexRequest  =  (IndexRequest)  request.request();                                  responses[request.id()]  =  new  BulkItemResponse(request.id(),  indexRequest.opType().toString().toLowerCase(),                                  responses[request.id()]  =  new  BulkItemResponse(request.id(),  indexRequest.opType().toString().toLowerCase(Locale.ENGLISH),  new  BulkItemResponse.Failure(indexRequest.index(),  indexRequest.type(),  indexRequest.id(),  message));  }  else  if  (request.request()  instanceof  DeleteRequest)  {  DeleteRequest  deleteRequest  =  (DeleteRequest)  request.request();  responses[request.id()]  =  new  BulkItemResponse(request.id(),   "delete ",  new  BulkItemResponse.Failure(deleteRequest.index(),  deleteRequest.type(),  deleteRequest.id(),  message));  }  }  }  	responses[request.id()]  =  new  BulkItemResponse(request.id(),  indexRequest.opType().toString().toLowerCase(Locale.ENGLISH),  
libgdx_a52d449d0330348fbafd9ebcceeddeec901b78fc	buggy:  public  byte  readByte  (int  b)  throws  IOException  {  context:  public  LittleEndianInputStream  (InputStream  in)  {  super(in);  }  public  boolean  readBoolean  ()  throws  IOException  {  int  bool  =  in.read();  if  (bool  ==  -1)  throw  new  EOFException();  return  (bool  !=  0);  }  public  byte  readByte  (int  b)  throws  IOException  {  public  byte  readByte  ()  throws  IOException  {  int  temp  =  in.read();  if  (temp  ==  -1)  throw  new  EOFException();  return  (byte)temp;  }  public  int  readUnsignedByte  ()  throws  IOException  {  int  temp  =  in.read();  if  (temp  ==  -1)  throw  new  EOFException();  	public  byte  readByte  ()  throws  IOException  {  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  Thread[]  writers  =  new  Thread[atLeast(3)];  context:  public  void  recoverWhileRelocating()  throws  Exception  {  final  int  numShards  =  between(2,  10);  final  int  numReplicas  =  0;  cluster().ensureAtLeastNumNodes(3);  int  allowNodes  =  2;  assertAcked(prepareCreate( "test ").setSettings(settingsBuilder().put(indexSettings()).put( "number_of_shards ",  numShards).put( "number_of_replicas ",  numReplicas).build()));  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  AtomicLong  indexCounter  =  new  AtomicLong();  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);          Thread[]  writers  =  new  Thread[atLeast(3)];          Thread[]  writers  =  new  Thread[scaledRandomIntBetween(3,  10)];  final  CountDownLatch  stopLatch  =  new  CountDownLatch(writers.length);  final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<Throwable>();  for  (int  i  =  0;  i  <  writers.length;  i++)  {  final  int  indexerId  =  i;  final  Client  client  =  client();  writers[i]  =  new  Thread()  {  	Thread[]  writers  =  new  Thread[scaledRandomIntBetween(3,  10)];  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  CountRequest  countRequest  =  new  CountRequest(RestActions.splitIndices(request.param( "index ")));  if  (request.hasParam( "ignore_indices "))  {  countRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }  countRequest.listenerThreaded(false);  try  {              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.SINGLE_THREAD);              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  countRequest.operationThreading(operationThreading);  if  (request.hasContent())  {  countRequest.query(request.content(),  request.contentUnsafe());  }  else  {  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operation_threading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_5fb80c391ba8f4bce294d549199b44a7105bcb64	buggy:  shardStateAction.shardStarted(shardRouting,   "after  recovery  (backup)  from  node  [ "  +  request.sourceNode()  +   "] ");  context:  private  final  IndexService  indexService;  private  PeerRecoveryListener(StartRecoveryRequest  request,  ShardRouting  shardRouting,  IndexService  indexService)  {  this.request  =  request;  this.shardRouting  =  shardRouting;  this.indexService  =  indexService;  }              shardStateAction.shardStarted(shardRouting,   "after  recovery  (backup)  from  node  [ "  +  request.sourceNode()  +   "] ");              shardStateAction.shardStarted(shardRouting,   "after  recovery  (replica)  from  node  [ "  +  request.sourceNode()  +   "] ");  }  threadPool.schedule(new  Runnable()  {  recoveryTarget.startRecovery(request,  true,  PeerRecoveryListener.this);  }  },  retryAfter);  	shardStateAction.shardStarted(shardRouting,   "after  recovery  (replica)  from  node  [ "  +  request.sourceNode()  +   "] ");  
elasticsearch_d2768098225a41bae47befc166982e409b4a66c2	buggy:  valuesLoaded  =  true;  context:  }  public  void  doc(Document  doc)  {  this.doc  =  doc;  }  public  void  clear()  {  value  =  null;  valueLoaded  =  false;  values.clear();          valuesLoaded  =  true;          valuesLoaded  =  false;  doc  =  null;  }  public  boolean  isEmpty()  {  if  (valueLoaded)  {  return  value  ==  null;  }  if  (valuesLoaded)  {  	valuesLoaded  =  false;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<PingResponse[]>();  context:  multicastChannel.close();  multicastChannel  =  null;  }  }  protected  void  doClose()  throws  ElasticsearchException  {  }  public  PingResponse[]  pingAndWait(TimeValue  timeout)  {          final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<PingResponse[]>();          final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);  try  {  ping(new  PingListener()  {  public  void  onPing(PingResponse[]  pings)  {  response.set(pings);  latch.countDown();  }  	final  AtomicReference<PingResponse[]>  response  =  new  AtomicReference<>();  
elasticsearch_0f6c24d0c5bd9197de4397e5ddd1dd3edeb9b524	buggy:  .endObject().bytes().array();  context:  DocumentMapper  docMapper  =  MapperTestUtils.newParser().parse(mapping);  String  builtMapping  =  docMapper.mappingSource().string();  DocumentMapper  builtDocMapper  =  MapperTestUtils.newParser().parse(builtMapping);  byte[]  json  =  jsonBuilder().startObject()  .field( "foo ",   "bar ")  .field( "_id ",  1)  .field( "foobar ",   "foobar ")                  .endObject().bytes().array();                  .endObject().bytes().toBytes();  Document  doc  =  builtDocMapper.parse(new  BytesArray(json)).rootDoc();  AllField  field  =  (AllField)  doc.getField( "_all ");  if  (enabled)  {  assertThat(field.fieldType().omitNorms(),  equalTo(omitNorms));  assertThat(field.fieldType().stored(),  equalTo(stored));  assertThat(field.fieldType().storeTermVectorOffsets(),  equalTo(tv_offsets));  assertThat(field.fieldType().storeTermVectorPayloads(),  equalTo(tv_payloads));  assertThat(field.fieldType().storeTermVectorPositions(),  equalTo(tv_positions));  	.endObject().bytes().toBytes();  
libgdx_32b98412f7409d91e046a8ede5b988c00464e9c6	buggy:  public  void  purchase(PurchaseListener  listener,  String  identifier)  {  context:  return  false;  }  public  void  dispose()  {  }    public  void  purchase(PurchaseListener  listener,  String  identifier)  {    public  void  purchase(String  identifier,  PurchaseListener  listener)  {  }  public  void  purchaseRestore()  {  	public  void  purchase(String  identifier,  PurchaseListener  listener)  {  
elasticsearch_ccd54dae2d9438bc8b7d2f2c2ead2ff350a8cff8	buggy:  DocumentMapper  mapper  =  mapperService.documentMapperWithAutoCreate( "my_type ");  context:  public  void  testDefaultMappingAndNoMappingWithMapperService()  throws  Exception  {  String  defaultMapping  =  XContentFactory.jsonBuilder().startObject().startObject(MapperService.DEFAULT_MAPPING)  .startObject( "_source ").field( "enabled ",  false).endObject()  .endObject().endObject().string();  MapperService  mapperService  =  MapperTestUtils.newMapperService();  mapperService.merge(MapperService.DEFAULT_MAPPING,  new  CompressedString(defaultMapping),  true);          DocumentMapper  mapper  =  mapperService.documentMapperWithAutoCreate( "my_type ");          DocumentMapper  mapper  =  mapperService.documentMapperWithAutoCreate( "my_type ").v1();  assertThat(mapper.type(),  equalTo( "my_type "));  assertThat(mapper.sourceMapper().enabled(),  equalTo(false));  }  public  void  testDefaultMappingAndWithMappingOverrideWithMapperService()  throws  Exception  {  String  defaultMapping  =  XContentFactory.jsonBuilder().startObject().startObject(MapperService.DEFAULT_MAPPING)  .startObject( "_source ").field( "enabled ",  false).endObject()  	DocumentMapper  mapper  =  mapperService.documentMapperWithAutoCreate( "my_type ").v1();  
elasticsearch_d5fcb0d52c1424fd01c0aa2bcb1db43ff763095b	buggy:  }  else  if  ( "_name ".equals(attr))  {  context:  }  }  return  false;  }  else  if  ( "_id ".equals(attr))  {  for  (String  value  :  values)  {  if  (node.id().equals(value))  {  return  true;  }  }  return  false;              }  else  if  ( "_name ".equals(attr))  {              }  else  if  ( "_name ".equals(attr)  ||   "name ".equals(attr))  {  for  (String  value  :  values)  {  if  (Regex.simpleMatch(value,  node.name()))  {  return  true;  }  }  return  false;  }  else  {  String  nodeAttributeValue  =  node.attributes().get(attr);  	}  else  if  ( "_name ".equals(attr)  ||   "name ".equals(attr))  {  
elasticsearch_4824f05369e7445cc25de3c72e799a8fbbe34a40	buggy:  if  (state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK))  {  context:  if  (lifecycle.stoppedOrClosed())  {  return;  }  if  (event.localNodeMaster()  &&  event.state().blocks().hasGlobalBlock(STATE_NOT_RECOVERED_BLOCK))  {  checkStateMeetsSettingsAndMaybeRecover(event.state(),  true);  }  }  protected  void  checkStateMeetsSettingsAndMaybeRecover(ClusterState  state,  boolean  asyncRecovery)  {  DiscoveryNodes  nodes  =  state.nodes();          if  (state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK))  {          if  (state.blocks().hasGlobalBlock(discoveryService.getNoMasterBlock()))  {  }  else  if  (recoverAfterNodes  !=  -1  &&  (nodes.masterAndDataNodes().size())  <  recoverAfterNodes)  {  }  else  if  (recoverAfterDataNodes  !=  -1  &&  nodes.dataNodes().size()  <  recoverAfterDataNodes)  {  }  else  if  (recoverAfterMasterNodes  !=  -1  &&  nodes.masterNodes().size()  <  recoverAfterMasterNodes)  {  }  else  {  	if  (state.blocks().hasGlobalBlock(discoveryService.getNoMasterBlock()))  {  
libgdx_1b63ab824068d43cdfdc870fd015c9324c96a954	buggy:  GdxTest  test  =  new  Basic3DTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  Basic3DTest();  GdxTest  test  =  new  ModelTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.width  =  480;  config.height  =  320;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  ModelTest();  
elasticsearch_bc452dff84da86298b5234f81e90dd768244d70c	buggy:  GeoDistance  geoDistance  =  GeoDistance.ARC;  context:  public  String[]  names()  {  return  new  String[]{ "_geo_distance ",   "_geoDistance "};  }  public  SortField  parse(XContentParser  parser,  SearchContext  context)  throws  Exception  {  String  fieldName  =  null;  GeoPoint  point  =  new  GeoPoint();  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;          GeoDistance  geoDistance  =  GeoDistance.ARC;          GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  boolean  reverse  =  false;  SortMode  sortMode  =  null;  String  nestedPath  =  null;  Filter  nestedFilter  =  null;  boolean  normalizeLon  =  true;  boolean  normalizeLat  =  true;  	GeoDistance  geoDistance  =  GeoDistance.DEFAULT;  
elasticsearch_49d84cb47f8f543ce1fb067267d6fafa71f9c479	buggy:  return  compare(v1,  v2);  context:  public  LongValuesComparator(IndexNumericFieldData<?>  indexFieldData,  long  missingValue,  int  numHits,  SortMode  sortMode)  {  super(indexFieldData,  missingValue,  sortMode);  this.values  =  new  long[numHits];  assert  indexFieldData.getNumericType().requiredBits()  <=  64;  }  public  int  compare(int  slot1,  int  slot2)  {  final  long  v1  =  values[slot1];  final  long  v2  =  values[slot2];          return  compare(v1,  v2);          return  Long.compare(v1,  v2);  }  public  void  setBottom(int  slot)  {  this.bottom  =  values[slot];  }  public  void  copy(int  slot,  int  doc)  throws  IOException  {  	return  Long.compare(v1,  v2);  
libgdx_2e281a8b841e40f82570ba3234b150a7bafc1501	buggy:  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE  );  context:  app.getGraphics().getGL20().glClear(  GL20.GL_COLOR_BUFFER_BIT  );  meshShader.begin();  mesh.render(meshShader,  GL20.GL_TRIANGLES);  meshShader.end();  frameBuffer.end();  app.getGraphics().getGL20().glClearColor(  0.2f,  0.2f,  0.2f,  1  );  app.getGraphics().getGL20().glClear(  GL20.GL_COLOR_BUFFER_BIT  );  spriteBatch.begin();  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE  );  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  spriteBatch.end();  }  public  void  surfaceChanged(Application  app,  int  width,  int  height)  {  }  	spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  context:  broadcastPingRequest.queryHint(request.param( "queryHint "));  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  broadcastPingRequest.operationThreading(operationThreading);  client.admin().cluster().execPing(broadcastPingRequest,  new  ActionListener<BroadcastPingResponse>()  {  try  {                      JsonBuilder  builder  =  RestJsonBuilder.cached(request);                      JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  
elasticsearch_bc1dd108d19be185d804291070ef3af7f72929bc	buggy:  buf  =  ChannelBuffers.wrappedBuffer(builder.unsafeBytes(),  0,  builder.unsafeBytesLength());  context:  ChannelFutureListener  releaseContentListener  =  null;  ChannelBuffer  buf;  try  {  if  (response  instanceof  XContentRestResponse)  {  XContentBuilder  builder  =  ((XContentRestResponse)  response).builder();  if  (builder.payload()  instanceof  CachedStreamOutput.Entry)  {  releaseContentListener  =  new  NettyTransport.CacheFutureListener((CachedStreamOutput.Entry)  builder.payload());                      buf  =  ChannelBuffers.wrappedBuffer(builder.unsafeBytes(),  0,  builder.unsafeBytesLength());                      buf  =  ChannelBuffers.wrappedBuffer(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());  }  else  if  (response.contentThreadSafe())  {  buf  =  ChannelBuffers.wrappedBuffer(response.content(),  0,  response.contentLength());  }  else  {  buf  =  ChannelBuffers.copiedBuffer(response.content(),  0,  response.contentLength());  }  }  else  {  if  (response.contentThreadSafe())  {  buf  =  ChannelBuffers.wrappedBuffer(response.content(),  0,  response.contentLength());  	buf  =  ChannelBuffers.wrappedBuffer(builder.underlyingBytes(),  0,  builder.underlyingBytesLength());  
elasticsearch_3c142e550d946347d87c6b48d5bc7ef6f99fff0a	buggy:  protected  final  void  incrementBucketDocCount(int  inc,  long  bucketOrd)  throws  IOException  {  context:  protected  final  void  collectBucketNoCounts(int  doc,  long  bucketOrd)  throws  IOException  {  collectableSubAggregators.collect(doc,  bucketOrd);  }      protected  final  void  incrementBucketDocCount(int  inc,  long  bucketOrd)  throws  IOException  {      protected  final  void  incrementBucketDocCount(long  bucketOrd,  int  inc)  throws  IOException  {  docCounts  =  bigArrays.grow(docCounts,  bucketOrd  +  1);  docCounts.increment(bucketOrd,  inc);  }  public  final  int  bucketDocCount(long  bucketOrd)  {  	protected  final  void  incrementBucketDocCount(long  bucketOrd,  int  inc)  throws  IOException  {  
elasticsearch_371b071fb791a73f6757c813200877ff3b6c8824	buggy:  searchContext.addScopePhase(parentFilter);  context:  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[parent]  filter  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  HasParentFilter  parentFilter  =  HasParentFilter.create(executionType,  query,  null,  parentType,  searchContext);          searchContext.addScopePhase(parentFilter);          searchContext.addRewrite(parentFilter);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  parentFilter);  }  return  parentFilter;  }  }  	searchContext.addRewrite(parentFilter);  
elasticsearch_bd6b89f7cab39acf5cd2b3d5b33adbcddf69c0d1	buggy:  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  query  =  smartNameFieldMappers.mapper().rangeQuery(from,  to,  includeLower,  includeUpper);  }  }  if  (query  ==  null)  {  query  =  new  TermRangeQuery(fieldName,  from,  to,  includeLower,  includeUpper);  }  query.setBoost(boost);          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());          return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  }  	return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  
libgdx_d3151bcae8c112186bf127141eba9a2bfe6d46fc	buggy:  renderer.render(world);  context:  body.setBullet(true);  body.setTransform(new  Vector2(0,  0),  body.getAngle());  body.setLinearVelocity(new  Vector2(50f,  0));  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  world.step(Math.min(0.032f,  Gdx.graphics.getDeltaTime()),  3,  4);  cam.update();  cam.apply(Gdx.gl10);  renderer.render(world);  renderer.render(world,  cam.combined);  }  }  	renderer.render(world,  cam.combined);  
elasticsearch_d6a3fc09f03fec24d86a33e82784b482613dbd27	buggy:  recoveryStatus().index().startTime(System.currentTimeMillis());  context:  return   "_none_ ";  }  public  RecoveryStatus  recoveryStatus()  {  return  recoveryStatus;  }  public  void  recover(boolean  indexShouldExists,  RecoveryStatus  recoveryStatus)  throws  IndexShardGatewayRecoveryException  {          recoveryStatus().index().startTime(System.currentTimeMillis());          recoveryStatus.index().startTime(System.currentTimeMillis());  try  {  indexShard.store().deleteContent();  }  catch  (IOException  e)  {  }  	recoveryStatus.index().startTime(System.currentTimeMillis());  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execGet(getRequest,  new  ActionListener<GetResponse>()  {  context:  super(settings,  client);  controller.registerHandler(GET,   "/{index}/{type}/{id} ",  this);  }  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);  getRequest.threadedOperation(true);          client.execGet(getRequest,  new  ActionListener<GetResponse>()  {          client.get(getRequest,  new  ActionListener<GetResponse>()  {  try  {  if  (!result.exists())  {  JsonBuilder  builder  =  restJsonBuilder(request);  builder.startObject();  builder.field( "_index ",  result.index());  builder.field( "_type ",  result.type());  builder.field( "_id ",  result.id());  	client.get(getRequest,  new  ActionListener<GetResponse>()  {  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  wipeIndex( "test ");  context:  final  String  fieldName  =   "field ";  final  String  mapping  =   "{  \ " "  +  mappingType  +   "\ ":  { "  +   "\ "dynamic_templates\ ":  [ "   "{  \ " "  +  fieldName  +   "\ ":  { "  +   "\ "path_match\ ":  \ "*\ ", "  +   "\ "mapping\ ":  { "  +   "\ "type\ ":  \ "string\ ", "  +   "\ "store\ ":  \ "yes\ ", "   "\ "index\ ":  \ "analyzed\ ",  \ "analyzer\ ":  \ "whitespace\ "  }  }  }  ]  }  } ";  int  iters  =  atLeast(5);  for  (int  i  =  0;  i  <  iters;  i++)  {              wipeIndex( "test ");              wipeIndices( "test ");  client().admin().indices().prepareCreate( "test ")  .setSettings(  ImmutableSettings.settingsBuilder()  .put( "number_of_shards ",  between(1,  5))  .put( "number_of_replicas ",  between(0,  1)).build())  .addMapping(mappingType,  mapping).execute().actionGet();  ensureYellow();  int  numDocs  =  atLeast(10);  	wipeIndices( "test ");  
elasticsearch_af39f07213ccce2419688191b47fbac5fbd4de40	buggy:  XContentDocumentMapper.Builder  docBuilder  =  doc(index.name(),  (RootObjectMapper.Builder)  rootObjectTypeParser.parse(type,  mapping,  parserContext));  context:  if  (defaultSource  !=  null)  {  Tuple<String,  Map<String,  Object>>  t  =  extractMapping(MapperService.DEFAULT_MAPPING,  defaultSource);  if  (t.v2()  !=  null)  {  XContentHelper.mergeDefaults(mapping,  t.v2());  }  }  XContentMapper.TypeParser.ParserContext  parserContext  =  new  XContentMapper.TypeParser.ParserContext(analysisService,  typeParsers);          XContentDocumentMapper.Builder  docBuilder  =  doc(index.name(),  (RootObjectMapper.Builder)  rootObjectTypeParser.parse(type,  mapping,  parserContext));          XContentDocumentMapper.Builder  docBuilder  =  doc(index.name(),  indexSettings,  (RootObjectMapper.Builder)  rootObjectTypeParser.parse(type,  mapping,  parserContext));  for  (Map.Entry<String,  Object>  entry  :  mapping.entrySet())  {  String  fieldName  =  Strings.toUnderscoreCase(entry.getKey());  Object  fieldNode  =  entry.getValue();  if  (SourceFieldMapper.CONTENT_TYPE.equals(fieldName)  ||   "sourceField ".equals(fieldName))  {  docBuilder.sourceField(parseSourceField((Map<String,  Object>)  fieldNode,  parserContext));  }  else  if  (SizeFieldMapper.CONTENT_TYPE.equals(fieldName))  {  	XContentDocumentMapper.Builder  docBuilder  =  doc(index.name(),  indexSettings,  (RootObjectMapper.Builder)  rootObjectTypeParser.parse(type,  mapping,  parserContext));  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  return  wrapSmartNameFilter(prefixFilter,  smartNameFieldMappers,  parseContext.filterCache());  context:  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  Filter  prefixFilter  =  new  PrefixFilter(new  Term(fieldName,  value));  prefixFilter  =  parseContext.cacheFilterIfPossible(prefixFilter);          return  wrapSmartNameFilter(prefixFilter,  smartNameFieldMappers,  parseContext.filterCache());          return  wrapSmartNameFilter(prefixFilter,  smartNameFieldMappers,  parseContext.indexCache());  }  }  	return  wrapSmartNameFilter(prefixFilter,  smartNameFieldMappers,  parseContext.indexCache());  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState.Builder  builder  =  ClusterState.builder();  context:  protected  ClusterStateResponse  newResponse()  {  return  new  ClusterStateResponse();  }  protected  void  masterOperation(final  ClusterStateRequest  request,  final  ClusterState  state,  ActionListener<ClusterStateResponse>  listener)  throws  ElasticsearchException  {  ClusterState  currentState  =  clusterService.state();          ClusterState.Builder  builder  =  ClusterState.builder();          ClusterState.Builder  builder  =  ClusterState.builder(currentState.getClusterName());  builder.version(currentState.version());  if  (request.nodes())  {  builder.nodes(currentState.nodes());  }  if  (request.routingTable())  {  if  (request.indices().length  >  0)  {  RoutingTable.Builder  routingTableBuilder  =  RoutingTable.builder();  for  (String  filteredIndex  :  request.indices())  {  	ClusterState.Builder  builder  =  ClusterState.builder(currentState.getClusterName());  
elasticsearch_2c4f7d1fc3eb8e1dce6df8e5418e23ed88e96c8c	buggy:  if  (extractFieldNames  !=  null)  {  context:  if  (loadAllStored)  {  if  (sourceRequested  ||  extractFieldNames  !=  null)  {  fieldSelector  =  null;  //  load  everything,  including  _source  }  else  {  fieldSelector  =  AllButSourceFieldSelector.INSTANCE;  }  }  else  if  (fieldSelectorMapper  !=  null)  {  fieldSelectorMapper.add(UidFieldMapper.NAME);                  if  (extractFieldNames  !=  null)  {                  if  (extractFieldNames  !=  null  ||  sourceRequested)  {  fieldSelectorMapper.add(SourceFieldMapper.NAME);  }  fieldSelector  =  fieldSelectorMapper;  }  else  if  (extractFieldNames  !=  null  ||  sourceRequested)  {  fieldSelector  =  new  UidAndSourceFieldSelector();  }  else  {  fieldSelector  =  UidFieldSelector.INSTANCE;  }  	if  (extractFieldNames  !=  null  ||  sourceRequested)  {  
elasticsearch_2778a6756cf59dae413ca860844c3c36c96bd9fd	buggy:  indicesStatsRequest.indexing(request.paramAsBoolean( "get ",  indicesStatsRequest.get()));  context:  boolean  clear  =  request.paramAsBoolean( "clear ",  false);  if  (clear)  {  indicesStatsRequest.clear();  }  if  (request.hasParam( "groups "))  {  indicesStatsRequest.groups(Strings.splitStringByCommaToArray(request.param( "groups ")));  }  indicesStatsRequest.docs(request.paramAsBoolean( "docs ",  indicesStatsRequest.docs()));  indicesStatsRequest.store(request.paramAsBoolean( "store ",  indicesStatsRequest.store()));  indicesStatsRequest.indexing(request.paramAsBoolean( "indexing ",  indicesStatsRequest.indexing()));          indicesStatsRequest.indexing(request.paramAsBoolean( "get ",  indicesStatsRequest.get()));          indicesStatsRequest.get(request.paramAsBoolean( "get ",  indicesStatsRequest.get()));  indicesStatsRequest.merge(request.paramAsBoolean( "merge ",  indicesStatsRequest.merge()));  indicesStatsRequest.refresh(request.paramAsBoolean( "refresh ",  indicesStatsRequest.refresh()));  indicesStatsRequest.flush(request.paramAsBoolean( "flush ",  indicesStatsRequest.flush()));  client.admin().indices().stats(indicesStatsRequest,  new  ActionListener<IndicesStats>()  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  	indicesStatsRequest.get(request.paramAsBoolean( "get ",  indicesStatsRequest.get()));  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  state  =  LocalGatewayStartedShards.Builder.readFrom(in,  null);  context:  this.state  =  state;  }  public  LocalGatewayStartedShards  state()  {  return  state;  }  super.readFrom(in);  if  (in.readBoolean())  {                  state  =  LocalGatewayStartedShards.Builder.readFrom(in,  null);                  state  =  LocalGatewayStartedShards.Builder.readFrom(in);  }  }  super.writeTo(out);  if  (state  ==  null)  {  out.writeBoolean(false);  }  else  {  	state  =  LocalGatewayStartedShards.Builder.readFrom(in);  
elasticsearch_ea96359d82a9a82da336e9dadbcb2ee0e9389a44	buggy:  result.matches(),  result.count(),  tookInMillis,  result.reducedFacets(),  result.reducedAggregations()  context:  if  (shardResults  ==  null)  {  long  tookInMillis  =  System.currentTimeMillis()  -  request.startTime;  PercolateResponse.Match[]  matches  =  request.onlyCount()  ?  null  :  PercolateResponse.EMPTY;  return  new  PercolateResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,  tookInMillis,  matches);  }  else  {  PercolatorService.ReduceResult  result  =  percolatorService.reduce(percolatorTypeId,  shardResults);  long  tookInMillis  =  System.currentTimeMillis()  -  request.startTime;  return  new  PercolateResponse(  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures,                      result.matches(),  result.count(),  tookInMillis,  result.reducedFacets(),  result.reducedAggregations()                      result.matches(),  result.count(),  tookInMillis,  result.reducedAggregations()  );  }  }  protected  PercolateShardRequest  newShardRequest()  {  return  new  PercolateShardRequest();  }  	result.matches(),  result.count(),  tookInMillis,  result.reducedAggregations()  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  percolateRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  public  RestPercolateAction(Settings  settings,  Client  client,  RestController  controller)  {  super(settings,  client);  controller.registerHandler(GET,   "/{index}/{type}/_percolate ",  this);  controller.registerHandler(POST,   "/{index}/{type}/_percolate ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  PercolateRequest  percolateRequest  =  new  PercolateRequest(request.param( "index "),  request.param( "type "));  percolateRequest.listenerThreaded(false);          percolateRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());          percolateRequest.source(request.content(),  request.contentUnsafe());  percolateRequest.listenerThreaded(false);  percolateRequest.operationThreaded(true);  percolateRequest.preferLocal(request.paramAsBoolean( "prefer_local ",  percolateRequest.preferLocalShard()));  client.percolate(percolateRequest,  new  ActionListener<PercolateResponse>()  {  	percolateRequest.source(request.content(),  request.contentUnsafe());  
libgdx_d8b940a55b7cf972c9daf44631ec873c5f8cde7b	buggy:  colors  =  new  float[3];  context:  colors  =  new  float[readInt(reader,   "colorsCount ")];  for  (int  i  =  0;  i  <  colors.length;  i++)  colors[i]  =  readFloat(reader,   "colors "  +  i);  timeline  =  new  float[readInt(reader,   "timelineCount ")];  for  (int  i  =  0;  i  <  timeline.length;  i++)  timeline[i]  =  readFloat(reader,   "timeline "  +  i);  }  public  void  load  (GradientColorValue  value)  {  super.load(value);  colors  =  new  float[3];  colors  =  new  float[value.colors.length];  System.arraycopy(value.colors,  0,  colors,  0,  colors.length);  timeline  =  new  float[value.timeline.length];  System.arraycopy(value.timeline,  0,  timeline,  0,  timeline.length);  }  }  static  public  class  SpawnShapeValue  extends  ParticleValue  {  SpawnShape  shape  =  SpawnShape.point;  	colors  =  new  float[value.colors.length];  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  NodeRequest  nodeRequest  =  newNodeRequest(nodeId,  request);  transportService.sendRequest(node,  transportNodeAction(),  nodeRequest,  transportRequestOptions,  new  BaseTransportResponseHandler<NodeResponse>()  {  return  newNodeResponse();  }  onOperation(response);  }                              @Override  public  void  handleException(RemoteTransportException  exp)  {                              @Override  public  void  handleException(TransportException  exp)  {  onFailure(node.id(),  exp);  }  return  false;  }  });  }  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ObjectOpenHashSet<String>  resolvedNodesIds  =  new  ObjectOpenHashSet<String>(nodesIds.length);  context:  public  String[]  resolveNodesIds(String...  nodesIds)  {  if  (isAllNodes(nodesIds))  {  int  index  =  0;  nodesIds  =  new  String[nodes.size()];  for  (DiscoveryNode  node  :  this)  {  nodesIds[index++]  =  node.id();  }  return  nodesIds;  }  else  {              ObjectOpenHashSet<String>  resolvedNodesIds  =  new  ObjectOpenHashSet<String>(nodesIds.length);              ObjectOpenHashSet<String>  resolvedNodesIds  =  new  ObjectOpenHashSet<>(nodesIds.length);  for  (String  nodeId  :  nodesIds)  {  if  (nodeId.equals( "_local "))  {  String  localNodeId  =  localNodeId();  if  (localNodeId  !=  null)  {  resolvedNodesIds.add(localNodeId);  }  }  else  if  (nodeId.equals( "_master "))  {  String  masterNodeId  =  masterNodeId();  	ObjectOpenHashSet<String>  resolvedNodesIds  =  new  ObjectOpenHashSet<>(nodesIds.length);  
elasticsearch_2cb40fcb1741ce1bf4c770aeec8b85717f2b5d98	buggy:  assertThat(deleteResponse.isNotFound(),  equalTo(false));  context:  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",   "value1_2 ",   "field2 ",   "value2_2 ").execute().actionGet();  response  =  client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet();  assertThat(response.isExists(),  equalTo(true));  assertThat(response.getSourceAsMap().get( "field1 ").toString(),  equalTo( "value1_2 "));  assertThat(response.getSourceAsMap().get( "field2 ").toString(),  equalTo( "value2_2 "));  DeleteResponse  deleteResponse  =  client().prepareDelete( "test ",   "type1 ",   "1 ").execute().actionGet();          assertThat(deleteResponse.isNotFound(),  equalTo(false));          assertThat(deleteResponse.isFound(),  equalTo(true));  response  =  client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet();  assertThat(response.isExists(),  equalTo(false));  }  public  void  simpleMultiGetTests()  throws  Exception  {  try  {  	assertThat(deleteResponse.isFound(),  equalTo(true));  
elasticsearch_2b9bdc37961022c0f254f86fac083f5d2fdeca12	buggy:  entry  =  new  InternalFullDateHistogramFacet.FullEntry(time,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);  context:  }  long  time  =  dateTime.getMillis();  if  (interval  !=  1)  {  time  =  CountDateHistogramFacetCollector.bucket(time,  interval);  }  InternalFullDateHistogramFacet.FullEntry  entry  =  entries.get(time);  if  (entry  ==  null)  {                  entry  =  new  InternalFullDateHistogramFacet.FullEntry(time,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);                  entry  =  new  InternalFullDateHistogramFacet.FullEntry(time,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  entries.put(time,  entry);  }  entry.count++;  valueAggregator.entry  =  entry;  valueFieldData.forEachValueInDoc(docId,  valueAggregator);  }  public  static  class  ValueAggregator  implements  NumericFieldData.DoubleValueInDocProc  {  	entry  =  new  InternalFullDateHistogramFacet.FullEntry(time,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  
elasticsearch_8ecf71ffb8a73a4b16f5b5c29b752fd094fa787a	buggy:  logger.debug( "Connected  to  node  [{}],  numberOfConnections  [{}] ",  node,  channels.size());  context:  break;  }  }  if  (channels.isEmpty())  {  if  (lastConnectException  !=  null)  {  throw  new  ConnectTransportException(node,   "connectTimeout[ "  +  connectTimeout  +   "],  connectRetries[ "  +  connectRetries  +   "] ",  lastConnectException);  }  throw  new  ConnectTransportException(node,   "connectTimeout[ "  +  connectTimeout  +   "],  connectRetries[ "  +  connectRetries  +   "],  reason  unknown ");  }  if  (logger.isDebugEnabled())  {                  logger.debug( "Connected  to  node  [{}],  numberOfConnections  [{}] ",  node,  channels.size());                  logger.debug( "Connected  to  node[{}],  number_of_connections[{}] ",  node,  channels.size());  }  clientChannels.put(node.id(),  new  NodeConnections(channels.toArray(new  Channel[channels.size()])));  }  return  clientChannels.get(node.id()).channel();  }  private  static  class  NodeConnections  {  	logger.debug( "Connected  to  node[{}],  number_of_connections[{}] ",  node,  channels.size());  
elasticsearch_92bdc23c781daa6bdff4c98a788ed60769f32443	buggy:  terminal.println(doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()));  context:  if  (size  >=  0)  {  builder.field( "_indexed_chars ",  size);  }  BytesReference  json  =  builder.endObject().endObject().bytes();  ParseContext.Document  doc  =  docMapper.parse(json).rootDoc();  terminal.println( "##  Extracted  text ");  terminal.println( "---------------------  BEGIN  ----------------------- ");              terminal.println(doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()));              terminal.println( "%s ",  doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()));  terminal.println( "----------------------  END  ------------------------ ");  terminal.println( "##  Metadata ");  printMetadataContent(doc,  AttachmentMapper.FieldNames.AUTHOR);  printMetadataContent(doc,  AttachmentMapper.FieldNames.CONTENT_LENGTH);  printMetadataContent(doc,  AttachmentMapper.FieldNames.CONTENT_TYPE);  printMetadataContent(doc,  AttachmentMapper.FieldNames.DATE);  printMetadataContent(doc,  AttachmentMapper.FieldNames.KEYWORDS);  printMetadataContent(doc,  AttachmentMapper.FieldNames.LANGUAGE);  	terminal.println( "%s ",  doc.get(docMapper.mappers().smartName( "file ").mapper().names().indexName()));  
elasticsearch_5b7173fc35cf2dbcfccb346cbb0271c07e9674a6	buggy:  return  new  IntArrayAtomicFieldData.Single(new  int[0],  0);  context:  }  }  }  public  IntArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  IntArrayAtomicFieldData.Single(new  int[0],  0);              return  new  IntArrayAtomicFieldData.SingleFixedSet(new  int[1],  0,  new  FixedBitSet(1));  }  final  TIntArrayList  values  =  new  TIntArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  new  IntArrayAtomicFieldData.SingleFixedSet(new  int[1],  0,  new  FixedBitSet(1));  
libgdx_fbef43ca95617a93068852b688a6857d4f172193	buggy:  BufferUtils.freeMemory(byteBuffer);  context:  bufferHandle  =  0;  }  else  if  (Gdx.gl11  !=  null)  {  tmpHandle.clear();  tmpHandle.put(bufferHandle);  tmpHandle.flip();  GL11  gl  =  Gdx.gl11;  gl.glBindBuffer(GL11.GL_ELEMENT_ARRAY_BUFFER,  0);  gl.glDeleteBuffers(1,  tmpHandle);  bufferHandle  =  0;  }  BufferUtils.freeMemory(byteBuffer);  BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  }  }  	BufferUtils.disposeUnsafeByteBuffer(byteBuffer);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(NodesInfoResponse  response)  {  try  {  response.settingsFilter(settingsFilter);  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  response.toXContent(builder,  request);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  termVectorRequest.index(clusterState.metaData().concreteIndex(termVectorRequest.index()));  context:  if  (!clusterState.metaData().hasConcreteIndex(termVectorRequest.index()))  {  responses.set(i,  new  MultiTermVectorsItemResponse(null,  new  MultiTermVectorsResponse.Failure(termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),   "[ "  +  termVectorRequest.index()  +   "]  missing ")));  continue;  }  if  (termVectorRequest.routing()  ==  null  &&  clusterState.getMetaData().routingRequired(termVectorRequest.index(),  termVectorRequest.type()))  {  responses.set(i,  new  MultiTermVectorsItemResponse(null,  new  MultiTermVectorsResponse.Failure(termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),   "routing  is  required,  but  hasn't  been  specified ")));  continue;  }              termVectorRequest.index(clusterState.metaData().concreteIndex(termVectorRequest.index()));              termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index()));  ShardId  shardId  =  clusterService  .operationRouting()  .getShards(clusterState,  termVectorRequest.index(),  termVectorRequest.type(),  termVectorRequest.id(),  termVectorRequest.routing(),  null).shardId();  MultiTermVectorsShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {  shardRequest  =  new  MultiTermVectorsShardRequest(shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  	termVectorRequest.index(clusterState.metaData().concreteSingleIndex(termVectorRequest.index()));  
elasticsearch_032184bd5eb63b9f5b4d2539b6d4e06e4716bfb0	buggy:  assertNoFailures(client().admin().indices().prepareOptimize( "test ").setForce(true).setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  context:  ensureYellow();  final  int  numDocs  =  randomIntBetween(10,  100);  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[numDocs];  for  (int  i  =  0;  i  <  builders.length;  i++)  {  builders[i]  =  client().prepareIndex( "test ",   "doc ",  Integer.toString(i)).setSource( "foo ",   "bar "  +  i);  }  indexRandom(true,  builders);  flushAndRefresh();          assertNoFailures(client().admin().indices().prepareOptimize( "test ").setForce(true).setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());          assertNoFailures(client().admin().indices().prepareOptimize( "test ").setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  CreateSnapshotResponse  createSnapshotResponseFirst  =  client.admin().cluster().prepareCreateSnapshot( "test-repo ",   "test ").setWaitForCompletion(true).setIndices( "test ").get();  assertThat(createSnapshotResponseFirst.getSnapshotInfo().successfulShards(),  greaterThan(0));  assertThat(createSnapshotResponseFirst.getSnapshotInfo().successfulShards(),  equalTo(createSnapshotResponseFirst.getSnapshotInfo().totalShards()));  assertThat(client.admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test ").get().getSnapshots().get(0).state(),  equalTo(SnapshotState.SUCCESS));  {  SnapshotStatus  snapshotStatus  =  client.admin().cluster().prepareSnapshotStatus( "test-repo ").setSnapshots( "test ").get().getSnapshots().get(0);  List<SnapshotIndexShardStatus>  shards  =  snapshotStatus.getShards();  	assertNoFailures(client().admin().indices().prepareOptimize( "test ").setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  
elasticsearch_35b573ff24c1462de77252f53cd60b4dcab23eda	buggy:  .withType(TransportRequestOptions.Type.fromString(settings.get( "action.bulk.transport.type ",  TransportRequestOptions.Type.LOW.toString())))  context:  }  public  BulkRequestBuilder  newRequestBuilder(Client  client)  {  return  new  BulkRequestBuilder(client);  }  public  TransportRequestOptions  transportOptions(Settings  settings)  {  return  TransportRequestOptions.options()                  .withType(TransportRequestOptions.Type.fromString(settings.get( "action.bulk.transport.type ",  TransportRequestOptions.Type.LOW.toString())))                  .withType(TransportRequestOptions.Type.BULK)  .withCompress(settings.getAsBoolean( "action.bulk.compress ",  true)  );  }  }  	.withType(TransportRequestOptions.Type.BULK)  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  return  new  CustomIntegerNumericField(this,  context.sourceLength());  context:  public  boolean  includeInObject()  {  return  false;  }  protected  Fieldable  parseCreateField(ParseContext  context)  throws  IOException  {  if  (!enabled)  {  return  null;  }          return  new  CustomIntegerNumericField(this,  context.sourceLength());          return  new  CustomIntegerNumericField(this,  context.source().length());  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (enabled  ==  Defaults.ENABLED  &&  store  ==  Defaults.STORE)  {  return  builder;  }  	return  new  CustomIntegerNumericField(this,  context.source().length());  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.field( "index ",  shardFailure.index());  context:  public  static  void  buildBroadcastShardsHeader(XContentBuilder  builder,  BroadcastOperationResponse  response)  throws  IOException  {  builder.startObject( "_shards ");  builder.field( "total ",  response.totalShards());  builder.field( "successful ",  response.successfulShards());  builder.field( "failed ",  response.failedShards());  if  (!response.shardFailures().isEmpty())  {  builder.startArray( "failures ");  for  (ShardOperationFailedException  shardFailure  :  response.shardFailures())  {  builder.startObject();  if  (shardFailure.index()  !=  null)  {                      builder.field( "index ",  shardFailure.index());                      builder.field( "index ",  shardFailure.index(),  XContentBuilder.FieldCaseConversion.NONE);  }  if  (shardFailure.shardId()  !=  -1)  {  builder.field( "shard ",  shardFailure.shardId());  }  builder.field( "reason ",  shardFailure.reason());  builder.endObject();  }  builder.endArray();  	builder.field( "index ",  shardFailure.index(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_198b219baf28634b485e788071ebaa31fac0a9c0	buggy:  if  (boolBuilder.clauses().isEmpty())  {  context:  }  if  (!fields.isEmpty())  {  parseSource(getResponse,  boolBuilder,  docMapper,  fields,  request);  }  }  else  {  parseSource(getResponse,  boolBuilder,  docMapper,  fields,  request);  }                      if  (boolBuilder.clauses().isEmpty())  {                      if  (!boolBuilder.hasClauses())  {  listener.onFailure(new  ElasticSearchException( "No  fields  found  to  fetch  the  'likeText'  from "));  return;  }  Term  uidTerm  =  docMapper.uidMapper().term(request.type(),  request.id());  boolBuilder.mustNot(termQuery(uidTerm.field(),  uidTerm.text()));  	if  (!boolBuilder.hasClauses())  {  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);  context:  }  if  (request.metaData())  {  MetaData.Builder  mdBuilder;  if  (request.indices().length  ==  0)  {  mdBuilder  =  MetaData.builder(currentState.metaData());  }  else  {  mdBuilder  =  MetaData.builder();  }  if  (request.indices().length  >  0)  {                  String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);                  String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.lenientExpandOpen());  for  (String  filteredIndex  :  indices)  {  IndexMetaData  indexMetaData  =  currentState.metaData().index(filteredIndex);  if  (indexMetaData  !=  null)  {  mdBuilder.put(indexMetaData,  false);  }  }  }  	String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.lenientExpandOpen());  
libgdx_f22feecdec37cfbe6fb89a3c620ef7f6ef32778d	buggy:  public  SubMesh  getSubMesh(String  name)  {  context:  for  (StillSubMesh  subMesh  :  this.subMeshes)  if  (name.equals(subMesh.name))  subMeshes.add(subMesh);  if  (subMeshes.size()  >  0)  return  new  StillModel(subMeshes.toArray(new  StillSubMesh[subMeshes  .size()]));  return  null;  }  public  SubMesh  getSubMesh(String  name)  {  public  StillSubMesh  getSubMesh(String  name)  {  for  (StillSubMesh  subMesh  :  subMeshes)  {  if  (subMesh.name.equals(name))  return  subMesh;  }  return  null;  }  	public  StillSubMesh  getSubMesh(String  name)  {  
elasticsearch_40d4a350fd355950f80cadb72c3bb8635f3b58c2	buggy:  return  aliasAndIndexToIndexMap2.get(index)  !=  null;  context:  throw  new  ElasticSearchIllegalArgumentException( "Alias  [ "  +  index  +   "]  has  more  than  one  indices  associated  with  it  [ "  +  Arrays.toString(lst)  +   "],  can't  execute  a  single  index  op ");  }  return  lst[0];  }  public  boolean  hasIndex(String  index)  {  return  indices.containsKey(index);  }  public  boolean  hasConcreteIndex(String  index)  {          return  aliasAndIndexToIndexMap2.get(index)  !=  null;          return  aliasAndIndexToIndexMap2.containsKey(index);  }  public  IndexMetaData  index(String  index)  {  return  indices.get(index);  }  public  ImmutableMap<String,  IndexMetaData>  indices()  {  return  this.indices;  	return  aliasAndIndexToIndexMap2.containsKey(index);  
libgdx_b9e0116d0ab0634b55e71b2b1c77f0aef0b713aa	buggy:  int  result  =  BufferUtils.copy(  vertices,  this.vertices,  count,  offset  );  context:  public  void  setVertices(float[]  vertices,  int  offset,  int  count)  {  if(  useFixedPoint  )  throw  new  IllegalArgumentException(   "can't  set  float  vertices  for  fixed  point  mesh "  );  int  result  =  BufferUtils.copy(  vertices,  this.vertices,  count,  offset  );  BufferUtils.copy(  vertices,  this.vertices,  count,  offset  );  this.verticesFloat.limit(this.vertices.limit()>>2);  this.verticesFloat.position(0);  dirty  =  true;  }  	BufferUtils.copy(  vertices,  this.vertices,  count,  offset  );  
elasticsearch_aec720218d0b685c60a2c31c2c766dda7da23c2b	buggy:  return  new  InternalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);  context:  counts.adjustOrPutValue(bucket,  1,  1);  totals.adjustOrPutValue(bucket,  value,  value);  }  keyScript.setNextReader(reader);  valueScript.setNextReader(reader);  }          return  new  InternalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);          return  new  InternalCountAndTotalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  }  	return  new  InternalCountAndTotalHistogramFacet(facetName,   "_na ",   "_na ",  -1,  comparatorType,  counts,  totals);  
elasticsearch_9d979dfc015ee8de43a1080d817f48a1583b8ae9	buggy:  return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.network(),  request.transport(),  request.http());  context:  }  protected  NodeStats  newNodeResponse()  {  return  new  NodeStats();  }  protected  NodeStats  nodeOperation(NodeStatsRequest  nodeStatsRequest)  throws  ElasticSearchException  {  NodesStatsRequest  request  =  nodeStatsRequest.request;          return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.network(),  request.transport(),  request.http());          return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeStatsRequest  extends  NodeOperationRequest  {  	return  nodeService.stats(request.indices(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),  request.network(),  request.transport(),  request.http());  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  TransportDeleteMappingAction  deleteMappingAction;  ThreadPool  threadPool,  MetaDataDeleteIndexService  deleteIndexService,  TransportDeleteMappingAction  deleteMappingAction)  {  super(settings,  transportService,  clusterService,  threadPool);  this.deleteIndexService  =  deleteIndexService;  this.deleteMappingAction  =  deleteMappingAction;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.DELETE;  }  return  new  DeleteIndexRequest();  	return  ThreadPool.Names.MANAGEMENT;  
libgdx_fa187b882171fc0c6cf049a85bcaae26d2261328	buggy:  if  (objects  ==  null)  continue;  context:  if  (pool  ==  null)  return;  //  Ignore  freeing  an  object  that  was  never  retained.  pool.free(object);  }  static  public  void  freeAll  (Array  objects)  {  if  (objects  ==  null)  throw  new  IllegalArgumentException( "objects  cannot  be  null. ");  for  (int  i  =  0,  n  =  objects.size;  i  <  n;  i++)  {  Object  object  =  objects.get(i);  if  (objects  ==  null)  continue;  if  (object  ==  null)  continue;  ReflectionPool  pool  =  typePools.get(object.getClass());  if  (pool  ==  null)  return;  //  Ignore  freeing  an  object  that  was  never  retained.  pool.free(object);  }  }  private  Pools  ()  {  }  	if  (object  ==  null)  continue;  
elasticsearch_1dc8c079da83bb37d537d23663fdf90991d74d9d	buggy:  return  clusterStateResponse.getState()  !=  null;  context:  if  (randomBoolean())  {  Thread.sleep(between(1,  400));  //  wait  a  bit  and  give  is  a  chance  to  try  to  allocate  }  clusterHealth  =  client().admin().cluster().health(clusterHealthRequest().waitForNodes( "1 ")).actionGet();  assertThat(clusterHealth.isTimedOut(),  equalTo(false));  assertThat(clusterHealth.getStatus(),  equalTo(ClusterHealthStatus.RED));  //  nothing  allocated  yet  assertThat(awaitBusy(new  Predicate<Object>()  {  public  boolean  apply(Object  input)  {  ClusterStateResponse  clusterStateResponse  =  cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();                  return  clusterStateResponse.getState()  !=  null;                  return  clusterStateResponse.getState()  !=  null  &&  clusterStateResponse.getState().routingTable().index( "test ")  !=  null;  }}),  equalTo(true));  //  wait  until  we  get  a  cluster  state  -  could  be  null  if  we  quick  enough.  final  ClusterStateResponse  clusterStateResponse  =  cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();  assertThat(clusterStateResponse.getState(),  notNullValue());  assertThat(clusterStateResponse.getState().routingTable().index( "test "),  notNullValue());  assertThat(clusterStateResponse.getState().routingTable().index( "test ").allPrimaryShardsActive(),  is(false));  client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "recovery.initial_shards ",  1)).get();  	return  clusterStateResponse.getState()  !=  null  &&  clusterStateResponse.getState().routingTable().index( "test ")  !=  null;  
elasticsearch_f869951364ef1c5f437b65e4bb8004283cb69ecb	buggy:  injector.getInstance(MapperService.class).type( "person ").parse(copyToBytesFromClasspath( "/org/elasticsearch/index/query/xcontent/data.json "));  context:  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index)  ).createInjector();  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/query/xcontent/mapping.json ");  injector.getInstance(MapperService.class).add( "person ",  mapping);          injector.getInstance(MapperService.class).type( "person ").parse(copyToBytesFromClasspath( "/org/elasticsearch/index/query/xcontent/data.json "));          injector.getInstance(MapperService.class).documentMapper( "person ").parse(copyToBytesFromClasspath( "/org/elasticsearch/index/query/xcontent/data.json "));  this.queryParser  =  injector.getInstance(IndexQueryParserService.class);  }  private  XContentIndexQueryParser  queryParser()  throws  IOException  {  return  (XContentIndexQueryParser)  this.queryParser.defaultIndexQueryParser();  }  	injector.getInstance(MapperService.class).documentMapper( "person ").parse(copyToBytesFromClasspath( "/org/elasticsearch/index/query/xcontent/data.json "));  
elasticsearch_ef861a6b7b97994567cd2a4cdd6ac14fb7c79d64	buggy:  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  face  [ "  +  name  +   "] ");  context:  public  GeoDistanceFacetBuilder  filter(XContentFilterBuilder  filter)  {  this.filter  =  filter;  return  this;  }  if  (fieldName  ==  null)  {  throw  new  SearchSourceBuilderException( "field  must  be  set  on  geo_distance  facet  for  facet  [ "  +  name  +   "] ");  }  if  (entries.isEmpty())  {              throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  face  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);  builder.startObject(GeoDistanceFacetCollectorParser.NAME);  if  (geohash  !=  null)  {  builder.field(fieldName,  geohash);  	throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  geo_distance  facet  [ "  +  name  +   "] ");  
elasticsearch_4492293b4936d5c59fe3602b20daf17ae2c6c2cd	buggy:  return  Integer.MIN_VALUE;  context:  this.nullValueAsString  =  nullValue  ==  null  ?  null  :  nullValue.toString();  }  return  32;  }  byte[]  value  =  field.getBinaryValue();  if  (value  ==  null)  {              return  Integer.MIN_VALUE;              return  null;  }  return  Numbers.bytesToInt(value);  }  return  indexedValue(Integer.parseInt(value));  }  	return  null;  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  shardTarget,  indexShard.searcher(),  indexService,  indexShard,  context:  }  protected  ShardCountResponse  shardOperation(ShardCountRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());  SearchContext  context  =  new  DefaultSearchContext(0,  new  ShardSearchRequest().types(request.types()).filteringAliases(request.filteringAliases()),                  shardTarget,  indexShard.searcher(),  indexService,  indexShard,                  shardTarget,  indexShard.acquireSearcher(),  indexService,  indexShard,  scriptService,  cacheRecycler);  SearchContext.setCurrent(context);  try  {  if  (request.minScore()  !=  -1)  {  context.minimumScore(request.minScore());  }  	shardTarget,  indexShard.acquireSearcher(),  indexService,  indexShard,  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  immutableCluster().wipeIndices( "test ");  context:  final  String  fieldName  =   "field ";  final  String  mapping  =   "{  \ " "  +  mappingType  +   "\ ":  { "  +   "\ "dynamic_templates\ ":  [ "   "{  \ " "  +  fieldName  +   "\ ":  { "  +   "\ "path_match\ ":  \ "*\ ", "  +   "\ "mapping\ ":  { "  +   "\ "type\ ":  \ "string\ ", "  +   "\ "store\ ":  \ "yes\ ", "   "\ "index\ ":  \ "analyzed\ ",  \ "analyzer\ ":  \ "whitespace\ "  }  }  }  ]  }  } ";  int  iters  =  scaledRandomIntBetween(5,  15);  for  (int  i  =  0;  i  <  iters;  i++)  {              immutableCluster().wipeIndices( "test ");              cluster().wipeIndices( "test ");  assertAcked(prepareCreate( "test ")  .addMapping(mappingType,  mapping));  ensureYellow();  int  numDocs  =  scaledRandomIntBetween(10,  100);  final  CountDownLatch  latch  =  new  CountDownLatch(numDocs);  final  List<Throwable>  throwable  =  new  CopyOnWriteArrayList<>();  int  currentID  =  0;  for  (int  j  =  0;  j  <  numDocs;  j++)  {  	cluster().wipeIndices( "test ");  
elasticsearch_82e9a4e80a398d7cfc729347a1f3e8b34f2aa17c	buggy:  builder.field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  context:  ((InternalAggregations)  bucket.getAggregations()).writeTo(out);  }  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(name);  builder.startArray(CommonFields.BUCKETS);  for  (InternalTerms.Bucket  bucket  :  buckets)  {  builder.startObject();              builder.field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);              builder.utf8Field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  builder.field(CommonFields.DOC_COUNT,  bucket.getDocCount());  ((InternalAggregations)  bucket.getAggregations()).toXContentInternal(builder,  params);  builder.endObject();  }  builder.endArray();  builder.endObject();  return  builder;  }  	builder.utf8Field(CommonFields.KEY,  ((Bucket)  bucket).termBytes);  
libgdx_07b497ea207e17445692c3c53c2bceae32f6ea20	buggy:  (  (viewportHeight  -screenY-1)  *  scale  )  -  (  viewportHeight  *  scale  )  /  2  +  position.y  );  context:  public  void  getScreenToWorld(  float  screenX,  float  screenY,  Vector2  world  )  {  screenX  =  screenX  /  graphics.getWidth()  *  viewportWidth;  screenY  =  screenY  /  graphics.getHeight()  *  viewportHeight;  world.set(  (  screenX  *  scale  )  -  (  viewportWidth  *  scale  )  /  2  +  position.x,    (  (viewportHeight  -screenY-1)  *  scale  )  -  (  viewportHeight  *  scale  )  /  2  +  position.y  );    (  (viewportHeight  -screenY)  *  scale  )  -  (  viewportHeight  *  scale  )  /  2  +  position.y  );  }  	(  (viewportHeight  -screenY)  *  scale  )  -  (  viewportHeight  *  scale  )  /  2  +  position.y  );  
elasticsearch_d3ba8bd48741d58b2d1192aa9701ea3147215e37	buggy:  }  else  if  ( "order ".equals(currentFieldName)  ||   "comparator ".equals(field))  {  context:  }  else  if  ( "script_field ".equals(currentFieldName))  {  script  =  parser.text();  }  else  if  ( "size ".equals(currentFieldName))  {  size  =  parser.intValue();  }  else  if  ( "all_terms ".equals(currentFieldName)  ||   "allTerms ".equals(currentFieldName))  {  allTerms  =  parser.booleanValue();  }  else  if  ( "regex ".equals(currentFieldName))  {  regex  =  parser.text();  }  else  if  ( "regex_flags ".equals(currentFieldName)  ||   "regexFlags ".equals(currentFieldName))  {  regexFlags  =  parser.text();                  }  else  if  ( "order ".equals(currentFieldName)  ||   "comparator ".equals(field))  {                  }  else  if  ( "order ".equals(currentFieldName)  ||   "comparator ".equals(currentFieldName))  {  comparatorType  =  TermsFacet.ComparatorType.fromString(parser.text());  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  }  }  	}  else  if  ( "order ".equals(currentFieldName)  ||   "comparator ".equals(currentFieldName))  {  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealth().waitForYellowStatus()).actionGet();  context:  closeAllNodes();  }  startNode( "server1 ");  client( "server1 ").admin().indices().prepareCreate( "test ").execute().actionGet(5000);          ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealth().waitForYellowStatus()).actionGet();          ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  client( "server1 ").index(indexRequest( "test ").type( "type1 ").id( "1 ").source(source( "1 ",   "test "))).actionGet();  FlushResponse  flushResponse  =  client( "server1 ").admin().indices().flush(flushRequest( "test ")).actionGet();  assertThat(flushResponse.totalShards(),  equalTo(10));  assertThat(flushResponse.successfulShards(),  equalTo(5));  	ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest().waitForYellowStatus()).actionGet();  
libgdx_4c4ca256f2daccfae510701b584b469fa97d1706	buggy:  cache.draw(batch,  color.a  *  parentAlpha);  context:  public  void  draw  (Batch  batch,  float  parentAlpha)  {  validate();  Color  color  =  getColor();  if  (style.background  !=  null)  {  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  style.background.draw(batch,  getX(),  getY(),  getWidth(),  getHeight());  }  cache.setColor(style.fontColor  ==  null  ?  color  :  Color.tmp.set(color).mul(style.fontColor));  cache.setPosition(getX(),  getY());  cache.draw(batch,  color.a  *  parentAlpha);  cache.draw(batch,  parentAlpha);  }  public  float  getPrefWidth  ()  {  if  (wrap)  return  0;  if  (sizeInvalid)  computeSize();  float  width  =  bounds.width;  Drawable  background  =  style.background;  if  (background  !=  null)  width  +=  background.getLeftWidth()  +  background.getRightWidth();  	cache.draw(batch,  parentAlpha);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  buildBroadcastShardsHeader(builder,  response);  Suggest  suggest  =  response.getSuggest();  if  (suggest  !=  null)  {  suggest.toXContent(builder,  request);  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  context:  return  null;  }  if  (childType  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  filter  requires  'type'  field ");  }  DocumentMapper  childDocMapper  =  parseContext.mapperService().documentMapper(childType);  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  mapping  for  for  type  [ "  +  childType  +   "] ");  }          if  (childDocMapper.parentFieldMapper()  ==  null)  {          if  (!childDocMapper.parentFieldMapper().active())  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  	if  (!childDocMapper.parentFieldMapper().active())  {  
libgdx_6b7b85dc781ea82e732e85b049aa252595041f49	buggy:  if  (w  >=  other.portraitHeight  &&  other.portraitHeight  >=  best.portraitHeight  &&  w  >=  other.portraitWidth  context:  Resolution  best  =  descriptors[0];  if  (w  <  h)  {  for  (int  i  =  0,  n  =  descriptors.length;  i  <  n;  i++)  {  Resolution  other  =  descriptors[i];  if  (w  >=  other.portraitWidth  &&  other.portraitWidth  >=  best.portraitWidth  &&  h  >=  other.portraitHeight  &&  other.portraitHeight  >=  best.portraitHeight)  best  =  descriptors[i];  }  }  else  {  for  (int  i  =  0,  n  =  descriptors.length;  i  <  n;  i++)  {  Resolution  other  =  descriptors[i];  if  (w  >=  other.portraitHeight  &&  other.portraitHeight  >=  best.portraitHeight  &&  w  >=  other.portraitWidth  if  (w  >=  other.portraitHeight  &&  other.portraitHeight  >=  best.portraitHeight  &&  h  >=  other.portraitWidth  &&  other.portraitWidth  >=  best.portraitWidth)  best  =  descriptors[i];  }  }  return  best;  }  }  	if  (w  >=  other.portraitHeight  &&  other.portraitHeight  >=  best.portraitHeight  &&  h  >=  other.portraitWidth  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  public  void  testOpenCloseUpdateSettings()  throws  Exception  {  createIndex( "test ");  try  {  client().admin().indices().prepareUpdateSettings( "test ")  .setSettings(ImmutableSettings.settingsBuilder()  .put( "index.refresh_interval ",  -1)  //  this  one  can  change  .put( "index.cache.filter.type ",   "none ")  //  this  one  can't  )  .execute().actionGet();              assert  false;              fail();  }  catch  (ElasticsearchIllegalArgumentException  e)  {  }  IndexMetaData  indexMetaData  =  client().admin().cluster().prepareState().execute().actionGet().getState().metaData().index( "test ");  assertThat(indexMetaData.settings().get( "index.refresh_interval "),  nullValue());  assertThat(indexMetaData.settings().get( "index.cache.filter.type "),  nullValue());  	fail();  
libgdx_76b37870539ba3ef57487269afe9b739149c726b	buggy:  durationTimer  =  0;  context:  }  public  void  start  ()  {  firstUpdate  =  true;  allowCompletion  =  false;  restart();  }  public  void  reset  ()  {  emissionDelta  =  0;  durationTimer  =  0;  durationTimer  =  duration;  start();  }  private  void  restart  ()  {  delay  =  delayValue.active  ?  delayValue.newLowValue()  :  0;  delayTimer  =  0;  durationTimer  -=  duration;  	durationTimer  =  duration;  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "nullValue ",  nullValue);  context:  }  return  JSON_TYPE;  }  builder.startObject(jsonType());  builder.field( "name ",  name());  if  (nullValue  !=  null)  {              builder.field( "nullValue ",  nullValue);              builder.field( "null_value ",  nullValue);  }  builder.endObject();  }  }  }  	builder.field( "null_value ",  nullValue);  
elasticsearch_dab23a4d51ecb87f056c27789f5af99bef0a98a5	buggy:  assertThat(response.getStatus(),  equalTo(Status.OK));  context:  node.close();  }  RestRequest  request  =  new  RestRequest(Method.POST,   "/test/type1 ");  request.setBody(ByteBuffer.wrap(XContentFactory.jsonBuilder().startObject()  .field( "field ",   "value ")  .endObject().copiedBytes()));  RestResponse  response  =  client.execute(request);  Map<String,  Object>  map  =  parseBody(response);          assertThat(response.getStatus(),  equalTo(Status.OK));          assertThat(response.getStatus(),  equalTo(Status.CREATED));  assertThat(map.get( "ok ").toString(),  equalTo( "true "));  assertThat(map.get( "_index ").toString(),  equalTo( "test "));  assertThat(map.get( "_type ").toString(),  equalTo( "type1 "));  request  =  new  RestRequest(Method.GET,   "/_cluster/health ");  response  =  client.execute(request);  assertThat(response.getStatus(),  equalTo(Status.OK));  }  	assertThat(response.getStatus(),  equalTo(Status.CREATED));  
libgdx_e2d8370eaf12f29bcf3365ad5e46ed2df382982f	buggy:  pressed  =  Gdx.input.isButtonPressed(button)  &&  isOver(event.getCurrentTarget(),  x,  y);  context:  public  boolean  isOver  (Actor  actor,  float  x,  float  y)  {  Actor  hit  =  actor.hit(x,  y);  if  (hit  ==  null  ||  !hit.isDescendant(actor))  {  if  (touchDownX  ==  -1  &&  touchDownY  ==  -1)  return  false;  return  Math.abs(x  -  touchDownX)  <  tapSquareSize  &&  Math.abs(y  -  touchDownY)  <  tapSquareSize;  }  return  true;  }  public  void  touchDragged  (ActorEvent  event,  float  x,  float  y,  int  pointer)  {  pressed  =  Gdx.input.isButtonPressed(button)  &&  isOver(event.getCurrentTarget(),  x,  y);  pressed  =  Gdx.input.isButtonPressed(button)  &&  isOver(event.getListenerActor(),  x,  y);  if  (!pressed)  {  touchDownX  =  -1;  touchDownY  =  -1;  }  }  public  void  touchUp  (ActorEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  	pressed  =  Gdx.input.isButtonPressed(button)  &&  isOver(event.getListenerActor(),  x,  y);  
libgdx_5578e1c0034aeb2e958490df8a25db017c69b8ed	buggy:  spriteBatch.draw(texture,  centerX  -  texture.getWidth()  /  2,  centerY  +  texture.getHeight()  /  2,  0,  0,  texture.getWidth(),  context:  int  centerY  =  Gdx.graphics.getHeight()  /  2;  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  if  (textPosition.x  <  0  ||  textPosition.x  >  Gdx.graphics.getWidth())  textDirection.x  =  -textDirection.x;  if  (textPosition.y  <  0  ||  textPosition.y  >  Gdx.graphics.getHeight())  textDirection.y  =  -textDirection.y;  textPosition.add(textDirection.tmp().mul(Gdx.graphics.getDeltaTime()).mul(60));  spriteBatch.begin();  spriteBatch.draw(texture,  centerX  -  texture.getWidth()  /  2,  centerY  +  texture.getHeight()  /  2,  0,  0,  texture.getWidth(),  spriteBatch.draw(texture,  centerX  -  texture.getWidth()  /  2,  centerY  -  texture.getHeight()  /  2,  0,  0,  texture.getWidth(),  texture.getHeight(),  Color.WHITE);  spriteBatch.drawText(font,   "Hello  World! ",  (int)textPosition.x,  (int)textPosition.y,  Color.RED);  spriteBatch.end();  }  }  	spriteBatch.draw(texture,  centerX  -  texture.getWidth()  /  2,  centerY  -  texture.getHeight()  /  2,  0,  0,  texture.getWidth(),  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  IndexWriterConfig  iwc  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  null);  context:  public  class  TestReplaceMissing  extends  ElasticsearchLuceneTestCase  {  public  void  test()  throws  Exception  {  Directory  dir  =  newDirectory();          IndexWriterConfig  iwc  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  null);          IndexWriterConfig  iwc  =  newIndexWriterConfig(null);  iwc.setMergePolicy(newLogMergePolicy());  IndexWriter  iw  =  new  IndexWriter(dir,  iwc);  Document  doc  =  new  Document();  doc.add(new  SortedDocValuesField( "field ",  new  BytesRef( "cat ")));  iw.addDocument(doc);  doc  =  new  Document();  	IndexWriterConfig  iwc  =  newIndexWriterConfig(null);  
elasticsearch_07ab5dcf9b4180f66fa89ea3539a429dcde18833	buggy:  builder.field( "_type ",   "histogram ");  context:  }  if  (totals  ==  null)  {  totals  =  EMPTY_LONG_DOUBLE_MAP;  }  return  new  InternalHistogramFacet(name,  keyFieldName,  valueFieldName,  interval,  comparatorType,  counts,  totals);  }  builder.startObject(name);          builder.field( "_type ",   "histogram ");          builder.field( "_type ",  HistogramFacetCollectorParser.NAME);  builder.field( "_key_field ",  keyFieldName);  builder.field( "_value_field ",  valueFieldName);  builder.field( "_comparator ",  comparatorType.description());  builder.field( "_interval ",  interval);  builder.startArray( "entries ");  for  (Entry  entry  :  computeEntries())  {  builder.startObject();  builder.field( "key ",  entry.key());  	builder.field( "_type ",  HistogramFacetCollectorParser.NAME);  
elasticsearch_2594828d48f100e897e03ccd02a45151a6df913c	buggy:  logger.warn( "received  ping  response  with  no  matching  id  [{}] ",  response.id);  context:  continue;  }  if  (!pingResponse.clusterName().equals(clusterName))  {  return;  }  ConcurrentMap<DiscoveryNode,  PingResponse>  responses  =  receivedResponses.get(response.id);  if  (responses  ==  null)  {                              logger.warn( "received  ping  response  with  no  matching  id  [{}] ",  response.id);                              logger.warn( "received  ping  response  {}  with  no  matching  id  [{}] ",  pingResponse,  response.id);  }  else  {  responses.put(pingResponse.target(),  pingResponse);  }  }  }  finally  {  latch.countDown();  }  }  	logger.warn( "received  ping  response  {}  with  no  matching  id  [{}] ",  pingResponse,  response.id);  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  {  context:  public  Class<?  extends  IndexShardGateway>  shardGatewayClass()  {  return  LocalIndexShardGateway.class;  }  public  String  toString()  {  return   "local ";  }      public  void  close(boolean  delete)  {      public  void  close()  {  }  }  	public  void  close()  {  
elasticsearch_19ff93b09af046d5a5223265698e90ce40b3040d	buggy:  return  false;  context:  }  }  }          return  false;          return  true;  }  if  (!enabled)  {  return  null;  }  context.allEntries().reset();  	return  true;  
elasticsearch_b49a1c441c1ba2e599f6469a3dfb89e285e113be	buggy:  this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  true),  channel.getAddress().toString(),  transportService.boundAddress().publishAddress());  context:  initialStateListeners.remove(listener);  }  try  {  channel.connect(clusterName.value());  channel.setReceiver(this);              this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  true),  channel.getAddress().toString(),  transportService.boundAddress().publishAddress());              this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  !settings.getAsBoolean( "node.client ",  false)),  channel.getAddress().toString(),  transportService.boundAddress().publishAddress());  if  (isMaster())  {  firstMaster  =  true;  clusterService.submitStateUpdateTask( "jgroups-disco-initialconnect(master) ",  new  ProcessedClusterStateUpdateTask()  {  DiscoveryNodes.Builder  builder  =  new  DiscoveryNodes.Builder()  .localNodeId(localNode.id())  .masterNodeId(localNode.id())  	this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  !settings.getAsBoolean( "node.client ",  false)),  channel.getAddress().toString(),  transportService.boundAddress().publishAddress());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  new  CopyOnWriteArrayList<IndexShardState>(new  IndexShardState[]{newState}));  context:  stateChangeListener.shardStates.clear();  }  private  static  class  IndexShardStateChangeListener  extends  IndicesLifecycle.Listener  {  final  ConcurrentMap<ShardId,  List<IndexShardState>>  shardStates  =  Maps.newConcurrentMap();  public  void  indexShardStateChanged(IndexShard  indexShard,  @Nullable  IndexShardState  previousState,  IndexShardState  newState,  @Nullable  String  reason)  {  List<IndexShardState>  shardStates  =  this.shardStates.putIfAbsent(indexShard.shardId(),                      new  CopyOnWriteArrayList<IndexShardState>(new  IndexShardState[]{newState}));                      new  CopyOnWriteArrayList<>(new  IndexShardState[]{newState}));  if  (shardStates  !=  null)  {  shardStates.add(newState);  }  }  public  String  toString()  {  StringBuilder  sb  =  new  StringBuilder();  	new  CopyOnWriteArrayList<>(new  IndexShardState[]{newState}));  
elasticsearch_6fb836c25e6cb31972ca24dc3f9739e7660d620e	buggy:  },   "es[keepAlive] ");  context:  keepAliveThread  =  new  Thread(new  Runnable()  {  public  void  run()  {  try  {  keepAliveLatch.await();  }  catch  (InterruptedException  e)  {  }  }              },   "es[keepAlive] ");              },   "elasticsearch[keepAlive] ");  keepAliveThread.setDaemon(false);  keepAliveThread.start();  }  catch  (Throwable  e)  {  ESLogger  logger  =  Loggers.getLogger(Bootstrap.class);  if  (bootstrap.node  !=  null)  {  }  String  errorMessage  =  buildErrorMessage(stage,  e);  	},   "elasticsearch[keepAlive] ");  
elasticsearch_86dfad24fe1c77e0a6df992381f68fe66f6d087a	buggy:  if  (script  !=  null  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {  context:  public  void  writeTo(StreamOutput  out)  throws  IOException  {  super.writeTo(out);  out.writeByte(replicationType.id());  out.writeByte(consistencyLevel.id());  out.writeSharedString(type);  out.writeString(id);  out.writeOptionalString(routing);  out.writeOptionalString(script);          if  (script  !=  null  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {          if  (Strings.hasLength(script)  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {  ScriptService.ScriptType.writeTo(scriptType,  out);  }  out.writeOptionalString(scriptLang);  out.writeMap(scriptParams);  out.writeVInt(retryOnConflict);  out.writeBoolean(refresh);  if  (doc  ==  null)  {  out.writeBoolean(false);  	if  (Strings.hasLength(script)  &&  out.getVersion().onOrAfter(Version.V_1_3_0))  {  
elasticsearch_1d39bb4d51796df342cc41eeb53af0be1f7418bf	buggy:  return  new  RamStore(shardId,  EMPTY_SETTINGS);  context:  engine  =  createEngine(store);  engine.start();  }  engine.close();  store.close();  }  protected  Store  createStore()  throws  IOException  {          return  new  RamStore(shardId,  EMPTY_SETTINGS);          return  new  RamStore(shardId,  EMPTY_SETTINGS,  null);  }  protected  Translog  createTranslog()  {  return  new  MemoryTranslog(shardId,  EMPTY_SETTINGS);  }  protected  IndexDeletionPolicy  createIndexDeletionPolicy()  {  return  new  KeepOnlyLastDeletionPolicy(shardId,  EMPTY_SETTINGS);  	return  new  RamStore(shardId,  EMPTY_SETTINGS,  null);  
elasticsearch_a9e2433dab3ced5de25b8483d56cf293f110d38e	buggy:  MappingMetaData  mappingMd  =  clusterState.metaData().index(request.index()).mapping(indexRequest.type());  context:  Set<Tuple<String,  String>>  mappingsToUpdate  =  null;  BulkItemResponse[]  responses  =  new  BulkItemResponse[request.items().length];  for  (int  i  =  0;  i  <  request.items().length;  i++)  {  BulkItemRequest  item  =  request.items()[i];  if  (item.request()  instanceof  IndexRequest)  {  IndexRequest  indexRequest  =  (IndexRequest)  item.request();  try  {                      MappingMetaData  mappingMd  =  clusterState.metaData().index(request.index()).mapping(indexRequest.type());                      MappingMetaData  mappingMd  =  clusterState.metaData().index(request.index()).mappingOrDefault(indexRequest.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required())  {  if  (indexRequest.routing()  ==  null)  {  throw  new  RoutingMissingException(indexRequest.index(),  indexRequest.type(),  indexRequest.id());  }  }  SourceToParse  sourceToParse  =  SourceToParse.source(indexRequest.underlyingSource(),  indexRequest.underlyingSourceOffset(),  indexRequest.underlyingSourceLength()).type(indexRequest.type()).id(indexRequest.id())  .routing(indexRequest.routing()).parent(indexRequest.parent()).timestamp(indexRequest.timestamp()).ttl(indexRequest.ttl());  	MappingMetaData  mappingMd  =  clusterState.metaData().index(request.index()).mappingOrDefault(indexRequest.type());  
elasticsearch_6e19ca808056e3c69545a837180d23faa863fec7	buggy:  builder.byteSizeField(Fields.MEMORY_SIZE,  Fields.MEMORY_SIZE_IN_BYTES,  memorySize);  context:  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  out.writeVLong(memorySize);  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(Fields.ID_CACHE);          builder.byteSizeField(Fields.MEMORY_SIZE,  Fields.MEMORY_SIZE_IN_BYTES,  memorySize);          builder.byteSizeField(Fields.MEMORY_SIZE_IN_BYTES,  Fields.MEMORY_SIZE,  memorySize);  builder.endObject();  return  builder;  }  static  final  class  Fields  {  static  final  XContentBuilderString  ID_CACHE  =  new  XContentBuilderString( "id_cache ");  static  final  XContentBuilderString  MEMORY_SIZE  =  new  XContentBuilderString( "memory_size ");  static  final  XContentBuilderString  MEMORY_SIZE_IN_BYTES  =  new  XContentBuilderString( "memory_size_in_bytes ");  	builder.byteSizeField(Fields.MEMORY_SIZE_IN_BYTES,  Fields.MEMORY_SIZE,  memorySize);  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  return  builder().put( "gateway.type ",   "local ").build();  context:  public  class  RecoveryPercolatorTests  extends  ElasticsearchIntegrationTest  {  protected  int  numberOfShards()  {  return  1;  }  protected  Settings  nodeSettings(int  nodeOrdinal)  {          return  builder().put( "gateway.type ",   "local ").build();          return  builder().put(super.nodeSettings(nodeOrdinal)).put( "gateway.type ",   "local ").build();  }  public  void  testRestartNodePercolator1()  throws  Exception  {  internalCluster().startNode();  createIndex( "test ");  	return  builder().put(super.nodeSettings(nodeOrdinal)).put( "gateway.type ",   "local ").build();  
elasticsearch_3840439365995595f262cd9505890289dcb95c81	buggy:  return  new  StringValues.LongBased(getLongValues());  context:  return  new  BytesValues.StringBased(getStringValues());  }  public  HashedBytesValues  getHashedBytesValues()  {  return  new  HashedBytesValues.StringBased(getStringValues());  }  public  StringValues  getStringValues()  {              return  new  StringValues.LongBased(getLongValues());              return  new  StringValues.IntBased(getIntValues());  }  public  ScriptDocValues  getScriptValues()  {  return  new  ScriptDocValues.NumericInteger(getIntValues());  }  	return  new  StringValues.IntBased(getIntValues());  
elasticsearch_d062b2b0a4123d1ba6e1a7bf6b6abc2287b62398	buggy:  cluster2  =  new  InternalTestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false);  context:  private  static  InternalTestCluster  cluster2;  private  Node  tribeNode;  private  Client  tribeClient;  public  static  void  setupSecondCluster()  throws  Exception  {  ElasticsearchIntegrationTest.beforeClass();          cluster2  =  new  InternalTestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false);          cluster2  =  new  InternalTestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false,  CHILD_JVM_ID);  cluster2.beforeTest(getRandom(),  0.1);  cluster2.ensureAtLeastNumDataNodes(2);  }  public  static  void  tearDownSecondCluster()  {  if  (cluster2  !=  null)  {  try  {  	cluster2  =  new  InternalTestCluster(randomLong(),  2,  2,  Strings.randomBase64UUID(getRandom()),  0,  false,  CHILD_JVM_ID);  
elasticsearch_7a0d7f531d553a8f06879babef049dc6a0eaa80c	buggy:  assertThat(ttl,  lessThan(3600000L));  context:  client.prepareUpdate( "test ",   "type1 ",   "2 ").setScript( "ctx._source.field  +=  1 ").execute().actionGet();  getResponse  =  client.prepareGet( "test ",   "type1 ",   "2 ").setFields( "_ttl ").execute().actionGet();  ttl  =  ((Number)  getResponse.field( "_ttl ").value()).longValue();  assertThat(ttl,  greaterThan(0L));  client.prepareUpdate( "test ",   "type1 ",   "2 ").setScript( "ctx._ttl  =  3600000 ").execute().actionGet();  getResponse  =  client.prepareGet( "test ",   "type1 ",   "2 ").setFields( "_ttl ").execute().actionGet();  ttl  =  ((Number)  getResponse.field( "_ttl ").value()).longValue();  assertThat(ttl,  greaterThan(0L));          assertThat(ttl,  lessThan(3600000L));          assertThat(ttl,  lessThanOrEqualTo(3600000L));  client.prepareIndex( "test ",   "type1 ",   "3 ").setSource( "field ",  1).setRefresh(true).execute().actionGet();  client.prepareUpdate( "test ",   "type1 ",   "3 ").setScript( "ctx._timestamp  =  \ "2009-11-15T14:12:12\ " ").execute().actionGet();  getResponse  =  client.prepareGet( "test ",   "type1 ",   "3 ").setFields( "_timestamp ").execute().actionGet();  long  timestamp  =  ((Number)  getResponse.field( "_timestamp ").value()).longValue();  assertThat(timestamp,  equalTo(1258294332000L));  	assertThat(ttl,  lessThanOrEqualTo(3600000L));  
libgdx_1356a9745d12a46cd5afcd301af9526212f4ab15	buggy:  if  (!particleCollided)  {  context:  final  float  x  =  getX()  +  getWidth()  /  2f;  final  float  y  =  getY()  +  getHeight()  /  2f;  particleCollided  =  false;  startPoint.set(x,  y);  endPoint.set(x  +  velocityX,  y  +  velocityY);  if  (world  !=  null)  world.rayCast(rayCallBack,  startPoint,  endPoint);  if  (!particleCollided)  {  if  (particleCollided)  {  angle  =  2f  *  normalAngle  -  angle  -  180f;  angleCos  =  MathUtils.cosDeg(angle);  angleSin  =  MathUtils.sinDeg(angle);  velocityX  =  velocity  *  angleCos;  velocityY  =  velocity  *  angleSin;  }  	if  (particleCollided)  {  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  ConcreteBytesRefAtomicFieldData(values.toArray(new  BytesRef[values.size()]),  new  SingleArrayOrdinals(ordinals.get(0),  termOrd));  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  ConcreteBytesRefAtomicFieldData(  values.toArray(new  BytesRef[values.size()]),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  BytesRefFieldComparatorSource(this);  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
libgdx_d8f7d5a551ee1b16e3c3a7f15bd518dc18c61f58	buggy:  GdxTest  test  =  new  MD5Test();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  MD5Test();  GdxTest  test  =  new  Box2DTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  Box2DTest();  
elasticsearch_d0f8742f8d31a8a496984d08635b549e9ae1f6d0	buggy:  client().prepareIndex(INDEX,  TYPE,   "1 ").setSource(jsonBuilder()  context:  completionMappingBuilder.indexAnalyzer( "simple ");  createIndexAndMappingAndSettings(settingsBuilder.build(),  completionMappingBuilder);  client().prepareIndex(INDEX,  TYPE,   "1 ").setSource(jsonBuilder()  .startObject().startObject(FIELD)  .startArray( "input ").value( "Feed  trolls ").endArray()  .field( "weight ",  5).endObject().endObject()  ).get();          client().prepareIndex(INDEX,  TYPE,   "1 ").setSource(jsonBuilder()          client().prepareIndex(INDEX,  TYPE,   "2 ").setSource(jsonBuilder()  .startObject().startObject(FIELD)  .startArray( "input ").value( "Feed  the  trolls ").endArray()  .field( "weight ",  10).endObject().endObject()  ).get();  refresh();  assertSuggestions( "f ",   "Feed  the  trolls ",   "Feed  trolls ");  	client().prepareIndex(INDEX,  TYPE,   "2 ").setSource(jsonBuilder()  
elasticsearch_3afdf4a872e257ec95a4436049907ee825d249e0	buggy:  .customs(request.customs());  context:  protected  void  masterOperation(final  CreateIndexRequest  request,  final  ClusterState  state,  final  ActionListener<CreateIndexResponse>  listener)  throws  ElasticsearchException  {  String  cause  =  request.cause();  if  (cause.length()  ==  0)  {  cause  =   "api ";  }  CreateIndexClusterStateUpdateRequest  updateRequest  =  new  CreateIndexClusterStateUpdateRequest(cause,  request.index())  .ackTimeout(request.timeout()).masterNodeTimeout(request.masterNodeTimeout())  .settings(request.settings()).mappings(request.mappings())                  .customs(request.customs());                  .aliases(request.aliases()).customs(request.customs());  createIndexService.createIndex(updateRequest,  new  ClusterStateUpdateListener()  {  public  void  onResponse(ClusterStateUpdateResponse  response)  {  listener.onResponse(new  CreateIndexResponse(response.isAcknowledged()));  }  	.aliases(request.aliases()).customs(request.customs());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.field(Fields.OK,  true);  builder.startArray(Fields.MATCHES);  for  (String  match  :  response)  {  builder.value(match);  }  builder.endArray();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_33d5a722b332f8a9bacfd3d3b5779494eae3cda7	buggy:  boolean  skip  =  restTestSuite.getSetupSection().getSkipSection().skipVersion(parseContext.getCurrentVersion());  context:  public  RestTestSuite  parse(RestTestSuiteParseContext  parseContext)  throws  IOException,  RestTestParseException  {  XContentParser  parser  =  parseContext.parser();  parser.nextToken();  assert  parser.currentToken()  ==  XContentParser.Token.START_OBJECT;  RestTestSuite  restTestSuite  =  new  RestTestSuite(parseContext.getApi(),  parseContext.getSuiteName());  restTestSuite.setSetupSection(parseContext.parseSetupSection());          boolean  skip  =  restTestSuite.getSetupSection().getSkipSection().skipVersion(parseContext.getCurrentVersion());          boolean  skip  =  restTestSuite.getSetupSection().getSkipSection().skip(parseContext.getCurrentVersion());  while(true)  {  if(parser.currentToken()  ==  null)  {  if  (parser.nextToken()  ==  null)  {  break;  	boolean  skip  =  restTestSuite.getSetupSection().getSkipSection().skip(parseContext.getCurrentVersion());  
libgdx_53c753014534ac75ddb453622d7e9113b3fa7d25	buggy:  return  new  LwjglFileHandle(file);  context:  file  =  new  File(filename);  else  file  =  new  File(this.externalPath  +  filename);  if  (!file.exists())  file  =  new  File( "resources/ "  +  filename);  if  (file.exists()  ==  false)  throw  new  GdxRuntimeException( "File  ' "  +  filename  +   "'  doesn't  exist ");  else  return  new  LwjglFileHandle(file);  return  new  LwjglFileHandle(file,  type);  }  public  String[]  listDirectory  (String  directory,  FileType  type)  {  File  file  =  null;  if  (type  ==  FileType.Absolute  ||  type  ==  FileType.Internal)  file  =  new  File(directory);  else  file  =  new  File(this.externalPath  +  directory);  	return  new  LwjglFileHandle(file,  type);  
elasticsearch_b02e6dc996d3985a8a136f290c4a8810ce05aaab	buggy:  request.network(),  request.transport(),  request.http(),  request.plugin());  context:  protected  NodeInfo  newNodeResponse()  {  return  new  NodeInfo();  }  protected  NodeInfo  nodeOperation(NodeInfoRequest  nodeRequest)  throws  ElasticsearchException  {  NodesInfoRequest  request  =  nodeRequest.request;  return  nodeService.info(request.settings(),  request.os(),  request.process(),  request.jvm(),  request.threadPool(),                  request.network(),  request.transport(),  request.http(),  request.plugin());                  request.network(),  request.transport(),  request.http(),  request.plugins());  }  protected  boolean  accumulateExceptions()  {  return  false;  }  static  class  NodeInfoRequest  extends  NodeOperationRequest  {  	request.network(),  request.transport(),  request.http(),  request.plugins());  
elasticsearch_e79b7086de26ece61edaca74fcf7dc99a11de486	buggy:  .setScript( "ctx._source.field  =  'value2' ")  context:  }  for  (int  i  =  0;  i  <  5;  i++)  {  assertThat(client().prepareGet( "alias0 ",   "type1 ",   "1 ").execute().actionGet().isExists(),  equalTo(true));  }  client().prepareUpdate( "alias0 ",   "type1 ",   "1 ")  .setUpsert(XContentFactory.jsonBuilder().startObject().field( "field ",  1).endObject())                  .setScript( "ctx._source.field  =  'value2' ")                  .setInlineScript( "ctx._source.field  =  'value2' ")  .execute().actionGet();  for  (int  i  =  0;  i  <  5;  i++)  {  assertThat(client().prepareGet( "alias0 ",   "type1 ",   "1 ").execute().actionGet().isExists(),  equalTo(true));  assertThat(client().prepareGet( "alias0 ",   "type1 ",   "1 ").execute().actionGet().getSourceAsMap().get( "field ").toString(),  equalTo( "value2 "));  }  	.setInlineScript( "ctx._source.field  =  'value2' ")  
elasticsearch_9654631186c7845493793eafd49f4232bc392ed1	buggy:  createIndexAndMapping( "standard ",   "standard ",  false,  false,  false);  context:  refresh();  assertSuggestions( "t ",   "The  Prodigy  Firestarter ");  assertSuggestions( "f ",   "Firestarter ");  }  public  void  testThatDisablingPositionIncrementsWorkForStopwords()  throws  Exception  {          createIndexAndMapping( "standard ",   "standard ",  false,  false,  false);          createIndexAndMapping( "classic ",   "classic ",  false,  false,  false);  client().prepareIndex(INDEX,  TYPE,   "1 ").setSource(jsonBuilder()  .startObject().startObject(FIELD)  .startArray( "input ").value( "The  Beatles ").endArray()  .endObject().endObject()  ).get();  refresh();  	createIndexAndMapping( "classic ",   "classic ",  false,  false,  false);  
elasticsearch_3a7f7664b61696141841a5d7e3166d69c28eab98	buggy:  Document  doc  =  docMapper.parse(json).doc();  context:  public  class  GenericStoreDynamicTemplateTests  {  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json ");  DocumentMapper  docMapper  =  MapperTests.newParser().parse(mapping);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json ");          Document  doc  =  docMapper.parse(json).doc();          Document  doc  =  docMapper.parse(json).masterDoc();  Fieldable  f  =  doc.getFieldable( "name ");  assertThat(f.name(),  equalTo( "name "));  assertThat(f.stringValue(),  equalTo( "some  name "));  assertThat(f.isStored(),  equalTo(true));  FieldMappers  fieldMappers  =  docMapper.mappers().fullName( "name ");  assertThat(fieldMappers.mappers().size(),  equalTo(1));  	Document  doc  =  docMapper.parse(json).masterDoc();  
elasticsearch_a414e4f2f3ce03c1cd80ca3ef7d01c370e49d5a7	buggy:  final  int  numNodes  =  immutableCluster().dataNodes();  context:  protected  int  numberOfReplicas()  {  return  0;  }  public  void  testSimpleStats()  throws  Exception  {  client().admin().indices().prepareStats().clear().execute().actionGet();          final  int  numNodes  =  immutableCluster().dataNodes();          final  int  numNodes  =  immutableCluster().numDataNodes();  assertThat(numNodes,  greaterThanOrEqualTo(2));  final  int  shardsIdx1  =  randomIntBetween(1,  10);  //  we  make  sure  each  node  gets  at  least  a  single  shard...  final  int  shardsIdx2  =  Math.max(numNodes  -  shardsIdx1,  randomIntBetween(1,  10));  assertThat(numNodes,  lessThanOrEqualTo(shardsIdx1  +  shardsIdx2));  assertAcked(prepareCreate( "test1 ").setSettings(ImmutableSettings.builder()  .put(SETTING_NUMBER_OF_SHARDS,  shardsIdx1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)));  int  docsTest1  =  scaledRandomIntBetween(3*shardsIdx1,  5*shardsIdx1);  	final  int  numNodes  =  immutableCluster().numDataNodes();  
elasticsearch_fdec15f204220c4b27df2ee77cf21622fc97917c	buggy:  validationException  =  addValidationError( "can't  say  to  upsert  doc  without  providing  doc ",  validationException);  context:  validationException  =  addValidationError( "can't  provide  both  retry_on_conflict  and  a  specific  version ",  validationException);  }  if  (script  ==  null  &&  doc  ==  null)  {  validationException  =  addValidationError( "script  or  doc  is  missing ",  validationException);  }  if  (script  !=  null  &&  doc  !=  null)  {  validationException  =  addValidationError( "can't  provide  both  script  and  doc ",  validationException);  }  if  (doc  ==  null  &&  docAsUpsert)  {              validationException  =  addValidationError( "can't  say  to  upsert  doc  without  providing  doc ",  validationException);              validationException  =  addValidationError( "doc  must  be  specified  if  doc_as_upsert  is  enabled ",  validationException);  }  return  validationException;  }  public  String  type()  {  	validationException  =  addValidationError( "doc  must  be  specified  if  doc_as_upsert  is  enabled ",  validationException);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();  context:  Terms.Bucket  bucket  =  terms.getBucketByKey( "val "  +  i);  assertThat(bucket,  notNullValue());  assertThat(key(bucket),  equalTo( "val "  +  i));  assertThat(bucket.getDocCount(),  equalTo(i  ==  3  ?  2L  :  1L));  }  }  public  void  emptyAggregation()  throws  Exception  {  prepareCreate( "empty_bucket_idx ").addMapping( "type ",  SINGLE_VALUED_FIELD_NAME,   "type=integer ").execute().actionGet();          List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();          List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field(SINGLE_VALUED_FIELD_NAME,  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  	List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  latestDiscoNodes  =  clusterState.nodes();  nodesFD.updateNodes(clusterState.nodes());  publishClusterState.publish(clusterState);  }  private  void  asyncJoinCluster()  {  if  (currentJoinThread  !=  null)  {  return;  }          threadPool.cached().execute(new  Runnable()  {          threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  currentJoinThread  =  Thread.currentThread();  try  {  innterJoinCluster();  }  finally  {  currentJoinThread  =  null;  }  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execStatus(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {  context:  IndicesStatusRequest  indicesStatusRequest  =  new  IndicesStatusRequest(splitIndices(request.param( "index ")));  indicesStatusRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.SINGLE_THREAD;  }  indicesStatusRequest.operationThreading(operationThreading);          client.admin().indices().execStatus(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {          client.admin().indices().status(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  	client.admin().indices().status(indicesStatusRequest,  new  ActionListener<IndicesStatusResponse>()  {  
elasticsearch_4eb85bbbd6204a2b58d8370e046db7903f058996	buggy:  final  int  NUMBER_OF_CLIENTS  =  1;  context:  }  };  public  abstract  Transport  newTransport(Settings  settings,  ThreadPool  threadPool);  }  public  static  void  main(String[]  args)  {  final  String  executor  =  ThreadPool.Names.GENERIC;  final  boolean  waitForRequest  =  true;  final  ByteSizeValue  payloadSize  =  new  ByteSizeValue(100,  ByteSizeUnit.BYTES);          final  int  NUMBER_OF_CLIENTS  =  1;          final  int  NUMBER_OF_CLIENTS  =  10;  final  int  NUMBER_OF_ITERATIONS  =  100000;  final  byte[]  payload  =  new  byte[(int)  payloadSize.bytes()];  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  Type  type  =  Type.NETTY;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .build();  	final  int  NUMBER_OF_CLIENTS  =  10;  
libgdx_d93adf0eb732287cc79847b4c51890db015e3307	buggy:  .color.set(0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  1f);  context:  final  float  BOXOFFSET_X  =  -2.5f;  final  float  BOXOFFSET_Y  =  0.5f;  final  float  BOXOFFSET_Z  =  0f;  public  void  create  ()  {  super.create();  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  0.5f  *  (float)Math.random(),  1f);  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  for  (int  x  =  0;  x  <  BOXCOUNT_X;  x++)  {  for  (int  y  =  0;  y  <  BOXCOUNT_Y;  y++)  {  for  (int  z  =  0;  z  <  BOXCOUNT_Z;  z++)  {  world.add( "box ",  BOXOFFSET_X  +  x,  BOXOFFSET_Y  +  y,  BOXOFFSET_Z  +  z)  .color.set(0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random(),  1f);  }  }  	.color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  
elasticsearch_d6bab1a892cbfdfaa46d8d0657ac0028255866b2	buggy:  return  TransportRequestOptions.options().withCompress(true);  context:  super(settings,  transportService,  BulkResponse.class);  }  return  TransportActions.BULK;  }          return  TransportRequestOptions.options().withCompress(true);          return  TransportRequestOptions.options().withLowType().withCompress(true);  }  }  	return  TransportRequestOptions.options().withLowType().withCompress(true);  
libgdx_ffbdb529fdbb524082a14f9c56519abedd31db28	buggy:  y  +=  parent.y;  context:  else  debugRenderer  =  new  ImmediateModeRenderer10(64);  }  Table  table  =  getTable();  Actor  parent  =  table.parent;  float  x  =  table.x,  y  =  0;  while  (parent  !=  null)  {  if  (parent  instanceof  Group)  {  x  +=  parent.x;  y  +=  parent.y;  y  =  parent.y  +  parent.height  -  y;  }  parent  =  parent.parent;  }  y  =  table.y  +  table.height  -  y;  int  viewHeight  =  Gdx.graphics.getHeight();  debugRenderer.begin(batch.getProjectionMatrix(),  GL10.GL_LINES);  	y  =  parent.y  +  parent.height  -  y;  
elasticsearch_b3866689fa1fe9ad85dbd17b287d53757a2d7764	buggy:  if  (disableDeleteAllIndices  &&  (request.indices()  ==  null  ||  request.indices().length  ==  0))  {  context:  return  new  DeleteIndexRequest();  }  protected  DeleteIndexResponse  newResponse()  {  return  new  DeleteIndexResponse();  }  protected  void  doExecute(DeleteIndexRequest  request,  ActionListener<DeleteIndexResponse>  listener)  {          if  (disableDeleteAllIndices  &&  (request.indices()  ==  null  ||  request.indices().length  ==  0))  {          if  (disableDeleteAllIndices  &&  (request.indices()  ==  null  ||  request.indices().length  ==  0  ||  (request.indices().length  ==  1  &&  request.indices()[0].equals( "_all "))))  {  throw  new  ElasticSearchIllegalArgumentException( "deleting  all  indices  is  disabled ");  }  request.indices(clusterService.state().metaData().concreteIndices(request.indices()));  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(DeleteIndexRequest  request,  ClusterState  state)  {  	if  (disableDeleteAllIndices  &&  (request.indices()  ==  null  ||  request.indices().length  ==  0  ||  (request.indices().length  ==  1  &&  request.indices()[0].equals( "_all "))))  {  
elasticsearch_8e17d636ef441a9be80977d34acfaabc12982eb7	buggy:  protected  XPassageFormatter  getFormatter(String  field)  {  context:  return  fieldValuesOffsets[currentValueIndex];  }  throw  new  IllegalArgumentException( "No  more  values  offsets  to  return ");  }  public  void  setBreakIterator(BreakIterator  breakIterator)  {  this.breakIterator  =  breakIterator;  }      protected  XPassageFormatter  getFormatter(String  field)  {      protected  PassageFormatter  getFormatter(String  field)  {  return  passageFormatter;  }  protected  BreakIterator  getBreakIterator(String  field)  {  if  (breakIterator  ==  null)  {  return  super.getBreakIterator(field);  }  	protected  PassageFormatter  getFormatter(String  field)  {  
elasticsearch_4b06eeb75a09b90c31464bbbe57fca4ff9a3c9d2	buggy:  listener.onIgnoreRecovery(true,   "source  node  disconnected ");  context:  removeAndCleanOnGoingRecovery(request.shardId());  if  (cause  instanceof  ConnectTransportException)  {  listener.onIgnoreRecovery(true,   "source  node  disconnected ");  return;  }  if  (cause  instanceof  IndexShardClosedException)  {                  listener.onIgnoreRecovery(true,   "source  node  disconnected ");                  listener.onIgnoreRecovery(true,   "source  shard  is  closed ");  return;  }  listener.onRecoveryFailure(new  RecoveryFailedException(request,  e),  true);  }  }  	listener.onIgnoreRecovery(true,   "source  shard  is  closed ");  
libgdx_c66c2895bb0f64140fb87b9f366e7063bf2bf3ca	buggy:  Bullet.init();  context:  final  Model  groundModel  =  modelBuilder.createRect(20f,  0f,  -20f,  -20f,  0f,  -20f,  -20f,  0f,  20f,  20f,  0f,  20f,  0,  1,  0,  new  Material(ColorAttribute.createDiffuse(Color.BLUE),  ColorAttribute.createSpecular(Color.WHITE),  FloatAttribute.createShininess(16f)),  Usage.Position  |  Usage.Normal);  models.add(groundModel);  final  Model  sphereModel  =  modelBuilder.createSphere(1f,  1f,  1f,  10,  10,  new  Material(ColorAttribute.createDiffuse(Color.RED),  ColorAttribute.createSpecular(Color.WHITE),  FloatAttribute.createShininess(64f)),  Usage.Position  |  Usage.Normal);  models.add(sphereModel);  Bullet.init();  BaseBulletTest.init();  //  Normally  use:  Bullet.init();  collisionConfiguration  =  new  btDefaultCollisionConfiguration();  dispatcher  =  new  btCollisionDispatcher(collisionConfiguration);  broadphase  =  new  btDbvtBroadphase();  solver  =  new  btSequentialImpulseConstraintSolver();  collisionWorld  =  new  btDiscreteDynamicsWorld(dispatcher,  broadphase,  solver,  collisionConfiguration);  collisionWorld.setGravity(gravity);  	BaseBulletTest.init();  //  Normally  use:  Bullet.init();  
libgdx_82cc28bc1830b173a6a92b4d3efeb602df97742e	buggy:  if(  mesh.getMaximumVertices()  /  6  <  text.length()  )  context:  public  void  rebuild(  )  {  if(  mesh  ==  null  )  {  FloatMesh  m  =  new  FloatMesh(  6  *  text.length(),  3,  false,  false,  true,  1,  2,  false,  0  );  mesh  =  new  MeshRenderer(  graphics.getGL10(),  m,  false,  font.isManaged()  );  }  if(  mesh.getMaximumVertices()  /  6  <  text.length()  )  if(  mesh.getMesh().getMaximumVertices()  /  6  <  text.length()  )  {  mesh.dispose();  FloatMesh  m  =  new  FloatMesh(  6  *  text.length(),  3,  false,  false,  true,  1,  2,  false,  0  );  mesh  =  new  MeshRenderer(  graphics.getGL10(),  m,  false,  font.isManaged()  );  }  float[]  vertices  =  ((FloatMesh)mesh.getMesh()).getVerticesArray();  int  vertIdx  =  0;  	if(  mesh.getMesh().getMaximumVertices()  /  6  <  text.length()  )  
elasticsearch_5763b2468669896ce69b7f728626a8c844f4aba4	buggy:  textsToHighlight  =  lookup.source().extractRawValues(mapper.names().sourcePath());  context:  hitContext.reader().document(hitContext.docId(),  fieldVisitor);  textsToHighlight  =  fieldVisitor.fields().get(mapper.names().indexName());  if  (textsToHighlight  ==  null)  {  textsToHighlight  =  ImmutableList.of();  }  }  else  {  SearchLookup  lookup  =  searchContext.lookup();  lookup.setNextReader(hitContext.readerContext());  lookup.setNextDocId(hitContext.docId());              textsToHighlight  =  lookup.source().extractRawValues(mapper.names().sourcePath());              textsToHighlight  =  lookup.source().extractRawValues(hitContext.getSourcePath(mapper.names().sourcePath()));  }  assert  textsToHighlight  !=  null;  return  textsToHighlight;  }  static  class  Encoders  {  static  Encoder  DEFAULT  =  new  DefaultEncoder();  static  Encoder  HTML  =  new  SimpleHTMLEncoder();  	textsToHighlight  =  lookup.source().extractRawValues(hitContext.getSourcePath(mapper.names().sourcePath()));  
elasticsearch_01ba2871643a7d75bbaba725e72370fbab219021	buggy:  assertThat(searchResponse.hits().getAt(0).fields().get( "boolean_field ").value(),  equalTo((Object)   "true "));  context:  assertThat(searchResponse.hits().getAt(0).fields().get( "byte_field ").value().toString(),  equalTo( "1 "));  assertThat(searchResponse.hits().getAt(0).fields().get( "short_field ").value().toString(),  equalTo( "2 "));  assertThat(searchResponse.hits().getAt(0).fields().get( "integer_field ").value(),  equalTo((Object)  3));  assertThat(searchResponse.hits().getAt(0).fields().get( "long_field ").value(),  equalTo((Object)  4l));  assertThat(searchResponse.hits().getAt(0).fields().get( "float_field ").value(),  equalTo((Object)  5.0f));  assertThat(searchResponse.hits().getAt(0).fields().get( "double_field ").value(),  equalTo((Object)  6.0d));  String  dateTime  =  Joda.forPattern( "dateOptionalTime ").printer().print(new  DateTime(2012,  3,  22,  0,  0,  DateTimeZone.UTC));  assertThat(searchResponse.hits().getAt(0).fields().get( "date_field ").value(),  equalTo((Object)  dateTime));          assertThat(searchResponse.hits().getAt(0).fields().get( "boolean_field ").value(),  equalTo((Object)   "true "));          assertThat(searchResponse.hits().getAt(0).fields().get( "boolean_field ").value(),  equalTo((Object)  Boolean.TRUE));  assertThat(searchResponse.hits().getAt(0).fields().get( "binary_field ").value().toString(),  equalTo(Base64.encodeBytes( "testing  text ".getBytes( "UTF8 "))));  }  }  	assertThat(searchResponse.hits().getAt(0).fields().get( "boolean_field ").value(),  equalTo((Object)  Boolean.TRUE));  
elasticsearch_5e164a85ed1745b5bf8148236eb2efcd1d1cbf82	buggy:  int[]  docIdsToLoad  =  new  int[context.size()];  context:  private  void  shortcutDocIdsToLoad(SearchContext  context)  {  TopDocs  topDocs  =  context.queryResult().topDocs();  if  (topDocs.scoreDocs.length  <  context.from())  {  context.docIdsToLoad(EMPTY_DOC_IDS,  0,  0);  return;  }  int  totalSize  =  context.from()  +  context.size();          int[]  docIdsToLoad  =  new  int[context.size()];          int[]  docIdsToLoad  =  new  int[Math.min(topDocs.scoreDocs.length  -  context.from(),  context.size())];  int  counter  =  0;  for  (int  i  =  context.from();  i  <  totalSize;  i++)  {  if  (i  <  topDocs.scoreDocs.length)  {  docIdsToLoad[counter]  =  topDocs.scoreDocs[i].doc;  }  else  {  break;  }  counter++;  	int[]  docIdsToLoad  =  new  int[Math.min(topDocs.scoreDocs.length  -  context.from(),  context.size())];  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  protected  abstract  ClusterBlockException  checkGlobalBlock(ClusterState  state,  Request  request);  protected  abstract  ClusterBlockException  checkRequestBlock(ClusterState  state,  Request  request);  protected  boolean  resolveRequest(ClusterState  state,  Request  request,  ActionListener<Response>  listener)  {          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  return  true;  }  protected  boolean  retryOnFailure(Throwable  e)  {  return  false;  }  protected  TransportRequestOptions  transportOptions()  {  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_464037e0c18d5bbcc33db0e01acde6c8849324a9	buggy:  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;  context:  sb.append(Double.isInfinite(to)  ?   "* "  :  to);  return  sb.toString();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {  String  field  =  null;  List<RangeAggregator.Range>  ranges  =  null;  GeoPoint  origin  =  null;          DistanceUnit  unit  =  DistanceUnit.KILOMETERS;          DistanceUnit  unit  =  DistanceUnit.DEFAULT;  GeoDistance  distanceType  =  GeoDistance.DEFAULT;  boolean  keyed  =  false;  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  	DistanceUnit  unit  =  DistanceUnit.DEFAULT;  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  .put( "index.engine.robin.refreshInterval ",   "-1 ")  context:  public  class  HistogramAggregationSearchBenchmark  {  static  final  long  COUNT  =  SizeValue.parseSizeValue( "20m ").singles();  static  final  int  BATCH  =  1000;  static  final  int  QUERY_WARMUP  =  5;  static  final  int  QUERY_COUNT  =  20;  static  final  int  NUMBER_OF_TERMS  =  1000;  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  settingsBuilder()                  .put( "index.engine.robin.refreshInterval ",   "-1 ")                  .put( "refresh_interval ",   "-1 ")  .put( "gateway.type ",   "local ")  .put(SETTING_NUMBER_OF_SHARDS,  2)  .put(SETTING_NUMBER_OF_REPLICAS,  1)  .build();  String  clusterName  =  HistogramAggregationSearchBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder()  .clusterName(clusterName)  	.put( "refresh_interval ",   "-1 ")  
elasticsearch_ed99a51406ab5fd8dcc626dc90f408559d57e3c1	buggy:  }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper().stored())  {  context:  Map<String,  Object>  sourceAsMap  =  null;  SearchLookup  searchLookup  =  null;  for  (String  field  :  gFields)  {  if  (field.equals( "_source "))  {  sourceRequested  =  true;  continue;  }  Object  value  =  null;  if  (field.equals(RoutingFieldMapper.NAME)  &&  docMapper.routingFieldMapper().stored())  {  value  =  source.routing;                          }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper().stored())  {                          }  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper()  !=  null  &&  docMapper.parentFieldMapper().stored())  {  value  =  source.parent;  }  else  if  (field.equals(TimestampFieldMapper.NAME)  &&  docMapper.timestampFieldMapper().stored())  {  value  =  source.timestamp;  }  else  {  String  script  =  null;  if  (field.contains( "_source. "))  {  script  =  field;  }  else  {  	}  else  if  (field.equals(ParentFieldMapper.NAME)  &&  docMapper.parentFieldMapper()  !=  null  &&  docMapper.parentFieldMapper().stored())  {  
elasticsearch_c96014bb90ca3e756da5ba1613e8e06aecf1cf0e	buggy:  indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  2));  context:  ImmutableSettings.Builder  indexSettingsBuilder  =  settingsBuilder().put(request.settings);  if  (request.settings.get(SETTING_NUMBER_OF_SHARDS)  ==  null)  {  if  (request.index.equals(riverIndexName))  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS,  settings.getAsInt(SETTING_NUMBER_OF_SHARDS,  1));  }  else  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS,  settings.getAsInt(SETTING_NUMBER_OF_SHARDS,  5));  }  }  if  (request.settings.get(SETTING_NUMBER_OF_REPLICAS)  ==  null)  {  if  (request.index.equals(riverIndexName))  {                              indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  2));                              indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  1));  }  else  {  indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  1));  }  }  Settings  actualIndexSettings  =  indexSettingsBuilder.build();  indicesService.createIndex(request.index,  actualIndexSettings,  clusterService.state().nodes().localNode().id());  	indexSettingsBuilder.put(SETTING_NUMBER_OF_REPLICAS,  settings.getAsInt(SETTING_NUMBER_OF_REPLICAS,  1));  
libgdx_304a52f855f3d24f385976d9fea435d11c6ed05c	buggy:  Array<AssetDescriptor>  deps  =  new  Array<AssetDescriptor>();  context:  public  class  BitmapFontLoader  extends  AsynchronousAssetLoader<BitmapFont,  BitmapFontLoader.BitmapFontParameter>  {  public  BitmapFontLoader  (FileHandleResolver  resolver)  {  super(resolver);  }  BitmapFontData  data;  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  file,  BitmapFontParameter  parameter)  {  Array<AssetDescriptor>  deps  =  new  Array<AssetDescriptor>();  Array<AssetDescriptor>  deps  =  Array.of(AssetDescriptor.class);  if  (parameter  !=  null  &&  parameter.bitmapFontData  !=  null)  {  data  =  parameter.bitmapFontData;  return  deps;  }  data  =  new  BitmapFontData(file,  parameter  !=  null  ?  parameter.flip  :  false);  for  (int  i=0;  i<data.getImagePaths().length;  i++)  {  deps.add(new  AssetDescriptor(data.getImagePath(i),  Texture.class));  }  	Array<AssetDescriptor>  deps  =  Array.of(AssetDescriptor.class);  
elasticsearch_1cbeaf6c4579bcab3310e4bacb543622d1859f0e	buggy:  return  new  SignificantStringTerms(subsetSize,  supersetSize,  getName(),  requiredSize,  supersetSize,  buckets);  context:  }  public  Type  type()  {  return  TYPE;  }  InternalSignificantTerms  newAggregation(long  subsetSize,  long  supersetSize,  List<InternalSignificantTerms.Bucket>  buckets)  {          return  new  SignificantStringTerms(subsetSize,  supersetSize,  getName(),  requiredSize,  supersetSize,  buckets);          return  new  SignificantStringTerms(subsetSize,  supersetSize,  getName(),  requiredSize,  minDocCount,  buckets);  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  this.name  =  in.readString();  this.requiredSize  =  readSize(in);  this.minDocCount  =  in.readVLong();  this.subsetSize  =  in.readVLong();  	return  new  SignificantStringTerms(subsetSize,  supersetSize,  getName(),  requiredSize,  minDocCount,  buckets);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  context:  controller.registerHandler(DELETE,   "/{index}/_query ",  this);  controller.registerHandler(DELETE,   "/{index}/{type}/_query ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  DeleteByQueryRequest  deleteByQueryRequest  =  new  DeleteByQueryRequest(splitIndices(request.param( "index ")));  deleteByQueryRequest.listenerThreaded(false);  try  {  if  (request.hasContent())  {                  deleteByQueryRequest.query(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());                  deleteByQueryRequest.query(request.content(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  deleteByQueryRequest.query(source);  }  else  {  BytesReference  bytes  =  RestActions.parseQuerySource(request);  deleteByQueryRequest.query(bytes,  false);  }  	deleteByQueryRequest.query(request.content(),  request.contentUnsafe());  
elasticsearch_db431b7cb35949806987dfe12a2ac8c0495a5097	buggy:  .setQuery(fieldQuery( "_id ",  key))  context:  BulkResponse  bulk  =  client().prepareBulk().add(bulkAction,  0,  bulkAction.length,  false,  null,  null).execute().actionGet();  for  (BulkItemResponse  item  :  bulk.getItems())  {  assert  !item.isFailed()  :   "unable  to  index  data ";  }  client().admin().indices().prepareRefresh().execute().actionGet();  String  key  =   "DE ";  SearchResponse  searchResponse  =  client().prepareSearch()                  .setQuery(fieldQuery( "_id ",  key))                  .setQuery(matchQuery( "_id ",  key))  .execute().actionGet();  assertHitCount(searchResponse,  1);  for  (SearchHit  hit  :  searchResponse.getHits())  {  assertThat(hit.getId(),  equalTo(key));  }  	.setQuery(matchQuery( "_id ",  key))  
elasticsearch_10f0eaad68557ff2aae92dd65e8f1b9037ea0942	buggy:  return   "memcached ";  context:  public  class  MemcachedPlugin  extends  AbstractPlugin  {  private  final  Settings  settings;  public  MemcachedPlugin(Settings  settings)  {  this.settings  =  settings;  }          return   "memcached ";          return   "transport-memcached ";  }  return   "Exports  elasticsearch  APIs  over  memcached ";  }  Collection<Class<?  extends  Module>>  modules  =  newArrayList();  	return   "transport-memcached ";  
libgdx_495acc3d9ba679323261f90372e5ca6a6d4cc2fe	buggy:  if  (!input.oldButtons[Input.ESCAPE]  &&  input.buttons[Input.ESCAPE]  ||  Gdx.input.isTouched())  {  context:  }  for  (int  y=0;  y<signs[id].length;  y++)  {  drawString(signs[id][y],  xp,  yp+y*6);  }  if  (delay==0)  drawString( "PRESS  X ",  xp+(xs-8)*6,  yp+(signs[id].length+2)*6);  spriteBatch.end();  }  public  void  tick(Input  input)  {          if  (!input.oldButtons[Input.ESCAPE]  &&  input.buttons[Input.ESCAPE]  ||  Gdx.input.isTouched())  {          if  (!input.oldButtons[Input.ESCAPE]  &&  input.buttons[Input.ESCAPE])  {  setScreen(parent);  return;  }  if  (delay>0)  delay--;  if  (delay==0  &&  input.buttons[Input.SHOOT]  &&  !input.oldButtons[Input.SHOOT])  {  setScreen(parent);  }  }  	if  (!input.oldButtons[Input.ESCAPE]  &&  input.buttons[Input.ESCAPE])  {  
elasticsearch_8eab5ec5286475b5c0602d8c230947c781db6596	buggy:  return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());  context:  public  void  setClusterService(@Nullable  ClusterService  clusterService)  {  this.clusterService  =  clusterService;  if  (clusterService  !=  null)  {  clusterService.add(this);  }  }  public  CacheStats  stats()  {          return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());          return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  filterCache.memEvictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());  }  public  FilterCache  filter()  {  return  filterCache;  }  public  FieldDataCache  fieldData()  {  return  fieldDataCache;  	return  new  CacheStats(fieldDataCache.evictions(),  filterCache.evictions(),  filterCache.memEvictions(),  fieldDataCache.sizeInBytes(),  filterCache.sizeInBytes(),  filterCache.count(),  bloomCache.sizeInBytes());  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.REFRESH;  }  return   "indices/refresh/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
libgdx_0682041958a20ebcea081e478d402e44b7afcd42	buggy:  GdxTest  test  =  new  Mpg123Test();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  GdxTest  test  =  new  Mpg123Test();  GdxTest  test  =  new  WavTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  config.vSyncEnabled  =  true;  config.resizable  =  true;  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  WavTest();  
libgdx_d66fa6fe6a4bda91171e07151f943272df3bc4cd	buggy:  localAxis1.set(bodyA.getLocalVector(  anchor  ));  context:  public  void  initialize(Body  bodyA,  Body  bodyB,  Vector2  anchor,  Vector2  axis)  {  this.bodyA  =  bodyA;  this.bodyB  =  bodyB;  localAnchorA.set(  bodyA.getLocalPoint(  anchor  )  );  localAnchorB.set(  bodyB.getLocalPoint(  anchor  )  );  localAxis1.set(bodyA.getLocalVector(  anchor  ));  localAxis1.set(bodyA.getLocalVector(  axis  ));  referenceAngle  =  bodyB.getAngle()  -  bodyA.getAngle();  }  public  final  Vector2  localAnchorA  =  new  Vector2();  	localAxis1.set(bodyA.getLocalVector(  axis  ));  
libgdx_d540b9daf86c19ba458ccb785eb6cbfb76f7ee1e	buggy:  if  (listener  !=  null)  listener.selected(this,  selected,  items[selected]);  context:  itemY  -=  itemHeight;  }  }  public  boolean  touchDown  (float  x,  float  y,  int  pointer)  {  if  (pointer  !=  0)  return  false;  selected  =  (int)((height  -  y)  /  itemHeight);  selected  =  Math.max(0,  selected);  selected  =  Math.min(items.length  -  1,  selected);  if  (listener  !=  null)  listener.selected(this,  selected,  items[selected]);  if  (listener  !=  null  &&  items.length  >  0)  listener.selected(this,  selected,  items[selected]);  return  true;  }  public  int  getSelectedIndex  ()  {  return  selected;  }  	if  (listener  !=  null  &&  items.length  >  0)  listener.selected(this,  selected,  items[selected]);  
elasticsearch_801c709b4243ee7089c093daf47ca9b2a0bd1878	buggy:  .put( "gateway.type ",   "fs ")  context:  private  static  final  ESLogger  logger  =  Loggers.getLogger(ManyIndicesStressTest.class);  public  static  void  main(String[]  args)  throws  Exception  {  System.setProperty( "es.logger.prefix ",   " ");  int  numberOfIndices  =  100;  int  numberOfDocs  =  100;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.shard.check_on_startup ",  false)                  .put( "gateway.type ",   "fs ")                  .put( "gateway.type ",   "local ")  .put( "index.number_of_shards ",  1)  .build();  Node  node  =  NodeBuilder.nodeBuilder().settings(settings).node();  for  (int  i  =  0;  i  <  numberOfIndices;  i++)  {  node.client().admin().indices().prepareCreate( "index_ "  +  i).execute().actionGet();  	.put( "gateway.type ",   "local ")  
elasticsearch_35bd7f0086cace871c861510c7282633d26adcdc	buggy:  listener.onFailure(new  ReduceSearchPhaseException( "query_fetch ",   " ",  e));  context:  finishHim();  }  }  });  }  private  void  finishHim()  {  try  {  innerFinishHim();  }  catch  (Exception  e)  {                  listener.onFailure(new  ReduceSearchPhaseException( "query_fetch ",   " ",  e));                  listener.onFailure(new  ReduceSearchPhaseException( "query_fetch ",   " ",  e,  buildShardFailures()));  }  }  private  void  innerFinishHim()  {  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollIdX  =  null;  if  (request.scroll()  !=  null)  {  	listener.onFailure(new  ReduceSearchPhaseException( "query_fetch ",   " ",  e,  buildShardFailures()));  
elasticsearch_684e6986279ddbacdacd5470e27eddc25207427e	buggy:  for  (DocumentMapper  documentMapper  :  mapperService)  {  context:  }  if  (typesToRefresh  !=  null)  {  if  (sendRefreshMapping)  {  nodeMappingRefreshAction.nodeMappingRefresh(event.state(),  new  NodeMappingRefreshAction.NodeMappingRefreshRequest(index,  indexMetaData.uuid(),  typesToRefresh.toArray(new  String[typesToRefresh.size()]),  event.state().nodes().localNodeId())  );  }  }              for  (DocumentMapper  documentMapper  :  mapperService)  {              for  (DocumentMapper  documentMapper  :  mapperService.docMappers(true))  {  if  (seenMappings.containsKey(new  Tuple<>(index,  documentMapper.type()))  &&  !indexMetaData.mappings().containsKey(documentMapper.type()))  {  mapperService.remove(documentMapper.type());  seenMappings.remove(new  Tuple<>(index,  documentMapper.type()));  }  }  }  }  	for  (DocumentMapper  documentMapper  :  mapperService.docMappers(true))  {  
elasticsearch_6de18262ddc574522488aee47c95211f415197e3	buggy:  .put( "discovery.zen.ping_timeout ",   "200ms ")  context:  assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(),  equalTo(100l));  }  }  public  void  multipleNodesShutdownNonMasterNodes()  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "discovery.type ",   "zen ")  .put( "discovery.zen.minimum_master_nodes ",  3)                  .put( "discovery.zen.ping_timeout ",   "200ms ")                  .put( "discovery.zen.ping_timeout ",   "1s ")  .put( "discovery.initial_state_timeout ",   "500ms ")  .put( "gateway.type ",   "local ")  .build();  internalCluster().startNode(settings);  internalCluster().startNode(settings);  	.put( "discovery.zen.ping_timeout ",   "1s ")  
elasticsearch_52f1ab6e164c3005c9e49449843855f262885d66	buggy:  client().admin().indices().prepareCreate( "test ").execute().actionGet();  context:  public  class  MultiPercolatorTests  extends  ElasticsearchIntegrationTest  {  public  void  testBasics()  throws  Exception  {          client().admin().indices().prepareCreate( "test ").execute().actionGet();          assertAcked(prepareCreate( "test ").addMapping( "type ",   "field1 ",   "type=string "));  ensureGreen();  client().prepareIndex( "test ",  PercolatorService.TYPE_NAME,   "1 ")  .setSource(jsonBuilder().startObject().field( "query ",  matchQuery( "field1 ",   "b ")).field( "a ",   "b ").endObject())  .execute().actionGet();  client().prepareIndex( "test ",  PercolatorService.TYPE_NAME,   "2 ")  .setSource(jsonBuilder().startObject().field( "query ",  matchQuery( "field1 ",   "c ")).endObject())  	assertAcked(prepareCreate( "test ").addMapping( "type ",   "field1 ",   "type=string "));  
elasticsearch_4723c2a2ee264390227a089c59d1930469d8b5e5	buggy:  spare  =  new  SignificantLongTerms.Bucket(0,  0,  0,  0,  0,  null);  context:  final  int  size  =  (int)  Math.min(bucketOrds.size(),  bucketCountThresholds.getShardSize());  long  supersetSize  =  termsAggFactory.prepareBackground(context);  long  subsetSize  =  numCollectedDocs;  BucketSignificancePriorityQueue  ordered  =  new  BucketSignificancePriorityQueue(size);  SignificantLongTerms.Bucket  spare  =  null;  for  (long  i  =  0;  i  <  bucketOrds.size();  i++)  {  if  (spare  ==  null)  {                  spare  =  new  SignificantLongTerms.Bucket(0,  0,  0,  0,  0,  null);                  spare  =  new  SignificantLongTerms.Bucket(0,  0,  0,  0,  0,  null,  formatter);  }  spare.term  =  bucketOrds.get(i);  spare.subsetDf  =  bucketDocCount(i);  spare.subsetSize  =  subsetSize;  spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(spare.term);  spare.supersetSize  =  supersetSize;  	spare  =  new  SignificantLongTerms.Bucket(0,  0,  0,  0,  0,  null,  formatter);  
elasticsearch_3028d5a7a16cd9ccb28f1a364ac2c1d762a6e6de	buggy:  logger.info( "-->  adding  two  nodes  and  performing  rerouting ");  context:  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(2).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  .add(indexRoutingTable( "test ").initializeEmpty(metaData.index( "test ")))  .build();  ClusterState  clusterState  =  newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();          logger.info( "-->  adding  two  nodes  and  performing  rerouting ");          logger.info( "-->  adding  four  nodes  and  performing  rerouting ");  clusterState  =  newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder()  .put(newNode( "node1 ",  ImmutableMap.of( "tag1 ",   "value1 ")))  .put(newNode( "node2 ",  ImmutableMap.of( "tag1 ",   "value2 ")))  .put(newNode( "node3 ",  ImmutableMap.of( "tag1 ",   "value3 ")))  .put(newNode( "node4 ",  ImmutableMap.of( "tag1 ",   "value4 ")))  ).build();  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  	logger.info( "-->  adding  four  nodes  and  performing  rerouting ");  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  cluster().ensureAtLeastNumDataNodes(1  +  replica);  context:  assertThat(getResponse.isExists(),  equalTo(false));  }  }  }  public  void  testBulkIndexingWhileInitializing()  throws  Exception  {  int  replica  =  randomInt(2);          cluster().ensureAtLeastNumDataNodes(1  +  replica);          internalCluster().ensureAtLeastNumDataNodes(1  +  replica);  assertAcked(prepareCreate( "test ").setSettings(  ImmutableSettings.builder()  .put(indexSettings())  .put( "index.number_of_replicas ",  replica)  ));  int  numDocs  =  scaledRandomIntBetween(100,  5000);  	internalCluster().ensureAtLeastNumDataNodes(1  +  replica);  
elasticsearch_b41166a78ad684e29110ebec948f0263b1fca9ed	buggy:  channel.sendResponse(new  StringRestResponse(INTERNAL_SERVER_ERROR));  context:  channel.sendResponse(new  StringRestResponse(NOT_FOUND));  }  }  catch  (Exception  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {                      channel.sendResponse(new  StringRestResponse(INTERNAL_SERVER_ERROR));                      channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  }  catch  (Exception  e1)  {  }  }  });  }  }  	channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  
elasticsearch_3381d77c143579c5489b84d6824e7ed2b2eb8eb4	buggy:  builder.field( "name ",  nodeStats.node().name());  context:  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "cluster_name ",  result.clusterName().value());  builder.startObject( "nodes ");  for  (NodeStats  nodeStats  :  result)  {  builder.startObject(nodeStats.node().id(),  XContentBuilder.FieldCaseConversion.NONE);                          builder.field( "name ",  nodeStats.node().name());                          builder.field( "name ",  nodeStats.node().name(),  XContentBuilder.FieldCaseConversion.NONE);  if  (nodeStats.indices()  !=  null)  {  nodeStats.indices().toXContent(builder,  request);  }  if  (nodeStats.os()  !=  null)  {  nodeStats.os().toXContent(builder,  request);  }  	builder.field( "name ",  nodeStats.node().name(),  XContentBuilder.FieldCaseConversion.NONE);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<AliasMetaData>  value  =  new  ArrayList<AliasMetaData>(valueSize);  context:  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  int  size  =  in.readVInt();  ImmutableOpenMap.Builder<String,  List<AliasMetaData>>  aliasesBuilder  =  ImmutableOpenMap.builder();  for  (int  i  =  0;  i  <  size;  i++)  {  String  key  =  in.readString();  int  valueSize  =  in.readVInt();              List<AliasMetaData>  value  =  new  ArrayList<AliasMetaData>(valueSize);              List<AliasMetaData>  value  =  new  ArrayList<>(valueSize);  for  (int  j  =  0;  j  <  valueSize;  j++)  {  value.add(AliasMetaData.Builder.readFrom(in));  }  aliasesBuilder.put(key,  ImmutableList.copyOf(value));  }  aliases  =  aliasesBuilder.build();  }  	List<AliasMetaData>  value  =  new  ArrayList<>(valueSize);  
libgdx_e167a69c58e51a796103b6124b63b7dce0631440	buggy:  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  context:  return  new  BulletWorld(collisionConfiguration,  dispatcher,  broadphase,  solver,  dynamicsWorld);  }  public  void  create  ()  {  super.create();  world.maxSubSteps  =  20;  world.add( "ground ",  0f,  0f,  0f)  .color.set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  .getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  final  StillModel  model  =  ModelLoaderRegistry.loadStillModel(Gdx.files.internal( "data/wheel.obj "));  mesh  =  model.subMeshes[0].getMesh().copy(false,  true,  new  int[]  {Usage.Position});  mesh.scale(6f,  6f,  6f);  softBody  =  new  btSoftBody(worldInfo,  mesh.getVerticesBuffer(),  mesh.getNumVertices(),  mesh.getVertexSize(),  mesh.getVertexAttribute(Usage.Position).offset,  mesh.getIndicesBuffer(),  mesh.getNumIndices()/3);  	.getColor().set(0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  0.25f  +  0.5f  *  (float)Math.random(),  1f);  
elasticsearch_daedf853a010a882f99cfe9605264adac6746a42	buggy:  @Test  @TestLogging( "org.elasticsearch.action.search.type:TRACE,org.elasticsearch.action.admin.indices.refresh:TRACE ")  context:  public  class  RecoveryWhileUnderLoadTests  extends  AbstractSharedClusterTest  {  private  final  ESLogger  logger  =  Loggers.getLogger(RecoveryWhileUnderLoadTests.class);      @Test  @TestLogging( "org.elasticsearch.action.search.type:TRACE,org.elasticsearch.action.admin.indices.refresh:TRACE ")      @Test  @TestLogging( "action.search.type:TRACE,action.admin.indices.refresh:TRACE ")  public  void  recoverWhileUnderLoadAllocateBackupsTest()  throws  Exception  {  prepareCreate( "test ",  1);  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  AtomicLong  indexCounter  =  new  AtomicLong();  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);  	@Test  @TestLogging( "action.search.type:TRACE,action.admin.indices.refresh:TRACE ")  
elasticsearch_8f1023cbbeae5a2f067c07580abdd9aaf087247b	buggy:  JsonBuilder  builder  =  JsonBuilder.cached();  context:  public  class  HttpJsonBuilder  {  public  static  JsonBuilder  cached(HttpRequest  request)  throws  IOException  {          JsonBuilder  builder  =  JsonBuilder.cached();          JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  String  prettyPrint  =  request.param( "pretty ");  if  (prettyPrint  !=  null  &&   "true ".equals(prettyPrint))  {  builder.prettyPrint();  }  return  builder;  }  }  	JsonBuilder  builder  =  JsonBuilder.jsonBuilder();  
elasticsearch_2bb31fe74037a7ee2a04c9a994bc4bacbc8e8102	buggy:  return   "[ "  +  Arrays.toString(indices)  +   "][ "  +  Arrays.toString(types)  +   "],  querySource[ "  +  Unicode.fromBytes(querySource)  +   "] ";  context:  out.writeBoolean(true);  out.writeUTF(queryParserName);  }  out.writeVInt(types.length);  for  (String  type  :  types)  {  out.writeUTF(type);  }  }          return   "[ "  +  Arrays.toString(indices)  +   "][ "  +  Arrays.toString(types)  +   "],  querySource[ "  +  Unicode.fromBytes(querySource)  +   "] ";          return   "[ "  +  Arrays.toString(indices)  +   "] "  +  Arrays.toString(types)  +   ",  querySource[ "  +  Unicode.fromBytes(querySource)  +   "] ";  }  }  	return   "[ "  +  Arrays.toString(indices)  +   "] "  +  Arrays.toString(types)  +   ",  querySource[ "  +  Unicode.fromBytes(querySource)  +   "] ";  
elasticsearch_ccb30d42e9512c2618880a3cd026d6c6c2e5a253	buggy:  },  recoverAfterTime);  context:  if  (!ignoreTimeout  &&  recoverAfterTime  !=  null)  {  if  (scheduledRecovery.compareAndSet(false,  true))  {  threadPool.schedule(new  Runnable()  {  if  (recovered.compareAndSet(false,  true))  {  gateway.performStateRecovery(recoveryListener);  }  }                  },  recoverAfterTime);                  },  recoverAfterTime,  ThreadPool.ExecutionType.THREADED);  }  }  else  {  if  (recovered.compareAndSet(false,  true))  {  gateway.performStateRecovery(recoveryListener);  }  }  if  (timeout  !=  null)  {  	},  recoverAfterTime,  ThreadPool.ExecutionType.THREADED);  
elasticsearch_523a8b4c3e8003316f3e7c6a74bdd5e4e1818dd6	buggy:  modules.add(MapperAttachmentsIndexModule.class);  context:  return   "mapper-attachments ";  }  return   "Adds  the  attachment  type  allowing  to  parse  difference  attachment  formats ";  }  Collection<Class<?  extends  Module>>  modules  =  newArrayList();          modules.add(MapperAttachmentsIndexModule.class);          modules.add(AttachmentsIndexModule.class);  return  modules;  }  }  	modules.add(AttachmentsIndexModule.class);  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  }  });  }  else  {  innerExecute(request,  listener);  }  }  protected  boolean  resolveRequest(final  ClusterState  state,  final  DeleteRequest  request,  final  ActionListener<DeleteResponse>  listener)  {  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  if  (state.metaData().hasIndex(request.index()))  {  MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mappingOrDefault(request.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required())  {  if  (request.routing()  ==  null)  {  if  (request.versionType()  !=  VersionType.INTERNAL)  {  throw  new  ElasticsearchIllegalArgumentException( "routing  value  is  required  for  deleting  documents  of  type  [ "  +  request.type()  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_35755cd8a4b4c5a829b47f9be07dfa64ccbfffe0	buggy:  sourceBuilder.toXContent(builder,  params);  context:  }  public  TopHitsBuilder  setHighlighterOptions(Map<String,  Object>  options)  {  highlightBuilder().options(options);  return  this;  }  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  builder.startObject(name).field(type);          sourceBuilder.toXContent(builder,  params);          sourceBuilder().toXContent(builder,  params);  return  builder.endObject();  }  private  SearchSourceBuilder  sourceBuilder()  {  if  (sourceBuilder  ==  null)  {  sourceBuilder  =  new  SearchSourceBuilder();  }  return  sourceBuilder;  	sourceBuilder().toXContent(builder,  params);  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  shardStatus.translogOperations  =  indexShard.translog().numberOfOperations();  context:  ShardStatus  shardStatus  =  new  ShardStatus(indexShard.routingEntry());  shardStatus.state  =  indexShard.state();  try  {  shardStatus.storeSize  =  indexShard.store().estimateSize();  }  catch  (IOException  e)  {  }  if  (indexShard.state()  ==  IndexShardState.STARTED)  {  shardStatus.translogId  =  indexShard.translog().currentId();              shardStatus.translogOperations  =  indexShard.translog().numberOfOperations();              shardStatus.translogOperations  =  indexShard.translog().estimatedNumberOfOperations();  Engine.Searcher  searcher  =  indexShard.searcher();  try  {  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {  searcher.release();  	shardStatus.translogOperations  =  indexShard.translog().estimatedNumberOfOperations();  
elasticsearch_1eb24d7efc20668f03fec8c4d4979d8f0763f217	buggy:  final  ShingleTokenFilterFactory  shingleFilterFactory  =  SuggestUtils.getShingleFilterFactory(suggestion.getAnalyzer()  ==  null  ?  context.mapperService().fieldSearchAnalyzer(suggestion.getField())  :  suggestion.getAnalyzer());  ;  context:  if  (suggestion.getField()  ==  null)  {  throw  new  ElasticSearchIllegalArgumentException( "The  required  field  option  is  missing ");  }  if  (suggestion.model()  ==  null)  {  suggestion.setModel(LaplaceScorer.FACTORY);  }  if  (!gramSizeSet  ||  suggestion.generators().isEmpty())  {              final  ShingleTokenFilterFactory  shingleFilterFactory  =  SuggestUtils.getShingleFilterFactory(suggestion.getAnalyzer()  ==  null  ?  context.mapperService().fieldSearchAnalyzer(suggestion.getField())  :  suggestion.getAnalyzer());  ;              final  ShingleTokenFilterFactory.Factory  shingleFilterFactory  =  SuggestUtils.getShingleFilterFactory(suggestion.getAnalyzer()  ==  null  ?  context.mapperService().fieldSearchAnalyzer(suggestion.getField())  :  suggestion.getAnalyzer());  ;  if  (!gramSizeSet)  {  if  (shingleFilterFactory  !=  null)  {  suggestion.setGramSize(shingleFilterFactory.getMaxShingleSize());  if  (suggestion.getAnalyzer()  ==  null  &&  shingleFilterFactory.getMinShingleSize()  >  1  &&  !shingleFilterFactory.getOutputUnigrams())  {  throw  new  ElasticSearchIllegalArgumentException( "The  default  analyzer  for  field:  [ "  +  suggestion.getField()  +   "]  doesn't  emit  unigrams.  If  this  is  intentional  try  to  set  the  analyzer  explicitly ");  }  }  	final  ShingleTokenFilterFactory.Factory  shingleFilterFactory  =  SuggestUtils.getShingleFilterFactory(suggestion.getAnalyzer()  ==  null  ?  context.mapperService().fieldSearchAnalyzer(suggestion.getField())  :  suggestion.getAnalyzer());  ;  
libgdx_21c209669e25d242d7386b0c1bf962af26d535aa	buggy:  logoSprite.getTextureRegion().flip(false,  true);  context:  renderMode  =  (renderMode  +  1)  %  2;  return  false;  }  });  spriteBatch  =  new  SpriteBatch();  spriteBatch.setProjectionMatrix(new  Matrix4().setToOrtho(0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  0,  0,  1));  logoSprite  =  new  Sprite(Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge));  logoSprite.getTextureRegion().flip(false,  true);  logoSprite.getRegion().flip(false,  true);  logoSprite.setPosition(0,  320  -  256);  logoSprite.setColor(1,  1,  1,  0.5f);  font  =  new  BitmapFont(Gdx.files.getFileHandle( "data/verdana39.fnt ",  FileType.Internal),  Gdx.files.getFileHandle(   "data/verdana39.png ",  FileType.Internal),  true);  cache1  =  new  BitmapFontCache(font);  cache2  =  new  BitmapFontCache(font);  	logoSprite.getRegion().flip(false,  true);  
elasticsearch_e551ec282faab265315fea299bbe04cfc8e640c9	buggy:  return  ClusterState.builder().state(currentState).metaData(mdBuilder).build();  context:  entries.add(new  IndexWarmersMetaData.Entry(request.name(),  request.searchRequest().types(),  source));  }  else  {  }  warmers  =  new  IndexWarmersMetaData(entries.toArray(new  IndexWarmersMetaData.Entry[entries.size()]));  }  IndexMetaData.Builder  indexBuilder  =  IndexMetaData.builder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  mdBuilder.put(indexBuilder);  }                          return  ClusterState.builder().state(currentState).metaData(mdBuilder).build();                          return  ClusterState.builder(currentState).metaData(mdBuilder).build();  }  public  void  clusterStateProcessed(String  source,  ClusterState  oldState,  ClusterState  newState)  {  }  });  }  	return  ClusterState.builder(currentState).metaData(mdBuilder).build();  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  this.mul(tmpMat.setToTranslation(position.tmp().mul(-1)));  context:  public  Matrix4  setToLookAt  (Vector3  position,  Vector3  target,  Vector3  up)  {  tmpVec.set(target).sub(position);  setToLookAt(tmpVec,  up);  this.mul(tmpMat.setToTranslation(position.tmp().mul(-1)));  this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  return  this;  }  static  final  Vector3  right  =  new  Vector3();  static  final  Vector3  tmpForward  =  new  Vector3();  static  final  Vector3  tmpUp  =  new  Vector3();  	this.mul(tmpMat.setToTranslation(position.tmp().scl(-1)));  
elasticsearch_73e5eb9e145ce20d375f4db7880762b32aa08c89	buggy:  deleteByQueryAction.execute(Requests.deleteByQueryRequest(request.indices()).query(QueryBuilders.filtered(QueryBuilders.matchAllQuery(),  FilterBuilders.termFilter(TypeFieldMapper.NAME,  request.type()))),  new  ActionListener<DeleteByQueryResponse>()  {  context:  for  (String  index  :  request.indices())  {  state.blocks().indexBlockedRaiseException(ClusterBlockLevel.METADATA,  index);  }  }  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          deleteByQueryAction.execute(Requests.deleteByQueryRequest(request.indices()).query(QueryBuilders.filtered(QueryBuilders.matchAllQuery(),  FilterBuilders.termFilter(TypeFieldMapper.NAME,  request.type()))),  new  ActionListener<DeleteByQueryResponse>()  {          deleteByQueryAction.execute(Requests.deleteByQueryRequest(request.indices()).query(QueryBuilders.filteredQuery(QueryBuilders.matchAllQuery(),  FilterBuilders.termFilter(TypeFieldMapper.NAME,  request.type()))),  new  ActionListener<DeleteByQueryResponse>()  {  refreshAction.execute(Requests.refreshRequest(request.indices()),  new  ActionListener<RefreshResponse>()  {  metaDataMappingService.removeMapping(new  MetaDataMappingService.RemoveRequest(request.indices(),  request.type()));  latch.countDown();  }  	deleteByQueryAction.execute(Requests.deleteByQueryRequest(request.indices()).query(QueryBuilders.filteredQuery(QueryBuilders.matchAllQuery(),  FilterBuilders.termFilter(TypeFieldMapper.NAME,  request.type()))),  new  ActionListener<DeleteByQueryResponse>()  {  
libgdx_58f608bfd069c28efa4a7e496b3d560d3c8eabae	buggy:  return  (float)Math.sqrt(  sum  /  values.length  );  context:  if(  !hasEnoughData()  )  return  0;  float  mean  =  getMean();  float  sum  =  0;  for(  int  i  =  0;  i  <  values.length;  i++  )  {  sum  +=  (values[i]  -  mean)  *  (values[i]  -  mean);  }  return  (float)Math.sqrt(  sum  /  values.length  );  return  FastMath.sqrt(  sum  /  values.length  );  }  }  	return  FastMath.sqrt(  sum  /  values.length  );  
elasticsearch_c30d790609a932acfcd38a072a4e7662a87b85fa	buggy:  builder.startObject( "queryBoost ");  context:  }  if  (sortTuple.type  !=  null)  {  builder.field( "type ",  sortTuple.type());  }  builder.endObject();  }  builder.endObject();  }  if  (indexBoost  !=  null)  {                  builder.startObject( "queryBoost ");                  builder.startObject( "indicesBoost ");  for  (TObjectFloatIterator<String>  it  =  indexBoost.iterator();  it.hasNext();)  {  it.advance();  builder.field(it.key(),  it.value());  }  builder.endObject();  }  if  (facetsBuilder  !=  null)  {  	builder.startObject( "indicesBoost ");  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  }  });  }  else  {  innerExecute(request,  listener);  }  }  protected  boolean  resolveRequest(final  ClusterState  state,  final  DeleteRequest  request,  final  ActionListener<DeleteResponse>  listener)  {  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  if  (state.metaData().hasIndex(request.index()))  {  MappingMetaData  mappingMd  =  state.metaData().index(request.index()).mappingOrDefault(request.type());  if  (mappingMd  !=  null  &&  mappingMd.routing().required())  {  if  (request.routing()  ==  null)  {  if  (request.versionType()  !=  VersionType.INTERNAL)  {  throw  new  ElasticsearchIllegalArgumentException( "routing  value  is  required  for  deleting  documents  of  type  [ "  +  request.type()  	request.index(state.metaData().concreteSingleIndex(request.index()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  messageReceived(final  MultiSearchRequest  request,  final  TransportChannel  channel)  throws  Exception  {  request.listenerThreaded(false);  execute(request,  new  ActionListener<MultiSearchResponse>()  {  public  void  onResponse(MultiSearchResponse  response)  {  try  {  channel.sendResponse(response);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
libgdx_36db44ba11e8c272ff4a37a92dc463760de6b985	buggy:  Actor  actor  =  stage.hit(stageCoords.x,  stageCoords.y);  context:  public  void  render  ()  {  Gdx.gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  if  (Gdx.input.isTouched())  {  Vector2  stageCoords  =  Vector2.tmp;  stage.screenToStageCoordinates(stageCoords.set(Gdx.input.getX(),  Gdx.input.getY()));  Actor  actor  =  stage.hit(stageCoords.x,  stageCoords.y);  Actor  actor  =  stage.hit(stageCoords.x,  stageCoords.y,  true);  if  (actor  instanceof  Image)  ((Image)actor).setColor((float)Math.random(),  (float)Math.random(),  (float)Math.random(),  0.5f  +  0.5f  *  (float)Math.random());  }  Array<Actor>  actors  =  stage.getActors();  int  len  =  actors.size;  if  (rotateSprites)  {  	Actor  actor  =  stage.hit(stageCoords.x,  stageCoords.y,  true);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray(),  false);  context:  out.writeShort((short)  -1);  out.writeInt(-1);  out.writeVInt(2);  out.writeLong(-3);  out.writeVLong(4);  out.writeFloat(1.1f);  out.writeDouble(2.2);  out.writeUTF( "hello ");  out.writeUTF( "goodbye ");          BytesStreamInput  in  =  new  BytesStreamInput(out.copiedByteArray(),  false);          BytesStreamInput  in  =  new  BytesStreamInput(out.bytes().toBytes(),  false);  assertThat(in.readBoolean(),  equalTo(false));  assertThat(in.readByte(),  equalTo((byte)  1));  assertThat(in.readShort(),  equalTo((short)  -1));  assertThat(in.readInt(),  equalTo(-1));  assertThat(in.readVInt(),  equalTo(2));  assertThat(in.readLong(),  equalTo((long)  -3));  assertThat(in.readVLong(),  equalTo((long)  4));  assertThat((double)  in.readFloat(),  closeTo(1.1,  0.0001));  	BytesStreamInput  in  =  new  BytesStreamInput(out.bytes().toBytes(),  false);  
elasticsearch_94c632b79b18f6e9de721d2a35bd4cc7bd1fae36	buggy:  throw  new  SearchParseException(context,   "No  facet  type  for  [ "  +  facetFieldName  +   "] ");  context:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  facetFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "facet_filter ".equals(facetFieldName)  ||   "facetFilter ".equals(facetFieldName))  {  XContentIndexQueryParser  indexQueryParser  =  (XContentIndexQueryParser)  context.queryParser();  filter  =  indexQueryParser.parseInnerFilter(parser);  }  else  {  FacetProcessor  facetProcessor  =  facetProcessors.processor(facetFieldName);  if  (facetProcessor  ==  null)  {                                  throw  new  SearchParseException(context,   "No  facet  type  for  [ "  +  facetFieldName  +   "] ");                                  throw  new  SearchParseException(context,   "No  facet  type  found  for  [ "  +  facetFieldName  +   "] ");  }  facet  =  facetProcessor.parse(topLevelFieldName,  parser,  context);  }  }  else  if  (token.isValue())  {  if  ( "global ".equals(facetFieldName))  {  if  (parser.booleanValue())  {  scope  =  ContextIndexSearcher.Scopes.GLOBAL;  }  	throw  new  SearchParseException(context,   "No  facet  type  found  for  [ "  +  facetFieldName  +   "] ");  
libgdx_a115dd10128240c0f8c7784b2153f2840948aedd	buggy:  font.draw(batch,   "button  is  2x1  cm  ( "  +  width  +   "x "  +  height  +   "px),  ppi:  ( "  +  Gdx.graphics.getPpiX()  +   ", "  +  Gdx.graphics.getPpiY()  + "),  ppc:  ( "  +  Gdx.graphics.getPpcX()  +   ", "  +  Gdx.graphics.getPpcY()+   ") ",  10,  50,  Color.WHITE);  context:  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  }  public  void  render()  {  Gdx.gl10.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  float  width  =  (int)(Gdx.graphics.getPpcX()  *  2);  float  height  =  (int)(Gdx.graphics.getPpcY()  *  1);  batch.draw(texture,  10,  100,  width,  height,  0,  0,  64,  32,  Color.WHITE,  false,  false  );  font.draw(batch,   "button  is  2x1  cm  ( "  +  width  +   "x "  +  height  +   "px),  ppi:  ( "  +  Gdx.graphics.getPpiX()  +   ", "  +  Gdx.graphics.getPpiY()  + "),  ppc:  ( "  +  Gdx.graphics.getPpcX()  +   ", "  +  Gdx.graphics.getPpcY()+   ") ",  10,  50,  Color.WHITE);  font.draw(batch,   "button  is  2x1  cm  ( "  +  width  +   "x "  +  height  +   "px),  ppi:  ( "  +  Gdx.graphics.getPpiX()  +   ", "  +  Gdx.graphics.getPpiY()  + "),  ppc:  ( "  +  Gdx.graphics.getPpcX()  +   ", "  +  Gdx.graphics.getPpcY()+   ") ",  10,  50);  batch.end();  }  public  boolean  needsGL20()  {  return  false;  }  	font.draw(batch,   "button  is  2x1  cm  ( "  +  width  +   "x "  +  height  +   "px),  ppi:  ( "  +  Gdx.graphics.getPpiX()  +   ", "  +  Gdx.graphics.getPpiY()  + "),  ppc:  ( "  +  Gdx.graphics.getPpcX()  +   ", "  +  Gdx.graphics.getPpcY()+   ") ",  10,  50);  
elasticsearch_c4bed91262394fcc26a2e8d20a5570fe70539fd2	buggy:  BytesRef  type  =  parser.bytes();  context:  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }  String  fieldName  =  parser.currentName();  if  (!fieldName.equals( "value "))  {  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }  token  =  parser.nextToken();  if  (token  !=  XContentParser.Token.VALUE_STRING)  {  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }          BytesRef  type  =  parser.bytes();          BytesRef  type  =  parser.utf8Bytes();  parser.nextToken();  Filter  filter;  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(type.utf8ToString());  if  (documentMapper  ==  null)  {  filter  =  new  TermFilter(new  Term(TypeFieldMapper.NAME,  type));  	BytesRef  type  =  parser.utf8Bytes();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalHistogram.Bucket>  buckets  =  new  ArrayList<InternalHistogram.Bucket>((int)  bucketOrds.size());  context:  bucketOrd  =  -1  -  bucketOrd;  }  collectBucket(doc,  bucketOrd);  previousKey  =  key;  }  }  public  InternalAggregation  buildAggregation(long  owningBucketOrdinal)  {  assert  owningBucketOrdinal  ==  0;          List<InternalHistogram.Bucket>  buckets  =  new  ArrayList<InternalHistogram.Bucket>((int)  bucketOrds.size());          List<InternalHistogram.Bucket>  buckets  =  new  ArrayList<>((int)  bucketOrds.size());  for  (long  i  =  0;  i  <  bucketOrds.capacity();  ++i)  {  final  long  ord  =  bucketOrds.id(i);  if  (ord  <  0)  {  continue;  //  slot  is  not  allocated  }  buckets.add(histogramFactory.createBucket(rounding.valueForKey(bucketOrds.key(i)),  bucketDocCount(ord),  bucketAggregations(ord),  valuesSource.formatter()));  }  	List<InternalHistogram.Bucket>  buckets  =  new  ArrayList<>((int)  bucketOrds.size());  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardExistsRequest(shard.index(),  shard.id(),  filteringAliases,  request);  context:  }  protected  ShardExistsRequest  newShardRequest()  {  return  new  ShardExistsRequest();  }  protected  ShardExistsRequest  newShardRequest(int  numShards,  ShardRouting  shard,  ExistsRequest  request)  {  String[]  filteringAliases  =  clusterService.state().metaData().filteringAliases(shard.index(),  request.indices());          return  new  ShardExistsRequest(shard.index(),  shard.id(),  filteringAliases,  request);          return  new  ShardExistsRequest(shard.shardId(),  filteringAliases,  request);  }  protected  ShardExistsResponse  newShardResponse()  {  return  new  ShardExistsResponse();  }  	return  new  ShardExistsRequest(shard.shardId(),  filteringAliases,  request);  
elasticsearch_6f39fce41f7c0486f11415c34c4cfedebb6a3e75	buggy:  return  typeParser.parse(name,  dynamicTemplate.mappingForName(name,  mappingType),  parserContext);  context:  DynamicTemplate  dynamicTemplate  =  findTemplate(context.path(),  name,  dynamicType);  if  (dynamicTemplate  ==  null)  {  return  null;  }  Mapper.TypeParser.ParserContext  parserContext  =  context.docMapperParser().parserContext();  String  mappingType  =  dynamicTemplate.mappingType(dynamicType);  Mapper.TypeParser  typeParser  =  parserContext.typeParser(mappingType);  if  (typeParser  ==  null)  {  throw  new  MapperParsingException( "failed  to  find  type  parsed  [ "  +  mappingType  +   "]  for  [ "  +  name  +   "] ");  }          return  typeParser.parse(name,  dynamicTemplate.mappingForName(name,  mappingType),  parserContext);          return  typeParser.parse(name,  dynamicTemplate.mappingForName(name,  dynamicType),  parserContext);  }  public  DynamicTemplate  findTemplate(ContentPath  path,  String  name,  String  dynamicType)  {  for  (DynamicTemplate  dynamicTemplate  :  dynamicTemplates)  {  if  (dynamicTemplate.match(path,  name,  dynamicType))  {  return  dynamicTemplate;  }  }  	return  typeParser.parse(name,  dynamicTemplate.mappingForName(name,  dynamicType),  parserContext);  
elasticsearch_0b449d3040d6a7285896be2a84acee206ec6231e	buggy:  throw  new  ElasticsearchIllegalArgumentException( "unsupported  node.mode  [ "  +  nodeMode  +   "] ");  context:  if  (settings.get( "node.local ")  !=  null)  {  return  settings.getAsBoolean( "node.local ",  false);  }  if  (settings.get( "node.mode ")  !=  null)  {  String  nodeMode  =  settings.get( "node.mode ");  if  ( "local ".equals(nodeMode))  {  return  true;  }  else  if  ( "network ".equals(nodeMode))  {  return  false;  }  else  {                  throw  new  ElasticsearchIllegalArgumentException( "unsupported  node.mode  [ "  +  nodeMode  +   "] ");                  throw  new  ElasticsearchIllegalArgumentException( "unsupported  node.mode  [ "  +  nodeMode  +   "].  Should  be  one  of  [local,  network]. ");  }  }  return  false;  }  public  static  boolean  nodeRequiresLocalStorage(Settings  settings)  {  return  !(settings.getAsBoolean( "node.client ",  false)  ||  (!settings.getAsBoolean( "node.data ",  true)  &&  !settings.getAsBoolean( "node.master ",  true)));  }  	throw  new  ElasticsearchIllegalArgumentException( "unsupported  node.mode  [ "  +  nodeMode  +   "].  Should  be  one  of  [local,  network]. ");  
elasticsearch_b9ee9157631ee3ff3e19b7745886e5c004dbe134	buggy:  if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0))  {  context:  public  void  setAllowUnmappedFields(boolean  allowUnmappedFields)  {  this.allowUnmappedFields  =  allowUnmappedFields;  }  private  <T>  T  failIfFieldMappingNotFound(String  name,  T  fieldMapping)  {  if  (allowUnmappedFields)  {  return  fieldMapping;  }  else  {  Version  indexCreatedVersion  =  indexQueryParser.getIndexCreatedVersion();              if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0))  {              if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta))  {  throw  new  QueryParsingException(index,   "Strict  field  resolution  and  no  field  mapping  can  be  found  for  the  field  with  name  [ "  +  name  +   "] ");  }  else  {  return  fieldMapping;  }  }  }  	if  (fieldMapping  ==  null  &&  indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta))  {  
libgdx_bd89839d56b3eff3d009c7fc4a2f57c75b890e2e	buggy:  return  layout.add(actor);  context:  }  public  Cell  add  ()  {  return  add((Actor)null);  }  public  Cell  add  (Actor  actor)  {  return  layout.add(actor);  return  layout.add(actor  ==  null  ?  new  Actor()  :  actor);  }  public  Cell  stack  (Actor...  actors)  {  Stack  stack  =  new  Stack();  if  (actors  !=  null)  {  for  (int  i  =  0,  n  =  actors.length;  i  <  n;  i++)  	return  layout.add(actor  ==  null  ?  new  Actor()  :  actor);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  hl  =  new  HashMap<String,  HighlightField>(size);  context:  return  hl;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  id  =  in.readText();  index  =  in.readText();  score  =  in.readFloat();  int  size  =  in.readVInt();  if  (size  >  0)  {                  hl  =  new  HashMap<String,  HighlightField>(size);                  hl  =  new  HashMap<>(size);  for  (int  j  =  0;  j  <  size;  j++)  {  hl.put(in.readString(),  HighlightField.readHighlightField(in));  }  }  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  	hl  =  new  HashMap<>(size);  
elasticsearch_98a674fc6ed8516f8a20641950e0c149b0494bee	buggy:  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.attributes().get( "total_hits ")),  0.0f),  null,  false);  context:  protected  final  void  addShardFailure(ShardSearchFailure  failure)  {  if  (shardFailures  ==  null)  {  shardFailures  =  ConcurrentCollections.newQueue();  }  shardFailures.add(failure);  }  public  void  start()  {  if  (scrollId.context().length  ==  0)  {                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.attributes().get( "total_hits ")),  0.0f),  null,  false);                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.attributes().get( "total_hits ")),  0.0f),  null,  null,  false);  searchCache.releaseQueryFetchResults(queryFetchResults);  listener.onResponse(new  SearchResponse(internalResponse,  request.scrollId(),  0,  0,  0l,  buildShardFailures()));  return;  }  int  localOperations  =  0;  for  (Tuple<String,  Long>  target  :  scrollId.context())  {  DiscoveryNode  node  =  nodes.get(target.v1());  	final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.attributes().get( "total_hits ")),  0.0f),  null,  null,  false);  
elasticsearch_c7f6c5266d15fefa1a5ce9ae7ffc519c5ff8abbe	buggy:  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -   "ms ".length())));  context:  public  static  TimeValue  parseTimeValue(String  sValue,  TimeValue  defaultValue)  {  if  (sValue  ==  null)  {  return  defaultValue;  }  try  {  long  millis;  if  (sValue.endsWith( "S "))  {  millis  =  Long.parseLong(sValue.substring(0,  sValue.length()  -  1));  }  else  if  (sValue.endsWith( "ms "))  {                  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -   "ms ".length())));                  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  2)));  }  else  if  (sValue.endsWith( "s "))  {  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  1))  *  1000);  }  else  if  (sValue.endsWith( "m "))  {  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  1))  *  60  *  1000);  }  else  if  (sValue.endsWith( "H ")  ||  sValue.endsWith( "h "))  {  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  1))  *  60  *  60  *  1000);  }  else  if  (sValue.endsWith( "d "))  {  millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  1))  *  24  *  60  *  60  *  1000);  	millis  =  (long)  (Double.parseDouble(sValue.substring(0,  sValue.length()  -  2)));  
elasticsearch_12e2ba822f52bcab5a74603f41233a6d5cb423f6	buggy:  normsField  =  jp.getText();  context:  String  currentFieldName  =  null;  JsonToken  token;  while  ((token  =  jp.nextToken())  !=  JsonToken.END_OBJECT)  {  if  (token  ==  JsonToken.FIELD_NAME)  {  currentFieldName  =  jp.getCurrentName();  }  else  {  if  ( "boost ".equals(currentFieldName))  {  boost  =  jp.getFloatValue();  }  else  if  ( "normsField ".equals(currentFieldName))  {                      normsField  =  jp.getText();                      normsField  =  parseContext.indexName(jp.getText());  }  }  }  MatchAllDocsQuery  query  =  new  MatchAllDocsQuery(normsField);  query.setBoost(boost);  return  query;  }  	normsField  =  parseContext.indexName(jp.getText());  
elasticsearch_411739fe3b5b2410fa9594edf27087718162225f	buggy:  assertAcked(client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setName( "custom_warmer "));  context:  }  public  void  testDeleteWarmerAcknowledgement()  {  createIndex( "test ");  ensureGreen();  assertAcked(client().admin().indices().preparePutWarmer( "custom_warmer ")  .setSearchRequest(client().prepareSearch( "test ").setTypes( "test ").setQuery(QueryBuilders.matchAllQuery())));          assertAcked(client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setName( "custom_warmer "));          assertAcked(client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setNames( "custom_warmer "));  for  (Client  client  :  clients())  {  GetWarmersResponse  getWarmersResponse  =  client.admin().indices().prepareGetWarmers().setLocal(true).get();  assertThat(getWarmersResponse.warmers().size(),  equalTo(0));  }  }  	assertAcked(client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setNames( "custom_warmer "));  
libgdx_8acc495173f331d13730415858eef17c4a82af56	buggy:  ui.act(Gdx.graphics.getDeltaTime());  context:  linearh.action(MoveTo.$(100,  10,  1.5f));  ui.addActor(linearh);  Gdx.input.setInputProcessor(this);  }  GL10  gl  =  Gdx.graphics.getGL10();  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  ui.act(Gdx.graphics.getDeltaTime());  ui.act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30.0f));  ui.draw();  }  return  false;  }  	ui.act(Math.min(Gdx.graphics.getDeltaTime(),  1  /  30.0f));  
elasticsearch_f8780751c43c098bef27ac912c69cdf236ca7e5f	buggy:  add(new  DeleteRequest(index,  type,  id).parent(parent).version(version).versionType(versionType).routing(routing),  payload);  context:  versionType  =  VersionType.fromString(parser.text());  }  else  if  ( "percolate ".equals(currentFieldName)  ||   "_percolate ".equals(currentFieldName))  {  percolate  =  parser.textOrNull();  }  else  if  ( "_retry_on_conflict ".equals(currentFieldName)  ||   "_retryOnConflict ".equals(currentFieldName))  {  retryOnConflict  =  parser.intValue();  }  }  }  if  ( "delete ".equals(action))  {                      add(new  DeleteRequest(index,  type,  id).parent(parent).version(version).versionType(versionType).routing(routing),  payload);                      add(new  DeleteRequest(index,  type,  id).routing(routing).parent(parent).version(version).versionType(versionType),  payload);  }  else  {  nextMarker  =  findNextMarker(marker,  from,  data,  length);  if  (nextMarker  ==  -1)  {  break;  }  	add(new  DeleteRequest(index,  type,  id).routing(routing).parent(parent).version(version).versionType(versionType),  payload);  
libgdx_194e431479a7081525f9acfa6f5afd71124e44a2	buggy:  model  =  new  MD2Loader().load(Gdx.files.internal( "data/knight.md2 ").read());  context:  public  class  MD2Viewer  implements  ApplicationListener  {  KeyframedModel  model;  PerspectiveCamera  cam;  float  angle  =  0;  model  =  new  MD2Loader().load(Gdx.files.internal( "data/knight.md2 ").read());  model  =  new  MD2Loader().load(Gdx.files.internal( "data/knight.md2 ").read(),  0.2f);  Material  material  =  new  Material( "knight ",  new  TextureAttribute(new  Texture( "data/knight.jpg "),  0,   "a_tex0 "));  model.setMaterial(material);  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.far  =  300;  cam.position.set(0,  12,  50);  }  	model  =  new  MD2Loader().load(Gdx.files.internal( "data/knight.md2 ").read(),  0.2f);  
elasticsearch_e0f9f292ec02a096a829dc42dffc3bbfdd9d6c4b	buggy:  logger.warn( "disabled,  failed  to  setup  multicast  discovery  on  {}:  {} ",  multicastInterface,  e.getMessage());  context:  this.receiver  =  new  Receiver();  this.receiverThread  =  daemonThreadFactory(settings,   "discovery#multicast#receiver ").newThread(receiver);  this.receiverThread.start();  }  catch  (Exception  e)  {  datagramPacketReceive  =  null;  datagramPacketSend  =  null;  if  (multicastSocket  !=  null)  {  multicastSocket.close();  multicastSocket  =  null;  }              logger.warn( "disabled,  failed  to  setup  multicast  discovery  on  {}:  {} ",  multicastInterface,  e.getMessage());              logger.warn( "disabled,  failed  to  setup  multicast  discovery  on  port  [{}],  [{}]:  {} ",  port,  multicastInterface,  e.getMessage());  if  (logger.isDebugEnabled())  {  }  }  }  protected  void  doStop()  throws  ElasticSearchException  {  	logger.warn( "disabled,  failed  to  setup  multicast  discovery  on  port  [{}],  [{}]:  {} ",  port,  multicastInterface,  e.getMessage());  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);  context:  public  class  PreBuiltTokenizerFactoryFactory  implements  TokenizerFactoryFactory  {  private  final  TokenizerFactory  tokenizerFactory;  public  PreBuiltTokenizerFactoryFactory(TokenizerFactory  tokenizerFactory)  {  this.tokenizerFactory  =  tokenizerFactory;  }  public  TokenizerFactory  create(String  name,  Settings  settings)  {          Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);          Version  indexVersion  =  Version.indexCreated(settings);  if  (!Version.CURRENT.equals(indexVersion))  {  PreBuiltTokenizers  preBuiltTokenizers  =  PreBuiltTokenizers.getOrDefault(name,  null);  if  (preBuiltTokenizers  !=  null)  {  return  preBuiltTokenizers.getTokenizerFactory(indexVersion);  }  }  return  tokenizerFactory;  	Version  indexVersion  =  Version.indexCreated(settings);  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(RangeFacetCollectorParser.NAME);  context:  if  (keyFieldName  ==  null)  {  throw  new  SearchSourceBuilderException( "field  must  be  set  on  range  facet  for  facet  [ "  +  name  +   "] ");  }  if  (entries.isEmpty())  {  throw  new  SearchSourceBuilderException( "at  least  one  range  must  be  defined  for  range  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(RangeFacetCollectorParser.NAME);          builder.startObject(RangeFacet.TYPE);  if  (valueFieldName  !=  null  &&  !keyFieldName.equals(valueFieldName))  {  builder.field( "key_field ",  keyFieldName);  builder.field( "value_field ",  valueFieldName);  }  else  {  builder.field( "field ",  keyFieldName);  }  builder.startArray( "ranges ");  	builder.startObject(RangeFacet.TYPE);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false  :   "Unknown  Scope:  [ "  +  currentClusterScope  +   "] ";  context:  clearClusters();  currentCluster  =  GLOBAL_CLUSTER;  break;  case  SUITE:  currentCluster  =  buildAndPutCluster(currentClusterScope,  false);  break;  case  TEST:  currentCluster  =  buildAndPutCluster(currentClusterScope,  true);  break;  default:                      assert  false  :   "Unknown  Scope:  [ "  +  currentClusterScope  +   "] ";                      fail( "Unknown  Scope:  [ "  +  currentClusterScope  +   "] ");  }  currentCluster.beforeTest(getRandom(),  getPerTestTransportClientRatio());  wipeIndices( "_all ");  wipeTemplates();  randomIndexTemplate();  wipeRepositories();  }  catch  (OutOfMemoryError  e)  {  	fail( "Unknown  Scope:  [ "  +  currentClusterScope  +   "] ");  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  Engine.Searcher  searcher  =  shard.acquireSearcher();  context:  }  private  boolean  hasPercolatorType(IndexShard  indexShard)  {  ShardId  otherShardId  =  indexShard.shardId();  return  shardId.equals(otherShardId)  &&  mapperService.hasMapping(PercolatorService.Constants.TYPE_NAME);  }  private  void  loadQueries(IndexShard  shard)  {  try  {  shard.refresh(new  Engine.Refresh().force(true).source( "percolator_load_queries "));                  Engine.Searcher  searcher  =  shard.acquireSearcher();                  Engine.Searcher  searcher  =  shard.acquireSearcher( "percolator_load_queries ");  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.Constants.TYPE_NAME))  )  );  QueriesLoaderCollector  queries  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  searcher.searcher().search(query,  queries);  	Engine.Searcher  searcher  =  shard.acquireSearcher( "percolator_load_queries ");  
elasticsearch_1d1ca3befc8bbe57bc58f32633c02d47922e651d	buggy:  return  new  FieldDataType( "double ");  context:  public  class  DoubleFieldDataTests  extends  AbstractNumericFieldDataTests  {  protected  FieldDataType  getFieldDataType()  {          return  new  FieldDataType( "double ");          return  new  FieldDataType( "double ",  getFieldDataSettings());  }  protected  String  one()  {  return   "1.0 ";  }  protected  String  two()  {  return   "2.0 ";  	return  new  FieldDataType( "double ",  getFieldDataSettings());  
elasticsearch_65ae606c41b165a72f8d0d8acbaa47829d8c15ff	buggy:  return   "Index  Shard  [ "  +  index.name()  +   "][ "  +  shardId  +   "] ";  context:  public  int  id()  {  return  this.shardId;  }  public  int  getId()  {  return  id();  }  public  String  toString()  {          return   "Index  Shard  [ "  +  index.name()  +   "][ "  +  shardId  +   "] ";          return   "[ "  +  index.name()  +   "][ "  +  shardId  +   "] ";  }  public  boolean  equals(Object  o)  {  if  (this  ==  o)  return  true;  if  (o  ==  null)  return  false;  ShardId  shardId1  =  (ShardId)  o;  return  shardId  ==  shardId1.shardId  &&  index.name().equals(shardId1.index.name());  	return   "[ "  +  index.name()  +   "][ "  +  shardId  +   "] ";  
elasticsearch_e955e41a912bb1e785ff55fb449a3b9d154a79aa	buggy:  }  catch  (IOException  e)  {  context:  if  (cachedMd5  !=  null  &&  cachedMd5.containsKey(name))  {  builder.put(name,  new  PlainBlobMetaData(name,  sizeInBytes,  cachedMd5.get(name)));  }  else  {  try  {  String  md5  =  Digest.md5HexFromByteArray(container.readBlobFully(name  +   ".md5 "));  if  (cachedMd5  !=  null)  {  cachedMd5.put(name,  md5);  }  builder.put(name,  new  PlainBlobMetaData(name,  sizeInBytes,  md5));                  }  catch  (IOException  e)  {                  }  catch  (Exception  e)  {  }  }  }  return  builder.build();  }  }  	}  catch  (Exception  e)  {  
elasticsearch_d487d809ea2e99a853cd7c845db1b14d8a160e72	buggy:  boolean  cache  =  false;  context:  super(index,  settings);  }  return  new  String[]{NAME};  }  XContentParser  parser  =  parseContext.parser();          boolean  cache  =  false;          boolean  cache  =  true;  String  fieldName  =  null;  String  from  =  null;  String  to  =  null;  boolean  includeLower  =  true;  boolean  includeUpper  =  true;  String  filterName  =  null;  String  currentFieldName  =  null;  	boolean  cache  =  true;  
elasticsearch_ec016c735ce8b7525de5b69c428ee47c0a328af7	buggy:  }  else  if  (fieldDataType.getLoading()  !=  Loading.EAGER  &&  warmUp.containsKey(indexName))  {  context:  final  FieldDataType  fieldDataType  =  fieldMapper.fieldDataType();  if  (fieldDataType  ==  null)  {  continue;  }  final  String  indexName  =  fieldMapper.names().indexName();  if  (fieldMapper  instanceof  ParentFieldMapper)  {  ParentFieldMapper  parentFieldMapper  =  (ParentFieldMapper)  fieldMapper;  if  (parentFieldMapper.active())  {  warmUp.put(indexName,  parentFieldMapper);  }                      }  else  if  (fieldDataType.getLoading()  !=  Loading.EAGER  &&  warmUp.containsKey(indexName))  {                      }  else  if  (fieldDataType.getLoading()  !=  Loading.EAGER  &&  !warmUp.containsKey(indexName))  {  warmUp.put(indexName,  fieldMapper);  }  }  }  final  IndexFieldDataService  indexFieldDataService  =  indexShard.indexFieldDataService();  final  Executor  executor  =  threadPool.executor(executor());  final  CountDownLatch  latch  =  new  CountDownLatch(context.newSearcher().reader().leaves().size()  *  warmUp.size());  for  (final  AtomicReaderContext  ctx  :  context.newSearcher().reader().leaves())  {  	}  else  if  (fieldDataType.getLoading()  !=  Loading.EAGER  &&  !warmUp.containsKey(indexName))  {  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  query  =  new  ConstantScoreQuery(query);  context:  public  static  SegmentInfos  readSegmentInfos(Directory  directory)  throws  IOException  {  final  SegmentInfos  sis  =  new  SegmentInfos();  sis.read(directory);  return  sis;  }  public  static  long  count(IndexSearcher  searcher,  Query  query)  throws  IOException  {  TotalHitCountCollector  countCollector  =  new  TotalHitCountCollector();  if  (!(query  instanceof  ConstantScoreQuery))  {              query  =  new  ConstantScoreQuery(query);              query  =  new  XLuceneConstantScoreQuery(query);  }  searcher.search(query,  countCollector);  return  countCollector.getTotalHits();  }  	query  =  new  XLuceneConstantScoreQuery(query);  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices( "idx ");  context:  }  }  public  void  testDuelTerms()  throws  Exception  {  final  int  numDocs  =  scaledRandomIntBetween(10000,  20000);  final  int  maxNumTerms  =  randomIntBetween(10,  100000);  final  IntOpenHashSet  valuesSet  =  new  IntOpenHashSet();          cluster().wipeIndices( "idx ");          immutableCluster().wipeIndices( "idx ");  prepareCreate( "idx ").addMapping( "type ",  jsonBuilder().startObject()  .startObject( "type ")  .startObject( "properties ")  .startObject( "string_values ")  .field( "type ",   "string ")  .field( "index ",   "not_analyzed ")  .endObject()  .startObject( "long_values ")  	immutableCluster().wipeIndices( "idx ");  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.get(getRequest,  new  ActionListener<GetResponse>()  {  public  void  onResponse(GetResponse  response)  {  try  {  if  (!response.isExists())  {  channel.sendResponse(new  StringRestResponse(NOT_FOUND));  }  else  {  channel.sendResponse(new  StringRestResponse(OK));  }                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  StringRestResponse(ExceptionsHelper.status(e)));  	}  catch  (Throwable  e)  {  
elasticsearch_ff6d7254fe230d332ba3fd131686cf2733307f6f	buggy:  MapperQueryParser  queryParser  =  parseContext.queryParser(qpSettings);  context:  if  (qpSettings.escape())  {  qpSettings.queryString(QueryParser.escape(qpSettings.queryString()));  }  Query  query  =  queryParserCache.get(qpSettings);  if  (query  !=  null)  {  return  query;  }          MapperQueryParser  queryParser  =  parseContext.queryParser(qpSettings);          MapperQueryParser  queryParser  =  parseContext.singleQueryParser(qpSettings);  try  {  query  =  queryParser.parse(qpSettings.queryString());  query.setBoost(qpSettings.boost());  query  =  optimizeQuery(fixNegativeQueryIfNeeded(query));  queryParserCache.put(qpSettings,  query);  return  query;  }  catch  (ParseException  e)  {  	MapperQueryParser  queryParser  =  parseContext.singleQueryParser(qpSettings);  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  return  readFrom(new  BytesStreamInput(data),  localNode);  context:  try  {  BytesStreamOutput  os  =  cachedEntry.cachedBytes();  writeTo(state,  os);  return  os.copiedByteArray();  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  }  }  public  static  ClusterState  fromBytes(byte[]  data,  DiscoveryNode  localNode)  throws  IOException  {              return  readFrom(new  BytesStreamInput(data),  localNode);              return  readFrom(new  BytesStreamInput(data,  false),  localNode);  }  public  static  void  writeTo(ClusterState  state,  StreamOutput  out)  throws  IOException  {  out.writeLong(state.version());  MetaData.Builder.writeTo(state.metaData(),  out);  RoutingTable.Builder.writeTo(state.routingTable(),  out);  DiscoveryNodes.Builder.writeTo(state.nodes(),  out);  ClusterBlocks.Builder.writeClusterBlocks(state.blocks(),  out);  	return  readFrom(new  BytesStreamInput(data,  false),  localNode);  
elasticsearch_a82d486bda87c06fcb34affb9706e30bf4b303b0	buggy:  return  ThreadPool.Names.GENERIC;  context:  }  transportService.sendRequest(node,  action.name(),  request,  transportOptions,  new  BaseTransportResponseHandler<Response>()  {  public  Response  newInstance()  {  return  action.newResponse();  }  public  String  executor()  {  if  (request.listenerThreaded())  {                      return  ThreadPool.Names.GENERIC;                      return  ThreadPool.Names.LISTENER;  }  return  ThreadPool.Names.SAME;  }  public  void  handleResponse(Response  response)  {  listener.onResponse(response);  }  	return  ThreadPool.Names.LISTENER;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execFlush(flushRequest,  new  ActionListener<FlushResponse>()  {  context:  FlushRequest  flushRequest  =  new  FlushRequest(RestActions.splitIndices(request.param( "index ")));  flushRequest.listenerThreaded(false);  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  flushRequest.operationThreading(operationThreading);  flushRequest.refresh(request.paramAsBoolean( "refresh ",  flushRequest.refresh()));          client.admin().indices().execFlush(flushRequest,  new  ActionListener<FlushResponse>()  {          client.admin().indices().flush(flushRequest,  new  ActionListener<FlushResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  buildBroadcastShardsHeader(builder,  response);  	client.admin().indices().flush(flushRequest,  new  ActionListener<FlushResponse>()  {  
elasticsearch_bae3203e3beee284ca79ef9e004dd7abb1cb5b94	buggy:  while  (cluster().size()  !=  0)  {  context:  public  void  testLoadByClassNameShardsAllocator()  {  Settings  build  =  settingsBuilder().put(ShardsAllocatorModule.TYPE_KEY,   "EvenShardsCount ").build();  assertAllocatorInstance(build,  EvenShardsCountAllocator.class);  build  =  settingsBuilder().put(ShardsAllocatorModule.TYPE_KEY,   "org.elasticsearch.cluster.routing.allocation.allocator.EvenShardsCountAllocator ").build();  assertAllocatorInstance(build,  EvenShardsCountAllocator.class);  }  private  void  assertAllocatorInstance(Settings  settings,  Class<?  extends  ShardsAllocator>  clazz)  {          while  (cluster().size()  !=  0)  {          while  (immutableCluster().size()  !=  0)  {  cluster().stopRandomNode();  }  cluster().startNode(settings);  ShardsAllocator  instance  =  cluster().getInstance(ShardsAllocator.class);  assertThat(instance,  instanceOf(clazz));  }  }  	while  (immutableCluster().size()  !=  0)  {  
elasticsearch_c10544479f3d774548a0b1243010ab36a8f9d3e8	buggy:  HandlesStreamOutput  out  =  BytesStreamOutput.Cached.cachedHandles();  context:  ConcurrentMap<DiscoveryNode,  PingResponse>  responses  =  receivedResponses.remove(id);  listener.onPing(responses.values().toArray(new  PingResponse[responses.size()]));  }  },  timeout);  }  private  void  sendPingRequest(int  id)  {  synchronized  (sendMutex)  {  try  {                  HandlesStreamOutput  out  =  BytesStreamOutput.Cached.cachedHandles();                  HandlesStreamOutput  out  =  CachedStreamOutput.cachedHandles();  out.writeInt(id);  clusterName.writeTo(out);  nodesProvider.nodes().localNode().writeTo(out);  datagramPacketSend.setData(((BytesStreamOutput)  out.wrappedOut()).copiedByteArray());  }  catch  (IOException  e)  {  receivedResponses.remove(id);  throw  new  ZenPingException( "Failed  to  serialize  ping  request ",  e);  }  	HandlesStreamOutput  out  =  CachedStreamOutput.cachedHandles();  
elasticsearch_63eb49d2021f8165b6511b6715932e38782170a6	buggy:  .put( "chunk_size ",  randomIntBetween(100,  1000))  context:  Client  client  =  client();  File  repositoryLocation  =  newTempDir(LifecycleScope.SUITE);  boolean  throttleSnapshot  =  randomBoolean();  boolean  throttleRestore  =  randomBoolean();  assertAcked(client.admin().cluster().preparePutRepository( "test-repo ")  .setType( "fs ").setSettings(ImmutableSettings.settingsBuilder()  .put( "location ",  repositoryLocation)  .put( "compress ",  randomBoolean())                          .put( "chunk_size ",  randomIntBetween(100,  1000))                          .put( "chunk_size ",  randomIntBetween(1000,  10000))  .put( "max_restore_bytes_per_sec ",  throttleRestore  ?   "2.5k "  :   "0 ")  .put( "max_snapshot_bytes_per_sec ",  throttleSnapshot  ?   "2.5k "  :   "0 ")));  createIndex( "test-idx ");  ensureGreen();  for  (int  i  =  0;  i  <  100;  i++)  {  	.put( "chunk_size ",  randomIntBetween(1000,  10000))  
elasticsearch_d94b25278a2554a2d4e63dab9b0eab9ffa96a893	buggy:  builder.field( "force_source ",  forceSource);  context:  if  (field.matchedFields  !=  null)  {  builder.field( "matched_fields ",  field.matchedFields);  }  if  (field.phraseLimit  !=  null)  {  builder.field( "phrase_limit ",  field.phraseLimit);  }  if  (field.options  !=  null  &&  field.options.size()  >  0)  {  builder.field( "options ",  field.options);  }  if  (field.forceSource  !=  null)  {                      builder.field( "force_source ",  forceSource);                      builder.field( "force_source ",  field.forceSource);  }  builder.endObject();  }  builder.endObject();  }  builder.endObject();  	builder.field( "force_source ",  field.forceSource);  
elasticsearch_8c7e0f5ca1bec303b0ffdad76974e56828e5877d	buggy:  intsScratch.values[0]  =  docId;  context:  public  int  getOrd(int  docId)  {  return  ordinals[docId];  }  public  IntArrayRef  getOrds(int  docId)  {  int  ordinal  =  ordinals[docId];  if  (ordinal  ==  0)  return  IntArrayRef.EMPTY;              intsScratch.values[0]  =  docId;              intsScratch.values[0]  =  ordinal;  return  intsScratch;  }  public  Iter  getIter(int  docId)  {  return  iter.reset(ordinals[docId]);  }  	intsScratch.values[0]  =  ordinal;  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  builder.field( "scope ",  scope);  context:  this.boost  =  boost;  return  this;  }  builder.startObject(TopChildrenQueryParser.NAME);  builder.field( "query ");  queryBuilder.toXContent(builder,  params);  builder.field( "type ",  childType);  if  (scope  !=  null)  {              builder.field( "scope ",  scope);              builder.field( "_scope ",  scope);  }  if  (score  !=  null)  {  builder.field( "score ",  score);  }  if  (boost  !=  -1)  {  builder.field( "boost ",  boost);  }  if  (factor  !=  -1)  {  	builder.field( "_scope ",  scope);  
libgdx_81c2094b77c636fcb720cd46f1e2b1a0532758cb	buggy:  if  (animTime  >  anim.totalDuration  -  anim.frameDuration)  {  context:  if  (texture  !=  null)  {  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  texture.bind();  }  angle  +=  45  *  Gdx.graphics.getDeltaTime();  animTime  +=  Gdx.graphics.getDeltaTime();  if  (animTime  >  anim.totalDuration  -  anim.frameDuration)  {  if  (animTime  >=  anim.totalDuration)  {  animTime  =  0;  }  model.setAnimation(anim.name,  animTime,  false);  for  (int  i  =  0;  i  <  20;  i++)  {  Gdx.gl10.glPushMatrix();  Gdx.gl10.glTranslatef(0,  0,  -100  +  i  *  10);  model.render();  	if  (animTime  >=  anim.totalDuration)  {  
elasticsearch_7867de4f5bb7bed1641e6be8d58118d3bc0c5ce3	buggy:  if  (ord  >  0)  {  context:  if  (uniqueValuesSize  +  ordinalsSize  <  singleValuesSize)  {  return  new  PackedArrayAtomicFieldData.WithOrdinals(values,  reader.maxDoc(),  build);  }  final  PackedInts.Mutable  sValues  =  PackedInts.getMutable(reader.maxDoc(),  bitsRequired,  acceptableOverheadRatio);  if  (missingValue  !=  0)  {  sValues.fill(0,  sValues.size(),  missingValue);  }  for  (int  i  =  0;  i  <  reader.maxDoc();  i++)  {  final  long  ord  =  ordinals.getOrd(i);                      if  (ord  >  0)  {                      if  (ord  !=  Ordinals.MISSING_ORDINAL)  {  sValues.set(i,  values.get(ord  -  1)  -  minValue);  }  }  if  (set  ==  null)  {  return  new  PackedArrayAtomicFieldData.Single(sValues,  minValue,  reader.maxDoc(),  ordinals.getNumOrds());  }  else  {  return  new  PackedArrayAtomicFieldData.SingleSparse(sValues,  minValue,  reader.maxDoc(),  missingValue,  ordinals.getNumOrds());  }  	if  (ord  !=  Ordinals.MISSING_ORDINAL)  {  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);  context:  private  void  publish(LocalDiscovery[]  members,  ClusterState  clusterState,  final  ClusterStatePublishResponseHandler  publishResponseHandler)  {  try  {  final  byte[]  clusterStateBytes  =  Builder.toBytes(clusterState);  for  (final  LocalDiscovery  discovery  :  members)  {  if  (discovery.master)  {  continue;  }                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode,  clusterName);  nodeSpecificClusterState.status(ClusterState.ClusterStateStatus.RECEIVED);  if  (nodeSpecificClusterState.nodes().localNode()  !=  null)  {  assert  nodeSpecificClusterState.nodes().masterNode()  !=  null  :   "received  a  cluster  state  without  a  master ";  assert  !nodeSpecificClusterState.blocks().hasGlobalBlock(discoveryService.getNoMasterBlock())  :   "received  a  cluster  state  with  a  master  block ";  discovery.clusterService.submitStateUpdateTask( "local-disco-receive(from  master) ",  new  ProcessedClusterStateNonMasterUpdateTask()  {  	final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode,  clusterName);  
elasticsearch_f62f7b8ffe323ec83ea4079ba9dcd525cdaaacef	buggy:  if  (indexSize  ==  reusedIndexSize)  {  context:  public  ByteSizeValue  getRecoveredIndexSize()  {  return  recoveredIndexSize();  }  public  int  indexRecoveryProgress()  {  if  (recoveredIndexSize  ==  0)  {              if  (indexSize  ==  reusedIndexSize)  {              if  (indexSize  !=  0  &&  indexSize  ==  reusedIndexSize)  {  return  100;  }  return  0;  }  return  (int)  (((double)  recoveredIndexSize)  /  expectedRecoveredIndexSize().bytes()  *  100);  }  public  int  getIndexRecoveryProgress()  {  	if  (indexSize  !=  0  &&  indexSize  ==  reusedIndexSize)  {  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  FloatValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  float  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Float.NEGATIVE_INFINITY  :  Float.POSITIVE_INFINITY;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Float.POSITIVE_INFINITY  :  Float.NEGATIVE_INFINITY;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).floatValue()  :  Float.parseFloat(missingValue.toString());  }          return  new  FloatValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  FloatValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  FloatValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
libgdx_04bb9edbe53007d6bb80483a7077ac5c7162d0fa	buggy:  l.range  =  4;  context:  lightManager  =  new  LightManager(8);  lightManager.ambientLight.set(0.1f,  0.1f,  0.1f,  0);  for  (int  i  =  0;  i  <  32;  i++)  {  PointLight  l  =  new  PointLight();  l.position.set(MathUtils.random(16)  -  8,  MathUtils.random(6)  -  2,  MathUtils.random(16)  +  2);  l.color.r  =  MathUtils.random();  l.color.b  =  MathUtils.random();  l.color.g  =  MathUtils.random();  l.range  =  4;  l.intensity  =  4;  lightManager.addLigth(l);  }  protoRenderer  =  new  PrototypeRendererGL20();  protoRenderer.setShader(shader);  protoRenderer.setLightManager(lightManager);  	l.intensity  =  4;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Dependency<T>(this,  key,  allowsNull,  parameterIndex);  context:  errors.merge(e.getErrors());  }  }  errors.throwConfigurationExceptionIfErrorsExist();  return  ImmutableList.copyOf(dependencies);  }  private  <T>  Dependency<T>  newDependency(Key<T>  key,  boolean  allowsNull,  int  parameterIndex)  {          return  new  Dependency<T>(this,  key,  allowsNull,  parameterIndex);          return  new  Dependency<>(this,  key,  allowsNull,  parameterIndex);  }  public  Member  getMember()  {  return  member;  }  	return  new  Dependency<>(this,  key,  allowsNull,  parameterIndex);  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  if  (termsEnum.seekExact(term,  true))  {  context:  public  long  frequency(BytesRef  term)  throws  IOException  {  term  =  preFilter(term,  spare,  byteSpare);  return  internalFrequency(term);  }  public  long  internalFrequency(BytesRef  term)  throws  IOException  {          if  (termsEnum.seekExact(term,  true))  {          if  (termsEnum.seekExact(term))  {  return  useTotalTermFrequency  ?  termsEnum.totalTermFreq()  :  termsEnum.docFreq();  }  return  0;  }  public  String  getField()  {  return  field;  }  	if  (termsEnum.seekExact(term))  {  
elasticsearch_3ac2f8c789550531fd5ab87b09647631af91b0f1	buggy:  throw  new  RestTestParseException( "malformed  test  section:  field  suiteName  expected  but  found   "  +  token);  context:  if  (token  ==  null)  {  token  =  parser.nextToken();  }  if  (token  ==  XContentParser.Token.START_ARRAY)  {  token  =  parser.nextToken();  }  if  (token  ==  XContentParser.Token.START_OBJECT)  {  token  =  parser.nextToken();  }  if  (token  !=  XContentParser.Token.FIELD_NAME)  {              throw  new  RestTestParseException( "malformed  test  section:  field  suiteName  expected  but  found   "  +  token);              throw  new  RestTestParseException( "malformed  test  section:  field  name  expected  but  found   "  +  token);  }  }  public  String  parseField()  throws  IOException,  RestTestParseException  {  parser.nextToken();  assert  parser.currentToken().isValue();  String  field  =  parser.text();  parser.nextToken();  	throw  new  RestTestParseException( "malformed  test  section:  field  name  expected  but  found   "  +  token);  
elasticsearch_9c1ac95ba8e593c90b4681f2a554b12ff677cf89	buggy:  id(Strings.randomBase64UUID());  context:  }  }  else  {  if  (parent  !=  null)  {  throw  new  ElasticsearchIllegalArgumentException( "Can't  specify  parent  if  no  parent  field  has  been  configured ");  }  }  if  (allowIdGeneration)  {  if  (id  ==  null)  {                  id(Strings.randomBase64UUID());                  id(Strings.base64UUID());  opType(IndexRequest.OpType.CREATE);  autoGeneratedId  =  true;  }  }  if  (timestamp  ==  null)  {  	id(Strings.base64UUID());  
elasticsearch_f05fa91cb2beed59f86214afe51b0335d258eff8	buggy:  searchLookup.source().setNextSource(SourceLookup.sourceAsMap(source.source.bytes(),  source.source.offset(),  source.source.length()));  context:  value  =  searchScript.run();  }  catch  (RuntimeException  e)  {  if  (logger.isTraceEnabled())  {  }  }  }  else  {  if  (searchLookup  ==  null)  {  searchLookup  =  new  SearchLookup(mapperService,  indexCache.fieldData());                                      searchLookup.source().setNextSource(SourceLookup.sourceAsMap(source.source.bytes(),  source.source.offset(),  source.source.length()));                                      searchLookup.source().setNextSource(source.source.bytes(),  source.source.offset(),  source.source.length());  }  FieldMapper<?>  x  =  docMapper.mappers().smartNameFieldMapper(field);  value  =  searchLookup.source().extractValue(field);  if  (x  !=  null  &&  value  instanceof  String)  {  value  =  x.valueFromString((String)  value);  }  }  	searchLookup.source().setNextSource(source.source.bytes(),  source.source.offset(),  source.source.length());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  }  if  (explanation.getExplanation()  !=  null)  {  builder.field( "explanation ",  explanation.getExplanation());  }  builder.endObject();  }  builder.endArray();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_e2961c0c7a24cc320e35d70b7181daf8f06a59bd	buggy:  public  static  EsThreadPoolExecutor  newSinglePrioritizingThreadExecutor(ThreadFactory  threadFactory)  {  context:  public  class  EsExecutors  {      public  static  EsThreadPoolExecutor  newSinglePrioritizingThreadExecutor(ThreadFactory  threadFactory)  {      public  static  PrioritizedEsThreadPoolExecutor  newSinglePrioritizingThreadExecutor(ThreadFactory  threadFactory)  {  return  new  PrioritizedEsThreadPoolExecutor(1,  1,  0L,  TimeUnit.MILLISECONDS,  threadFactory);  }  public  static  EsThreadPoolExecutor  newScalingExecutorService(int  min,  int  max,  long  keepAliveTime,  TimeUnit  unit,  ThreadFactory  threadFactory)  {  ExecutorScalingQueue<Runnable>  queue  =  new  ExecutorScalingQueue<Runnable>();  EsThreadPoolExecutor  executor  =  new  EsThreadPoolExecutor(min,  max,  keepAliveTime,  unit,  queue,  threadFactory,  	public  static  PrioritizedEsThreadPoolExecutor  newSinglePrioritizingThreadExecutor(ThreadFactory  threadFactory)  {  
elasticsearch_455c92d27ba45af0cda31c61db4ddd524bc636c0	buggy:  table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage()[0]);  context:  table.addCell(info  ==  null  ?  null  :  info.getProcess().id());  table.addCell(((InetSocketTransportAddress)  node.address()).address().getAddress().getHostAddress());  table.addCell(((InetSocketTransportAddress)  node.address()).address().getPort());  table.addCell(info  ==  null  ?  null  :  info.getVersion().number());  table.addCell(info  ==  null  ?  null  :  info.getJvm().version());  table.addCell(availableDisk  <  0  ?  null  :  ByteSizeValue.parseBytesSizeValue(new  Long(availableDisk).toString()));  table.addCell(heapRatio  <  0  ?  null  :  String.format(Locale.ROOT,   "%.1f ",  heapRatio*100.0));  table.addCell(heapMax  <  0  ?  null  :  new  ByteSizeValue(heapMax));  table.addCell(stats  ==  null  ?  null  :  stats.getOs().mem()  ==  null  ?  null  :  stats.getOs().mem().usedPercent());  table.addCell(info  ==  null  ?  null  :  info.getOs().mem()  ==  null  ?  null  :  info.getOs().mem().total());  //  sigar  fails  to  load  in  IntelliJ              table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage()[0]);              table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  stats.getOs().getLoadAverage()[0]);  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().uptime());  table.addCell(node.clientNode()  ?   "c "  :  node.dataNode()  ?   "d "  :  null);  table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :  null);  table.addCell(node.name());  table.endRow();  }  	table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  stats.getOs().getLoadAverage()[0]);  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  query  =  Queries.NO_MATCH_QUERY;  context:  public  Query  parseInnerQuery(XContentParser  parser)  throws  IOException  {  QueryParseContext  context  =  cache.get();  context.reset(parser);  return  context.parseInnerQuery();  }  private  ParsedQuery  parse(QueryParseContext  parseContext,  XContentParser  parser)  throws  IOException,  QueryParsingException  {  parseContext.reset(parser);  Query  query  =  parseContext.parseInnerQuery();  if  (query  ==  null)  {              query  =  Queries.NO_MATCH_QUERY;              query  =  Queries.newMatchNoDocsQuery();  }  return  new  ParsedQuery(query,  parseContext.copyNamedFilters());  }  private  void  add(Map<String,  FilterParser>  map,  FilterParser  filterParser)  {  for  (String  name  :  filterParser.names())  {  map.put(name.intern(),  filterParser);  }  	query  =  Queries.newMatchNoDocsQuery();  
elasticsearch_20745adaddde495c72de733e0081f7852c21dafd	buggy:  return  ThreadPool.Names.SEARCH;  context:  public  TransportSuggestAction(Settings  settings,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService,  SuggestPhase  suggestPhase)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  this.suggestPhase  =  suggestPhase;  }  protected  String  executor()  {          return  ThreadPool.Names.SEARCH;          return  ThreadPool.Names.SUGGEST;  }  protected  String  transportAction()  {  return  SuggestAction.NAME;  }  	return  ThreadPool.Names.SUGGEST;  
elasticsearch_17a5575757317962dab4c295bbfacbdb136cc61e	buggy:  assertThat(failure.reason(),  containsString( "[twitter]  [has_child]  No  mapping  for  for  type  [type] "));  context:  NumShards  twitter  =  getNumShards( "twitter ");  assertThat(response.status(),  equalTo(RestStatus.BAD_REQUEST));  assertThat(response.getIndex( "twitter ").getSuccessfulShards(),  equalTo(0));  assertThat(response.getIndex( "twitter ").getFailedShards(),  equalTo(twitter.numPrimaries));  assertThat(response.getIndices().size(),  equalTo(1));  assertThat(response.getIndices().get( "twitter ").getFailedShards(),  equalTo(twitter.numPrimaries));  assertThat(response.getIndices().get( "twitter ").getFailures().length,  equalTo(twitter.numPrimaries));  for  (ShardOperationFailedException  failure  :  response.getIndices().get( "twitter ").getFailures())  {              assertThat(failure.reason(),  containsString( "[twitter]  [has_child]  No  mapping  for  for  type  [type] "));              assertThat(failure.reason(),  containsString( "[twitter]  [has_child]  unsupported  in  delete_by_query  api "));  assertThat(failure.status(),  equalTo(RestStatus.BAD_REQUEST));  assertThat(failure.shardId(),  greaterThan(-1));  }  }  public  void  testDeleteByFieldQuery()  throws  Exception  {  client().admin().indices().prepareCreate( "test ").execute().actionGet();  	assertThat(failure.reason(),  containsString( "[twitter]  [has_child]  unsupported  in  delete_by_query  api "));  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();  context:  .put(IndexMetaData.builder( "test_idx ").numberOfShards(10).numberOfReplicas(1))  .put(IndexTemplateMetaData.builder( "test_template ").build())  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test_idx "))  .build();  DiscoveryNodes  nodes  =  DiscoveryNodes.builder().put(new  DiscoveryNode( "node_foo ",  DummyTransportAddress.INSTANCE,  Version.CURRENT)).localNodeId( "node_foo ").masterNodeId( "node_foo ").build();          ClusterState  clusterState  =  ClusterState.builder().nodes(nodes).metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).nodes(nodes).metaData(metaData).routingTable(routingTable).build();  AllocationService  strategy  =  createAllocationService();  clusterState  =  ClusterState.builder(clusterState).routingTable(strategy.reroute(clusterState).routingTable()).build();  String  clusterStateString  =  clusterState.toString();  assertNotNull(clusterStateString);  assertThat(clusterStateString,  containsString( "test_idx "));  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).nodes(nodes).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_fda6ca4869182a2dfc082490c183eadf8f4e3d05	buggy:  }  else  if  ( "shard_size ".equals(currentFieldName))  {  context:  }  else  {  throw  new  ElasticSearchParseException( "unknown  parameter  [ "  +  currentFieldName  +   "]  while  parsing  terms  facet  [ "  +  facetName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script_field ".equals(currentFieldName)  ||   "scriptField ".equals(currentFieldName))  {  script  =  parser.text();  }  else  if  ( "size ".equals(currentFieldName))  {  size  =  parser.intValue();                  }  else  if  ( "shard_size ".equals(currentFieldName))  {                  }  else  if  ( "shard_size ".equals(currentFieldName)  ||   "shardSize ".equals(currentFieldName))  {  shardSize  =  parser.intValue();  }  else  if  ( "all_terms ".equals(currentFieldName)  ||   "allTerms ".equals(currentFieldName))  {  allTerms  =  parser.booleanValue();  }  else  if  ( "regex ".equals(currentFieldName))  {  regex  =  parser.text();  }  else  if  ( "regex_flags ".equals(currentFieldName)  ||   "regexFlags ".equals(currentFieldName))  {  regexFlags  =  parser.text();  }  else  if  ( "order ".equals(currentFieldName)  ||   "comparator ".equals(currentFieldName))  {  	}  else  if  ( "shard_size ".equals(currentFieldName)  ||   "shardSize ".equals(currentFieldName))  {  
elasticsearch_dfa67bf07166d99b674646860ade1a397010f600	buggy:  throw  new  ElasticSearchIllegalArgumentException( "No  custom  index  metadata  factoy  registered  for  type  [ "  +  type  +   "] ");  context:  }  public  static  <T  extends  Custom>  Custom.Factory<T>  lookupFactory(String  type)  {  return  customFactories.get(type);  }  public  static  <T  extends  Custom>  Custom.Factory<T>  lookupFactorySafe(String  type)  throws  ElasticSearchIllegalArgumentException  {  Custom.Factory<T>  factory  =  customFactories.get(type);  if  (factory  ==  null)  {              throw  new  ElasticSearchIllegalArgumentException( "No  custom  index  metadata  factoy  registered  for  type  [ "  +  type  +   "] ");              throw  new  ElasticSearchIllegalArgumentException( "No  custom  index  metadata  factory  registered  for  type  [ "  +  type  +   "] ");  }  return  factory;  }  public  static  final  String  SETTING_READ_ONLY  =   "cluster.blocks.read_only ";  public  static  final  ClusterBlock  CLUSTER_READ_ONLY_BLOCK  =  new  ClusterBlock(6,   "cluster  read-only  (api) ",  false,  false,  RestStatus.FORBIDDEN,  ClusterBlockLevel.WRITE,  ClusterBlockLevel.METADATA);  	throw  new  ElasticSearchIllegalArgumentException( "No  custom  index  metadata  factory  registered  for  type  [ "  +  type  +   "] ");  
elasticsearch_31a8e92b8edbe1664c30a2b1f84009d8b90e3540	buggy:  return  new  HttpInfo(transport.boundAddress());  context:  nodeService.removeAttribute( "http_address ");  transport.stop();  }  protected  void  doClose()  throws  ElasticSearchException  {  transport.close();  }  public  HttpInfo  info()  {          return  new  HttpInfo(transport.boundAddress());          return  transport.info();  }  public  HttpStats  stats()  {  return  transport.stats();  }  public  void  internalDispatchRequest(final  HttpRequest  request,  final  HttpChannel  channel)  {  if  (request.rawPath().startsWith( "/_plugin/ "))  {  	return  transport.info();  
elasticsearch_d4ec03ed76673e14c5e5566a78fc3785b8a73f1e	buggy:  }  catch  (Exception  e)  {  context:  }  });  }  }  public  void  sendExecuteQuery(DiscoveryNode  node,  final  ShardSearchRequest  request,  final  SearchServiceListener<QuerySearchResult>  listener)  {  if  (clusterService.state().nodes().localNodeId().equals(node.id()))  {  try  {  QuerySearchResult  result  =  searchService.executeQueryPhase(request);  listener.onResult(result);              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  listener.onFailure(e);  }  }  else  {  transportService.sendRequest(node,  SearchQueryTransportHandler.ACTION,  request,  new  BaseTransportResponseHandler<QuerySearchResult>()  {  public  QuerySearchResult  newInstance()  {  return  new  QuerySearchResult();  	}  catch  (Throwable  e)  {  
elasticsearch_383945416866849139755c6761ad162faaadcbe0	buggy:  IntArray  hashes  =  BigArrays.newIntArray(ordinals.getMaxOrd());  context:  }  return  size;  }  public  BytesValues.WithOrdinals  getBytesValues(boolean  needsHashes)  {  assert  fst  !=  null;  if  (needsHashes)  {  if  (hashes  ==  null)  {  BytesRefFSTEnum<Long>  fstEnum  =  new  BytesRefFSTEnum<Long>(fst);                  IntArray  hashes  =  BigArrays.newIntArray(ordinals.getMaxOrd());                  IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(ordinals.getMaxOrd());  hashes.set(0,  new  BytesRef().hashCode());  try  {  for  (long  i  =  1,  maxOrd  =  ordinals.getMaxOrd();  i  <  maxOrd;  ++i)  {  hashes.set(i,  fstEnum.next().input.hashCode());  }  assert  fstEnum.next()  ==  null;  	IntArray  hashes  =  BigArrays.NON_RECYCLING_INSTANCE.newIntArray(ordinals.getMaxOrd());  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(settings),  context:  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),  new  ScriptModule(settings),  new  MapperServiceModule(),                  new  IndexSettingsModule(settings),                  new  IndexSettingsModule(index,  settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index),  new  AbstractModule()  {  	new  IndexSettingsModule(index,  settings),  
libgdx_d69f047ed13a15d17432d37f97e315a4dfa49f8d	buggy:  stage.render();  context:  img.action(actionDelay);  stage.addActor(img);  }  public  void  render()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  stage.render();  stage.draw();  }  public  void  completed(Action  action)  {  }  }  	stage.draw();  
libgdx_a4a361f68cf9556d384ef356b85a24ea24500dc5	buggy:  if  (atlas.getPages().size  !=  1)  context:  config.forceExit  =  false;  config.width  =  1;  config.height  =  1;  config.title  =   "SkinPacker ";  new  LwjglApplication(new  ApplicationListener()  {  public  void  create  ()  {  Skin  skin  =  new  Skin();  TextureAtlasData  atlas  =  new  TextureAtlasData(new  FileHandle(new  File(packedDir,   "pack ")),  new  FileHandle(packedDir),  true);  if  (atlas.getPages().size  !=  1)  if  (atlas.getPages().size  >  1)  throw  new  GdxRuntimeException( "Skin  images  could  not  be  packed  on  to  a  single  image! ");  Texture  texture  =  new  Texture(1,  1,  Format.Alpha);  for  (Region  region  :  atlas.getRegions())  {  int[]  split  =  nameToSplits.get(region.name);  TextureRegion  textureRegion  =  new  TextureRegion(texture,  region.left,  region.top,  region.width,  region.height);  if  (split  ==  null)  {  skin.addResource(region.name,  textureRegion);  }  else  {  	if  (atlas.getPages().size  >  1)  
elasticsearch_5af634369737765bb4f6b52817b2570ade149429	buggy:  if  (!build.isMultiValued())  {  context:  lat.add(Double.parseDouble(new  String(spare.chars,  spare.offset,  (i  -  spare.offset))));  lon.add(Double.parseDouble(new  String(spare.chars,  (spare.offset  +  (i  +  1)),  spare.length  -  ((i  +  1)  -  spare.offset))));  parsed  =  true;  break;  }  }  assert  parsed;  }  Ordinals  build  =  builder.build(fieldDataType.getSettings());              if  (!build.isMultiValued())  {              if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  Docs  ordinals  =  build.ordinals();  double[]  sLat  =  new  double[reader.maxDoc()];  double[]  sLon  =  new  double[reader.maxDoc()];  for  (int  i  =  0;  i  <  sLat.length;  i++)  {  int  nativeOrdinal  =  ordinals.getOrd(i);  sLat[i]  =  lat.get(nativeOrdinal);  sLon[i]  =  lon.get(nativeOrdinal);  }  	if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  this.node  =  node;  this.clusterName  =  clusterName;  this.disabled  =  settings.getAsBoolean( "action.disable_shutdown ",  componentSettings.getAsBoolean( "disabled ",  false));  this.delay  =  componentSettings.getAsTime( "delay ",  TimeValue.timeValueMillis(200));  this.transportService.registerHandler(NodeShutdownRequestHandler.ACTION,  new  NodeShutdownRequestHandler());  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return  NodesShutdownAction.NAME;  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execHealth(clusterHealthRequest,  new  ActionListener<ClusterHealthResponse>()  {  context:  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  PRECONDITION_FAILED,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }  final  int  fLevel  =  level;          client.admin().cluster().execHealth(clusterHealthRequest,  new  ActionListener<ClusterHealthResponse>()  {          client.admin().cluster().health(clusterHealthRequest,  new  ActionListener<ClusterHealthResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "status ",  response.status().name().toLowerCase());  builder.field( "timedOut ",  response.timedOut());  builder.field( "activePrimaryShards ",  response.activePrimaryShards());  	client.admin().cluster().health(clusterHealthRequest,  new  ActionListener<ClusterHealthResponse>()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  HashMap<String,  Object>  scopes  =  new  HashMap<String,  Object>();  context:  public  class  MustacheTest  extends  ElasticsearchTestCase  {  public  void  test()  {          HashMap<String,  Object>  scopes  =  new  HashMap<String,  Object>();          HashMap<String,  Object>  scopes  =  new  HashMap<>();  scopes.put( "boost_val ",   "0.2 ");  String  template  =   "GET  _search  {\ "query\ ":   "  +   "{\ "boosting\ ":  { "   "\ "positive\ ":  {\ "match\ ":  {\ "body\ ":  \ "gift\ "}}, "   "\ "negative\ ":  {\ "term\ ":  {\ "body\ ":  {\ "value\ ":  \ "solr\ "} "   "}},  \ "negative_boost\ ":  {{boost_val}}  }  }} ";  MustacheFactory  f  =  new  DefaultMustacheFactory();  Mustache  mustache  =  f.compile(new  StringReader(template),   "example ");  	HashMap<String,  Object>  scopes  =  new  HashMap<>();  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  final  String  executor  =  ThreadPool.Names.CACHED;  context:  public  Transport  newTransport(Settings  settings,  ThreadPool  threadPool)  {  return  new  NettyTransport(settings,  threadPool);  }  };  public  abstract  Transport  newTransport(Settings  settings,  ThreadPool  threadPool);  }  public  static  void  main(String[]  args)  {          final  String  executor  =  ThreadPool.Names.CACHED;          final  String  executor  =  ThreadPool.Names.GENERIC;  final  boolean  waitForRequest  =  true;  final  ByteSizeValue  payloadSize  =  new  ByteSizeValue(100,  ByteSizeUnit.BYTES);  final  int  NUMBER_OF_CLIENTS  =  1;  final  int  NUMBER_OF_ITERATIONS  =  100000;  final  byte[]  payload  =  new  byte[(int)  payloadSize.bytes()];  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  Type  type  =  Type.NETTY;  	final  String  executor  =  ThreadPool.Names.GENERIC;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(min( "min ")))  context:  public  class  MinTests  extends  AbstractNumericTests  {  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(min( "min ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(min( "min ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(min( "min ")))  
elasticsearch_f97021b165f980b4b9a5c6f03794d6ca936f1622	buggy:  .setSize(10).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always "))  context:  .execute().actionGet();  }  }  client.admin().indices().prepareRefresh().execute().actionGet();  SearchResponse  search  =  client.prepareSearch()  .setSuggestText( "prefix_abcd ")  .addSuggestion(fuzzySuggestion( "size3SortScoreFirst ")  .setSize(3).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always "))  .addSuggestion(fuzzySuggestion( "size10SortScoreFirst ")                          .setSize(10).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always "))                          .setSize(10).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always ").setShardSize(50))  .addSuggestion(fuzzySuggestion( "size3SortScoreFirstMaxEdits1 ")  .setMaxEdits(1)  .setSize(10).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always "))  .addSuggestion(fuzzySuggestion( "size10SortFrequencyFirst ")  .setSize(10).setSort( "frequency ").setShardSize(1000)  .setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always "))  .execute().actionGet();  	.setSize(10).setMinDocFreq(0).setField( "field1 ").setSuggestMode( "always ").setShardSize(50))  
elasticsearch_c8e553054b40705086a6f2970157a2d798685731	buggy:  public  void  fieldMappers(Iterable<FieldMapper>  fieldMappers)  {  context:  public  final  List<FieldMapper>  mappers  =  new  ArrayList<>();  public  void  fieldMapper(FieldMapper  fieldMapper)  {  mappers.add(fieldMapper);  }  }  public  abstract  void  fieldMapper(FieldMapper  fieldMapper);      public  void  fieldMappers(Iterable<FieldMapper>  fieldMappers)  {      public  void  fieldMappers(List<FieldMapper>  fieldMappers)  {  for  (FieldMapper  mapper  :  fieldMappers)  {  fieldMapper(mapper);  }  }  }  	public  void  fieldMappers(List<FieldMapper>    fieldMappers)  {  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  .put( "discovery.zen.ping_timeout ",   "200ms ")  context:  assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(),  equalTo(100l));  }  }  public  void  multipleNodesShutdownNonMasterNodes()  throws  Exception  {  Settings  settings  =  settingsBuilder()  .put( "discovery.type ",   "zen ")  .put( "discovery.zen.minimum_master_nodes ",  3)                  .put( "discovery.zen.ping_timeout ",   "200ms ")                  .put( "discovery.zen.ping_timeout ",   "1s ")  .put( "discovery.initial_state_timeout ",   "500ms ")  .put( "gateway.type ",   "local ")  .build();  internalCluster().startNode(settings);  internalCluster().startNode(settings);  	.put( "discovery.zen.ping_timeout ",   "1s ")  
elasticsearch_541acc7e9b1118d50a5989cafa67689316549dbc	buggy:  recoveryTarget.retryRecovery(request,  recoveryStatus,  PeerRecoveryListener.this);  context:  this.indexMetaData  =  indexMetaData;  }  public  void  onRecoveryDone()  {  shardStateAction.shardStarted(shardRouting,  indexMetaData.getUUID(),   "after  recovery  (replica)  from  node  [ "  +  request.sourceNode()  +   "] ");  }  public  void  onRetryRecovery(TimeValue  retryAfter,  RecoveryStatus  recoveryStatus)  {              recoveryTarget.retryRecovery(request,  recoveryStatus,  PeerRecoveryListener.this);              recoveryTarget.retryRecovery(request,  retryAfter,  recoveryStatus,  PeerRecoveryListener.this);  }  public  void  onIgnoreRecovery(boolean  removeShard,  String  reason)  {  if  (!removeShard)  {  return;  }  synchronized  (mutex)  {  	recoveryTarget.retryRecovery(request,  retryAfter,  recoveryStatus,  PeerRecoveryListener.this);  
elasticsearch_2123ab591c399fd67ff3df88fac1b793b7bd5486	buggy:  }  else  if  ( "random_access_random ".equals(value)  ||   "randomAccessAlways ".equals(value))  {  context:  filterFound  =  true;  filter  =  parseContext.parseInnerFilter();  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[filtered]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "strategy ".equals(currentFieldName))  {  String  value  =  parser.text();  if  ( "query_first ".equals(value)  ||   "queryFirst ".equals(value))  {  filterStrategy  =  FilteredQuery.QUERY_FIRST_FILTER_STRATEGY;                      }  else  if  ( "random_access_random ".equals(value)  ||   "randomAccessAlways ".equals(value))  {                      }  else  if  ( "random_access_always ".equals(value)  ||   "randomAccessAlways ".equals(value))  {  filterStrategy  =  XFilteredQuery.ALWAYS_RANDOM_ACCESS_FILTER_STRATEGY;  }  else  if  ( "leap_frog ".equals(value)  ||   "leapFrog ".equals(value))  {  filterStrategy  =  FilteredQuery.LEAP_FROG_QUERY_FIRST_STRATEGY;  }  else  if  (value.startsWith( "random_access_ "))  {  int  threshold  =  Integer.parseInt(value.substring( "random_access_ ".length()));  filterStrategy  =  new  XFilteredQuery.CustomRandomAccessFilterStrategy(threshold);  }  else  if  (value.startsWith( "randomAccess "))  {  int  threshold  =  Integer.parseInt(value.substring( "randomAccess ".length()));  	}  else  if  ( "random_access_always ".equals(value)  ||   "randomAccessAlways ".equals(value))  {  
libgdx_335bbf4ff4b0a346f7e63fb40586e5ed33857e84	buggy:  GdxTest  test  =  new  SuperKoalio();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  SuperKoalio();  GdxTest  test  =  new  FullscreenTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  FullscreenTest();  
libgdx_b4e80f40083a508a1ac29d5974265f3b308adb49	buggy:  new  LwjglApplication(new  ETC1Test(),  config);  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.width  =  800;  config.height  =  480;  config.useGL20  =  true;  new  LwjglApplication(new  ETC1Test(),  config);  new  LwjglApplication(new  AssetManagerTest(),  config);  }  }  	new  LwjglApplication(new  AssetManagerTest(),  config);  
elasticsearch_2bb681466c49de9643f1cf8d3487afb66ed8d797	buggy:  int  idx  =  sAttr.indexOf('=');  context:  mAttr  =  new  HashMap<String,  String>();  if  (!inHeaders)  {  mAttr.putAll(headers.get(currentCells.size()).attr);  }  String[]  sAttrs  =  Strings.split(attributes,   "; ");  for  (String  sAttr  :  sAttrs)  {  if  (sAttr.length()  ==  0)  {  continue;  }                  int  idx  =  sAttr.indexOf('=');                  int  idx  =  sAttr.indexOf(':');  mAttr.put(sAttr.substring(0,  idx),  sAttr.substring(idx  +  1));  }  }  currentCells.add(new  Cell(value,  mAttr));  return  this;  }  public  List<Cell>  getHeaders()  {  	int  idx  =  sAttr.indexOf(':');  
elasticsearch_906ec57f20d53b6353e504d69c4e4257d5ba92dd	buggy:  int  delimiterIndex  =  uid.lastIndexOf(DELIMITER);  context:  int  result  =  type  !=  null  ?  type.hashCode()  :  0;  result  =  31  *  result  +  (id  !=  null  ?  id.hashCode()  :  0);  return  result;  }  return  type  +  DELIMITER  +  id;  }  public  static  Uid  createUid(String  uid)  {          int  delimiterIndex  =  uid.lastIndexOf(DELIMITER);          int  delimiterIndex  =  uid.indexOf(DELIMITER);  //  type  is  not  allowed  to  have  #  in  it...,  ids  can  return  new  Uid(uid.substring(0,  delimiterIndex),  uid.substring(delimiterIndex  +  1));  }  public  static  String  createUid(String  type,  String  id)  {  return  createUid(new  StringBuilder(),  type,  id);  }  public  static  String  createUid(StringBuilder  sb,  String  type,  String  id)  {  	int  delimiterIndex  =  uid.indexOf(DELIMITER);  //  type  is  not  allowed  to  have  #  in  it...,  ids  can  
elasticsearch_0f23485a3c628ad947496ceb53bf05592ed0c2c7	buggy:  return  new  GlobalOrdinalsIndexFieldData(indexFieldData.index(),  settings,  indexFieldData.getFieldNames(),  context:  String  implName  =  segmentOrdToGlobalOrdLookups.getClass().getSimpleName();   "Global-ordinals[{}][{}][{}]  took  {}  ms ",  implName,  indexFieldData.getFieldNames().fullName(),  maxOrd,  (System.currentTimeMillis()  -  startTime)  );  }          return  new  GlobalOrdinalsIndexFieldData(indexFieldData.index(),  settings,  indexFieldData.getFieldNames(),          return  new  InternalGlobalOrdinalsIndexFieldData(indexFieldData.index(),  settings,  indexFieldData.getFieldNames(),  fieldDataType,  withOrdinals,  globalOrdToFirstSegment,  globalOrdToFirstSegmentDelta,  segmentOrdToGlobalOrdLookups,  memorySizeInBytes  );  }  public  interface  OrdinalMappingSource  {  Ordinals.Docs  globalOrdinals(Ordinals.Docs  segmentOrdinals);  	return  new  InternalGlobalOrdinalsIndexFieldData(indexFieldData.index(),  settings,  indexFieldData.getFieldNames(),  
elasticsearch_6b4e483f558e7cbc1c5b6118161cefabfbcbb9ae	buggy:  .add(object( "name ").add(stringField( "first ").store(YES).index(Field.Index.NO)))  context:  public  class  SimpleMapperTests  {  public  void  testSimpleMapper()  throws  Exception  {  DocumentMapperParser  mapperParser  =  MapperTests.newParser();  DocumentMapper  docMapper  =  doc( "test ",  rootObject( "person ")                          .add(object( "name ").add(stringField( "first ").store(YES).index(Field.Index.NO)))                          .add(object( "name ").add(stringField( "first ").store(true).index(false)))  ).build(mapperParser);  BytesReference  json  =  new  BytesArray(copyToBytesFromClasspath( "/org/elasticsearch/test/unit/index/mapper/simple/test1.json "));  Document  doc  =  docMapper.parse( "person ",   "1 ",  json).rootDoc();  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().names().indexName()),  equalTo( "shay "));  assertThat(docMapper.mappers().name( "first ").mapper().names().fullName(),  equalTo( "name.first "));  	.add(object( "name ").add(stringField( "first ").store(true).index(false)))  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices( "test ");  context:  final  String  fieldName  =   "field ";  final  String  mapping  =   "{  \ " "  +  mappingType  +   "\ ":  { "  +   "\ "dynamic_templates\ ":  [ "   "{  \ " "  +  fieldName  +   "\ ":  { "  +   "\ "path_match\ ":  \ "*\ ", "  +   "\ "mapping\ ":  { "  +   "\ "type\ ":  \ "string\ ", "  +   "\ "store\ ":  \ "yes\ ", "   "\ "index\ ":  \ "analyzed\ ",  \ "analyzer\ ":  \ "whitespace\ "  }  }  }  ]  }  } ";  int  iters  =  scaledRandomIntBetween(5,  15);  for  (int  i  =  0;  i  <  iters;  i++)  {              wipeIndices( "test ");              cluster().wipeIndices( "test ");  assertAcked(prepareCreate( "test ")  .addMapping(mappingType,  mapping));  ensureYellow();  int  numDocs  =  scaledRandomIntBetween(10,  100);  final  CountDownLatch  latch  =  new  CountDownLatch(numDocs);  final  List<Throwable>  throwable  =  new  CopyOnWriteArrayList<Throwable>();  int  currentID  =  0;  for  (int  j  =  0;  j  <  numDocs;  j++)  {  	cluster().wipeIndices( "test ");  
libgdx_190a3f2ec4e4f885f6db3e0cc69b078b66498a3d	buggy:  if  (config.keyboardHidden  ==  Configuration.HARDKEYBOARDHIDDEN_NO)  keyboardAvailable  =  true;  context:  public  void  postRunnable  (Runnable  runnable)  {  synchronized  (runnables)  {  runnables.add(runnable);  }  }  public  void  onConfigurationChanged  (Configuration  config)  {  super.onConfigurationChanged(config);  boolean  keyboardAvailable  =  false;  if  (config.keyboardHidden  ==  Configuration.HARDKEYBOARDHIDDEN_NO)  keyboardAvailable  =  true;  if  (config.hardKeyboardHidden  ==  Configuration.HARDKEYBOARDHIDDEN_NO)  keyboardAvailable  =  true;  input.keyboardAvailable  =  keyboardAvailable;  }  public  void  exit  ()  {  handler.post(new  Runnable()  {  public  void  run  ()  {  	if  (config.hardKeyboardHidden  ==  Configuration.HARDKEYBOARDHIDDEN_NO)  keyboardAvailable  =  true;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  context.cacheRecycler().longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector(entries.v());  }  public  InternalFacet  buildFacet(String  facetName)  {          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());          List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }  	List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  
elasticsearch_b5f3fc9ae1a68a9114acf1ef2bc9bc4d90ad1bea	buggy:  builder.startObject( "setting ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();  context:  builder.startObject( "metadata ");  builder.field( "maxNumberOfShardsPerNode ",  state.metaData().maxNumberOfShardsPerNode());  builder.startObject( "indices ");  for  (IndexMetaData  indexMetaData  :  state.metaData())  {  builder.startObject(indexMetaData.index());  builder.startObject( "settings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.settings().getAsMap().entrySet())  {                              builder.startObject( "setting ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();                              builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  builder.startObject( "mappings ");  for  (Map.Entry<String,  String>  entry  :  indexMetaData.mappings().entrySet())  {  builder.startObject( "mapping ").field( "name ",  entry.getKey()).field( "value ",  entry.getValue()).endObject();  }  builder.endObject();  	builder.field(entry.getKey(),  entry.getValue());  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.underlyingSource(),  request.underlyingSourceOffset(),  request.underlyingSourceLength()));  context:  protected  ShardsIterator  shards(ClusterState  clusterState,  PercolateRequest  request)  {  return  clusterState.routingTable().index(request.index()).randomAllActiveShardsIt();  }  protected  PercolateResponse  shardOperation(PercolateRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.underlyingSource(),  request.underlyingSourceOffset(),  request.underlyingSourceLength()));          PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  return  new  PercolateResponse(percolate.matches());  }  }  	PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.SourceRequest(request.type(),  request.source()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  final  CreateIndexListener  listener  =  new  CreateIndexListener(mdLock,  request,  userListener);  clusterService.submitStateUpdateTask( "create-index  [ "  +  request.index  +   "],  cause  [ "  +  request.cause  +   "] ",  Priority.URGENT,  new  ProcessedClusterStateUpdateTask()  {  public  ClusterState  execute(ClusterState  currentState)  {  boolean  indexCreated  =  false;  String  failureReason  =  null;  try  {  try  {  validate(request,  currentState);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  listener.onFailure(e);  return  currentState;  }  List<IndexTemplateMetaData>  templates  =  findTemplates(request,  currentState);  	}  catch  (Throwable  e)  {  
libgdx_8eb042c6b155e9f7ded1cf229d69f8b7f9bd67c3	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.FramebufferToTextureTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.FramebufferToTextureTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.SimpleAnimationTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.SimpleAnimationTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_836f93ec606186020ac2b03b1c0ddf27fc2a218f	buggy:  return  ReflectionCache.forName(superClass.getName());  context:  }  public  Class  getClassOfType  ()  {  return  clazz;  }  public  Type  getSuperclass  ()  {  try  {  return  ReflectionCache.forName(superClass.getName());  return  superClass  ==  null  ?  null  :  ReflectionCache.forName(superClass.getName());  }  catch  (ClassNotFoundException  e)  {  return  null;  }  }  public  boolean  isAssignableFrom  (Type  otherType)  {  	return  superClass  ==  null  ?  null  :  ReflectionCache.forName(superClass.getName());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicArray<BulkItemResponse>  responses  =  new  AtomicArray<BulkItemResponse>(bulkRequest.requests.size());  context:  executeBulk(bulkRequest,  startTime,  listener);  }  }  private  void  executeBulk(final  BulkRequest  bulkRequest,  final  long  startTime,  final  ActionListener<BulkResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();  clusterState.blocks().globalBlockedRaiseException(ClusterBlockLevel.WRITE);  MetaData  metaData  =  clusterState.metaData();          final  AtomicArray<BulkItemResponse>  responses  =  new  AtomicArray<BulkItemResponse>(bulkRequest.requests.size());          final  AtomicArray<BulkItemResponse>  responses  =  new  AtomicArray<>(bulkRequest.requests.size());  for  (int  i  =  0;  i  <  bulkRequest.requests.size();  i++)  {  ActionRequest  request  =  bulkRequest.requests.get(i);  if  (request  instanceof  IndexRequest)  {  IndexRequest  indexRequest  =  (IndexRequest)  request;  String  aliasOrIndex  =  indexRequest.index();  indexRequest.index(clusterState.metaData().concreteIndex(indexRequest.index()));  	final  AtomicArray<BulkItemResponse>  responses  =  new  AtomicArray<>(bulkRequest.requests.size());  
elasticsearch_78e39882ee0176946c0da0f6b05a343af6ffc5da	buggy:  ConcurrentMergeSchedulerProvider  mergeSchedulerProvider  =  new  ConcurrentMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool);  context:  assertThat(segments.get(2).isCommitted(),  equalTo(false));  assertThat(segments.get(2).isSearch(),  equalTo(true));  assertThat(segments.get(2).getNumDocs(),  equalTo(1));  assertThat(segments.get(2).getDeletedDocs(),  equalTo(0));  assertThat(segments.get(2).isCompound(),  equalTo(true));  }  public  void  testSegmentsWithMergeFlag()  throws  Exception  {          ConcurrentMergeSchedulerProvider  mergeSchedulerProvider  =  new  ConcurrentMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool);          ConcurrentMergeSchedulerProvider  mergeSchedulerProvider  =  new  ConcurrentMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS));  final  AtomicReference<CountDownLatch>  waitTillMerge  =  new  AtomicReference<>();  final  AtomicReference<CountDownLatch>  waitForMerge  =  new  AtomicReference<>();  mergeSchedulerProvider.addListener(new  MergeSchedulerProvider.Listener()  {  public  void  beforeMerge(OnGoingMerge  merge)  {  try  {  if  (waitTillMerge.get()  !=  null)  {  waitTillMerge.get().countDown();  	ConcurrentMergeSchedulerProvider  mergeSchedulerProvider  =  new  ConcurrentMergeSchedulerProvider(shardId,  EMPTY_SETTINGS,  threadPool,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS));  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);  context:  return  new  GetAliasesRequest();  }  protected  AliasesExistResponse  newResponse()  {  return  new  AliasesExistResponse();  }  protected  void  masterOperation(GetAliasesRequest  request,  ClusterState  state,  ActionListener<AliasesExistResponse>  listener)  throws  ElasticSearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  request.indices(concreteIndices);  boolean  result  =  state.metaData().hasAliases(request.aliases(),  request.indices());  listener.onResponse(new  AliasesExistResponse(result));  }  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthResponse  clusterHealth  =  node.client().admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();  context:  }  node.close();  }  node.client().admin().indices().create(createIndexRequest( "test ").settings(settingsBuilder().put( "index.numberOfReplicas ",  0))).actionGet();          ClusterHealthResponse  clusterHealth  =  node.client().admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();          ClusterHealthResponse  clusterHealth  =  node.client().admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  }  node.client().admin().indices().delete(deleteIndexRequest( "test ")).actionGet();  	ClusterHealthResponse  clusterHealth  =  node.client().admin().cluster().health(clusterHealthRequest().waitForGreenStatus()).actionGet();  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal),  true);  context:  float  touchStartX  =  0;  float  touchStartY  =  0;  long  frameStart;  int  frames  =  0;  if  (mesh  ==  null)  {  Gdx.input.addInputListener(this);  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal),  true);  mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  texture  =  Gdx.graphics.newTexture(Gdx.files.getFileHandle( "data/badlogic.jpg ",  FileType.Internal),  TextureFilter.MipMap,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  cam  =  new  PerspectiveCamera();  cam.getPosition().set(2,  2,  2);  cam.getDirection().set(-1,  -1,  -1);  }  frameStart  =  System.nanoTime();  	mesh  =  ModelLoader.loadObj(Gdx.files.readFile( "data/cube.obj ",  FileType.Internal));  
elasticsearch_9f427010bf4a44f78e48c551189d89e29681b6ee	buggy:  queueSize  <=  0  ?  new  LinkedTransferQueue<Runnable>()  :  new  LinkedBlockingQueue<Runnable>(queueSize),  context:  if  ( "abort ".equals(rejectSetting))  {  rejectedExecutionHandler  =  new  ThreadPoolExecutor.AbortPolicy();  }  else  if  ( "caller ".equals(rejectSetting))  {  rejectedExecutionHandler  =  new  ThreadPoolExecutor.CallerRunsPolicy();  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "reject_policy  [ "  +  rejectSetting  +   "]  not  valid  for  [ "  +  name  +   "]  thread  pool ");  }  return  new  ThreadPoolExecutor(size,  size,  0L,  TimeUnit.MILLISECONDS,                      queueSize  <=  0  ?  new  LinkedTransferQueue<Runnable>()  :  new  LinkedBlockingQueue<Runnable>(queueSize),                      queueSize  <=  0  ?  new  LinkedTransferQueue<Runnable>()  :  new  ArrayBlockingQueue<Runnable>(queueSize),  threadFactory,  rejectedExecutionHandler);  }  else  if  ( "scaling ".equals(type))  {  TimeValue  keepAlive  =  settings.getAsTime( "keep_alive ",  defaultSettings.getAsTime( "keep_alive ",  timeValueMinutes(5)));  int  min  =  settings.getAsInt( "min ",  defaultSettings.getAsInt( "min ",  1));  int  size  =  settings.getAsInt( "size ",  defaultSettings.getAsInt( "size ",  Runtime.getRuntime().availableProcessors()  *  5));  return  DynamicExecutors.newScalingThreadPool(min,  size,  keepAlive.millis(),  threadFactory);  }  else  if  ( "blocking ".equals(type))  {  	queueSize  <=  0  ?  new  LinkedTransferQueue<Runnable>()  :  new  ArrayBlockingQueue<Runnable>(queueSize),  
libgdx_d89f94f322c4e4c9cef68dc524c6b7c1cf956848	buggy:  listener.dispose(  app  );  context:  public  void  setRenderListener(RenderListener  listener)  {  synchronized(  this  )  {  if(  this.listener  !=  null  )  listener.dispose(  app  );  this.listener.dispose(  app  );  this.listener  =  listener;  }  }  public  void  onDrawFrame(javax.microedition.khronos.opengles.GL10  gl)  {  	this.listener.dispose(  app  );  
elasticsearch_37f08ea8b876c08a7ed3f3cb295678edc412643c	buggy:  tokenFiltersBindings.processTokenFilter( "hypennation_decompounder ",  HyphenationCompoundWordTokenFilterFactory.class);  context:  tokenFiltersBindings.processTokenFilter( "snowball ",  SnowballTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "stemmer ",  StemmerTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "word_delimiter ",  WordDelimiterTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "synonym ",  SynonymTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "elision ",  ElisionTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "pattern_replace ",  PatternReplaceTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "phonetic ",  PhoneticTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "dictionary_decompounder ",  DictionaryCompoundWordTokenFilterFactory.class);              tokenFiltersBindings.processTokenFilter( "hypennation_decompounder ",  HyphenationCompoundWordTokenFilterFactory.class);              tokenFiltersBindings.processTokenFilter( "hyphenation_decompounder ",  HyphenationCompoundWordTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "arabic_stem ",  ArabicStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "brazilian_stem ",  BrazilianStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "czech_stem ",  CzechStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "dutch_stem ",  DutchStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "french_stem ",  FrenchStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "german_stem ",  GermanStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "russian_stem ",  RussianStemTokenFilterFactory.class);  	tokenFiltersBindings.processTokenFilter( "hyphenation_decompounder ",  HyphenationCompoundWordTokenFilterFactory.class);  
elasticsearch_27481800bc6fe4fea9ca13896e30ed650d621a29	buggy:  query  =  smartNameFieldMappers.mapper().fuzzyQuery(value,  minSimilarity,  prefixLength,  maxExpansions);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  value  specified  for  fuzzy  query ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().fuzzyQuery(value,  minSimilarity,  prefixLength,  maxExpansions);                  query  =  smartNameFieldMappers.mapper().fuzzyQuery(value,  minSimilarity,  prefixLength,  maxExpansions,  transpositions);  }  }  if  (query  ==  null)  {  int  edits  =  FuzzyQuery.floatToEdits(Float.parseFloat(minSimilarity),  value.codePointCount(0,  value.length()));  query  =  new  FuzzyQuery(new  Term(fieldName,  value),  edits,  prefixLength,  maxExpansions,  transpositions);  }  	query  =  smartNameFieldMappers.mapper().fuzzyQuery(value,  minSimilarity,  prefixLength,  maxExpansions,  transpositions);  
libgdx_00bc8c303c1f7c1bb905a0bba4e9aa90d0bfef91	buggy:  public  void  click  (Actor  button)  {  context:  table.width  =  ui.width();  table.height  =  ui.height();  table.top().padTop(15);  table.add(reload).spaceRight(5);  table.add(camera).spaceRight(5);  table.add(fps);  ui.addActor(table);  reload.setClickListener(new  ClickListener()  {  public  void  click  (Actor  button)  {  public  void  click  (Actor  button,  float  x,  float  y)  {  ShaderProgram  prog  =  new  ShaderProgram(Gdx.files.internal( "data/shaders/projtex-vert.glsl ").readString(),  Gdx.files  .internal( "data/shaders/projtex-frag.glsl ").readString());  if  (prog.isCompiled()  ==  false)  {  Gdx.app.log( "GLSL  ERROR ",   "Couldn't  reload  shaders:\n "  +  prog.getLog());  }  else  {  projTexShader.dispose();  projTexShader  =  prog;  }  	public  void  click  (Actor  button,  float  x,  float  y)  {  
elasticsearch_36c3e896de86ced11a239e9b0ce66a896d472a8a	buggy:  nodesFD.start(clusterState);  context:  public  void  testNodesFaultDetectionConnectOnDisconnect()  throws  InterruptedException  {  ImmutableSettings.Builder  settings  =  ImmutableSettings.builder();  boolean  shouldRetry  =  randomBoolean();  settings.put(FaultDetection.SETTING_CONNECT_ON_NETWORK_DISCONNECT,  shouldRetry)  .put(FaultDetection.SETTING_PING_INTERVAL,   "5m ");  ClusterState  clusterState  =  ClusterState.builder(new  ClusterName( "test ")).nodes(buildNodesForA(true)).build();  NodesFaultDetection  nodesFD  =  new  NodesFaultDetection(settings.build(),  threadPool,  serviceA,  clusterState.getClusterName());  nodesFD.setLocalNode(clusterState.nodes().localNode());          nodesFD.start(clusterState);          nodesFD.updateNodesAndPing(clusterState);  final  String[]  failureReason  =  new  String[1];  final  DiscoveryNode[]  failureNode  =  new  DiscoveryNode[1];  final  CountDownLatch  notified  =  new  CountDownLatch(1);  nodesFD.addListener(new  NodesFaultDetection.Listener()  {  public  void  onNodeFailure(DiscoveryNode  node,  String  reason)  {  failureNode[0]  =  node;  failureReason[0]  =  reason;  	nodesFD.updateNodesAndPing(clusterState);  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  Engine.Searcher  searcher  =  shardToPurge.searcher();  context:  }  }  }  return  shardsToPurge;  }  }  private  void  purgeShards(List<IndexShard>  shardsToPurge)  {  for  (IndexShard  shardToPurge  :  shardsToPurge)  {  Query  query  =  NumericRangeQuery.newLongRange(TTLFieldMapper.NAME,  null,  System.currentTimeMillis(),  false,  true);              Engine.Searcher  searcher  =  shardToPurge.searcher();              Engine.Searcher  searcher  =  shardToPurge.acquireSearcher();  try  {  ExpiredDocsCollector  expiredDocsCollector  =  new  ExpiredDocsCollector(shardToPurge.routingEntry().index());  searcher.searcher().search(query,  expiredDocsCollector);  List<DocToPurge>  docsToPurge  =  expiredDocsCollector.getDocsToPurge();  BulkRequestBuilder  bulkRequest  =  client.prepareBulk();  for  (DocToPurge  docToPurge  :  docsToPurge)  {  bulkRequest.add(new  DeleteRequest().index(shardToPurge.routingEntry().index()).type(docToPurge.type).id(docToPurge.id).version(docToPurge.version).routing(docToPurge.routing));  	Engine.Searcher  searcher  =  shardToPurge.acquireSearcher();  
elasticsearch_3770924300a0c22f1db4d31e29bab702216edd79	buggy:  byte[]  buffer  =  new  byte[1024  *  16];  context:  return  builder.build();  }  public  boolean  deleteBlob(String  blobName)  throws  IOException  {  return  blobStore.fileSystem().delete(new  Path(path,  blobName),  true);  }  blobStore.executorService().execute(new  Runnable()  {                  byte[]  buffer  =  new  byte[1024  *  16];                  byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  FSDataInputStream  fileStream;  try  {  fileStream  =  blobStore.fileSystem().open(new  Path(path,  blobName));  }  catch  (IOException  e)  {  listener.onFailure(e);  return;  	byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  
libgdx_22deb2e572586fd56b080714cd706501de3403b4	buggy:  public  void  destroy()  {  context:  public  void  render()  {  }  public  void  pause()  {  }  public  void  destroy()  {  public  void  dispose()  {  }  public  void  create()  {  }  	public  void  dispose()  {  
elasticsearch_a0e9532dcaa79ad931c8dc18cb6dec2f00b19400	buggy:  return  ImmutableSettings.settingsBuilder().put( "threadpool.search.type ",   "cached ").put(super.nodeSettings(nodeOrdinal)).build();  context:  public  class  SimpleThreadPoolTests  extends  ElasticsearchIntegrationTest  {  protected  Settings  nodeSettings(int  nodeOrdinal)  {          return  ImmutableSettings.settingsBuilder().put( "threadpool.search.type ",   "cached ").put(super.nodeSettings(nodeOrdinal)).build();          return  ImmutableSettings.settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "threadpool.search.type ",   "cached ").build();  }  public  void  verifyThreadNames()  throws  Exception  {  ThreadMXBean  threadBean  =  ManagementFactory.getThreadMXBean();  Set<String>  preNodeStartThreadNames  =  Sets.newHashSet();  for  (long  l  :  threadBean.getAllThreadIds())  {  	return  ImmutableSettings.settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put( "threadpool.search.type ",   "cached ").build();  
libgdx_abda11305bc00c182bdce9de323e57b6cf900b43	buggy:  while  ((c  =  reader.read())  !=  -1  &&  process.isAlive())  {  context:  private  static  boolean  startProcess  (String  command,  File  directory,  final  CharCallback  callback)  {  try  {  final  Process  process  =  new  ProcessBuilder(command.split( "   ")).redirectErrorStream(true).directory(directory).start();  Thread  t  =  new  Thread(new  Runnable()  {  public  void  run  ()  {  BufferedReader  reader  =  new  BufferedReader(new  InputStreamReader(process.getInputStream()),  1);  try  {  int  c  =  0;  while  ((c  =  reader.read())  !=  -1  &&  process.isAlive())  {  while  ((c  =  reader.read())  !=  -1)  {  callback.character((char)c);  }  }  catch  (IOException  e)  {  }  }  });  t.setDaemon(true);  	while  ((c  =  reader.read())  !=  -1)  {  
elasticsearch_1461da5b494d1f5b9a0f5a2c285ea93293f2184d	buggy:  sb.append( "              :  recovered_files  [ ").append(recoveryStatus.index().numberOfRecoveredFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().reusedTotalSize())).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");  context:  indexShard.refresh(new  Engine.Refresh(false));  recoveryStatus.time(System.currentTimeMillis()  -  recoveryStatus.startTime());  recoveryStatus.updateStage(RecoveryStatus.Stage.DONE);  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  sb.append( "recovery  completed  from   ").append(shardGateway).append( ",  took  [ ").append(timeValueMillis(recoveryStatus.time())).append( "]\n ");  sb.append( "    index    :  files            [ ").append(recoveryStatus.index().numberOfFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().totalSize())).append( "],  took[ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");                          sb.append( "              :  recovered_files  [ ").append(recoveryStatus.index().numberOfRecoveredFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().reusedTotalSize())).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.index().time())).append( "]\n ");                          sb.append( "              :  recovered_files  [ ").append(recoveryStatus.index().numberOfRecoveredFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().recoveredTotalSize())).append( "]\n ");  sb.append( "              :  reusing_files    [ ").append(recoveryStatus.index().numberOfReusedFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().reusedTotalSize())).append( "]\n ");  sb.append( "    translog  :  number_of_operations  [ ").append(recoveryStatus.translog().currentTranslogOperations()).append( "],  took  [ ").append(TimeValue.timeValueMillis(recoveryStatus.translog().time())).append( "] ");  }  listener.onRecoveryDone();  scheduleSnapshotIfNeeded();  }  catch  (IndexShardGatewayRecoveryException  e)  {  if  (indexShard.state()  ==  IndexShardState.CLOSED)  {  	sb.append( "                          :  recovered_files  [ ").append(recoveryStatus.index().numberOfRecoveredFiles()).append( "]  with  total_size  [ ").append(new  ByteSizeValue(recoveryStatus.index().recoveredTotalSize())).append( "]\n ");  
libgdx_e4a9393a9957e7f6e114ec3aba69fd849e2e1dd5	buggy:  super.setV(u);  context:  vertices[V4]  =  v2;  }  public  void  setU  (float  u)  {  super.setU(u);  vertices[U1]  =  u;  vertices[U2]  =  u;  }  public  void  setV  (float  v)  {  super.setV(u);  super.setV(v);  vertices[V2]  =  v;  vertices[V3]  =  v;  }  public  void  setU2  (float  u2)  {  super.setU2(u2);  vertices[U3]  =  u2;  vertices[U4]  =  u2;  	super.setV(v);  
libgdx_5823a5cf9807eac212b50d5e8c2313e987536455	buggy:  audio  =  new  OpenALAudio();  context:  }  }  else  {  initialize(listener,  config);  }  }  void  initialize  (ApplicationListener  listener,  JoglApplicationConfiguration  config)  {  JoglNativesLoader.load();  graphics  =  new  JoglGraphics(listener,  config);  input  =  new  JoglInput(graphics.getCanvas());  audio  =  new  OpenALAudio();  audio  =  new  OpenALAudio(config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  files  =  new  JoglFiles();  Gdx.app  =  JoglApplication.this;  Gdx.graphics  =  JoglApplication.this.getGraphics();  Gdx.input  =  JoglApplication.this.getInput();  Gdx.audio  =  JoglApplication.this.getAudio();  Gdx.files  =  JoglApplication.this.getFiles();  	audio  =  new  OpenALAudio(config.audioDeviceBufferCount,  config.audioDeviceBufferSize);  
elasticsearch_121e548d7624406737dddaf68b1c74f8ab644d6b	buggy:  if  (!state.nodes().localNodeMaster())  {  context:  }  else  {  }  }  });  }  private  class  UpdateClusterStateListener  implements  PublishIndexerClusterStateAction.NewClusterStateListener  {  ClusterState  state  =  clusterService.state();              if  (!state.nodes().localNodeMaster())  {              if  (state.nodes().localNodeMaster())  {  return;  }  submitStateUpdateTask( "received_state ",  new  IndexerClusterStateUpdateTask()  {  return  clusterState;  }  	if  (state.nodes().localNodeMaster())  {  
elasticsearch_1e937fd5d1ee6265782c311593a8711b0e537003	buggy:  builder.field( "index ",  fieldType.indexed());  context:  public  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {  if  (fieldType.stored()  ==  Defaults.FIELD_TYPE.stored()  &&  fieldType.indexed()  ==  Defaults.FIELD_TYPE.indexed())  {  return  builder;  }  builder.startObject(CONTENT_TYPE);  if  (fieldType.stored()  !=  Defaults.FIELD_TYPE.stored())  {  builder.field( "store ",  fieldType.stored());  }  if  (fieldType.indexed()  !=  Defaults.FIELD_TYPE.indexed())  {              builder.field( "index ",  fieldType.indexed());              builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  }  builder.endObject();  return  builder;  }  public  void  merge(Mapper  mergeWith,  MergeContext  mergeContext)  throws  MergeMappingException  {  	builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.admin().indices().aliases(indicesAliasesRequest,  new  ActionListener<IndicesAliasesResponse>()  {  public  void  onResponse(IndicesAliasesResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.isAcknowledged())  .endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_25bd9cecd066e7920776eef0885b1c4a905a3156	buggy:  suggestBuilder  =  new  SuggestBuilder();  context:  public  SearchSourceBuilder  highlight(HighlightBuilder  highlightBuilder)  {  this.highlightBuilder  =  highlightBuilder;  return  this;  }  public  SuggestBuilder  suggest()  {  if  (suggestBuilder  ==  null)  {              suggestBuilder  =  new  SuggestBuilder();              suggestBuilder  =  new  SuggestBuilder( "suggest ");  }  return  suggestBuilder;  }  public  RescoreBuilder  rescore()  {  if  (rescoreBuilder  ==  null)  {  rescoreBuilder  =  new  RescoreBuilder();  }  	suggestBuilder  =  new  SuggestBuilder( "suggest ");  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  controller.registerHandler(GET,   "/{index}/_flush ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  FlushRequest  flushRequest  =  new  FlushRequest(RestActions.splitIndices(request.param( "index ")));  flushRequest.listenerThreaded(false);  if  (request.hasParam( "ignore_indices "))  {  flushRequest.ignoreIndices(IgnoreIndices.fromString(request.param( "ignore_indices ")));  }          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);          BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  flushRequest.operationThreading(operationThreading);  flushRequest.refresh(request.paramAsBoolean( "refresh ",  flushRequest.refresh()));  flushRequest.full(request.paramAsBoolean( "full ",  flushRequest.full()));  flushRequest.force(request.paramAsBoolean( "force ",  flushRequest.force()));  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_e33dbcd93e3b1d0beac7e1629a790a28e5cab749	buggy:  return  termFactory.createTerm(uid);  context:  return  value;  }  public  Term  term(String  type,  String  id)  {  return  term(Uid.createUid(type,  id));  }  public  Term  term(String  uid)  {          return  termFactory.createTerm(uid);          return  names().createIndexNameTerm(uid);  }  fieldCache.remove();  }  return  CONTENT_TYPE;  	return  names().createIndexNameTerm(uid);  
elasticsearch_673655cc7b7ab115257f75e64be4c9d918fc9144	buggy:  MapperService.SmartNameObjectMapper  mapper  =  context.mapperService().smartNameObjectMapper(nestedPath);  context:  }  if  (filter  !=  null)  {  if  (cacheFilter)  {  filter  =  context.filterCache().cache(filter);  }  facet.setFilter(filter);  }  if  (nestedPath  !=  null)  {                      MapperService.SmartNameObjectMapper  mapper  =  context.mapperService().smartNameObjectMapper(nestedPath);                      MapperService.SmartNameObjectMapper  mapper  =  context.smartNameObjectMapper(nestedPath);  if  (mapper  ==  null)  {  throw  new  SearchParseException(context,   "facet  nested  path  [ "  +  nestedPath  +   "]  not  found ");  }  ObjectMapper  objectMapper  =  mapper.mapper();  if  (objectMapper  ==  null)  {  throw  new  SearchParseException(context,   "facet  nested  path  [ "  +  nestedPath  +   "]  not  found ");  }  if  (!objectMapper.nested().isNested())  {  	MapperService.SmartNameObjectMapper  mapper  =  context.smartNameObjectMapper(nestedPath);  
libgdx_69a8d3f7e32e9d92101347e22d589198349ca373	buggy:  return  $(x,  y,  duration);  context:  target.y  =  startY  +  deltaY  *  alpha;  }  }  super.finish();  pool.free(this);  }  return  $(x,  y,  duration);  return  $(deltaX,  deltaY,  duration);  }  }  	return  $(deltaX,  deltaY,  duration);  
elasticsearch_66825ac851a2578686eefca08f1900bf86f3d443	buggy:  addDocValue(context,  value);  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              addDocValue(context,  value);              addDocValue(context,  fields,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  fields,  value);  
libgdx_66d46be69bf4f3f6b2da5ac1677bf255eb852a39	buggy:  btAxisSweep3  broadphase  =  new  btAxisSweep3(Vector3.tmp.set(-1000,  -1000,  -1000),  Vector3.tmp2.set(1000,  1000,  1000),  1024);  context:  BulletEntity  entity;  ShortBuffer  indexMap;  Vector3  tmpV  =  new  Vector3();  int  positionOffset;  int  normalOffset;  public  BulletWorld  createWorld  ()  {  btDefaultCollisionConfiguration  collisionConfiguration  =  new  btSoftBodyRigidBodyCollisionConfiguration();  btCollisionDispatcher  dispatcher  =  new  btCollisionDispatcher(collisionConfiguration);  btAxisSweep3  broadphase  =  new  btAxisSweep3(Vector3.tmp.set(-1000,  -1000,  -1000),  Vector3.tmp2.set(1000,  1000,  1000),  1024);  btAxisSweep3  broadphase  =  new  btAxisSweep3(tmpV1.set(-1000,  -1000,  -1000),  tmpV2.set(1000,  1000,  1000),  1024);  btSequentialImpulseConstraintSolver  solver  =  new  btSequentialImpulseConstraintSolver();  btSoftRigidDynamicsWorld  dynamicsWorld  =  new  btSoftRigidDynamicsWorld(dispatcher,  broadphase,  solver,  collisionConfiguration);  worldInfo  =  new  btSoftBodyWorldInfo();  worldInfo.setBroadphase(broadphase);  worldInfo.setDispatcher(dispatcher);  worldInfo.getSparsesdf().Initialize();  	btAxisSweep3  broadphase  =  new  btAxisSweep3(tmpV1.set(-1000,  -1000,  -1000),  tmpV2.set(1000,  1000,  1000),  1024);  
elasticsearch_7aac88cf5c6f644858460dccdd4386c630b1596c	buggy:  return  liveDocs.get(doc);  context:  private  final  Bits  liveDocs;  NotDeletedDocIdSetIterator(DocIdSetIterator  innerIter,  Bits  liveDocs)  {  super(innerIter);  this.liveDocs  =  liveDocs;  }  protected  boolean  match(int  doc)  {              return  liveDocs.get(doc);              return  liveDocs  ==  null  ||  liveDocs.get(doc);  }  }  }  	return  liveDocs  ==  null  ||  liveDocs.get(doc);  
elasticsearch_76d042f3c5c4c4fcce91a09e1d10204ff7dace36	buggy:  throw  new  UnknownHostException( "network  interface   "  +  intf  +   "  not  found ");  context:  InetAddress  address  =  (InetAddress)  addresses.nextElement();  if  ((address  instanceof  Inet4Address  &&  (ipVersion  ==  StackType.IPv4))  ||  (address  instanceof  Inet6Address  &&  (ipVersion  ==  StackType.IPv6)))  {  supportsVersion  =  true;  break;  }  }  }  else  {              throw  new  UnknownHostException( "network  interface   "  +  intf  +   "  not  found ");              throw  new  UnknownHostException( "network  interface  not  found ");  }  return  supportsVersion;  }  	throw  new  UnknownHostException( "network  interface  not  found ");  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean  []  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }          entries.release();          entries.close();  return  new  InternalFullHistogramFacet(facetName,  comparatorType,  entries1);  }  class  Collector  extends  FacetExecutor.Collector  {  private  final  HistogramProc  histoProc;  private  DoubleValues  keyValues;  	entries.close();  
elasticsearch_7f5befd95e19badf8b911df5c28a08613b0a9cd0	buggy:  assertThat(client().admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test-snap-2 ").execute().actionGet().getSnapshots().get(0).state(),  equalTo(SnapshotState.SUCCESS));  context:  CreateSnapshotResponse  createSnapshotResponse  =  client().admin().cluster().prepareCreateSnapshot( "test-repo ",   "test-snap-1 ").setWaitForCompletion(true).execute().actionGet();  assertThat(createSnapshotResponse.getSnapshotInfo().state(),  equalTo(SnapshotState.FAILED));  createSnapshotResponse  =  client().admin().cluster().prepareCreateSnapshot( "test-repo ",   "test-snap-2 ").setWaitForCompletion(true).setPartial(true).execute().actionGet();  assertThat(createSnapshotResponse.getSnapshotInfo().totalShards(),  equalTo(12));  assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(),  lessThan(12));  assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(),  greaterThan(6));          assertThat(client().admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test-snap-2 ").execute().actionGet().getSnapshots().get(0).state(),  equalTo(SnapshotState.SUCCESS));          assertThat(client().admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test-snap-2 ").execute().actionGet().getSnapshots().get(0).state(),  equalTo(SnapshotState.PARTIAL));  assertAcked(client().admin().indices().prepareClose( "test-idx-1 ",   "test-idx-2 ").execute().actionGet());  assertThrows(client().admin().cluster().prepareRestoreSnapshot( "test-repo ",   "test-snap-2 ").setRestoreGlobalState(false).setWaitForCompletion(true).execute(),  SnapshotRestoreException.class);  RestoreSnapshotResponse  restoreSnapshotResponse  =  client().admin().cluster().prepareRestoreSnapshot( "test-repo ",   "test-snap-2 ").setRestoreGlobalState(false).setIndices( "test-idx-2 ").setWaitForCompletion(true).execute().actionGet();  	assertThat(client().admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test-snap-2 ").execute().actionGet().getSnapshots().get(0).state(),  equalTo(SnapshotState.PARTIAL));  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  request.waitForOperations(waitForOperations);  context:  public  class  RefreshRequestBuilder  extends  BroadcastOperationRequestBuilder<RefreshRequest,  RefreshResponse,  RefreshRequestBuilder>  {  public  RefreshRequestBuilder(IndicesAdminClient  indicesClient)  {  super((InternalIndicesAdminClient)  indicesClient,  new  RefreshRequest());  }  public  RefreshRequestBuilder  setWaitForOperations(boolean  waitForOperations)  {          request.waitForOperations(waitForOperations);          request.setWaitForOperations(waitForOperations);  return  this;  }  protected  void  doExecute(ActionListener<RefreshResponse>  listener)  {  ((IndicesAdminClient)  client).refresh(request,  listener);  }  }  	request.setWaitForOperations(waitForOperations);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  restTestExecutionContext.resetClient(immutableCluster().httpAddresses());  context:  public  void  reset()  throws  IOException,  RestException  {  for  (PathMatcher  blacklistedPathMatcher  :  blacklistPathMatchers)  {  String  testSection  =  testCandidate.getTestSection().getName().replace( "* ",   " ").replace( "\\ ",   "/ ").replaceAll( "\\s+/ ",   "/ ").trim();  String  testPath  =  testCandidate.getSuitePath()  +   "/ "  +  testSection;  assumeFalse( "[ "  +  testCandidate.getTestPath()  +   "]  skipped,  reason:  blacklisted ",  blacklistedPathMatcher.matches(Paths.get(testPath)));  }          restTestExecutionContext.resetClient(immutableCluster().httpAddresses());          restTestExecutionContext.resetClient(cluster().httpAddresses());  restTestExecutionContext.clear();  assumeFalse(buildSkipMessage(testCandidate.getSuitePath(),  testCandidate.getSetupSection().getSkipSection()),  testCandidate.getSetupSection().getSkipSection().skip(restTestExecutionContext.esVersion()));  assumeFalse(buildSkipMessage(testCandidate.getTestPath(),  testCandidate.getTestSection().getSkipSection()),  testCandidate.getTestSection().getSkipSection().skip(restTestExecutionContext.esVersion()));  	restTestExecutionContext.resetClient(cluster().httpAddresses());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<String>  list  =  new  ArrayList<String>();  context:  set1  =  null;  set2  =  null;  try  {  toList(HppcMaps.intersection(set1,  set2));  fail();  }  catch  (AssertionError  e)  {}  }  private  List<String>  toList(Iterable<String>  iterable)  {          List<String>  list  =  new  ArrayList<String>();          List<String>  list  =  new  ArrayList<>();  for  (String  s  :  iterable)  {  list.add(s);  }  return  list;  }  }  	List<String>  list  =  new  ArrayList<>();  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().numNodes()+2).put( "index.number_of_replicas ",  0)).execute().actionGet();  context:  public  class  SearchPreferenceTests  extends  ElasticsearchIntegrationTest  {  public  void  testStopOneNodePreferenceWithRedState()  throws  InterruptedException  {          client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().numNodes()+2).put( "index.number_of_replicas ",  0)).execute().actionGet();          client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().size()+2).put( "index.number_of_replicas ",  0)).execute().actionGet();  client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();  for  (int  i  =  0;  i  <  10;  i++)  {  client().prepareIndex( "test ",   "type1 ",   " "+i).setSource( "field1 ",   "value1 ").execute().actionGet();  }  client().admin().indices().prepareRefresh().execute().actionGet();  cluster().stopRandomNode();  client().admin().cluster().prepareHealth().setWaitForStatus(ClusterHealthStatus.RED).execute().actionGet();  String[]  preferences  =  new  String[]  { "_primary ",   "_local ",   "_primary_first ",   "_only_local ",   "_prefer_node:somenode ",   "_prefer_node:server2 "};  	client().admin().indices().prepareCreate( "test ").setSettings(settingsBuilder().put( "index.number_of_shards ",  cluster().size()+2).put( "index.number_of_replicas ",  0)).execute().actionGet();  
elasticsearch_8f88d0aa4a7ec5b9379d7a1c5a532de3865c1bb1	buggy:  multiSearchRequest.add(request.content(),  request.contentUnsafe(),  indices,  types,  request.param( "search_type "),  ignoreIndices,  allowExplicitIndex);  context:  multiSearchRequest.listenerThreaded(false);  String[]  indices  =  Strings.splitStringByCommaToArray(request.param( "index "));  String[]  types  =  Strings.splitStringByCommaToArray(request.param( "type "));  IgnoreIndices  ignoreIndices  =  null;  if  (request.hasParam( "ignore_indices "))  {  ignoreIndices  =  IgnoreIndices.fromString(request.param( "ignore_indices "));  }  try  {              multiSearchRequest.add(request.content(),  request.contentUnsafe(),  indices,  types,  request.param( "search_type "),  ignoreIndices,  allowExplicitIndex);              multiSearchRequest.add(request.content(),  request.contentUnsafe(),  indices,  types,  request.param( "search_type "),  request.param( "routing "),  ignoreIndices,  allowExplicitIndex);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  channel.sendResponse(new  XContentRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  	multiSearchRequest.add(request.content(),  request.contentUnsafe(),  indices,  types,  request.param( "search_type "),  request.param( "routing "),  ignoreIndices,  allowExplicitIndex);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  ClusterState  state  =  node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  context:  TimeValue  timeout  =  TimeValue.timeValueMillis(200);  Node  node  =  startNode( "node1 ",  settings);  Node  node2  =  startNode( "node2 ",  settings);  node.client().admin().indices().prepareCreate( "test ").execute().actionGet();  node2.close();  Thread.sleep(200);          ClusterState  state  =  node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().state();          ClusterState  state  =  node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(true));  try  {  node.client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet();  assert  false;  }  catch  (ClusterBlockException  e)  {  assertThat(e.status(),  equalTo(RestStatus.SERVICE_UNAVAILABLE));  }  	ClusterState  state  =  node.client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();  
libgdx_c7e59359c7838a8ef6d2e724125b59a8668fb144	buggy:  setRotation(dir,  Vector3.Y);  context:  final  static  Vector3  dir  =  new  Vector3();  public  void  lookAt(Vector3  position,  Vector3  up)  {  dir.set(position).sub(this.position).nor();  setRotation(dir,  Vector3.Y);  setRotation(dir,  up);  }  public  static  final  int  X1  =  0;  public  static  final  int  Y1  =  1;  public  static  final  int  Z1  =  2;  public  static  final  int  C1  =  3;  public  static  final  int  U1  =  4;  	setRotation(dir,  up);  
libgdx_586c8eda959300c12504bda3c404b117dace13bd	buggy:  defaultFramebufferHandle  =  intbuf.get();  context:  if  (!Gdx.graphics.isGL20Available())  throw  new  GdxRuntimeException( "GL2  is  required. ");  GL20  gl  =  Gdx.graphics.getGL20();  if  (!defaultFramebufferHandleInitialized)  {  defaultFramebufferHandleInitialized  =  true;  if  (Gdx.app.getType()  ==  ApplicationType.iOS)  {  IntBuffer  intbuf  =  ByteBuffer.allocateDirect(16  *  Integer.SIZE  /  8).order(ByteOrder.nativeOrder()).asIntBuffer();  gl.glGetIntegerv(GL20.GL_FRAMEBUFFER_BINDING,  intbuf);      defaultFramebufferHandle  =  intbuf.get();      defaultFramebufferHandle  =  intbuf.get(0);  }  else  {  defaultFramebufferHandle  =  0;  }  }  setupTexture();  	defaultFramebufferHandle  =  intbuf.get(0);  
elasticsearch_4ab298ce00b53243831ed1e178f13535ac2926d3	buggy:  query  =  smartNameFieldMappers.mapper().fieldQuery(value);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().fieldQuery(value);                  query  =  smartNameFieldMappers.mapper().termQuery(value);  }  }  if  (query  ==  null)  {  query  =  new  TermQuery(new  Term(fieldName,  value));  }  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.indexCache());  }  	query  =  smartNameFieldMappers.mapper().termQuery(value);  
elasticsearch_8ee038574def7f43f5e8501dba57a9c23c82f7f8	buggy:  docMapper.parse(request.type(),  request.id(),  getResponse.source(),  new  DocumentMapper.ParseListenerAdapter()  {  context:  listener.onFailure(e);  }  });  }  private  void  parseSource(GetResponse  getResponse,  final  BoolQueryBuilder  boolBuilder,  DocumentMapper  docMapper,  final  Set<String>  fields,  final  MoreLikeThisRequest  request)  {  if  (getResponse.source()  ==  null)  {  return;  }          docMapper.parse(request.type(),  request.id(),  getResponse.source(),  new  DocumentMapper.ParseListenerAdapter()  {          docMapper.parse(SourceToParse.source(getResponse.source()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  if  (fieldMapper  instanceof  InternalMapper)  {  return  true;  }  String  value  =  fieldMapper.valueAsString(field);  if  (value  ==  null)  {  return  false;  }  	docMapper.parse(SourceToParse.source(getResponse.source()).type(request.type()).id(request.id()),  new  DocumentMapper.ParseListenerAdapter()  {  
elasticsearch_cfe7504d1cee2cffd3ed06c3b61d0c77de63b67f	buggy:  return  new  ShardGatewaySnapshotRequest(shard.index(),  shard.id());  context:  return  new  GatewaySnapshotResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardGatewaySnapshotRequest  newShardRequest()  {  return  new  ShardGatewaySnapshotRequest();  }  protected  ShardGatewaySnapshotRequest  newShardRequest(ShardRouting  shard,  GatewaySnapshotRequest  request)  {          return  new  ShardGatewaySnapshotRequest(shard.index(),  shard.id());          return  new  ShardGatewaySnapshotRequest(shard.index(),  shard.id(),  request);  }  protected  ShardGatewaySnapshotResponse  newShardResponse()  {  return  new  ShardGatewaySnapshotResponse();  }  	return  new  ShardGatewaySnapshotRequest(shard.index(),  shard.id(),  request);  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  names.add(fieldMapper.indexName());  context:  public  class  FieldMappersFieldSelector  implements  FieldSelector  {  private  final  HashSet<String>  names  =  new  HashSet<String>();  public  void  add(FieldMappers  fieldMappers)  {  for  (FieldMapper  fieldMapper  :  fieldMappers)  {              names.add(fieldMapper.indexName());              names.add(fieldMapper.names().indexName());  }  }  if  (names.contains(fieldName))  {  return  FieldSelectorResult.LOAD;  }  return  FieldSelectorResult.NO_LOAD;  	names.add(fieldMapper.names().indexName());  
elasticsearch_fe4ba2ad559451ba1cdf61cb7832855e10a93b6e	buggy:  return  new  Names(name,  buildIndexName(context),  indexName  ==  null  ?  name  :  indexName,  buildFullName(context));  context:  this.searchAnalyzer  =  searchAnalyzer;  return  builder;  }  protected  T  includeInAll(Boolean  includeInAll)  {  this.includeInAll  =  includeInAll;  return  builder;  }  protected  Names  buildNames(BuilderContext  context)  {              return  new  Names(name,  buildIndexName(context),  indexName  ==  null  ?  name  :  indexName,  buildFullName(context));              return  new  Names(name,  buildIndexName(context),  indexName  ==  null  ?  name  :  indexName,  buildFullName(context),  context.path().sourcePath());  }  protected  String  buildIndexName(BuilderContext  context)  {  String  actualIndexName  =  indexName  ==  null  ?  name  :  indexName;  return  context.path().pathAsText(actualIndexName);  }  protected  String  buildFullName(BuilderContext  context)  {  	return  new  Names(name,  buildIndexName(context),  indexName  ==  null  ?  name  :  indexName,  buildFullName(context),  context.path().sourcePath());  
elasticsearch_ed996c3e850b047d52e36e7e865e3f39ccfd7ab6	buggy:  if  (!clusterService.localNode().masterNode()  ||  !clusterService.localNode().dataNode())  {  context:  private  synchronized  void  lazyInitialize()  {  if  (initialized)  {  return;  }  initialized  =  true;          if  (!clusterService.localNode().masterNode()  ||  !clusterService.localNode().dataNode())  {          if  (!clusterService.localNode().masterNode()  &&  !clusterService.localNode().dataNode())  {  location  =  null;  }  else  {  this.location  =  new  File(nodeEnv.nodeDataLocation(),   "_state ");  this.location.mkdirs();  if  (clusterService.localNode().masterNode())  {  try  {  	if  (!clusterService.localNode().masterNode()  &&  !clusterService.localNode().dataNode())  {  
elasticsearch_36a76cc0ab20b210c2e21b8c352427399a8e35bb	buggy:  clusterService.submitStateUpdateTask( "update-mapping  [ "  +  index  +   "][ "  +  type  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {  context:  }  });  }  public  void  updateMapping(final  String  index,  final  String  indexUUID,  final  String  type,  final  CompressedString  mappingSource,  final  long  order,  final  String  nodeId,  final  ClusterStateUpdateListener  listener)  {  final  long  insertOrder;  synchronized  (refreshOrUpdateMutex)  {  insertOrder  =  ++refreshOrUpdateInsertOrder;  refreshOrUpdateQueue.add(new  UpdateTask(index,  indexUUID,  type,  mappingSource,  order,  nodeId,  listener));  }          clusterService.submitStateUpdateTask( "update-mapping  [ "  +  index  +   "][ "  +  type  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {          clusterService.submitStateUpdateTask( "update-mapping  [ "  +  index  +   "][ "  +  type  +   "]  /  node  [ "  +  nodeId  +   "],  order  [ "  +  order  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {  public  void  onFailure(String  source,  Throwable  t)  {  listener.onFailure(t);  }  public  ClusterState  execute(final  ClusterState  currentState)  throws  Exception  {  return  executeRefreshOrUpdate(currentState,  insertOrder);  	clusterService.submitStateUpdateTask( "update-mapping  [ "  +  index  +   "][ "  +  type  +   "]  /  node  [ "  +  nodeId  +   "],  order  [ "  +  order  +   "] ",  Priority.HIGH,  new  ClusterStateUpdateTask()  {  
elasticsearch_3f8b7f0fce96727beea3696fd70897d058b1a65b	buggy:  Thread.sleep(500);  context:  }  Set<String>  nodesToShutdown  =  Sets.newHashSet();  nodesToShutdown.add(nonMasterNodes.removeLast());  nodesToShutdown.add(nonMasterNodes.removeLast());  for  (String  nodeToShutdown  :  nodesToShutdown)  {  closeNode(nodeToShutdown);  }          Thread.sleep(500);          Thread.sleep(1000);  String  lastNonMasterNodeUp  =  nonMasterNodes.removeLast();  state  =  client(masterNode).admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(true));  state  =  client(lastNonMasterNodeUp).admin().cluster().prepareState().setLocal(true).execute().actionGet().state();  assertThat(state.blocks().hasGlobalBlock(Discovery.NO_MASTER_BLOCK),  equalTo(true));  	Thread.sleep(1000);  
elasticsearch_d031662da34412839680af41648734a2e86a0d96	buggy:  logger.warn( "[{}]  failed  to  read  template  [{}]  from  config ",  request.index,  templatesFile.getAbsolutePath());  context:  for  (File  templatesFile  :  templatesFiles)  {  XContentParser  parser  =  null;  try  {  byte[]  templatesData  =  Streams.copyToByteArray(templatesFile);  parser  =  XContentHelper.createParser(templatesData,  0,  templatesData.length);  IndexTemplateMetaData  template  =  IndexTemplateMetaData.Builder.fromXContentStandalone(parser);  if  (Regex.simpleMatch(template.template(),  request.index))  {  templates.add(template);  }  }  catch  (Exception  e)  {                          logger.warn( "[{}]  failed  to  read  template  [{}]  from  config ",  request.index,  templatesFile.getAbsolutePath());                          logger.warn( "[{}]  failed  to  read  template  [{}]  from  config ",  e,  request.index,  templatesFile.getAbsolutePath());  }  finally  {  Closeables.closeQuietly(parser);  }  }  }  }  Collections.sort(templates,  new  Comparator<IndexTemplateMetaData>()  {  	logger.warn( "[{}]  failed  to  read  template  [{}]  from  config ",  e,  request.index,  templatesFile.getAbsolutePath());  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  for  (int  i  =  0;  i  <  indexFieldsNames.length;  i++)  {  fieldsData[i]  =  fieldDataCache.cache(fieldsDataType[i],  context.reader(),  indexFieldsNames[i]);  }  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  for  (FieldData  fieldData  :  fieldsData)  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  counts.release();  context:  CountEntry[]  countEntries  =  new  CountEntry[counts.v().size()];  final  boolean[]  states  =  counts.v().allocated;  final  long[]  keys  =  counts.v().keys;  final  long[]  values  =  counts.v().values;  int  entriesIndex  =  0;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  countEntries[entriesIndex++]  =  new  CountEntry(keys[i],  values[i]);  }  }          counts.release();          counts.close();  Arrays.sort(countEntries,  comparatorType.comparator());  return  new  InternalCountDateHistogramFacet(getName(),  comparatorType,  countEntries);  }  static  final  class  Fields  {  static  final  XContentBuilderString  _TYPE  =  new  XContentBuilderString( "_type ");  	counts.close();  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().allShardsGrouped(concreteIndices);  context:  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.flush(new  Engine.Flush().refresh(request.refresh()).full(request.full()));  return  new  ShardFlushResponse(request.index(),  request.shardId());  }          return  clusterState.routingTable().allShardsGrouped(concreteIndices);          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  
elasticsearch_eb4491004706f764c8a43e48228b73bba54aa5d0	buggy:  return  new  String[]{ "python "};  context:  private  final  PythonInterpreter  interp;  super(settings);  this.interp  =  PythonInterpreter.threadLocalStateInterpreter(null);  }          return  new  String[]{ "python "};          return  new  String[]{ "python ",   "py "};  }  return  new  String[]{ "py "};  }  return  interp.compile(script);  	return  new  String[]{ "python ",   "py "};  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  streamOutput.writeBytesReference(source,  false);  context:  if  (compressThreshold  ==  -1  ||  source.length()  >  compressThreshold)  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {  XContentType  contentType  =  XContentFactory.xContentType(source);  if  (formatContentType  !=  null  &&  formatContentType  !=  contentType)  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(formatContentType,  cachedEntry.bytes(CompressorFactory.defaultCompressor()));  builder.copyCurrentStructure(XContentFactory.xContent(contentType).createParser(source));  builder.close();  }  else  {  StreamOutput  streamOutput  =  cachedEntry.bytes(CompressorFactory.defaultCompressor());                          streamOutput.writeBytesReference(source,  false);                          source.writeTo(streamOutput);  streamOutput.close();  }  source  =  cachedEntry.bytes().bytes().copyBytesArray();  context.source(source);  }  finally  {  	source.writeTo(streamOutput);  
libgdx_2f5fefdc0db537150a65dc92965ba495d9eca56c	buggy:  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  context:  int  drawn;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  true);  Gdx.input.setInputProcessor(stage);  root  =  new  Table();  root.setFillParent(true);  stage.addActor(root);  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  Table  labels  =  new  Table();  root.add(new  ScrollPane(labels,  skin)).expand().fill();  root.row();  root.add(drawnLabel  =  new  Label( " ",  skin));  for  (int  i  =  0;  i  <  count;  i++)  {  labels.add(new  Label( "Label:   "  +  i,  skin)  {  	skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  context:  Filter  nonNestedDocsFilter  =  null;  if  (parentDocMapper.hasNestedObjects())  {  nonNestedDocsFilter  =  parseContext.cacheFilter(NonNestedDocsFilter.INSTANCE,  null);  }  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  Query  query;  Filter  parentFilter  =  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null);          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);          ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  if  (minChildren  >  1  ||  maxChildren  >  0  ||  scoreType  !=  ScoreType.NONE)  {  query  =  new  ChildrenQuery(parentChildIndexFieldData,  parentType,  childType,  parentFilter,  innerQuery,  scoreType,  minChildren,  maxChildren,  shortCircuitParentDocSet,  nonNestedDocsFilter);  }  else  {  query  =  new  ChildrenConstantScoreQuery(parentChildIndexFieldData,  innerQuery,  parentType,  childType,  parentFilter,  shortCircuitParentDocSet,  nonNestedDocsFilter);  }  if  (queryName  !=  null)  {  	ParentChildIndexFieldData  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  
elasticsearch_82298d890c3549c9d62ed8cec39eeb068bc7b7b0	buggy:  BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(InternalStringTermsFacet.ComparatorType.COUNT.comparator(),  size  *  numberOfShards);  context:  }  return  true;  }  if  (facets.isEmpty())  {  TermsStringFacetCollector.pushFacets(facets);  return  new  InternalStringTermsFacet(facetName,  sScript,  comparatorType,  size,  ImmutableList.<InternalStringTermsFacet.StringEntry>of());  }  else  {              BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(InternalStringTermsFacet.ComparatorType.COUNT.comparator(),  size  *  numberOfShards);              BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(comparatorType.comparator(),  size  *  numberOfShards);  for  (TObjectIntIterator<String>  it  =  facets.iterator();  it.hasNext();)  {  it.advance();  ordered.add(new  InternalStringTermsFacet.StringEntry(it.key(),  it.value()));  }  TermsStringFacetCollector.pushFacets(facets);  return  new  InternalStringTermsFacet(facetName,  sScript,  comparatorType,  size,  ordered);  }  }  	BoundedTreeSet<InternalStringTermsFacet.StringEntry>  ordered  =  new  BoundedTreeSet<InternalStringTermsFacet.StringEntry>(comparatorType.comparator(),  size  *  numberOfShards);  
elasticsearch_83d5084f620e13678e7786b5c735de32c4e9fb80	buggy:  Map<String,  Object>  mapping  =  XContentHelper.convertToMap(source.compressed(),  0,  source.compressed().length).v2();  context:  }  public  CompressedString  source()  {  return  this.source;  }  public  Map<String,  Object>  sourceAsMap()  throws  IOException  {          Map<String,  Object>  mapping  =  XContentHelper.convertToMap(source.compressed(),  0,  source.compressed().length).v2();          Map<String,  Object>  mapping  =  XContentHelper.convertToMap(source.compressed(),  0,  source.compressed().length,  true).v2();  if  (mapping.size()  ==  1  &&  mapping.containsKey(type()))  {  mapping  =  (Map<String,  Object>)  mapping.get(type());  }  return  mapping;  }  	Map<String,  Object>  mapping  =  XContentHelper.convertToMap(source.compressed(),  0,  source.compressed().length,  true).v2();  
elasticsearch_ac1e9856703960d953b81ba987f04596c925d153	buggy:  Query  parentConstantScoreQuery  =  new  ParentConstantScoreQuery(query,  parentType,  childrenFilter,  false);  context:  }  else  {  XBooleanFilter  parentsFilter  =  new  XBooleanFilter();  for  (String  parentTypeStr  :  parentTypes)  {  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(parentTypeStr);  Filter  filter  =  parseContext.cacheFilter(documentMapper.typeFilter(),  null);  parentsFilter.add(filter,  BooleanClause.Occur.SHOULD);  }  parentFilter  =  parentsFilter;  }  Filter  childrenFilter  =  parseContext.cacheFilter(new  NotFilter(parentFilter),  null);          Query  parentConstantScoreQuery  =  new  ParentConstantScoreQuery(query,  parentType,  childrenFilter,  false);          Query  parentConstantScoreQuery  =  new  ParentConstantScoreQuery(query,  parentType,  childrenFilter);  if  (filterName  !=  null)  {  parseContext.addNamedQuery(filterName,  parentConstantScoreQuery);  }  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  if  (deleteByQuery)  {  return  new  DeleteByQueryWrappingFilter(parentConstantScoreQuery);  	Query  parentConstantScoreQuery  =  new  ParentConstantScoreQuery(query,  parentType,  childrenFilter);  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  values  =  indexFieldData.load(context).getBytesValues();  context:  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  if  (current  !=  null)  {  missing  +=  current.counts.get(0);  total  +=  current.total  -  current.counts.get(0);  if  (current.values.ordinals().getNumOrds()  >  0)  {  aggregators.add(current);  }  }              values  =  indexFieldData.load(context).getBytesValues();              values  =  indexFieldData.load(context).getBytesValues(false);  current  =  new  ReaderAggregator(values,  ordinalsCacheAbove,  cacheRecycler);  ordinals  =  values.ordinals();  }  public  void  collect(int  doc)  throws  IOException  {  final  int  length  =  ordinals.setDocument(doc);  int  missing  =  1;  	values  =  indexFieldData.load(context).getBytesValues(false);  
elasticsearch_4634ca5cb8c8ad0a3c725363f3705a4078c04c9c	buggy:  if  (includeInAll  ==  null  ||  includeInAll)  {  context:  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  dateAsString  =  nullValue;  }  else  {  dateAsString  =  context.parser().text();  }  }  if  (dateAsString  ==  null)  {  return  null;  }          if  (includeInAll  ==  null  ||  includeInAll)  {          if  (context.includeInAll(includeInAll))  {  context.allEntries().addText(names.fullName(),  dateAsString,  boost);  }  final  long  value  =  parseStringValue(dateAsString);  return  new  LongFieldMapper.CustomLongNumericField(this,  value);  }  	if  (context.includeInAll(includeInAll))  {  
elasticsearch_34a3e8af352ed5bb241cc1b22b934c1002785192	buggy:  }  catch  (IOException  ex)  {  context:  public  static  RestSpec  parseFrom(String  optionalPathPrefix,  String...  paths)  throws  IOException  {  RestSpec  restSpec  =  new  RestSpec();  for  (String  path  :  paths)  {  for  (File  jsonFile  :  FileUtils.findJsonSpec(optionalPathPrefix,  path))  {  try  {  XContentParser  parser  =  JsonXContent.jsonXContent.createParser(new  FileInputStream(jsonFile));  RestApi  restApi  =  new  RestApiParser().parse(parser);  restSpec.addApi(restApi);                  }  catch  (IOException  ex)  {                  }  catch  (Throwable  ex)  {  throw  new  IOException( "Can't  parse  rest  spec  file:  [ "  +  jsonFile  +   "] ",  ex);  }  }  }  return  restSpec;  }  }  	}  catch  (Throwable  ex)  {  
elasticsearch_2e4d18b519a4074d2b0c25f51147f334bfc9c6a1	buggy:  if  (enabledState.enabled)  {  context:  }  }  public  boolean  includeInObject()  {  return  true;  }  protected  Field  innerParseCreateField(ParseContext  context)  throws  IOException,  AlreadyExpiredException  {          if  (enabledState.enabled)  {          if  (enabledState.enabled  &&  !context.sourceToParse().flyweight())  {  long  ttl  =  context.sourceToParse().ttl();  if  (ttl  <=  0  &&  defaultTTL  >  0)  {  //  no  ttl  provided  so  we  use  the  default  value  ttl  =  defaultTTL;  context.sourceToParse().ttl(ttl);  }  if  (ttl  >  0)  {  //  a  ttl  has  been  provided  either  externally  or  in  the  _source  long  timestamp  =  context.sourceToParse().timestamp();  long  expire  =  new  Date(timestamp  +  ttl).getTime();  	if  (enabledState.enabled  &&  !context.sourceToParse().flyweight())  {  
libgdx_77286f13f4c5adad20ea70812862f8e5cb282c66	buggy:  setBackground(background,  background  !=  null);  //  Keep  padding  from  last  background  if  new  background  is  null.  context:  background  =  style.disabled;  else  if  (isChecked  &&  style.checked  !=  null)  background  =  (isOver()  &&  style.checkedOver  !=  null)  ?  style.checkedOver  :  style.checked;  else  if  (isOver()  &&  style.over  !=  null)  background  =  style.over;  else  background  =  style.up;  offsetX  =  style.unpressedOffsetX;  offsetY  =  style.unpressedOffsetY;  }  setBackground(background,  background  !=  null);  //  Keep  padding  from  last  background  if  new  background  is  null.  setBackground(background);  Array<Actor>  children  =  getChildren();  for  (int  i  =  0;  i  <  children.size;  i++)  children.get(i).moveBy(offsetX,  offsetY);  super.draw(batch,  parentAlpha);  for  (int  i  =  0;  i  <  children.size;  i++)  children.get(i).moveBy(-offsetX,  -offsetY);  }  	setBackground(background);  
elasticsearch_4bdae621f92beb226cf5873a9efe721b38c7e0c7	buggy:  new  ScriptModule(),  context:  .put( "index.queryparser.query.my.param1 ",   "value1 ")  .put( "index.queryparser.filter.my.type ",  MyJsonFilterParser.class)  .put( "index.queryparser.filter.my.param2 ",   "value2 ")  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),                  new  ScriptModule(),                  new  ScriptModule(settings),  new  IndexSettingsModule(settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index)  ).createInjector();  	new  ScriptModule(settings),  
libgdx_865f8a60d4a7f7ca4e0edd47c7bf724aab92895f	buggy:  if  (region  ==  null)  throw  new  GdxRuntimeException(String.format( "Could  not  find  font  region   "  +  name  +   "  in  atlas   "+  parameter.atlasName));  context:  public  void  loadAsync  (AssetManager  manager,  String  fileName,  FileHandle  file,  BitmapFontParameter  parameter)  {  }  public  BitmapFont  loadSync  (AssetManager  manager,  String  fileName,  FileHandle  file,  BitmapFontParameter  parameter)  {  if  (parameter  !=  null  &&  parameter.atlasName  !=  null)  {  TextureAtlas  atlas  =  manager.get(parameter.atlasName,  TextureAtlas.class);  String  name  =  file.sibling(data.imagePaths[0]).nameWithoutExtension().toString();  AtlasRegion  region  =  atlas.findRegion(name);  if  (region  ==  null)  throw  new  GdxRuntimeException(String.format( "Could  not  find  font  region   "  +  name  +   "  in  atlas   "+  parameter.atlasName));  if  (region  ==  null)  throw  new  GdxRuntimeException( "Could  not  find  font  region   "  +  name  +   "  in  atlas   "  +  parameter.atlasName);  return  new  BitmapFont(file,  region);  }  else  {  TextureRegion[]  regs  =  new  TextureRegion[data.getImagePaths().length];  for  (int  i  =  0;  i  <  regs.length;  i++)  {  regs[i]  =  new  TextureRegion(manager.get(data.getImagePath(i),  Texture.class));  }  return  new  BitmapFont(data,  regs,  true);  }  	if  (region  ==  null)  throw  new  GdxRuntimeException( "Could  not  find  font  region   "  +  name  +   "  in  atlas   "  +  parameter.atlasName);  
elasticsearch_6a476f440b3991553cb60719c595249dbe5f7c05	buggy:  singlePingRequest.threadedOperation(true);  context:  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/{index}/{type}/{id}/_ping ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/{index}/{type}/{id}/_ping ",  this);  }  SinglePingRequest  singlePingRequest  =  new  SinglePingRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  singlePingRequest.listenerThreaded(false);          singlePingRequest.threadedOperation(true);          singlePingRequest.operationThreaded(true);  client.admin().cluster().ping(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {  try  {  JsonBuilder  generator  =  RestJsonBuilder.restJsonBuilder(request);  generator.startObject().field( "ok ",  true).endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  generator));  }  catch  (Exception  e)  {  onFailure(e);  	singlePingRequest.operationThreaded(true);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  ui  =  new  Stage(480,  320,  true);  context:  controller  =  new  PerspectiveCamController(cam);  projector  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  projector.position.set(2,  3,  2);  projector.lookAt(0,  0,  0);  projector.normalizeUp();  projector.update();  }  public  void  setupUI  ()  {  ui  =  new  Stage(480,  320,  true);  ui  =  new  Stage();;  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  TextButton  reload  =  new  TextButton( "Reload  Shaders ",  skin.get(TextButtonStyle.class));  camera  =  new  SelectBox(skin.get(SelectBoxStyle.class));  camera.setItems( "Camera ",   "Light ");  fps  =  new  Label( "fps:   ",  skin.get(LabelStyle.class));  Table  table  =  new  Table();  table.setFillParent(true);  	ui  =  new  Stage();;  
elasticsearch_82397c05542a794c8629fe611cbca58a3d831780	buggy:  if  (preference  ==  null)  {  context:  }  else  {  for  (IndexShardRoutingTable  indexShard  :  indexRouting)  {  set.add(indexShard);  }  }  }  return  set;  }  private  ShardIterator  preferenceActiveShardIterator(IndexShardRoutingTable  indexShard,  String  localNodeId,  DiscoveryNodes  nodes,  @Nullable  String  preference)  {          if  (preference  ==  null)  {          if  (preference  ==  null  ||  preference.isEmpty())  {  String[]  awarenessAttributes  =  awarenessAllocationDecider.awarenessAttributes();  if  (awarenessAttributes.length  ==  0)  {  return  indexShard.activeInitializingShardsRandomIt();  }  else  {  return  indexShard.preferAttributesActiveInitializingShardsIt(awarenessAttributes,  nodes);  }  }  if  (preference.charAt(0)  ==  '_')  {  	if  (preference  ==  null  ||  preference.isEmpty())  {  
elasticsearch_8ccfca3a2f0193f0a4da38e206c35cf08402218f	buggy:  TermsEnum  termsEnum  =  afd.getTermsEnum();  context:  }  public  void  testTermsEnum()  throws  Exception  {  fillExtendedMvSet();  AtomicReaderContext  atomicReaderContext  =  refreshReader();  IndexFieldData.WithOrdinals  ifd  =  getForField( "value ");  AtomicFieldData.WithOrdinals  afd  =  ifd.load(atomicReaderContext);          TermsEnum  termsEnum  =  afd.getTermsEnum();          TermsEnum  termsEnum  =  afd.getBytesValues().getTermsEnum();  int  size  =  0;  while  (termsEnum.next()  !=  null)  {  size++;  }  assertThat(size,  equalTo(12));  assertThat(termsEnum.seekExact(new  BytesRef( "10 ")),  is(true));  assertThat(termsEnum.term().utf8ToString(),  equalTo( "10 "));  	TermsEnum  termsEnum  =  afd.getBytesValues().getTermsEnum();  
elasticsearch_84593f0d7c7eb2d61cc22c93fa10dd4578e2da13	buggy:  StringBuilder  sb  =  new  StringBuilder( "routing_table:\n ");  context:  public  static  void  writeTo(RoutingTable  table,  StreamOutput  out)  throws  IOException  {  out.writeLong(table.version);  out.writeVInt(table.indicesRouting.size());  for  (IndexRoutingTable  index  :  table.indicesRouting.values())  {  IndexRoutingTable.Builder.writeTo(index,  out);  }  }  }  public  String  prettyPrint()  {          StringBuilder  sb  =  new  StringBuilder( "routing_table:\n ");          StringBuilder  sb  =  new  StringBuilder( "routing_table  (version   ").append(version).append( "):\n ");  for  (Map.Entry<String,  IndexRoutingTable>  entry  :  indicesRouting.entrySet())  {  sb.append(entry.getValue().prettyPrint()).append('\n');  }  return  sb.toString();  }  }  	StringBuilder  sb  =  new  StringBuilder( "routing_table  (version   ").append(version).append( "):\n ");  
elasticsearch_32e26a6bd0c21b2c0fd5a1040c98967df84469e2	buggy:  }  else  if  ( "value_field ".equals(currentName)  ||   "valueName ".equals(currentName))  {  context:  lon  =  values[1];  }  }  }  }  }  else  if  (token.isValue())  {  if  (currentName.equals( "unit "))  {  unit  =  DistanceUnit.fromString(parser.text());  }  else  if  (currentName.equals( "distance_type ")  ||  currentName.equals( "distanceType "))  {  geoDistance  =  GeoDistance.fromString(parser.text());                  }  else  if  ( "value_field ".equals(currentName)  ||   "valueName ".equals(currentName))  {                  }  else  if  ( "value_field ".equals(currentName)  ||   "valueField ".equals(currentName))  {  valueFieldName  =  parser.text();  }  else  if  ( "value_script ".equals(currentName)  ||   "valueScript ".equals(currentName))  {  valueScript  =  parser.text();  }  else  {  String  value  =  parser.text();  int  comma  =  value.indexOf(',');  if  (comma  !=  -1)  {  	}  else  if  ( "value_field ".equals(currentName)  ||   "valueField ".equals(currentName))  {  
elasticsearch_bad8643978f79ea5d26aff9cb4a58ba95ee44611	buggy:  escape  =  jp.getIntValue()  !=  0;  context:  boost  =  jp.getFloatValue();  }  else  if  ( "allowLeadingWildcard ".equals(currentFieldName))  {  allowLeadingWildcard  =  jp.getIntValue()  !=  0;  }  else  if  ( "lowercaseExpandedTerms ".equals(currentFieldName))  {  lowercaseExpandedTerms  =  jp.getIntValue()  !=  0;  }  else  if  ( "enablePositionIncrements ".equals(currentFieldName))  {  enablePositionIncrements  =  jp.getIntValue()  !=  0;  }  else  if  ( "escape ".equals(currentFieldName))  {  escape  =  jp.getIntValue()  !=  0;  }  else  if  ( "useDisMax ".equals(currentFieldName))  {                      escape  =  jp.getIntValue()  !=  0;                      useDisMax  =  jp.getIntValue()  !=  0;  }  else  if  ( "tieBreaker ".equals(currentFieldName))  {  tieBreaker  =  jp.getFloatValue();  }  }  }  if  (queryString  ==  null)  {  throw  new  QueryParsingException(index,   "QueryString  must  be  provided  with  a  [query] ");  }  	useDisMax  =  jp.getIntValue()  !=  0;  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  SearchContext.current().release();  context:  if  (request.explain())  {  explanation  =  parsedQuery.query().toString();  }  }  catch  (QueryParsingException  e)  {  valid  =  false;  error  =  e.getDetailedMessage();  }  catch  (AssertionError  e)  {  valid  =  false;  error  =  e.getMessage();  }  finally  {                  SearchContext.current().release();                  SearchContext.current().close();  SearchContext.removeCurrent();  }  }  return  new  ShardValidateQueryResponse(request.index(),  request.shardId(),  valid,  explanation,  error);  }  }  	SearchContext.current().close();  
elasticsearch_73383e201431cff19a278925eef630a2db2d6f51	buggy:  assert  rewriteIndexReader  ==  searcher.getIndexReader();  context:  public  Weight  createWeight(IndexSearcher  searcher)  throws  IOException  {  SearchContext  searchContext  =  SearchContext.current();  ParentIdAndScoreCollector  collector  =  new  ParentIdAndScoreCollector(searchContext,  parentChildIndexFieldData,  parentType);  final  Query  parentQuery;  if  (rewrittenParentQuery  ==  null)  {  parentQuery  =  rewrittenParentQuery  =  searcher.rewrite(originalParentQuery);  }  else  {              assert  rewriteIndexReader  ==  searcher.getIndexReader();              assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  parentQuery  =  rewrittenParentQuery;  }  IndexSearcher  indexSearcher  =  new  IndexSearcher(searcher.getIndexReader());  indexSearcher.setSimilarity(searcher.getSimilarity());  indexSearcher.search(parentQuery,  collector);  FloatArray  scores  =  collector.scores;  BytesRefHash  parentIds  =  collector.parentIds;  	assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  
elasticsearch_0ef4000842b86b947c27d1052a8e1ed981d03fcb	buggy:  MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreDuplicates(),  request.timeout());  context:  return  new  PutMappingRequest();  }  return  new  PutMappingResponse();  }  final  String[]  indices  =  processIndices(clusterService.state(),  request.indices());          MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreDuplicates(),  request.timeout());          MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreConflicts(),  request.timeout());  return  new  PutMappingResponse(result.acknowledged());  }  final  String[]  indices  =  processIndices(clusterService.state(),  request.indices());  if  (autoCreateIndex)  {  final  CountDownLatch  latch  =  new  CountDownLatch(indices.length);  for  (String  index  :  indices)  {  	MetaDataService.PutMappingResult  result  =  metaDataService.putMapping(indices,  request.type(),  request.mappingSource(),  request.ignoreConflicts(),  request.timeout());  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.lenientExpandOpen());  context:  }  if  (request.metaData())  {  MetaData.Builder  mdBuilder;  if  (request.indices().length  ==  0)  {  mdBuilder  =  MetaData.builder(currentState.metaData());  }  else  {  mdBuilder  =  MetaData.builder();  }  if  (request.indices().length  >  0)  {                  String[]  indices  =  currentState.metaData().concreteIndices(request.indices(),  IndicesOptions.lenientExpandOpen());                  String[]  indices  =  currentState.metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  request.indices());  for  (String  filteredIndex  :  indices)  {  IndexMetaData  indexMetaData  =  currentState.metaData().index(filteredIndex);  if  (indexMetaData  !=  null)  {  mdBuilder.put(indexMetaData,  false);  }  }  }  	String[]  indices  =  currentState.metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  request.indices());  
elasticsearch_ef5b7412e62c47c933541896564939d37788031b	buggy:  .point(-45,  30);  context:  assertEquals(exterior.getCoordinateN(3),  new  Coordinate(-45,  -30));  }  public  void  testToJTSGeometry()  {  ShapeBuilder.PolygonBuilder  polygonBuilder  =  ShapeBuilder.newPolygon()  .point(-45,  30)  .point(45,  30)  .point(45,  -30)  .point(-45,  -30)                  .point(-45,  30);                  .close();  Shape  polygon  =  polygonBuilder.build();  Geometry  polygonGeometry  =  ShapeBuilder.toJTSGeometry(polygon);  assertEquals(polygonBuilder.toPolygon(),  polygonGeometry);  Rectangle  rectangle  =  ShapeBuilder.newRectangle().topLeft(-45,  30).bottomRight(45,  -30).build();  Geometry  rectangleGeometry  =  ShapeBuilder.toJTSGeometry(rectangle);  assertEquals(rectangleGeometry,  polygonGeometry);  	.close();  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()  context:  public  class  RebalanceAfterActiveTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(RebalanceAfterActiveTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()          AllocationService  strategy  =  new  AllocationService(settingsBuilder()  .put( "cluster.routing.allocation.concurrent_recoveries ",  10)  .put( "cluster.routing.allocation.allow_rebalance ",   "always ")  .put( "cluster.routing.allocation.cluster_concurrent_rebalance ",  -1)  .build());  MetaData  metaData  =  newMetaDataBuilder()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder()  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (ShortFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
libgdx_aab2ea247c4831cad7da76c03670528aa2befe7b	buggy:  textures.put(textureFile.path(),  new  Texture(textureFile,  parameters.generateMipMaps));  context:  public  TiledMap  load(String  fileName,  TmxMapLoader.Parameters  parameters)  {  try  {  this.yUp  =  parameters.yUp;  FileHandle  tmxFile  =  resolve(fileName);  root  =  xml.parse(tmxFile);  ObjectMap<String,  Texture>  textures  =  new  ObjectMap<String,  Texture>();  for(FileHandle  textureFile:  loadTilesets(root,  tmxFile))  {  Texture  texture  =  new  Texture(textureFile,  parameters.generateMipMaps);  texture.setFilter(parameters.textureMinFilter,  parameters.textureMagFilter);  textures.put(textureFile.path(),  new  Texture(textureFile,  parameters.generateMipMaps));  textures.put(textureFile.path(),  texture);  }  DirectImageResolver  imageResolver  =  new  DirectImageResolver(textures);  TiledMap  map  =  loadTilemap(root,  tmxFile,  imageResolver);  map.setOwnedTextures(textures.values().toArray());  return  map;  }  catch(IOException  e)  {  throw  new  GdxRuntimeException( "Couldn't  load  tilemap  ' "  +  fileName  +   "' ",  e);  }  	textures.put(textureFile.path(),  texture);  
elasticsearch_13845e47d6ad44f63ba93383701f7bb0f4128bc3	buggy:  ShardIterator  reset();  context:  public  interface  ShardIterator  extends  ShardsIterator  {  ShardId  shardId();      ShardIterator  reset();      void  reset();  }  	void  reset();  
elasticsearch_06da379f5045e0c1d7436a7757400f9ba5b7f993	buggy:  if  (smartNameFieldMappers.hasDocMapper())  {  context:  public  Query  parse(Type  type)  {  FieldMapper  mapper  =  null;  String  field  =  fieldName;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null  &&  smartNameFieldMappers.hasMapper())  {  mapper  =  smartNameFieldMappers.mapper();  field  =  mapper.names().indexName();  }  if  (mapper  !=  null  &&  mapper.useFieldQueryWithQueryString())  {              if  (smartNameFieldMappers.hasDocMapper())  {              if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  String[]  previousTypes  =  QueryParseContext.setTypesWithPrevious(new  String[]{smartNameFieldMappers.docMapper().type()});  try  {  return  wrapSmartNameQuery(mapper.fieldQuery(text,  parseContext),  smartNameFieldMappers,  parseContext);  }  finally  {  QueryParseContext.setTypes(previousTypes);  }  }  else  {  return  wrapSmartNameQuery(mapper.fieldQuery(text,  parseContext),  smartNameFieldMappers,  parseContext);  	if  (smartNameFieldMappers.explicitTypeInNameWithDocMapper())  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<CompletionSuggestion.Entry.Option>  options  =  new  ArrayList<CompletionSuggestion.Entry.Option>(results.values());  context:  final  Option  option  =  new  CompletionSuggestion.Entry.Option(new  StringText(key),  score,  res.payload  ==  null  ?  null  :  new  BytesArray(res.payload));  results.put(key,  option);  }  else  if  (value.getScore()  <  score)  {  value.setScore(score);  value.setPayload(res.payload  ==  null  ?  null  :  new  BytesArray(res.payload));  }  }  }  }          final  List<CompletionSuggestion.Entry.Option>  options  =  new  ArrayList<CompletionSuggestion.Entry.Option>(results.values());          final  List<CompletionSuggestion.Entry.Option>  options  =  new  ArrayList<>(results.values());  CollectionUtil.introSort(options,  scoreComparator);  int  optionCount  =  Math.min(suggestionContext.getSize(),  options.size());  for  (int  i  =  0  ;  i  <  optionCount  ;  i++)  {  completionSuggestEntry.addOption(options.get(i));  }  return  completionSuggestion;  	final  List<CompletionSuggestion.Entry.Option>  options  =  new  ArrayList<>(results.values());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  ObjectObjectOpenHashMap<K,  V>(capacity);  context:  public  final  class  HppcMaps  {  private  HppcMaps()  {  }  public  static  <K,  V>  ObjectObjectOpenHashMap<K,  V>  newMap(int  capacity)  {          return  new  ObjectObjectOpenHashMap<K,  V>(capacity);          return  new  ObjectObjectOpenHashMap<>(capacity);  }  public  static  <K,  V>  ObjectObjectOpenHashMap<K,  V>  newMap()  {  return  newMap(16);  	return  new  ObjectObjectOpenHashMap<>(capacity);  
elasticsearch_f7d152821d37de3c875b969e3a77a91dd65afece	buggy:  return  Boolean.valueOf(sValue);  context:  throw  new  SettingsException( "Failed  to  parse  long  setting  [ "  +  setting  +   "]  with  value  [ "  +  sValue  +   "] ",  e);  }  }  String  sValue  =  get(setting);  if  (sValue  ==  null)  {  return  defaultValue;  }  try  {              return  Boolean.valueOf(sValue);              return  sValue.equals( "true ")  ||  sValue.equals( "1 ");  }  catch  (NumberFormatException  e)  {  throw  new  SettingsException( "Failed  to  parse  boolean  setting  [ "  +  setting  +   "]  with  value  [ "  +  sValue  +   "] ",  e);  }  }  return  TimeValue.parseTimeValue(get(setting),  defaultValue);  }  	return  sValue.equals( "true ")  ||  sValue.equals( "1 ");  
elasticsearch_8470e79aedd7e5f5ce847214878fd3cd671c2b49	buggy:  translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null,  null));  context:  assertThat(snapshot,  translogSize(2));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(2));  snapshot.release();  translog.add(new  Translog.Delete(newUid( "3 ")));  snapshot  =  translog.snapshot();  assertThat(snapshot,  translogSize(3));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(3));  snapshot.release();          translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null,  null));          translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null));  snapshot  =  translog.snapshot();  assertThat(snapshot,  translogSize(4));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(4));  snapshot.release();  snapshot  =  translog.snapshot();  assertThat(snapshot.hasNext(),  equalTo(true));  	translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null));  
elasticsearch_ffd019c07e19477b820985cf83f9bb0bc2ee0f9b	buggy:  logger.trace( "[{}][{}]  failed  to  multi  percolate ",  e,  request.index(),  request.shardId());  context:  protected  Response  shardOperation(Request  request,  int  shardId)  throws  ElasticSearchException  {  Response  response  =  new  Response();  response.items  =  new  ArrayList<Response.Item>(request.items.size());  for  (Request.Item  item  :  request.items)  {  Response.Item  responseItem  =  new  Response.Item();  responseItem.slot  =  item.slot;  try  {  responseItem.response  =  percolatorService.percolate(item.request);  }  catch  (Throwable  e)  {                  logger.trace( "[{}][{}]  failed  to  multi  percolate ",  e,  request.index(),  request.shardId());                  logger.debug( "[{}][{}]  failed  to  multi  percolate ",  e,  request.index(),  request.shardId());  if  (TransportActions.isShardNotAvailableException(e))  {  throw  new  ElasticSearchException( " ",  e);  }  else  {  responseItem.error  =  new  StringText(ExceptionsHelper.detailedMessage(e));  }  }  response.items.add(responseItem);  }  	logger.debug( "[{}][{}]  failed  to  multi  percolate ",  e,  request.index(),  request.shardId());  
elasticsearch_12d1bf848543b9e4c483ffa62161ac8b5be6c35d	buggy:  spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(topReader,  spare.termBytes);  context:  BucketSignificancePriorityQueue  ordered  =  new  BucketSignificancePriorityQueue(size);  SignificantStringTerms.Bucket  spare  =  null;  for  (int  i  =  0;  i  <  bucketOrds.size();  i++)  {  if  (spare  ==  null)  {  spare  =  new  SignificantStringTerms.Bucket(new  BytesRef(),  0,  0,  0,  0,  null);  }  bucketOrds.get(i,  spare.termBytes);  spare.subsetDf  =  bucketDocCount(i);  spare.subsetSize  =  subsetSize;              spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(topReader,  spare.termBytes);              spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(spare.termBytes);  spare.supersetSize  =  supersetSize;  assert  spare.subsetDf  <=  spare.supersetDf;  spare.updateScore();  	spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(spare.termBytes);  
elasticsearch_dd8512ddd1a328e32c3755964a8da3a79120883e	buggy:  indexRandom( "test ",  true,  builders);  context:  }  while  (denseBytes.containsKey(ref));  denseBytes.put(ref,  docId);  XContentBuilder  src  =  jsonBuilder().startObject().field( "dense_bytes ",  ref.utf8ToString());  if  (rarely())  {  src.field( "sparse_bytes ",  ref.utf8ToString());  sparseBytes.put(ref,  docId);  }  src.endObject();  builders[i]  =  client().prepareIndex( "test ",   "type ",  docId).setSource(src);  }          indexRandom( "test ",  true,  builders);          indexRandom(true,  builders);  {  int  size  =  between(1,  denseBytes.size());  SearchResponse  searchResponse  =  client().prepareSearch( "test ").setQuery(matchAllQuery()).setSize(size)  .addSort( "dense_bytes ",  SortOrder.ASC).execute().actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().getTotalHits(),  equalTo((long)  numDocs));  assertThat(searchResponse.getHits().hits().length,  equalTo(size));  Set<Entry<BytesRef,  String>>  entrySet  =  denseBytes.entrySet();  	indexRandom(true,  builders);  
elasticsearch_20d5481ac6a077ff1a646961aa9a03084023b4be	buggy:  .put( "number_of_shards ",  between(cluster().size(),  DEFAULT_MAX_NUM_SHARDS))  context:  }  }  }  }  }  public  void  testClusterUpdateSettingsNoAcknowledgement()  {  client().admin().indices().prepareCreate( "test ")  .setSettings(settingsBuilder()                          .put( "number_of_shards ",  between(cluster().size(),  DEFAULT_MAX_NUM_SHARDS))                          .put( "number_of_shards ",  between(cluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))  .put( "number_of_replicas ",  0)).get();  ensureGreen();  NodesInfoResponse  nodesInfo  =  client().admin().cluster().prepareNodesInfo().get();  String  excludedNodeId  =  null;  for  (NodeInfo  nodeInfo  :  nodesInfo)  {  if  (nodeInfo.getNode().isDataNode())  {  excludedNodeId  =  nodeInfo.getNode().id();  	.put( "number_of_shards ",  between(cluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))  
libgdx_455ec2bbd0a9d2a16780a3edf82d369056e3401e	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.RotationTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.RotationTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_c0daacd3e40a9c8adebf9e03512f325cdc188a6a	buggy:  vertexAttributes.add(VertexAttribute.Color());  context:  vertexAttributes.add(VertexAttribute.TexCoords(unit++));  }  else  if(attr.equals( "TANGENT "))  {  vertexAttributes.add(VertexAttribute.Tangent());  }  else  if(attr.equals( "BINORMAL "))  {  vertexAttributes.add(VertexAttribute.Binormal());  }  else  if(attr.equals( "BLENDINDICES "))  {  vertexAttributes.add(VertexAttribute.BoneIds(4));  }  else  if(attr.equals( "BLENDWEIGHTS "))  {  vertexAttributes.add(VertexAttribute.BoneWeights(4));  }  else  if(attr.equals( "COLOR "))  {  vertexAttributes.add(VertexAttribute.Color());  vertexAttributes.add(VertexAttribute.ColorUnpacked());  }  else  {  throw  new  GdxRuntimeException( "Unknown  vertex  attribuet  ' "  +  attr  +   "',  should  be  one  of  position,  normal,  uv,  tangent  or  binormal ");  }  }  return  vertexAttributes.toArray(VertexAttribute.class);  }  private  void  parseMaterials  (ModelData  model,  OrderedMap<String,  Object>  json,  String  materialDir)  {  	vertexAttributes.add(VertexAttribute.ColorUnpacked());  
elasticsearch_02cb2976917e3a6edb5e0caf5a65a95e3bff5f3a	buggy:  node.client().admin().indices().putMapping(putMappingRequest( "test ").mappingSource(mapping)).actionGet();  context:  }  node.client().admin().indices().delete(deleteIndexRequest( "test ")).actionGet();  }  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/plugin/attachments/index/mapper/test-mapping.json ");          node.client().admin().indices().putMapping(putMappingRequest( "test ").mappingSource(mapping)).actionGet();          node.client().admin().indices().putMapping(putMappingRequest( "test ").source(mapping)).actionGet();  node.client().index(indexRequest( "test ").type( "person ")  .source(jsonBuilder().startObject().field( "file ",  copyToBytesFromClasspath( "/org/elasticsearch/plugin/attachments/index/mapper/testXHTML.html ")).endObject())).actionGet();  node.client().admin().indices().refresh(refreshRequest()).actionGet();  CountResponse  countResponse  =  node.client().count(countRequest( "test ").query(fieldQuery( "file.title ",   "test  document "))).actionGet();  assertThat(countResponse.count(),  equalTo(1l));  	node.client().admin().indices().putMapping(putMappingRequest( "test ").source(mapping)).actionGet();  
libgdx_39c42c2dc347f1d8b10311c09e436fd4ade63c4c	buggy:  connection.setFollowRedirects(httpRequest.getFollowRedirects());  context:  }  else  {  url  =  new  URL(httpRequest.getUrl());  }  final  HttpURLConnection  connection  =  (HttpURLConnection)url.openConnection();  final  boolean  doingOutPut  =  method.equalsIgnoreCase(HttpMethods.POST)  ||  method.equalsIgnoreCase(HttpMethods.PUT);  connection.setDoOutput(doingOutPut);  connection.setDoInput(true);  connection.setRequestMethod(method);  connection.setFollowRedirects(httpRequest.getFollowRedirects());  HttpURLConnection.setFollowRedirects(httpRequest.getFollowRedirects());  lock.lock();  connections.put(httpRequest,  connection);  listeners.put(httpRequest,  httpResponseListener);  lock.unlock();  for  (Map.Entry<String,  String>  header  :  httpRequest.getHeaders().entrySet())  	HttpURLConnection.setFollowRedirects(httpRequest.getFollowRedirects());  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  context:  float  volume  =  0.5f;  long  soundId  =  0;  Stage  ui;  Skin  skin;  public  void  create  ()  {  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/shotgun.ogg ",  FileType.Internal));  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  true);  ui  =  new  Stage();  TextButton  play  =  new  TextButton( "Play ",  skin);  TextButton  stop  =  new  TextButton( "Stop ",  skin);  final  Slider  pitch  =  new  Slider(0.1f,  4,  0.1f,  false,  skin);  pitch.setValue(1);  final  Label  pitchValue  =  new  Label( "1.0 ",  skin);  final  Slider  volume  =  new  Slider(0.1f,  1,  0.1f,  false,  skin);  volume.setValue(1);  final  Label  volumeValue  =  new  Label( "1.0 ",  skin);  	ui  =  new  Stage();  
elasticsearch_9126d118246157e59f0ce3ffeb66491a1a9935d0	buggy:  logger.info( "deleting  shard  content ");  context:  public  RecoveryStatus  recoveryStatus()  {  return  recoveryStatus;  }  public  void  recover(boolean  indexShouldExists,  RecoveryStatus  recoveryStatus)  throws  IndexShardGatewayRecoveryException  {  recoveryStatus().index().startTime(System.currentTimeMillis());  try  {              logger.info( "deleting  shard  content ");              logger.debug( "cleaning  shard  content  before  creation ");  indexShard.store().deleteContent();  }  catch  (IOException  e)  {  }  indexShard.start( "post  recovery  from  gateway ");  recoveryStatus.index().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  recoveryStatus.translog().startTime(System.currentTimeMillis());  recoveryStatus.translog().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  	logger.debug( "cleaning  shard  content  before  creation ");  
elasticsearch_91144fc92f80d02282c7b741787200539566d713	buggy:  Filter  nestedFilter  =  Queries.wrap(new  ToParentBlockJoinQuery(query,  parentFilter,  ScoreMode.None));  context:  }  parentFilter  =  parseContext.fixedBitSetFilter(parentFilter);              Filter  nestedFilter  =  Queries.wrap(new  ToParentBlockJoinQuery(query,  parentFilter,  ScoreMode.None));              Filter  nestedFilter  =  Queries.wrap(new  ToParentBlockJoinQuery(query,  parentFilter,  ScoreMode.None),  parseContext);  if  (cache)  {  nestedFilter  =  parseContext.cacheFilter(nestedFilter,  cacheKey);  }  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  nestedFilter);  }  return  nestedFilter;  	Filter  nestedFilter  =  Queries.wrap(new  ToParentBlockJoinQuery(query,  parentFilter,  ScoreMode.None),  parseContext);  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (!stored())  {  context:  }  }  public  String  valueAsString(Object  value)  {  return  null;  }  protected  Field  parseCreateField(ParseContext  context)  throws  IOException  {          if  (!stored())  {          if  (!fieldType().stored())  {  return  null;  }  byte[]  value;  if  (context.parser().currentToken()  ==  XContentParser.Token.VALUE_NULL)  {  return  null;  }  else  {  value  =  context.parser().binaryValue();  if  (compress  !=  null  &&  compress  &&  !CompressorFactory.isCompressed(value,  0,  value.length))  {  	if  (!fieldType().stored())  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  String>  map  =  new  HashMap<String,  String>();  context:  if  (loggerName.equalsIgnoreCase( "_root "))  {  return  ESLoggerFactory.getRootLogger();  }  return  Loggers.getLogger(loggerName);  }  private  Map<String,  String>  processTestLogging(TestLogging  testLogging)  {  if  (testLogging  ==  null)  {  return  null;  }          Map<String,  String>  map  =  new  HashMap<String,  String>();          Map<String,  String>  map  =  new  HashMap<>();  final  String[]  loggersAndLevels  =  testLogging.value().split( ", ");  for  (String  loggerAndLevel  :  loggersAndLevels)  {  String[]  loggerAndLevelArray  =  loggerAndLevel.split( ": ");  if  (loggerAndLevelArray.length  >=2)  {  String  loggerName  =  loggerAndLevelArray[0];  String  level  =  loggerAndLevelArray[1];  ESLogger  esLogger  =  resolveLogger(loggerName);  map.put(loggerName,  esLogger.getLevel());  	Map<String,  String>  map  =  new  HashMap<>();  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  nullValue,  ignoreMalformed);  context:  public  Builder  nullValue(int  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  IntegerFieldMapper  build(BuilderContext  context)  {  IntegerFieldMapper  fieldMapper  =  new  IntegerFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,                      nullValue,  ignoreMalformed);                      nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	nullValue,  ignoreMalformed(context));  
libgdx_db2e9988236332c9ad65189c0e3090007849940d	buggy:  if  (width  >  height)  {  context:  public  void  setViewport  (float  width,  float  height,  boolean  stretch)  {  if  (!stretch)  {  if  (width  >  height)  {  if  (width  >  height  &&  width/(float)Gdx.graphics.getWidth()  <=  height/(float)Gdx.graphics.getHeight())  {  float  toDeviceSpace  =  Gdx.graphics.getHeight()  /  height;  float  toViewportSpace  =  height  /  Gdx.graphics.getHeight();  float  deviceWidth  =  width  *  toDeviceSpace;  this.width  =  width  +  (Gdx.graphics.getWidth()  -  deviceWidth)  *  toViewportSpace;  this.height  =  height;  }  else  {  float  toDeviceSpace  =  Gdx.graphics.getWidth()  /  width;  	if  (width  >  height  &&  width/(float)Gdx.graphics.getWidth()  <=  height/(float)Gdx.graphics.getHeight())  {  
elasticsearch_4baf9df68ecdfd8a4c740aef404d4430c90e4555	buggy:  fail( "failed  to  find  mappings  for  index   "  +  index  +   ",  type   "  +  type  +   "  on  master  node[ "  +  source  +   "] ");  context:  if  (mappings  !=  null)  {  MappingMetaData  mappingMetaData  =  mappings.get(type);  if  (mappingMetaData  !=  null)  {  try  {  source  =  mappingMetaData.source().string();  }  catch  (IOException  e)  {  throw  ExceptionsHelper.convertToElastic(e);  }  }  }              fail( "failed  to  find  mappings  for  index   "  +  index  +   ",  type   "  +  type  +   "  on  master  node[ "  +  source  +   "] ");              fail( "failed  to  find  mappings  for  index   "  +  index  +   ",  type   "  +  type  +   ",  fields   "  +  fieldNames  +   ",  on  master  node,  mapping  source  [ "  +  source  +   "] ");  }  }  	fail( "failed  to  find  mappings  for  index   "  +  index  +   ",  type   "  +  type  +   ",  fields   "  +  fieldNames  +   ",  on  master  node,  mapping  source  [ "  +  source  +   "] ");  
elasticsearch_2655c2aa58df53e055d59d383ccfa8241274741a	buggy:  builder.field( "index ",  fieldType.indexed());  context:  if  (fieldType.stored()  ==  Defaults.FIELD_TYPE.stored()  &&  fieldType.indexed()  ==  Defaults.FIELD_TYPE.indexed()  &&  path  ==  Defaults.PATH)  {  return  builder;  }  builder.startObject(CONTENT_TYPE);  if  (fieldType.stored()  !=  Defaults.FIELD_TYPE.stored())  {  builder.field( "store ",  fieldType.stored());  }  if  (fieldType.indexed()  !=  Defaults.FIELD_TYPE.indexed())  {              builder.field( "index ",  fieldType.indexed());              builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  }  if  (path  !=  Defaults.PATH)  {  builder.field( "path ",  path);  }  builder.endObject();  return  builder;  }  	builder.field( "index ",  indexTokenizeOptionToString(fieldType.indexed(),  fieldType.tokenized()));  
libgdx_1fc2cfd32ba00cfba02d6b9258d655056457646b	buggy:  headerDirs.append( "\t\t\t<arg  value=\ " "  +  headerDir  +   "\ "/>\n ");  context:  cExcludes.append( "\t\t<exclude  name=\ " "  +  cExclude  +   "\ "/>\n ");  }  StringBuffer  cppExcludes  =  new  StringBuffer();  for(String  cppExclude:  target.cppExcludes)  {  cppExcludes.append( "\t\t<exclude  name=\ " "  +  cppExclude  +   "\ "/>\n ");  }  StringBuffer  headerDirs  =  new  StringBuffer();  for(String  headerDir:  target.headerDirs)  {  headerDirs.append( "\t\t\t<arg  value=\ " "  +  headerDir  +   "\ "/>\n ");  headerDirs.append( "\t\t\t<arg  value=\ "-I "  +  headerDir  +   "\ "/>\n ");  }  template  =  template.replace( "%projectName% ",  config.sharedLibName  +   "- "  +  target.os  +   "- "  +  (target.is64Bit? "64 ": "32 "));  template  =  template.replace( "%buildDir% ",  config.buildDir.child(target.os.toString().toLowerCase()  +  (target.is64Bit? "64 ": "32 ")).path().replace('\\',  '/'));  template  =  template.replace( "%libsDir% ",   "../ "  +  getLibsDirectory(config,  target));  template  =  template.replace( "%libName% ",  libName);  template  =  template.replace( "%jniPlatform% ",  jniPlatform);  	headerDirs.append( "\t\t\t<arg  value=\ "-I "  +  headerDir  +   "\ "/>\n ");  
elasticsearch_7ea490dfd15ea9f969d41e00fd452c0144c804dc	buggy:  return  new  StringTerms(name,  order,  bucketCountThresholds.getRequiredSize(),  bucketCountThresholds.getShardSize(),  bucketCountThresholds.getMinDocCount(),  Collections.<InternalTerms.Bucket>emptyList(),  showTermDocCountError,  0);  context:  this.showTermDocCountError  =  showTermDocCountError;  }  public  boolean  shouldCollect()  {  return  true;  }  public  InternalAggregation  buildEmptyAggregation()  {          return  new  StringTerms(name,  order,  bucketCountThresholds.getRequiredSize(),  bucketCountThresholds.getShardSize(),  bucketCountThresholds.getMinDocCount(),  Collections.<InternalTerms.Bucket>emptyList(),  showTermDocCountError,  0);          return  new  StringTerms(name,  order,  bucketCountThresholds.getRequiredSize(),  bucketCountThresholds.getShardSize(),  bucketCountThresholds.getMinDocCount(),  Collections.<InternalTerms.Bucket>emptyList(),  showTermDocCountError,  0,  0);  }  }  	return  new  StringTerms(name,  order,  bucketCountThresholds.getRequiredSize(),  bucketCountThresholds.getShardSize(),  bucketCountThresholds.getMinDocCount(),  Collections.<InternalTerms.Bucket>emptyList(),  showTermDocCountError,  0,  0);  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  StreamOutput  out  =  cachedEntry.cachedHandles();  context:  });  }  private  void  sendPingRequest(int  id)  {  if  (multicastSocket  ==  null)  {  return;  }  synchronized  (sendMutex)  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {                  StreamOutput  out  =  cachedEntry.cachedHandles();                  StreamOutput  out  =  cachedEntry.handles();  out.writeBytes(INTERNAL_HEADER);  Version.writeVersion(Version.CURRENT,  out);  out.writeInt(id);  clusterName.writeTo(out);  nodesProvider.nodes().localNode().writeTo(out);  out.close();  datagramPacketSend.setData(cachedEntry.bytes().copiedByteArray());  multicastSocket.send(datagramPacketSend);  	StreamOutput  out  =  cachedEntry.handles();  
libgdx_bf60fe7b39c92395dc34ef2564c4cf4f447e3e31	buggy:  pixmap.drawCircle(400,  300,  16);  context:  pixmap.setColor(1.0f,  0.0f,  0.0f,  1.0f);    //  Red  pixmap.drawLine(0,  0,  100,  100);  pixmap.setColor(0.0f,  0.0f,  1.0f,  1.0f);    //  Blue  pixmap.drawLine(100,  100,  200,  0);  pixmap.setColor(0.0f,  1.0f,  0.0f,  1.0f);    //  Green  pixmap.drawLine(100,  0,  100,  100);  pixmap.setColor(1.0f,  1.0f,  1.0f,  1.0f);    //  White        pixmap.drawCircle(400,  300,  16);        pixmap.drawCircle(400,  300,  100);  texture.draw  (pixmap,  0,0);  region  =  new  TextureRegion(texture,  0,  0,  800,  480);  batch  =  new  SpriteBatch();  }  public  void  render()  {  	pixmap.drawCircle(400,  300,  100);  
libgdx_6f9efed67c550675db27ce834917d5e0cf947d36	buggy:  return  ModelBuilder.createCylinder(radius  *  2,  hh  *  2f,  radius  *  2f,  16,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  context:  localA.setFromEulerAngles(0,  PI2,  0).trn(0,  0.18f,  0);  localB.setFromEulerAngles(0,  PI2,  0).trn(0,  -0.14f,  0);  constraints.add(hingeC  =  new  btHingeConstraint(rightupperarm,  rightlowerarm,  localA,  localB));  hingeC.setLimit(0,  PI2);  ((btDynamicsWorld)world.collisionWorld).addConstraint(hingeC,  true);  }  protected  Model  createCapsuleModel(float  radius,  float  height)  {  final  float  hh  =  radius  +  0.5f  *  height;  return  ModelBuilder.createCylinder(radius  *  2,  hh  *  2f,  radius  *  2f,  16,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  return  modelBuilder.createCylinder(radius  *  2,  hh  *  2f,  radius  *  2f,  16,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  }  }  	return  modelBuilder.createCylinder(radius  *  2,  hh  *  2f,  radius  *  2f,  16,  new  NewMaterial(new  ColorAttribute(ColorAttribute.Diffuse,  Color.WHITE)),  new  VertexAttributes(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE)));  
elasticsearch_c9c68fced74e89b726b594a0141746f4f0eac074	buggy:  final  SuggestionSearchContext  context  =  suggestPhase.parseElement().parseInternal(parser,  indexService.mapperService());  context:  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  final  Engine.Searcher  searcher  =  indexShard.searcher();  XContentParser  parser  =  null;  try  {  BytesReference  suggest  =  request.suggest();  if  (suggest  !=  null  &&  suggest.length()  >  0)  {  parser  =  XContentFactory.xContent(suggest).createParser(suggest);  if  (parser.nextToken()  !=  XContentParser.Token.START_OBJECT)  {  throw  new  ElasticSearchIllegalArgumentException( "suggest  content  missing ");  }                  final  SuggestionSearchContext  context  =  suggestPhase.parseElement().parseInternal(parser,  indexService.mapperService());                  final  SuggestionSearchContext  context  =  suggestPhase.parseElement().parseInternal(parser,  indexService.mapperService(),  request.index(),  request.shardId());  final  Suggest  result  =  suggestPhase.execute(context,  searcher.reader());  return  new  ShardSuggestResponse(request.index(),  request.shardId(),  result);  }  return  new  ShardSuggestResponse(request.index(),  request.shardId(),  new  Suggest());  }  catch  (Throwable  ex)  {  throw  new  ElasticSearchException( "failed  to  execute  suggest ",  ex);  }  finally  {  searcher.release();  	final  SuggestionSearchContext  context  =  suggestPhase.parseElement().parseInternal(parser,  indexService.mapperService(),  request.index(),  request.shardId());  
elasticsearch_bfc5ad7b921f1bf1e64b5f56075a47deebeb76c7	buggy:  return  sValue.equals( "true ")  ||  sValue.equals( "1 ");  context:  }  catch  (NumberFormatException  e)  {  throw  new  ElasticSearchIllegalArgumentException( "Failed  to  parse  int  parameter  [ "  +  key  +   "]  with  value  [ "  +  sValue  +   "] ",  e);  }  }  String  sValue  =  param(key);  if  (sValue  ==  null)  {  return  defaultValue;  }          return  sValue.equals( "true ")  ||  sValue.equals( "1 ");          return  sValue.equals( "true ")  ||  sValue.equals( "1 ")  ||  sValue.equals( "on ");  }  return  parseTimeValue(param(key),  defaultValue);  }  return  parseSizeValue(param(key),  defaultValue);  	return  sValue.equals( "true ")  ||  sValue.equals( "1 ")  ||  sValue.equals( "on ");  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (!stored())  {  context:  public  boolean  includeInObject()  {  return  false;  }  protected  Field  parseCreateField(ParseContext  context)  throws  IOException  {  if  (!enabled)  {  return  null;  }          if  (!stored())  {          if  (!fieldType.stored())  {  return  null;  }  if  (context.flyweight())  {  return  null;  }  BytesReference  source  =  context.source();  boolean  filtered  =  includes.length  >  0  ||  excludes.length  >  0;  	if  (!fieldType.stored())  {  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  bigArrays  context:  return  new  ExplainResponse(shardId.getIndex(),  request.type(),  request.id(),  false);  }  SearchContext  context  =  new  DefaultSearchContext(  0,  new  ShardSearchRequest(request).types(new  String[]{request.type()})  .filteringAliases(request.filteringAlias())  .nowInMillis(request.nowInMillis),  null,  result.searcher(),  indexService,  indexShard,  scriptService,  pageCacheRecycler,                  bigArrays                  bigArrays,  threadPool.estimatedTimeInMillisCounter()  );  SearchContext.setCurrent(context);  try  {  context.parsedQuery(indexService.queryParserService().parseQuery(request.source()));  context.preProcess();  int  topLevelDocId  =  result.docIdAndVersion().docId  +  result.docIdAndVersion().context.docBase;  Explanation  explanation  =  context.searcher().explain(context.query(),  topLevelDocId);  	bigArrays,  threadPool.estimatedTimeInMillisCounter()  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  numDocs  =  atLeast(5);  context:  .endObject()  .endObject()  .endObject()  .startObject( "not_filtered ")  .field( "type ",   "string ")  .endObject()  .endObject()  .endObject().endObject();  assertAcked(builder.addMapping( "type ",  mapping));  ensureGreen();          int  numDocs  =  atLeast(5);          int  numDocs  =  scaledRandomIntBetween(5,  50);  for  (int  i  =  0;  i  <  numDocs;  i++)  {  client().prepareIndex( "test ",   "type ",   " "  +  0).setSource( "name ",   "bacon  bastards ",   "not_filtered ",   "bacon  bastards ").get();  }  refresh();  SearchResponse  searchResponse  =  client().prepareSearch()  .setSearchType(SearchType.COUNT)  .setQuery(matchAllQuery())  .addFacet(termsFacet( "name ").field( "name "))  	int  numDocs  =  scaledRandomIntBetween(5,  50);  
elasticsearch_9e7b3963d81afc74907a130533738cb90e6f993b	buggy:  return  this.source();  context:  private  final  String  source;  private  final  IndexSearcher  searcher;  public  SimpleSearcher(String  source,  IndexSearcher  searcher)  {  this.source  =  source;  this.searcher  =  searcher;  }  public  String  source()  {              return  this.source();              return  source;  }  public  IndexReader  reader()  {  return  searcher.getIndexReader();  }  	return  source;  
libgdx_d31c6771afdc6929484ad561d9247939f370c306	buggy:  Method  m  =  File.class.getMethod( "canWrite ");  context:  return  true;  }  catch  (Throwable  ex)  {  return  false;  }  finally  {  testFile.delete();  }  }  private  boolean  canExecute(File  file)  {  try  {  Method  m  =  File.class.getMethod( "canWrite ");  Method  m  =  File.class.getMethod( "canExecute ");  return  (Boolean)m.invoke(file);  }  catch  (Exception  e)  {  return  false;  }  }  private  File  extractFile  (String  sourcePath,  String  sourceCrc,  File  extractedFile)  throws  IOException  {  String  extractedCrc  =  null;  	Method  m  =  File.class.getMethod( "canExecute ");  
elasticsearch_83010f7ee152c8213f3dc7d577928d606c5ae5aa	buggy:  return   "Search  Failure  Shard   "  +  shardTarget  +   ",  reason  [ "  +  reason  +   "] ";  context:  }  public  String  reason()  {  return  this.reason;  }          return   "Search  Failure  Shard   "  +  shardTarget  +   ",  reason  [ "  +  reason  +   "] ";          return   "shard  [ "  +  (shardTarget  ==  null  ?   "_na "  :  shardTarget)  +   "],  reason  [ "  +  reason  +   "] ";  }  public  static  ShardSearchFailure  readShardSearchFailure(StreamInput  in)  throws  IOException  {  ShardSearchFailure  shardSearchFailure  =  new  ShardSearchFailure();  shardSearchFailure.readFrom(in);  return  shardSearchFailure;  }  	return   "shard  [ "  +  (shardTarget  ==  null  ?   "_na "  :  shardTarget)  +   "],  reason  [ "  +  reason  +   "] ";  
elasticsearch_71ebb14b584c6ce2492783b0b5bcb60fbffbddb0	buggy:  return  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAliveTime,  unit,  new  SynchronousQueue<Runnable>(),  threadFactory);  context:  public  static  EsThreadPoolExecutor  newScaling(int  min,  int  max,  long  keepAliveTime,  TimeUnit  unit,  ThreadFactory  threadFactory)  {  ExecutorScalingQueue<Runnable>  queue  =  new  ExecutorScalingQueue<Runnable>();  EsThreadPoolExecutor  executor  =  new  EsThreadPoolExecutor(min,  max,  keepAliveTime,  unit,  queue,  threadFactory,  new  ForceQueuePolicy());  queue.executor  =  executor;  return  executor;  }  public  static  EsThreadPoolExecutor  newCached(long  keepAliveTime,  TimeUnit  unit,  ThreadFactory  threadFactory)  {          return  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAliveTime,  unit,  new  SynchronousQueue<Runnable>(),  threadFactory);          return  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAliveTime,  unit,  new  SynchronousQueue<Runnable>(),  threadFactory,  new  EsAbortPolicy());  }  public  static  EsThreadPoolExecutor  newFixed(int  size,  BlockingQueue<Runnable>  queue,  ThreadFactory  threadFactory)  {  return  new  EsThreadPoolExecutor(size,  size,  0,  TimeUnit.MILLISECONDS,  queue,  threadFactory,  new  EsAbortPolicy());  }  public  static  EsThreadPoolExecutor  newFixed(int  size,  BlockingQueue<Runnable>  queue,  ThreadFactory  threadFactory,  XRejectedExecutionHandler  rejectedExecutionHandler)  {  return  new  EsThreadPoolExecutor(size,  size,  0,  TimeUnit.MILLISECONDS,  queue,  threadFactory,  rejectedExecutionHandler);  	return  new  EsThreadPoolExecutor(0,  Integer.MAX_VALUE,  keepAliveTime,  unit,  new  SynchronousQueue<Runnable>(),  threadFactory,  new  EsAbortPolicy());  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {  context:  protected  PutMappingResponse  masterOperation(PutMappingRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  ClusterState  clusterState  =  clusterService.state();  request.indices(clusterState.metaData().concreteIndices(request.indices()));  final  AtomicReference<PutMappingResponse>  responseRef  =  new  AtomicReference<PutMappingResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()),  new  MetaDataMappingService.Listener()  {          metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataMappingService.Listener()  {  public  void  onResponse(MetaDataMappingService.Response  response)  {  responseRef.set(new  PutMappingResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	metaDataMappingService.putMapping(new  MetaDataMappingService.PutRequest(request.indices(),  request.type(),  request.source()).ignoreConflicts(request.ignoreConflicts()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataMappingService.Listener()  {  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(sum( "sum ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  Sum  sum  =  bucket.getAggregations().get( "sum ");  assertThat(sum,  notNullValue());  assertThat(sum.getName(),  equalTo( "sum "));  assertThat(sum.getValue(),  equalTo(0.0));  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_b53a8aff6a0df645d5335ac3982ecedee951b464	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  null);  context:  }  protected  ShardCountResponse  newShardResponse()  {  return  new  ShardCountResponse();  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  CountRequest  request,  String[]  concreteIndices)  {  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(request.routing(),  request.indices());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  null);          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  request.preference());  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  CountRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.READ);  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  routingMap,  request.preference());  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  aggregated.release();  context:  for  (int  i  =  0;  i  <  aggregatedEntries.allocated.length;  i++)  {  if  (states[i])  {  Text  key  =  (Text)  keys[i];  ordered.add(new  TermEntry(key,  values[i]));  }  }  first.entries  =  ordered;  first.missing  =  missing;  first.total  =  total;          aggregated.release();          aggregated.close();  return  first;  }  private  void  trimExcessEntries()  {  if  (requiredSize  >=  entries.size())  {  return;  }  	aggregated.close();  
elasticsearch_a8281065535d6e140c5d563d6487ad2a160605e0	buggy:  throw  new  DfsPhaseExecutionException(context);  context:  context.rewriteQuery();  THashSet<Term>  termsSet  =  new  THashSet<Term>();  context.query().extractTerms(termsSet);  Term[]  terms  =  termsSet.toArray(new  Term[termsSet.size()]);  int[]  freqs  =  context.searcher().docFreqs(terms);  context.dfsResult().termsAndFreqs(terms,  freqs);  context.dfsResult().maxDoc(context.searcher().getIndexReader().maxDoc());  }  catch  (Exception  e)  {              throw  new  DfsPhaseExecutionException(context);              throw  new  DfsPhaseExecutionException(context,   " ",  e);  }  }  }  	throw  new  DfsPhaseExecutionException(context,   " ",  e);  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.settings,  discovery.localNode);  context:  return;  }  try  {  final  byte[]  clusterStateBytes  =  Builder.toBytes(clusterState);  for  (LocalDiscovery  discovery  :  clusterGroup.members())  {  if  (discovery.master)  {  continue;  }                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.settings,  discovery.localNode);                  final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);  if  (nodeSpecificClusterState.nodes().localNode()  !=  null)  {  discovery.clusterService.submitStateUpdateTask( "local-disco-receive(from  master) ",  new  ProcessedClusterStateUpdateTask()  {  return  nodeSpecificClusterState;  }  	final  ClusterState  nodeSpecificClusterState  =  ClusterState.Builder.fromBytes(clusterStateBytes,  discovery.localNode);  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  fieldMappers.mappers().get(0).indexName();  context:  }  else  {  sortFields.add(SORT_DOC);  }  }  else  {  FieldMappers  fieldMappers  =  context.mapperService().smartNameFieldMappers(fieldName);  if  (fieldMappers  ==  null  ||  fieldMappers.mappers().isEmpty())  {  if  (type  ==  -1)  {  throw  new  SearchParseException(context,   "No  built  in  mapping  found  for  [ "  +  fieldName  +   "],  and  no  explicit  type  defined ");  }  }  else  {                  fieldName  =  fieldMappers.mappers().get(0).indexName();                  fieldName  =  fieldMappers.mappers().get(0).names().indexName();  if  (type  ==  -1)  {  type  =  fieldMappers.mappers().get(0).sortType();  }  }  sortFields.add(new  SortField(fieldName,  type,  reverse));  }  }  }  	fieldName  =  fieldMappers.mappers().get(0).names().indexName();  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  shardRequest  =  new  MultiTermVectorsShardRequest(shardId.index().name(),  shardId.id());  context:  String  concreteSingleIndex  =  clusterState.metaData().concreteSingleIndex(termVectorRequest.index(),  termVectorRequest.indicesOptions());  if  (termVectorRequest.routing()  ==  null  &&  clusterState.getMetaData().routingRequired(concreteSingleIndex,  termVectorRequest.type()))  {  responses.set(i,  new  MultiTermVectorsItemResponse(null,  new  MultiTermVectorsResponse.Failure(concreteSingleIndex,  termVectorRequest.type(),  termVectorRequest.id(),   "routing  is  required  for  [ "  +  concreteSingleIndex  +   "]/[ "  +  termVectorRequest.type()  +   "]/[ "  +  termVectorRequest.id()  +   "] ")));  continue;  }  ShardId  shardId  =  clusterService.operationRouting().getShards(clusterState,  concreteSingleIndex,  termVectorRequest.type(),  termVectorRequest.id(),  termVectorRequest.routing(),  null).shardId();  MultiTermVectorsShardRequest  shardRequest  =  shardRequests.get(shardId);  if  (shardRequest  ==  null)  {                  shardRequest  =  new  MultiTermVectorsShardRequest(shardId.index().name(),  shardId.id());                  shardRequest  =  new  MultiTermVectorsShardRequest(request,  shardId.index().name(),  shardId.id());  shardRequest.preference(request.preference);  shardRequests.put(shardId,  shardRequest);  }  shardRequest.add(i,  termVectorRequest);  }  if  (shardRequests.size()  ==  0)  {  	shardRequest  =  new  MultiTermVectorsShardRequest(request,  shardId.index().name(),  shardId.id());  
elasticsearch_403ebc9e07e0fa0da226c354321b75f6a8b173cf	buggy:  nodesFD.updateNodes(buildNodesForA(true));  context:  }  public  void  testNodesFaultDetectionConnectOnDisconnect()  throws  InterruptedException  {  ImmutableSettings.Builder  settings  =  ImmutableSettings.builder();  boolean  shouldRetry  =  randomBoolean();  settings.put( "discovery.zen.fd.connect_on_network_disconnect ",  shouldRetry).put( "discovery.zen.fd.ping_interval ",   "5m ");  NodesFaultDetection  nodesFD  =  new  NodesFaultDetection(settings.build(),  threadPool,  serviceA,  new  ClusterName( "test "));  nodesFD.start();          nodesFD.updateNodes(buildNodesForA(true));          nodesFD.updateNodes(buildNodesForA(true),  -1);  final  String[]  failureReason  =  new  String[1];  final  DiscoveryNode[]  failureNode  =  new  DiscoveryNode[1];  final  CountDownLatch  notified  =  new  CountDownLatch(1);  nodesFD.addListener(new  NodesFaultDetection.Listener()  {  public  void  onNodeFailure(DiscoveryNode  node,  String  reason)  {  failureNode[0]  =  node;  failureReason[0]  =  reason;  	nodesFD.updateNodes(buildNodesForA(true),  -1);  
elasticsearch_c0a7dc327c547e22f45dfc9f25090255969bb3f6	buggy:  return  new  InternalRangeDistanceFacet(facetName,   "_na ",   "_na ",  entries);  context:  for  (RangeFacet.Entry  entry  :  entries)  {  if  (key  >=  entry.getFrom()  &&  key  <  entry.getTo())  {  entry.count++;  entry.total  +=  value;  }  }  }          return  new  InternalRangeDistanceFacet(facetName,   "_na ",   "_na ",  entries);          return  new  InternalRangeFacet(facetName,   "_na ",   "_na ",  entries);  }  }  	return  new  InternalRangeFacet(facetName,   "_na ",   "_na ",  entries);  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "ranges ".equals(currentFieldName))  {  ranges  =  new  ArrayList<RangeAggregator.Range>();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  double  from  =  Double.NEGATIVE_INFINITY;  String  fromAsStr  =  null;  	}  else  if  ( "lang ".equals(currentFieldName))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Document>  docs  =  new  ArrayList<Document>();  context:  public  void  testNestedSortingMax()  throws  IOException  {  testNestedSorting(SortMode.MAX);  }  public  void  testNestedSorting(SortMode  sortMode)  throws  IOException  {  final  String[]  values  =  new  String[randomIntBetween(2,  20)];  for  (int  i  =  0;  i  <  values.length;  ++i)  {  values[i]  =  _TestUtil.randomSimpleString(getRandom());  }  final  int  numParents  =  scaledRandomIntBetween(100,  10000);          List<Document>  docs  =  new  ArrayList<Document>();          List<Document>  docs  =  new  ArrayList<>();  final  OpenBitSet  parents  =  new  OpenBitSet();  for  (int  i  =  0;  i  <  numParents;  ++i)  {  docs.clear();  final  int  numChildren  =  randomInt(4);  for  (int  j  =  0;  j  <  numChildren;  ++j)  {  final  Document  child  =  new  Document();  final  int  numValues  =  randomInt(3);  for  (int  k  =  0;  k  <  numValues;  ++k)  {  	List<Document>  docs  =  new  ArrayList<>();  
elasticsearch_4e5ad568bb000a8026494fbc1e66752eeccc1826	buggy:  return  Integer.compare(o2.order(),  o1.order());  context:  for  (Integer  order  :  orders)  {  TestFilter  testFilter  =  new  TestFilter(order,  randomFrom(Operation.values()));  filters.add(testFilter);  restController.registerFilter(testFilter);  }  ArrayList<RestFilter>  restFiltersByOrder  =  Lists.newArrayList(filters);  Collections.sort(restFiltersByOrder,  new  Comparator<RestFilter>()  {  public  int  compare(RestFilter  o1,  RestFilter  o2)  {                  return  Integer.compare(o2.order(),  o1.order());                  return  Integer.compare(o1.order(),  o2.order());  }  });  List<RestFilter>  expectedRestFilters  =  Lists.newArrayList();  for  (RestFilter  filter  :  restFiltersByOrder)  {  TestFilter  testFilter  =  (TestFilter)  filter;  expectedRestFilters.add(testFilter);  if  (!(testFilter.callback  ==  Operation.CONTINUE_PROCESSING)  )  {  	return  Integer.compare(o1.order(),  o2.order());  
elasticsearch_684e6986279ddbacdacd5470e27eddc25207427e	buggy:  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  context:  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  query  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  innerQuery.setBoost(boost);  innerQuery  =  new  XFilteredQuery(innerQuery,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;  Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);          for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {          for  (DocumentMapper  documentMapper  :  parseContext.mapperService().docMappers(false))  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  	for  (DocumentMapper  documentMapper  :  parseContext.mapperService().docMappers(false))  {  
elasticsearch_4c9cf299e6a127f7a3c7d546e2b65cacb7df0f62	buggy:  existingMappers.put(index,  newMapper);  context:  DocumentMapper  newMapper  =  indexService.mapperService().parse(mappingType,  mappingSource);  newMappers.put(index,  newMapper);  DocumentMapper  existingMapper  =  indexService.mapperService().documentMapper(mappingType);  if  (existingMapper  !=  null)  {  DocumentMapper.MergeResult  mergeResult  =  existingMapper.merge(newMapper,  mergeFlags().simulate(true));  if  (!ignoreConflicts  &&  mergeResult.hasConflicts())  {  throw  new  MergeMappingException(mergeResult.conflicts());  }                      existingMappers.put(index,  newMapper);                      existingMappers.put(index,  existingMapper);  }  }  else  {  throw  new  IndexMissingException(new  Index(index));  }  }  if  (mappingType  ==  null)  {  mappingType  =  newMappers.values().iterator().next().type();  	existingMappers.put(index,  existingMapper);  
elasticsearch_2c2783875e1befec504247f8e843a7c031bba92f	buggy:  ThreadPool  threadPool  =  new  ThreadPool();  context:  iterator  =  actual.iterator();  for  (int  doc  =  iterator.nextDoc();  doc  !=  DocIdSetIterator.NO_MORE_DOCS;  doc  =  iterator.nextDoc())  {  builder.append( "Actual  doc[ ").append(doc).append( "]  with  id  value   ").append(indexSearcher.doc(doc).get(UidFieldMapper.NAME)).append('\n');  }  return  builder.toString();  }  static  SearchContext  createSearchContext(String  indexName,  String  parentType,  String  childType)  throws  IOException  {  final  Index  index  =  new  Index(indexName);  final  CacheRecycler  cacheRecycler  =  new  CacheRecycler(ImmutableSettings.EMPTY);          ThreadPool  threadPool  =  new  ThreadPool();          ThreadPool  threadPool  =  new  ThreadPool( "ChildrenConstantScoreQueryTests ");  final  PageCacheRecycler  pageCacheRecycler  =  new  PageCacheRecycler(ImmutableSettings.EMPTY,  threadPool);  final  BigArrays  bigArrays  =  new  BigArrays(ImmutableSettings.EMPTY,  pageCacheRecycler);  Settings  settings  =  ImmutableSettings.EMPTY;  MapperService  mapperService  =  MapperTestUtils.newMapperService(index,  settings);  IndexFieldDataService  indexFieldDataService  =  new  IndexFieldDataService(index,  new  DummyCircuitBreakerService());  final  IndexService  indexService  =  new  StubIndexService(mapperService);  indexFieldDataService.setIndexService(indexService);  	ThreadPool  threadPool  =  new  ThreadPool( "ChildrenConstantScoreQueryTests ");  
libgdx_dc6c3d91bdb6fe5ee4dd9135c69f9ea48c0d1cf5	buggy:  Gdx.gl.glScissor((int)scissor.x,  (int)scissor.y,  (int)scissor.width,  (int)scissor.height);  context:  float  minY  =  Math.max(parent.y,  scissor.y);  float  maxY  =  Math.min(parent.y  +  parent.height,  scissor.y  +  scissor.height);  if  (maxY  -  minY  <  1)  return  false;  scissor.x  =  minX;  scissor.y  =  minY;  scissor.width  =  maxX  -  minX;  scissor.height  =  Math.max(1,  maxY  -  minY);  }  scissors.add(scissor);  Gdx.gl.glScissor((int)scissor.x,  (int)scissor.y,  (int)scissor.width,  (int)scissor.height);  Gdx.gl.glScissor(Math.round(scissor.x),  Math.round(scissor.y),  Math.round(scissor.width),  Math.round(scissor.height));  return  true;  }  public  static  void  popScissors  ()  {  scissors.pop();  if  (scissors.size  ==  0)  	Gdx.gl.glScissor(Math.round(scissor.x),  Math.round(scissor.y),  Math.round(scissor.width),  Math.round(scissor.height));  
elasticsearch_720e6a6d5b2e952265551438919af2c944dc6e19	buggy:  sb.append( "-----NodeId[ ").append(nodeId).append( "]\n ");  context:  if  (current.shardId().equals(requested.shardId()))  {  return  false;  }  }  return  true;  }  public  String  prettyPrint()  {  StringBuilder  sb  =  new  StringBuilder();          sb.append( "-----NodeId[ ").append(nodeId).append( "]\n ");          sb.append( "-----node_id[ ").append(nodeId).append( "]\n ");  for  (MutableShardRouting  entry  :  shards)  {  sb.append( "-------- ").append(entry.shortSummary()).append('\n');  }  return  sb.toString();  }  }  	sb.append( "-----node_id[ ").append(nodeId).append( "]\n ");  
elasticsearch_3b21759bec0a668970de0ba0ef92af64dc9f866e	buggy:  query  =  currentMapper.fieldQuery(queryText);  context:  return  fieldQueryExtension.query(parseContext,  queryText);  }  currentMapper  =  null;  if  (parseContext.mapperService()  !=  null)  {  MapperService.SmartNameFieldMappers  fieldMappers  =  parseContext.mapperService().smartName(field);  if  (fieldMappers  !=  null)  {  currentMapper  =  fieldMappers.fieldMappers().mapper();  if  (currentMapper  !=  null)  {  Query  query  =  null;  if  (currentMapper.useFieldQueryWithQueryString())  {                          query  =  currentMapper.fieldQuery(queryText);                          query  =  currentMapper.fieldQuery(queryText,  parseContext);  }  if  (query  ==  null)  {  query  =  super.getFieldQuery(currentMapper.names().indexName(),  queryText,  quoted);  }  return  wrapSmartNameQuery(query,  fieldMappers,  parseContext);  }  }  }  	query  =  currentMapper.fieldQuery(queryText,  parseContext);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataIndexTemplateService  indexTemplateService;  ThreadPool  threadPool,  MetaDataIndexTemplateService  indexTemplateService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.indexTemplateService  =  indexTemplateService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.DELETE_INDEX_TEMPLATE;  }  return  new  DeleteIndexTemplateRequest();  	return  ThreadPool.Names.MANAGEMENT;  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  listener.cancled();  context:  input.setSingleLine();  alert.setView(input);  alert.setPositiveButton( "Ok ",  new  DialogInterface.OnClickListener()  {  public  void  onClick  (DialogInterface  dialog,  int  whichButton)  {  listener.input(input.getText().toString());  }  });  alert.setOnCancelListener(new  OnCancelListener()  {  public  void  onCancel(DialogInterface  arg0)  {  listener.cancled();  listener.canceled();  }  });  alert.show();  }  });  }  	listener.canceled();  
libgdx_226527bf6c5daf0274cf4d557d86253dcfeffd12	buggy:  sprite.rotate(90);  context:  sprite.setSize(tileSize,  tileSize);  cache  =  new  SpriteCache(1000,  false);  for  (int  y  =  0;  y  <  tileMapHeight;  y++)  {  cache.beginCache();  for  (int  x  =  0;  x  <  tileMapWidth;  x++)  {  sprite.setPosition(x  *  tileSize,  y  *  tileSize);  cache.add(sprite);  }  cache.endCache();  sprite.rotate(90);  sprite.rotate90(true);  }  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  cache.begin();  for  (int  y  =  1;  y  <  tileMapHeight  -  1;  y++)  cache.draw(y,  1,  tileMapWidth  -  2);  	sprite.rotate90(true);  
elasticsearch_2bb31fe74037a7ee2a04c9a994bc4bacbc8e8102	buggy:  return  new  BroadcastPingResponse(successfulShards,  failedShards,  shardFailures);  context:  }  else  if  (shardResponse  instanceof  BroadcastShardOperationFailedException)  {  failedShards++;  if  (shardFailures  ==  null)  {  shardFailures  =  newArrayList();  }  shardFailures.add(new  DefaultShardOperationFailedException((BroadcastShardOperationFailedException)  shardResponse));  }  else  {  successfulShards++;  }  }          return  new  BroadcastPingResponse(successfulShards,  failedShards,  shardFailures);          return  new  BroadcastPingResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  return  new  BroadcastShardPingRequest();  }  return  new  BroadcastShardPingRequest(shard.index(),  shard.id());  	return  new  BroadcastPingResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  
elasticsearch_aecadfcc61a0182f233d0ba3a1a3ba23c0c9b01c	buggy:  for  (Collector  queryCollector  :  percolateCollector.facetCollectors)  {  context:  }  };  private  void  queryBasedPercolating(Engine.Searcher  percolatorSearcher,  PercolateContext  context,  QueryCollector  percolateCollector)  throws  IOException  {  Filter  percolatorTypeFilter  =  context.indexService().mapperService().documentMapper(TYPE_NAME).typeFilter();  percolatorTypeFilter  =  context.indexService().cache().filter().cache(percolatorTypeFilter);  FilteredQuery  query  =  new  FilteredQuery(context.percolateQuery(),  percolatorTypeFilter);  percolatorSearcher.searcher().search(query,  percolateCollector);          for  (Collector  queryCollector  :  percolateCollector.facetCollectors)  {          for  (Collector  queryCollector  :  percolateCollector.facetAndAggregatorCollector)  {  if  (queryCollector  instanceof  XCollector)  {  ((XCollector)  queryCollector).postCollection();  }  }  if  (context.facets()  !=  null)  {  facetPhase.execute(context);  }  if  (context.aggregations()  !=  null)  {  	for  (Collector  queryCollector  :  percolateCollector.facetAndAggregatorCollector)  {  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.ignoreIndices(),  true);  context:  transportService.registerHandler(SearchAction.NAME,  new  TransportHandler());  }  protected  void  doExecute(SearchRequest  searchRequest,  ActionListener<SearchResponse>  listener)  {  if  (optimizeSingleShard  &&  searchRequest.searchType()  !=  SCAN  &&  searchRequest.searchType()  !=  COUNT)  {  try  {  ClusterState  clusterState  =  clusterService.state();                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.ignoreIndices(),  true);                  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.indicesOptions());  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting(searchRequest.routing(),  searchRequest.indices());  int  shardCount  =  clusterService.operationRouting().searchShardsCount(clusterState,  searchRequest.indices(),  concreteIndices,  routingMap,  searchRequest.preference());  if  (shardCount  ==  1)  {  searchRequest.searchType(QUERY_AND_FETCH);  }  }  catch  (IndexMissingException  e)  {  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(searchRequest.indices(),  searchRequest.indicesOptions());  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  client(),  new  String[]  {INDEX_NAME},  cluster().size(),  null)).actionGet();  context:  private  static  final  String  INDEX_NAME  =   "test_index ";  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.builder().put( "node.bench ",  false).build();  }  public  void  testSubmitBenchmarkNegative()  {  client().bench(BenchmarkTestUtil.randomRequest(                  client(),  new  String[]  {INDEX_NAME},  cluster().size(),  null)).actionGet();                  client(),  new  String[]  {INDEX_NAME},  internalCluster().size(),  null)).actionGet();  }  public  void  testListBenchmarkNegative()  {  final  BenchmarkStatusResponse  response  =  client().prepareBenchStatus().execute().actionGet();  assertThat(response.benchmarkResponses().size(),  equalTo(0));  }  	client(),  new  String[]  {INDEX_NAME},  internalCluster().size(),  null)).actionGet();  
elasticsearch_526b46402530817f63c4c70ed382fee34b8b7cf3	buggy:  Set<String>  matches  =  documentMapper.mappers().simpleMatchToFullName(fieldName);  context:  public  void  run()  {  Set<String>  nodes  =  internalCluster().nodesInclude(index);  assertThat(nodes,  Matchers.not(Matchers.emptyIterable()));  for  (String  node  :  nodes)  {  IndicesService  indicesService  =  internalCluster().getInstance(IndicesService.class,  node);  IndexService  indexService  =  indicesService.indexService(index);  assertThat( "index  service  doesn't  exists  on   "  +  node,  indexService,  notNullValue());  DocumentMapper  documentMapper  =  indexService.mapperService().documentMapper(type);  assertThat( "document  mapper  doesn't  exists  on   "  +  node,  documentMapper,  notNullValue());  for  (String  fieldName  :  fieldNames)  {                          Set<String>  matches  =  documentMapper.mappers().simpleMatchToFullName(fieldName);                          List<String>  matches  =  documentMapper.mappers().simpleMatchToFullName(fieldName);  assertThat( "field   "  +  fieldName  +   "  doesn't  exists  on   "  +  node,  matches,  Matchers.not(emptyIterable()));  }  }  }  });  waitForMappingOnMaster(index,  type,  fieldNames);  }  	List<String>  matches  =  documentMapper.mappers().simpleMatchToFullName(fieldName);  
elasticsearch_1f9bceb5c54dfeade0326b90b74c39fe6ffe8aae	buggy:  handler.handleException(new  TransportException( " ",  new  InternalException(action,  request.getHeaders())));  context:  public  InternalTransportService(Settings  settings,  Transport  transport,  ThreadPool  threadPool)  {  super(settings,  transport,  threadPool);  }  public  <T  extends  TransportResponse>  void  sendRequest(DiscoveryNode  node,  String  action,  TransportRequest  request,  TransportRequestOptions  options,  TransportResponseHandler<T>  handler)  {  if  (NodesInfoAction.NAME.equals(action))  {  ((TransportResponseHandler<NodesInfoResponse>)  handler).handleResponse(new  NodesInfoResponse(ClusterName.DEFAULT,  new  NodeInfo[0]));  return;  }              handler.handleException(new  TransportException( " ",  new  InternalException(action,  request.getHeaders())));              handler.handleException(new  TransportException( " ",  new  InternalException(action,  request)));  }  public  boolean  nodeConnected(DiscoveryNode  node)  {  assertThat((LocalTransportAddress)  node.getAddress(),  equalTo(address));  return  true;  }  	handler.handleException(new  TransportException( " ",  new  InternalException(action,  request)));  
elasticsearch_22ea5e660888f363969d444e4fc8b6adfcfd7a27	buggy:  throw  new  IllegalShardRoutingStateException(this,   "Already  primary,  can't  move  to  backup ");  context:  public  void  moveToPrimary()  {  if  (primary)  {  throw  new  IllegalShardRoutingStateException(this,   "Already  primary,  can't  move  to  primary ");  }  primary  =  true;  }  public  void  moveFromPrimary()  {  if  (!primary)  {              throw  new  IllegalShardRoutingStateException(this,   "Already  primary,  can't  move  to  backup ");              throw  new  IllegalShardRoutingStateException(this,   "Already  primary,  can't  move  to  replica ");  }  primary  =  false;  }  }  	throw  new  IllegalShardRoutingStateException(this,   "Already  primary,  can't  move  to  replica ");  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  putMappingRequest.source(request.contentAsString());  context:  controller.registerHandler(POST,   "/{index}/_mapping ",  this);  controller.registerHandler(POST,   "/{index}/{type}/_mapping ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  PutMappingRequest  putMappingRequest  =  putMappingRequest(splitIndices(request.param( "index ")));  putMappingRequest.listenerThreaded(false);  putMappingRequest.type(request.param( "type "));          putMappingRequest.source(request.contentAsString());          putMappingRequest.source(request.content().toUtf8());  putMappingRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));  putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignore_conflicts ",  putMappingRequest.ignoreConflicts()));  client.admin().indices().putMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  public  void  onResponse(PutMappingResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject()  	putMappingRequest.source(request.content().toUtf8());  
libgdx_504d68c027e371fe01cf897125e2fd8c20339b39	buggy:  new  LwjglApplication(new  com.badlogic.gdx.tests.CullTest(),  config);  context:  package  com.badlogic.gdx.tests.lwjgl;  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  new  LwjglApplication(new  com.badlogic.gdx.tests.CullTest(),  config);  new  LwjglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  }  }  	new  LwjglApplication(new  com.badlogic.gdx.tests.InputTest(),  config);  
libgdx_34ed5fbfe5d918ed411939d351930b0ab1457dd2	buggy:  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  context:  vertices[idx++]  =  frame.vertices[idxV++];  }  Keyframe  keyFrame  =  new  Keyframe(frameNum  *  frameDuration,  vertices);  animation.keyframes[frameNum]  =  keyFrame;  }  Mesh  mesh  =  new  Mesh(false,  header.numVertices,  indices.length,  new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE),  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  mesh.setIndices(indices);  ObjectMap<String,  KeyframedAnimation>  animations  =  new  ObjectMap<String,  KeyframedAnimation>();  animations.put( "all ",  animation);  KeyframedSubMesh  subMesh  =  new  KeyframedSubMesh( "md2-mesh ",  mesh,  blendedVertices,  animations,  3,  GL10.GL_TRIANGLES);  KeyframedModel  model  =  new  KeyframedModel(new  KeyframedSubMesh[]  {subMesh});  model.setAnimation( "all ",  0,  false);  return  model;  	new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  void  handleException(RemoteTransportException  exp);  context:  T  newInstance();  void  handleResponse(T  response);      void  handleException(RemoteTransportException  exp);      void  handleException(TransportException  exp);  boolean  spawn();  }  	void  handleException(TransportException  exp);  
elasticsearch_c989d3a928b6bfc526dc5e21161fb31f058f77dc	buggy:  int  utflen  =  readUnsignedShort();  context:  pos  =  0;  }  }  public  String  readUTF()  throws  IOException  {          int  utflen  =  readUnsignedShort();          int  utflen  =  readInt();  if  (utflen  ==  0)  {  return   " ";  }  if  (chararr.length  <  utflen)  {  chararr  =  new  char[utflen  *  2];  }  char[]  chararr  =  this.chararr;  byte[]  bytearr  =  buf;  	int  utflen  =  readInt();  
elasticsearch_7db5e63ab76dd58abd0250864fc43ed1cdb7486e	buggy:  ShardsIterator  shardsIt();  context:  boolean  primary();  String  shortSummary();      ShardsIterator  shardsIt();      ShardIterator  shardsIt();  void  writeToThin(StreamOutput  out)  throws  IOException;  void  readFromThin(StreamInput  in)  throws  ClassNotFoundException,  IOException;  }  	ShardIterator  shardsIt();  
libgdx_52ae94eb6fe9e481c8c6df3557257b352dd7d92f	buggy:  cppFile.writeString(buffer.toString(),  false);  context:  buffer.append(line);  }  index  =  javaFileContent.indexOf(JAVA_JNI_MARKER,  endIndex);  }  for(int  i  =  0;  i  <  javaMethods.size();  i++)  {  mergeJavaAndCMethod(buffer,  javaMethods.get(i),  cMethods.get(i));  buffer.append( "\n ");  }  cppFile.writeString(buffer.toString(),  false);  cppFile.writeString(buffer.toString(),  false,   "UTF-8 ");  }  private  void  mergeJavaAndCMethod(StringBuffer  buffer,  JavaMethod  javaMethod,  CMethod  cMethod)  {  buffer.append(cMethod.head);  buffer.append( "\n(JNIEnv*  env,  jclass  clazz,   ");  for(int  i  =  0;  i  <  javaMethod.arguments.size();  i++)  {  Argument  javaArg  =  javaMethod.arguments.get(i);  	cppFile.writeString(buffer.toString(),  false,   "UTF-8 ");  
libgdx_55c68e81adde8f159ae95fb32db1cc91d70296af	buggy:  centroid.y  =  (x1  +  x2  +  x3)  /  3;  context:  float  denom  =  dir.dot(plane.getNormal());  float  t  =  -(start.dot(plane.getNormal())  +  plane.getD())  /  denom;  if  (t  <  0  ||  t  >  1)  return  false;  intersection.set(start).add(dir.scl(t));  return  true;  }  public  static  Vector2  triangleCentroid  (float  x1,  float  y1,  float  x2,  float  y2,  float  x3,  float  y3,  Vector2  centroid)  {  centroid.x  =  (x1  +  x2  +  x3)  /  3;  centroid.y  =  (x1  +  x2  +  x3)  /  3;  centroid.y  =  (y1  +  y2  +  y3)  /  3;  return  centroid;  }  public  static  Vector2  quadrilateralCentroid  (float  x1,  float  y1,  float  x2,  float  y2,  float  x3,  float  y3,  float  x4,  float  y4,  Vector2  centroid)  {  float  avgX1  =  (x1  +  x2  +  x3)  /  3;  float  avgY1  =  (y1  +  y2  +  y3)  /  3;  float  avgX2  =  (x1  +  x4  +  x3)  /  3;  	centroid.y  =  (y1  +  y2  +  y3)  /  3;  
elasticsearch_ee585ad96c96040fccca79524e3c1f53d6294bd3	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  IndicesService  indicesService;  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.STATS;  }  return   "indices/stats/shard ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_a7542247516d594f612044f33b95db39d27c5393	buggy:  NodeStats  nodeStats  =  nodeService.stats(CommonStatsFlags.NONE,  false,  true,  true,  false,  false,  true,  false,  false);  context:  }  protected  ClusterStatsNodeResponse  newNodeResponse()  {  return  new  ClusterStatsNodeResponse();  }  protected  ClusterStatsNodeResponse  nodeOperation(ClusterStatsNodeRequest  nodeRequest)  throws  ElasticSearchException  {  NodeInfo  nodeInfo  =  nodeService.info(false,  true,  false,  true,  false,  false,  true,  false,  true);          NodeStats  nodeStats  =  nodeService.stats(CommonStatsFlags.NONE,  false,  true,  true,  false,  false,  true,  false,  false);          NodeStats  nodeStats  =  nodeService.stats(CommonStatsFlags.NONE,  false,  true,  true,  false,  false,  true,  false,  false,  false);  List<ShardStats>  shardsStats  =  new  ArrayList<ShardStats>();  for  (String  index  :  indicesService.indices())  {  IndexService  indexService  =  indicesService.indexService(index);  if  (indexService  ==  null)  {  continue;  }  for  (IndexShard  indexShard  :  indexService)  {  if  (indexShard.routingEntry().active())  {  	NodeStats  nodeStats  =  nodeService.stats(CommonStatsFlags.NONE,  false,  true,  true,  false,  false,  true,  false,  false,  false);  
elasticsearch_71de2bc414b56462086ec03e5d1ac4888e941bfc	buggy:   "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ");  context:  return  this;  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TestCluster.TESTS_ENABLE_MOCK_MODULES,                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ");                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  return  this;  }  protected  ReproduceErrorMessageBuilder  appendProperties(String...  properties)  {  for  (String  sysPropName  :  properties)  {  	 "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ",   "tests.heap.size ");  
elasticsearch_8eab5ec5286475b5c0602d8c230947c781db6596	buggy:  .setQuery(filteredQuery(matchAllQuery(),  rangeFilter( "field ").from(System.currentTimeMillis())))  context:  client.prepareIndex( "test ",   "type1 ").setSource( "field ",  System.currentTimeMillis()).execute().actionGet();  }  }  };  indexingThread.start();  Thread  searchThread  =  new  Thread()  {  while  (!stop.get())  {  client.prepareSearch()                              .setQuery(filteredQuery(matchAllQuery(),  rangeFilter( "field ").from(System.currentTimeMillis())))                              .setQuery(filteredQuery(matchAllQuery(),  rangeFilter( "field ").from(System.currentTimeMillis()  -  1000000)))  .execute().actionGet();  }  }  };  searchThread.start();  }  }  	.setQuery(filteredQuery(matchAllQuery(),  rangeFilter( "field ").from(System.currentTimeMillis()  -  1000000)))  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  threadPool.execute(new  Runnable()  {  context:  if  (indexShard.state()  ==  IndexShardState.CLOSED)  {  listener.onIgnoreRecovery( "shard  closed ");  return;  }  if  (!indexShard.routingEntry().primary())  {  listener.onRecoveryFailed(new  IndexShardGatewayRecoveryException(shardId,   "Trying  to  recover  when  the  shard  is  in  backup  state ",  null));  return;  }          threadPool.execute(new  Runnable()  {          threadPool.cached().execute(new  Runnable()  {  indexShard.recovering();  StopWatch  throttlingWaitTime  =  new  StopWatch().start();  while  (!recoveryThrottler.tryRecovery(shardId,   "gateway "))  {  try  {  	threadPool.cached().execute(new  Runnable()  {  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  byte[]  data  =  os.copiedByteArray();  context:  gen.writeFieldName( "source ");  gen.writeStartObject();  gen.writeStringField( "value ",   "something ");  gen.writeEndObject();  gen.writeEndObject();  gen.close();          byte[]  data  =  os.copiedByteArray();          byte[]  data  =  os.bytes().toBytes();  JsonParser  parser  =  new  JsonFactory().createJsonParser(data);  assertThat(parser.nextToken(),  equalTo(JsonToken.START_OBJECT));  assertThat(parser.nextToken(),  equalTo(JsonToken.FIELD_NAME));  //   "index "  assertThat(parser.nextToken(),  equalTo(JsonToken.VALUE_STRING));  assertThat(parser.nextToken(),  equalTo(JsonToken.FIELD_NAME));  //   "source "  	byte[]  data  =  os.bytes().toBytes();  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  request.listenerThreaded(false);  if  (request.operationThreading()  ==  BroadcastOperationThreading.NO_THREADS)  {  request.operationThreading(BroadcastOperationThreading.SINGLE_THREAD);  }  execute(request,  new  ActionListener<Response>()  {  public  void  onResponse(Response  response)  {  try  {  channel.sendResponse(response);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  final  String  concreteIndex  =  clusterState.metaData().concreteIndex(request.index());  context:  this.transportService  =  transportService;  transportService.registerHandler(MoreLikeThisAction.NAME,  new  TransportHandler());  }  protected  void  doExecute(final  MoreLikeThisRequest  request,  final  ActionListener<SearchResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();          final  String  concreteIndex  =  clusterState.metaData().concreteIndex(request.index());          final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index());  Iterable<MutableShardRouting>  routingNode  =  clusterState.getRoutingNodes().routingNodeIter(clusterService.localNode().getId());  if  (routingNode  ==  null)  {  redirect(request,  concreteIndex,  listener,  clusterState);  return;  }  boolean  hasIndexLocally  =  false;  for  (MutableShardRouting  shardRouting  :  routingNode)  {  	final  String  concreteIndex  =  clusterState.metaData().concreteSingleIndex(request.index());  
libgdx_dc782167843974cc9267e8ecc8a05534b8bae963	buggy:  else  processor.touchMoved(mouseX,  mouseY);  context:  this.mouseY  +=  getMovementYJSNI(e);  }  else  {  this.deltaX  =  (int)getRelativeX(e,  canvas)  -  mouseX;  this.deltaY  =  (int)getRelativeY(e,  canvas)  -  mouseY;  this.mouseX  =  (int)getRelativeX(e,  canvas);  this.mouseY  =  (int)getRelativeY(e,  canvas);  }  this.currentEventTimeStamp  =  TimeUtils.nanoTime();  if(processor  !=  null)  {  if(touched)  processor.touchDragged(mouseX,  mouseY,  0);  else  processor.touchMoved(mouseX,  mouseY);  else  processor.mouseMoved(mouseX,  mouseY);  }  }  if(e.getType().equals( "mouseup "))  {  if(!touched)  return;  this.pressedButtons.remove(getButton(e.getButton()));  this.touched  =  pressedButtons.size()  >  0;  if(isCursorCatched())  {  	else  processor.mouseMoved(mouseX,  mouseY);  
libgdx_633ee79f66365887d4699e8aa6b6131793f41fbb	buggy:  badlogicSmall.getRegion().flip(true,  true);  context:  public  void  create  ()  {  batch  =  new  SpriteBatch();  atlas  =  new  TextureAtlas(Gdx.files.internal( "data "));  badlogic  =  atlas.getSprite( "badlogicslice ");  badlogic.setPosition(50,  50);  badlogicSmall  =  atlas.getSprite( "badlogicsmall ");  badlogicSmall.setPosition(10,  10);  badlogicSmall.getRegion().flip(true,  true);  badlogicSmall.flip(true,  true);  AtlasRegion  region  =  atlas.getRegion( "badlogicsmall ");  star  =  atlas.getSprite( "particle-star ");  star.setPosition(10,  70);  	badlogicSmall.flip(true,  true);  
elasticsearch_b35dfd3aa7245c02154034a616fbef075c29aa10	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  concreteIndices,  request.queryHint(),  null,  null);  context:  return   "/cluster/ping/broadcast/shard ";  }  return  new  BroadcastPingRequest();  }          return  clusterService.operationRouting().searchShards(clusterState,  concreteIndices,  request.queryHint(),  null,  null);          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  request.queryHint(),  null,  null);  }  int  successfulShards  =  0;  int  failedShards  =  0;  List<ShardOperationFailedException>  shardFailures  =  null;  for  (int  i  =  0;  i  <  shardsResponses.length();  i++)  {  Object  shardResponse  =  shardsResponses.get(i);  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  request.queryHint(),  null,  null);  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  listeners.add(listener);  }  public  void  remove(Listener  listener)  {  listeners.remove(listener);  }  public  void  nodeIndexCreated(final  String  index,  final  String  nodeId)  throws  ElasticSearchException  {  DiscoveryNodes  nodes  =  clusterService.state().nodes();  if  (nodes.localNodeMaster())  {              threadPool.cached().execute(new  Runnable()  {              threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  innerNodeIndexCreated(index,  nodeId);  }  });  }  else  {  transportService.sendRequest(clusterService.state().nodes().masterNode(),  NodeIndexCreatedTransportHandler.ACTION,  new  NodeIndexCreatedMessage(index,  nodeId),  VoidTransportResponseHandler.INSTANCE_SAME);  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  HashMap<String,Bucket>topWords=new  HashMap<String,Bucket>();  context:  .addAggregation(new  SignificantTermsBuilder( "mySignificantTerms ").field( "description ")  .minDocCount(2))  .execute()  .actionGet();  SignificantTerms  topTerms  =  response.getAggregations().get( "mySignificantTerms ");  checkExpectedStringTermsFound(topTerms);  }  private  void  checkExpectedStringTermsFound(SignificantTerms  topTerms)  {          HashMap<String,Bucket>topWords=new  HashMap<String,Bucket>();          HashMap<String,Bucket>topWords=new  HashMap<>();  for  (Bucket  topTerm  :  topTerms  ){  topWords.put(topTerm.getKey(),topTerm);  }  assertTrue(  topWords.containsKey( "haakonsen "));  assertTrue(  topWords.containsKey( "craig "));  assertTrue(  topWords.containsKey( "kelly "));  assertTrue(  topWords.containsKey( "burton "));  assertTrue(  topWords.containsKey( "snowboards "));  	HashMap<String,Bucket>topWords=new  HashMap<>();  
elasticsearch_64358948eff4e3b75134dc9e2776e9dc5a39e156	buggy:  AsyncAction.this.shardFailures.add(new  ShardSearchFailure(t));  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  public  void  onFailure(Throwable  t)  {  if  (logger.isDebugEnabled())  {  }                      AsyncAction.this.shardFailures.add(new  ShardSearchFailure(t));                      AsyncAction.this.addShardFailure(new  ShardSearchFailure(t));  successulOps.decrementAndGet();  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  	AsyncAction.this.addShardFailure(new  ShardSearchFailure(t));  
elasticsearch_397f442c6dabf5cd2105ba01d6864fbbb22d11e2	buggy:  indexShard.start( "post  recovery  from  gateway,  no  translog ");  context:  }  }  throw  new  IndexShardGatewayRecoveryException(shardId,   "No  commit  point  data  is  available  in  gateway ",  null);  }  private  void  recoverTranslog(CommitPoint  commitPoint,  ImmutableMap<String,  BlobMetaData>  blobs)  throws  IndexShardGatewayRecoveryException  {  if  (commitPoint.translogFiles().isEmpty())  {  recoveryStatus.start().startTime(System.currentTimeMillis());  recoveryStatus.updateStage(RecoveryStatus.Stage.START);              indexShard.start( "post  recovery  from  gateway,  no  translog ");              indexShard.postRecovery( "post  recovery  from  gateway,  no  translog ");  recoveryStatus.start().time(System.currentTimeMillis()  -  recoveryStatus.start().startTime());  recoveryStatus.start().checkIndexTime(indexShard.checkIndexTook());  return;  }  try  {  recoveryStatus.start().startTime(System.currentTimeMillis());  recoveryStatus.updateStage(RecoveryStatus.Stage.START);  	indexShard.postRecovery( "post  recovery  from  gateway,  no  translog ");  
libgdx_9349f129ed8dbced7c9e3f2d0bd0f83d7a092f1f	buggy:  Gdx.app.log( "PixmaPackerTest ",   "Number  of  textures:   "  +  atlas.getTextures().size());  context:  PixmapPacker  packer  =  new  PixmapPacker(1024,  1024,  Format.RGBA8888,  2,  true);  packer.pack( "badlogic ",  pixmap1);  packer.pack( "wheel ",  pixmap1);  packer.pack( "egg ",  pixmap1);  pixmap1.dispose();  pixmap2.dispose();  pixmap3.dispose();  atlas  =  packer.generateTextureAtlas(TextureFilter.Nearest,  TextureFilter.Nearest,  false);  Gdx.app.log( "PixmaPackerTest ",   "Number  of  textures:   "  +  atlas.getTextures().size());  Gdx.app.log( "PixmaPackerTest ",   "Number  of  textures:   "  +  atlas.getTextures().size);  }  public  void  render  ()  {  }  	Gdx.app.log( "PixmaPackerTest ",   "Number  of  textures:   "  +  atlas.getTextures().size);  
elasticsearch_771225ccc9dfc5eef5ccbca4dfbd2fc2400be39a	buggy:  clear();  context:  changed  =  true;  ResidentFieldDataCache.this.maxSize  =  maxSize;  }  if  (!Objects.equal(expire,  ResidentFieldDataCache.this.expire))  {  changed  =  true;  ResidentFieldDataCache.this.expire  =  expire;  }  if  (changed)  {                  clear();                  clear( "update_settings ");  }  }  }  }  	clear( "update_settings ");  
elasticsearch_3ee9f27fbe8a90c8ab38543300766811f6e6dfa0	buggy:  listener.onResponse(new  ClusterStateUpdateResponse(true));  context:  return  true;  }  public  void  onAllNodesAcked(@Nullable  Throwable  t)  {  listener.onResponse(new  ClusterStateUpdateResponse(true));  }  public  void  onAckTimeout()  {                  listener.onResponse(new  ClusterStateUpdateResponse(true));                  listener.onResponse(new  ClusterStateUpdateResponse(false));  }  public  TimeValue  ackTimeout()  {  return  request.ackTimeout();  }  	listener.onResponse(new  ClusterStateUpdateResponse(false));  
elasticsearch_b113eb18fe25c6b36595b8bbc84807b574c459fa	buggy:  BytesStream  bos  =  sourceBuilder.buildAsUnsafeBytes(Requests.CONTENT_TYPE);  context:  searchSourceOffset  =  0;  searchSourceUnsafe  =  false;  }  }  public  MoreLikeThisRequest  searchSource(SearchSourceBuilder  sourceBuilder)  {          BytesStream  bos  =  sourceBuilder.buildAsUnsafeBytes(Requests.CONTENT_TYPE);          BytesStream  bos  =  sourceBuilder.buildAsBytesStream(Requests.CONTENT_TYPE);  this.searchSource  =  bos.underlyingBytes();  this.searchSourceOffset  =  0;  this.searchSourceLength  =  bos.size();  this.searchSourceUnsafe  =  true;  return  this;  }  	BytesStream  bos  =  sourceBuilder.buildAsBytesStream(Requests.CONTENT_TYPE);  
elasticsearch_3ddbc6469a3f2e57255dafaa4cf519ea3802f9b9	buggy:  throw  new  MapperParsingException( "Wrong  value  for  pathType  [ "  +  path  +   "]  for  objet  [ "  +  name  +   "] ");  context:  }  }  public  static  ContentPath.Type  parsePathType(String  name,  String  path)  throws  MapperParsingException  {  path  =  Strings.toUnderscoreCase(path);  if  ( "just_name ".equals(path))  {  return  ContentPath.Type.JUST_NAME;  }  else  if  ( "full ".equals(path))  {  return  ContentPath.Type.FULL;  }  else  {              throw  new  MapperParsingException( "Wrong  value  for  pathType  [ "  +  path  +   "]  for  objet  [ "  +  name  +   "] ");              throw  new  MapperParsingException( "Wrong  value  for  pathType  [ "  +  path  +   "]  for  object  [ "  +  name  +   "] ");  }  }  }  	throw  new  MapperParsingException( "Wrong  value  for  pathType  [ "  +  path  +   "]  for  object  [ "  +  name  +   "] ");  
elasticsearch_2259ef671b2fd9656d039440cd6525e30f6abe67	buggy:  out.write(b);  context:  public  class  DataOutputStreamOutput  extends  StreamOutput  {  private  final  DataOutput  out;  public  DataOutputStreamOutput(DataOutput  out)  {  this.out  =  out;  }          out.write(b);          out.writeByte(b);  }  out.write(b,  offset,  length);  }  	out.writeByte(b);  
elasticsearch_b0e44a2b40bfc3c8bed6eb3f20c497b2b3226d1e	buggy:  ScriptTermsStringFieldFacetExecutor.this.total  =  missing;  context:  total++;  }  else  {  missing++;  }  }  }  public  void  postCollection()  {  ScriptTermsStringFieldFacetExecutor.this.missing  =  missing;              ScriptTermsStringFieldFacetExecutor.this.total  =  missing;              ScriptTermsStringFieldFacetExecutor.this.total  =  total;  }  private  boolean  match(String  value)  {  if  (excluded  !=  null  &&  excluded.contains(new  BytesRef(value)))  {  return  false;  }  if  (matcher  !=  null  &&  !matcher.reset(value).matches())  {  return  false;  	ScriptTermsStringFieldFacetExecutor.this.total  =  total;  
libgdx_ae45ffe4ebe41482453af5e1245f4a93f57ae3b4	buggy:  font  =  new  BitmapFont();  context:  public  class  FlickScrollPaneTest  extends  GdxTest  {  private  Stage  stage;  private  BitmapFont  font;  private  Table  container;  public  void  create  ()  {  stage  =  new  Stage(0,  0,  false);  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  Gdx.input.setInputProcessor(stage);  Gdx.graphics.setVSync(false);  container  =  new  Table();  stage.addActor(container);  container.getTableLayout().debug();  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  return  new  ShortArrayAtomicFieldData.SingleFixedSet(sValues,  reader.maxDoc(),  set);  }  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  ShortArrayAtomicFieldData.WithOrdinals(  values.toArray(new  short[values.size()]),  reader.maxDoc(),                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  return  new  ShortValuesComparatorSource(this,  missingValue);  }  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_c05df433c6ff92b69a2acaa411c1b66e537e0811	buggy:  return  new  Term(names.indexName(),  uid);  context:  return  value;  }  return  term(Uid.createUid(type,  id));  }          return  new  Term(names.indexName(),  uid);          return  termFactory.createTerm(uid);  }  fieldCache.remove();  }  return  CONTENT_TYPE;  	return  termFactory.createTerm(uid);  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(TermsFacetCollectorParser.NAME);  context:  params.put(name,  value);  return  this;  }  if  (fieldName  ==  null  &&  fieldsNames  ==  null  &&  script  ==  null)  {  throw  new  SearchSourceBuilderException( "field/fields/script  must  be  set  on  terms  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(TermsFacetCollectorParser.NAME);          builder.startObject(TermsFacet.TYPE);  if  (fieldsNames  !=  null)  {  if  (fieldsNames.length  ==  1)  {  builder.field( "field ",  fieldsNames[0]);  }  else  {  builder.field( "fields ",  fieldsNames);  }  }  else  if  (fieldName  !=  null)  {  builder.field( "field ",  fieldName);  	builder.startObject(TermsFacet.TYPE);  
elasticsearch_9addac830089e48bdcd77a5cc972d85808d863e5	buggy:  Explanation  functionExplanation  =  filterFunction.function.explainScore(doc,  subQueryExpl);  context:  if  (!subQueryExpl.isMatch())  {  return  subQueryExpl;  }  List<ComplexExplanation>  filterExplanations  =  new  ArrayList<>();  for  (FilterFunction  filterFunction  :  filterFunctions)  {  Bits  docSet  =  DocIdSets.toSafeBits(context.reader(),  filterFunction.filter.getDocIdSet(context,  context.reader().getLiveDocs()));  if  (docSet.get(doc))  {  filterFunction.function.setNextReader(context);                      Explanation  functionExplanation  =  filterFunction.function.explainScore(doc,  subQueryExpl);                      Explanation  functionExplanation  =  filterFunction.function.explainScore(doc,  subQueryExpl.getValue());  double  factor  =  functionExplanation.getValue();  float  sc  =  CombineFunction.toFloat(factor);  ComplexExplanation  filterExplanation  =  new  ComplexExplanation(true,  sc,   "function  score,  product  of: ");  filterExplanation.addDetail(new  Explanation(1.0f,   "match  filter:   "  +  filterFunction.filter.toString()));  filterExplanation.addDetail(functionExplanation);  filterExplanations.add(filterExplanation);  }  }  	Explanation  functionExplanation  =  filterFunction.function.explainScore(doc,  subQueryExpl.getValue());  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  boolean  seenTest1  =  false;  boolean  seenTest2  =  false;  for  (ClusterSearchShardsGroup  group  :  response.getGroups())  {  if  (group.getIndex().equals( "test1 "))  {  seenTest1  =  true;  assertThat(group.getShards().length,  equalTo(2));  }  else  if  (group.getIndex().equals( "test2 "))  {  seenTest2  =  true;  assertThat(group.getShards().length,  equalTo(2));  }  else  {                  assert  false;                  fail();  }  }  assertThat(seenTest1,  equalTo(true));  assertThat(seenTest2,  equalTo(true));  assertThat(response.getNodes().length,  equalTo(2));  }  }  	fail();  
libgdx_9349f129ed8dbced7c9e3f2d0bd0f83d7a092f1f	buggy:  Array<AssetDescriptor>  deps  =  Array.of(AssetDescriptor.class);  context:  public  class  BitmapFontLoader  extends  AsynchronousAssetLoader<BitmapFont,  BitmapFontLoader.BitmapFontParameter>  {  public  BitmapFontLoader  (FileHandleResolver  resolver)  {  super(resolver);  }  BitmapFontData  data;  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  file,  BitmapFontParameter  parameter)  {  Array<AssetDescriptor>  deps  =  Array.of(AssetDescriptor.class);  Array<AssetDescriptor>  deps  =  new  Array();  if  (parameter  !=  null  &&  parameter.bitmapFontData  !=  null)  {  data  =  parameter.bitmapFontData;  return  deps;  }  data  =  new  BitmapFontData(file,  parameter  !=  null  ?  parameter.flip  :  false);  for  (int  i=0;  i<data.getImagePaths().length;  i++)  {  deps.add(new  AssetDescriptor(data.getImagePath(i),  Texture.class));  }  	Array<AssetDescriptor>  deps  =  new  Array();  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));  context:  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  No  mapping  for  for  type  [ "  +  childType  +   "] ");  }  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  HasChildFilter  childFilter  =  new  HasChildFilter(query,  scope,  childType,  parentType,  searchContext);  ConstantScoreQuery  childQuery  =  new  ConstantScoreQuery(childFilter);  childQuery.setBoost(boost);  searchContext.addScopePhase(childFilter);  return  childQuery;  	query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  
elasticsearch_918da65d357df0d1b3a2fe046c9a2dcc1a9d3a0f	buggy:  throw  new  RestTestParseException( "duplicate  test  section  [ "  +  testSection.getName()  +   "]  found  in  [ "  +  restTestSuite.getDescription()  +   "] ");  context:  if(parser.currentToken()  ==  null)  {  if  (parser.nextToken()  ==  null)  {  break;  }  }  TestSection  testSection  =  parseContext.parseTestSection();  if  (!restTestSuite.addTestSection(testSection))  {                  throw  new  RestTestParseException( "duplicate  test  section  [ "  +  testSection.getName()  +   "]  found  in  [ "  +  restTestSuite.getDescription()  +   "] ");                  throw  new  RestTestParseException( "duplicate  test  section  [ "  +  testSection.getName()  +   "]  found  in  [ "  +  restTestSuite.getPath()  +   "] ");  }  }  return  restTestSuite;  }  }  	throw  new  RestTestParseException( "duplicate  test  section  [ "  +  testSection.getName()  +   "]  found  in  [ "  +  restTestSuite.getPath()  +   "] ");  
elasticsearch_4c8978237fdb07ed81fc7cb0255f43cfe7c1f490	buggy:  return  indicesService.searchShards(clusterState,  request.indices(),  request.queryHint());  context:  return  new  ShardCountRequest(shard.index(),  shard.id(),  request);  }  return  new  ShardCountResponse();  }          return  indicesService.searchShards(clusterState,  request.indices(),  request.queryHint());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  }  for  (String  index  :  request.indices())  {  state.blocks().indexBlocked(ClusterBlockLevel.READ,  index);  }  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  dfsResults);  context:  searchCache.releaseDfsResults(dfsResults);  searchCache.releaseQueryResults(queryResults);  searchCache.releaseFetchResults(fetchResults);  }  }  private  void  innerFinishHim()  throws  Exception  {  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryResults,  fetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  dfsResults);                  scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  dfsResults,  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	scrollId  =  TransportSearchHelper.buildScrollId(request.searchType(),  dfsResults,  null);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  indices  =  new  HashSet<String>();  context:  protected  int  numberOfReplicas()  {  return  -1;  }  public  void  testThatLoadingTemplateFromFileWorks()  throws  Exception  {  final  int  iters  =  scaledRandomIntBetween(5,  20);          Set<String>  indices  =  new  HashSet<String>();          Set<String>  indices  =  new  HashSet<>();  for  (int  i  =  0;  i  <  iters;  i++)  {  String  indexName  =   "foo "  +  randomRealisticUnicodeOfLengthBetween(0,  5);  if  (indices.contains(indexName))  {  continue;  }  indices.add(indexName);  createIndex(indexName);  ensureYellow();  //  ensuring  yellow  so  the  test  fails  faster  if  the  template  cannot  be  loaded  	Set<String>  indices  =  new  HashSet<>();  
elasticsearch_0072dd816b928c4f3b23a210bd959819509ed512	buggy:  Blob  blob  =  cloudBlobStore.sync().newBlob(buildBlobPath(blobName));  context:  public  class  CloudImmutableBlobContainer  extends  AbstractCloudBlobContainer  implements  ImmutableBlobContainer  {  public  CloudImmutableBlobContainer(BlobPath  path,  CloudBlobStore  cloudBlobStore)  {  super(path,  cloudBlobStore);  }          Blob  blob  =  cloudBlobStore.sync().newBlob(buildBlobPath(blobName));          Blob  blob  =  cloudBlobStore.async().newBlob(buildBlobPath(blobName));  blob.setPayload(is);  blob.setContentLength(sizeInBytes);  final  ListenableFuture<String>  future  =  cloudBlobStore.async().putBlob(cloudBlobStore.container(),  blob);  future.addListener(new  Runnable()  {  try  {  future.get();  listener.onCompleted();  	Blob  blob  =  cloudBlobStore.async().newBlob(buildBlobPath(blobName));  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execPing(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {  context:  controller.registerHandler(RestRequest.Method.GET,   "/{index}/{type}/{id}/_ping ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/{index}/{type}/{id}/_ping ",  this);  }  SinglePingRequest  singlePingRequest  =  new  SinglePingRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  singlePingRequest.listenerThreaded(false);  singlePingRequest.threadedOperation(true);          client.admin().cluster().execPing(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {          client.admin().cluster().ping(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {  try  {  JsonBuilder  generator  =  RestJsonBuilder.restJsonBuilder(request);  generator.startObject().field( "ok ",  true).endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  generator));  }  catch  (Exception  e)  {  onFailure(e);  }  	client.admin().cluster().ping(singlePingRequest,  new  ActionListener<SinglePingResponse>()  {  
elasticsearch_b49a1c441c1ba2e599f6469a3dfb89e285e113be	buggy:  this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  true),  Long.toString(nodeIdGenerator.incrementAndGet()),  transportService.boundAddress().publishAddress());  context:  }  synchronized  (clusterGroups)  {  ClusterGroup  clusterGroup  =  clusterGroups.get(clusterName);  if  (clusterGroup  ==  null)  {  clusterGroup  =  new  ClusterGroup();  clusterGroups.put(clusterName,  clusterGroup);  }              this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  true),  Long.toString(nodeIdGenerator.incrementAndGet()),  transportService.boundAddress().publishAddress());              this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  !settings.getAsBoolean( "node.client ",  false)),  Long.toString(nodeIdGenerator.incrementAndGet()),  transportService.boundAddress().publishAddress());  clusterGroup.members().add(this);  if  (clusterGroup.members().size()  ==  1)  {  master  =  true;  firstMaster  =  true;  clusterService.submitStateUpdateTask( "local-disco-initialconnect(master) ",  new  ProcessedClusterStateUpdateTask()  {  	this.localNode  =  new  DiscoveryNode(settings.get( "name "),  settings.getAsBoolean( "node.data ",  !settings.getAsBoolean( "node.client ",  false)),  Long.toString(nodeIdGenerator.incrementAndGet()),  transportService.boundAddress().publishAddress());  
elasticsearch_1feddac3152340128f93fac5fc66057d65acff0e	buggy:  logger.info( "Clear  CacheRecycler  on  index  [{}] ",  service.index());  context:  clearedAtLeastOne  =  true;  if  (request.fields()  ==  null  ||  request.fields().length  ==  0)  {  service.fieldData().clear();  }  else  {  for  (String  field  :  request.fields())  {  service.fieldData().clearField(field);  }  }  }  if  (request.recycler())  {                  logger.info( "Clear  CacheRecycler  on  index  [{}] ",  service.index());                  logger.debug( "Clear  CacheRecycler  on  index  [{}] ",  service.index());  clearedAtLeastOne  =  true;  }  if  (request.idCache())  {  clearedAtLeastOne  =  true;  service.fieldData().clearField(ParentFieldMapper.NAME);  }  if  (!clearedAtLeastOne)  {  	logger.debug( "Clear  CacheRecycler  on  index  [{}] ",  service.index());  
elasticsearch_2e8b0464b65a2ca0d7db738637b151d586395b63	buggy:  final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool)).start();  context:  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  boolean  waitForRequest  =  false;  final  boolean  spawn  =  true;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "network.server ",  false)  .put( "transport.netty.connectionsPerNode ",  5)  .build();  final  ThreadPool  threadPool  =  new  CachedThreadPool();          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool)).start();          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  final  Node  node  =  new  Node( "server ",  new  InetSocketTransportAddress( "localhost ",  9999));  transportService.nodesAdded(Lists.newArrayList(node));  Thread[]  clients  =  new  Thread[NUMBER_OF_CLIENTS];  final  CountDownLatch  latch  =  new  CountDownLatch(NUMBER_OF_CLIENTS  *  NUMBER_OF_ITERATIONS);  	final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  
elasticsearch_90d005a330eb7ce132c2489722fbb1d0adde0fb0	buggy:  return   "ping_response  target  [ "  +  target  +   "],  master  [ "  +  master  +   "] ";  context:  target.writeTo(out);  if  (master  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  master.writeTo(out);  }  }              return   "ping_response  target  [ "  +  target  +   "],  master  [ "  +  master  +   "] ";              return   "ping_response{target  [ "  +  target  +   "],  master  [ "  +  master  +   "],  cluster_name[ "  +  clusterName.value()  +   "]} ";  }  }  }  	return   "ping_response{target  [ "  +  target  +   "],  master  [ "  +  master  +   "],  cluster_name[ "  +  clusterName.value()  +   "]} ";  
elasticsearch_d570d588a8fdfd7feca537d97f1455c6a5a52220	buggy:  final  int  numNodes  =  cluster().dataNodes();  context:  protected  int  numberOfReplicas()  {  return  0;  }  public  void  testSimpleStats()  throws  Exception  {  client().admin().indices().prepareStats().clear().execute().actionGet();          final  int  numNodes  =  cluster().dataNodes();          final  int  numNodes  =  immutableCluster().dataNodes();  assertThat(numNodes,  greaterThanOrEqualTo(2));  final  int  shardsIdx1  =  randomIntBetween(1,  10);  //  we  make  sure  each  node  gets  at  least  a  single  shard...  final  int  shardsIdx2  =  Math.max(numNodes  -  shardsIdx1,  randomIntBetween(1,  10));  assertThat(numNodes,  lessThanOrEqualTo(shardsIdx1  +  shardsIdx2));  assertAcked(prepareCreate( "test1 ").setSettings(ImmutableSettings.builder()  .put(SETTING_NUMBER_OF_SHARDS,  shardsIdx1)  .put(SETTING_NUMBER_OF_REPLICAS,  0)));  int  docsTest1  =  scaledRandomIntBetween(3*shardsIdx1,  5*shardsIdx1);  	final  int  numNodes  =  immutableCluster().dataNodes();  
elasticsearch_52ac24fa23d32bfe47c1001d8831fff5d9ba0326	buggy:  return  new  RecoveryStatus(RecoveryStatus.Index.EMPTY,  new  RecoveryStatus.Translog(0));  context:  try  {  indexShard.store().deleteContent();  }  catch  (IOException  e)  {  }  indexShard.start();          return  new  RecoveryStatus(RecoveryStatus.Index.EMPTY,  new  RecoveryStatus.Translog(0));          return  new  RecoveryStatus(RecoveryStatus.Index.EMPTY,  RecoveryStatus.Translog.EMPTY);  }  return  NoneGateway.TYPE;  }  return  SnapshotStatus.NA;  	return  new  RecoveryStatus(RecoveryStatus.Index.EMPTY,  RecoveryStatus.Translog.EMPTY);  
elasticsearch_f64f7c0c089d886080f0a7cdbeec33b63cb499df	buggy:  context.externalValue(Double.toString(point.lat())  +  ','  +  Double.toString(point.lat()));  context:  if  (point.lat()  >  90.0  ||  point.lat()  <  -90.0)  {  throw  new  ElasticSearchIllegalArgumentException( "illegal  latitude  value  [ "  +  point.lat()  +   "]  for   "  +  name);  }  }  if  (validateLon)  {  if  (point.lon()  >  180.0  ||  point.lon()  <  -180)  {  throw  new  ElasticSearchIllegalArgumentException( "illegal  longitude  value  [ "  +  point.lon()  +   "]  for   "  +  name);  }  }          context.externalValue(Double.toString(point.lat())  +  ','  +  Double.toString(point.lat()));          context.externalValue(Double.toString(point.lat())  +  ','  +  Double.toString(point.lon()));  geoStringMapper.parse(context);  if  (enableGeoHash)  {  context.externalValue(geohash);  geohashMapper.parse(context);  }  if  (enableLatLon)  {  context.externalValue(point.lat());  latMapper.parse(context);  	context.externalValue(Double.toString(point.lat())  +  ','  +  Double.toString(point.lon()));  
libgdx_538c3b231b1ca8775c656260ed69c401e94446e6	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  280,  100,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  280,  100,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_96a185e107fd72900a7d7ed96c3c9031e226e451	buggy:  c.resolveStrategy  =  Closure.DELEGATE_FIRST  context:  def  GIndicesAdminClient(gClient)  {  this.gClient  =  gClient  this.internalClient  =  gClient.client  this.indicesAdminClient  =  internalClient.admin().indices();  }  GActionFuture<RefreshResponse>  refresh(Closure  c)  {  RefreshRequest  request  =  new  RefreshRequest()  c.setDelegate  request          c.resolveStrategy  =  Closure.DELEGATE_FIRST          c.resolveStrategy  =  gClient.resolveStrategy  c.call()  refresh(request)  }  GActionFuture<RefreshResponse>  refresh(RefreshRequest  request)  {  GActionFuture<RefreshResponse>  future  =  new  GActionFuture<RefreshResponse>(internalClient.threadPool(),  request);  indicesAdminClient.refresh(request,  future)  return  future  	c.resolveStrategy  =  gClient.resolveStrategy  
libgdx_8b55a44660e93fd653d9c88daa1e0bbc030f6557	buggy:  final  AudioDevice  device  =  Gdx.app.getAudio().newAudioDevice(false);  context:  public  class  AudioDeviceTest  extends  GdxTest  {  Thread  thread;  boolean  stop  =  false;  if  (thread  ==  null)  {  final  AudioDevice  device  =  Gdx.app.getAudio().newAudioDevice(false);  final  AudioDevice  device  =  Gdx.app.getAudio().newAudioDevice(44100,  false);  thread  =  new  Thread(new  Runnable()  {  final  float  frequency  =  440;  float  increment  =  (float)(2  *  Math.PI)  *  frequency  /  44100;  //  angular  increment  for  each  sample  float  angle  =  0;  float  samples[]  =  new  float[1024];  while  (!stop)  {  	final  AudioDevice  device  =  Gdx.app.getAudio().newAudioDevice(44100,  false);  
libgdx_7e3cf32d3997a4500d73e5362f615d811d0e0bfc	buggy:  return  ByteBuffer.allocate(1);  context:  return  ((FT_Bitmap*)bitmap)->pitch;  public  ByteBuffer  getBuffer()  {  if  (getRows()  ==  0)  return  ByteBuffer.allocate(1);  return  BufferUtils.newByteBuffer(1);  return  getBuffer(address);  }  public  Pixmap  getPixmap(Format  format)  {  Pixmap  pixmap  =  new  Pixmap(getWidth(),  getRows(),  Format.Alpha);  	return  BufferUtils.newByteBuffer(1);  
libgdx_ad4ba1c7473f6d64a1cb52eb5cefbff49eb20142	buggy:  batch.draw(texture,  0,  0,  256,  256,  0,  0,  256,  256,  Color.WHITE,  false,  false);  context:  texture  =  Gdx.graphics.newUnmanagedTexture(pixmap,  TextureFilter.Linear,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge);  batch  =  new  SpriteBatch();  }  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  batch.draw(texture,  0,  0,  256,  256,  0,  0,  256,  256,  Color.WHITE,  false,  false);  batch.draw(texture,  0,  0,  256,  256,  0,  0,  256,  256,  false,  false);  batch.end();  }  return  false;  }  }  	batch.draw(texture,  0,  0,  256,  256,  0,  0,  256,  256,  false,  false);  
libgdx_1ab8a2c62465f79a661d142737d3f6a3706bbe62	buggy:  GdxTest  test  =  new  SuperKoalio();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  SharedLibraryLoader( "../../extensions/gdx-audio/libs/gdx-audio-natives.jar ").load( "gdx-audio ");  new  SharedLibraryLoader( "../../extensions/gdx-image/libs/gdx-image-natives.jar ").load( "gdx-image ");  new  SharedLibraryLoader( "../../extensions/gdx-freetype/libs/gdx-freetype-natives.jar ").load( "gdx-freetype ");  new  SharedLibraryLoader( "../../extensions/gdx-controllers/gdx-controllers-desktop/libs/gdx-controllers-desktop-natives.jar ").load( "gdx-controllers-desktop ");  new  SharedLibraryLoader( "../../gdx/libs/gdx-natives.jar ").load( "gdx ");  GdxTest  test  =  new  SuperKoalio();  GdxTest  test  =  new  TideMapDirectLoaderTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  config.useGL20  =  test.needsGL20();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  TideMapDirectLoaderTest();  
elasticsearch_914fd29e70ff66a4c11561510b7d3c4a70774a11	buggy:  if  ((Constants.WINDOWS  ||  Constants.SUN_OS)  context:  private  final  Settings  settings;  public  IndexStoreModule(Settings  settings)  {  this.settings  =  settings;  }  public  Iterable<?  extends  Module>  spawnModules()  {  Class<?  extends  Module>  indexStoreModule  =  NioFsIndexStoreModule.class;          if  ((Constants.WINDOWS  ||  Constants.SUN_OS)          if  ((Constants.WINDOWS  ||  Constants.SUN_OS  ||  Constants.LINUX)  &&  Constants.JRE_IS_64BIT  &&  MMapDirectory.UNMAP_SUPPORTED)  {  indexStoreModule  =  MmapFsIndexStoreModule.class;  }  else  if  (Constants.WINDOWS)  {  indexStoreModule  =  SimpleFsIndexStoreModule.class;  }  String  storeType  =  settings.get( "index.store.type ");  if  ( "ram ".equalsIgnoreCase(storeType))  {  indexStoreModule  =  RamIndexStoreModule.class;  	if  ((Constants.WINDOWS  ||  Constants.SUN_OS  ||  Constants.LINUX)  
elasticsearch_9addac830089e48bdcd77a5cc972d85808d863e5	buggy:  public  Explanation  explainScore(int  docId,  Explanation  subQueryExpl)  {  context:  public  void  setNextReader(AtomicReaderContext  context)  {  }  public  double  score(int  docId,  float  subQueryScore)  {  return  boost;  }      public  Explanation  explainScore(int  docId,  Explanation  subQueryExpl)  {      public  Explanation  explainScore(int  docId,  float  subQueryScore)  {  Explanation  exp  =  new  Explanation(boost,   "static  boost  factor ");  exp.addDetail(new  Explanation(boost,   "boostFactor "));  return  exp;  }  public  boolean  equals(Object  o)  {  if  (this  ==  o)  	public  Explanation  explainScore(int  docId,  float  subQueryScore)  {  
elasticsearch_38d10d19bc75f59f23cffc37f0a6bfa8c4de5812	buggy:  return  clusterState.routingTable().index(request.index()).allShardsIt();  context:  return  TransportActions.PERCOLATE;  }  return   "indices/percolate/shard ";  }  request.index(clusterState.metaData().concreteIndex(request.index()));          return  clusterState.routingTable().index(request.index()).allShardsIt();          return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  PercolatorService  percolatorService  =  indexService.percolateService();  PercolatorExecutor.Response  percolate  =  percolatorService.percolate(new  PercolatorExecutor.Request(request.source()));  return  new  PercolateResponse(percolate.matches());  	return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  
libgdx_d21306c50fe55461c61f1ed228c9ef38ba77f9e6	buggy:  ByteBuffer  bytebuffer  =  BufferUtils.newDisposableByteBuffer(1000  *  1000);  context:  public  class  BufferUtilsTest  extends  GdxTest  {  static  final  int  NUM_MB  =  5;  public  boolean  needsGL20  ()  {  return  false;  }  public  void  create  ()  {  ByteBuffer  bytebuffer  =  BufferUtils.newDisposableByteBuffer(1000  *  1000);  ByteBuffer  bytebuffer  =  BufferUtils.newUnsafeByteBuffer(1000  *  1000);  BufferUtils.freeMemory(bytebuffer);  ByteBuffer  bb  =  BufferUtils.newByteBuffer(8);  CharBuffer  cb  =  BufferUtils.newCharBuffer(8);  ShortBuffer  sb  =  BufferUtils.newShortBuffer(8);  IntBuffer  ib  =  BufferUtils.newIntBuffer(8);  LongBuffer  lb  =  BufferUtils.newLongBuffer(8);  FloatBuffer  fb  =  BufferUtils.newFloatBuffer(8);  	ByteBuffer  bytebuffer  =  BufferUtils.newUnsafeByteBuffer(1000  *  1000);  
elasticsearch_8a69910465d525e0e7c6dafc0603a91bf70dc70b	buggy:  StoreFileMetaData  toMetaData  =  new  StoreFileMetaData(fromMetaData.name(),  fromMetaData.length(),  fromMetaData.lastModified(),  fromMetaData.checksum());  context:  }  return  Directories.estimateSize(directory());  }  doRenameFile(from,  to);  synchronized  (mutex)  {  StoreFileMetaData  fromMetaData  =  filesMetadata.get(from);  //  we  should  always  find  this  one              StoreFileMetaData  toMetaData  =  new  StoreFileMetaData(fromMetaData.name(),  fromMetaData.length(),  fromMetaData.lastModified(),  fromMetaData.checksum());              StoreFileMetaData  toMetaData  =  new  StoreFileMetaData(to,  fromMetaData.length(),  fromMetaData.lastModified(),  fromMetaData.checksum());  filesMetadata  =  MapBuilder.newMapBuilder(filesMetadata).remove(from).put(to,  toMetaData).immutableMap();  files  =  filesMetadata.keySet().toArray(new  String[filesMetadata.size()]);  }  }  protected  abstract  void  doRenameFile(String  from,  String  to)  throws  IOException;  public  static  Map<String,  String>  readChecksums(Directory  dir)  throws  IOException  {  	StoreFileMetaData  toMetaData  =  new  StoreFileMetaData(to,  fromMetaData.length(),  fromMetaData.lastModified(),  fromMetaData.checksum());  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (childDocMapper.parentFieldMapper()  ==  null)  {  context:  }  if  (childType  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  requires  'type'  field ");  }  innerQuery.setBoost(boost);  DocumentMapper  childDocMapper  =  parseContext.mapperService().documentMapper(childType);  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  No  mapping  for  for  type  [ "  +  childType  +   "] ");  }          if  (childDocMapper.parentFieldMapper()  ==  null)  {          if  (!childDocMapper.parentFieldMapper().active())  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  DocumentMapper  parentDocMapper  =  parseContext.mapperService().documentMapper(parentType);  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_child]  Type  [ "  +  childType  +   "]  points  to  a  non  existent  parent  type  [ "  +  parentType  +   "] ");  }  	if  (!childDocMapper.parentFieldMapper().active())  {  
elasticsearch_e5737e305804da5f09b716e66fa1d5e17bddc07e	buggy:  logger.trace( "Node  [{}]  failed  on  ping ",  node);  context:  }  if  (running)  {  NodeFD  nodeFD  =  nodesFD.get(node);  if  (nodeFD  !=  null)  {  int  retryCount  =  ++nodeFD.retryCount;  if  (retryCount  >=  pingRetryCount)  {                                          logger.trace( "Node  [{}]  failed  on  ping ",  node);                                          logger.debug( "Node  [{}]  failed  on  ping,  tried  [{}]  times,  each  with  [{}]  timeout ",  node,  pingRetryCount,  pingRetryTimeout);  if  (nodesFD.remove(node)  !=  null)  {  notifyNodeFailure(node);  }  }  }  }  }  	logger.debug( "Node  [{}]  failed  on  ping,  tried  [{}]  times,  each  with  [{}]  timeout ",  node,  pingRetryCount,  pingRetryTimeout);  
elasticsearch_efb3e97ce4fe8edbd3fec9bb217fe6e42bde6dba	buggy:  return  new  DocIdAndVersion(Lucene.NO_DOC,  -1,  reader);  context:  this.reader  =  reader;  }  }  public  static  DocIdAndVersion  loadDocIdAndVersion(IndexReader  reader,  Term  term)  {  int  docId  =  Lucene.NO_DOC;  TermPositions  uid  =  null;  try  {  uid  =  reader.termPositions(term);  if  (!uid.next())  {                  return  new  DocIdAndVersion(Lucene.NO_DOC,  -1,  reader);                  return  null;  //  no  doc  }  docId  =  uid.doc();  uid.nextPosition();  if  (!uid.isPayloadAvailable())  {  return  new  DocIdAndVersion(docId,  -2,  reader);  }  if  (uid.getPayloadLength()  <  8)  {  return  new  DocIdAndVersion(docId,  -2,  reader);  	return  null;  //  no  doc  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  TermsEnum.SeekStatus  status  =  termsEnum.seekCeil(nextParent.toBytesRef(),  false);  context:  DocsEnum  docsEnum  =  null;  uid:  for  (BytesRef  term  =  termsEnum.next();  term  !=  null;  term  =  termsEnum.next())  {  HashedBytesArray[]  typeAndId  =  Uid.splitUidIntoTypeAndId(term);  if  (!parentTypes.contains(typeAndId[0]))  {  do  {  HashedBytesArray  nextParent  =  parentTypes.ceiling(typeAndId[0]);  if  (nextParent  ==  null)  {  break  uid;  }                                      TermsEnum.SeekStatus  status  =  termsEnum.seekCeil(nextParent.toBytesRef(),  false);                                      TermsEnum.SeekStatus  status  =  termsEnum.seekCeil(nextParent.toBytesRef());  if  (status  ==  TermsEnum.SeekStatus.END)  {  break  uid;  }  else  if  (status  ==  TermsEnum.SeekStatus.NOT_FOUND)  {  term  =  termsEnum.term();  typeAndId  =  Uid.splitUidIntoTypeAndId(term);  }  else  if  (status  ==  TermsEnum.SeekStatus.FOUND)  {  assert  false  :   "Seek  status  should  never  be  FOUND,  because  we  seek  only  the  type  part ";  term  =  termsEnum.term();  	TermsEnum.SeekStatus  status  =  termsEnum.seekCeil(nextParent.toBytesRef());  
elasticsearch_ba79c778ba21e8b4fd61543fc3fbf55694f38321	buggy:  if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  settings.getAsBoolean( "index.warm.enabled ",  true)))  {  context:  public  void  removeListener(Listener  listener)  {  listeners.remove(listener);  }  public  void  warm(final  ShardId  shardId,  final  Engine.Searcher  searcher)  {  final  IndexMetaData  indexMetaData  =  clusterService.state().metaData().index(shardId.index().name());  if  (indexMetaData  ==  null)  {  return;  }          if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  settings.getAsBoolean( "index.warm.enabled ",  true)))  {          if  (!indexMetaData.settings().getAsBoolean( "index.warmer.enabled ",  settings.getAsBoolean( "index.warmer.enabled ",  true)))  {  return;  }  IndexService  indexService  =  indicesService.indexService(shardId.index().name());  if  (indexService  ==  null)  {  return;  }  IndexShard  indexShard  =  indexService.shard(shardId.id());  if  (indexShard  ==  null)  {  	if  (!indexMetaData.settings().getAsBoolean( "index.warmer.enabled ",  settings.getAsBoolean( "index.warmer.enabled ",  true)))  {  
elasticsearch_07ab5dcf9b4180f66fa89ea3539a429dcde18833	buggy:  builder.field( "_type ",   "statistical ");  context:  total  +=  statsFacet.total();  sumOfSquares  +=  statsFacet.sumOfSquares();  count  +=  statsFacet.count();  }  return  new  InternalStatisticalFacet(name,  fieldName,  min,  max,  total,  sumOfSquares,  count);  }  builder.startObject(name);          builder.field( "_type ",   "statistical ");          builder.field( "_type ",  StatisticalFacetCollectorParser.NAME);  builder.field( "_field ",  fieldName);  builder.field( "count ",  count());  builder.field( "total ",  total());  builder.field( "min ",  min());  builder.field( "max ",  max());  builder.field( "mean ",  mean());  builder.field( "sum_of_squares ",  sumOfSquares());  builder.field( "variance ",  variance());  	builder.field( "_type ",  StatisticalFacetCollectorParser.NAME);  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  values[i].length  =  0;  context:  this.script  =  script;  }  public  SearchScript  script()  {  return  script;  }  private  void  set(int  i,  Object  o)  {  if  (o  ==  null)  {              values[i].length  =  0;              values[i].clear();  }  else  {  values[i].copyChars(o.toString());  }  }  public  void  setDocument(int  docId)  {  script.setNextDocId(docId);  	values[i].clear();  
libgdx_5fd25ffb3dc8849230b693316e47670110b0928c	buggy:  String  fileName  =   "data/models/robot-mesh.xml.g3d ";  context:  cam.far  =  64f;  cam.position.set(2,  2.75f,  1f);  cam.update();  camController  =  new  PerspectiveCamController(cam);  Gdx.input.setInputProcessor(camController);  texture  =  new  Texture(Gdx.files.internal( "data/models/robot.jpg "),  Format.RGB565,  true);  texture.setFilter(TextureFilter.MipMapLinearNearest,  TextureFilter.Linear);  String  fileName  =   "data/models/robot-mesh.xml.g3d ";  String  fileName  =   "data/models/ninja.mesh.xml ";  if  (!fileName.endsWith( ".g3d ")  &&  Gdx.app.getType()  ==  ApplicationType.Desktop)  {  model  =  ModelLoaderRegistry.loadSkeletonModel(Gdx.files.internal(fileName));  if(model  ==  null){  model  =  new  OgreXmlLoader().load(Gdx.files.internal(fileName),  Gdx.files.internal(fileName.replace( "mesh.xml ",   "skeleton.xml ")));  	String  fileName  =   "data/models/ninja.mesh.xml ";  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.field( "mustNot ");  context:  return  this;  }  builder.startObject( "bool ");  for  (Clause  clause  :  clauses)  {  if  (clause.occur  ==  BooleanClause.Occur.MUST)  {  builder.field( "must ");  clause.filterBuilder.toJson(builder,  params);  }  else  if  (clause.occur  ==  BooleanClause.Occur.MUST_NOT)  {                  builder.field( "mustNot ");                  builder.field( "must_not ");  clause.filterBuilder.toJson(builder,  params);  }  else  if  (clause.occur  ==  BooleanClause.Occur.SHOULD)  {  builder.field( "should ");  clause.filterBuilder.toJson(builder,  params);  }  }  builder.endObject();  }  	builder.field( "must_not ");  
elasticsearch_8f9693063820fb7417c53e7fbe8b10ddcd16c422	buggy:  queryStringBuilder.lenient(request.paramAsBooleanOptional( "lenient ",  null));  context:  if  (request.hasContent())  {  explainRequest.source(request.content(),  request.contentUnsafe());  }  else  if  (sourceString  !=  null)  {  explainRequest.source(new  BytesArray(request.param( "source ")),  false);  }  else  if  (queryString  !=  null)  {  QueryStringQueryBuilder  queryStringBuilder  =  QueryBuilders.queryString(queryString);  queryStringBuilder.defaultField(request.param( "df "));  queryStringBuilder.analyzer(request.param( "analyzer "));  queryStringBuilder.analyzeWildcard(request.paramAsBoolean( "analyze_wildcard ",  false));  queryStringBuilder.lowercaseExpandedTerms(request.paramAsBoolean( "lowercase_expanded_terms ",  true));              queryStringBuilder.lenient(request.paramAsBooleanOptional( "lenient ",  null));              queryStringBuilder.lenient(request.paramAsBoolean( "lenient ",  null));  String  defaultOperator  =  request.param( "default_operator ");  if  (defaultOperator  !=  null)  {  if  ( "OR ".equals(defaultOperator))  {  queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);  }  else  if  ( "AND ".equals(defaultOperator))  {  queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);  }  else  {  throw  new  ElasticsearchIllegalArgumentException( "Unsupported  defaultOperator  [ "  +  defaultOperator  +   "],  can  either  be  [OR]  or  [AND] ");  	queryStringBuilder.lenient(request.paramAsBoolean( "lenient ",  null));  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  if  (version.onOrAfter(Version.LUCENE_48))  {  context:  flags  |=  getFlag(STEM_ENGLISH_POSSESSIVE,  settings,   "stem_english_possessive ",  true);  Set<?>  protectedWords  =  Analysis.getWordSet(env,  settings,   "protected_words ",  version);  this.protoWords  =  protectedWords  ==  null  ?  null  :  CharArraySet.copy(Lucene.VERSION,  protectedWords);  this.flags  =  flags;  }  public  TokenStream  create(TokenStream  tokenStream)  {          if  (version.onOrAfter(Version.LUCENE_48))  {          if  (version.onOrAfter(Version.LUCENE_4_8))  {  return  new  WordDelimiterFilter(version,  tokenStream,  charTypeTable,  flags,  protoWords);  }  else  {  return  new  Lucene47WordDelimiterFilter(tokenStream,  charTypeTable,  flags,  	if  (version.onOrAfter(Version.LUCENE_4_8))  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  .field(Fields._INDEX,  result.getIndex())  .field(Fields._TYPE,  result.getType())  .field(Fields._ID,  result.getId())  .field(Fields._VERSION,  result.getVersion())  .endObject();  RestStatus  status  =  OK;  if  (result.isNotFound())  {  status  =  NOT_FOUND;  }  channel.sendResponse(new  XContentRestResponse(request,  status,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_3ed848a495a494538a9071ccd447f23fa07fb7f2	buggy:  threadPool.execute(new  Runnable()  {  context:  if  (request.method()  ==  RestRequest.Method.OPTIONS)  {  StringRestResponse  response  =  new  StringRestResponse(OK);  channel.sendResponse(response);  }  else  {  channel.sendResponse(new  StringRestResponse(BAD_REQUEST,   "No  handler  found  for  uri  [ "  +  request.uri()  +   "]  and  method  [ "  +  request.method()  +   "] "));  }  }  }  else  {  if  (httpHandler.spawn())  {                  threadPool.execute(new  Runnable()  {                  threadPool.cached().execute(new  Runnable()  {  try  {  httpHandler.handleRequest(request,  channel);  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  }  catch  (IOException  e1)  {  	threadPool.cached().execute(new  Runnable()  {  
elasticsearch_3d4c31de91a0cbdceb4c910a5bd8eaad3bd09501	buggy:  StringBuilder  errorMessage  =  new  StringBuilder( "{ ").append(Version.full()).append( "}:   ");  context:  }  if  (logger.isDebugEnabled())  {  }  System.exit(3);  }  }  private  static  String  buildErrorMessage(String  stage,  Throwable  e)  {          StringBuilder  errorMessage  =  new  StringBuilder( "{ ").append(Version.full()).append( "}:   ");          StringBuilder  errorMessage  =  new  StringBuilder( "{ ").append(Version.CURRENT).append( "}:   ");  try  {  if  (ANSI.isEnabled())  {  errorMessage.append(attrib(ANSI.Code.FG_RED)).append(stage).append( "  Failed  ... ").append(attrib(ANSI.Code.OFF)).append( "\n ");  }  else  {  errorMessage.append(stage).append( "  Failed  ...\n ");  }  }  catch  (Throwable  t)  {  errorMessage.append(stage).append( "  Failed  ...\n ");  	StringBuilder  errorMessage  =  new  StringBuilder( "{ ").append(Version.CURRENT).append( "}:   ");  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataCreateIndexService  createIndexService;  ThreadPool  threadPool,  MetaDataCreateIndexService  createIndexService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.createIndexService  =  createIndexService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.CREATE;  }  return  new  CreateIndexRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_415cfa2e896be82a543ffe70ca40f31f5f585087	buggy:  DocIdSet  docIdSet  =  filter.getDocIdSet(hitContext.reader());  context:  return  !context.parsedQuery().namedFilters().isEmpty();  }  public  void  hitExecute(SearchContext  context,  HitContext  hitContext)  throws  ElasticSearchException  {  List<String>  matchedFilters  =  Lists.newArrayListWithCapacity(2);  for  (Map.Entry<String,  Filter>  entry  :  context.parsedQuery().namedFilters().entrySet())  {  String  name  =  entry.getKey();  Filter  filter  =  entry.getValue();  try  {                  DocIdSet  docIdSet  =  filter.getDocIdSet(hitContext.reader());                  DocIdSet  docIdSet  =  filter.getDocIdSet(hitContext.readerContext(),  null);  //  null  is  fine,  since  we  filter  by  hitContext.docId()  if  (docIdSet  !=  null)  {  DocSet  docSet  =  DocSets.convert(hitContext.reader(),  docIdSet);  if  (docSet.get(hitContext.docId()))  {  matchedFilters.add(name);  }  }  }  catch  (IOException  e)  {  	DocIdSet  docIdSet  =  filter.getDocIdSet(hitContext.readerContext(),  null);  //  null  is  fine,  since  we  filter  by  hitContext.docId()  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshotBuild ",  Version.snapshotBuild()).endObject();  context:  }  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request).prettyPrint();  builder.startObject();  builder.field( "ok ",  true);  if  (settings.get( "name ")  !=  null)  {  builder.field( "name ",  settings.get( "name "));  }              builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshotBuild ",  Version.snapshotBuild()).endObject();              builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshot_build ",  Version.snapshotBuild()).endObject();  builder.field( "version ",  Version.number());  builder.field( "tagline ",   "You  Know,  for  Search ");  builder.field( "cover ",   "DON'T  PANIC ");  if  (rootNode  !=  null)  {  builder.startObject( "quote ");  ArrayNode  arrayNode  =  (ArrayNode)  rootNode.get( "quotes ");  JsonNode  quoteNode  =  arrayNode.get(ThreadLocalRandom.current().nextInt(quotesSize));  builder.field( "book ",  quoteNode.get( "book ").getValueAsText());  	builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "snapshot_build ",  Version.snapshotBuild()).endObject();  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);  context:  return  new  TypesExistsResponse();  }  protected  ClusterBlockException  checkBlock(TypesExistsRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  TypesExistsRequest  request,  final  ClusterState  state,  final  ActionListener<TypesExistsResponse>  listener)  throws  ElasticSearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  if  (concreteIndices.length  ==  0)  {  listener.onResponse(new  TypesExistsResponse(false));  return;  }  for  (String  concreteIndex  :  concreteIndices)  {  if  (!state.metaData().hasConcreteIndex(concreteIndex))  {  listener.onResponse(new  TypesExistsResponse(false));  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_8c9dffc235a940e1f9cccbd62333795868e68149	buggy:  @Override  public  ShardRouting  nextActiveOrNull()  throws  NoSuchElementException  {  context:  }  ShardRouting  shardRouting  =  nextActiveOrNull();  if  (shardRouting  ==  null)  {  throw  new  NoSuchElementException( "No  active  shard  found ");  }  return  shardRouting;  }      @Override  public  ShardRouting  nextActiveOrNull()  throws  NoSuchElementException  {      @Override  public  ShardRouting  nextActiveOrNull()  {  int  counter  =  this.counter;  int  index  =  this.index;  while  (counter++  <  size())  {  ShardRouting  shardRouting  =  shardModulo(index++);  if  (shardRouting.active())  {  this.counter  =  counter;  this.index  =  index;  return  shardRouting;  	@Override  public  ShardRouting  nextActiveOrNull()  {  
elasticsearch_2c07588a1a5fb6c136d8b43bf6646d308cb7f53b	buggy:  assertThat(routing.state(),  equalTo(ShardRoutingState.STARTED));  context:  }  assertThat(response.getStatus(),  is(ClusterHealthStatus.RED));  ClusterState  state  =  client().admin().cluster().prepareState().get().getState();  GroupShardsIterator  shardIterators  =  state.getRoutingNodes().getRoutingTable().activePrimaryShardsGrouped(new  String[]  { "test "},  false);  for  (ShardIterator  iterator  :  shardIterators.iterators())  {  ShardRouting  routing;  while  ((routing  =  iterator.nextOrNull())  !=  null)  {  if  (routing.getId()  ==  shardRouting.getId())  {  assertThat(routing.state(),  equalTo(ShardRoutingState.UNASSIGNED));  }  else  {                      assertThat(routing.state(),  equalTo(ShardRoutingState.STARTED));                      assertThat(routing.state(),  anyOf(equalTo(ShardRoutingState.RELOCATING),  equalTo(ShardRoutingState.STARTED)));  }  }  }  final  List<File>  files  =  listShardFiles(shardRouting);  File  corruptedFile  =  null;  for  (File  file  :  files)  {  if  (file.getName().startsWith( "corrupted_ "))  {  corruptedFile  =  file;  	assertThat(routing.state(),  anyOf(equalTo(ShardRoutingState.RELOCATING),  equalTo(ShardRoutingState.STARTED)));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  routing  =  new  HashSet<String>(routingSize);  context:  source  =  in.readBytesReference();  int  typesSize  =  in.readVInt();  if  (typesSize  >  0)  {  types  =  new  String[typesSize];  for  (int  i  =  0;  i  <  typesSize;  i++)  {  types[i]  =  in.readString();  }  }  int  routingSize  =  in.readVInt();  if  (routingSize  >  0)  {              routing  =  new  HashSet<String>(routingSize);              routing  =  new  HashSet<>(routingSize);  for  (int  i  =  0;  i  <  routingSize;  i++)  {  routing.add(in.readString());  }  }  int  aliasesSize  =  in.readVInt();  if  (aliasesSize  >  0)  {  filteringAliases  =  new  String[aliasesSize];  for  (int  i  =  0;  i  <  aliasesSize;  i++)  {  	routing  =  new  HashSet<>(routingSize);  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,  ignoreMalformed);  context:  }  public  Builder  nullValue(byte  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  ByteFieldMapper  build(BuilderContext  context)  {  ByteFieldMapper  fieldMapper  =  new  ByteFieldMapper(buildNames(context),                      precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,  ignoreMalformed);                      precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,  ignoreMalformed(context));  
elasticsearch_f8a615f9a31940240b675a0d40412e0ad93c5685	buggy:  UnicodeUtil.UTF16Result  result  =  Unicode.unsafeFromBytesAsUtf16(json);  context:  public  StringJsonBuilder(JsonGenerator  generator)  throws  IOException  {  this.writer  =  new  FastCharArrayWriter();  this.generator  =  generator;  this.factory  =  null;  this.builder  =  this;  }  flush();          UnicodeUtil.UTF16Result  result  =  Unicode.unsafeFromBytesAsUtf16(json);          Unicode.UTF16Result  result  =  Unicode.unsafeFromBytesAsUtf16(json);  writer.write(result.result,  0,  result.length);  return  this;  }  public  StringJsonBuilder  reset()  throws  IOException  {  writer.reset();  generator  =  factory.createJsonGenerator(writer);  return  this;  	Unicode.UTF16Result  result  =  Unicode.unsafeFromBytesAsUtf16(json);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  cluster().wipeIndices( "idx2 ");  context:  indexDoc(2,  15,  3),  //  date:  Feb  15,  dates:  Feb  15,  Mar  16  indexDoc(3,  2,  4),  //  date:  Mar  2,  dates:  Mar  2,  Apr  3  indexDoc(3,  15,  5),  //  date:  Mar  15,  dates:  Mar  15,  Apr  16  indexDoc(3,  23,  6)));  //  date:  Mar  23,  dates:  Mar  23,  Apr  24  indexRandom(true,  builders);  ensureSearchable();  }  public  void  afterEachTest()  throws  IOException  {          cluster().wipeIndices( "idx2 ");          internalCluster().wipeIndices( "idx2 ");  }  private  static  DateHistogram.Bucket  getBucket(DateHistogram  histogram,  DateTime  key)  {  return  getBucket(histogram,  key,  DateFieldMapper.Defaults.DATE_TIME_FORMATTER.format());  }  private  static  DateHistogram.Bucket  getBucket(DateHistogram  histogram,  DateTime  key,  String  format)  {  if  (randomBoolean())  {  	internalCluster().wipeIndices( "idx2 ");  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  final  Engine.Searcher  searcher  =  indexShard.searcher();  context:  }  }  return  new  SuggestResponse(new  Suggest(Suggest.reduce(groupedSuggestions)),  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardSuggestResponse  shardOperation(ShardSuggestRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());          final  Engine.Searcher  searcher  =  indexShard.searcher();          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  XContentParser  parser  =  null;  try  {  BytesReference  suggest  =  request.suggest();  if  (suggest  !=  null  &&  suggest.length()  >  0)  {  parser  =  XContentFactory.xContent(suggest).createParser(suggest);  if  (parser.nextToken()  !=  XContentParser.Token.START_OBJECT)  {  throw  new  ElasticSearchIllegalArgumentException( "suggest  content  missing ");  }  	final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  
elasticsearch_2fad1c430879168e319fa906784ac26775a9ddb6	buggy:  mergePolicy  =  new  CustomLogByteSizeMergePolicy(this);  context:  this.asyncMerge  =  indexSettings.getAsBoolean( "index.merge.async ",  true);  mergeFactor,  minMergeSize,  maxMergeSize,  maxMergeDocs,  calibrateSizeByDeletes,  asyncMerge);  indexSettingsService.addListener(applySettings);  }  CustomLogByteSizeMergePolicy  mergePolicy;  if  (asyncMerge)  {              mergePolicy  =  new  CustomLogByteSizeMergePolicy(this);              mergePolicy  =  new  EnableMergeLogByteSizeMergePolicy(this);  }  else  {  mergePolicy  =  new  CustomLogByteSizeMergePolicy(this);  }  mergePolicy.setMinMergeMB(minMergeSize.mbFrac());  mergePolicy.setMaxMergeMB(maxMergeSize.mbFrac());  mergePolicy.setMergeFactor(mergeFactor);  mergePolicy.setMaxMergeDocs(maxMergeDocs);  mergePolicy.setCalibrateSizeByDeletes(calibrateSizeByDeletes);  	mergePolicy  =  new  EnableMergeLogByteSizeMergePolicy(this);  
elasticsearch_fdd5e53aa779cb9f7d3e765583f23ce04cac709d	buggy:  }  catch  (Exception  e)  {  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  void  finishHim()  {  try  {  innerFinishHim();              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  ReduceSearchPhaseException  failure  =  new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures());  if  (logger.isDebugEnabled())  {  }  listener.onFailure(failure);  }  finally  {  releaseIrrelevantSearchContexts(firstResults,  docIdsToLoad);  }  	}  catch  (Throwable  e)  {  
elasticsearch_35f5ca915d4e3cf625f2b4ed6ca29cd80cd166d0	buggy:  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices());  context:  protected  abstract  Map<String,  Set<String>>  resolveRouting(ClusterState  clusterState,  Request  request)  throws  ElasticSearchException;  protected  void  doExecute(final  Request  request,  final  ActionListener<Response>  listener)  {  ClusterState  clusterState  =  clusterService.state();  ClusterBlockException  blockException  =  checkGlobalBlock(clusterState,  request);  if  (blockException  !=  null)  {  throw  blockException;  }          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices());          String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);  blockException  =  checkRequestBlock(clusterState,  request,  concreteIndices);  if  (blockException  !=  null)  {  throw  blockException;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<Object>(concreteIndices.length);  	String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false);  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.Box2DTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.SoundTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.SoundTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  int  currentNumberOfOperations  =  translog.numberOfOperations();  context:  private  volatile  long  lastFlushTime  =  System.currentTimeMillis();  if  (indexShard.state()  ==  IndexShardState.CLOSED)  {  return;  }  if  (disableFlush)  {  return;  }              int  currentNumberOfOperations  =  translog.numberOfOperations();              int  currentNumberOfOperations  =  translog.estimatedNumberOfOperations();  if  (currentNumberOfOperations  >  flushThresholdOperations)  {  asyncFlushAndReschedule();  return;  }  long  sizeInBytes  =  translog.translogSizeInBytes();  if  (sizeInBytes  >  flushThresholdSize.bytes())  {  	int  currentNumberOfOperations  =  translog.estimatedNumberOfOperations();  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  throws  ElasticSearchException  {  context:  mergePolicy.setFloorSegmentMB(floorSegment.mbFrac());  mergePolicy.setMaxMergeAtOnce(maxMergeAtOnce);  mergePolicy.setMaxMergeAtOnceExplicit(maxMergeAtOnceExplicit);  mergePolicy.setMaxMergedSegmentMB(maxMergedSegment.mbFrac());  mergePolicy.setSegmentsPerTier(segmentsPerTier);  mergePolicy.setReclaimDeletesWeight(reclaimDeletesWeight);  return  mergePolicy;  }      public  void  close(boolean  delete)  throws  ElasticSearchException  {      public  void  close()  throws  ElasticSearchException  {  indexSettingsService.removeListener(applySettings);  }  public  static  final  String  INDEX_MERGE_POLICY_EXPUNGE_DELETES_ALLOWED  =   "index.merge.policy.expunge_deletes_allowed ";  public  static  final  String  INDEX_MERGE_POLICY_FLOOR_SEGMENT  =   "index.merge.policy.floor_segment ";  public  static  final  String  INDEX_MERGE_POLICY_MAX_MERGE_AT_ONCE  =   "index.merge.policy.max_merge_at_once ";  public  static  final  String  INDEX_MERGE_POLICY_MAX_MERGE_AT_ONCE_EXPLICIT  =   "index.merge.policy.max_merge_at_once_explicit ";  public  static  final  String  INDEX_MERGE_POLICY_MAX_MERGED_SEGMENT  =   "index.merge.policy.max_merged_segment ";  	public  void  close()  throws  ElasticSearchException  {  
elasticsearch_836461e6de36c3218d9a7d90712370f1523057bb	buggy:  return  new  InternalSearchRequest( "test ",  0,  builder.buildAsBytes());  context:  try  {  searchService.executeFetchPhase(new  FetchSearchRequest(queryResult.id(),  docIdsToLoad.values().iterator().next()));  assert  true  :   "context  should  be  missing  since  it  timed  out ";  }  catch  (SearchContextMissingException  e)  {  }  }  private  InternalSearchRequest  searchRequest(SearchSourceBuilder  builder)  {          return  new  InternalSearchRequest( "test ",  0,  builder.buildAsBytes());          return  new  InternalSearchRequest( "test ",  0).source(builder.buildAsBytes());  }  private  void  index(Client  client,  String  id,  String  nameValue,  int  age)  {  client.index(indexRequest( "test ").type( "type1 ").id(id).source(source(id,  nameValue,  age))).actionGet();  }  private  String  source(String  id,  String  nameValue,  int  age)  {  return   "{  type1  :  {  \ "id\ "  :  \ " "  +  id  +   "\ ",  \ "name\ "  :  \ " "  +  nameValue  +   "\ ",  age  :   "  +  age  +   "  }  } ";  	return  new  InternalSearchRequest( "test ",  0).source(builder.buildAsBytes());  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(source,  true);  context:  public  void  writeTo(StreamOutput  out)  throws  IOException  {  writeTo(out,  InternalSearchHits.streamContext().streamShardTarget(InternalSearchHits.StreamContext.ShardTargetType.STREAM));  }  public  void  writeTo(StreamOutput  out,  InternalSearchHits.StreamContext  context)  throws  IOException  {  out.writeFloat(score);  out.writeUTF(id);  out.writeUTF(type);  out.writeLong(version);          out.writeBytesReference(source,  true);          out.writeBytesReference(source);  if  (explanation  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  writeExplanation(out,  explanation);  }  if  (fields  ==  null)  {  out.writeVInt(0);  	out.writeBytesReference(source);  
elasticsearch_be424c45645b2c25c61b5e6ca0f137abe50bec16	buggy:  public  Object  clone()  {  context:  }  protected  abstract  void  readHeader(IndexInput  in)  throws  IOException;  protected  abstract  int  uncompress(IndexInput  in,  byte[]  out)  throws  IOException;      public  Object  clone()  {      public  IndexInput  clone()  {  CompressedIndexInput  cloned  =  (CompressedIndexInput)  super.clone();  cloned.uncompressed  =  new  byte[uncompressedLength];  System.arraycopy(uncompressed,  0,  cloned.uncompressed,  0,  uncompressedLength);  cloned.in  =  (IndexInput)  cloned.in.clone();  return  cloned;  }  }  	public  IndexInput  clone()  {  
libgdx_059c409f5853bf2ce50e02d7fd4c3ed7f7282dc1	buggy:  diffuse.setFilter(TextureFilter.MipMapNearestNearest,  TextureFilter.Linear);  context:  cam.update();  cam.apply(Gdx.gl10);  Gdx.gl.glEnable(GL10.GL_CULL_FACE);  Gdx.gl.glEnable(GL10.GL_DEPTH_TEST);  Gdx.gl.glActiveTexture(GL10.GL_TEXTURE0);  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  diffuse.bind();  diffuse.setFilter(TextureFilter.MipMapNearestNearest,  TextureFilter.Linear);  diffuse.setFilter(TextureFilter.MipMap,  TextureFilter.Linear);  Gdx.gl.glActiveTexture(GL10.GL_TEXTURE1);  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  lightMaps[0].bind();  lightMaps[0].setFilter(TextureFilter.MipMapNearestNearest,  TextureFilter.Linear);  setCombiners();  	diffuse.setFilter(TextureFilter.MipMap,  TextureFilter.Linear);  
elasticsearch_032184bd5eb63b9f5b4d2539b6d4e06e4716bfb0	buggy:  assertNoFailures(client().admin().indices().prepareOptimize( "test ").setForce(true).setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  context:  ensureGreen();  final  int  numdocs  =  randomIntBetween(10,  100);  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[numdocs];  for  (int  i  =  0;  i  <  builders.length;  i++)  {  builders[i]  =  client().prepareIndex( "test ",   "doc ",  Integer.toString(i)).setSource( "foo ",   "bar "  +  i);  }  indexRandom(true,  builders);  flushAndRefresh();          assertNoFailures(client().admin().indices().prepareOptimize( "test ").setForce(true).setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());          assertNoFailures(client().admin().indices().prepareOptimize( "test ").setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  CreateSnapshotResponse  createSnapshotResponseFirst  =  client.admin().cluster().prepareCreateSnapshot( "test-repo ",   "test ").setWaitForCompletion(true).setIndices( "test ").get();  assertThat(createSnapshotResponseFirst.getSnapshotInfo().successfulShards(),  greaterThan(0));  assertThat(createSnapshotResponseFirst.getSnapshotInfo().successfulShards(),  equalTo(createSnapshotResponseFirst.getSnapshotInfo().totalShards()));  assertThat(client.admin().cluster().prepareGetSnapshots( "test-repo ").setSnapshots( "test ").get().getSnapshots().get(0).state(),  equalTo(SnapshotState.SUCCESS));  {  SnapshotStatus  snapshotStatus  =  client.admin().cluster().prepareSnapshotStatus( "test-repo ").setSnapshots( "test ").get().getSnapshots().get(0);  List<SnapshotIndexShardStatus>  shards  =  snapshotStatus.getShards();  	assertNoFailures(client().admin().indices().prepareOptimize( "test ").setFlush(true).setWaitForMerge(true).setMaxNumSegments(1).get());  
libgdx_b8c23d8c6ffd1fd251bdaf3e7e6b28e788420515	buggy:  String  name  =  this.name  !=  null  ?  this.name  :  getClass().getSimpleName();  context:  actions.add(action);  }  public  void  clearActions  ()  {  actions.clear();  }  public  String  toString  ()  {  String  name  =  this.name  !=  null  ?  this.name  :  getClass().getSimpleName();  String  name  =  this.name  !=  null  ?  this.name  :  getClass().getName();  if  (name.equals( " "))  name  =  getClass().getName();  return  name  +   "  pos= "  +  x  +   ", "  +  y  +   "  origin= "  +  originX  +   ", "  +  originY  +   "  size= "  +  width  +   ", "  +  height;  }  	String  name  =  this.name  !=  null  ?  this.name  :  getClass().getName();  
elasticsearch_2b9bdc37961022c0f254f86fac083f5d2fdeca12	buggy:  entries.add(new  GeoDistanceFacet.Entry(from,  to,  0,  0,  0,  Double.MAX_VALUE,  Double.MIN_VALUE));  context:  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentName  =  parser.currentName();  }  else  if  (token.isValue())  {  if  ( "from ".equals(currentName))  {  from  =  parser.doubleValue();  }  else  if  ( "to ".equals(currentName))  {  to  =  parser.doubleValue();  }  }  }                          entries.add(new  GeoDistanceFacet.Entry(from,  to,  0,  0,  0,  Double.MAX_VALUE,  Double.MIN_VALUE));                          entries.add(new  GeoDistanceFacet.Entry(from,  to,  0,  0,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY));  }  }  else  {  token  =  parser.nextToken();  lon  =  parser.doubleValue();  token  =  parser.nextToken();  lat  =  parser.doubleValue();  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_ARRAY)  {  	entries.add(new  GeoDistanceFacet.Entry(from,  to,  0,  0,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY));  
elasticsearch_f285ffc61088f72be9790c80db55b2d69f05f461	buggy:  ce.setDescription( "max(0.0,  (( "  +  scale  +   "  -  abs( "  +  valueExpl  +   "))/ "  +  scale  +   ") ");  context:  public  double  evaluate(double  value,  double  scale)  {  return  Math.max(0.0,  (scale  -  value)  /  scale);  }  public  Explanation  explainFunction(String  valueExpl,  double  value,  double  scale)  {  ComplexExplanation  ce  =  new  ComplexExplanation();  ce.setValue((float)  evaluate(value,  scale));              ce.setDescription( "max(0.0,  (( "  +  scale  +   "  -  abs( "  +  valueExpl  +   "))/ "  +  scale  +   ") ");              ce.setDescription( "max(0.0,  (( "  +  scale  +   "  -   "  +  valueExpl  +   ")/ "  +  scale  +   ") ");  return  ce;  }  public  double  processScale(double  scale,  double  decay)  {  return  scale  /  (1.0  -  decay);  }  	ce.setDescription( "max(0.0,  (( "  +  scale  +   "  -   "  +  valueExpl  +   ")/ "  +  scale  +   ") ");  
libgdx_e25ed8a793e47e39867022760a417509ead7610e	buggy:  int  dotIndex  =  imageName.indexOf('.');  context:  }  catch  (IOException  ex)  {  throw  new  RuntimeException( "Error  writing  pack  file. ",  ex);  }  imageProcessor.clear();  }  }  private  void  writeImages  (File  packFile,  Array<Page>  pages)  {  File  packDir  =  packFile.getParentFile();  String  imageName  =  packFile.getName();  int  dotIndex  =  imageName.indexOf('.');  int  dotIndex  =  imageName.lastIndexOf('.');  if  (dotIndex  !=  -1)  imageName  =  imageName.substring(0,  dotIndex);  int  fileIndex  =  0;  for  (Page  page  :  pages)  {  int  width  =  page.width,  height  =  page.height;  int  paddingX  =  settings.paddingX;  int  paddingY  =  settings.paddingY;  if  (settings.duplicatePadding)  {  	int  dotIndex  =  imageName.lastIndexOf('.');  
elasticsearch_efe85f322a073313d35f7261bfbe04baa3235de1	buggy:  return  search(compile(lang,  script),  new  SearchLookup(mapperService,  fieldDataCache),  vars);  context:  public  SearchScript  search(CompiledScript  compiledScript,  SearchLookup  lookup,  @Nullable  Map<String,  Object>  vars)  {  return  scriptEngines.get(compiledScript.lang()).search(compiledScript.compiled(),  lookup,  vars);  }  public  SearchScript  search(SearchLookup  lookup,  String  lang,  String  script,  @Nullable  Map<String,  Object>  vars)  {  return  search(compile(lang,  script),  lookup,  vars);  }  public  SearchScript  search(MapperService  mapperService,  FieldDataCache  fieldDataCache,  String  lang,  String  script,  @Nullable  Map<String,  Object>  vars)  {          return  search(compile(lang,  script),  new  SearchLookup(mapperService,  fieldDataCache),  vars);          return  search(compile(lang,  script),  new  SearchLookup(mapperService,  fieldDataCache,  null),  vars);  }  public  Object  execute(CompiledScript  compiledScript,  Map  vars)  {  return  scriptEngines.get(compiledScript.lang()).execute(compiledScript.compiled(),  vars);  }  public  void  clear()  {  cache.invalidateAll();  	return  search(compile(lang,  script),  new  SearchLookup(mapperService,  fieldDataCache,  null),  vars);  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardOptimizeRequest(shard.index(),  shard.id(),  request);  context:  return  new  OptimizeResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardOptimizeRequest  newShardRequest()  {  return  new  ShardOptimizeRequest();  }  protected  ShardOptimizeRequest  newShardRequest(int  numShards,  ShardRouting  shard,  OptimizeRequest  request)  {          return  new  ShardOptimizeRequest(shard.index(),  shard.id(),  request);          return  new  ShardOptimizeRequest(shard.shardId(),  request);  }  protected  ShardOptimizeResponse  newShardResponse()  {  return  new  ShardOptimizeResponse();  }  	return  new  ShardOptimizeRequest(shard.shardId(),  request);  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  context:  return  context;  }  private  SearchContext  createContext(InternalSearchRequest  request)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  Engine.Searcher  engineSearcher  =  indexShard.searcher();  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.state().nodes().localNodeId(),  request.index(),  request.shardId());          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);          SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.numberOfShards(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  context.scroll(request.scroll());  parseSource(context,  request.source(),  request.sourceOffset(),  request.sourceLength());  parseSource(context,  request.extraSource(),  request.extraSourceOffset(),  request.extraSourceLength());  if  (context.from()  ==  -1)  {  	SearchContext  context  =  new  SearchContext(idGenerator.incrementAndGet(),  shardTarget,  request.numberOfShards(),  request.timeout(),  request.types(),  engineSearcher,  indexService,  scriptService);  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  refresh(new  Refresh().force(true).source( "version_table "));  context:  }  }  }  finally  {  flushLock.unlock();  flushing.decrementAndGet();  }  }  private  void  refreshVersioningTable(long  time)  {          refresh(new  Refresh().force(true).source( "version_table "));          refresh(new  Refresh( "version_table ").force(true));  for  (Map.Entry<HashedBytesRef,  VersionValue>  entry  :  versionMap.entrySet())  {  HashedBytesRef  uid  =  entry.getKey();  synchronized  (dirtyLock(uid.bytes))  {  //  can  we  do  it  without  this  lock  on  each  value?  maybe  batch  to  a  set  and  get  the  lock  once  per  set?  VersionValue  versionValue  =  versionMap.get(uid);  if  (versionValue  ==  null)  {  continue;  }  if  (time  -  versionValue.time()  <=  0)  {  	refresh(new  Refresh( "version_table ").force(true));  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "time_zone ".equals(currentFieldName)  ||   "timeZone ".equals(currentFieldName))  {  preZone  =  parseZone(parser,  token);  }  else  if  ( "pre_zone ".equals(currentFieldName)  ||   "preZone ".equals(currentFieldName))  {  preZone  =  parseZone(parser,  token);  }  else  if  ( "pre_zone_adjust_large_interval ".equals(currentFieldName)  ||   "preZoneAdjustLargeInterval ".equals(currentFieldName))  {  preZoneAdjustLargeInterval  =  parser.booleanValue();  }  else  if  ( "post_zone ".equals(currentFieldName)  ||   "postZone ".equals(currentFieldName))  {  	}  else  if  ( "lang ".equals(currentFieldName))  {  
libgdx_0e0eda76dc2dbe9c200da4fc8782e55914aa6a50	buggy:  screen  =  new  MainMenu(Gdx.app);  context:  if  (screen  instanceof  GameOver)  screen  =  new  MainMenu(app);  }  }  }  if  (!isInitialized)  {  screen  =  new  MainMenu(Gdx.app);  screen  =  new  GameOver(Gdx.app);  Music  music  =  Gdx.audio.newMusic(Gdx.files.getFileHandle( "data/8.12.mp3 ",  FileType.Internal));  music.setLooping(true);  music.play();  isInitialized  =  true;  }  }  	screen  =  new  GameOver(Gdx.app);  
elasticsearch_83770c258387600a2d1754f1ad545184450ac328	buggy:  ensureGreen();  context:  .startObject( "pin ")  .field( "type ",   "geo_point ")  .startObject( "fielddata ")  .field( "format ",   "compressed ")  .field( "precision ",   "2mm ")  .endObject()  .endObject()  .endObject()  .endObject()  .endObject()).execute().actionGet();          ensureGreen();          ensureYellow();  assertPrecision(new  Distance(2,  DistanceUnit.MILLIMETERS));  client().admin().indices().preparePutMapping( "test ").setType( "type1 ").setSource(XContentFactory.jsonBuilder().startObject()  .startObject( "type1 ")  .startObject( "properties ")  .startObject( "pin ")  .field( "type ",   "geo_point ")  .startObject( "fielddata ")  	ensureYellow();  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  timeoutUpdateTask.onTimeout(task.source);  context:  }  final  UpdateTask  task  =  new  UpdateTask(source,  priority,  updateTask);  if  (updateTask  instanceof  TimeoutClusterStateUpdateTask)  {  final  TimeoutClusterStateUpdateTask  timeoutUpdateTask  =  (TimeoutClusterStateUpdateTask)  updateTask;  updateTasksExecutor.execute(task,  threadPool.scheduler(),  timeoutUpdateTask.timeout(),  new  Runnable()  {  public  void  run()  {  threadPool.generic().execute(new  Runnable()  {  public  void  run()  {                              timeoutUpdateTask.onTimeout(task.source);                              timeoutUpdateTask.onTimeout(timeoutUpdateTask.timeout(),  task.source);  }  });  }  });  }  else  {  updateTasksExecutor.execute(task);  }  }  	timeoutUpdateTask.onTimeout(timeoutUpdateTask.timeout(),  task.source);  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(extendedStats( "stats ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  ExtendedStats  stats  =  bucket.getAggregations().get( "stats ");  assertThat(stats,  notNullValue());  assertThat(stats.getName(),  equalTo( "stats "));  assertThat(stats.getSumOfSquares(),  equalTo(0.0));  assertThat(stats.getCount(),  equalTo(0l));  assertThat(stats.getSum(),  equalTo(0.0));  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_bc452dff84da86298b5234f81e90dd768244d70c	buggy:  GeoDistance  distanceType  =  GeoDistance.ARC;  context:  return  sb.toString();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {  String  field  =  null;  List<RangeAggregator.Range>  ranges  =  null;  GeoPoint  origin  =  null;  DistanceUnit  unit  =  DistanceUnit.KILOMETERS;          GeoDistance  distanceType  =  GeoDistance.ARC;          GeoDistance  distanceType  =  GeoDistance.DEFAULT;  boolean  keyed  =  false;  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  	GeoDistance  distanceType  =  GeoDistance.DEFAULT;  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  state  =  LocalGatewayMetaState.Builder.readFrom(in,  null);  context:  this.state  =  state;  }  public  LocalGatewayMetaState  state()  {  return  state;  }  super.readFrom(in);  if  (in.readBoolean())  {                  state  =  LocalGatewayMetaState.Builder.readFrom(in,  null);                  state  =  LocalGatewayMetaState.Builder.readFrom(in);  }  }  super.writeTo(out);  if  (state  ==  null)  {  out.writeBoolean(false);  }  else  {  	state  =  LocalGatewayMetaState.Builder.readFrom(in);  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  smartNameFieldMappers.mapper().indexName();  context:  jp.nextToken();  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  prefix  query ");  }  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  fieldName  =  smartNameFieldMappers.mapper().indexName();                  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  PrefixQuery  query  =  new  PrefixQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  	fieldName  =  smartNameFieldMappers.mapper().names().indexName();  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execTerms(termsRequest,  new  ActionListener<TermsResponse>()  {  context:  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }  final  boolean  termsAsArray  =  request.paramAsBoolean( "termsAsArray ",  true);          client.execTerms(termsRequest,  new  ActionListener<TermsResponse>()  {          client.terms(termsRequest,  new  ActionListener<TermsResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  buildBroadcastShardsHeader(builder,  response);  builder.startObject( "docs ");  	client.terms(termsRequest,  new  ActionListener<TermsResponse>()  {  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  int  shardNo  =  Math.max(5,  cluster().numNodes());  context:  JsonXContent.contentBuilder().startObject().startObject(MapperService.DEFAULT_MAPPING)  .startObject( "properties ").startObject( "f ").field( "type ",   "DOESNT_EXIST ").endObject().endObject()  .endObject().endObject()  ),  MapperParsingException.class);  }  public  void  updateMappingConcurrently()  throws  Throwable  {          int  shardNo  =  Math.max(5,  cluster().numNodes());          int  shardNo  =  Math.max(5,  cluster().size());  prepareCreate( "test1 ").setSettings( "index.number_of_shards ",  shardNo).execute().actionGet();  prepareCreate( "test2 ").setSettings( "index.number_of_shards ",  shardNo).execute().actionGet();  ensureYellow();  	int  shardNo  =  Math.max(5,  cluster().size());  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  Object>  map  =  new  HashMap<String,  Object>();  context:  public  class  IndexRequestBuilderTests  extends  ElasticsearchIntegrationTest  {  public  void  testSetSource()  throws  InterruptedException,  ExecutionException  {  createIndex( "test ");  ensureYellow();          Map<String,  Object>  map  =  new  HashMap<String,  Object>();          Map<String,  Object>  map  =  new  HashMap<>();  map.put( "test_field ",   "foobar ");  IndexRequestBuilder[]  builders  =  new  IndexRequestBuilder[]  {  client().prepareIndex( "test ",   "test ").setSource((Object) "test_field ",  (Object) "foobar "),  client().prepareIndex( "test ",   "test ").setSource( "{\ "test_field\ "  :  \ "foobar\ "} "),  client().prepareIndex( "test ",   "test ").setSource(new  BytesArray( "{\ "test_field\ "  :  \ "foobar\ "} ")),  client().prepareIndex( "test ",   "test ").setSource(new  BytesArray( "{\ "test_field\ "  :  \ "foobar\ "} "),  randomBoolean()),  client().prepareIndex( "test ",   "test ").setSource(new  BytesArray( "{\ "test_field\ "  :  \ "foobar\ "} ").toBytes()),  client().prepareIndex( "test ",   "test ").setSource(map)  	Map<String,  Object>  map  =  new  HashMap<>();  
libgdx_d29bd34e4fe878775842bafbf3a7b9ec8abbb59d	buggy:  if(cube.state  ==  Cube.DEAD)  cube  =  new  Cube(this,  activeDispenser.bounds.x,  activeDispenser.bounds.y);  context:  }  for(int  i  =  0;  i  <  lasers.size;  i++)  {  lasers.get(i).init();  }  }  public  void  update(float  deltaTime)  {  bob.update(deltaTime);  if(bob.state  ==  Bob.DEAD)  bob  =  new  Bob(this,  activeDispenser.bounds.x,  activeDispenser.bounds.y);  cube.update(deltaTime);  if(cube.state  ==  Cube.DEAD)  cube  =  new  Cube(this,  activeDispenser.bounds.x,  activeDispenser.bounds.y);  if(cube.state  ==  Cube.DEAD)  cube  =  new  Cube(this,  bob.bounds.x,  bob.bounds.y);  for(int  i  =  0;  i  <  dispensers.size;  i++)  {  if(bob.bounds.overlaps(dispensers.get(i).bounds))  {  activeDispenser  =  dispensers.get(i);  }  }  for(int  i  =  0;  i  <  rockets.size;  i++)  {  Rocket  rocket  =  rockets.get(i);  rocket.update(deltaTime);  	if(cube.state  ==  Cube.DEAD)  cube  =  new  Cube(this,  bob.bounds.x,  bob.bounds.y);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  }  return;  }  client.admin().cluster().updateSettings(clusterUpdateSettingsRequest,  new  ActionListener<ClusterUpdateSettingsResponse>()  {  public  void  onResponse(ClusterUpdateSettingsResponse  response)  {  try  {  channel.sendResponse(new  StringRestResponse(RestStatus.OK));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  if  (logger.isDebugEnabled())  {  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  context:  public  void  doRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  String[]  indices  =  Strings.splitStringByCommaToArray(request.param( "index "));  final  ClusterStateRequest  clusterStateRequest  =  new  ClusterStateRequest();  clusterStateRequest.clear().indices(indices).metaData(true);  clusterStateRequest.local(request.paramAsBoolean( "local ",  clusterStateRequest.local()));  clusterStateRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterStateRequest.masterNodeTimeout()));  client.admin().cluster().state(clusterStateRequest,  new  RestActionListener<ClusterStateResponse>(channel)  {  public  void  processResponse(final  ClusterStateResponse  clusterStateResponse)  {                  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());                  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  ClusterHealthRequest  clusterHealthRequest  =  Requests.clusterHealthRequest(concreteIndices);  clusterHealthRequest.local(request.paramAsBoolean( "local ",  clusterHealthRequest.local()));  client.admin().cluster().health(clusterHealthRequest,  new  RestActionListener<ClusterHealthResponse>(channel)  {  public  void  processResponse(final  ClusterHealthResponse  clusterHealthResponse)  {  IndicesStatsRequest  indicesStatsRequest  =  new  IndicesStatsRequest();  indicesStatsRequest.all();  client.admin().indices().stats(indicesStatsRequest,  new  RestResponseListener<IndicesStatsResponse>(channel)  {  	final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  
libgdx_d650b1c8f3d6d32b44945de72891895fb7f58361	buggy:  getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  context:  package  com.badlogic.gdx.box2d;  public  class  TestCollection  extends  AndroidApplication  {  public  void  onCreate  (Bundle  bundle)  {  super.onCreate(bundle);  initialize(false);  getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  }  }  	getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  
elasticsearch_167538ef0d8003e083af4f85da139c7020afcc57	buggy:  indexShard.refresh(new  Engine.Refresh().force(true));  context:  lastIndexVersion  =  recoveryStatus.index().version();  lastTranslogId  =  -1;  lastTranslogLength  =  0;  lastTotalTranslogOperations  =  recoveryStatus.translog().currentTranslogOperations();  if  (indexShard.state()  !=  IndexShardState.STARTED)  {  indexShard.start( "post  recovery  from  gateway ");  }                      indexShard.refresh(new  Engine.Refresh().force(true));                      indexShard.refresh(new  Engine.Refresh().force(true).source( "post_gateway "));  recoveryStatus.time(System.currentTimeMillis()  -  recoveryStatus.startTime());  recoveryStatus.updateStage(RecoveryStatus.Stage.DONE);  if  (logger.isDebugEnabled())  {  }  else  if  (logger.isTraceEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  	indexShard.refresh(new  Engine.Refresh().force(true).source( "post_gateway "));  
libgdx_ec4aec44c18052ddfab89213cfd2247270d3559c	buggy:  if  (isDisabled  &&  style.disabledFontColor  !=  null)  context:  label.setStyle(labelStyle);  }  }  public  TextButtonStyle  getStyle  ()  {  return  style;  }  public  void  draw  (Batch  batch,  float  parentAlpha)  {  Color  fontColor;  if  (isDisabled  &&  style.disabledFontColor  !=  null)  if  (isDisabled()  &&  style.disabledFontColor  !=  null)  fontColor  =  style.disabledFontColor;  else  if  (isPressed()  &&  style.downFontColor  !=  null)  fontColor  =  style.downFontColor;  else  if  (isChecked  &&  style.checkedFontColor  !=  null)  fontColor  =  (isOver()  &&  style.checkedOverFontColor  !=  null)  ?  style.checkedOverFontColor  :  style.checkedFontColor;  else  if  (isOver()  &&  style.overFontColor  !=  null)  fontColor  =  style.overFontColor;  else  	if  (isDisabled()  &&  style.disabledFontColor  !=  null)  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setFilterIndices( "test ").execute().actionGet();  context:  cluster().closeNonSharedNodes(false);  cluster().startNode(settingsBuilder().put( "node.data ",  false).put( "gateway.type ",   "local ").put( "index.number_of_shards ",  2).put( "index.number_of_replicas ",  1).build());  ClusterHealthResponse  health  =  client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setIndices( "test ").execute().actionGet();  assertThat(health.isTimedOut(),  equalTo(false));          ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setFilterIndices( "test ").execute().actionGet();          ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setIndices( "test ").execute().actionGet();  assertThat(clusterStateResponse.getState().metaData().hasIndex( "test "),  equalTo(true));  }  public  void  testJustMasterNodeAndJustDataNode()  throws  Exception  {  	ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setIndices( "test ").execute().actionGet();  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  Settings  settings  =  settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).build();  context:  public  class  SearchStatsTests  extends  AbstractNodesTests  {  private  Client  client;  public  void  createNodes()  throws  Exception  {          Settings  settings  =  settingsBuilder().put( "number_of_shards ",  3).put( "number_of_replicas ",  0).build();          Settings  settings  =  settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).build();  startNode( "server1 ",  settings);  startNode( "server2 ",  settings);  client  =  getClient();  }  public  void  closeNodes()  {  client.close();  	Settings  settings  =  settingsBuilder().put( "index.number_of_shards ",  3).put( "index.number_of_replicas ",  0).build();  
elasticsearch_9539661d40d5eb219f68e1298feddb9359b4a14d	buggy:  public  Facet  reduce(String  name,  List<Facet>  facets)  {  context:  }  return  other;  }  public  long  getOtherCount()  {  return  otherCount();  }      public  Facet  reduce(String  name,  List<Facet>  facets)  {      public  Facet  reduce(List<Facet>  facets)  {  if  (facets.size()  ==  1)  {  return  facets.get(0);  }  InternalStringTermsFacet  first  =  (InternalStringTermsFacet)  facets.get(0);  TObjectIntHashMap<Text>  aggregated  =  CacheRecycler.popObjectIntMap();  long  missing  =  0;  long  total  =  0;  for  (Facet  facet  :  facets)  {  	public  Facet  reduce(List<Facet>  facets)  {  
elasticsearch_5cdba0383b08b24e6d829975b308e60bc81fc459	buggy:  indexShard.flush(new  Engine.Flush().refresh(request.refresh()));  context:  return  new  ShardFlushRequest(shard.index(),  shard.id(),  request);  }  return  new  ShardFlushResponse();  }  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());          indexShard.flush(new  Engine.Flush().refresh(request.refresh()));          indexShard.flush(new  Engine.Flush().refresh(request.refresh()).full(request.full()));  return  new  ShardFlushResponse(request.index(),  request.shardId());  }  return  clusterState.routingTable().allShardsGrouped(request.indices());  	indexShard.flush(new  Engine.Flush().refresh(request.refresh()).full(request.full()));  
elasticsearch_244e78fbfb0c6ee5dcb6813b7832e46693a281fc	buggy:  assertThat(leftResult.cardinality(),  equalTo(leftResult.cardinality()));  context:  DocIdSetIterator  leftIter  =  left.iterator();  DocIdSetIterator  rightIter  =  right.iterator();  if  (leftIter  !=  null)  {  leftResult.or(leftIter);  }  if  (rightIter  !=  null)  {  rightResult.or(rightIter);  }                  assertThat(leftResult.cardinality(),  equalTo(leftResult.cardinality()));                  assertThat(leftResult.cardinality(),  equalTo(rightResult.cardinality()));  for  (int  i  =  0;  i  <  reader.maxDoc();  i++)  {  assertThat(errorMsg(clauses,  topLevel)  +   "  --  failed  at  index   "  +  i,  leftResult.get(i),  equalTo(rightResult.get(i)));  }  }  }  }  private  String  errorMsg(FilterClause[]  clauses,  BooleanQuery  query)  {  	assertThat(leftResult.cardinality(),  equalTo(rightResult.cardinality()));  
libgdx_f51f115489ad0adb7c8f12f1a0d80ef51cf011c9	buggy:  for  (int  i  =  other.bits.length,  s  =  bits.length;  s  >  i;  i++)  {  context:  public  void  and  (Bits  other)  {  int  commonWords  =  Math.min(bits.length,  other.bits.length);  for  (int  i  =  0;  commonWords  >  i;  i++)  {  bits[i]  &=  other.bits[i];  }  if  (bits.length  >  commonWords)  {  for  (int  i  =  other.bits.length,  s  =  bits.length;  s  >  i;  i++)  {  for  (int  i  =  commonWords,  s  =  bits.length;  s  >  i;  i++)  {  bits[i]  =  0L;  }  }  }  	for  (int  i  =  commonWords,  s  =  bits.length;  s  >  i;  i++)  {  
elasticsearch_f8a08a46ac4bb34f9df23a22baae2021cbe0b541	buggy:  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUid(request.type(),  request.id()));  context:  protected  void  resolveRequest(ClusterState  state,  ExplainRequest  request)  {  String  concreteIndex  =  state.metaData().concreteIndex(request.index());  request.filteringAlias(state.metaData().filteringAliases(concreteIndex,  request.index()));  request.index(state.metaData().concreteIndex(request.index()));  }  protected  ExplainResponse  shardOperation(ExplainRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexService(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);          Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUid(request.type(),  request.id()));          Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  Engine.GetResult  result  =  indexShard.get(new  Engine.Get(false,  uidTerm));  if  (!result.exists())  {  return  new  ExplainResponse(false);  }  SearchContext  context  =  new  SearchContext(  0,  new  ShardSearchRequest().types(new  String[]{request.type()})  	Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  
elasticsearch_4cf1b3ed9ee2a77c393f7fc5770015c8531f892c	buggy:  return  copyToString(new  InputStreamReader(is));  context:  StringWriter  out  =  new  StringWriter();  copy(in,  out);  return  out.toString();  }  public  static  String  copyToStringFromClasspath(ClassLoader  classLoader,  String  path)  throws  IOException  {  InputStream  is  =  classLoader.getResourceAsStream(path);  if  (is  ==  null)  {  throw  new  FileNotFoundException( "Resource  [ "  +  path  +   "]  not  found  in  classpath  with  class  loader  [ "  +  classLoader  +   "] ");  }          return  copyToString(new  InputStreamReader(is));          return  copyToString(new  InputStreamReader(is,   "UTF-8 "));  }  public  static  String  copyToStringFromClasspath(String  path)  throws  IOException  {  InputStream  is  =  Streams.class.getResourceAsStream(path);  if  (is  ==  null)  {  throw  new  FileNotFoundException( "Resource  [ "  +  path  +   "]  not  found  in  classpath ");  }  return  copyToString(new  InputStreamReader(is));  	return  copyToString(new  InputStreamReader(is,   "UTF-8 "));  
elasticsearch_76622f1a9b21d3be105f712ed384d0ba80fb422e	buggy:  final  int  numDocs  =  between(100,  500);  context:  .put( "gateway.type ",   "none ")  .put(RobinEngine.INDEX_COMPOUND_ON_FLUSH,  randomBoolean())  .put( "index.warmer.enabled ",  false)  .build()).get());  NodesInfoResponse  nodeInfos  =  client().admin().cluster().prepareNodesInfo().setJvm(true).get();  NodeInfo[]  nodes  =  nodeInfos.getNodes();  for  (NodeInfo  info  :  nodes)  {  ByteSizeValue  directMemoryMax  =  info.getJvm().getMem().getDirectMemoryMax();  }          final  int  numDocs  =  between(100,  500);          final  int  numDocs  =  between(30,  100);  //  30  docs  are  enough  to  fail  without  the  fix  for  #4093  for  (int  i  =  0;  i  <  numDocs;  i++)  {  if  ((i+1)  %  10  ==  0)  {  }  client().prepareIndex( "test ",   "type1 ")  .setSource( "a ",   " "  +  i)  .setRefresh(true)  	final  int  numDocs  =  between(30,  100);  //  30  docs  are  enough  to  fail  without  the  fix  for  #4093  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  numQueries  =  atLeast(250);  context:  public  class  PercolatorFacetsAndAggregationsTests  extends  ElasticsearchIntegrationTest  {  public  void  testFacetsAndAggregations()  throws  Exception  {  client().admin().indices().prepareCreate( "test ").execute().actionGet();  ensureGreen();          int  numQueries  =  atLeast(250);          int  numQueries  =  scaledRandomIntBetween(250,  500);  int  numUniqueQueries  =  between(1,  numQueries  /  2);  String[]  values  =  new  String[numUniqueQueries];  for  (int  i  =  0;  i  <  values.length;  i++)  {  values[i]  =   "value "  +  i;  }  int[]  expectedCount  =  new  int[numUniqueQueries];  	int  numQueries  =  scaledRandomIntBetween(250,  500);  
libgdx_357d9211c5b8b000cd46dcb0bace2511cd3e03cf	buggy:  Element  child  =  children.get(i);  context:  }  public  Array<Element>  getChildrenByName(String  name)  {  Array<Element>  children  =  new  Array<Element>();  if(this.children  ==  null)  return  children;  for(int  i  =  0;  i  <  this.children.size;  i++)  {  Element  child  =  children.get(i);  Element  child  =  this.children.get(i);  if(child.name.equals(name))  children.add(child);  }  return  children;  }  }  }  	Element  child  =  this.children.get(i);  
elasticsearch_4bdae621f92beb226cf5873a9efe721b38c7e0c7	buggy:  new  ScriptModule(),  context:  private  static  int  NUMBER_OF_QUERIES  =  100;  public  static  void  main(String[]  args)  throws  Exception  {  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "index.cache.filter.type ",   "none ")  .build();  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),                  new  ScriptModule(),                  new  ScriptModule(settings),  new  MapperServiceModule(),  new  IndexSettingsModule(settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  new  IndexQueryParserModule(settings),  new  IndexNameModule(index),  	new  ScriptModule(settings),  
libgdx_d661aac56fe4dbc87c95bba23eccb4a828e49297	buggy:  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  context:  explosion.dispose();  }  public  boolean  isDone  ()  {  return  simulation.ship.lives  ==  0;  }  public  void  draw  (float  delta)  {  Gdx.graphics.getGL10().glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  renderer.render(simulation,  delta);  }  public  void  update  (float  delta)  {  simulation.update(delta);  float  accelerometerY  =  Gdx.input.getAccelerometerY();  	Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  
libgdx_db17325d71bec6c0769d0a7bc20060d617360000	buggy:  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.xml "),  Gdx.files.internal( "data/uiskin.png "));  context:  createUI();  multiplexer  =  new  InputMultiplexer();  Gdx.input.setInputProcessor(multiplexer);  multiplexer.addProcessor(ui);  multiplexer.addProcessor(controller);  }  private  void  createUI  ()  {  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.xml "),  Gdx.files.internal( "data/uiskin.png "));  Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  ui  =  new  Stage(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight(),  false);  String[]  filters  =  new  String[TextureFilter.values().length];  int  idx  =  0;  for  (TextureFilter  filter  :  TextureFilter.values())  {  filters[idx++]  =  filter.toString();  }  hwMipMap  =  skin.newCheckBox( "hardware ",   "Hardware  Mips ");  	Skin  skin  =  new  Skin(Gdx.files.internal( "data/uiskin.json "),  Gdx.files.internal( "data/uiskin.png "));  
elasticsearch_5d2c0056226604badc8f8121a1b7eb3c0e507b11	buggy:  if  (!(node.canAllocate(routingNodes.metaData(),  routingNodes.routingTable())  &&  node.canAllocate(shard)))  {  context:  continue;  }  RoutingNode  node  =  routingNodes.node(discoNode.id());  if  (node  ==  null)  {  continue;  }                  if  (!(node.canAllocate(routingNodes.metaData(),  routingNodes.routingTable())  &&  node.canAllocate(shard)))  {                  if  (!(node.canAllocate(routingNodes)  &&  node.canAllocate(shard)))  {  continue;  }  if  (storeFilesMetaData.allocated())  {  continue;  }  	if  (!(node.canAllocate(routingNodes)  &&  node.canAllocate(shard)))  {  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  mapper  =  context.mapperService().smartNameFieldMapper(keyField);  context:  }  else  if  ( "lang ".equals(fieldName))  {  scriptLang  =  parser.text();  }  }  }  if  (keyField  ==  null)  {  throw  new  FacetPhaseExecutionException(facetName,   "key  field  is  required  to  be  set  for  histogram  facet,  either  using  [field]  or  using  [key_field] ");  }          FieldMapper  mapper  =  context.mapperService().smartNameFieldMapper(keyField);          FieldMapper  mapper  =  context.smartNameFieldMapper(keyField);  if  (mapper  ==  null)  {  throw  new  FacetPhaseExecutionException(facetName,   "(key)  field  [ "  +  keyField  +   "]  not  found ");  }  if  (mapper.fieldDataType()  !=  FieldDataType.DefaultTypes.LONG)  {  throw  new  FacetPhaseExecutionException(facetName,   "(key)  field  [ "  +  keyField  +   "]  is  not  of  type  date ");  }  if  (!intervalSet)  {  	FieldMapper  mapper  =  context.smartNameFieldMapper(keyField);  
elasticsearch_ee26d55296f7ff31d11c666721696c1a06baaa7a	buggy:  ((InternalIndexShard)  indexShard).engine().indexingBuffer(shardIndexingBufferSize);  context:  ByteSizeValue  shardIndexingBufferSize  =  calcShardIndexingBuffer(shardsCount);  if  (shardIndexingBufferSize  ==  null)  {  return;  }  if  (shardIndexingBufferSize.bytes()  <  minShardIndexBufferSize.bytes())  {  shardIndexingBufferSize  =  minShardIndexBufferSize;  }  for  (IndexService  indexService  :  indicesService)  {  for  (IndexShard  indexShard  :  indexService)  {                      ((InternalIndexShard)  indexShard).engine().indexingBuffer(shardIndexingBufferSize);                      ((InternalIndexShard)  indexShard).engine().updateIndexingBufferSize(shardIndexingBufferSize);  }  }  }  private  ByteSizeValue  calcShardIndexingBuffer(int  shardsCount)  {  return  new  ByteSizeValue(indexingBuffer.bytes()  /  shardsCount);  }  	((InternalIndexShard)  indexShard).engine().updateIndexingBufferSize(shardIndexingBufferSize);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  false);  context:  public  void  render  ()  {  Gdx.gl.glClearColor(0.2f,  0.2f,  0.2f,  1);  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act();  stage.draw();  Table.drawDebug(stage);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  false);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  skin.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
libgdx_f4403485c763c8f14391055f14f2f62bd5436df2	buggy:  e.transform.getTranslation(tmpV);  context:  if  (world.performanceCounter  !=  null)  world.performanceCounter.start();  if  (USE_BULLET_FRUSTUM_CULLING)  getEntitiesCollidingWithObject(world,  frustumObject,  visibleEntities,  tempManifoldArr);  else  {  visibleEntities.clear();  for  (int  i  =  0;  i  <  world.entities.size;  i++)  {  final  BulletEntity  e  =  world.entities.get(i);  if  (e  ==  frustumEntity)  continue;  e.transform.getTranslation(tmpV);  e.modelInstance.transform.getTranslation(tmpV);  if  (frustumCam.frustum.sphereInFrustum(tmpV,  1))  visibleEntities.add(e);  }  }  if  (world.performanceCounter  !=  null)  world.performanceCounter.stop();  for  (int  i  =  0;  i  <  visibleEntities.size;  i++)  	e.modelInstance.transform.getTranslation(tmpV);  
libgdx_8c1eb89354495c8efffe82f0e21ce339c881aa83	buggy:  return  gdxBulletJNI.ContactAddedListenerByValue_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  userValue0,  partId0,  index0,  match0,  userValue1,  partId1,  index1,  match1);  context:  swigCMemOwn  =  false;  gdxBulletJNI.ContactAddedListenerByValue_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  gdxBulletJNI.ContactAddedListenerByValue_change_ownership(this,  swigCPtr,  true);  }  public  boolean  onContactAdded(btManifoldPoint  cp,  int  userValue0,  int  partId0,  int  index0,  boolean  match0,  int  userValue1,  int  partId1,  int  index1,  boolean  match1)  {      return  gdxBulletJNI.ContactAddedListenerByValue_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  userValue0,  partId0,  index0,  match0,  userValue1,  partId1,  index1,  match1);      return  gdxBulletJNI.ContactAddedListenerByValue_onContactAdded(swigCPtr,  this,  cp,  userValue0,  partId0,  index0,  match0,  userValue1,  partId1,  index1,  match1);  }  public  ContactAddedListenerByValue()  {  this(gdxBulletJNI.new_ContactAddedListenerByValue(),  true);  gdxBulletJNI.ContactAddedListenerByValue_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	return  gdxBulletJNI.ContactAddedListenerByValue_onContactAdded(swigCPtr,  this,  cp,  userValue0,  partId0,  index0,  match0,  userValue1,  partId1,  index1,  match1);  
libgdx_d98a1953ae203ca841166b807f514e222c96e819	buggy:  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  context:  meshShader.setUniformi(   "u_texture ",  0  );  mesh.render(meshShader,  GL20.GL_TRIANGLES);  meshShader.end();  frameBuffer.end();  Gdx.graphics.getGL20().glViewport(  0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight()  );  Gdx.graphics.getGL20().glClearColor(  0.2f,  0.2f,  0.2f,  1  );  Gdx.graphics.getGL20().glClear(  GL20.GL_COLOR_BUFFER_BIT  );  spriteBatch.begin();  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  200,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  0,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  spriteBatch.end();  }  public  void  surfaceChanged(int  width,  int  height)  {  }  	spriteBatch.draw(  frameBuffer.getColorBufferTexture(),  0,  0,  256,  256,  0,  0,  frameBuffer.getColorBufferTexture().getWidth(),  frameBuffer.getColorBufferTexture().getHeight(),  Color.WHITE,  false,  true  );  
elasticsearch_265b386fa75f9446378e65002d9fc16766e67892	buggy:  int  numberOfUpdates  =  scaledRandomIntBetween(1,  5);  context:  Filter  filterMe;  if  (random().nextBoolean())  {  filterMe  =  SearchContext.current().filterCache().cache(rawFilterMe);  }  else  {  filterMe  =  rawFilterMe;  }  if  (random().nextBoolean())  {                  int  numberOfUpdates  =  scaledRandomIntBetween(1,  5);                  int  numberOfUpdates  =  childIdToParentId.isEmpty()  ?  0  :  scaledRandomIntBetween(1,  5);  int[]  childIds  =  childIdToParentId.keys().toArray();  for  (int  j  =  0;  j  <  numberOfUpdates;  j++)  {  int  childId  =  childIds[random().nextInt(childIds.length)];  String  childUid  =  Uid.createUid( "child ",  Integer.toString(childId));  indexWriter.deleteDocuments(new  Term(UidFieldMapper.NAME,  childUid));  Document  document  =  new  Document();  document.add(new  StringField(UidFieldMapper.NAME,  childUid,  Field.Store.YES));  	int  numberOfUpdates  =  childIdToParentId.isEmpty()  ?  0  :  scaledRandomIntBetween(1,  5);  
elasticsearch_79ab05cdcfd369207bda48531bb2788bbf53bae7	buggy:  final  int  numberOfRuns  =  10;  context:  public  class  ClusterAllocationRerouteBenchmark  {  private  static  final  ESLogger  logger  =  Loggers.getLogger(ClusterAllocationRerouteBenchmark.class);  public  static  void  main(String[]  args)  {          final  int  numberOfRuns  =  10;          final  int  numberOfRuns  =  1;  final  int  numIndices  =  5  *  365;  //  five  years  final  int  numShards  =  6;  final  int  numReplicas  =  2;  final  int  numberOfNodes  =  30;  final  int  numberOfTags  =  2;  AllocationService  strategy  =  new  AllocationService(settingsBuilder().build());  	final  int  numberOfRuns  =  1;  
libgdx_5f1027544f3cd6b9fd3ab0406c3cf33f11d0fb35	buggy:  public  boolean  handle  (Event  event);  context:  ++  libgdx_5f1027544f3cd6b9fd3ab0406c3cf33f11d0fb35_47.java  package  com.badlogic.gdx.scenes.scene2d;  public  interface  EventListener  {  public  boolean  handle  (Event  event);  public  void  handle  (Event  event);  }  	public  void  handle  (Event  event);  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  builder.startObject(name).startObject(type);  context:  public  abstract  class  MetricsAggregationBuilder<B  extends  MetricsAggregationBuilder<B>>  extends  AbstractAggregationBuilder  {  public  MetricsAggregationBuilder(String  name,  String  type)  {  super(name,  type);  }  public  final  XContentBuilder  toXContent(XContentBuilder  builder,  Params  params)  throws  IOException  {          builder.startObject(name).startObject(type);          builder.startObject(getName()).startObject(type);  internalXContent(builder,  params);  return  builder.endObject().endObject();  }  protected  abstract  void  internalXContent(XContentBuilder  builder,  Params  params)  throws  IOException;  }  	builder.startObject(getName()).startObject(type);  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  filter  =  context.queryParserService().parseInnerFilter(parser);  context:  Filter  filter  =  null;  boolean  cacheFilter  =  false;  String  nestedPath  =  null;  String  fieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  fieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "facet_filter ".equals(fieldName)  ||   "facetFilter ".equals(fieldName))  {                              filter  =  context.queryParserService().parseInnerFilter(parser);                              filter  =  context.queryParserService().parseInnerFilter(parser).filter();  }  else  {  FacetParser  facetParser  =  facetParsers.parser(fieldName);  if  (facetParser  ==  null)  {  throw  new  SearchParseException(context,   "No  facet  type  found  for  [ "  +  fieldName  +   "] ");  }  facetExecutor  =  facetParser.parse(facetName,  parser,  context);  defaultMainMode  =  facetParser.defaultMainMode();  defaultGlobalMode  =  facetParser.defaultGlobalMode();  	filter  =  context.queryParserService().parseInnerFilter(parser).filter();  
elasticsearch_f19f729498a76158095549cbdcebbb9f6d0f91e4	buggy:  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  context:  Table  tab  =  buildTable(request,  pendingClusterTasks);  channel.sendResponse(RestTable.buildResponse(tab,  request,  channel));  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {                      channel.sendResponse(new  XContentThrowableRestResponse(request,  e));                      channel.sendResponse(new  BytesRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  }  });  }  	channel.sendResponse(new  BytesRestResponse(request,  e));  
elasticsearch_be6aaa157f66a1761169b4205c696fdf1be2df10	buggy:  newSnapshot.seekForward(memorySnapshot.length());  context:  }  }  synchronized  (mutex)  {  MemorySnapshot  memorySnapshot  =  (MemorySnapshot)  snapshot;  if  (currentId()  !=  snapshot.translogId())  {  return  snapshot();  }  MemorySnapshot  newSnapshot  =  new  MemorySnapshot(currentId(),  operations,  operationCounter.get());              newSnapshot.seekForward(memorySnapshot.length());              newSnapshot.seekForward(memorySnapshot.position());  return  newSnapshot;  }  }  }  }  	newSnapshot.seekForward(memorySnapshot.position());  
elasticsearch_560d2c094e6d8c2c8605a0b1c45afb006e072e6f	buggy:  if  (DirectoryReader.indexExists(store.directory()))  {  context:  throw  new  IndexShardGatewayRecoveryException(shardId,   "Interrupted  while  recovering  index ",  e);  }  if  (!failures.isEmpty())  {  throw  new  IndexShardGatewayRecoveryException(shardId,   "Failed  to  recover  index ",  failures.get(0));  }  long  version  =  -1;  try  {              if  (DirectoryReader.indexExists(store.directory()))  {              if  (Lucene.indexExists(store.directory()))  {  version  =  Lucene.readSegmentInfos(store.directory()).getVersion();  }  }  catch  (IOException  e)  {  throw  new  IndexShardGatewayRecoveryException(shardId(),   "Failed  to  fetch  index  version  after  copying  it  over ",  e);  }  recoveryStatus.index().updateVersion(version);  	if  (Lucene.indexExists(store.directory()))  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  AnalyzeRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.READ);  }  protected  ClusterBlockException  checkRequestBlock(ClusterState  state,  AnalyzeRequest  request)  {  if  (request.index()  !=  null)  {              request.index(state.metaData().concreteIndex(request.index()));              request.index(state.metaData().concreteSingleIndex(request.index()));  return  state.blocks().indexBlockedException(ClusterBlockLevel.READ,  request.index());  }  return  null;  }  protected  ShardsIterator  shards(ClusterState  state,  AnalyzeRequest  request)  {  if  (request.index()  ==  null)  {  	request.index(state.metaData().concreteSingleIndex(request.index()));  
libgdx_31c5b74028f0be7430fd668e08d8d012c9d2bdad	buggy:  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.FixedPointMeshRendererTest()  );  context:  public  class  FixedPointMeshRendererTest  extends  AndroidApplication  {  public  void  onCreate(  Bundle  bundle  )  {  super.onCreate(  bundle  );  initialize(  false  );  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.FixedPointMeshRendererTest()  );  getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.FixedPointMeshTest()  );  }  }  	getGraphics().setRenderListener(  new  com.badlogic.gdx.tests.FixedPointMeshTest()  );  
elasticsearch_454954e7be9fecf80311fbbfd184e22cd827f4e2	buggy:  public  int  reducedType()  {  context:  private  InnerSource(SearchScript  script)  {  this.script  =  script;  }  public  FieldComparator  newComparator(String  fieldname,  int  numHits,  int  sortPos,  boolean  reversed)  throws  IOException  {  return  new  DoubleFieldsFunctionDataComparator(numHits,  script);  }          public  int  reducedType()  {          public  SortField.Type  reducedType()  {  return  SortField.DOUBLE;  }  }  private  final  SearchScript  script;  private  final  double[]  values;  private  double  bottom;  	public  SortField.Type  reducedType()  {  
elasticsearch_526f28f47981bfa83d79f5c09b2f6b5724649b78	buggy:  if  (source.size()  !=  1  ||  source.containsKey(type))  {  context:  }  public  CreateIndexRequest  mapping(String  type,  Map  source)  {          if  (source.size()  !=  1  ||  source.containsKey(type))  {          if  (source.size()  !=  1  ||  !source.containsKey(type))  {  source  =  MapBuilder.<String,  Object>newMapBuilder().put(type,  source).map();  }  try  {  XContentBuilder  builder  =  XContentFactory.contentBuilder(XContentType.JSON);  builder.map(source);  return  mapping(type,  builder.string());  }  catch  (IOException  e)  {  throw  new  ElasticSearchGenerationException( "Failed  to  generate  [ "  +  source  +   "] ",  e);  	if  (source.size()  !=  1  ||  !source.containsKey(type))  {  
elasticsearch_371d6021e7e381cc7d26261d74a4dcc25d37d9a8	buggy:  if  (pos  <  0)  {  context:  if  (debugEnabled())  {  LOGGER.debug( "Holes:   "  +  Arrays.toString(holes));  }  for  (int  i  =  0;  i  <  numHoles;  i++)  {  final  Edge  current  =  new  Edge(holes[i].coordinate,  holes[i].next);  current.intersect  =  current.coordinate;  final  int  intersections  =  intersections(current.coordinate.x,  edges);  final  int  pos  =  Arrays.binarySearch(edges,  0,  intersections,  current,  INTERSECTION_ORDER);              if  (pos  <  0)  {              if  (pos  >=  0)  {  throw  new  ElasticsearchParseException( "Invaild  shape:  Hole  is  not  within  polygon ");  }  final  int  index  =  -(pos+2);  final  int  component  =  -edges[index].component  -  numHoles  -  1;  if(debugEnabled())  {  LOGGER.debug( "\tposition  ( "+index+ ")  of  edge   "+current+ ":   "  +  edges[index]);  LOGGER.debug( "\tComponent:   "  +  component);  	if  (pos  >=  0)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();  context:  public  static  void  main(String[]  args)  throws  Exception  {  int  minTerms  =  1;  int  maxTerms  =  50;  int  maxIter  =  100;  int  warmerIter  =  10;  boolean  runMVEL  =  false;  init(maxTerms);          List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();          List<Results>  allResults  =  new  ArrayList<>();  Settings  settings  =  settingsBuilder().put( "plugin.types ",  NativeScriptExamplesPlugin.class.getName()).build();  String  clusterName  =  ScriptsScoreBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().clusterName(clusterName).settings(settingsBuilder().put(settings).put( "name ",   "node1 ")).node();  Client  client  =  node1.client();  client.admin().cluster().prepareHealth( "test ").setWaitForGreenStatus().setTimeout( "10s ").execute().actionGet();  indexData(10000,  client,  false);  	List<Results>  allResults  =  new  ArrayList<>();  
elasticsearch_b17e074f07e495874195800dde8e2fe50c5d7535	buggy:   "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ");  context:  return  this;  }  if  (Strings.hasLength(value))  {  return  super.appendOpt(sysPropName,  value);  }  return  this;  }  public  ReproduceErrorMessageBuilder  appendESProperties()  {  appendProperties( "es.logger.level ",   "es.node.mode ",   "es.node.local ",  TestCluster.TESTS_ENABLE_MOCK_MODULES,                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ");                       "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ");  if  (System.getProperty( "tests.jvm.argline ")  !=  null  &&  !System.getProperty( "tests.jvm.argline ").isEmpty())  {  appendOpt( "tests.jvm.argline ",   "\ " "  +  System.getProperty( "tests.jvm.argline ")  +   "\ " ");  }  return  this;  }  protected  ReproduceErrorMessageBuilder  appendProperties(String...  properties)  {  for  (String  sysPropName  :  properties)  {  	 "tests.assertion.disabled ",   "tests.security.manager ",   "tests.nighly ",   "tests.jvms ",   "tests.client.ratio ");  
elasticsearch_8dedbd01df14c76fc8f1ac9060facc053fa2be9b	buggy:  if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {  context:  }  protected  void  doExecute(GetFieldMappingsRequest  request,  final  ActionListener<GetFieldMappingsResponse>  listener)  {  ClusterState  clusterState  =  clusterService.state();  String[]  concreteIndices  =  clusterState.metaData().concreteIndices(request.indicesOptions(),  request.indices());  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);          if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {          if  (concreteIndices.length  ==  0)  {  listener.onResponse(new  GetFieldMappingsResponse());  }  else  {  boolean  probablySingleFieldRequest  =  concreteIndices.length  ==  1  &&  request.types().length  ==  1  &&  request.fields().length  ==  1;  for  (final  String  index  :  concreteIndices)  {  GetFieldMappingsIndexRequest  shardRequest  =  new  GetFieldMappingsIndexRequest(request,  index,  probablySingleFieldRequest);  shardRequest.listenerThreaded(false);  shardAction.execute(shardRequest,  new  ActionListener<GetFieldMappingsResponse>()  {  	if  (concreteIndices.length  ==  0)  {  
elasticsearch_6342beeeb0a4624fb1cc6fcdd0e17c247fac550b	buggy:  return  resolveNamedStopWords(stopWords,  version,  ignore_case);  context:  }  else  {  return  resolveNamedStopWords(Strings.commaDelimitedListToSet(value),  version,  ignore_case);  }  }  String[]  stopWords  =  settings.getAsArray( "stopwords ",  null);  if  (stopWords  !=  null)  {  return  resolveNamedStopWords(stopWords,  version,  ignore_case);  }  List<String>  pathLoadedStopWords  =  getWordList(env,  settings,   "stopwords ");  if  (pathLoadedStopWords  !=  null)  {              return  resolveNamedStopWords(stopWords,  version,  ignore_case);              return  resolveNamedStopWords(pathLoadedStopWords,  version,  ignore_case);  }  return  defaultStopWords;  }  private  static  CharArraySet  resolveNamedStopWords(Collection<String>  words,  Version  version,  boolean  ignore_case)  {  CharArraySet  setStopWords  =  new  CharArraySet(version,  words.size(),  ignore_case);  for  (String  stopWord  :  words)  {  	return  resolveNamedStopWords(pathLoadedStopWords,  version,  ignore_case);  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);  context:  if  (smartMappers  ==  null  ||  !smartMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  geo_point  field  [ "  +  fieldName  +   "] ");  }  FieldMapper<?>  mapper  =  smartMappers.mapper();  if  (!(mapper  instanceof  GeoPointFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "field  [ "  +  fieldName  +   "]  is  not  a  geo_point  field ");  }  GeoPointFieldMapper  geoMapper  =  ((GeoPointFieldMapper)  mapper);          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  Filter  filter  =  new  GeoDistanceFilter(point.lat(),  point.lon(),  distance,  geoDistance,  indexFieldData,  geoMapper,  optimizeBbox);  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  
libgdx_72c71776d155fa8f4ea2b369c202141ddf75df58	buggy:  renderBatch.addModel(instances.get(i).model,  instances.get(i).transform,  lights);  context:  exclusiveTextures.resetCounts();  }  GL20  gl  =  Gdx.gl20;  gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.gl.glClearColor(0,  0,  0,  0);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT  |  GL10.GL_DEPTH_BUFFER_BIT);  Gdx.gl.glDisable(GL20.GL_CULL_FACE);  renderBatch.begin(cam);  for  (int  i  =  0;  i  <  instances.size;  i++)  renderBatch.addModel(instances.get(i).model,  instances.get(i).transform,  lights);  renderBatch.render(instances.get(i).model,  instances.get(i).transform,  lights);  renderBatch.end();  }  public  boolean  touchDown  (int  x,  int  y,  int  pointer,  int  newParam)  {  touchStartX  =  x;  touchStartY  =  y;  return  false;  	renderBatch.render(instances.get(i).model,  instances.get(i).transform,  lights);  
elasticsearch_7f0034d42fa92b1a566d8684a17aa11cc533a13b	buggy:  builder.field(Fields.LARGEST,  rejected);  context:  if  (queue  !=  -1)  {  builder.field(Fields.QUEUE,  queue);  }  if  (active  !=  -1)  {  builder.field(Fields.ACTIVE,  active);  }  if  (rejected  !=  -1)  {  builder.field(Fields.REJECTED,  rejected);  }  if  (largest  !=  -1)  {                  builder.field(Fields.LARGEST,  rejected);                  builder.field(Fields.LARGEST,  largest);  }  if  (completed  !=  -1)  {  builder.field(Fields.COMPLETED,  completed);  }  builder.endObject();  return  builder;  }  }  	builder.field(Fields.LARGEST,  largest);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  fieldMapper  =  context.mapperService().smartNameFieldMapper(fieldName);  context:  }  else  {  sortFields.add(SORT_SCORE);  }  }  else  if  (DOC_FIELD_NAME.equals(fieldName))  {  if  (reverse)  {  sortFields.add(SORT_DOC_REVERSE);  }  else  {  sortFields.add(SORT_DOC);  }  }  else  {              FieldMapper  fieldMapper  =  context.mapperService().smartNameFieldMapper(fieldName);              FieldMapper  fieldMapper  =  context.smartNameFieldMapper(fieldName);  if  (fieldMapper  ==  null)  {  throw  new  SearchParseException(context,   "No  mapping  found  for  [ "  +  fieldName  +   "] ");  }  sortFields.add(new  SortField(fieldMapper.names().indexName(),  fieldMapper.fieldDataType().newFieldComparatorSource(context.fieldDataCache(),  missing),  reverse));  }  }  }  	FieldMapper  fieldMapper  =  context.smartNameFieldMapper(fieldName);  
elasticsearch_428080b49a8032a0ae4af6ff06b306b33dc3ef7c	buggy:  assertSearchResponse(response);System.out.println(response);  context:  public  void  sizeIsZero()  {  final  int  minDocCount  =  randomInt(1);  SearchResponse  response  =  client().prepareSearch( "idx ").setTypes( "high_card_type ")  .addAggregation(terms( "terms ")  .executionHint(randomExecutionHint())  .field(SINGLE_VALUED_FIELD_NAME)  .minDocCount(minDocCount)  .size(0))  .execute().actionGet();          assertSearchResponse(response);System.out.println(response);          assertSearchResponse(response);  Terms  terms  =  response.getAggregations().get( "terms ");  assertThat(terms,  notNullValue());  assertThat(terms.getName(),  equalTo( "terms "));  assertThat(terms.getBuckets().size(),  equalTo(minDocCount  ==  0  ?  105  :  100));  //  105  because  of  the  other  type  }  	assertSearchResponse(response);  
elasticsearch_5f986ef4224f85b8ca3d8c9f977fd95c58f7e29d	buggy:  Query  query  =  new  DeletionAwareConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));  context:  if  (context.facets()  ==  null)  {  return;  }  if  (context.queryResult().facets()  !=  null)  {  return;  }  if  (context.searcher().globalCollectors()  !=  null)  {              Query  query  =  new  DeletionAwareConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));              Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER);  //  no  need  to  cache  a  MATCH  ALL  FILTER  if  (context.types().length  >  0)  {  if  (context.types().length  ==  1)  {  String  type  =  context.types()[0];  DocumentMapper  docMapper  =  context.mapperService().documentMapper(type);  Filter  typeFilter  =  new  TermFilter(docMapper.typeMapper().term(docMapper.type()));  typeFilter  =  context.filterCache().cache(typeFilter);  query  =  new  FilteredQuery(query,  typeFilter);  }  else  {  	Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER);  //  no  need  to  cache  a  MATCH  ALL  FILTER  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  String  script  =  Streams.copyToString(new  InputStreamReader(new  FileInputStream(file),   "UTF-8 "));  context:  int  extIndex  =  file.getName().lastIndexOf('.');  if  (extIndex  !=  -1)  {  String  ext  =  file.getName().substring(extIndex  +  1);  String  scriptName  =  prefix  +  file.getName().substring(0,  extIndex);  boolean  found  =  false;  for  (ScriptEngineService  engineService  :  scriptEngines.values())  {  for  (String  s  :  engineService.extensions())  {  if  (s.equals(ext))  {  found  =  true;  try  {                                      String  script  =  Streams.copyToString(new  InputStreamReader(new  FileInputStream(file),   "UTF-8 "));                                      String  script  =  Streams.copyToString(new  InputStreamReader(new  FileInputStream(file),  Streams.UTF8));  staticCache.put(scriptName,  new  CompiledScript(engineService.types()[0],  engineService.compile(script)));  }  catch  (Exception  e)  {  }  break;  }  }  if  (found)  {  	String  script  =  Streams.copyToString(new  InputStreamReader(new  FileInputStream(file),  Streams.UTF8));  
libgdx_8716aeb8ff465eb32c7679cbea52205aa406f599	buggy:  Gdx.app.log( "AssetManagerTest ",   "\n "  +  manager.getDiagonistics()  +   "\n "  +  Texture.getManagedStatus());  context:  private  void  invalidateTexture(Texture  texture)  {  IntBuffer  buffer  =  BufferUtils.newIntBuffer(1);  buffer.put(0,  texture.getTextureObjectHandle());  Gdx.gl.glDeleteTextures(1,  buffer);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  boolean  result  =  manager.update();  if  (result  &  !diagnosed)  {  Gdx.app.log( "AssetManagerTest ",   "\n "  +  manager.getDiagonistics()  +   "\n "  +  Texture.getManagedStatus());  Gdx.app.log( "AssetManagerTest ",   "\n "  +  manager.getDiagnostics()  +   "\n "  +  Texture.getManagedStatus());  diagnosed  =  false;  	Gdx.app.log( "AssetManagerTest ",   "\n "  +  manager.getDiagnostics()  +   "\n "  +  Texture.getManagedStatus());  
elasticsearch_30f54fe23e8a782ffd2db3e6e6d73b138b64645a	buggy:  TimeValue  optimizeInterval  =  indexSettings.getAsTime( "index.merge.async_interval ",  TimeValue.timeValueSeconds(30));  context:  TimeValue  refreshInterval  =  ((ScheduledRefreshableEngine)  engine).refreshInterval();  if  (refreshInterval.millis()  >  0)  {  refreshScheduledFuture  =  threadPool.scheduleWithFixedDelay(new  EngineRefresher(),  refreshInterval);  }  else  {  }  }          TimeValue  optimizeInterval  =  indexSettings.getAsTime( "index.merge.async_interval ",  TimeValue.timeValueSeconds(30));          TimeValue  optimizeInterval  =  indexSettings.getAsTime( "index.merge.async_interval ",  TimeValue.timeValueSeconds(1));  if  (optimizeInterval.millis()  >  0)  {  optimizeScheduleFuture  =  threadPool.scheduleWithFixedDelay(new  EngineOptimizer(),  optimizeInterval);  }  else  {  }  }  	TimeValue  optimizeInterval  =  indexSettings.getAsTime( "index.merge.async_interval ",  TimeValue.timeValueSeconds(1));  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  termsIndex  =  indexFieldData.load(context).getBytesValues(false);  context:  ord  =  ((-2  -  docOrd)  <<  2)  +  2;  }  }  assert  (ord  &  1)  ==  0;  return  ord;  }  public  FieldComparator<BytesRef>  setNextReader(AtomicReaderContext  context)  throws  IOException  {          termsIndex  =  indexFieldData.load(context).getBytesValues(false);          termsIndex  =  indexFieldData.load(context).getBytesValues();  assert  termsIndex.ordinals()  !=  null;  missingOrd  =  ordInCurrentReader(termsIndex,  missingValue);  assert  consistentInsertedOrd(termsIndex,  missingOrd,  missingValue);  FieldComparator<BytesRef>  perSegComp  =  null;  assert  termsIndex.ordinals()  !=  null;  if  (termsIndex.isMultiValued())  {  perSegComp  =  new  PerSegmentComparator(termsIndex)  {  	termsIndex  =  indexFieldData.load(context).getBytesValues();  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataIndexAliasesService  indexAliasesService;  ThreadPool  threadPool,  MetaDataIndexAliasesService  indexAliasesService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.indexAliasesService  =  indexAliasesService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.ALIASES;  }  return  new  IndicesAliasesRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_f49f3e169aaec2a1ea46496b4c01d8427e97058c	buggy:  fieldSelector.add(context.mapperService().uidFieldMappers());  context:  }  FieldMappersFieldSelector  fieldSelector  =  new  FieldMappersFieldSelector();  for  (String  fieldName  :  context.fieldNames())  {  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);  if  (x  ==  null)  {  throw  new  FetchPhaseExecutionException(context,   "No  mapping  for  field  [ "  +  fieldName  +   "] ");  }  fieldSelector.add(x);  }          fieldSelector.add(context.mapperService().uidFieldMappers());          fieldSelector.add(UidFieldMapper.NAME);  return  fieldSelector;  }  }  	fieldSelector.add(UidFieldMapper.NAME);  
elasticsearch_1517fa3d286e069af8806bbc2f0e8783eaddabbf	buggy:  totalSizeInBytes  +=  file.sizeInBytes();  context:  return  allocated;  }  public  ShardId  shardId()  {  return  this.shardId;  }  public  long  totalSizeInBytes()  {  long  totalSizeInBytes  =  0;  for  (StoreFileMetaData  file  :  this)  {                  totalSizeInBytes  +=  file.sizeInBytes();                  totalSizeInBytes  +=  file.length();  }  return  totalSizeInBytes;  }  return  files.values().iterator();  }  	totalSizeInBytes  +=  file.length();  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  lastOperationRead  =  TranslogStreams.readTranslogOperation(new  BytesStreamInput(cacheBuffer.array(),  0,  opSize));  context:  return  false;  }  if  (cacheBuffer.capacity()  <  opSize)  {  cacheBuffer  =  ByteBuffer.allocate(opSize);  }  cacheBuffer.clear();  cacheBuffer.limit(opSize);  channel.read(cacheBuffer,  position);  cacheBuffer.flip();  position  +=  opSize;              lastOperationRead  =  TranslogStreams.readTranslogOperation(new  BytesStreamInput(cacheBuffer.array(),  0,  opSize));              lastOperationRead  =  TranslogStreams.readTranslogOperation(new  BytesStreamInput(cacheBuffer.array(),  0,  opSize,  true));  return  true;  }  catch  (Exception  e)  {  return  false;  }  }  public  Translog.Operation  next()  {  	lastOperationRead  =  TranslogStreams.readTranslogOperation(new  BytesStreamInput(cacheBuffer.array(),  0,  opSize,  true));  
elasticsearch_f554178fc72ea575bfa42db8d24c0afe41f85d4d	buggy:  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);  context:  public  void  doRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  String[]  indices  =  Strings.splitStringByCommaToArray(request.param( "index "));  final  ClusterStateRequest  clusterStateRequest  =  new  ClusterStateRequest();  clusterStateRequest.clear().indices(indices).metaData(true);  clusterStateRequest.local(request.paramAsBoolean( "local ",  clusterStateRequest.local()));  clusterStateRequest.masterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterStateRequest.masterNodeTimeout()));  client.admin().cluster().state(clusterStateRequest,  new  RestActionListener<ClusterStateResponse>(channel)  {  public  void  processResponse(final  ClusterStateResponse  clusterStateResponse)  {                  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.IGNORE_UNAVAILABLE_EXPAND_OPEN_ONLY);                  final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  ClusterHealthRequest  clusterHealthRequest  =  Requests.clusterHealthRequest(concreteIndices);  clusterHealthRequest.local(request.paramAsBoolean( "local ",  clusterHealthRequest.local()));  client.admin().cluster().health(clusterHealthRequest,  new  RestActionListener<ClusterHealthResponse>(channel)  {  public  void  processResponse(final  ClusterHealthResponse  clusterHealthResponse)  {  IndicesStatsRequest  indicesStatsRequest  =  new  IndicesStatsRequest();  indicesStatsRequest.all();  client.admin().indices().stats(indicesStatsRequest,  new  RestResponseListener<IndicesStatsResponse>(channel)  {  	final  String[]  concreteIndices  =  clusterStateResponse.getState().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  
elasticsearch_e3a9271000128121c056ac59dfe6c7fede80f0d1	buggy:  long  count  =  Lucene.count(searcher.searcher(),  query,  -1f);  context:  private  final  int  totalHits;  public  EngineSearcherTotalHitsMatcher(Query  query,  int  totalHits)  {  this.query  =  query;  this.totalHits  =  totalHits;  }  public  boolean  matchesSafely(Engine.Searcher  searcher)  {  try  {              long  count  =  Lucene.count(searcher.searcher(),  query,  -1f);              long  count  =  Lucene.count(searcher.searcher(),  query);  return  count  ==  totalHits;  }  catch  (IOException  e)  {  return  false;  }  }  public  void  describeTo(Description  description)  {  	long  count  =  Lucene.count(searcher.searcher(),  query);  
elasticsearch_30c6f2fa23c9db62acdbc7d7bfb643e8182c4d67	buggy:  allocation.routingNodes().assignShardToNode(  shardRouting,  routingNode.nodeId()  );  context:  Decision  decision  =  allocation.deciders().canAllocate(shardRouting,  routingNode,  allocation);  if  (decision.type()  ==  Decision.Type.NO)  {  throw  new  ElasticSearchIllegalArgumentException( "[allocate]  allocation  of   "  +  shardId  +   "  on  node   "  +  discoNode  +   "  is  not  allowed,  reason:   "  +  decision);  }  for  (Iterator<MutableShardRouting>  it  =  allocation.routingNodes().unassigned().iterator();  it.hasNext();  )  {  if  (it.next()  !=  shardRouting)  {  continue;  }  it.remove();              allocation.routingNodes().assignShardToNode(  shardRouting,  routingNode.nodeId()  );              allocation.routingNodes().assign(shardRouting,  routingNode.nodeId());  if  (shardRouting.primary())  {  allocation.routingNodes().addClearPostAllocationFlag(shardRouting.shardId());  }  break;  }  }  	allocation.routingNodes().assign(shardRouting,  routingNode.nodeId());  
elasticsearch_29d337c44b7dd263a0fea2e0ef0de4b2e9b57657	buggy:  }  catch  (final  Exception  e)  {  context:  final  TransportRequestOptions  options,  final  TransportResponseHandler<T>  handler)  throws  TransportException  {  final  long  requestId  =  newRequestId();  TimeoutHandler  timeoutHandler  =  null;  try  {  if  (options.timeout()  !=  null)  {  timeoutHandler  =  new  TimeoutHandler(requestId);  timeoutHandler.future  =  threadPool.schedule(options.timeout(),  ThreadPool.Names.GENERIC,  timeoutHandler);  }  clientHandlers.put(requestId,  new  RequestHolder<T>(handler,  node,  action,  timeoutHandler));  transport.sendRequest(node,  requestId,  action,  request,  options);          }  catch  (final  Exception  e)  {          }  catch  (final  Throwable  e)  {  clientHandlers.remove(requestId);  if  (timeoutHandler  !=  null)  {  timeoutHandler.future.cancel(false);  }  if  (throwConnectException)  {  if  (e  instanceof  ConnectTransportException)  {  	}  catch  (final  Throwable  e)  {  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  fields.add(toDocValues((int)  value));  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomShortNumericField  field  =  new  CustomShortNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              fields.add(toDocValues((int)  value));              addDocValue(context,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  value);  
elasticsearch_5ea6c77dad00b90ed73779a4d936cc61c6fa0a3f	buggy:  if  (fieldsVisitor.fields()  !=  null)  {  context:  }  InternalSearchHit[]  hits  =  new  InternalSearchHit[context.docIdsToLoadSize()];  for  (int  index  =  0;  index  <  context.docIdsToLoadSize();  index++)  {  int  docId  =  context.docIdsToLoad()[context.docIdsToLoadFrom()  +  index];  loadStoredFields(context,  fieldsVisitor,  docId);  fieldsVisitor.postProcess(context.mapperService());  Map<String,  SearchHitField>  searchFields  =  null;              if  (fieldsVisitor.fields()  !=  null)  {              if  (!fieldsVisitor.fields().isEmpty())  {  searchFields  =  new  HashMap<String,  SearchHitField>(fieldsVisitor.fields().size());  for  (Map.Entry<String,  List<Object>>  entry  :  fieldsVisitor.fields().entrySet())  {  searchFields.put(entry.getKey(),  new  InternalSearchHitField(entry.getKey(),  entry.getValue()));  }  }  DocumentMapper  documentMapper  =  context.mapperService().documentMapper(fieldsVisitor.uid().type());  Text  typeText;  	if  (!fieldsVisitor.fields().isEmpty())  {  
libgdx_96b45536a97092f632fb744ff7b857f7e970d19d	buggy:  currentShader.setUniformf( "camPos ",  cam.position.x,  cam.position.y,  cam.position.z);  context:  boolean  bindShader  (Material  material)  {  ShaderProgram  shader  =  material.getShader();  if  (shader  ==  currentShader)  return  false;  currentShader  =  shader;  currentShader.begin();  lightManager.applyGlobalLights(currentShader);  lightManager.applyLights(currentShader);  currentShader.setUniformMatrix( "u_projectionViewMatrix ",  cam.combined);  currentShader.setUniformf( "camPos ",  cam.position.x,  cam.position.y,  cam.position.z);  currentShader.setUniformf( "camPos ",  cam.position.x,  cam.position.y,  cam.position.z,  1.2f  /  cam.far);  currentShader.setUniformf( "camDir ",  cam.direction.x,  cam.direction.y,  cam.direction.z);  return  true;  }  public  void  dispose  ()  {  materialShaderHandler.dispose();  }  	currentShader.setUniformf( "camPos ",  cam.position.x,  cam.position.y,  cam.position.z,  1.2f  /  cam.far);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ArrayList<FieldMapper>  mappers  =  new  ArrayList<FieldMapper>(fieldsNames.length);  context:  }  if  (shardSize  <  size)  {  shardSize  =  size;  }  if  (fieldsNames  !=  null)  {              ArrayList<FieldMapper>  mappers  =  new  ArrayList<FieldMapper>(fieldsNames.length);              ArrayList<FieldMapper>  mappers  =  new  ArrayList<>(fieldsNames.length);  for  (int  i  =  0;  i  <  fieldsNames.length;  i++)  {  FieldMapper  mapper  =  context.smartNameFieldMapper(fieldsNames[i]);  if  (mapper  !=  null)  {  mappers.add(mapper);  }  }  if  (mappers.isEmpty())  {  	ArrayList<FieldMapper>  mappers  =  new  ArrayList<>(fieldsNames.length);  
elasticsearch_deada942e5c85f49e7452291c4242cb41b784eef	buggy:  boolean  cache  =  true;  context:  return  new  String[]{NAME};  }  XContentParser  parser  =  parseContext.parser();  Query  query  =  null;  Filter  filter  =  null;  float  boost  =  1.0f;          boolean  cache  =  true;          boolean  cache  =  false;  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "query ".equals(currentFieldName))  {  	boolean  cache  =  false;  
libgdx_61a644025318b4de08386a63162ca5eae8303b0b	buggy:  System.out.println( "dispose  game  screen ");  context:  game.setScreen(new  GameOverScreen(game));  }  if  (Gdx.input.isKeyPressed(Keys.ESCAPE))  {  game.setScreen(new  MainMenu(game));  }  }  public  void  hide  ()  {  System.out.println( "dispose  game  screen ");  Gdx.app.debug( "Cubocy ",   "dispose  game  screen ");  renderer.dispose();  controlRenderer.dispose();  }  }  	Gdx.app.debug( "Cubocy ",   "dispose  game  screen ");  
elasticsearch_23d2b1ea7b191f27f8882494b520b8d6f443f7de	buggy:  .setFilter(FilterBuilders.geoDistanceFilter( "pin ")  context:  ensureYellow();  client().admin().indices().prepareCreate( "locations ").addMapping( "location ",  mapping).execute().actionGet();  client().prepareIndex( "locations ",   "location ",   "1 ").setCreate(true).setSource(source).execute().actionGet();  client().admin().indices().prepareRefresh( "locations ").execute().actionGet();  client().prepareGet( "locations ",   "location ",   "1 ").execute().actionGet();  SearchResponse  result  =  client().prepareSearch( "locations ")  .setQuery(QueryBuilders.matchAllQuery())                  .setFilter(FilterBuilders.geoDistanceFilter( "pin ")                  .setPostFilter(FilterBuilders.geoDistanceFilter( "pin ")  .geoDistance(GeoDistance.ARC)  .lat(lat).lon(lon)  .distance( "1m "))  .execute().actionGet();  assertHitCount(result,  1);  }  	.setPostFilter(FilterBuilders.geoDistanceFilter( "pin ")  
elasticsearch_3c95d6a2153b8243d376725363340488f727a7f6	buggy:  void  close(boolean  delete);  context:  package  org.elasticsearch.indexer;  public  interface  Indexer  extends  IndexerComponent  {      void  close(boolean  delete);      void  close();  }  	void  close();  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()  context:  public  class  TenShardsOneReplicaRoutingTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(TenShardsOneReplicaRoutingTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder()          AllocationService  strategy  =  new  AllocationService(settingsBuilder()  .put( "cluster.routing.allocation.node_concurrent_recoveries ",  10)  .put( "cluster.routing.allocation.node_initial_primaries_recoveries ",  10)  .put( "cluster.routing.allocation.allow_rebalance ",   "always ")  .put( "cluster.routing.allocation.cluster_concurrent_rebalance ",  -1)  .build());  	AllocationService  strategy  =  new  AllocationService(settingsBuilder()  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (FloatFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_d069212ce46b0dc6800a74b654affee139a62a28	buggy:  }  else  if  (value  ==  Short.class)  {  context:  writeLong(((Date)  value).getTime());  }  else  if  (value  instanceof  ReadableInstant)  {  writeByte((byte)  13);  writeLong(((ReadableInstant)  value).getMillis());  }  else  if  (value  instanceof  BytesReference)  {  writeByte((byte)  14);  writeBytesReference((BytesReference)  value);  }  else  if  (value  instanceof  Text)  {  writeByte((byte)  15);  writeText((Text)  value);          }  else  if  (value  ==  Short.class)  {          }  else  if  (type  ==  Short.class)  {  writeByte((byte)  16);  writeShort((Short)  value);  }  else  {  throw  new  IOException( "Can't  write  type  [ "  +  type  +   "] ");  }  }  }  	}  else  if  (type  ==  Short.class)  {  
elasticsearch_a62f1f3e0dc0716918945d5d9ff48503c90ccb2c	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  context:  return   "/cluster/ping/broadcast/shard ";  }  return  new  BroadcastPingRequest();  }          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null);  }  int  successfulShards  =  0;  int  failedShards  =  0;  List<ShardOperationFailedException>  shardFailures  =  null;  for  (int  i  =  0;  i  <  shardsResponses.length();  i++)  {  Object  shardResponse  =  shardsResponses.get(i);  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  null);  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  GeoPointDoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  new  double[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  GeoPointDoubleArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  GeoPointDoubleArrayAtomicFieldData.SingleFixedSet(new  double[1],  new  double[1],  0,  new  FixedBitSet(1));              return  GeoPointDoubleArrayAtomicFieldData.EMPTY;  }  final  TDoubleArrayList  lat  =  new  TDoubleArrayList();  final  TDoubleArrayList  lon  =  new  TDoubleArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  GeoPointDoubleArrayAtomicFieldData.EMPTY;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "  +  i).setSource(jsonBuilder()  .startObject()  .field( "value ",  i  *  2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(range( "range ").addRange( "0-2 ",  0.0,  2.0)))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  JsonBuilder  builder  =  RestJsonBuilder.cached(request).prettyPrint();  context:  quotesSize  =  -1;  }  this.rootNode  =  rootNode;  this.quotesSize  =  quotesSize;  controller.registerHandler(GET,   "/ ",  this);  }  try  {              JsonBuilder  builder  =  RestJsonBuilder.cached(request).prettyPrint();              JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request).prettyPrint();  builder.startObject();  builder.field( "ok ",  true);  if  (settings.get( "name ")  !=  null)  {  builder.field( "name ",  settings.get( "name "));  }  builder.startObject( "version ").field( "number ",  Version.number()).field( "date ",  Version.date()).field( "devBuild ",  Version.devBuild()).endObject();  builder.field( "version ",  Version.number());  builder.field( "tagline ",   "You  Know,  for  Search ");  	JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request).prettyPrint();  
elasticsearch_638a8a19e40964601c37938c2f368cf909dddc67	buggy:  BytesHolder  bytes  =  in.readBytesHolder();  context:  public  String[]  filteringAliases()  {  return  filteringAliases;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  minScore  =  in.readFloat();          BytesHolder  bytes  =  in.readBytesHolder();          BytesHolder  bytes  =  in.readBytesReference();  querySource  =  bytes.bytes();  querySourceOffset  =  bytes.offset();  querySourceLength  =  bytes.length();  int  typesSize  =  in.readVInt();  if  (typesSize  >  0)  {  types  =  new  String[typesSize];  for  (int  i  =  0;  i  <  typesSize;  i++)  {  	BytesHolder  bytes  =  in.readBytesReference();  
libgdx_01e254477052a47b350799df638f6e65f77e1799	buggy:  Slider  slider  =  new  Slider(0,  100,  100,  skin);  context:  table.add(new  Label(i  +   "uno ",  skin)).expandX().fillX();  TextButton  button  =  new  TextButton(i  +   "dos ",  skin);  table.add(button);  button.addListener(new  ClickListener()  {  public  void  clicked  (InputEvent  event,  float  x,  float  y)  {  }  });  Slider  slider  =  new  Slider(0,  100,  100,  skin);  Slider  slider  =  new  Slider(0,  100,  100,  false,  skin);  slider.addListener(stopTouchDown);  //  Stops  touchDown  events  from  propagating  to  the  FlickScrollPane.  table.add(slider);  table.add(new  Label(i  +   "tres  long0  long1  long2  long3  long4  long5  long6  long7  long8  long9  long10  long11  long12 ",  skin));  }  final  TextButton  flickButton  =  new  TextButton( "Flick  Scroll ",  skin.get( "toggle ",  TextButtonStyle.class));  flickButton.setChecked(true);  	Slider  slider  =  new  Slider(0,  100,  100,  false,  skin);  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  MultiTermVectorsItemResponse[]  responseItems  =  run(requestBuilder).getResponses();  context:  AbstractTermVectorTests.TestDoc[]  testDocs  =  generateTestDocs(5,  testFieldSettings);  DirectoryReader  directoryReader  =  indexDocsWithLucene(testDocs);  AbstractTermVectorTests.TestConfig[]  testConfigs  =  generateTestConfigs(20,  testDocs,  testFieldSettings);  MultiTermVectorsRequestBuilder  requestBuilder  =  client().prepareMultiTermVectors();  for  (AbstractTermVectorTests.TestConfig  test  :  testConfigs)  {  requestBuilder.add(getRequestForConfig(test).request());  }          MultiTermVectorsItemResponse[]  responseItems  =  run(requestBuilder).getResponses();          MultiTermVectorsItemResponse[]  responseItems  =  requestBuilder.get().getResponses();  for  (int  i  =  0;  i  <  testConfigs.length;  i++)  {  TestConfig  test  =  testConfigs[i];  try  {  MultiTermVectorsItemResponse  item  =  responseItems[i];  if  (test.expectedException  !=  null)  {  assertTrue(item.isFailed());  continue;  	MultiTermVectorsItemResponse[]  responseItems  =  requestBuilder.get().getResponses();  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  if  (!getResponse.exists())  {  context:  ThreadLocalRandom  random  =  ThreadLocalRandom.current();  while  (!done.get())  {  String  id  =  String.valueOf(idGenerator.incrementAndGet());  client.client().prepareIndex( "test ",   "type1 ",  id)  .setSource( "field ",  random.nextInt(100))  .execute().actionGet();  GetResponse  getResponse  =  client.client().prepareGet( "test ",   "type1 ",  id)  .execute().actionGet();                          if  (!getResponse.exists())  {                          if  (!getResponse.isExists())  {  System.err.println( "Failed  to  find   "  +  id);  }  long  count  =  counter.incrementAndGet();  if  ((count  %  10000)  ==  0)  {  }  }  	if  (!getResponse.isExists())  {  
elasticsearch_1d860f70cab472f22ed7c1938934c719787017cb	buggy:  pendingClusterTasks.add(new  PendingClusterTask(pending.insertionOrder,  pending.priority,  new  StringText(source),  timeInQueue));  context:  final  long  timeInQueue;  if  (pending.task  instanceof  UpdateTask)  {  UpdateTask  updateTask  =  (UpdateTask)  pending.task;  source  =  updateTask.source;  timeInQueue  =  now  -  updateTask.addedAt;  }  else  {  source  =   "unknown ";  timeInQueue  =  -1;  }              pendingClusterTasks.add(new  PendingClusterTask(pending.insertionOrder,  pending.priority,  new  StringText(source),  timeInQueue));              pendingClusterTasks.add(new  PendingClusterTask(pending.insertionOrder,  pending.priority,  new  StringText(source),  timeInQueue,  pending.executing));  }  return  pendingClusterTasks;  }  class  UpdateTask  extends  PrioritizedRunnable  {  public  final  String  source;  public  final  ClusterStateUpdateTask  updateTask;  	pendingClusterTasks.add(new  PendingClusterTask(pending.insertionOrder,  pending.priority,  new  StringText(source),  timeInQueue,  pending.executing));  
elasticsearch_441c1c82686d8ae26aeaeb132413d7d537996e94	buggy:  new  ShardSearchRequest().types(request.types())  context:  return  new  CountResponse(count,  terminatedEarly,  shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardCountResponse  shardOperation(ShardCountRequest  request)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.shardId().getIndex());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.shardId().getIndex(),  request.shardId().id());  SearchContext  context  =  new  DefaultSearchContext(0,                  new  ShardSearchRequest().types(request.types())                  new  ShardSearchRequest(request).types(request.types())  .filteringAliases(request.filteringAliases())  .nowInMillis(request.nowInMillis()),  shardTarget,  indexShard.acquireSearcher( "count "),  indexService,  indexShard,  scriptService,  cacheRecycler,  pageCacheRecycler,  bigArrays);  SearchContext.setCurrent(context);  try  {  	new  ShardSearchRequest(request).types(request.types())  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test1 ").numberOfShards(1).numberOfReplicas(1))  .put(IndexMetaData.builder( "test2 ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test1 "))  .addAsNew(metaData.index( "test2 "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode( "node1 ")).put(newNode( "node2 "))).build();  RoutingTable  prevRoutingTable  =  routingTable;  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  for  (int  i  =  0;  i  <  routingTable.index( "test1 ").shards().size();  i++)  {  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_c76e589bc56599b6c1023b66962757d8ce747037	buggy:  shard.idCache().onCached(readerCache.sizeInBytes());  context:  if  (shard  !=  null)  {  shard.idCache().onCached(readerCache.sizeInBytes());  }  }  }  void  onRemoval(SimpleIdReaderCache  readerCache)  {  if  (readerCache.shardId  !=  null)  {  IndexShard  shard  =  indexService.shard(readerCache.shardId.id());  if  (shard  !=  null)  {                  shard.idCache().onCached(readerCache.sizeInBytes());                  shard.idCache().onRemoval(readerCache.sizeInBytes());  }  }  }  private  HashedBytesArray  checkIfCanReuse(Map<Object,  Map<String,  TypeBuilder>>  builders,  HashedBytesArray  idAsBytes)  {  HashedBytesArray  finalIdAsBytes;  if  (reuse)  {  	shard.idCache().onRemoval(readerCache.sizeInBytes());  
elasticsearch_90bd82ac5082dcc22ab40df3e8464f60e2f99d02	buggy:  Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  topScorer,  acceptDocs);  context:  return  sum;  }  public  void  normalize(float  norm,  float  topLevelBoost)  {  subQueryWeight.normalize(norm,  topLevelBoost  *  getBoost());  }  public  Scorer  scorer(AtomicReaderContext  context,  boolean  scoreDocsInOrder,  boolean  topScorer,  Bits  acceptDocs)  throws  IOException  {              Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  topScorer,  acceptDocs);              Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  false,  acceptDocs);  if  (subQueryScorer  ==  null)  {  return  null;  }  function.setNextReader(context);  return  new  CustomBoostFactorScorer(this,  subQueryScorer,  function);  }  	Scorer  subQueryScorer  =  subQueryWeight.scorer(context,  scoreDocsInOrder,  false,  acceptDocs);  
elasticsearch_09362f47e91533f45ae703a111d492fe67c3c861	buggy:  final  float  acceptableOverheadRatio  =  settings.getAsFloat( "acceptable_overhead_ratio ",  PackedInts.COMPACT);  context:  bitSet.set(docID);  }  }  return  bitSet;  }  public  Ordinals  build(Settings  settings)  {          final  float  acceptableOverheadRatio  =  settings.getAsFloat( "acceptable_overhead_ratio ",  PackedInts.COMPACT);          final  float  acceptableOverheadRatio  =  settings.getAsFloat( "acceptable_overhead_ratio ",  PackedInts.DEFAULT);  if  (numMultiValuedDocs  >  0  ||  MultiOrdinals.significantlySmallerThanSinglePackedOrdinals(maxDoc,  numDocsWithValue,  getNumOrds()))  {  return  new  MultiOrdinals(this);  }  else  {  return  new  SinglePackedOrdinals(this,  acceptableOverheadRatio);  }  }  	final  float  acceptableOverheadRatio  =  settings.getAsFloat( "acceptable_overhead_ratio ",  PackedInts.DEFAULT);  
elasticsearch_2d417cf5b6519bb771419b0735e9f00c6b04ae42	buggy:  cacheEntry.docId  =  highlighterContext.hitContext.docId();  context:  final  int  docId  =  highlighterContext.hitContext.readerContext().docBase  +  highlighterContext.hitContext.docId();  if  (cacheEntry  ==  null)  {  cacheEntry  =  new  CacheEntry();  highlighterContext.hitContext.cache().put( "test-custom ",  cacheEntry);  cacheEntry.docId  =  docId;  cacheEntry.position  =  1;  }  else  {  if  (cacheEntry.docId  ==  docId)  {  cacheEntry.position++;  }  else  {                  cacheEntry.docId  =  highlighterContext.hitContext.docId();                  cacheEntry.docId  =  docId;  cacheEntry.position  =  1;  }  }  List<Text>  responses  =  Lists.newArrayList();  responses.add(new  StringText(String.format(Locale.ENGLISH,   "standard  response  for  %s  at  position  %s ",  field.field(),  cacheEntry.position)));  	cacheEntry.docId  =  docId;  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  public  boolean  deleteBlob(String  blobName)  throws  IOException  {  return  new  File(path,  blobName).delete();  }  return  new  File(path,  blobName).exists();  }          blobStore.executorService().execute(new  Runnable()  {          blobStore.executor().execute(new  Runnable()  {  byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  FileInputStream  is;  try  {  is  =  new  FileInputStream(new  File(path,  blobName));  }  catch  (FileNotFoundException  e)  {  listener.onFailure(e);  return;  	blobStore.executor().execute(new  Runnable()  {  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  BytesStreamOutput  out  =  cachedEntry.cachedBytes();  context:  }  finally  {  rwl.readLock().unlock();  }  }  public  Location  add(Operation  operation)  throws  TranslogException  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  rwl.readLock().lock();  try  {              BytesStreamOutput  out  =  cachedEntry.cachedBytes();              BytesStreamOutput  out  =  cachedEntry.bytes();  out.writeInt(0);  //  marker  for  the  size...  TranslogStreams.writeTranslogOperation(out,  operation);  out.flush();  int  size  =  out.size();  out.seek(0);  out.writeInt(size  -  4);  	BytesStreamOutput  out  =  cachedEntry.bytes();  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  }  if  (value  instanceof  BytesRef)  {  return  ((BytesRef)  value).bytes[((BytesRef)  value).offset];  }  return  Byte.parseByte(value.toString());  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.intToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  byte  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).byteValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.intToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  
elasticsearch_8b7620f9de67794e48c762a81ccd8997bee34d75	buggy:  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class))  context:  public  class  MergePolicyModule  extends  AbstractModule  {  private  final  Settings  settings;  public  MergePolicyModule(Settings  settings)  {  this.settings  =  settings;  }  bind(MergePolicyProvider.class)                  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class))                  .to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy ",   "MergePolicyProvider "))  .asEagerSingleton();  }  }  	.to(settings.getAsClass( "index.merge.policy.type ",  TieredMergePolicyProvider.class,   "org.elasticsearch.index.merge.policy ",   "MergePolicyProvider "))  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  JoglApplication  app  =  new  JoglApplication( "BitmapFont  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.desktop;  public  class  BitmapFontTest  {  public  static  void  main  (String[]  argv)  {  JoglApplication  app  =  new  JoglApplication( "BitmapFont  Test ",  480,  320,  false);  JoglApplication  app  =  new  JoglApplication( "BitmapFont  Flip  Test ",  480,  320,  false);  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.BitmapFontTest());  }  }  	JoglApplication  app  =  new  JoglApplication( "BitmapFont  Flip  Test ",  480,  320,  false);  
elasticsearch_ba5814a72fb7df6466c85b6dc1462663ced7bdc2	buggy:  logger.trace( "[{}][{}]:  throttling  allocation  [{}]  to  [{}]  in  order  to  reuse  its  unallocated  persistent  store  with  total_size  [{}] ",  shard.index(),  shard.id(),  shard,  lastDiscoNodeMatched,  new  ByteSizeValue(lastSizeMatched));  context:  continue;  }  }  }  }  if  (lastNodeMatched  !=  null)  {  if  (nodeAllocations.canAllocate(shard,  lastNodeMatched,  routingNodes)  ==  NodeAllocation.Decision.THROTTLE)  {  if  (logger.isTraceEnabled())  {                          logger.trace( "[{}][{}]:  throttling  allocation  [{}]  to  [{}]  in  order  to  reuse  its  unallocated  persistent  store  with  total_size  [{}] ",  shard.index(),  shard.id(),  shard,  lastDiscoNodeMatched,  new  ByteSizeValue(lastSizeMatched));                          logger.debug( "[{}][{}]:  throttling  allocation  [{}]  to  [{}]  in  order  to  reuse  its  unallocated  persistent  store  with  total_size  [{}] ",  shard.index(),  shard.id(),  shard,  lastDiscoNodeMatched,  new  ByteSizeValue(lastSizeMatched));  }  unassignedIterator.remove();  routingNodes.ignoredUnassigned().add(shard);  }  else  {  if  (logger.isDebugEnabled())  {  }  	logger.debug( "[{}][{}]:  throttling  allocation  [{}]  to  [{}]  in  order  to  reuse  its  unallocated  persistent  store  with  total_size  [{}] ",  shard.index(),  shard.id(),  shard,  lastDiscoNodeMatched,  new  ByteSizeValue(lastSizeMatched));  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  indicesExistsRequest.listenerThreaded(false);  client.admin().indices().exists(indicesExistsRequest,  new  ActionListener<IndicesExistsResponse>()  {  public  void  onResponse(IndicesExistsResponse  response)  {  try  {  if  (response.isExists())  {  channel.sendResponse(new  StringRestResponse(OK));  }  else  {  channel.sendResponse(new  StringRestResponse(NOT_FOUND));  }                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  StringRestResponse(ExceptionsHelper.status(e)));  	}  catch  (Throwable  e)  {  
elasticsearch_a234e45b59338e77c39b0f914642674a27834929	buggy:  clusterHealthRequest.setLocal(request.paramAsBoolean( "local ",  clusterHealthRequest.getLocal()));  context:  public  RestClusterHealthAction(Settings  settings,  Client  client,  RestController  controller)  {  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/health ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/health/{index} ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  ClusterHealthRequest  clusterHealthRequest  =  clusterHealthRequest(RestActions.splitIndices(request.param( "index ")));          clusterHealthRequest.setLocal(request.paramAsBoolean( "local ",  clusterHealthRequest.getLocal()));          clusterHealthRequest.setLocal(request.paramAsBoolean( "local ",  clusterHealthRequest.isLocal()));  clusterHealthRequest.setListenerThreaded(false);  int  level  =  0;  try  {  clusterHealthRequest.setMasterNodeTimeout(request.paramAsTime( "master_timeout ",  clusterHealthRequest.getMasterNodeTimeout()));  clusterHealthRequest.setTimeout(request.paramAsTime( "timeout ",  clusterHealthRequest.getTimeout()));  String  waitForStatus  =  request.param( "wait_for_status ");  if  (waitForStatus  !=  null)  {  clusterHealthRequest.setWaitForStatus(ClusterHealthStatus.valueOf(waitForStatus.toUpperCase()));  	clusterHealthRequest.setLocal(request.paramAsBoolean( "local ",  clusterHealthRequest.isLocal()));  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(10000);  context:  public  class  DoubleObjectHashMapTests  extends  ElasticsearchTestCase  {  public  void  duel()  {  final  DoubleObjectOpenHashMap<Object>  map1  =  new  DoubleObjectOpenHashMap<Object>();  final  DoubleObjectPagedHashMap<Object>  map2  =  new  DoubleObjectPagedHashMap<Object>(randomInt(42),  0.6f  +  randomFloat()  *  0.39f,  BigArraysTests.randombigArrays());  final  int  maxKey  =  randomIntBetween(1,  10000);          final  int  iters  =  atLeast(10000);          final  int  iters  =  scaledRandomIntBetween(10000,  100000);  for  (int  i  =  0;  i  <  iters;  ++i)  {  final  boolean  put  =  randomBoolean();  final  int  iters2  =  randomIntBetween(1,  100);  for  (int  j  =  0;  j  <  iters2;  ++j)  {  final  double  key  =  randomInt(maxKey);  if  (put)  {  final  Object  value  =  new  Object();  assertSame(map1.put(key,  value),  map2.put(key,  value));  	final  int  iters  =  scaledRandomIntBetween(10000,  100000);  
libgdx_c9af856df9a4698a44f8f2ed62132f3b00d0f151	buggy:  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  context:  }  public  boolean  removeAll  (BooleanArray  array)  {  int  size  =  this.size;  int  startSize  =  size;  boolean[]  items  =  this.items;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  {  boolean  item  =  array.get(i);  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  for  (int  ii  =  0;  ii  <  size;  ii++)  {  if  (item  ==  items[ii])  {  removeIndex(ii);  size--;  break;  }  }  }  return  size  !=  startSize;  	for  (int  ii  =  0;  ii  <  size;  ii++)  {  
elasticsearch_08ca383fd59b9d5fb105dc7aab293b3843a22633	buggy:  Blob  blob  =  cloudBlobStore.sync().newBlob(blobName);  context:  public  class  CloudImmutableBlobContainer  extends  AbstractCloudBlobContainer  implements  ImmutableBlobContainer  {  public  CloudImmutableBlobContainer(BlobPath  path,  CloudBlobStore  cloudBlobStore)  {  super(path,  cloudBlobStore);  }          Blob  blob  =  cloudBlobStore.sync().newBlob(blobName);          Blob  blob  =  cloudBlobStore.sync().newBlob(buildBlobPath(blobName));  blob.setPayload(is);  blob.setContentLength(sizeInBytes);  final  ListenableFuture<String>  future  =  cloudBlobStore.async().putBlob(cloudBlobStore.container(),  blob);  future.addListener(new  Runnable()  {  try  {  future.get();  listener.onCompleted();  	Blob  blob  =  cloudBlobStore.sync().newBlob(buildBlobPath(blobName));  
elasticsearch_c021f22523a69583b94c56921792b727ab4030fb	buggy:  .force(request.force())  context:  }  protected  ShardOptimizeResponse  shardOperation(ShardOptimizeRequest  request)  throws  ElasticsearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.shardId().getIndex()).shardSafe(request.shardId().id());  indexShard.optimize(new  Engine.Optimize()  .waitForMerge(request.waitForMerge())  .maxNumSegments(request.maxNumSegments())  .onlyExpungeDeletes(request.onlyExpungeDeletes())  .flush(request.flush())                  .force(request.force())                  .upgrade(request.upgrade())  );  return  new  ShardOptimizeResponse(request.shardId());  }  	.upgrade(request.upgrade())  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  blobStore.executorService().execute(new  Runnable()  {  context:  private  class  FsAppendableBlob  implements  AppendableBlob  {  private  final  File  file;  public  FsAppendableBlob(File  file)  throws  IOException  {  this.file  =  file;  }              blobStore.executorService().execute(new  Runnable()  {              blobStore.executor().execute(new  Runnable()  {  RandomAccessFile  raf  =  null;  try  {  raf  =  new  RandomAccessFile(file,   "rw ");  raf.seek(raf.length());  listener.withStream(new  DataOutputStreamOutput(raf));  listener.onCompleted();  raf.close();  	blobStore.executor().execute(new  Runnable()  {  
elasticsearch_1a085d9bfa9e29c43e9a2c3b25393a574ae2fa53	buggy:  value  =  field.getBinaryValue();  context:  FieldMappers  fieldMappers  =  documentMapper.mappers().indexName(field.name());  if  (fieldMappers  !=  null)  {  FieldMapper  mapper  =  fieldMappers.mapper();  if  (mapper  !=  null)  {  name  =  mapper.names().fullName();  value  =  mapper.valueForSearch(field);  }  }  if  (value  ==  null)  {  if  (field.isBinary())  {                          value  =  field.getBinaryValue();                          value  =  new  BytesArray(field.getBinaryValue(),  field.getBinaryOffset(),  field.getBinaryLength());  }  else  {  value  =  field.stringValue();  }  }  if  (searchHit.fieldsOrNull()  ==  null)  {  searchHit.fields(new  HashMap<String,  SearchHitField>(2));  }  	value  =  new  BytesArray(field.getBinaryValue(),  field.getBinaryOffset(),  field.getBinaryLength());  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  cachedEntry.cachedBytes(),  cachedEntry);  context:  if  (request.hasContent())  {  contentType  =  XContentFactory.xContentType(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  }  }  if  (contentType  ==  null)  {  contentType  =  XContentType.JSON;  }  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();          XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  cachedEntry.cachedBytes(),  cachedEntry);          XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  cachedEntry.bytes(),  cachedEntry);  if  (request.paramAsBoolean( "pretty ",  false))  {  builder.prettyPrint();  }  String  casing  =  request.param( "case ");  if  (casing  !=  null  &&   "camelCase ".equals(casing))  {  builder.fieldCaseConversion(XContentBuilder.FieldCaseConversion.CAMELCASE);  }  else  {  	XContentBuilder  builder  =  new  XContentBuilder(XContentFactory.xContent(contentType),  cachedEntry.bytes(),  cachedEntry);  
elasticsearch_37acba1b57e5775eaa7f04aba814e1d70936adf1	buggy:  return  NumericType.DOUBLE;  context:  return  new  LongArrayIndexFieldData(index,  indexSettings,  fieldNames,  type,  cache);  }  }  public  LongArrayIndexFieldData(Index  index,  @IndexSettings  Settings  indexSettings,  FieldMapper.Names  fieldNames,  FieldDataType  fieldDataType,  IndexFieldDataCache  cache)  {  super(index,  indexSettings,  fieldNames,  fieldDataType,  cache);  }  public  NumericType  getNumericType()  {          return  NumericType.DOUBLE;          return  NumericType.LONG;  }  public  boolean  valuesOrdered()  {  return  false;  }  	return  NumericType.LONG;  
elasticsearch_eb956e7c091a02924c9a640d5a17d389f0e5ff3b	buggy:  NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);  context:  Long  val  =  value(value);  if  (val  ==  null)  {  return  null;  }  return  dateTimeFormatter.printer().print(val);  }  public  BytesRef  indexedValueForSearch(Object  value)  {  BytesRef  bytesRef  =  new  BytesRef();          NumericUtils.longToPrefixCoded(parseValue(value),  precisionStep(),  bytesRef);          NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  return  bytesRef;  }  private  long  parseValue(Object  value)  {  if  (value  instanceof  Number)  {  return  ((Number)  value).longValue();  }  if  (value  instanceof  BytesRef)  {  	NumericUtils.longToPrefixCoded(parseValue(value),  0,  bytesRef);  //  0  because  of  exact  match  
libgdx_03c9c5ffd9a12b1dd5d39e56ce619e0b2388755a	buggy:  GL10  gl  =  Gdx.graphics.getGL10();  context:  }  public  void  setMatrices  ()  {  setViewport(Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  update();  GL10  gl  =  Gdx.graphics.getGL10();  GL10  gl  =  Gdx.gl10;  gl.glMatrixMode(GL10.GL_PROJECTION);  gl.glLoadMatrixf(getCombinedMatrix().val,  0);  gl.glMatrixMode(GL10.GL_MODELVIEW);  gl.glLoadIdentity();  }  	GL10  gl  =  Gdx.gl10;  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  client.admin().indices().create(createIndexRequest,  new  ActionListener<CreateIndexResponse>()  {  public  void  onResponse(CreateIndexResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.isAcknowledged())  .endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_e370e52969919e157b2ef3dd8ef43b6e06e7e674	buggy:  setBackground(isPressed  ?  style.down  :  style.up);  context:  this.isChecked  =  isChecked;  }  public  boolean  isChecked  ()  {  return  isChecked;  }  public  void  setStyle  (ButtonStyle  style)  {  if  (style  ==  null)  throw  new  IllegalArgumentException( "style  cannot  be  null. ");  this.style  =  style;  setBackground(isPressed  ?  style.down  :  style.up);  setBackground((isPressed  &&  style.down  !=  null)  ?  style.down  :  style.up);  invalidateHierarchy();  }  public  ButtonStyle  getStyle  ()  {  return  style;  }  	setBackground((isPressed  &&  style.down  !=  null)  ?  style.down  :  style.up);  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  iterations  =  atLeast(400);  //  don't  worry  that  is  fast!  context:  private  static  XBooleanFilter  createBooleanFilter(FilterClause...  clauses)  {  XBooleanFilter  booleanFilter  =  new  XBooleanFilter();  for  (FilterClause  clause  :  clauses)  {  booleanFilter.add(clause);  }  return  booleanFilter;  }  public  void  testRandom()  throws  IOException  {          int  iterations  =  atLeast(400);  //  don't  worry  that  is  fast!          int  iterations  =  scaledRandomIntBetween(100,  1000);  //  don't  worry  that  is  fast!  for  (int  iter  =  0;  iter  <  iterations;  iter++)  {  int  numClauses  =  1  +  random().nextInt(10);  FilterClause[]  clauses  =  new  FilterClause[numClauses];  BooleanQuery  topLevel  =  new  BooleanQuery();  BooleanQuery  orQuery  =  new  BooleanQuery();  boolean  hasMust  =  false;  boolean  hasShould  =  false;  boolean  hasMustNot  =  false;  	int  iterations  =  scaledRandomIntBetween(100,  1000);  //  don't  worry  that  is  fast!  
elasticsearch_e059a7b37f1a023c5110aece90e5a7f5b8269be4	buggy:  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler ",   "MergeSchedulerProvider "))  context:  }  private  final  Settings  settings;  public  MergeSchedulerModule(Settings  settings)  {  this.settings  =  settings;  }  bind(MergeSchedulerProvider.class)                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler ",   "MergeSchedulerProvider "))                  .to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler. ",   "MergeSchedulerProvider "))  .asEagerSingleton();  }  }  	.to(settings.getAsClass(TYPE,  ConcurrentMergeSchedulerProvider.class,   "org.elasticsearch.index.scheduler. ",   "MergeSchedulerProvider "))  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  .setQuery(filteredQuery(matchAllQuery(),  scriptFilter( "Thread.sleep(100);  return  true; ")))  context:  protected  Settings  nodeSettings(int  nodeOrdinal)  {  return  ImmutableSettings.settingsBuilder().put(super.nodeSettings(nodeOrdinal)).put(GroovyScriptEngineService.GROOVY_SCRIPT_SANDBOX_ENABLED,  false).build();  }  public  void  simpleTimeoutTest()  throws  Exception  {  client().prepareIndex( "test ",   "type ",   "1 ").setSource( "field ",   "value ").setRefresh(true).execute().actionGet();  SearchResponse  searchResponse  =  client().prepareSearch( "test ")  .setTimeout( "10ms ")                  .setQuery(filteredQuery(matchAllQuery(),  scriptFilter( "Thread.sleep(100);  return  true; ")))                  .setQuery(filteredQuery(matchAllQuery(),  scriptFilter( "Thread.sleep(500);  return  true; ")))  .execute().actionGet();  assertThat(searchResponse.isTimedOut(),  equalTo(true));  }  }  	.setQuery(filteredQuery(matchAllQuery(),  scriptFilter( "Thread.sleep(500);  return  true; ")))  
libgdx_c9af856df9a4698a44f8f2ed62132f3b00d0f151	buggy:  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  context:  }  public  boolean  removeAll  (CharArray  array)  {  int  size  =  this.size;  int  startSize  =  size;  char[]  items  =  this.items;  for  (int  i  =  0,  n  =  array.size;  i  <  n;  i++)  {  char  item  =  array.get(i);  for  (int  ii  =  0,  nn  =  size;  ii  <  nn;  ii++)  {  for  (int  ii  =  0;  ii  <  size;  ii++)  {  if  (item  ==  items[ii])  {  removeIndex(ii);  size--;  break;  }  }  }  return  size  !=  startSize;  	for  (int  ii  =  0;  ii  <  size;  ii++)  {  
elasticsearch_ad01f19db8955c7039ff6d4ca2e8991f24976493	buggy:  object( "person ")  context:  public  class  SimpleMapperTests  {  XContentDocumentMapperParser  mapperParser  =  MapperTests.newParser();  XContentDocumentMapper  docMapper  =  doc( "test ",                  object( "person ")                  rootObject( "person ")  .add(object( "name ").add(stringField( "first ").store(YES).index(Field.Index.NO)))  ).sourceField(source()).build(mapperParser);  byte[]  json  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/simple/test1.json ");  Document  doc  =  docMapper.parse( "person ",   "1 ",  json).doc();  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().names().indexName()),  equalTo( "shay "));  	rootObject( "person ")  
libgdx_41467c8004b716fb78002c3139ea771b70ed165d	buggy:  cache.setColor(style.fontColor  ==  null  ?  color  :  Color.tmp.set(color).mul(style.fontColor));  context:  if  (fontScaleX  !=  1  ||  fontScaleY  !=  1)  font.setScale(oldScaleX,  oldScaleY);  }  public  void  draw  (Batch  batch,  float  parentAlpha)  {  validate();  Color  color  =  getColor();  if  (style.background  !=  null)  {  batch.setColor(color.r,  color.g,  color.b,  color.a  *  parentAlpha);  style.background.draw(batch,  getX(),  getY(),  getWidth(),  getHeight());  }  cache.setColor(style.fontColor  ==  null  ?  color  :  Color.tmp.set(color).mul(style.fontColor));  cache.setColors(style.fontColor  ==  null  ?  color  :  Color.tmp.set(color).mul(style.fontColor));  cache.setPosition(getX(),  getY());  cache.draw(batch,  parentAlpha);  }  public  float  getPrefWidth  ()  {  if  (wrap)  return  0;  if  (sizeInvalid)  scaleAndComputeSize();  float  width  =  bounds.width;  	cache.setColors(style.fontColor  ==  null  ?  color  :  Color.tmp.set(color).mul(style.fontColor));  
elasticsearch_e53b2eede7bab2557a944d9ccad9bbff1270ec38	buggy:  mltQuery.setMinimumShouldMatch((int)  (parser.floatValue()  *  100)  +   "% ");  context:  mltQuery.setMaxWordLen(parser.intValue());  }  else  if  (Fields.BOOST_TERMS.match(currentFieldName,  parseContext.parseFlags()))  {  float  boostFactor  =  parser.floatValue();  if  (boostFactor  !=  0)  {  mltQuery.setBoostTerms(true);  mltQuery.setBoostTermsFactor(boostFactor);  }  }  else  if  (Fields.MINIMUM_SHOULD_MATCH.match(currentFieldName,  parseContext.parseFlags()))  {  mltQuery.setMinimumShouldMatch(parser.text());  }  else  if  (Fields.PERCENT_TERMS_TO_MATCH.match(currentFieldName,  parseContext.parseFlags()))  {                      mltQuery.setMinimumShouldMatch((int)  (parser.floatValue()  *  100)  +   "% ");                      mltQuery.setMinimumShouldMatch(Math.round(parser.floatValue()  *  100)  +   "% ");  }  else  if  ( "analyzer ".equals(currentFieldName))  {  analyzer  =  parseContext.analysisService().analyzer(parser.text());  }  else  if  ( "boost ".equals(currentFieldName))  {  mltQuery.setBoost(parser.floatValue());  }  else  if  (Fields.FAIL_ON_UNSUPPORTED_FIELD.match(currentFieldName,  parseContext.parseFlags()))  {  failOnUnsupportedField  =  parser.booleanValue();  }  else  if  ( "_name ".equals(currentFieldName))  {  queryName  =  parser.text();  	mltQuery.setMinimumShouldMatch(Math.round(parser.floatValue()  *  100)  +   "% ");  
elasticsearch_28ecafac119975cee127c789b31c62a004103398	buggy:  table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :  null);  context:  table.addCell(info  ==  null  ?  null  :  info.getVersion().number());  table.addCell(info  ==  null  ?  null  :  info.getJvm().version());  table.addCell(availableDisk  <  0  ?  null  :  ByteSizeValue.parseBytesSizeValue(new  Long(availableDisk).toString()));  table.addCell(heapRatio  <  0  ?  null  :  String.format(Locale.ROOT,   "%.1f ",  heapRatio*100.0));  table.addCell(heapMax  <  0  ?  null  :  new  ByteSizeValue(heapMax));  table.addCell(stats  ==  null  ?  null  :  stats.getOs().mem()  ==  null  ?  null  :  stats.getOs().mem().usedPercent());  table.addCell(info  ==  null  ?  null  :  info.getOs().mem()  ==  null  ?  null  :  info.getOs().mem().total());  //  sigar  fails  to  load  in  IntelliJ  table.addCell(stats  ==  null  ?  null  :  stats.getOs()  ==  null  ?  null  :  stats.getOs().getLoadAverage().length  <  1  ?  null  :  stats.getOs().getLoadAverage()[0]);  table.addCell(stats  ==  null  ?  null  :  stats.getJvm().uptime());  table.addCell(node.clientNode()  ?   "c "  :  node.dataNode()  ?   "d "  :  null);              table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :  null);              table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  table.addCell(node.name());  table.endRow();  }  return  table;  }  }  	table.addCell(masterId.equals(node.id())  ?   "* "  :  node.masterNode()  ?   "m "  :   "- ");  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  indexAliasesService.indicesAliases(new  MetaDataIndexAliasesService.Request(request.aliasActions().toArray(new  AliasAction[request.aliasActions().size()]),  request.timeout()),  new  MetaDataIndexAliasesService.Listener()  {  context:  indices.add(aliasAction.index());  }  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  indices.toArray(new  String[indices.size()]));  }  protected  IndicesAliasesResponse  masterOperation(IndicesAliasesRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<IndicesAliasesResponse>  responseRef  =  new  AtomicReference<IndicesAliasesResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          indexAliasesService.indicesAliases(new  MetaDataIndexAliasesService.Request(request.aliasActions().toArray(new  AliasAction[request.aliasActions().size()]),  request.timeout()),  new  MetaDataIndexAliasesService.Listener()  {          indexAliasesService.indicesAliases(new  MetaDataIndexAliasesService.Request(request.aliasActions().toArray(new  AliasAction[request.aliasActions().size()]),  request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataIndexAliasesService.Listener()  {  public  void  onResponse(MetaDataIndexAliasesService.Response  response)  {  responseRef.set(new  IndicesAliasesResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	indexAliasesService.indicesAliases(new  MetaDataIndexAliasesService.Request(request.aliasActions().toArray(new  AliasAction[request.aliasActions().size()]),  request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataIndexAliasesService.Listener()  {  
elasticsearch_a62f1f3e0dc0716918945d5d9ff48503c90ccb2c	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  context:  return  new  ShardCountRequest(shard.index(),  shard.id(),  request);  }  return  new  ShardCountResponse();  }          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing());  }  for  (String  index  :  request.indices())  {  state.blocks().indexBlocked(ClusterBlockLevel.READ,  index);  }  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint(),  request.routing());  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)  context:  .startObject().field( "value ",  i  +  3).endObject()  .startObject().field( "value ",  i  +  4).endObject()  .startObject().field( "value ",  i  +  5).endObject()  .endArray()  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true)                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(nested( "nested ").path( "nested ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  
elasticsearch_09cc70b8c91c25ebf50f592fd9f8f52ac4e67028	buggy:  return  new  IntArrayAtomicFieldData.SingleFixedSet(new  int[1],  0,  new  FixedBitSet(1));  context:  }  }  }  public  IntArrayAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  if  (terms  ==  null)  {              return  new  IntArrayAtomicFieldData.SingleFixedSet(new  int[1],  0,  new  FixedBitSet(1));              return  IntArrayAtomicFieldData.EMPTY;  }  final  TIntArrayList  values  =  new  TIntArrayList();  ArrayList<int[]>  ordinals  =  new  ArrayList<int[]>();  int[]  idx  =  new  int[reader.maxDoc()];  ordinals.add(new  int[reader.maxDoc()]);  	return  IntArrayAtomicFieldData.EMPTY;  
elasticsearch_c111e1ab80c37bd229123e32b49c37a41f90b6a0	buggy:  return  queryBuilder.build();  context:  String  defaultOperator  =  request.param( "defaultOperator ");  if  (defaultOperator  !=  null)  {  if  ( "OR ".equals(defaultOperator))  {  queryBuilder.defualtOperator(QueryStringJsonQueryBuilder.Operator.OR);  }  else  if  ( "AND ".equals(defaultOperator))  {  queryBuilder.defualtOperator(QueryStringJsonQueryBuilder.Operator.AND);  }  else  {  throw  new  ElasticSearchIllegalArgumentException( "Unsupported  defaultOperator  [ "  +  defaultOperator  +   "],  can  either  be  [OR]  or  [AND] ");  }  }          return  queryBuilder.build();          return  queryBuilder.buildAsString();  }  public  static  String[]  splitIndices(String  indices)  {  if  (indices  ==  null)  {  return  Strings.EMPTY_ARRAY;  }  return  indicesPattern.split(indices);  }  	return  queryBuilder.buildAsString();  
libgdx_3c626b4a5e50e7287a60fd758766de596928607c	buggy:  new  JoglApplication(  new  com.badlogic.gdx.tests.TileTest(),   "Debug  Test ",  480,  320,  false  );  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main(  String[]  argv  )  {  new  JoglApplication(  new  com.badlogic.gdx.tests.TileTest(),   "Debug  Test ",  480,  320,  false  );  new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  480,  320,  false  );  }  }  	new  JoglApplication(  new  com.badlogic.gdx.tests.IsometricTileTest(),   "Debug  Test ",  480,  320,  false  );  
elasticsearch_82072fc47fd37b9c1fff457b66f2112d88e4a396	buggy:  return  annotationType.isAnnotationPresent(BindingAnnotation.class);  context:  return   "@ "  +  annotationType.getName();  }  }  static  boolean  isBindingAnnotation(Annotation  annotation)  {  return  isBindingAnnotation(annotation.annotationType());  }  static  boolean  isBindingAnnotation(  Class<?  extends  Annotation>  annotationType)  {          return  annotationType.isAnnotationPresent(BindingAnnotation.class);          return  annotationType.getAnnotation(BindingAnnotation.class)  !=  null;  }  }  	return  annotationType.getAnnotation(BindingAnnotation.class)  !=  null;  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  bulkRequest.add(Requests.indexRequest( "test "  +  ThreadLocalRandom.current().nextInt(NUMBER_OF_INDICES)).type( "type ").source( "field ",   "value "));  context:  Node[]  nodes  =  new  Node[NUMBER_OF_NODES];  for  (int  i  =  0;  i  <  nodes.length;  i++)  {  nodes[i]  =  NodeBuilder.nodeBuilder().settings(nodeSettings).node();  }  Client  client  =  nodes.length  ==  1  ?  nodes[0].client()  :  nodes[1].client();  while  (true)  {  BulkRequestBuilder  bulkRequest  =  client.prepareBulk();  for  (int  i  =  0;  i  <  BATCH;  i++)  {                  bulkRequest.add(Requests.indexRequest( "test "  +  ThreadLocalRandom.current().nextInt(NUMBER_OF_INDICES)).type( "type ").source( "field ",   "value "));                  bulkRequest.add(Requests.indexRequest( "test "  +  ThreadLocalRandom.current().nextInt(NUMBER_OF_INDICES)).setType( "type ").setSource( "field ",   "value "));  }  bulkRequest.execute().actionGet();  }  }  }  	bulkRequest.add(Requests.indexRequest( "test "  +  ThreadLocalRandom.current().nextInt(NUMBER_OF_INDICES)).setType( "type ").setSource( "field ",   "value "));  
elasticsearch_4bd37d7ee69c7dfb59bfb6181b21fe638b117392	buggy:  return  nodePrefix.matcher(t.getName()).find()  ||  true;  //  TODO  disabled  for  now  context:  public  boolean  reject(Thread  t)  {  String  threadName  =  t.getName();  if  (threadName.contains( "[ "  +  MulticastChannel.SHARED_CHANNEL_NAME  +   "] ")  ||  threadName.contains( "[ "  +  ElasticsearchSingleNodeTest.nodeName()  +   "] ")  ||  threadName.contains( "Keep-Alive-Timer "))  {  return  true;  }          return  nodePrefix.matcher(t.getName()).find()  ||  true;  //  TODO  disabled  for  now          return  nodePrefix.matcher(t.getName()).find();  }  }  	return  nodePrefix.matcher(t.getName()).find();  
elasticsearch_e530f03b9445e98728b5fbf203c57ab774928ff3	buggy:  final  String[]  nodesIds  =  state.nodes().resolveNodes(request.nodesIds);  context:  public  void  handleException(TransportException  exp)  {  }  });  }  });  t.start();  }  else  {              final  String[]  nodesIds  =  state.nodes().resolveNodes(request.nodesIds);              final  String[]  nodesIds  =  state.nodes().resolveNodesIds(request.nodesIds);  for  (String  nodeId  :  nodesIds)  {  final  DiscoveryNode  node  =  state.nodes().get(nodeId);  if  (node  !=  null)  {  nodes.add(node);  }  }  	final  String[]  nodesIds  =  state.nodes().resolveNodesIds(request.nodesIds);  
elasticsearch_1d9942847e69fcb59d8e19a62a81ffb8e6da10a3	buggy:  if  (maxMergeAtOnce  !=  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit)  {  context:  int  maxMergeAtOnce  =  settings.getAsInt( "index.merge.policy.max_merge_at_once ",  TieredMergePolicyProvider.this.maxMergeAtOnce);  if  (maxMergeAtOnce  !=  TieredMergePolicyProvider.this.maxMergeAtOnce)  {  TieredMergePolicyProvider.this.maxMergeAtOnce  =  maxMergeAtOnce;  for  (CustomTieredMergePolicyProvider  policy  :  policies)  {  policy.setMaxMergeAtOnce(maxMergeAtOnce);  }  }  int  maxMergeAtOnceExplicit  =  settings.getAsInt( "index.merge.policy.max_merge_at_once_explicit ",  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit);              if  (maxMergeAtOnce  !=  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit)  {              if  (maxMergeAtOnceExplicit  !=  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit)  {  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit  =  maxMergeAtOnceExplicit;  for  (CustomTieredMergePolicyProvider  policy  :  policies)  {  policy.setMaxMergeAtOnceExplicit(maxMergeAtOnceExplicit);  }  }  ByteSizeValue  maxMergedSegment  =  settings.getAsBytesSize( "index.merge.policy.max_merged_segment ",  TieredMergePolicyProvider.this.maxMergedSegment);  	if  (maxMergeAtOnceExplicit  !=  TieredMergePolicyProvider.this.maxMergeAtOnceExplicit)  {  
elasticsearch_dab4596b13a33a5142018b6fa4d21fa86390c5b9	buggy:  return  this.queryBuilder.forceAnalyzeQueryString();  context:  return  new  Term(field,  bytesRef);  }  catch  (Exception  ex)  {  }  return  new  Term(field,  value);  }  }  protected  boolean  forceAnalyzeQueryString()  {          return  this.queryBuilder.forceAnalyzeQueryString();          return  this.queryBuilder  ==  null  ?  super.forceAnalyzeQueryString()  :  this.queryBuilder.forceAnalyzeQueryString();  }  }  	return  this.queryBuilder  ==  null  ?  super.forceAnalyzeQueryString()  :  this.queryBuilder.forceAnalyzeQueryString();  
elasticsearch_ef56c68f67925948fee6065c5e5b754a1ca2040e	buggy:  IndexMetaData.Builder  indexBuilder  =  IndexMetaData.newIndexMetaDataBuilder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  context:  if  (request.name()  ==  null  ||  Regex.simpleMatch(request.name(),  entry.name()))  {  globalFoundAtLeastOne  =  true;  }  else  {  entries.add(entry);  }  }  if  (entries.size()  !=  warmers.entries().size())  {  warmers  =  new  IndexWarmersMetaData(entries.toArray(new  IndexWarmersMetaData.Entry[entries.size()]));                              IndexMetaData.Builder  indexBuilder  =  IndexMetaData.newIndexMetaDataBuilder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);                              IndexMetaData.Builder  indexBuilder  =  IndexMetaData.builder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  mdBuilder.put(indexBuilder);  }  }  }  if  (!globalFoundAtLeastOne)  {  if  (request.name()  ==  null)  {  	IndexMetaData.Builder  indexBuilder  =  IndexMetaData.builder(indexMetaData).putCustom(IndexWarmersMetaData.TYPE,  warmers);  
elasticsearch_be4b2e2de618240a64524f5256ff857cf6f9d4ea	buggy:  SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  params,  context.scriptService());  context:  }  }  }  if  (script  ==  null)  {  throw  new  SearchParseException(context,   "_script  sorting  requires  setting  the  script  to  sort  by ");  }  if  (type  ==  null)  {  throw  new  SearchParseException(context,   "_script  sorting  requires  setting  the  type  of  the  script ");  }          SearchScript  searchScript  =  new  SearchScript(context.scriptSearchLookup(),  scriptLang,  script,  params,  context.scriptService());          SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  params,  context.scriptService());  FieldComparatorSource  fieldComparatorSource;  if  ( "string ".equals(type))  {  fieldComparatorSource  =  StringFieldsFunctionDataComparator.comparatorSource(searchScript);  }  else  if  ( "number ".equals(type))  {  fieldComparatorSource  =  DoubleFieldsFunctionDataComparator.comparatorSource(searchScript);  }  else  {  throw  new  SearchParseException(context,   "custom  script  sort  type  [ "  +  type  +   "]  not  supported ");  }  	SearchScript  searchScript  =  new  SearchScript(context.lookup(),  scriptLang,  script,  params,  context.scriptService());  
elasticsearch_d591972c1819d3297cd190e333200028f7053bf4	buggy:  assertThat(storeString,  equalTo( "store(least_used[byte_buffer]) "));  context:  assertThat(storeString.toLowerCase(Locale.ROOT),  startsWith( "store(least_used[rate_limited(simplefs( "  +  dataPaths[0].getAbsolutePath().toLowerCase(Locale.ROOT)));  if  (dataPaths.length  >  1)  {  assertThat(storeString.toLowerCase(Locale.ROOT),  containsString( "),  rate_limited(simplefs( "  +  dataPaths[1].getAbsolutePath().toLowerCase(Locale.ROOT)));  }  assertThat(storeString,  endsWith( ",  type=MERGE,  rate=20.0)]) "));  createIndexWithStoreType( "test ",   "memory ",   "least_used ");  storeString  =  getStoreDirectory( "test ",  0).toString();  dataPaths  =  dataPaths();          assertThat(storeString,  equalTo( "store(least_used[byte_buffer]) "));          assertThat(storeString,  equalTo( "store(least_used[ram]) "));  createIndexWithoutRateLimitingStoreType( "test ",   "niofs ",   "least_used ");  storeString  =  getStoreDirectory( "test ",  0).toString();  dataPaths  =  dataPaths();  assertThat(storeString.toLowerCase(Locale.ROOT),  startsWith( "store(least_used[niofs( "  +  dataPaths[0].getAbsolutePath().toLowerCase(Locale.ROOT)));  if  (dataPaths.length  >  1)  {  assertThat(storeString.toLowerCase(Locale.ROOT),  containsString( "),  niofs( "  +  dataPaths[1].getAbsolutePath().toLowerCase(Locale.ROOT)));  	assertThat(storeString,  equalTo( "store(least_used[ram]) "));  
elasticsearch_72c4cb51cc9d5768f8a1e40d7acb08f046ac9faf	buggy:  boolean  freed  =  searchService.freeContext(contextId);  context:  public  void  sendFreeContext(DiscoveryNode  node,  final  long  contextId,  SearchRequest  request)  {  if  (clusterService.state().nodes().localNodeId().equals(node.id()))  {  searchService.freeContext(contextId);  }  else  {  transportService.sendRequest(node,  FREE_CONTEXT_ACTION_NAME,  new  SearchFreeContextRequest(request,  contextId),  freeContextResponseHandler);  }  }  public  void  sendFreeContext(DiscoveryNode  node,  long  contextId,  ClearScrollRequest  request,  final  ActionListener<Boolean>  actionListener)  {  if  (clusterService.state().nodes().localNodeId().equals(node.id()))  {              boolean  freed  =  searchService.freeContext(contextId);              final  boolean  freed  =  searchService.freeContext(contextId);  actionListener.onResponse(freed);  }  else  {  transportService.sendRequest(node,  FREE_CONTEXT_ACTION_NAME,  new  SearchFreeContextRequest(request,  contextId),  new  FreeContextResponseHandler(actionListener));  }  }  public  void  sendClearAllScrollContexts(DiscoveryNode  node,  ClearScrollRequest  request,  final  ActionListener<Boolean>  actionListener)  {  if  (clusterService.state().nodes().localNodeId().equals(node.id()))  {  	final  boolean  freed  =  searchService.freeContext(contextId);  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  public  void  sameHost()  {  AllocationService  strategy  =  createAllocationService(settingsBuilder().put(SameShardAllocationDecider.SAME_HOST_SETTING,  true).build());  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(2).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  clusterState  =  ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()  .put(new  DiscoveryNode( "node1 ",   "node1 ",   "test1 ",   "test1 ",  DummyTransportAddress.INSTANCE,  ImmutableMap.<String,  String>of(),  Version.CURRENT))  .put(new  DiscoveryNode( "node2 ",   "node2 ",   "test1 ",   "test1 ",  DummyTransportAddress.INSTANCE,  ImmutableMap.<String,  String>of(),  Version.CURRENT))).build();  routingTable  =  strategy.reroute(clusterState).routingTable();  clusterState  =  ClusterState.builder(clusterState).routingTable(routingTable).build();  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
libgdx_6d35d3f784c49157dcc4f6530d6a528732358216	buggy:  GdxTest  test  =  new  MusicTest();  context:  public  class  LwjglDebugStarter  {  public  static  void  main  (String[]  argv)  {  GdxTest  test  =  new  MusicTest();  GdxTest  test  =  new  DownloadTest();  LwjglApplicationConfiguration  config  =  new  LwjglApplicationConfiguration();  new  LwjglApplication(test,  config);  }  }  	GdxTest  test  =  new  DownloadTest();  
elasticsearch_6bc3a744a1a4d516a8839470e3c4a474b2d9999d	buggy:  return  SpecialOperations.getFiniteStrings(automaton,  maxGraphExpansions);  context:  assert  SpecialOperations.isFinite(automaton);        return  SpecialOperations.getFiniteStrings(automaton,  maxGraphExpansions);        return  XSpecialOperations.getFiniteStrings(automaton,  maxGraphExpansions);  }  final  Automaton  toLookupAutomaton(final  CharSequence  key)  throws  IOException  {  TokenStream  ts  =  queryAnalyzer.tokenStream( " ",  key.toString());  Automaton  automaton  =  (getTokenStreamToAutomaton()).toAutomaton(ts);  ts.close();  	return  XSpecialOperations.getFiniteStrings(automaton,  maxGraphExpansions);  
elasticsearch_73383e201431cff19a278925eef630a2db2d6f51	buggy:  assert  rewriteIndexReader  ==  searcher.getIndexReader();  context:  public  Weight  createWeight(IndexSearcher  searcher)  throws  IOException  {  SearchContext  searchContext  =  SearchContext.current();  BytesRefHash  parentIds  =  new  BytesRefHash(512,  searchContext.bigArrays());  ParentIdCollector  collector  =  new  ParentIdCollector(parentType,  parentChildIndexFieldData,  parentIds);  final  Query  childQuery;  if  (rewrittenChildQuery  ==  null)  {  childQuery  =  rewrittenChildQuery  =  searcher.rewrite(originalChildQuery);  }  else  {              assert  rewriteIndexReader  ==  searcher.getIndexReader();              assert  rewriteIndexReader  ==  searcher.getIndexReader()  :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  childQuery  =  rewrittenChildQuery;  }  IndexSearcher  indexSearcher  =  new  IndexSearcher(searcher.getIndexReader());  indexSearcher.setSimilarity(searcher.getSimilarity());  indexSearcher.search(childQuery,  collector);  long  remaining  =  parentIds.size();  if  (remaining  ==  0)  {  	assert  rewriteIndexReader  ==  searcher.getIndexReader()    :   "not  equal,  rewriteIndexReader= "  +  rewriteIndexReader  +   "  searcher.getIndexReader()= "  +  searcher.getIndexReader();  
elasticsearch_3e92b1d6b8f7febd210928e05e021a405c06de31	buggy:  bulkRequest.add(data,  contentUnsafe,  defaultIndex,  defaultType,  payload);  context:  private  synchronized  void  internalAdd(ActionRequest  request,  @Nullable  Object  payload)  {  bulkRequest.add(request,  payload);  executeIfNeeded();  }  public  BulkProcessor  add(BytesReference  data,  boolean  contentUnsafe,  @Nullable  String  defaultIndex,  @Nullable  String  defaultType)  throws  Exception  {  return  add(data,  contentUnsafe,  defaultIndex,  defaultType,  null);  }  public  synchronized  BulkProcessor  add(BytesReference  data,  boolean  contentUnsafe,  @Nullable  String  defaultIndex,  @Nullable  String  defaultType,  @Nullable  Object  payload)  throws  Exception  {          bulkRequest.add(data,  contentUnsafe,  defaultIndex,  defaultType,  payload);          bulkRequest.add(data,  contentUnsafe,  defaultIndex,  defaultType,  payload,  true);  executeIfNeeded();  return  this;  }  private  void  executeIfNeeded()  {  if  (closed)  {  throw  new  ElasticSearchIllegalStateException( "bulk  process  already  closed ");  }  	bulkRequest.add(data,  contentUnsafe,  defaultIndex,  defaultType,  payload,  true);  
elasticsearch_454954e7be9fecf80311fbbfd184e22cd827f4e2	buggy:  public  int  reducedType()  {  context:  this.fieldDataCache  =  fieldDataCache;  this.mapperService  =  mapperService;  }  public  FieldComparator  newComparator(String  fieldname,  int  numHits,  int  sortPos,  boolean  reversed)  throws  IOException  {  return  new  GeoDistanceDataComparator(numHits,  fieldname,  lat,  lon,  unit,  geoDistance,  fieldDataCache,  mapperService);  }          public  int  reducedType()  {          public  SortField.Type  reducedType()  {  return  SortField.DOUBLE;  }  }  protected  final  String  fieldName;  protected  final  String  indexFieldName;  	public  SortField.Type  reducedType()  {  
elasticsearch_a04d18d2d24056c128043ddb7c3bc3b6ade545f8	buggy:  fields.add(toDocValues(value));  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomLongNumericField  field  =  new  CustomLongNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              fields.add(toDocValues(value));              addDocValue(context,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  value);  
elasticsearch_99d31cc8c84d0f55c9c052b2875bc2002b85d7b9	buggy:  serverOpenChannels  =  new  OpenChannelsHandler();  context:  clientBootstrap.setOption( "receiveBufferSize ",  tcpReceiveBufferSize.bytes());  }  if  (reuseAddress  !=  null)  {  clientBootstrap.setOption( "reuseAddress ",  reuseAddress);  }  if  (!settings.getAsBoolean( "network.server ",  true))  {  return;  }          serverOpenChannels  =  new  OpenChannelsHandler();          serverOpenChannels  =  new  OpenChannelsHandler(logger);  if  (blockingServer)  {  serverBootstrap  =  new  ServerBootstrap(new  OioServerSocketChannelFactory(  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "transport_server_boss ")),  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "transport_server_worker "))  ));  }  else  {  serverBootstrap  =  new  ServerBootstrap(new  NioServerSocketChannelFactory(  Executors.newCachedThreadPool(daemonThreadFactory(settings,   "transport_server_boss ")),  	serverOpenChannels  =  new  OpenChannelsHandler(logger);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<ContextDocIdSet>  nestedEntries  =  new  ArrayList<ContextDocIdSet>(docSets.size());  context:  }  public  Post(Post  post,  Filter  filter)  {  this.post  =  new  FacetExecutor.Post.Filtered(post.post,  filter);  this.parentFilter  =  post.parentFilter;  this.childFilter  =  post.childFilter;  }  public  void  executePost(List<ContextDocIdSet>  docSets)  throws  IOException  {              List<ContextDocIdSet>  nestedEntries  =  new  ArrayList<ContextDocIdSet>(docSets.size());              List<ContextDocIdSet>  nestedEntries  =  new  ArrayList<>(docSets.size());  for  (int  i  =  0;  i  <  docSets.size();  i++)  {  ContextDocIdSet  entry  =  docSets.get(i);  AtomicReaderContext  context  =  entry.context;  DocIdSet  docIdSet  =  parentFilter.getDocIdSet(context,  null);  if  (DocIdSets.isEmpty(docIdSet))  {  continue;  }  	List<ContextDocIdSet>  nestedEntries  =  new  ArrayList<>(docSets.size());  
elasticsearch_deada942e5c85f49e7452291c4242cb41b784eef	buggy:  boolean  cache  =  true;  context:  return  new  String[]{NAME,  Strings.toCamelCase(NAME)};  }  XContentParser  parser  =  parseContext.parser();  Filter  filter  =  null;  float  boost  =  1.0f;          boolean  cache  =  true;          boolean  cache  =  false;  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "filter ".equals(currentFieldName))  {  	boolean  cache  =  false;  
elasticsearch_07c9b5b08d985a270e36f2cac790d7450d8a7905	buggy:  logger.error( "[{}]  New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  context:  newUsed  =  currentUsed  +  bytes;  long  newUsedWithOverhead  =  (long)  (newUsed  *  overheadConstant);  if  (logger.isTraceEnabled())  {  this.name,  new  ByteSizeValue(bytes),  label,  new  ByteSizeValue(newUsed),  memoryBytesLimit,  new  ByteSizeValue(memoryBytesLimit),  newUsedWithOverhead,  new  ByteSizeValue(newUsedWithOverhead));  }  if  (memoryBytesLimit  >  0  &&  newUsedWithOverhead  >  memoryBytesLimit)  {                      logger.error( "[{}]  New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",                      logger.warn( "[{}]  New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  this.name,  newUsedWithOverhead,  new  ByteSizeValue(newUsedWithOverhead),  label,  memoryBytesLimit,  new  ByteSizeValue(memoryBytesLimit));  circuitBreak(label,  newUsedWithOverhead);  }  }  while  (!this.used.compareAndSet(currentUsed,  newUsed));  	logger.warn( "[{}]  New  used  memory  {}  [{}]  from  field  [{}]  would  be  larger  than  configured  breaker:  {}  [{}],  breaking ",  
elasticsearch_3c5dd43928678cba2e3ca5d55636e70139b9ae74	buggy:  logger.warn( "using  stable  discover  node  UUIDs  with  seed:  [{}] ",  seed);  context:  if  (minimumMasterNodes  !=  ZenDiscovery.this.electMaster.minimumMasterNodes())  {  handleMinimumMasterNodesChanged(minimumMasterNodes);  }  }  }  private  final  String  getNodeUUID(Settings  settings)  {  String  seed  =  settings.get( "discovery.id.seed ");  if  (seed  !=  null)  {              logger.warn( "using  stable  discover  node  UUIDs  with  seed:  [{}] ",  seed);              logger.trace( "using  stable  discover  node  UUIDs  with  seed:  [{}] ",  seed);  Strings.randomBase64UUID(new  Random(Long.parseLong(seed)));  }  return  Strings.randomBase64UUID();  }  }  	logger.trace( "using  stable  discover  node  UUIDs  with  seed:  [{}] ",  seed);  
libgdx_61a644025318b4de08386a63162ca5eae8303b0b	buggy:  System.out.println( "dispose  intro ");  context:  time  +=  delta;  if  (time  >  1)  {  if  (Gdx.input.isKeyPressed(Keys.ANY_KEY)  ||  Gdx.input.justTouched())  {  game.setScreen(new  MainMenu(game));  }  }  }  public  void  hide  ()  {  System.out.println( "dispose  intro ");  Gdx.app.debug( "Cubocy ",   "dispose  intro ");  batch.dispose();  intro.getTexture().dispose();  }  }  	Gdx.app.debug( "Cubocy ",   "dispose  intro ");  
libgdx_a733ccb6fbaa5cdb99538db4511af3c4933d6642	buggy:  textBounds.height  =  data.capHeight  +  (numLines  -  1)  *  data.lineHeight;  context:  int  numLines  =  0;  int  length  =  str.length();  while  (start  <  length)  {  int  lineEnd  =  indexOf(str,  '\n',  start);  float  lineWidth  =  getBounds(str,  start,  lineEnd).width;  maxWidth  =  Math.max(maxWidth,  lineWidth);  start  =  lineEnd  +  1;  numLines++;  }  textBounds.width  =  maxWidth;  textBounds.height  =  data.capHeight  +  (numLines  -  1)  *  data.lineHeight;  textBounds.height  =  data.capHeight  -  data.descent  +  (numLines  -  1)  *  data.lineHeight;  return  textBounds;  }  public  TextBounds  getWrappedBounds  (CharSequence  str,  float  wrapWidth)  {  	textBounds.height  =  data.capHeight  -  data.descent  +  (numLines  -  1)  *  data.lineHeight;  
elasticsearch_d0b89c227cca35977e2828541ac4577d01519a34	buggy:  return  new  JapanesePartOfSpeechStopFilter(Version.LUCENE_44,  tokenStream,  stopTags);  context:  public  KuromojiPartOfSpeechFilterFactory(Index  index,  @IndexSettings  Settings  indexSettings,  Environment  env,  @Assisted  String  name,  @Assisted  Settings  settings)  {  super(index,  indexSettings,  name,  settings);  List<String>  wordList  =  Analysis.getWordList(env,  settings,   "stoptags ");  if  (wordList  !=  null)  {  stopTags.addAll(wordList);  }  }  public  TokenStream  create(TokenStream  tokenStream)  {          return  new  JapanesePartOfSpeechStopFilter(Version.LUCENE_44,  tokenStream,  stopTags);          return  new  JapanesePartOfSpeechStopFilter(Version.LUCENE_48,  tokenStream,  stopTags);  }  }  	return  new  JapanesePartOfSpeechStopFilter(Version.LUCENE_48,  tokenStream,  stopTags);  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  context:  public  class  UpdateNumberOfReplicasTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(UpdateNumberOfReplicasTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (DoubleFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_e75301b781f2ee73f0782d9b90b5fa085052ad9a	buggy:  BytesRef  type  =  parser.bytes(null);  context:  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }  String  fieldName  =  parser.currentName();  if  (!fieldName.equals( "value "))  {  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }  token  =  parser.nextToken();  if  (token  !=  XContentParser.Token.VALUE_STRING)  {  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }          BytesRef  type  =  parser.bytes(null);          BytesRef  type  =  parser.bytes();  parser.nextToken();  Filter  filter;  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(type.utf8ToString());  if  (documentMapper  ==  null)  {  filter  =  new  TermFilter(new  Term(TypeFieldMapper.TERM_FACTORY.field(),  type));  	BytesRef  type  =  parser.bytes();  
elasticsearch_3c95d6a2153b8243d376725363340488f727a7f6	buggy:  bind(Map.class).annotatedWith(IndexerSettings.class).toInstance(settings);  context:  this.indexerName  =  indexerName;  this.globalSettings  =  globalSettings;  this.settings  =  settings;  }  return  ImmutableList.of(Modules.createModule(loadTypeModule(indexerName.type(),   "org.elasticsearch.indexer. ",   "IndexerModule "),  globalSettings));  }          bind(Map.class).annotatedWith(IndexerSettings.class).toInstance(settings);          bind(IndexerSettings.class).toInstance(new  IndexerSettings(globalSettings,  settings));  }  private  Class<?  extends  Module>  loadTypeModule(String  type,  String  prefixPackage,  String  suffixClassName)  {  String  fullClassName  =  type;  try  {  return  (Class<?  extends  Module>)  globalSettings.getClassLoader().loadClass(fullClassName);  }  catch  (ClassNotFoundException  e)  {  fullClassName  =  prefixPackage  +  Strings.capitalize(toCamelCase(type))  +  suffixClassName;  	bind(IndexerSettings.class).toInstance(new  IndexerSettings(globalSettings,  settings));  
elasticsearch_646800cb29240065604482403caf672a66edce88	buggy:  translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null));  context:  assertThat(snapshot,  translogSize(2));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(2));  snapshot.release();  translog.add(new  Translog.Delete(newUid( "3 ")));  snapshot  =  translog.snapshot();  assertThat(snapshot,  translogSize(3));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(3));  snapshot.release();          translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null));          translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null,  null));  snapshot  =  translog.snapshot();  assertThat(snapshot,  translogSize(4));  assertThat(snapshot.estimatedTotalOperations(),  equalTo(4));  snapshot.release();  snapshot  =  translog.snapshot();  assertThat(snapshot.hasNext(),  equalTo(true));  	translog.add(new  Translog.DeleteByQuery(new  byte[]{4},  null,  null));  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);  context:  MapperService.SmartNameFieldMappers  smartMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartMappers  ==  null  ||  !smartMappers.hasMapper())  {  throw  new  QueryParsingException(parseContext.index(),   "failed  to  find  geo_point  field  [ "  +  fieldName  +   "] ");  }  FieldMapper<?>  mapper  =  smartMappers.mapper();  if  (!(mapper  instanceof  GeoPointFieldMapper))  {  throw  new  QueryParsingException(parseContext.index(),   "field  [ "  +  fieldName  +   "]  is  not  a  geo_point  field ");  }  GeoPointFieldMapper  geoMapper  =  ((GeoPointFieldMapper)  mapper);          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.fieldData().getForField(mapper);          IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  Filter  filter  =  new  GeoDistanceRangeFilter(point,  from,  to,  includeLower,  includeUpper,  geoDistance,  geoMapper,  indexFieldData,  optimizeBbox);  if  (cache)  {  filter  =  parseContext.cacheFilter(filter,  cacheKey);  }  filter  =  wrapSmartNameFilter(filter,  smartMappers,  parseContext);  if  (filterName  !=  null)  {  parseContext.addNamedFilter(filterName,  filter);  }  	IndexGeoPointFieldData<?>  indexFieldData  =  parseContext.getForField(mapper);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);  context:  fieldSelector  =  new  UidAndSourceFieldSelector();  }  else  if  (context.fieldNames().isEmpty())  {  fieldSelector  =  UidFieldSelector.INSTANCE;  }  else  if  (context.fieldNames().get(0).equals( "* "))  {  fieldSelector  =  AllButSourceFieldSelector.INSTANCE;  }  else  {  FieldMappersFieldSelector  fieldSelectorMapper  =  new  FieldMappersFieldSelector();  for  (String  fieldName  :  context.fieldNames())  {                  FieldMappers  x  =  context.mapperService().smartNameFieldMappers(fieldName);                  FieldMappers  x  =  context.smartNameFieldMappers(fieldName);  if  (x  !=  null  &&  x.mapper().stored())  {  fieldSelectorMapper.add(x);  }  else  {  if  (extractFieldNames  ==  null)  {  extractFieldNames  =  Lists.newArrayList();  }  extractFieldNames.add(fieldName);  }  	FieldMappers  x  =  context.smartNameFieldMappers(fieldName);  
libgdx_969f0110339763f523cbd41d2901b4fad75b3762	buggy:  buffer.put(indices);  context:  public  void  setIndices  (short[]  indices,  int  offset,  int  count)  {  isDirty  =  true;  buffer.clear();  buffer.put(indices);  buffer.put(indices,  offset,  count);  buffer.flip();  byteBuffer.position(0);  byteBuffer.limit(count  <<  1);  if  (isBound)  {  if  (Gdx.gl11  !=  null)  {  GL11  gl  =  Gdx.gl11;  	buffer.put(indices,  offset,  count);  
elasticsearch_689fd15d786428869a7e311ef6c42f0094ae45a9	buggy:  shell.add(GeoPoint.parse(parser));  context:  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  fieldName  =  currentFieldName;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  (POINTS.equals(currentFieldName))  {  while  ((token  =  parser.nextToken())  !=  Token.END_ARRAY)  {                                  shell.add(GeoPoint.parse(parser));                                  shell.add(GeoUtils.parseGeoPoint(parser));  }  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[geo_polygon]  filter  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[geo_polygon]  filter  does  not  support  token  type  [ "  +  token.name()  +   "]  under  [ "  +  currentFieldName  +   "] ");  }  }  	shell.add(GeoUtils.parseGeoPoint(parser));  
elasticsearch_31f0aca65d4955bc0d91063842d93bcb78d00bc6	buggy:  SegmentInfoPerCommit  info  =  Lucene.getSegmentInfo((SegmentReader)  reader.reader());  context:  if  (indexWriter  ==  null)  {  throw  new  EngineClosedException(shardId,  failedEngine);  }  Map<String,  Segment>  segments  =  new  HashMap<String,  Segment>();  Searcher  searcher  =  searcher();  try  {  for  (AtomicReaderContext  reader  :  searcher.reader().leaves())  {  assert  reader.reader()  instanceof  SegmentReader;                      SegmentInfoPerCommit  info  =  Lucene.getSegmentInfo((SegmentReader)  reader.reader());                      SegmentInfoPerCommit  info  =  ((SegmentReader)  reader.reader()).getSegmentInfo();  assert  !segments.containsKey(info.info.name);  Segment  segment  =  new  Segment(info.info.name);  segment.search  =  true;  segment.docCount  =  reader.reader().numDocs();  segment.delDocCount  =  reader.reader().numDeletedDocs();  segment.version  =  info.info.getVersion();  segment.compound  =  info.info.getUseCompoundFile();  try  {  	SegmentInfoPerCommit  info  =  ((SegmentReader)  reader.reader()).getSegmentInfo();  
libgdx_4834cf9474ca71c245a0ff942a082a0d208b1e33	buggy:  com.badlogic.gdx.graphics.g3d.model.Model  model2  =  new  com.badlogic.gdx.graphics.g3d.model.Model(loader.parseModel(Gdx.files.internal( "data/g3d/head2.g3dj "),  null));  context:  float  angleY  =  0;  float  angleX  =  0;  float[]  lightColor  =  {1,  1,  1,  0};  float[]  lightPosition  =  {2,  5,  10,  0};  float  touchStartX  =  0;  float  touchStartY  =  0;  public  void  create  ()  {  JsonModelLoader  loader  =  new  JsonModelLoader();  com.badlogic.gdx.graphics.g3d.model.Model  model2  =  new  com.badlogic.gdx.graphics.g3d.model.Model(loader.parseModel(Gdx.files.internal( "data/g3d/head2.g3dj "),  null));  com.badlogic.gdx.graphics.g3d.Model  model2  =  new  com.badlogic.gdx.graphics.g3d.Model(loader.parseModel(Gdx.files.internal( "data/g3d/head2.g3dj "),  null));  model  =  loader.load(Gdx.files.internal( "data/g3d/head2.g3dj "),  null);  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  cam.position.set(1f,  1.5f,  1f);  cam.direction.set(-1,  -1,  -1);  cam.near  =  0.001f;  Gdx.input.setInputProcessor(this);  }  	com.badlogic.gdx.graphics.g3d.Model  model2  =  new  com.badlogic.gdx.graphics.g3d.Model(loader.parseModel(Gdx.files.internal( "data/g3d/head2.g3dj "),    null));  
elasticsearch_7bcabf9481a8edd2ba88d82ae122f61778c6e239	buggy:  public  BytesValues  getBytesValues(boolean  needsHashes)  {  context:  public  abstract  class  AtomicGeoPointFieldData<Script  extends  ScriptDocValues>  implements  AtomicFieldData<Script>  {  public  abstract  GeoPointValues  getGeoPointValues();      public  BytesValues  getBytesValues(boolean  needsHashes)  {      public  BytesValues  getBytesValues()  {  final  GeoPointValues  values  =  getGeoPointValues();  return  new  BytesValues(values.isMultiValued())  {  public  int  setDocument(int  docId)  {  this.docId  =  docId;  return  values.setDocument(docId);  }  	public  BytesValues  getBytesValues()  {  
elasticsearch_facd18086cf4d74e7a7959c0e73dda68ec1c786c	buggy:  String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)].name().toLowerCase(Locale.ROOT);  context:  .setSource(jsonBuilder().startObject().field( "p_field ",   "2 ").startArray( "objects ")  .startObject().field( "i_field ",   "1 ").endObject()  .startObject().field( "i_field ",   "2 ").endObject()  .endArray().endObject())  .execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c1 ").setParent( "p1 ").setSource( "c_field ",   "blue ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c2 ").setParent( "p1 ").setSource( "c_field ",   "red ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c3 ").setParent( "p2 ").setSource( "c_field ",   "red ").execute().actionGet();  client().admin().indices().prepareRefresh( "test ").execute().actionGet();          String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)].name().toLowerCase(Locale.ROOT);          String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)  -  1].name().toLowerCase(Locale.ROOT);  SearchResponse  searchResponse  =  client().prepareSearch( "test ")  .setQuery(filteredQuery(QueryBuilders.hasChildQuery( "child ",  termQuery( "c_field ",   "blue ")).scoreType(scoreMode),  notFilter(termFilter( "p_field ",   "3 "))))  .execute().actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  searchResponse  =  client().prepareSearch( "test ")  .setQuery(filteredQuery(QueryBuilders.hasChildQuery( "child ",  termQuery( "c_field ",   "red ")).scoreType(scoreMode),  notFilter(termFilter( "p_field ",   "3 "))))  	String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)  -  1].name().toLowerCase(Locale.ROOT);  
libgdx_f89eef53238003b3067d684726c6314051cf6996	buggy:  if  (!child.touchable  ||  !child.touchable)  continue;  context:  return  false;  }  public  boolean  touchMoved  (float  x,  float  y)  {  if  (!touchable  ||  !visible)  return  false;  int  len  =  children.size()  -  1;  for  (int  i  =  len;  i  >=  0;  i--)  {  Actor  child  =  children.get(i);  if  (!child.touchable  ||  !child.touchable)  continue;  if  (!child.touchable  ||  !child.visible)  continue;  toChildCoordinates(child,  x,  y,  point);  if  (child.touchMoved(point.x,  point.y))  return  true;  }  return  false;  }  	if  (!child.touchable  ||  !child.visible)  continue;  
elasticsearch_054542383762e28de1e0595ece9bbe3b137a86cf	buggy:  ).sourceField(source( "_source ").compressionThreshold(0)).build();  context:  public  class  SimpleJsonMapperTests  {  JsonDocumentMapper  docMapper  =  doc(  object( "person ")  .add(object( "name ").add(stringField( "first ").store(YES).index(Field.Index.NO)))          ).sourceField(source( "_source ").compressionThreshold(0)).build();          ).sourceField(source().compressionThreshold(0)).build();  String  json  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/json/simple/test1.json ");  Document  doc  =  docMapper.parse( "person ",   "1 ",  json).doc();  assertThat((double)  doc.getBoost(),  closeTo(3.7,  0.01));  assertThat(doc.get(docMapper.mappers().name( "first ").mapper().indexName()),  equalTo( "shay "));  assertThat(docMapper.mappers().name( "first ").mapper().fullName(),  equalTo( "name.first "));  	).sourceField(source().compressionThreshold(0)).build();  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  BytesStreamInput  in  =  new  BytesStreamInput(data);  context:  operation  =  new  Translog.Index();  break;  default:  throw  new  IOException( "No  type  for  [ "  +  type  +   "] ");  }  operation.readFrom(in);  return  operation;  }  public  static  Translog.Source  readSource(byte[]  data)  throws  IOException  {          BytesStreamInput  in  =  new  BytesStreamInput(data);          BytesStreamInput  in  =  new  BytesStreamInput(data,  false);  in.readInt();  //  the  size  header  Translog.Operation.Type  type  =  Translog.Operation.Type.fromId(in.readByte());  Translog.Operation  operation;  switch  (type)  {  case  CREATE:  operation  =  new  Translog.Create();  break;  case  DELETE:  	BytesStreamInput  in  =  new  BytesStreamInput(data,  false);  
elasticsearch_ae326c42328994a6dd78a4e73c5b2528d08570ab	buggy:  for  (int  i  =  0;  i  <  2000;  i++)  {  context:  CompressedString  cstr2  =  new  CompressedString(str2);  assertThat(cstr2.string(),  not(equalTo(str)));  assertThat(new  CompressedString(str2),  not(equalTo(cstr)));  assertThat(new  CompressedString(str2),  equalTo(cstr2));  }  public  void  testRandom()  throws  IOException  {  String  compressor  =   "lzf ";  CompressorFactory.configure(ImmutableSettings.settingsBuilder().put( "compress.default.type ",  compressor).build());  Random  r  =  getRandom();          for  (int  i  =  0;  i  <  2000;  i++)  {          for  (int  i  =  0;  i  <  1000;  i++)  {  String  string  =  TestUtil.randomUnicodeString(r,  10000);  CompressedString  compressedString  =  new  CompressedString(string);  assertThat(compressedString.string(),  equalTo(string));  }  }  }  	for  (int  i  =  0;  i  <  1000;  i++)  {  
elasticsearch_d1d3f8c4ca39471ff551330eea508d31d9aea2ea	buggy:  channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));  context:  }  if  (nodeStats.transport()  !=  null)  {  nodeStats.transport().toXContent(builder,  request);  }  builder.endObject();  }  builder.endObject();  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  
elasticsearch_f997315f54ec7bf8b158e051a68a5580b5a023d8	buggy:  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);  context:  public  static  final  String  NAME  =   "_exists_ ";  public  Query  query(QueryParseContext  parseContext,  String  queryText)  {  String  fieldName  =  queryText;  Filter  filter  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true);                  filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  }  }  if  (filter  ==  null)  {  filter  =  new  TermRangeFilter(fieldName,  null,  null,  true,  true);  }  filter  =  parseContext.cacheFilter(filter,  null);  	filter  =  smartNameFieldMappers.mapper().rangeFilter(null,  null,  true,  true,  parseContext);  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));  context:  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(CloseIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  void  masterOperation(final  CloseIndexRequest  request,  final  ClusterState  state,  final  ActionListener<CloseIndexResponse>  listener)  throws  ElasticsearchException  {          request.indices(state.metaData().concreteIndices(request.indices(),  request.indicesOptions()));          request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  CloseIndexClusterStateUpdateRequest  updateRequest  =  new  CloseIndexClusterStateUpdateRequest()  .ackTimeout(request.timeout()).masterNodeTimeout(request.masterNodeTimeout())  .indices(request.indices());  indexStateService.closeIndex(updateRequest,  new  ClusterStateUpdateListener()  {  public  void  onResponse(ClusterStateUpdateResponse  response)  {  	request.indices(state.metaData().concreteIndices(request.indicesOptions(),  request.indices()));  
elasticsearch_9c9cd01854d4343b11314d58b82c00f1de335f8a	buggy:  if  (parser.hasTextCharacters())  {  context:  String  op  =  parser.text();  if  ( "or ".equalsIgnoreCase(op))  {  defaultOperator  =  BooleanClause.Occur.SHOULD;  }  else  if  ( "and ".equalsIgnoreCase(op))  {  defaultOperator  =  BooleanClause.Occur.MUST;  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[ "  +  NAME  +   "]  default  operator  [ "  +  op  +   "]  is  not  allowed ");  }  }  else  if  ( "flags ".equals(currentFieldName))  {                      if  (parser.hasTextCharacters())  {                      if  (parser.currentToken()  !=  XContentParser.Token.VALUE_NUMBER)  {  flags  =  SimpleQueryStringFlag.resolveFlags(parser.text());  }  else  {  flags  =  parser.intValue();  if  (flags  <  0)  {  flags  =  SimpleQueryStringFlag.ALL.value();  }  	if  (parser.currentToken()  !=  XContentParser.Token.VALUE_NUMBER)  {  
elasticsearch_a2011e0151bcda374a878fe4b3c8e33668e07275	buggy:  Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER);  //  no  need  to  cache  a  MATCH  ALL  FILTER  context:  if  (context.facets()  ==  null)  {  return;  }  if  (context.queryResult().facets()  !=  null)  {  return;  }  if  (context.searcher().globalCollectors()  !=  null)  {              Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER);  //  no  need  to  cache  a  MATCH  ALL  FILTER              Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER,  true);  //  no  need  to  cache  a  MATCH  ALL  FILTER  if  (context.types().length  >  0)  {  if  (context.types().length  ==  1)  {  String  type  =  context.types()[0];  DocumentMapper  docMapper  =  context.mapperService().documentMapper(type);  query  =  new  FilteredQuery(query,  context.filterCache().cache(docMapper.typeFilter()));  }  else  {  BooleanFilter  booleanFilter  =  new  BooleanFilter();  for  (String  type  :  context.types())  {  	Query  query  =  new  DeletionAwareConstantScoreQuery(Queries.MATCH_ALL_FILTER,  true);  //  no  need  to  cache  a  MATCH  ALL  FILTER  
elasticsearch_454954e7be9fecf80311fbbfd184e22cd827f4e2	buggy:  public  int  reducedType()  {  context:  private  InnerSource(SearchScript  script)  {  this.script  =  script;  }  public  FieldComparator  newComparator(String  fieldname,  int  numHits,  int  sortPos,  boolean  reversed)  throws  IOException  {  return  new  StringFieldsFunctionDataComparator(numHits,  script);  }          public  int  reducedType()  {          public  SortField.Type  reducedType()  {  return  SortField.STRING;  }  }  private  final  SearchScript  script;  private  String[]  values;  	public  SortField.Type  reducedType()  {  
elasticsearch_bcbc0dd7414b26fdb4479f0bc9ac269d46f335a6	buggy:  sb.append( "Failed  to  execute  [ ").append(phaseName).append( "]   ").append(msg);  context:  public  String  phaseName()  {  return  phaseName;  }  public  ShardSearchFailure[]  shardFailures()  {  return  shardFailures;  }  private  static  final  String  buildMessage(String  phaseName,  String  msg,  ShardSearchFailure[]  shardFailures)  {  StringBuilder  sb  =  new  StringBuilder();          sb.append( "Failed  to  execute  [ ").append(phaseName).append( "]   ").append(msg);          sb.append( "Failed  to  execute  phase  [ ").append(phaseName).append( "],   ").append(msg);  if  (shardFailures  !=  null  &&  shardFailures.length  >  0)  {  sb.append( ";  shardFailures   ");  for  (ShardSearchFailure  shardFailure  :  shardFailures)  {  sb.append( "{ ").append(shardFailure.shard()).append( ":   ").append(shardFailure.reason()).append( "} ");  }  }  return  sb.toString();  }  	sb.append( "Failed  to  execute  phase  [ ").append(phaseName).append( "],   ").append(msg);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();  context:  public  class  ScriptsScorePayloadSumBenchmark  extends  BasicScriptBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {  int  minTerms  =  1;  int  maxTerms  =  50;  int  maxIter  =  100;  int  warmerIter  =  10;  init(maxTerms);          List<Results>  allResults  =  new  ArrayList<BasicScriptBenchmark.Results>();          List<Results>  allResults  =  new  ArrayList<>();  Settings  settings  =  settingsBuilder().put( "plugin.types ",  NativeScriptExamplesPlugin.class.getName()).build();  String  clusterName  =  ScriptsScoreBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().clusterName(clusterName).settings(settingsBuilder().put(settings).put( "name ",   "node1 ")).node();  Client  client  =  node1.client();  client.admin().cluster().prepareHealth( "test ").setWaitForGreenStatus().setTimeout( "10s ").execute().actionGet();  indexData(10000,  client,  false);  	List<Results>  allResults  =  new  ArrayList<>();  
libgdx_7f8d8ae28dfeb1dbc59b86a741845809cf4013fb	buggy:  Gdx.graphics.getGL10().glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  context:  camera  =  new  PerspectiveCamera(60,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  camera.position.set(0,  25,  100);  camera.near  =  1;  camera.far  =  1000;  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  Gdx.graphics.getGL10().glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  Gdx.input.setInputProcessor(this);  }  float  angle  =  0;  public  void  render  ()  {  	Gdx.gl.glViewport(0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  
libgdx_6b851cfa71f0ecc1c687d1c4be3b6dc07c1a8adf	buggy:  System.arraycopy(value,  0,  value,  length,  value.length);  context:  chars[length++]  =  'u';  chars[length++]  =  'l';  chars[length++]  =  'l';  }  final  void  append0  (char[]  value)  {  int  newSize  =  length  +  value.length;  if  (newSize  >  chars.length)  {  enlargeBuffer(newSize);  }  System.arraycopy(value,  0,  value,  length,  value.length);  System.arraycopy(value,  0,  chars,  length,  value.length);  length  =  newSize;  }  final  void  append0  (char[]  value,  int  offset,  int  length)  {  if  (offset  >  value.length  ||  offset  <  0)  {  throw  new  ArrayIndexOutOfBoundsException( "Offset  out  of  bounds:   "  +  offset);  }  	System.arraycopy(value,  0,  chars,  length,  value.length);  
elasticsearch_8dedbd01df14c76fc8f1ac9060facc053fa2be9b	buggy:  if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {  context:  if  (blockException  !=  null)  {  throw  blockException;  }  final  AtomicInteger  indexCounter  =  new  AtomicInteger();  final  AtomicInteger  completionCounter  =  new  AtomicInteger(concreteIndices.length);  final  AtomicReferenceArray<Object>  indexResponses  =  new  AtomicReferenceArray<>(concreteIndices.length);  final  long  startTimeInMillis  =  System.currentTimeMillis();  Map<String,  Set<String>>  routingMap  =  resolveRouting(clusterState,  request);          if  (concreteIndices  ==  null  ||  concreteIndices.length  ==  0)  {          if  (concreteIndices.length  ==  0)  {  listener.onResponse(newResponseInstance(request,  indexResponses));  }  else  {  for  (final  String  index  :  concreteIndices)  {  Set<String>  routing  =  null;  if  (routingMap  !=  null)  {  routing  =  routingMap.get(index);  }  IndexRequest  indexRequest  =  newIndexRequestInstance(request,  index,  routing,  startTimeInMillis);  	if  (concreteIndices.length  ==  0)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<CoordinateNode>  nodes  =  new  ArrayList<CoordinateNode>();  context:  if  (token  !=  XContentParser.Token.START_ARRAY)  {  double  lon  =  parser.doubleValue();  token  =  parser.nextToken();  double  lat  =  parser.doubleValue();  token  =  parser.nextToken();  return  new  CoordinateNode(new  Coordinate(lon,  lat));  }          List<CoordinateNode>  nodes  =  new  ArrayList<CoordinateNode>();          List<CoordinateNode>  nodes  =  new  ArrayList<>();  while  (token  !=  XContentParser.Token.END_ARRAY)  {  nodes.add(parseCoordinates(parser));  token  =  parser.nextToken();  }  return  new  CoordinateNode(nodes);  }  	List<CoordinateNode>  nodes  =  new  ArrayList<>();  
libgdx_db17325d71bec6c0769d0a7bc20060d617360000	buggy:  return  false;  context:  public  class  BlitTest  extends  GdxTest  {  public  boolean  needsGL20  ()  {  return  false;  return  true;  }  Texture  rgb888;  Texture  rgba8888;  Texture  psRgb888;  Texture  psRgba8888;  SpriteBatch  batch;  	return  true;  
elasticsearch_14def814fac9042c0ae63992da596852d643dddb	buggy:  tokenizersBindings.processTokenizer( "uaUrlEmail ",  UAX29URLEmailTokenizerFactory.class);  context:  tokenFiltersBindings.processTokenFilter( "phonetic ",  PhoneticTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "dictionaryDecompounder ",  DictionaryCompoundWordTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "dictionary_decompounder ",  DictionaryCompoundWordTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "hyphenationDecompounder ",  HyphenationCompoundWordTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "hypennation_decompounder ",  HyphenationCompoundWordTokenFilterFactory.class);  }  tokenizersBindings.processTokenizer( "standard ",  StandardTokenizerFactory.class);  tokenizersBindings.processTokenizer( "uax_url_email ",  UAX29URLEmailTokenizerFactory.class);              tokenizersBindings.processTokenizer( "uaUrlEmail ",  UAX29URLEmailTokenizerFactory.class);              tokenizersBindings.processTokenizer( "uaxUrlEmail ",  UAX29URLEmailTokenizerFactory.class);  tokenizersBindings.processTokenizer( "path_hierarchy ",  PathHierarchyTokenizerFactory.class);  tokenizersBindings.processTokenizer( "pathHierarchy ",  PathHierarchyTokenizerFactory.class);  tokenizersBindings.processTokenizer( "keyword ",  KeywordTokenizerFactory.class);  tokenizersBindings.processTokenizer( "letter ",  LetterTokenizerFactory.class);  tokenizersBindings.processTokenizer( "lowercase ",  LowerCaseTokenizerFactory.class);  tokenizersBindings.processTokenizer( "whitespace ",  WhitespaceTokenizerFactory.class);  tokenizersBindings.processTokenizer( "russian_letter ",  RussianLetterTokenizerFactory.class);  tokenizersBindings.processTokenizer( "russianLetter ",  RussianLetterTokenizerFactory.class);  	tokenizersBindings.processTokenizer( "uaxUrlEmail ",  UAX29URLEmailTokenizerFactory.class);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  mapper  =  parseContext.mapperService().smartNameFieldMapper(field);  context:  }  }  }  if  (inner  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "field_masking_span  must  have  [query]  span  query  clause ");  }  if  (field  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "field_masking_span  must  have  [field]  set  for  it ");  }          FieldMapper  mapper  =  parseContext.mapperService().smartNameFieldMapper(field);          FieldMapper  mapper  =  parseContext.fieldMapper(field);  if  (mapper  !=  null)  {  field  =  mapper.names().indexName();  }  FieldMaskingSpanQuery  query  =  new  FieldMaskingSpanQuery(inner,  field);  query.setBoost(boost);  return  query;  }  	FieldMapper  mapper  =  parseContext.fieldMapper(field);  
elasticsearch_c46228254dee13dc8f6bfeeb4ce508bd8bfc6975	buggy:  context.reader().document(doc,  new  UidAndRoutingFieldVisitor());  context:  public  void  setScorer(Scorer  scorer)  {  }  public  boolean  acceptsDocsOutOfOrder()  {  return  true;  }  public  void  collect(int  doc)  {  try  {  UidAndRoutingFieldVisitor  fieldVisitor  =  new  UidAndRoutingFieldVisitor();                  context.reader().document(doc,  new  UidAndRoutingFieldVisitor());                  context.reader().document(doc,  fieldVisitor);  String  uid  =  fieldVisitor.uid();  long  version  =  UidField.loadVersion(context,  new  Term(UidFieldMapper.NAME,  uid));  docsToPurge.add(new  DocToPurge(Uid.typeFromUid(uid),  Uid.idFromUid(uid),  version,  fieldVisitor.routing()));  }  catch  (Exception  e)  {  }  }  	context.reader().document(doc,  fieldVisitor);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  true);  context:  }  public  void  render  ()  {  Gdx.gl.glClear(GL20.GL_COLOR_BUFFER_BIT);  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  Table.drawDebug(stage);  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
libgdx_8c1eb89354495c8efffe82f0e21ce339c881aa83	buggy:  return  gdxBulletJNI.ContactAddedListenerByObject_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  partId0,  index0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  partId1,  index1,  match1);  context:  swigCMemOwn  =  false;  gdxBulletJNI.ContactAddedListenerByObject_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  gdxBulletJNI.ContactAddedListenerByObject_change_ownership(this,  swigCPtr,  true);  }  public  boolean  onContactAdded(btManifoldPoint  cp,  btCollisionObject  colObj0,  int  partId0,  int  index0,  boolean  match0,  btCollisionObject  colObj1,  int  partId1,  int  index1,  boolean  match1)  {      return  gdxBulletJNI.ContactAddedListenerByObject_onContactAdded(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  partId0,  index0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  partId1,  index1,  match1);      return  gdxBulletJNI.ContactAddedListenerByObject_onContactAdded(swigCPtr,  this,  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  partId0,  index0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  partId1,  index1,  match1);  }  public  ContactAddedListenerByObject()  {  this(gdxBulletJNI.new_ContactAddedListenerByObject(),  true);  gdxBulletJNI.ContactAddedListenerByObject_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	return  gdxBulletJNI.ContactAddedListenerByObject_onContactAdded(swigCPtr,  this,  cp,  btCollisionObject.getCPtr(colObj0),  colObj0,  partId0,  index0,  match0,  btCollisionObject.getCPtr(colObj1),  colObj1,  partId1,  index1,  match1);  
elasticsearch_36edcef640b5213439e35f3da4b35321c85906c0	buggy:  channel.sendResponse(new  StringMessage( "hello   "  +  request.message),  TransportResponseOptions.options().withCompress());  context:  return  new  StringMessage();  }  return  ThreadPool.Names.CACHED;  }  assertThat( "moshe ",  equalTo(request.message));  try  {                      channel.sendResponse(new  StringMessage( "hello   "  +  request.message),  TransportResponseOptions.options().withCompress());                      channel.sendResponse(new  StringMessage( "hello   "  +  request.message),  TransportResponseOptions.options().withCompress(true));  }  catch  (IOException  e)  {  e.printStackTrace();  assertThat(e.getMessage(),  false,  equalTo(true));  }  }  });  TransportFuture<StringMessage>  res  =  serviceB.submitRequest(serviceANode,   "sayHello ",  	channel.sendResponse(new  StringMessage( "hello   "  +  request.message),  TransportResponseOptions.options().withCompress(true));  
elasticsearch_610d9a70a19a546134882c2e30efbcf98a62249a	buggy:  String  protocol  =  componentSettings.get( "protocol ",   "http ").toLowerCase();  context:  networkService.addCustomNameResolver(new  Ec2NameResolver(settings));  discoveryNodeService.addCustomAttributeProvider(new  Ec2CustomNodeAttributes(settings));  }  public  synchronized  AmazonEC2  client()  {  if  (client  !=  null)  {  return  client;  }  ClientConfiguration  clientConfiguration  =  new  ClientConfiguration();          String  protocol  =  componentSettings.get( "protocol ",   "http ").toLowerCase();          String  protocol  =  componentSettings.get( "protocol ",   "https ").toLowerCase();  protocol  =  componentSettings.get( "ec2.protocol ",  protocol).toLowerCase();  if  ( "http ".equals(protocol))  {  clientConfiguration.setProtocol(Protocol.HTTP);  }  else  if  ( "https ".equals(protocol))  {  clientConfiguration.setProtocol(Protocol.HTTPS);  }  else  {  throw  new  ElasticsearchIllegalArgumentException( "No  protocol  supported  [ "  +  protocol  +   "],  can  either  be  [http]  or  [https] ");  }  	String  protocol  =  componentSettings.get( "protocol ",   "https ").toLowerCase();  
elasticsearch_85b7efa08bd0c1429799641898647dd89d155102	buggy:  return  indexQueryParser.parseInnerFilter(parser);  context:  }  private  Filter  parse(String  alias,  CompressedString  filter)  {  if  (filter  ==  null)  {  return  null;  }  try  {  byte[]  filterSource  =  filter.uncompressed();  XContentParser  parser  =  XContentFactory.xContent(filterSource).createParser(filterSource);  try  {                  return  indexQueryParser.parseInnerFilter(parser);                  return  indexQueryParser.parseInnerFilter(parser).filter();  }  finally  {  parser.close();  }  }  catch  (IOException  ex)  {  throw  new  AliasFilterParsingException(index,  alias,   "Invalid  alias  filter ",  ex);  }  }  	return  indexQueryParser.parseInnerFilter(parser).filter();  
elasticsearch_a3c413707941f3913349564585198755bde56e37	buggy:  throw  new  SearchSourceBuilderException( "invalid  CIDR  mask  [ "  +  mask  +   "]  in  ip_range  aggregation  [ "  +  name  +   "] ");  context:  return  this;  }  public  IPv4RangeBuilder  addMaskRange(String  mask)  {  return  addMaskRange(mask,  mask);  }  public  IPv4RangeBuilder  addMaskRange(String  key,  String  mask)  {  long[]  fromTo  =  cidrMaskToMinMax(mask);  if  (fromTo  ==  null)  {              throw  new  SearchSourceBuilderException( "invalid  CIDR  mask  [ "  +  mask  +   "]  in  ip_range  aggregation  [ "  +  name  +   "] ");              throw  new  SearchSourceBuilderException( "invalid  CIDR  mask  [ "  +  mask  +   "]  in  ip_range  aggregation  [ "  +  getName()  +   "] ");  }  ranges.add(new  Range(key,  fromTo[0]  <  0  ?  null  :  fromTo[0],  fromTo[1]  <  0  ?  null  :  fromTo[1]));  return  this;  }  public  IPv4RangeBuilder  addRange(String  from,  String  to)  {  return  addRange(null,  from,  to);  }  	throw  new  SearchSourceBuilderException( "invalid  CIDR  mask  [ "  +  mask  +   "]  in  ip_range  aggregation  [ "  +  getName()  +   "] ");  
elasticsearch_9f57dc1de31c6dd88a2db04b5fa35d847a470087	buggy:  String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)  -  1].name().toLowerCase(Locale.ROOT);  context:  .setSource(jsonBuilder().startObject().field( "p_field ",   "2 ").startArray( "objects ")  .startObject().field( "i_field ",   "1 ").endObject()  .startObject().field( "i_field ",   "2 ").endObject()  .endArray().endObject())  .execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c1 ").setParent( "p1 ").setSource( "c_field ",   "blue ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c2 ").setParent( "p1 ").setSource( "c_field ",   "red ").execute().actionGet();  client().prepareIndex( "test ",   "child ",   "c3 ").setParent( "p2 ").setSource( "c_field ",   "red ").execute().actionGet();  client().admin().indices().prepareRefresh( "test ").execute().actionGet();          String  scoreMode  =  ScoreType.values()[randomInt(ScoreType.values().length)  -  1].name().toLowerCase(Locale.ROOT);          String  scoreMode  =  ScoreType.values()[getRandom().nextInt(ScoreType.values().length)].name().toLowerCase(Locale.ROOT);  SearchResponse  searchResponse  =  client().prepareSearch( "test ")  .setQuery(filteredQuery(QueryBuilders.hasChildQuery( "child ",  termQuery( "c_field ",   "blue ")).scoreType(scoreMode),  notFilter(termFilter( "p_field ",   "3 "))))  .execute().actionGet();  assertNoFailures(searchResponse);  assertThat(searchResponse.getHits().totalHits(),  equalTo(1l));  searchResponse  =  client().prepareSearch( "test ")  .setQuery(filteredQuery(QueryBuilders.hasChildQuery( "child ",  termQuery( "c_field ",   "red ")).scoreType(scoreMode),  notFilter(termFilter( "p_field ",   "3 "))))  	String  scoreMode  =  ScoreType.values()[getRandom().nextInt(ScoreType.values().length)].name().toLowerCase(Locale.ROOT);  
libgdx_d650b1c8f3d6d32b44945de72891895fb7f58361	buggy:  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  context:  package  com.badlogic.gdx.tests.desktop.box2d;  public  class  TestCollection  {  public  static  void  main  (String[]  argv)  {  JoglApplication  app  =  new  JoglApplication( "Simple  Test ",  480,  320,  false);  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.box2d.TestCollection());  app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  }  }  	app.getGraphics().setRenderListener(new  com.badlogic.gdx.tests.Box2DTestCollection());  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());  context:  }  }  }  if  (queryName  !=  null)  {  parseContext.addNamedQuery(queryName,  chosenQuery);  }  return  chosenQuery;  }  protected  boolean  matchesIndices(String  currentIndex,  String...  indices)  {          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(indices,  IndicesOptions.lenientExpandOpen());          final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  for  (String  index  :  concreteIndices)  {  if  (Regex.simpleMatch(index,  currentIndex))  {  return  true;  }  }  return  false;  }  }  	final  String[]  concreteIndices  =  clusterService.state().metaData().concreteIndices(IndicesOptions.lenientExpandOpen(),  indices);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.startObject( "transient ");  for  (Map.Entry<String,  String>  entry  :  response.getState().metaData().transientSettings().getAsMap().entrySet())  {  builder.field(entry.getKey(),  entry.getValue());  }  builder.endObject();  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
libgdx_d4b38f5c8607d373ee35176a2c6cc34cdcba764b	buggy:  action.restart();  context:  static  public  final  int  FOREVER  =  -1;  private  int  repeatCount,  executedCount;  private  boolean  finished;  public  boolean  act  (float  delta)  {  if  (executedCount  ==  repeatCount)  return  true;  if  (action.act(delta))  {  if  (repeatCount  >  0)  executedCount++;  if  (executedCount  ==  repeatCount)  return  true;  action.restart();  if  (action  !=  null)  action.restart();  }  return  false;  }  public  void  finish  ()  {  finished  =  true;  }  	if  (action  !=  null)  action.restart();  
elasticsearch_6ef6bb993c8bdd3190454ba2eac6b1c1193869e7	buggy:  clusterStateRequest.filterAll().filterBlocks(false);  context:  controller.registerHandler(GET,   "/ ",  this);  controller.registerHandler(HEAD,   "/ ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  ClusterStateRequest  clusterStateRequest  =  new  ClusterStateRequest();  clusterStateRequest.listenerThreaded(false);  clusterStateRequest.masterNodeTimeout(TimeValue.timeValueMillis(0));  clusterStateRequest.local(true);          clusterStateRequest.filterAll().filterBlocks(false);          clusterStateRequest.clear().blocks(true);  client.admin().cluster().state(clusterStateRequest,  new  ActionListener<ClusterStateResponse>()  {  public  void  onResponse(ClusterStateResponse  response)  {  RestStatus  status  =  RestStatus.OK;  if  (response.getState().blocks().hasGlobalBlock(RestStatus.SERVICE_UNAVAILABLE))  {  status  =  RestStatus.SERVICE_UNAVAILABLE;  }  if  (request.method()  ==  RestRequest.Method.HEAD)  {  	clusterStateRequest.clear().blocks(true);  
elasticsearch_0697e2f23e4ca3f53417e2a251f13aec9f663cf8	buggy:  .setSettings(settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  nodes.length  -  1))  context:  public  void  concurrentOperationOnSameDocTest()  throws  Exception  {  Node[]  nodes  =  new  Node[5];  for  (int  i  =  0;  i  <  nodes.length;  i++)  {  nodes[i]  =  startNode(Integer.toString(i));  }  nodes[0].client().admin().indices().prepareCreate( "test ")                  .setSettings(settingsBuilder().put( "number_of_shards ",  1).put( "number_of_replicas ",  nodes.length  -  1))                  .setSettings(settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  nodes.length  -  1))  .execute().actionGet();  int  numberOfUpdates  =  100;  final  AtomicReference<Throwable>  failure  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(numberOfUpdates);  for  (int  i  =  0;  i  <  numberOfUpdates;  i++)  {  nodes[0].client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",  i).execute(new  ActionListener<IndexResponse>()  {  	.setSettings(settingsBuilder().put( "index.number_of_shards ",  1).put( "index.number_of_replicas ",  nodes.length  -  1))  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  shardStates  =  new  ObjectLongOpenHashMap<DiscoveryNode>();  context:  }  }  }  return  changed;  }  private  ObjectLongOpenHashMap<DiscoveryNode>  buildShardStates(final  DiscoveryNodes  nodes,  MutableShardRouting  shard)  {  ObjectLongOpenHashMap<DiscoveryNode>  shardStates  =  cachedShardsState.get(shard.shardId());  ObjectOpenHashSet<String>  nodeIds;  if  (shardStates  ==  null)  {              shardStates  =  new  ObjectLongOpenHashMap<DiscoveryNode>();              shardStates  =  new  ObjectLongOpenHashMap<>();  cachedShardsState.put(shard.shardId(),  shardStates);  nodeIds  =  ObjectOpenHashSet.from(nodes.dataNodes().keys());  }  else  {  shardStates.keys().removeAll(new  ObjectPredicate<DiscoveryNode>()  {  public  boolean  apply(DiscoveryNode  node)  {  return  !nodes.nodeExists(node.id());  	shardStates  =  new  ObjectLongOpenHashMap<>();  
elasticsearch_8b19d353c14104f031d203937e9bc1f0183abac1	buggy:  builder.startArray( "sort_values ");  context:  builder.startArray();  for  (String  fragment  :  field.fragments())  {  builder.value(fragment);  }  builder.endArray();  }  }  builder.endObject();  }  if  (sortValues  !=  null  &&  sortValues.length  >  0)  {              builder.startArray( "sort_values ");              builder.startArray( "sort ");  for  (Object  sortValue  :  sortValues)  {  builder.value(sortValue);  }  builder.endArray();  }  if  (explanation()  !=  null)  {  builder.field( "_explanation ");  buildExplanation(builder,  explanation());  	builder.startArray( "sort ");  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  final  int  iters  =  atLeast(5);  context:  }  protected  int  numberOfReplicas()  {  return  -1;  }  public  void  testThatLoadingTemplateFromFileWorks()  throws  Exception  {          final  int  iters  =  atLeast(5);          final  int  iters  =  scaledRandomIntBetween(5,  20);  Set<String>  indices  =  new  HashSet<String>();  for  (int  i  =  0;  i  <  iters;  i++)  {  String  indexName  =   "foo "  +  randomRealisticUnicodeOfLengthBetween(0,  5);  if  (indices.contains(indexName))  {  continue;  }  indices.add(indexName);  createIndex(indexName);  	final  int  iters  =  scaledRandomIntBetween(5,  20);  
libgdx_893466e120e16638847491ebf92efffa03ff2b70	buggy:  draw(region,  x,  y,  region.getRegionWidth(),  region.getRegionHeight());  context:  }  else  if  (idx  +  length  >=  vertices.length)  renderMesh();  System.arraycopy(spriteVertices,  offset,  vertices,  idx,  length);  idx  +=  length;  }  public  void  draw  (TextureRegion  region,  float  x,  float  y)  {  draw(region,  x,  y,  region.getRegionWidth(),  region.getRegionHeight());  draw(region,  x,  y,  Math.abs(region.getRegionWidth()),  Math.abs(region.getRegionHeight()));  }  public  void  draw  (TextureRegion  region,  float  x,  float  y,  float  width,  float  height)  {  if  (!drawing)  throw  new  IllegalStateException( "SpriteBatch.begin  must  be  called  before  draw. ");  	draw(region,  x,  y,  Math.abs(region.getRegionWidth()),  Math.abs(region.getRegionHeight()));  
elasticsearch_a6bd64f30db2f1a5a4c1c64a98de35f6fb72019c	buggy:  sendExecuteFirstPhase(node,  internalSearchRequest(shard,  request),  new  SearchServiceListener<FirstResult>()  {  context:  private  void  performFirstPhase(final  ShardsIterator  shardIt)  {  final  ShardRouting  shard  =  shardIt.nextActiveOrNull();  if  (shard  ==  null)  {  onFirstPhaseResult(shard,  shardIt,  null);  }  else  {  DiscoveryNode  node  =  nodes.get(shard.currentNodeId());  if  (node  ==  null)  {  onFirstPhaseResult(shard,  shardIt,  null);  }  else  {                      sendExecuteFirstPhase(node,  internalSearchRequest(shard,  request),  new  SearchServiceListener<FirstResult>()  {                      sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request),  new  SearchServiceListener<FirstResult>()  {  onFirstPhaseResult(shard,  result,  shardIt);  }  onFirstPhaseResult(shard,  shardIt,  t);  }  });  	sendExecuteFirstPhase(node,  internalSearchRequest(shard,  shardsIts.size(),  request),  new  SearchServiceListener<FirstResult>()  {  
elasticsearch_ab6715b2923d6fcd141add1b04b5227622f751c1	buggy:  indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE).source( "refresh_flag_mget "));  context:  }  protected  MultiGetShardResponse  shardOperation(MultiGetShardRequest  request,  int  shardId)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(shardId);  if  (request.refresh()  &&  !request.realtime())  {              indexShard.refresh(new  Engine.Refresh().force(TransportGetAction.REFRESH_FORCE).source( "refresh_flag_mget "));              indexShard.refresh(new  Engine.Refresh( "refresh_flag_mget ").force(TransportGetAction.REFRESH_FORCE));  }  MultiGetShardResponse  response  =  new  MultiGetShardResponse();  for  (int  i  =  0;  i  <  request.locations.size();  i++)  {  String  type  =  request.types.get(i);  String  id  =  request.ids.get(i);  String[]  fields  =  request.fields.get(i);  	indexShard.refresh(new  Engine.Refresh( "refresh_flag_mget ").force(TransportGetAction.REFRESH_FORCE));  
libgdx_c6111e81b06b7afe849c52447b86ed734342f1c5	buggy:  Gdx.app.log( "Test ",   "Thread= "  +  Thread.currentThread().getId()  +   ",  app  resized ");  context:  e.printStackTrace();  }  }  Gdx.app.log( "Test ",   "Thread= "  +  Thread.currentThread().getId()  +   ",  app  created:   "  +  Gdx.graphics.getWidth()  +   "x "  Gdx.graphics.getHeight());  }  Gdx.app.log( "Test ",   "Thread= "  +  Thread.currentThread().getId()  +   ",  app  resized ");  Gdx.app.log( "Test ",   "Thread= "  +  Thread.currentThread().getId()  +   ",  app  resized:   "  +  width  +   "x "  +  height  +   ",  Graphics  says:   "+  Gdx.graphics.getWidth()  +   "x "  +  Gdx.graphics.getHeight());  }  return  false;  }  }  	Gdx.app.log( "Test ",   "Thread= "  +  Thread.currentThread().getId()  +   ",  app  resized:   "  +  width  +   "x "  +  height  +   ",  Graphics  says:   "+  Gdx.graphics.getWidth()  +   "x "  +  Gdx.graphics.getHeight());  
elasticsearch_b3e0e58094d02cdc9f98d63fa56cabe7b12f2966	buggy:  data  =  FSTBytesAtomicFieldData.empty(reader.maxDoc());  context:  public  FSTBytesAtomicFieldData  loadDirect(AtomicReaderContext  context)  throws  Exception  {  AtomicReader  reader  =  context.reader();  Terms  terms  =  reader.terms(getFieldNames().indexName());  FSTBytesAtomicFieldData  data  =  null;  NonEstimatingEstimator  estimator  =  new  NonEstimatingEstimator(breakerService.getBreaker());  if  (terms  ==  null)  {              data  =  FSTBytesAtomicFieldData.empty(reader.maxDoc());              data  =  FSTBytesAtomicFieldData.empty();  estimator.afterLoad(null,  data.getMemorySizeInBytes());  return  data;  }  PositiveIntOutputs  outputs  =  PositiveIntOutputs.getSingleton();  org.apache.lucene.util.fst.Builder<Long>  fstBuilder  =  new  org.apache.lucene.util.fst.Builder<>(INPUT_TYPE.BYTE1,  outputs);  final  IntsRef  scratch  =  new  IntsRef();  final  long  numTerms;  	data  =  FSTBytesAtomicFieldData.empty();  
libgdx_6956f9776d189ef182f0fc25853c44304cf5fb78	buggy:  if  (button  instanceof  TextButton  &&  text.equals(((TextButton)button).getText()))  {  context:  if  (buttons  ==  null)  throw  new  IllegalArgumentException( "buttons  cannot  be  null. ");  for  (int  i  =  0,  n  =  buttons.length;  i  <  n;  i++)  remove(buttons[i]);  }  public  void  setChecked  (String  text)  {  if  (text  ==  null)  throw  new  IllegalArgumentException( "text  cannot  be  null. ");  for  (int  i  =  0,  n  =  buttons.size;  i  <  n;  i++)  {  Button  button  =  buttons.get(i);  if  (button  instanceof  TextButton  &&  text.equals(((TextButton)button).getText()))  {  if  (button  instanceof  TextButton  &&  text.contentEquals(((TextButton)button).getText()))  {  button.setChecked(true);  return;  }  }  }  	if  (button  instanceof  TextButton  &&  text.contentEquals(((TextButton)button).getText()))  {  
elasticsearch_2288c5d6702a0bbb395de843e78d91a3197e115f	buggy:  highlightBuilder().preTags(postTags);  context:  public  SearchRequestBuilder  setHighlighterPreTags(String...  preTags)  {  highlightBuilder().preTags(preTags);  return  this;  }  public  SearchRequestBuilder  setHighlighterPostTags(String...  postTags)  {          highlightBuilder().preTags(postTags);          highlightBuilder().postTags(postTags);  return  this;  }  	highlightBuilder().postTags(postTags);  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(max( "max ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  notNullValue());  Max  max  =  bucket.getAggregations().get( "max ");  assertThat(max,  notNullValue());  assertThat(max.getName(),  equalTo( "max "));  assertThat(max.getValue(),  equalTo(Double.NEGATIVE_INFINITY));  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_fd574880fcf7cd7a14e25087029a47a7ae3aca1b	buggy:  MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.filterCache());  context:  }  if  (analyzer  ==  null)  {  analyzer  =  parseContext.mapperService().searchAnalyzer();  }  if  (queryString  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }          MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.filterCache());          MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.indexCache());  queryParser.setEnablePositionIncrements(enablePositionIncrements);  queryParser.setLowercaseExpandedTerms(lowercaseExpandedTerms);  queryParser.setPhraseSlop(phraseSlop);  queryParser.setDefaultOperator(defaultOperator);  queryParser.setFuzzyMinSim(fuzzyMinSim);  queryParser.setFuzzyPrefixLength(fuzzyPrefixLength);  if  (escape)  {  	MapperQueryParser  queryParser  =  new  MapperQueryParser(fieldName,  analyzer,  parseContext.mapperService(),  parseContext.indexCache());  
libgdx_240a1abed481b80d28da269ac544e2b33fd36ee9	buggy:  return  PurchaseManagerConfig.STORE_NAME_OUYA;  context:  this(activity,  1001);  //  NOTE:  requestCode  here  is  an  arbitrarily  chosen  number!  }  public  PurchaseManagerAndroidOUYA  (Activity  activity,  int  requestCode)  {  this.activity  =  activity;  this.requestCode  =  requestCode;//  TODO:  the  request  code  for  onActivityResult,  not  needed  for  OUYA!  }  public  String  storeName()  {  return  PurchaseManagerConfig.STORE_NAME_OUYA;  return  PurchaseManagerConfig.STORE_NAME_ANDROID_OUYA;  }  public  void  install  (final  PurchaseObserver  observer,  PurchaseManagerConfig  config)  {  this.observer  =  observer;  this.config  =  config;  ouyaFacade  =  OuyaFacade.getInstance();  	return  PurchaseManagerConfig.STORE_NAME_ANDROID_OUYA;  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  smartNameFieldMappers.mapper().indexName();  context:  String  value  =  jp.getText();  jp.nextToken();  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  prefix  query ");  }  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  fieldName  =  smartNameFieldMappers.mapper().indexName();                  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  Filter  prefixFilter  =  new  PrefixFilter(new  Term(fieldName,  value));  prefixFilter  =  parseContext.cacheFilterIfPossible(prefixFilter);  return  wrapSmartNameFilter(prefixFilter,  smartNameFieldMappers,  parseContext.filterCache());  }  	fieldName  =  smartNameFieldMappers.mapper().names().indexName();  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  return  MetaData.Builder.fromXContent(parser,  settings);  context:  }  }  return  index;  }  private  MetaData  readMetaData(byte[]  data)  throws  IOException  {  XContentParser  parser  =  null;  try  {  parser  =  XContentFactory.xContent(XContentType.JSON).createParser(data);              return  MetaData.Builder.fromXContent(parser,  settings);              return  MetaData.Builder.fromXContent(parser);  }  finally  {  if  (parser  !=  null)  {  parser.close();  }  }  }  }  	return  MetaData.Builder.fromXContent(parser);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  if  (percolate.matches().size()  !=  QUERIES)  {  context:  .setRefresh(true)  .execute().actionGet();  }  StopWatch  stopWatch  =  new  StopWatch().start();  int  i  =  1;  for  (;  i  <=  COUNT;  i++)  {  PercolateResponse  percolate  =  client1.preparePercolate( "test ",   "type1 ").setSource(source(Integer.toString(i),   "value "))  .execute().actionGet();              if  (percolate.matches().size()  !=  QUERIES)  {              if  (percolate.getMatches().size()  !=  QUERIES)  {  System.err.println( "No  matching  number  of  queries ");  }  if  ((i  %  10000)  ==  0)  {  stopWatch.start();  }  }  	if  (percolate.getMatches().size()  !=  QUERIES)  {  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.execSearch(searchRequest,  new  ActionListener<SearchResponse>()  {  context:  searchRequest.operationThreading(operationThreading);  }  catch  (Exception  e)  {  try  {  JsonBuilder  builder  =  restJsonBuilder(request);  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  builder.startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }          client.execSearch(searchRequest,  new  ActionListener<SearchResponse>()  {          client.search(searchRequest,  new  ActionListener<SearchResponse>()  {  try  {  JsonBuilder  builder  =  restJsonBuilder(request);  builder.startObject();  response.toJson(builder,  request);  builder.endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  }  catch  (Exception  e)  {  	client.search(searchRequest,  new  ActionListener<SearchResponse>()  {  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  assertAcked(prepareCreate( "test ").setSettings(randomSettingsBuilder().put( "number_of_shards ",  numShards).put( "number_of_replicas ",  numReplicas).build()));  context:  public  void  recoverWhileRelocating()  throws  Exception  {  final  int  numShards  =  between(2,  10);  final  int  numReplicas  =  0;  cluster().ensureAtLeastNumNodes(3);  int  allowNodes  =  2;          assertAcked(prepareCreate( "test ").setSettings(randomSettingsBuilder().put( "number_of_shards ",  numShards).put( "number_of_replicas ",  numReplicas).build()));          assertAcked(prepareCreate( "test ").setSettings(ImmutableSettings.builder().put( "number_of_shards ",  numShards).put( "number_of_replicas ",  numReplicas).build()));  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  AtomicLong  indexCounter  =  new  AtomicLong();  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);  Thread[]  writers  =  new  Thread[atLeast(3)];  final  CountDownLatch  stopLatch  =  new  CountDownLatch(writers.length);  final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<Throwable>();  for  (int  i  =  0;  i  <  writers.length;  i++)  {  	assertAcked(prepareCreate( "test ").setSettings(ImmutableSettings.builder().put( "number_of_shards ",  numShards).put( "number_of_replicas ",  numReplicas).build()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ArrayList<String>  fieldsOrder  =  new  ArrayList<String>();  context:  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  Document  document  =  new  Document();  document.add(new  TextField( "_id ",   "1 ",  Field.Store.YES));  document.add(new  TextField( "#id ",   "1 ",  Field.Store.YES));  indexWriter.addDocument(document);  IndexReader  reader  =  DirectoryReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  TopDocs  topDocs  =  searcher.search(new  TermQuery(new  Term( "_id ",   "1 ")),  1);          final  ArrayList<String>  fieldsOrder  =  new  ArrayList<String>();          final  ArrayList<String>  fieldsOrder  =  new  ArrayList<>();  searcher.doc(topDocs.scoreDocs[0].doc,  new  StoredFieldVisitor()  {  public  Status  needsField(FieldInfo  fieldInfo)  throws  IOException  {  fieldsOrder.add(fieldInfo.name);  return  Status.YES;  }  });  	final  ArrayList<String>  fieldsOrder  =  new  ArrayList<>();  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  return  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false);  context:  public  class  FsChannelSimpleTranslogTests  extends  AbstractSimpleTranslogTests  {          return  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false);          return  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "));  }  FileSystemUtils.deleteRecursively(new  File( "work/fs-translog "),  true);  }  }  	return  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "));  
elasticsearch_ad0d681b6d5273c0f448fe3490ca01dd028d13a1	buggy:  Engine  engine  =  new  RobinEngine(shardId,  settings,  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  context:  Settings  settings  =  EMPTY_SETTINGS;  Store  store  =  new  ByteBufferStore(shardId,  settings,  null,  new  ByteBufferCache(settings));  store.deleteContent();  ThreadPool  threadPool  =  new  ThreadPool();  SnapshotDeletionPolicy  deletionPolicy  =  new  SnapshotDeletionPolicy(new  KeepOnlyLastDeletionPolicy(shardId,  settings));          Engine  engine  =  new  RobinEngine(shardId,  settings,  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),          Engine  engine  =  new  RobinEngine(shardId,  settings,  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  new  ConcurrentMergeSchedulerProvider(shardId,  settings),  new  AnalysisService(shardId.index()),  new  SimilarityService(shardId.index()),  new  NonBloomCache(shardId.index()));  engine.start();  SimpleEngineBenchmark  benchmark  =  new  SimpleEngineBenchmark(store,  engine)  .numberOfContentItems(1000)  .searcherThreads(50).searcherIterations(10000)  .writerThreads(10).writerIterations(10000)  .refreshSchedule(new  TimeValue(1,  TimeUnit.SECONDS))  	Engine  engine  =  new  RobinEngine(shardId,  settings,  new  IndexSettingsService(shardId.index(),  settings),  store,  deletionPolicy,  new  FsTranslog(shardId,  EMPTY_SETTINGS,  new  File( "work/fs-translog "),  false),  new  LogByteSizeMergePolicyProvider(store,  new  IndexSettingsService(shardId.index(),  EMPTY_SETTINGS)),  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(entry.source(),  true);  context:  public  void  writeTo(IndexWarmersMetaData  warmers,  StreamOutput  out)  throws  IOException  {  out.writeVInt(warmers.entries().size());  for  (Entry  entry  :  warmers.entries())  {  out.writeUTF(entry.name());  out.writeStringArray(entry.types());  if  (entry.source()  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);                      out.writeBytesReference(entry.source(),  true);                      out.writeBytesReference(entry.source());  }  }  }  public  IndexWarmersMetaData  fromMap(Map<String,  Object>  map)  throws  IOException  {  if  (map.size()  ==  1  &&  map.containsKey(TYPE))  {  	out.writeBytesReference(entry.source());  
elasticsearch_3e264f6b95c6356c43adc2ec2053a612ffbfce80	buggy:  public  void  close(boolean  delete)  throws  ElasticSearchException  {  context:  this.mergeFactor  =  componentSettings.getAsInt( "merge_factor ",  LogDocMergePolicy.DEFAULT_MERGE_FACTOR);  this.calibrateSizeByDeletes  =  componentSettings.getAsBoolean( "calibrate_size_by_deletes ",  true);  this.asyncMerge  =  indexSettings.getAsBoolean( "index.merge.async ",  true);  mergeFactor,  minMergeDocs,  maxMergeDocs,  calibrateSizeByDeletes,  asyncMerge);  indexSettingsService.addListener(applySettings);  }      public  void  close(boolean  delete)  throws  ElasticSearchException  {      public  void  close()  throws  ElasticSearchException  {  indexSettingsService.removeListener(applySettings);  }  public  LogDocMergePolicy  newMergePolicy()  {  CustomLogDocMergePolicy  mergePolicy;  if  (asyncMerge)  {  mergePolicy  =  new  EnableMergeLogDocMergePolicy(this);  	public  void  close()  throws  ElasticSearchException  {  
elasticsearch_e2cb7edb08b9bb2367117de9b60e5ef2fc4ce3f6	buggy:  assert  currentState  ==  stage;  context:  queryCollectors  =  new  ArrayList<Collector>();  }  queryCollectors.add(collector);  }  public  void  inStage(Stage  stage)  {  this.currentState  =  stage;  }  public  void  finishStage(Stage  stage)  {          assert  currentState  ==  stage;          assert  currentState  ==  stage  :   "Expected  stage   "  +  stage  +   "  but  was  stage   "  +  currentState;  this.currentState  =  Stage.NA;  }  public  Query  rewrite(Query  original)  throws  IOException  {  if  (original  ==  searchContext.query()  ||  original  ==  searchContext.parsedQuery().query())  {  if  (searchContext.queryRewritten())  {  	assert  currentState  ==  stage  :   "Expected  stage   "  +  stage  +   "  but  was  stage   "  +  currentState;  
elasticsearch_05b6c46becc8c26c06b84caebffe5902941b60d0	buggy:  ClearIndicesCacheResponse  clearIndicesCacheResponse  =  client1.admin().indices().clearCache(clearIndicesCacheRequest( "test ")).actionGet();  context:  IndicesExistsResponse  indicesExistsResponse  =  client1.admin().indices().prepareExists(getConcreteIndexName()).execute().actionGet();  assertThat(indicesExistsResponse.isExists(),  equalTo(true));  indicesExistsResponse  =  client1.admin().indices().prepareExists( "test1234565 ").execute().actionGet();  assertThat(indicesExistsResponse.isExists(),  equalTo(false));          ClearIndicesCacheResponse  clearIndicesCacheResponse  =  client1.admin().indices().clearCache(clearIndicesCacheRequest( "test ")).actionGet();          ClearIndicesCacheResponse  clearIndicesCacheResponse  =  client1.admin().indices().clearCache(clearIndicesCacheRequest( "test ").recycler(true).fieldDataCache(true).filterCache(true).idCache(true)).actionGet();  assertThat(clearIndicesCacheResponse.getSuccessfulShards(),  equalTo(10));  assertThat(clearIndicesCacheResponse.getFailedShards(),  equalTo(0));  OptimizeResponse  optimizeResponse  =  client1.admin().indices().prepareOptimize( "test ").execute().actionGet();  assertThat(optimizeResponse.getSuccessfulShards(),  equalTo(10));  assertThat(optimizeResponse.getFailedShards(),  equalTo(0));  	ClearIndicesCacheResponse  clearIndicesCacheResponse  =  client1.admin().indices().clearCache(clearIndicesCacheRequest( "test ").recycler(true).fieldDataCache(true).filterCache(true).idCache(true)).actionGet();  
libgdx_ee8abe88c4b2b706551b37579bc749dc5bd6cc32	buggy:  TextureRegion  tileRegion  =  new  TextureRegion(new  TextureRegion(texture,  x,  y,  tilewidth,  tileheight));  context:  TiledMapTileSet  tileset  =  new  TiledMapTileSet();  tileset.setName(name);  int  stopWidth  =  texture.getRegionWidth()  -  tilewidth;  int  stopHeight  =  texture.getRegionHeight()  -  tileheight;  int  id  =  firstgid;  for  (int  y  =  margin;  y  <=  stopHeight;  y  +=  tileheight  +  spacing)  {  for  (int  x  =  margin;  x  <=  stopWidth;  x  +=  tilewidth  +  spacing)  {  TextureRegion  tileRegion  =  new  TextureRegion(new  TextureRegion(texture,  x,  y,  tilewidth,  tileheight));  TextureRegion  tileRegion  =  new  TextureRegion(texture,  x,  y,  tilewidth,  tileheight);  if  (!yUp)  {  tileRegion.flip(false,  true);  }  TiledMapTile  tile  =  new  StaticTiledMapTile(tileRegion);  tile.setId(id);  tileset.putTile(id++,  tile);  }  }  	TextureRegion  tileRegion  =  new  TextureRegion(texture,  x,  y,  tilewidth,  tileheight);  
elasticsearch_2b9bdc37961022c0f254f86fac083f5d2fdeca12	buggy:  entry  =  new  InternalBoundedFullHistogramFacet.FullEntry(index,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);  context:  this.entries  =  CacheRecycler.popObjectArray(size);  }  if  (value  <=  from  ||  value  >  to)  {  //  bounds  check  return;  }  int  index  =  ((int)  ((value  +  offset)  /  interval));  InternalBoundedFullHistogramFacet.FullEntry  entry  =  (InternalBoundedFullHistogramFacet.FullEntry)  entries[index];  if  (entry  ==  null)  {                  entry  =  new  InternalBoundedFullHistogramFacet.FullEntry(index,  0,  Double.MAX_VALUE,  Double.MIN_VALUE,  0,  0);                  entry  =  new  InternalBoundedFullHistogramFacet.FullEntry(index,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  entries[index]  =  entry;  }  entry.count++;  valueAggregator.entry  =  entry;  valueFieldData.forEachValueInDoc(docId,  valueAggregator);  }  	entry  =  new  InternalBoundedFullHistogramFacet.FullEntry(index,  0,  Double.POSITIVE_INFINITY,  Double.NEGATIVE_INFINITY,  0,  0);  
elasticsearch_21405f5aa49e77c345c187f3a4ec86e7f7dcd23f	buggy:  System.out.println(fragment);  context:  IndexReader  reader  =  IndexReader.open(indexWriter,  true);  IndexSearcher  searcher  =  new  IndexSearcher(reader);  TopDocs  topDocs  =  searcher.search(new  TermQuery(new  Term( "_id ",   "1 ")),  1);  assertThat(topDocs.totalHits,  equalTo(1));  FastVectorHighlighter  highlighter  =  new  FastVectorHighlighter();  String  fragment  =  highlighter.getBestFragment(highlighter.getFieldQuery(new  TermQuery(new  Term( "content ",   "bad "))),  reader,  topDocs.scoreDocs[0].doc,   "content ",  30);  assertThat(fragment,  notNullValue());          System.out.println(fragment);          assertThat(fragment,  equalTo( "e  big  <b>bad</b>  dog   "));  }  public  void  testVectorHighlighterPrefixQuery()  throws  Exception  {  Directory  dir  =  new  RAMDirectory();  IndexWriter  indexWriter  =  new  IndexWriter(dir,  new  IndexWriterConfig(Lucene.VERSION,  Lucene.STANDARD_ANALYZER));  indexWriter.addDocument(doc().add(field( "_id ",   "1 ")).add(field( "content ",   "the  big  bad  dog ",  Field.Store.YES,  Field.Index.ANALYZED,  Field.TermVector.WITH_POSITIONS_OFFSETS)).build());  	assertThat(fragment,  equalTo( "e  big  <b>bad</b>  dog   "));  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardFlushRequest(shard.index(),  shard.id(),  request);  context:  return  new  FlushResponse(shardsResponses.length(),  successfulShards,  failedShards,  shardFailures);  }  protected  ShardFlushRequest  newShardRequest()  {  return  new  ShardFlushRequest();  }  protected  ShardFlushRequest  newShardRequest(int  numShards,  ShardRouting  shard,  FlushRequest  request)  {          return  new  ShardFlushRequest(shard.index(),  shard.id(),  request);          return  new  ShardFlushRequest(shard.shardId(),  request);  }  protected  ShardFlushResponse  newShardResponse()  {  return  new  ShardFlushResponse();  }  	return  new  ShardFlushRequest(shard.shardId(),  request);  
elasticsearch_efe85f322a073313d35f7261bfbe04baa3235de1	buggy:  lookup  =  new  SearchLookup(mapperService(),  indexCache().fieldData());  context:  }  private  SearchLookup  lookup  =  null;  public  SearchLookup  lookup()  {  SearchContext  current  =  SearchContext.current();  if  (current  !=  null)  {  return  current.lookup();  }  if  (lookup  ==  null)  {              lookup  =  new  SearchLookup(mapperService(),  indexCache().fieldData());              lookup  =  new  SearchLookup(mapperService(),  indexCache().fieldData(),  null);  }  return  lookup;  }  public  long  nowInMillis()  {  SearchContext  current  =  SearchContext.current();  if  (current  !=  null)  {  return  current.nowInMillis();  	lookup  =  new  SearchLookup(mapperService(),  indexCache().fieldData(),  null);  
elasticsearch_051beb51a3847c457324ecc07db708538e34d15c	buggy:  assert  request.versionType().validateVersion(request.version());  context:  indexShard.refresh(new  Engine.Refresh( "refresh_flag_index ").force(false));  }  catch  (Throwable  e)  {  }  }  request.version(version);  request.versionType(request.versionType().versionTypeForReplicationAndRecovery());          assert  request.versionType().validateVersion(request.version());          assert  request.versionType().validateVersionForWrites(request.version());  IndexResponse  response  =  new  IndexResponse(request.index(),  request.type(),  request.id(),  version,  created);  return  new  PrimaryResponse<>(shardRequest.request,  response,  op);  }  protected  void  shardOperationOnReplica(ReplicaOperationRequest  shardRequest)  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(shardRequest.request.index()).shardSafe(shardRequest.shardId);  	assert  request.versionType().validateVersionForWrites(request.version());  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataStateIndexService  stateIndexService;  ThreadPool  threadPool,  MetaDataStateIndexService  stateIndexService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.stateIndexService  =  stateIndexService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.CLOSE;  }  return  new  CloseIndexRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_1257109944e0e44a61c5319835ce73425a3c24e3	buggy:  builder.put( "index.number_of_shards ",  between(1,5)).put( "index.number_of_replicas ",  between(0,3));  context:  assertThat(suggest,  notNullValue());  assertThat(suggest.size(),  equalTo(1));  assertThat(suggest.getSuggestion( "simple ").getName(),  equalTo( "simple "));  assertThat(suggest.getSuggestion( "simple ").getEntries().size(),  equalTo(1));  assertThat(suggest.getSuggestion( "simple ").getEntries().get(0).getOptions().size(),  equalTo(3));  }  public  void  testShardFailures()  throws  IOException,  InterruptedException  {  Builder  builder  =  ImmutableSettings.builder();          builder.put( "index.number_of_shards ",  between(1,5)).put( "index.number_of_replicas ",  between(0,3));          builder.put( "index.number_of_shards ",  between(1,  5)).put( "index.number_of_replicas ",  between(0,  2));  builder.put( "index.analysis.analyzer.suggest.tokenizer ",   "standard ");  builder.putArray( "index.analysis.analyzer.suggest.filter ",   "standard ",   "lowercase ",   "shingler ");  builder.put( "index.analysis.filter.shingler.type ",   "shingle ");  builder.put( "index.analysis.filter.shingler.min_shingle_size ",  2);  builder.put( "index.analysis.filter.shingler.max_shingle_size ",  5);  builder.put( "index.analysis.filter.shingler.output_unigrams ",  true);  XContentBuilder  mapping  =  XContentFactory.jsonBuilder().startObject().startObject( "type1 ")  	builder.put( "index.number_of_shards ",  between(1,  5)).put( "index.number_of_replicas ",  between(0,  2));  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false));  context:  return  new  OpenIndexRequest();  }  protected  OpenIndexResponse  newResponse()  {  return  new  OpenIndexResponse();  }  protected  void  doExecute(OpenIndexRequest  request,  ActionListener<OpenIndexResponse>  listener)  {          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  false));          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(OpenIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  	request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  routing  =  new  HashSet<String>(routingSize);  context:  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  super.readFrom(in);  source  =  in.readBytesReference();  shardId  =  in.readVInt();  types  =  in.readStringArray();  int  routingSize  =  in.readVInt();  if  (routingSize  >  0)  {              routing  =  new  HashSet<String>(routingSize);              routing  =  new  HashSet<>(routingSize);  for  (int  i  =  0;  i  <  routingSize;  i++)  {  routing.add(in.readString());  }  }  int  aliasesSize  =  in.readVInt();  if  (aliasesSize  >  0)  {  filteringAliases  =  new  String[aliasesSize];  for  (int  i  =  0;  i  <  aliasesSize;  i++)  {  	routing  =  new  HashSet<>(routingSize);  
elasticsearch_b55ad98d73b0d89763295e508710f28d240279a2	buggy:  conf.setMergePolicy(randomBoolean()  ?  NoMergePolicy.COMPOUND_FILES  :  NoMergePolicy.NO_COMPOUND_FILES);  context:  public  void  setUp()  throws  Exception  {  super.setUp();  referenceAll  =  Maps.newHashMap();  referenceNotDeleted  =  Maps.newHashMap();  referenceFilter  =  Maps.newHashMap();  Directory  dir  =  newDirectory();  IndexWriterConfig  conf  =  newIndexWriterConfig(TEST_VERSION_CURRENT,  new  MockAnalyzer(random()));  if  (frequently())  {              conf.setMergePolicy(randomBoolean()  ?  NoMergePolicy.COMPOUND_FILES  :  NoMergePolicy.NO_COMPOUND_FILES);              conf.setMergePolicy(NoMergePolicy.INSTANCE);  }  iw  =  new  IndexWriter(dir,  conf);  terms  =  new  String[scaledRandomIntBetween(10,  300)];  for  (int  i  =  0;  i  <  terms.length;  i++)  {  terms[i]  =  randomAsciiOfLength(5);  }  int  numberOfDocs  =  scaledRandomIntBetween(30,  300);  	conf.setMergePolicy(NoMergePolicy.INSTANCE);  
elasticsearch_76b32a646c644c3eaf41758f91887cab58c22d08	buggy:  String  initialShards  =  indexMetaData.settings().get( "index.recovery.initial_shards ",  this.initialShards);  context:  nodesWithHighestVersion.add(node);  }  }  }  }  int  requiredAllocation  =  1;  try  {  IndexMetaData  indexMetaData  =  routingNodes.metaData().index(shard.index());                  String  initialShards  =  indexMetaData.settings().get( "index.recovery.initial_shards ",  this.initialShards);                  String  initialShards  =  indexMetaData.settings().get( "index.recovery.initial_shards ",  settings.get( "index.recovery.initial_shards ",  this.initialShards));  if  ( "quorum ".equals(initialShards))  {  if  (indexMetaData.numberOfReplicas()  >  1)  {  requiredAllocation  =  ((1  +  indexMetaData.numberOfReplicas())  /  2)  +  1;  }  }  else  if  ( "quorum-1 ".equals(initialShards)  ||   "half ".equals(initialShards))  {  if  (indexMetaData.numberOfReplicas()  >  2)  {  requiredAllocation  =  ((1  +  indexMetaData.numberOfReplicas())  /  2);  }  	String  initialShards  =  indexMetaData.settings().get( "index.recovery.initial_shards ",  settings.get( "index.recovery.initial_shards ",  this.initialShards));  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  timeUnit,  parseUpperInclusive,  ignoreMalformed);  context:  }  public  DateFieldMapper  build(BuilderContext  context)  {  boolean  parseUpperInclusive  =  Defaults.PARSE_UPPER_INCLUSIVE;  if  (context.indexSettings()  !=  null)  {  parseUpperInclusive  =  context.indexSettings().getAsBoolean( "index.mapping.date.parse_upper_inclusive ",  Defaults.PARSE_UPPER_INCLUSIVE);  }  DateFieldMapper  fieldMapper  =  new  DateFieldMapper(buildNames(context),  dateTimeFormatter,  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,                      timeUnit,  parseUpperInclusive,  ignoreMalformed);                      timeUnit,  parseUpperInclusive,  ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	timeUnit,  parseUpperInclusive,  ignoreMalformed(context));  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  immutableCluster().wipeIndices( "idx ");  context:  assertThat(filter.getDocCount(),  equalTo(count));  }  }  public  void  testDuelTerms()  throws  Exception  {  final  int  numDocs  =  scaledRandomIntBetween(1000,  2000);  final  int  maxNumTerms  =  randomIntBetween(10,  5000);  final  IntOpenHashSet  valuesSet  =  new  IntOpenHashSet();          immutableCluster().wipeIndices( "idx ");          cluster().wipeIndices( "idx ");  prepareCreate( "idx ")  .setSettings(ImmutableSettings.builder().put(InternalGlobalOrdinalsBuilder.ORDINAL_MAPPING_THRESHOLD_INDEX_SETTING_KEY,  randomIntBetween(1,  maxNumTerms)))  .addMapping( "type ",  jsonBuilder().startObject()  .startObject( "type ")  .startObject( "properties ")  .startObject( "string_values ")  .field( "type ",   "string ")  .field( "index ",   "not_analyzed ")  	cluster().wipeIndices( "idx ");  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  Engine.Searcher  searcher  =  shard.searcher();  context:  }  private  boolean  hasPercolatorType(IndexShard  indexShard)  {  ShardId  otherShardId  =  indexShard.shardId();  return  shardId.equals(otherShardId)  &&  mapperService.hasMapping(PercolatorService.Constants.TYPE_NAME);  }  private  void  loadQueries(IndexShard  shard)  {  try  {  shard.refresh(new  Engine.Refresh().force(true));                  Engine.Searcher  searcher  =  shard.searcher();                  Engine.Searcher  searcher  =  shard.acquireSearcher();  try  {  Query  query  =  new  XConstantScoreQuery(  indexCache.filter().cache(  new  TermFilter(new  Term(TypeFieldMapper.NAME,  PercolatorService.Constants.TYPE_NAME))  )  );  QueriesLoaderCollector  queries  =  new  QueriesLoaderCollector(PercolatorQueriesRegistry.this,  logger,  indexFieldDataService);  searcher.searcher().search(query,  queries);  	Engine.Searcher  searcher  =  shard.acquireSearcher();  
libgdx_a81506b17bf8f5c48988b2413438594b72e07223	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.KinematicBodyTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.KinematicBodyTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.MatrixJNITest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.MatrixJNITest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_720e6a6d5b2e952265551438919af2c944dc6e19	buggy:  logger.warn( "Failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  context:  public  void  publish(ClusterState  clusterState)  {  DiscoveryNode  localNode  =  nodesProvider.nodes().localNode();  for  (final  DiscoveryNode  node  :  clusterState.nodes())  {  if  (node.equals(localNode))  {  continue;  }  transportService.sendRequest(node,  PublishClusterStateRequestHandler.ACTION,  new  PublishClusterStateRequest(clusterState),  new  VoidTransportResponseHandler(false)  {                      logger.warn( "Failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);                      logger.warn( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  }  });  }  }  private  class  PublishClusterStateRequest  implements  Streamable  {  private  ClusterState  clusterState;  	logger.warn( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  
elasticsearch_fdd5e53aa779cb9f7d3e765583f23ce04cac709d	buggy:  }  catch  (Exception  e)  {  context:  if  (counter.decrementAndGet()  ==  0)  {  finishHim();  }  }  });  }  private  void  finishHim()  {  try  {  innerFinishHim();              }  catch  (Exception  e)  {              }  catch  (Throwable  e)  {  ReduceSearchPhaseException  failure  =  new  ReduceSearchPhaseException( "fetch ",   " ",  e,  buildShardFailures());  if  (logger.isDebugEnabled())  {  }  listener.onFailure(failure);  }  }  	}  catch  (Throwable  e)  {  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/sell_buy_item.wav ",  FileType.Internal));  context:  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  font.draw(batch,   "Position:   "  +  music.getPosition(),  30,  146);  batch.end();  }  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/sell_buy_item.wav ",  FileType.Internal));  sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/test2_notwork.wav ",  FileType.Internal));  music  =  Gdx.audio.newMusic(Gdx.files.getFileHandle( "data/threeofaperfectpair.mp3 ",  FileType.Internal));  music.setVolume(volume);  music.play();  music.setLooping(true);  Gdx.input.setInputProcessor(this);  	sound  =  Gdx.audio.newSound(Gdx.files.getFileHandle( "data/test2_notwork.wav ",  FileType.Internal));  
elasticsearch_38d10d19bc75f59f23cffc37f0a6bfa8c4de5812	buggy:  return  clusterState.routingTable().index(request.index()).allShardsIt();  context:  return  TransportActions.Admin.Indices.ANALYZE;  }  return   "indices/analyze/shard ";  }  request.index(clusterState.metaData().concreteIndex(request.index()));          return  clusterState.routingTable().index(request.index()).allShardsIt();          return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  }  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  Analyzer  analyzer  =  null;  String  field  =   "contents ";  if  (request.analyzer()  !=  null)  {  analyzer  =  indexService.analysisService().analyzer(request.analyzer());  	return  clusterState.routingTable().index(request.index()).randomAllShardsIt();  
elasticsearch_38ea07cfbe20484c7a53307468c326105402e614	buggy:  .to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE,  SoftFieldDataCache.class,   "org.elasticsearch.index.cache.field. ",   "FieldDataCache "))  context:  }  private  final  Settings  settings;  public  FieldDataCacheModule(Settings  settings)  {  this.settings  =  settings;  }  bind(FieldDataCache.class)                  .to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE,  SoftFieldDataCache.class,   "org.elasticsearch.index.cache.field. ",   "FieldDataCache "))                  .to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE,  SoftFieldDataCache.class,   "org.elasticsearch.index.cache.field.data. ",   "FieldDataCache "))  .in(Scopes.SINGLETON);  }  }  	.to(settings.getAsClass(FieldDataCacheSettings.FIELD_DATA_CACHE_TYPE,  SoftFieldDataCache.class,   "org.elasticsearch.index.cache.field.data. ",   "FieldDataCache "))  
libgdx_f880a095f459a9696e0968680b34dc85b7a542a0	buggy:  MipMapGenerator.generateMipMap(pixmap,  this,  disposePixmap);  context:  Blending  blend  =  Pixmap.getBlending();  Pixmap.setBlending(Blending.None);  tmp.drawPixmap(pixmap,  0,  0,  0,  0,  pixmap.getWidth(),  pixmap.getHeight());  Pixmap.setBlending(blend);  pixmap  =  tmp;  disposePixmap  =  true;  }  Gdx.gl.glBindTexture(GL10.GL_TEXTURE_2D,  glHandle);  if(data.useMipMaps())  {  MipMapGenerator.generateMipMap(pixmap,  this,  disposePixmap);  MipMapGenerator.generateMipMap(pixmap,  pixmap.getWidth(),  pixmap.getHeight(),  disposePixmap);  }  else  {  Gdx.gl.glTexImage2D(GL10.GL_TEXTURE_2D,  0,  pixmap.getGLInternalFormat(),  pixmap.getWidth(),  pixmap.getHeight(),  0,  pixmap.getGLFormat(),  pixmap.getGLType(),  pixmap.getPixels());  if(disposePixmap)  pixmap.dispose();  }  }  	MipMapGenerator.generateMipMap(pixmap,  pixmap.getWidth(),  pixmap.getHeight(),  disposePixmap);  
elasticsearch_cc9ab111a04661367cea50e444b5a9e0d4544d1a	buggy:  if  (parentFieldMapper  !=  null)  {  context:  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  filter  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  Set<String>  parentTypes  =  new  HashSet<String>(5);  parentTypes.add(parentType);  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();              if  (parentFieldMapper  !=  null)  {              if  (parentFieldMapper.active())  {  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  }  }  	if  (parentFieldMapper.active())  {  
libgdx_c5edc0976145a61a5551053dfda8a8c3394100ee	buggy:  Preferences  prefs  =  new  LwjglPreferences(name);  context:  return  getJavaHeap();  }  ObjectMap<String,  Preferences>  preferences  =  new  ObjectMap<String,  Preferences>();  public  Preferences  getPreferences(String  name)  {  if  (preferences.containsKey(name))  {  return  preferences.get(name);  }  else  {  Preferences  prefs  =  new  LwjglPreferences(name);  Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  preferences.put(name,  prefs);  return  prefs;  }  }  public  Clipboard  getClipboard  ()  {  return  new  LwjglClipboard();  	Preferences  prefs  =  new  LwjglPreferences(name,   ".prefs/ ");  
libgdx_3d959269f4266f8a7fd44c7ee012227e119c29e1	buggy:  cell.setLayout(null);  context:  }  };  public  Cell  obtainCell  (TableLayout  layout)  {  Cell  cell  =  cellPool.obtain();  cell.setLayout(layout);  return  cell;  }  public  void  freeCell  (Cell  cell)  {  cell.setLayout(null);  cell.free();  cellPool.free(cell);  }  public  void  addChild  (Actor  parent,  Actor  child)  {  child.remove();  ((Group)parent).addActor(child);  }  	cell.free();  
libgdx_373af508d4356f18a0303562df714b9034f31b08	buggy:  batch.draw(fboRegion,  0,  0,  Gdx.graphics.getWidth()  /  2,  Gdx.graphics.getHeight()  /  2);  context:  mesh.render(shader,  GL10.GL_TRIANGLES);  shader.end();  fbo.end();  batch.begin();  batch.disableBlending();  batchShader.setUniformi( "u_filterSize ",  filter.length);  batchShader.setUniform1fv( "u_filter ",  filter,  0,  filter.length);  batchShader.setUniform2fv( "u_offsets ",  offsets,  0,  offsets.length);  batch.draw(fboRegion,  0,  0,  Gdx.graphics.getWidth()  /  2,  Gdx.graphics.getHeight()  /  2);  batch.draw(fboRegion,  0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  batch.end();  }  }  	batch.draw(fboRegion,  0,  0,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  boolean  foundTerm  =  topLevelIterator.seekExact(term,  false);  context:  startField(field,  fieldTermVector.size(),  positions,  offsets,  payloads);  if  (flags.contains(Flag.FieldStatistics))  {  writeFieldStatistics(topLevelTerms);  }  iterator  =  fieldTermVector.iterator(iterator);  final  boolean  useDocsAndPos  =  positions  ||  offsets  ||  payloads;  while  (iterator.next()  !=  null)  {  //  iterate  all  terms  of  the  BytesRef  term  =  iterator.term();                  boolean  foundTerm  =  topLevelIterator.seekExact(term,  false);                  boolean  foundTerm  =  topLevelIterator.seekExact(term);  assert  (foundTerm);  startTerm(term);  if  (flags.contains(Flag.TermStatistics))  {  writeTermStatistics(topLevelIterator);  }  if  (useDocsAndPos)  {  docsAndPosEnum  =  writeTermWithDocsAndPos(iterator,  docsAndPosEnum,  positions,  offsets,  payloads);  	boolean  foundTerm  =  topLevelIterator.seekExact(term);  
elasticsearch_e5737e305804da5f09b716e66fa1d5e17bddc07e	buggy:  logger.trace( "Master  [{}]  failed  on  ping ",  masterNode);  context:  }  }  }  if  (sentToNode.equals(MasterFaultDetection.this.masterNode()))  {  int  retryCount  =  ++MasterFaultDetection.this.retryCount;  if  (retryCount  >=  pingRetryCount)  {                                          logger.trace( "Master  [{}]  failed  on  ping ",  masterNode);                                          logger.debug( "Master  [{}]  failed  on  ping,  tried  [{}]  times,  each  with  [{}]  timeout ",  masterNode,  pingRetryCount,  pingRetryTimeout);  notifyMasterFailure(sentToNode);  }  }  }  });  }  }  	logger.debug( "Master  [{}]  failed  on  ping,  tried  [{}]  times,  each  with  [{}]  timeout ",  masterNode,  pingRetryCount,  pingRetryTimeout);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<ComplexExplanation>  filterExplanations  =  new  ArrayList<ComplexExplanation>();  context:  }  public  Explanation  explain(AtomicReaderContext  context,  int  doc)  throws  IOException  {  Explanation  subQueryExpl  =  subQueryWeight.explain(context,  doc);  if  (!subQueryExpl.isMatch())  {  return  subQueryExpl;  }              List<ComplexExplanation>  filterExplanations  =  new  ArrayList<ComplexExplanation>();              List<ComplexExplanation>  filterExplanations  =  new  ArrayList<>();  for  (FilterFunction  filterFunction  :  filterFunctions)  {  Bits  docSet  =  DocIdSets.toSafeBits(context.reader(),  filterFunction.filter.getDocIdSet(context,  context.reader().getLiveDocs()));  if  (docSet.get(doc))  {  filterFunction.function.setNextReader(context);  Explanation  functionExplanation  =  filterFunction.function.explainScore(doc,  subQueryExpl);  double  factor  =  functionExplanation.getValue();  float  sc  =  CombineFunction.toFloat(factor);  	List<ComplexExplanation>  filterExplanations  =  new  ArrayList<>();  
libgdx_7cccb823556e567d2ec2dfa731e1a7e4f2dda3c0	buggy:  TextureFilter.Nearest,  TextureFilter.Nearest,  context:  camera.getDirection().set(0,  0,  -1);  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  load();  }  private  void  load  ()  {  try  {  tiles  =  Gdx.graphics.newTexture(  Gdx.files.getFileHandle( "data/tiles-3.png ",  FileType.Internal),  TextureFilter.Nearest,  TextureFilter.Nearest,  TextureFilter.MipMap,  TextureFilter.Nearest,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge  );  TextureAtlas  atlas  =  new  TextureAtlas(tiles);  for(  int  i  =  0;  i  <  12;  i++  )  {  TextureRegion  region  =  new  TextureRegion(tiles,  i  %  4  *  64  +  1,  i  /  4  *  64  +  1,  64,  64);  atlas.addRegion( " "  +  i,  region);  }  float  uSize  =  62.0f  /  256.0f;  	TextureFilter.MipMap,  TextureFilter.Nearest,  
elasticsearch_e66bd4359a5d5e03a04a4a8a6bb26f25fe107f24	buggy:  ShingleFilter  filter  =  new  ShingleFilter(tokenStream,  maxShingleSize,  minShingleSize);  context:  super(index,  indexSettings,  name,  settings);  maxShingleSize  =  settings.getAsInt( "max_shingle_size ",  ShingleFilter.DEFAULT_MAX_SHINGLE_SIZE);  minShingleSize  =  settings.getAsInt( "min_shingle_size ",  ShingleFilter.DEFAULT_MIN_SHINGLE_SIZE);  outputUnigrams  =  settings.getAsBoolean( "output_unigrams ",  true);  outputUnigramsIfNoShingles  =  settings.getAsBoolean( "output_unigrams_if_no_shingles ",  false);  tokenSeparator  =  settings.get( "token_separator ",  ShingleFilter.TOKEN_SEPARATOR);  }  public  TokenStream  create(TokenStream  tokenStream)  {          ShingleFilter  filter  =  new  ShingleFilter(tokenStream,  maxShingleSize,  minShingleSize);          ShingleFilter  filter  =  new  ShingleFilter(tokenStream,  minShingleSize,  maxShingleSize);  filter.setOutputUnigrams(outputUnigrams);  filter.setOutputUnigramsIfNoShingles(outputUnigramsIfNoShingles);  filter.setTokenSeparator(tokenSeparator);  return  filter;  }  }  	ShingleFilter  filter  =  new  ShingleFilter(tokenStream,  minShingleSize,  maxShingleSize);  
elasticsearch_223dab892144b0c8f9d073baf1598a1e3cdfa3ed	buggy:  builder.addSurface(spare.surfaceForm,  spare.payload,  spare.weight);  context:  this.builder  =  builder;  }  public  void  startDoc(int  docID,  int  freq)  throws  IOException  {  }  public  void  addPosition(int  position,  BytesRef  payload,  int  startOffset,  int  endOffset)  throws  IOException  {  analyzingSuggestLookupProvider.parsePayload(payload,  spare);              builder.addSurface(spare.surfaceForm,  spare.payload,  spare.weight);              builder.addSurface(spare.surfaceForm.get(),  spare.payload.get(),  spare.weight);  maxAnalyzedPathsForOneInput  =  Math.max(maxAnalyzedPathsForOneInput,  position  +  1);  }  public  void  finishDoc()  throws  IOException  {  }  	builder.addSurface(spare.surfaceForm.get(),  spare.payload.get(),  spare.weight);  
elasticsearch_07ab5dcf9b4180f66fa89ea3539a429dcde18833	buggy:  builder.field( "_type ",   "terms ");  context:  for  (TObjectIntIterator<String>  it  =  aggregated.iterator();  it.hasNext();)  {  it.advance();  ordered.add(new  Entry(it.key(),  it.value()));  }  return  new  InternalTermsFacet(name,  fieldName,  comparatorType,  requiredSize,  ordered);  }  builder.startObject(name);          builder.field( "_type ",   "terms ");          builder.field( "_type ",  TermsFacetCollectorParser.NAME);  builder.field( "_field ",  fieldName);  builder.startArray( "terms ");  for  (Entry  entry  :  entries)  {  builder.startObject();  builder.field( "term ",  entry.term());  builder.field( "count ",  entry.count());  builder.endObject();  }  	builder.field( "_type ",  TermsFacetCollectorParser.NAME);  
elasticsearch_847db717c66509a817e1b965226ee1e44c08918d	buggy:  Class<?  extends  Module>  defaultDiscoveryModule  =  null;  context:  public  class  DiscoveryModule  extends  AbstractModule  {  private  final  Settings  settings;  public  DiscoveryModule(Settings  settings)  {  this.settings  =  settings;  }  protected  void  configure()  {          Class<?  extends  Module>  defaultDiscoveryModule  =  null;          Class<?  extends  Module>  defaultDiscoveryModule;  if  (settings.getAsBoolean( "node.local ",  false))  {  defaultDiscoveryModule  =  LocalDiscoveryModule.class;  }  else  {  try  {  Classes.getDefaultClassLoader().loadClass( "org.elasticsearch.discovery.jgroups.JgroupsDiscovery ");  defaultDiscoveryModule  =  (Class<?  extends  Module>)  Classes.getDefaultClassLoader().loadClass( "org.elasticsearch.discovery.jgroups.JgroupsDiscoveryModule ");  }  catch  (ClassNotFoundException  e)  {  defaultDiscoveryModule  =  LocalDiscoveryModule.class;  	Class<?  extends  Module>  defaultDiscoveryModule;  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  }  else  if  (propName.equals( "omitTermFreqAndPositions ")  ||  propName.equals( "omit_termFreq_and_positions "))  {  context:  }  else  if  (propName.equals( "store "))  {  builder.store(parseStore(name,  propNode.getTextValue()));  }  else  if  (propName.equals( "index "))  {  builder.index(parseIndex(name,  propNode.getTextValue()));  }  else  if  (propName.equals( "termVector ")  ||  propName.equals( "term_vector "))  {  builder.termVector(parseTermVector(name,  propNode.getTextValue()));  }  else  if  (propName.equals( "boost "))  {  builder.boost(nodeFloatValue(propNode));  }  else  if  (propName.equals( "omitNorms ")  ||  propName.equals( "omit_norms "))  {  builder.omitNorms(nodeBooleanValue(propNode));              }  else  if  (propName.equals( "omitTermFreqAndPositions ")  ||  propName.equals( "omit_termFreq_and_positions "))  {              }  else  if  (propName.equals( "omitTermFreqAndPositions ")  ||  propName.equals( "omit_term_freq_and_positions "))  {  builder.omitTermFreqAndPositions(nodeBooleanValue(propNode));  }  else  if  (propName.equals( "indexAnalyzer ")  ||  propName.equals( "index_analyzer "))  {  builder.indexAnalyzer(parserContext.analysisService().analyzer(propNode.getTextValue()));  }  else  if  (propName.equals( "searchAnalyzer ")  ||  propName.equals( "search_analyzer "))  {  builder.searchAnalyzer(parserContext.analysisService().analyzer(propNode.getTextValue()));  }  else  if  (propName.equals( "analyzer "))  {  builder.indexAnalyzer(parserContext.analysisService().analyzer(propNode.getTextValue()));  builder.searchAnalyzer(parserContext.analysisService().analyzer(propNode.getTextValue()));  	}  else  if  (propName.equals( "omitTermFreqAndPositions ")  ||  propName.equals( "omit_term_freq_and_positions "))  {  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(CountResponse  response)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  builder.startObject();  builder.field( "count ",  response.getCount());  buildBroadcastShardsHeader(builder,  response);  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_3d4c31de91a0cbdceb4c910a5bd8eaad3bd09501	buggy:  byte[]  bytes  =  Version.full().getBytes();  context:  }  else  if  ( "delete ".equals(cmd))  {  request  =  new  MemcachedRestRequest(RestRequest.Method.DELETE,  args[1],  null,  -1,  false);  return  request;  }  else  if  ( "set ".equals(cmd))  {  this.request  =  new  MemcachedRestRequest(RestRequest.Method.POST,  args[1],  null,  Integer.parseInt(args[4]),  false);  buffer.markReaderIndex();  }  else  if  ( "version ".equals(cmd))  {  //  sent  as  a  noop                      byte[]  bytes  =  Version.full().getBytes();                      byte[]  bytes  =  Version.CURRENT.toString().getBytes();  ChannelBuffer  writeBuffer  =  ChannelBuffers.dynamicBuffer(bytes.length);  writeBuffer.writeBytes(bytes);  channel.write(writeBuffer);  return  MemcachedDispatcher.IGNORE_REQUEST;  }  else  if  ( "quit ".equals(cmd))  {  if  (channel.isConnected())  {  //  we  maybe  in  the  process  of  clearing  the  queued  bits  channel.disconnect();  }  	byte[]  bytes  =  Version.CURRENT.toString().getBytes();  
libgdx_629f270a6e207add4aec1647869dc8a833e6a611	buggy:  return  new  VertexAttribute(Usage.TextureCoordinates,  3,  ShaderProgram.NORMAL_ATTRIBUTE);  context:  public  static  VertexAttribute  Position()  {  return  new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE);  }  public  static  VertexAttribute  TexCoords(int  unit)  {  return  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +  unit);  }  public  static  VertexAttribute  Normal()  {  return  new  VertexAttribute(Usage.TextureCoordinates,  3,  ShaderProgram.NORMAL_ATTRIBUTE);  return  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE);  }  public  static  VertexAttribute  Color()  {  return  new  VertexAttribute(Usage.ColorPacked,  4,  ShaderProgram.COLOR_ATTRIBUTE);  }  }  	return  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE);  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  buildScrollId(request.searchType(),  dfsResults);  context:  searchCache.releaseDfsResults(dfsResults);  searchCache.releaseQueryFetchResults(queryFetchResults);  }  }  private  void  innerFinishHim()  throws  Exception  {  sortedShardList  =  searchPhaseController.sortDocs(queryFetchResults.values());  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(sortedShardList,  queryFetchResults,  queryFetchResults);  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  buildScrollId(request.searchType(),  dfsResults);                  scrollId  =  buildScrollId(request.searchType(),  dfsResults,  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  }  }  }  	scrollId  =  buildScrollId(request.searchType(),  dfsResults,  null);  
elasticsearch_bcc16654d21c5d6c5f43940b77948ada4087521b	buggy:  if  (name  ==  null)  {  context:  continue;  }  providers.put(factory.name(),  factory.get());  }  this.providers  =  providers.immutableMap();  }  public  PostingsFormatProvider  get(String  name)  throws  ElasticSearchIllegalArgumentException  {  PostingsFormatProvider  provider  =  providers.get(name);          if  (name  ==  null)  {          if  (provider  ==  null)  {  throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  postings_format  [ "  +  name  +   "] ");  }  return  provider;  }  }  	if  (provider  ==  null)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<ShardRecoveryResponse>  nodeResponses  =  new  ArrayList<ShardRecoveryResponse>();  context:  assertThat(shardResponse.recoveryState().getType(),  equalTo(RecoveryState.Type.SNAPSHOT));  assertThat(shardResponse.recoveryState().getStage(),  equalTo(RecoveryState.Stage.DONE));  assertNotNull(shardResponse.recoveryState().getRestoreSource());  assertThat(shardResponse.recoveryState().getTargetNode().getName(),  equalTo(nodeA));  }  }  }  private  List<ShardRecoveryResponse>  findRecoveriesForTargetNode(String  nodeName,  List<ShardRecoveryResponse>  responses)  {          List<ShardRecoveryResponse>  nodeResponses  =  new  ArrayList<ShardRecoveryResponse>();          List<ShardRecoveryResponse>  nodeResponses  =  new  ArrayList<>();  for  (ShardRecoveryResponse  response  :  responses)  {  if  (response.recoveryState().getTargetNode().getName().equals(nodeName))  {  nodeResponses.add(response);  }  }  return  nodeResponses;  }  	List<ShardRecoveryResponse>  nodeResponses  =  new  ArrayList<>();  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().cluster().execPing(replicationPingRequest,  new  ActionListener<ReplicationPingResponse>()  {  context:  super(settings,  client);  controller.registerHandler(RestRequest.Method.GET,   "/{index}/_ping/replication ",  this);  controller.registerHandler(RestRequest.Method.GET,   "/_cluster/{index}/_ping/replication ",  this);  }  ReplicationPingRequest  replicationPingRequest  =  new  ReplicationPingRequest(RestActions.splitIndices(request.param( "index ")));  replicationPingRequest.timeout(request.paramAsTime( "timeout ",  ShardReplicationPingRequest.DEFAULT_TIMEOUT));  replicationPingRequest.listenerThreaded(false);          client.admin().cluster().execPing(replicationPingRequest,  new  ActionListener<ReplicationPingResponse>()  {          client.admin().cluster().ping(replicationPingRequest,  new  ActionListener<ReplicationPingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject();  builder.field( "ok ",  true);  for  (IndexReplicationPingResponse  indexResponse  :  result.indices().values())  {  builder.startObject(indexResponse.index())  .field( "ok ",  true)  	client.admin().cluster().ping(replicationPingRequest,  new  ActionListener<ReplicationPingResponse>()  {  
elasticsearch_2e8b0464b65a2ca0d7db738637b151d586395b63	buggy:  final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool)).start();  context:  public  class  BenchmarkNettyServer  {  public  static  void  main(String[]  args)  {  final  boolean  spawn  =  true;  Settings  settings  =  ImmutableSettings.settingsBuilder()  .put( "transport.netty.port ",  9999)  .build();  final  ThreadPool  threadPool  =  new  CachedThreadPool();          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool)).start();          final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  transportService.registerHandler( "benchmark ",  new  BaseTransportRequestHandler<BenchmarkMessage>()  {  return  new  BenchmarkMessage();  }  channel.sendResponse(request);  	final  TransportService  transportService  =  new  TransportService(new  NettyTransport(settings,  threadPool),  threadPool).start();  
elasticsearch_d570d588a8fdfd7feca537d97f1455c6a5a52220	buggy:  return  cluster().dataNodes()  -  1;  context:  protected  int  numberOfShards()  {  return  between(minimumNumberOfShards(),  maximumNumberOfShards());  }  protected  int  minimumNumberOfReplicas()  {  return  0;  }  protected  int  maximumNumberOfReplicas()  {          return  cluster().dataNodes()  -  1;          return  immutableCluster().dataNodes()  -  1;  }  protected  int  numberOfReplicas()  {  return  between(minimumNumberOfReplicas(),  maximumNumberOfReplicas());  }  	return  immutableCluster().dataNodes()  -  1;  
elasticsearch_cca84431f596336670892d8ba3884ddcd088b03d	buggy:  assertThat( "Unexpectd  ShardFailures:   "  +  Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getShardFailures().length,  equalTo(0));  context:  }  public  static  void  assertSearchHit(SearchResponse  searchResponse,  int  number,  Matcher<SearchHit>  matcher)  {  assert  number  >  0;  assertThat( "SearchHit  number  must  be  greater  than  0 ",  number,  greaterThan(0));  assertThat(searchResponse.getHits().totalHits(),  greaterThanOrEqualTo((long)  number));  assertSearchHit(searchResponse.getHits().getAt(number  -  1),  matcher);  }  public  static  void  assertNoFailures(SearchResponse  searchResponse)  {          assertThat( "Unexpectd  ShardFailures:   "  +  Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getShardFailures().length,  equalTo(0));          assertThat( "Unexpected  ShardFailures:   "  +  Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getShardFailures().length,  equalTo(0));  }  public  static  void  assertNoFailures(BroadcastOperationResponse  response)  {  assertThat( "Unexpectd  ShardFailures:   "  +  Arrays.toString(response.getShardFailures()),  response.getFailedShards(),  equalTo(0));  }  public  static  void  assertSearchHit(SearchHit  searchHit,  Matcher<SearchHit>  matcher)  {  assertThat(searchHit,  matcher);  	assertThat( "Unexpected  ShardFailures:   "  +  Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getShardFailures().length,  equalTo(0));  
libgdx_ad4ba1c7473f6d64a1cb52eb5cefbff49eb20142	buggy:  rotation,  0,  0,  debugTexture.getWidth(),  debugTexture.getHeight(),  Color.WHITE,  false,  false);  context:  child.act(delta);  }  }  updateTransform();  tmp4.set(scenetransform);  if  (debug  &&  debugTexture  !=  null  &&  parent  !=  null)  batch.draw(debugTexture,  x,  y,  originX,  originY,  width  ==  0  ?  200  :  width,  height  ==  0  ?  200  :  height,  scaleX,  scaleY,  rotation,  0,  0,  debugTexture.getWidth(),  debugTexture.getHeight(),  Color.WHITE,  false,  false);  rotation,  0,  0,  debugTexture.getWidth(),  debugTexture.getHeight(),  false,  false);  batch.end();  oldBatchTransform.set(batch.getTransformMatrix());  batch.setTransformMatrix(tmp4);  batch.begin();  int  len  =  children.size();  for  (int  i  =  0;  i  <  len;  i++)  	rotation,  0,  0,  debugTexture.getWidth(),  debugTexture.getHeight(),  false,  false);  
elasticsearch_616b09e9b4a650275e3e460c99c9c6556a8c21a0	buggy:  this.updateTasksExecutor  =  EsExecutors.newSinglePrioritizingThreadExecutor(daemonThreadFactory(settings,   "clusterService#updateTask "));  context:  if  (lifecycle.started())  {  throw  new  ElasticSearchIllegalStateException( "can't  set  initial  block  when  started ");  }  initialBlocks.addGlobalBlock(block);  }  protected  void  doStart()  throws  ElasticSearchException  {  add(localNodeMasterListeners);  this.clusterState  =  newClusterStateBuilder().blocks(initialBlocks).build();          this.updateTasksExecutor  =  EsExecutors.newSinglePrioritizingThreadExecutor(daemonThreadFactory(settings,   "clusterService#updateTask "));          this.updateTasksExecutor  =  EsExecutors.newSinglePrioritizing(daemonThreadFactory(settings,   "clusterService#updateTask "));  this.reconnectToNodes  =  threadPool.schedule(reconnectInterval,  ThreadPool.Names.GENERIC,  new  ReconnectToNodes());  }  protected  void  doStop()  throws  ElasticSearchException  {  this.reconnectToNodes.cancel(true);  for  (NotifyTimeout  onGoingTimeout  :  onGoingTimeouts)  {  onGoingTimeout.cancel();  	this.updateTasksExecutor  =  EsExecutors.newSinglePrioritizing(daemonThreadFactory(settings,   "clusterService#updateTask "));  
elasticsearch_3e9dff8b7e7672eece3593ea3bc6e920ebd95f89	buggy:  tokenFiltersBindings.processTokenFilter( "k_stem ",  KStemTokenFilterFactory.class);  context:  charFiltersBindings.processCharFilter( "html_strip ",  HtmlStripCharFilterFactory.class);  }  tokenFiltersBindings.processTokenFilter( "stop ",  StopTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "reverse ",  ReverseTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "asciifolding ",  ASCIIFoldingTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "length ",  LengthTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "lowercase ",  LowerCaseTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "porter_stem ",  PorterStemTokenFilterFactory.class);              tokenFiltersBindings.processTokenFilter( "k_stem ",  KStemTokenFilterFactory.class);              tokenFiltersBindings.processTokenFilter( "kstem ",  KStemTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "standard ",  StandardTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "nGram ",  NGramTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "ngram ",  NGramTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "edgeNGram ",  EdgeNGramTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "edge_ngram ",  EdgeNGramTokenFilterFactory.class);  tokenFiltersBindings.processTokenFilter( "shingle ",  ShingleTokenFilterFactory.class);  }  	tokenFiltersBindings.processTokenFilter( "kstem ",  KStemTokenFilterFactory.class);  
libgdx_cc848b176103cea64f8abf17f6410fea5fc9d091	buggy:  OrderedMap  oldSkin  =  json.fromJson(OrderedMap.class,  new  FileHandle(skinFile));  context:  FileHandle  newSkinFile  =  new  FileHandle(new  File(inputDir,   "temp-skin "));  skin.save(newSkinFile);  atlas.getPages().get(0).textureFile.moveTo(new  FileHandle(imageFile));  new  FileHandle(packedDir).deleteDirectory();  Json  json  =  new  Json();  if  (skinFile  !=  null)  {  FileHandle  oldSkinFile  =  new  FileHandle(skinFile);  OrderedMap  oldSkin  =  json.fromJson(OrderedMap.class,  new  FileHandle(skinFile));  OrderedMap  oldSkin  =  json.fromJson(OrderedMap.class,  oldSkinFile);  OrderedMap  newSkin  =  json.fromJson(OrderedMap.class,  newSkinFile);  OrderedMap  oldResources  =  (OrderedMap)oldSkin.get( "resources ");  OrderedMap  newResources  =  (OrderedMap)newSkin.get( "resources ");  OrderedMap  newPatches  =  (OrderedMap)newResources.get(NinePatch.class.getName());  newPatches.orderedKeys().sort();  oldResources.put(NinePatch.class.getName(),  newPatches);  	OrderedMap  oldSkin  =  json.fromJson(OrderedMap.class,  oldSkinFile);  
libgdx_db146dbd644c482242d8d96c763ce0ef5b0cf9df	buggy:  FileHandle  src  =  Gdx.files.internal( "data/iron.mp3 ");  context:  public  class  ExternalMusicTest  extends  GdxTest  {  public  void  create  ()  {  FileHandle  src  =  Gdx.files.internal( "data/iron.mp3 ");  FileHandle  src  =  Gdx.files.internal( "data/8.12.mp3 ");  FileHandle  dst  =  Gdx.files.external( "8.12.mp3 ");  src.copyTo(dst);  Music  music  =  Gdx.audio.newMusic(dst);  music.play();  }  	FileHandle  src  =  Gdx.files.internal( "data/8.12.mp3 ");  
elasticsearch_eb68891ae5538511118a2f095579ff93e17e0c42	buggy:  .loadFromClasspath( "org/elasticsearch/util/settings/loader/test-settings.yml ")  context:  public  class  YamlSettingsLoaderTests  {  Settings  settings  =  settingsBuilder()                  .loadFromClasspath( "org/elasticsearch/util/settings/loader/test-settings.yml ")                  .loadFromClasspath( "org/elasticsearch/common/settings/loader/test-settings.yml ")  .build();  assertThat(settings.get( "test1.value1 "),  equalTo( "value1 "));  assertThat(settings.get( "test1.test2.value2 "),  equalTo( "value2 "));  assertThat(settings.getAsInt( "test1.test2.value3 ",  -1),  equalTo(2));  assertThat(settings.get( "test1.test3.0 "),  equalTo( "test3-1 "));  	.loadFromClasspath( "org/elasticsearch/common/settings/loader/test-settings.yml ")  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false;  context:  assertThat(updateResponse.getGetResult().sourceAsMap().get( "extra "),  nullValue());  }  public  void  testUpdate()  throws  Exception  {  createIndex();  ensureGreen();  try  {  client().prepareUpdate( "test ",   "type1 ",   "1 ").setScript( "ctx._source.field++ ").execute().actionGet();              assert  false;              fail();  }  catch  (DocumentMissingException  e)  {  }  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field ",  1).execute().actionGet();  UpdateResponse  updateResponse  =  client().prepareUpdate( "test ",   "type1 ",   "1 ").setScript( "ctx._source.field  +=  1 ").execute().actionGet();  assertThat(updateResponse.getVersion(),  equalTo(2L));  	fail();  
libgdx_ae45ffe4ebe41482453af5e1245f4a93f57ae3b4	buggy:  font  =  new  BitmapFont();  context:  for  (int  i  =  0;  i  <  5000;  i++)  {  Actor  img  =  new  CullableActor( "img "  +  i,  texture,  (OrthographicCamera)stage.getCamera());  img.x  =  (float)Math.random()  *  480  *  10;  img.y  =  (float)Math.random()  *  320  *  10;  stage.addActor(img);  }  batch  =  new  SpriteBatch();  font  =  new  BitmapFont();  font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  stage.draw();  List<Actor>  actors  =  stage.getActors();  	font  =  new  BitmapFont(Gdx.files.internal( "data/arial-15.fnt "),  false);  
elasticsearch_c05df433c6ff92b69a2acaa411c1b66e537e0811	buggy:  return  new  Term(names.indexName(),  uid);  context:  return  Uid.createUid(type,  value);  }  return  value;  }  return  term(Uid.createUid(type,  id));  }          return  new  Term(names.indexName(),  uid);          return  termFactory.createTerm(uid);  }  return  CONTENT_TYPE;  }  builder.startObject(CONTENT_TYPE);  	return  termFactory.createTerm(uid);  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.startObject(StatisticalFacetCollectorParser.NAME);  context:  params.put(name,  value);  return  this;  }  if  (script  ==  null)  {  throw  new  SearchSourceBuilderException( "script  must  be  set  on  statistical  script  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.startObject(StatisticalFacetCollectorParser.NAME);          builder.startObject(StatisticalFacet.TYPE);  builder.field( "script ",  script);  if  (lang  !=  null)  {  builder.field( "lang ",  lang);  }  if  (this.params  !=  null)  {  builder.field( "params ",  this.params);  }  builder.endObject();  	builder.startObject(StatisticalFacet.TYPE);  
elasticsearch_613b7462997ea41ed37bd1045a7de8937e3c5ef0	buggy:  Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())  context:  if  (ordinals.size()  ==  1)  {  return  new  PagedBytesAtomicFieldData(bytesReader,  termOrdToBytesOffsetReader,  new  SingleArrayOrdinals(ordinals.get(0),  termOrd));  }  else  {  int[][]  nativeOrdinals  =  new  int[ordinals.size()][];  for  (int  i  =  0;  i  <  nativeOrdinals.length;  i++)  {  nativeOrdinals[i]  =  ordinals.get(i);  }  return  new  PagedBytesAtomicFieldData(  bytesReader,  termOrdToBytesOffsetReader,                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getOptions())                      Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  );  }  }  public  XFieldComparatorSource  comparatorSource(@Nullable  Object  missingValue)  {  	Ordinals.Factories.createFromFlatOrdinals(nativeOrdinals,  termOrd,  fieldDataType.getSettings())  
elasticsearch_55101edb4690bc7d17266f6c769c80930a4736b6	buggy:  return  contentBuilder(XContentType.SMILE);  context:  public  static  XContentBuilder  smileBuilder(OutputStream  os)  throws  IOException  {  return  new  XContentBuilder(SmileXContent.smileXContent,  os);  }  public  static  XContentBuilder  yamlBuilder()  throws  IOException  {          return  contentBuilder(XContentType.SMILE);          return  contentBuilder(XContentType.YAML);  }  public  static  XContentBuilder  yamlBuilder(OutputStream  os)  throws  IOException  {  return  new  XContentBuilder(YamlXContent.yamlXContent,  os);  }  	return  contentBuilder(XContentType.YAML);  
elasticsearch_25bce1db5ddbaada99e87fc76ae1ab3125228441	buggy:  failure  =  new  NoShardAvailableActionException(shardIt.shardId());  context:  private  void  perform(@Nullable  final  Throwable  currentFailure)  {  Throwable  lastFailure  =  this.lastFailure;  if  (lastFailure  ==  null  ||  TransportActions.isReadOverrideException(currentFailure))  {  lastFailure  =  currentFailure;  this.lastFailure  =  currentFailure;  }  final  ShardRouting  shardRouting  =  shardIt.nextOrNull();  if  (shardRouting  ==  null)  {  Throwable  failure  =  lastFailure;  if  (failure  ==  null  ||  isShardNotAvailableException(failure))  {                      failure  =  new  NoShardAvailableActionException(shardIt.shardId());                      failure  =  new  NoShardAvailableActionException(shardIt.shardId(),  null,  failure);  }  else  {  if  (logger.isDebugEnabled())  {  }  }  listener.onFailure(failure);  return;  }  	failure  =  new  NoShardAvailableActionException(shardIt.shardId(),  null,  failure);  
elasticsearch_9addac830089e48bdcd77a5cc972d85808d863e5	buggy:  Explanation  functionExplanation  =  function.explainScore(doc,  subQueryExpl);  context:  return  new  CustomBoostFactorScorer(this,  subQueryScorer,  function,  maxBoost,  combineFunction);  }  public  Explanation  explain(AtomicReaderContext  context,  int  doc)  throws  IOException  {  Explanation  subQueryExpl  =  subQueryWeight.explain(context,  doc);  if  (!subQueryExpl.isMatch())  {  return  subQueryExpl;  }  function.setNextReader(context);              Explanation  functionExplanation  =  function.explainScore(doc,  subQueryExpl);              Explanation  functionExplanation  =  function.explainScore(doc,  subQueryExpl.getValue());  return  combineFunction.explain(getBoost(),  subQueryExpl,  functionExplanation,  maxBoost);  }  }  static  class  CustomBoostFactorScorer  extends  Scorer  {  private  final  float  subQueryBoost;  private  final  Scorer  scorer;  	Explanation  functionExplanation  =  function.explainScore(doc,  subQueryExpl.getValue());  
libgdx_9349f129ed8dbced7c9e3f2d0bd0f83d7a092f1f	buggy:  deps  =  Array.of(AssetDescriptor.class);  context:  effect.load(file,  param.imagesDir);  else  effect.load(file,  file.parent());  return  effect;  }  public  Array<AssetDescriptor>  getDependencies  (String  fileName,  FileHandle  file,  ParticleEffectParameter  param)  {  Array<AssetDescriptor>  deps  =  null;  if  (param  !=  null  &&  param.atlasFile  !=  null)  {  deps  =  Array.of(AssetDescriptor.class);  deps  =  new  Array();  deps.add(new  AssetDescriptor<TextureAtlas>(param.atlasFile,  TextureAtlas.class));  }  return  deps;  }  public  static  class  ParticleEffectParameter  extends  AssetLoaderParameters<ParticleEffect>  {  	deps  =  new  Array();  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  false  :   "should  be  rejected... ";  context:  });  final  AtomicBoolean  executed3  =  new  AtomicBoolean();  try  {  executor.execute(new  Runnable()  {  public  void  run()  {  executed3.set(true);  }  });              assert  false  :   "should  be  rejected... ";              fail( "should  be  rejected... ");  }  catch  (EsRejectedExecutionException  e)  {  }  wait.countDown();  exec1Wait.await();  exec2Wait.await();  	fail( "should  be  rejected... ");  
elasticsearch_4c8978237fdb07ed81fc7cb0255f43cfe7c1f490	buggy:  return  indicesService.searchShards(clusterState,  request.indices(),  request.queryHint());  context:  return   "/cluster/ping/broadcast/shard ";  }  return  new  BroadcastPingRequest();  }          return  indicesService.searchShards(clusterState,  request.indices(),  request.queryHint());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  }  int  successfulShards  =  0;  int  failedShards  =  0;  List<ShardOperationFailedException>  shardFailures  =  null;  for  (int  i  =  0;  i  <  shardsResponses.length();  i++)  {  Object  shardResponse  =  shardsResponses.get(i);  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  request.queryHint());  
elasticsearch_7307e37efec6e5aa7675121a664c24060efe086f	buggy:  logger.debug( "Refresh  request  executed  for  {}.  Force:  [{}]. ",  indexShard.shardId(),  request.force());  context:  protected  ShardRefreshResponse  newShardResponse()  {  return  new  ShardRefreshResponse();  }  protected  ShardRefreshResponse  shardOperation(ShardRefreshRequest  request)  throws  ElasticSearchException  {  IndexShard  indexShard  =  indicesService.indexServiceSafe(request.index()).shardSafe(request.shardId());  indexShard.refresh(new  Engine.Refresh().force(request.force()));          logger.debug( "Refresh  request  executed  for  {}.  Force:  [{}]. ",  indexShard.shardId(),  request.force());          logger.debug( "{}  Refresh  request  executed.  Force:  [{}]. ",  indexShard.shardId(),  request.force());  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  RefreshRequest  request,  String[]  concreteIndices)  {  	logger.debug( "{}  Refresh  request  executed.  Force:  [{}]. ",  indexShard.shardId(),  request.force());  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));  context:  if  (childDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "No  mapping  for  for  type  [ "  +  childType  +   "] ");  }  if  (childDocMapper.parentFieldMapper()  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "Type  [ "  +  childType  +   "]  does  not  have  parent  mapping ");  }  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter()));          query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  scope,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  searchContext.addScopePhase(childQuery);  return  childQuery;  }  }  	query  =  new  FilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  
elasticsearch_b05b01d9f8ab5f4844426eaf1a6f26b420b2c680	buggy:  final  boolean  termsAsArray  =  request.paramAsBoolean( "termsAsArray ",  false);  context:  termsRequest.sortType(TermsRequest.SortType.fromString(request.param( "sort "),  termsRequest.sortType()));  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  JsonRestResponse(request,  BAD_REQUEST,  JsonBuilder.jsonBuilder().startObject().field( "error ",  e.getMessage()).endObject()));  }  catch  (IOException  e1)  {  }  return;  }          final  boolean  termsAsArray  =  request.paramAsBoolean( "termsAsArray ",  false);          final  boolean  termsAsArray  =  request.paramAsBoolean( "termsAsArray ",  true);  client.execTerms(termsRequest,  new  ActionListener<TermsResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.cached(request);  builder.startObject();  buildBroadcastShardsHeader(builder,  response);  	final  boolean  termsAsArray  =  request.paramAsBoolean( "termsAsArray ",  true);  
elasticsearch_7ed68a5c30e1a94d1938aef513e343f508eadf15	buggy:  return  ThreadPool.Names.MANAGEMENT;  context:  private  final  IndicesService  indicesService;  public  TransportFlushAction(Settings  settings,  ThreadPool  threadPool,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }  protected  String  executor()  {          return  ThreadPool.Names.MANAGEMENT;          return  ThreadPool.Names.FLUSH;  }  protected  String  transportAction()  {  return  FlushAction.NAME;  }  	return  ThreadPool.Names.FLUSH;  
elasticsearch_5f9581d4f02b2deda4161376f4aa4f77c71b906a	buggy:  TopChildrenQuery  childQuery  =  new  TopChildrenQuery(searchContext,  query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  context:  String  parentType  =  childDocMapper.parentFieldMapper().type();  query.setBoost(boost);  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(childDocMapper.typeFilter(),  null));  SearchContext  searchContext  =  SearchContext.current();  if  (searchContext  ==  null)  {  throw  new  ElasticSearchIllegalStateException( "[top_children]  Can't  execute,  search  context  not  set. ");  }          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(searchContext,  query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);          TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  searchContext.addRewrite(childQuery);  return  childQuery;  }  }  	TopChildrenQuery  childQuery  =  new  TopChildrenQuery(query,  childType,  parentType,  scoreType,  factor,  incrementalFactor);  
elasticsearch_c0552bdc7099a93a57e8b574f43b0daefc07a9d1	buggy:  assertThat(stop1.stopWords(),  hasItem( "test-stop "));  context:  Analyzer  analyzer  =  analysisService.analyzer( "custom1 ").analyzer();  assertThat(analyzer,  instanceOf(CustomAnalyzer.class));  CustomAnalyzer  custom1  =  (CustomAnalyzer)  analyzer;  assertThat(custom1.tokenizerFactory(),  instanceOf(StandardTokenizerFactory.class));  assertThat(custom1.tokenFilters().length,  equalTo(2));  StopTokenFilterFactory  stop1  =  (StopTokenFilterFactory)  custom1.tokenFilters()[0];  assertThat(stop1.stopWords().size(),  equalTo(1));          assertThat(stop1.stopWords(),  hasItem( "test-stop "));          assertThat((Iterable<String>)  stop1.stopWords(),  hasItem( "test-stop "));  analyzer  =  analysisService.analyzer( "custom2 ").analyzer();  assertThat(analyzer,  instanceOf(CustomAnalyzer.class));  CustomAnalyzer  custom2  =  (CustomAnalyzer)  analyzer;  HtmlStripCharFilterFactory  html  =  (HtmlStripCharFilterFactory)  custom2.charFilters()[0];  assertThat(html.readAheadLimit(),  equalTo(HTMLStripCharFilter.DEFAULT_READ_AHEAD));  	assertThat((Iterable<String>)  stop1.stopWords(),  hasItem( "test-stop "));  
libgdx_7b41ab127c0b80c9ce3bf1cb4cd7ca56c2d9bdcd	buggy:  font  =  app.getGraphics().newFont(  app.getFiles().getInternalFileHandle(   "data/arial.ttf "),  12,  FontStyle.Plain,  true  );  context:  JoglApplication  app  =  new  JoglApplication(   "Text  Test ",  480,  320,  false  );  app.getGraphics().setRenderListener(  new  TextTest()  );  }  public  void  surfaceCreated(Application  app)  {  if(  text  ==  null  )  {  cam  =  new  OrthographicCamera();  font  =  app.getGraphics().newFont(  app.getFiles().getInternalFileHandle(   "data/arial.ttf "),  12,  FontStyle.Plain,  true  );  font  =  app.getGraphics().newFont(  app.getFiles().getInternalFileHandle(   "data/arial.ttf "),  11,  FontStyle.Plain,  true  );  text  =  font.newText(  );  text.setText(   "This  is  a  test\nIt  is  a  multline  text!\nyes  really!11!111one "  );  text.setHorizontalAlign(  HorizontalAlign.Center  );  text.rebuild();  FloatMesh  m  =  new  FloatMesh(  4,  2,  false,  false,  false,  0,  0,  false,  0  );  m.setVertices(  new  float[]{  0,  0,  text.getWidth(),  0,  text.getWidth(),  text.getHeight(),  0,  text.getHeight()  }  );  bounds  =  new  MeshRenderer(  app.getGraphics().getGL10(),  m,  true,  true  );  	font  =  app.getGraphics().newFont(  app.getFiles().getInternalFileHandle(   "data/arial.ttf "),  11,  FontStyle.Plain,  true  );  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  threadPool.cached().execute(new  Runnable()  {  context:  listeners.add(listener);  }  public  void  remove(Listener  listener)  {  listeners.remove(listener);  }  public  void  nodeIndexDeleted(final  String  index,  final  String  nodeId)  throws  ElasticSearchException  {  DiscoveryNodes  nodes  =  clusterService.state().nodes();  if  (nodes.localNodeMaster())  {              threadPool.cached().execute(new  Runnable()  {              threadPool.generic().execute(new  Runnable()  {  public  void  run()  {  innerNodeIndexDeleted(index,  nodeId);  }  });  }  else  {  transportService.sendRequest(clusterService.state().nodes().masterNode(),  NodeIndexDeletedTransportHandler.ACTION,  new  NodeIndexDeletedMessage(index,  nodeId),  VoidTransportResponseHandler.INSTANCE_SAME);  	threadPool.generic().execute(new  Runnable()  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();  context:  assertThat(bucket,  notNullValue());  assertThat(key(bucket),  equalTo( " "  +  i));  assertThat(bucket.getKeyAsNumber().intValue(),  equalTo(i));  assertThat(bucket.getDocCount(),  equalTo(1l));  }  }  public  void  emptyAggregation()  throws  Exception  {  prepareCreate( "empty_bucket_idx ").addMapping( "type ",  SINGLE_VALUED_FIELD_NAME,   "type=integer ").execute().actionGet();          List<IndexRequestBuilder>  builders  =  new  ArrayList<IndexRequestBuilder>();          List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  for  (int  i  =  0;  i  <  2;  i++)  {  builders.add(client().prepareIndex( "empty_bucket_idx ",   "type ",   " "+i).setSource(jsonBuilder()  .startObject()  .field(SINGLE_VALUED_FIELD_NAME,  i*2)  .endObject()));  }  indexRandom(true,  builders.toArray(new  IndexRequestBuilder[builders.size()]));  	List<IndexRequestBuilder>  builders  =  new  ArrayList<>();  
libgdx_1a45313e2a9a5942bfa2689cccd89ee3d4fc88f2	buggy:  badlogic  =  spriteSheet.get( "badlogic ");  context:  public  class  SpriteSheetTest  extends  GdxTest  {  SpriteBatch  batch;  Sprite  badlogic,  badlogicSmall,  star;  SpriteSheet  spriteSheet;  public  void  create  ()  {  batch  =  new  SpriteBatch();  spriteSheet  =  new  SpriteSheet(Gdx.files.internal( "data/pack "),  Gdx.files.internal( "data "));  badlogic  =  spriteSheet.get( "badlogic ");  badlogic  =  spriteSheet.get( "badlogicslice ");  badlogicSmall  =  spriteSheet.get( "badlogicsmall ");  star  =  spriteSheet.get( "particle-star ");  badlogic.setPosition(50,  50);  badlogicSmall.setPosition(10,  10);  star.setPosition(10,  70);  Gdx.gl.glClearColor(0,  1,  0,  1);  	badlogic  =  spriteSheet.get( "badlogicslice ");  
elasticsearch_6823d50840c7d6cd0bb886cd7fcea68b3cbf0f7e	buggy:  }  else  if  (extractFieldNames  !=  null)  {  context:  }  else  {  fieldSelector  =  AllButSourceFieldSelector.INSTANCE;  }  }  else  if  (fieldSelectorMapper  !=  null)  {  fieldSelectorMapper.add(UidFieldMapper.NAME);  if  (extractFieldNames  !=  null)  {  fieldSelectorMapper.add(SourceFieldMapper.NAME);  }  fieldSelector  =  fieldSelectorMapper;              }  else  if  (extractFieldNames  !=  null)  {              }  else  if  (extractFieldNames  !=  null  ||  sourceRequested)  {  fieldSelector  =  new  UidAndSourceFieldSelector();  }  else  {  fieldSelector  =  UidFieldSelector.INSTANCE;  }  }  InternalSearchHit[]  hits  =  new  InternalSearchHit[context.docIdsToLoadSize()];  for  (int  index  =  0;  index  <  context.docIdsToLoadSize();  index++)  {  	}  else  if  (extractFieldNames  !=  null  ||  sourceRequested)  {  
elasticsearch_397f442c6dabf5cd2105ba01d6864fbbb22d11e2	buggy:  indexShard.start( "post  recovery  from  gateway ");  context:  public  void  recover(boolean  indexShouldExists,  RecoveryStatus  recoveryStatus)  throws  IndexShardGatewayRecoveryException  {  recoveryStatus.index().startTime(System.currentTimeMillis());  try  {  indexShard.store().deleteContent();  }  catch  (IOException  e)  {  }          indexShard.start( "post  recovery  from  gateway ");          indexShard.postRecovery( "post  recovery  from  gateway ");  recoveryStatus.index().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  recoveryStatus.translog().startTime(System.currentTimeMillis());  recoveryStatus.translog().time(System.currentTimeMillis()  -  recoveryStatus.index().startTime());  }  public  String  type()  {  return  NoneGateway.TYPE;  	indexShard.postRecovery( "post  recovery  from  gateway ");  
elasticsearch_54437c1bd3125c1e5cddbd1cad4a26fca03c002b	buggy:  System.out.println( "Indexed   "  +  (i  *  100)  +   "  took   "  +  stopWatch.stop().lastTaskTime());  context:  BulkRequestBuilder  request  =  client1.prepareBulk();  for  (int  j  =  0;  j  <  BATCH;  j++)  {  counter++;  request.add(Requests.indexRequest( "test ").type( "type1 ").id(Integer.toString(counter)).source(source(Integer.toString(counter),   "test "  +  counter)));  }  BulkResponse  response  =  request.execute().actionGet();  if  (response.hasFailures())  {  System.err.println( "failures... ");  }  if  (((i  *  BATCH)  %  10000)  ==  0)  {                  System.out.println( "Indexed   "  +  (i  *  100)  +   "  took   "  +  stopWatch.stop().lastTaskTime());                  System.out.println( "Indexed   "  +  (i  *  BATCH)  +   "  took   "  +  stopWatch.stop().lastTaskTime());  stopWatch.start();  }  }  client.client().admin().indices().prepareRefresh().execute().actionGet();  	System.out.println( "Indexed   "  +  (i  *  BATCH)  +   "  took   "  +  stopWatch.stop().lastTaskTime());  
elasticsearch_929bb3f2bef221181f11da30a691340029f6faa1	buggy:  .from(0).size(60).explain(true);  context:  searchPhaseController  =  ((InternalServer)  server( "server1 ")).injector().getInstance(SearchPhaseController.class);  }  closeAllServers();  }  SearchSourceBuilder  sourceBuilder  =  searchSource()  .query(termQuery( "multi ",   "test "))                  .from(0).size(60).explain(true);                  .from(0).size(60).explain(true).indexBoost( "test ",  1.0f).indexBoost( "test2 ",  2.0f);  List<DfsSearchResult>  dfsResults  =  newArrayList();  for  (ShardsIterator  shardsIt  :  indicesService.searchShards(clusterService.state(),  new  String[]{ "test "},  null))  {  for  (ShardRouting  shardRouting  :  shardsIt)  {  InternalSearchRequest  searchRequest  =  searchRequest(shardRouting,  sourceBuilder)  .scroll(new  Scroll(new  TimeValue(10,  TimeUnit.MINUTES)));  dfsResults.add(nodeToSearchService.get(shardRouting.currentNodeId()).executeDfsPhase(searchRequest));  }  	.from(0).size(60).explain(true).indexBoost( "test ",  1.0f).indexBoost( "test2 ",  2.0f);  
libgdx_de6e7376e909f3f92fb677e79412700f62ec513a	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.SpritePerformanteTest2(),   "Debug  Test ",  800,  600,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.SpritePerformanteTest2(),   "Debug  Test ",  800,  600,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  280,  100,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  280,  100,  false);  
elasticsearch_e1732d0a590098409d511821a7ddd99d3e72edf7	buggy:  if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  true))  {  context:  public  void  removeListener(Listener  listener)  {  listeners.remove(listener);  }  public  void  warm(final  ShardId  shardId,  final  Engine.Searcher  searcher)  {  final  IndexMetaData  indexMetaData  =  clusterService.state().metaData().index(shardId.index().name());  if  (indexMetaData  ==  null)  {  return;  }          if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  true))  {          if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  settings.getAsBoolean( "index.warm.enabled ",  true)))  {  return;  }  IndexService  indexService  =  indicesService.indexService(shardId.index().name());  if  (indexService  ==  null)  {  return;  }  IndexShard  indexShard  =  indexService.shard(shardId.id());  if  (indexShard  ==  null)  {  	if  (!indexMetaData.settings().getAsBoolean( "index.warm.enabled ",  settings.getAsBoolean( "index.warm.enabled ",  true)))  {  
elasticsearch_536930c751e6dc62946fa1382609464132f89e60	buggy:  return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]:  routing  [ "  +  routing  +   "] ";  context:  }  out.writeByte(versionType.getValue());  Versions.writeVersionWithVLongForBW(version,  out);  FetchSourceContext.optionalWriteToStream(fetchSourceContext,  out);  }  public  String  toString()  {          return   "[ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]:  routing  [ "  +  routing  +   "] ";          return   "get  [ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]:  routing  [ "  +  routing  +   "] ";  }  }  	return   "get  [ "  +  index  +   "][ "  +  type  +   "][ "  +  id  +   "]:  routing  [ "  +  routing  +   "] ";  
elasticsearch_2d1b841ba1db958d25c9818979494a7584a1d3fd	buggy:  HttpClient  httpClient  =  new  HttpClient( "http://localhost:9200/ ");  context:  private  void  assertPluginLoaded(String  pluginName)  {  NodesInfoResponse  nodesInfoResponse  =  client().admin().cluster().prepareNodesInfo().clear().setPlugin(true).get();  assertThat(nodesInfoResponse.getNodes().length,  equalTo(1));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos(),  notNullValue());  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().size(),  equalTo(1));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().get(0).getName(),  equalTo(pluginName));  assertThat(nodesInfoResponse.getNodes()[0].getPlugins().getInfos().get(0).isSite(),  equalTo(true));  }  private  void  assertPluginAvailable(String  pluginName)  {          HttpClient  httpClient  =  new  HttpClient( "http://localhost:9200/ ");          HttpClient  httpClient  =  new  HttpClient( "http://127.0.0.1:9200/ ");  HttpClientResponse  response  =  httpClient.request( "_plugin/ "  +  pluginName  +   "/ ");  assertThat(response.errorCode(),  Matchers.equalTo(RestStatus.OK.getStatus()));  }  public  void  before()  {  deletePluginsFolder();  }  	HttpClient  httpClient  =  new  HttpClient( "http://127.0.0.1:9200/ ");  
elasticsearch_1f9bceb5c54dfeade0326b90b74c39fe6ffe8aae	buggy:  listener.onFailure(new  InternalException(actionName,  request.getHeaders()));  context:  }  private  static  class  InternalTransportAction  extends  TransportAction  {  private  InternalTransportAction(Settings  settings,  String  actionName,  ThreadPool  threadPool)  {  super(settings,  actionName,  threadPool,  EMPTY_FILTERS);  }  protected  void  doExecute(ActionRequest  request,  ActionListener  listener)  {              listener.onFailure(new  InternalException(actionName,  request.getHeaders()));              listener.onFailure(new  InternalException(actionName,  request));  }  }  }  	listener.onFailure(new  InternalException(actionName,  request));  
libgdx_7cf9073b932279f418ecc3c18bfc0f7b09ccdfae	buggy:  if  (sizeNeeded  >=  items.length)  resize(Math.max(8,  sizeNeeded));  context:  public  void  shrink  ()  {  if  (items.length  ==  size)  return;  resize(size);  }  public  T[]  ensureCapacity  (int  additionalCapacity)  {  int  sizeNeeded  =  size  +  additionalCapacity;  if  (sizeNeeded  >=  items.length)  resize(Math.max(8,  sizeNeeded));  if  (sizeNeeded  >  items.length)  resize(Math.max(8,  sizeNeeded));  return  items;  }  protected  T[]  resize  (int  newSize)  {  T[]  items  =  this.items;  T[]  newItems  =  (T[])ArrayReflection.newInstance(items.getClass().getComponentType(),  newSize);  System.arraycopy(items,  0,  newItems,  0,  Math.min(size,  newItems.length));  	if  (sizeNeeded  >  items.length)  resize(Math.max(8,  sizeNeeded));  
libgdx_504d68c027e371fe01cf897125e2fd8c20339b39	buggy:  frameBuffer  =  new  FrameBuffer(Format.RGB565,  128,  128,  true);  context:  float  c2  =  Color.toFloatBits(255,  0,  0,  255);  ;  float  c3  =  Color.toFloatBits(0,  0,  255,  255);  ;  mesh.setVertices(new  float[]  {-0.5f,  -0.5f,  0,  c1,  0,  0,  0.5f,  -0.5f,  0,  c2,  1,  0,  0,  0.5f,  0,  c3,  0.5f,  1});  texture  =  new  Texture(Gdx.files.internal( "data/badlogic.jpg "));  spriteBatch  =  new  SpriteBatch();  frameBuffer  =  new  FrameBuffer(Format.RGB565,  128,  128,  true);  frameBuffer  =  new  FrameBuffer(Format.RGB565,  128,  128,  false);  createShader(Gdx.graphics);  }  private  void  createShader  (Graphics  graphics)  {  String  vertexShader  =   "attribute  vec4  a_Position;    \n "  +   "attribute  vec4  a_Color;\n "  +   "attribute  vec2  a_texCoords;\n "   "varying  vec4  v_Color; "  +   "varying  vec2  v_texCoords;  \n "  +   "void  main()                  \n "  +   "{                            \n "  +   "    v_Color  =  a_Color; "  	frameBuffer  =  new  FrameBuffer(Format.RGB565,  128,  128,  false);  
elasticsearch_22ea5e660888f363969d444e4fc8b6adfcfd7a27	buggy:  assertThat(routingTable.index( "test ").shard(0).backupsShards().get(0).currentNodeId(),  equalTo( "node3 "));  context:  clusterState  =  newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();  routingNodes  =  routingTable.routingNodes(metaData);  assertThat(prevRoutingTable  !=  routingTable,  equalTo(true));  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingNodes.node( "node1 "),  nullValue());  assertThat(routingNodes.node( "node2 ").numberOfShardsWithState(STARTED),  equalTo(1));  assertThat(routingNodes.node( "node3 ").numberOfShardsWithState(INITIALIZING),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).primaryShard().currentNodeId(),  equalTo( "node2 "));          assertThat(routingTable.index( "test ").shard(0).backupsShards().get(0).currentNodeId(),  equalTo( "node3 "));          assertThat(routingTable.index( "test ").shard(0).replicaShards().get(0).currentNodeId(),  equalTo( "node3 "));  }  private  DiscoveryNode  newNode(String  nodeId)  {  return  new  DiscoveryNode(nodeId,  DummyTransportAddress.INSTANCE);  }  }  	assertThat(routingTable.index( "test ").shard(0).replicaShards().get(0).currentNodeId(),  equalTo( "node3 "));  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  String  bodySettings  =  request.contentAsString();  context:  controller.registerHandler(RestRequest.Method.PUT,   "/{index}/_settings ",  this);  controller.registerHandler(RestRequest.Method.PUT,   "/_settings ",  this);  }  public  void  handleRequest(final  RestRequest  request,  final  RestChannel  channel)  {  UpdateSettingsRequest  updateSettingsRequest  =  updateSettingsRequest(splitIndices(request.param( "index ")));  updateSettingsRequest.listenerThreaded(false);  ImmutableSettings.Builder  updateSettings  =  ImmutableSettings.settingsBuilder();          String  bodySettings  =  request.contentAsString();          String  bodySettings  =  request.content().toUtf8();  if  (Strings.hasText(bodySettings))  {  try  {  updateSettings.put(ImmutableSettings.settingsBuilder().loadFromSource(bodySettings).build());  }  catch  (Exception  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  BAD_REQUEST,  new  SettingsException( "Failed  to  parse  index  settings ",  e)));  }  catch  (IOException  e1)  {  	String  bodySettings  =  request.content().toUtf8();  
libgdx_34ed5fbfe5d918ed411939d351930b0ab1457dd2	buggy:  attributes[idx++]  =  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +  i);  context:  }  return  vertices;  }  private  static  VertexAttribute[]  createVertexAttributes  (boolean  hasNormals,  int  uvs)  {  VertexAttribute[]  attributes  =  new  VertexAttribute[1  +  (hasNormals?1:0)  +  uvs];  int  idx  =  0;  attributes[idx++]  =  new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE);  if(hasNormals)  attributes[idx++]  =  new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE);  for(int  i  =  0;  i  <  uvs;  i++)  {  attributes[idx++]  =  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +  i);  attributes[idx++]  =  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +  i);  }  return  attributes;  }  private  static  FloatArray  readUVSet(BufferedReader  in,  int  numVertices,  boolean  flipV)  throws  IOException  {  FloatArray  uvSet  =  new  FloatArray(numVertices  *  2);  FloatArray  uv  =  new  FloatArray(2);  for(int  i  =  0;  i  <  numVertices;  i++)  {  	attributes[idx++]  =  new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +  i);  
elasticsearch_8247e4beaeef9c20b68ee9e785b6cae21cc62648	buggy:  bind(Engine.class).to(MockRobinEngine.class).asEagerSingleton();  context:  package  org.elasticsearch.test.engine;  public  class  MockEngineModule  extends  AbstractModule  {  protected  void  configure()  {          bind(Engine.class).to(MockRobinEngine.class).asEagerSingleton();          bind(Engine.class).to(MockInternalEngine.class).asEagerSingleton();  }  }  	bind(Engine.class).to(MockInternalEngine.class).asEagerSingleton();  
elasticsearch_a4c2087511327d7287181a64917c6831fb611c70	buggy:  }  else  if  (clusterState.blocks().hasGlobalBlock(GatewayService.NOT_RECOVERED_FROM_GATEWAY_BLOCK))  {  context:  response.activePrimaryShards  +=  indexHealth.activePrimaryShards;  response.activeShards  +=  indexHealth.activeShards;  response.relocatingShards  +=  indexHealth.relocatingShards;  response.initializingShards  +=  indexHealth.initializingShards;  response.unassignedShards  +=  indexHealth.unassignedShards;  }  response.status  =  ClusterHealthStatus.GREEN;  if  (!response.validationFailures().isEmpty())  {  response.status  =  ClusterHealthStatus.RED;          }  else  if  (clusterState.blocks().hasGlobalBlock(GatewayService.NOT_RECOVERED_FROM_GATEWAY_BLOCK))  {          }  else  if  (clusterState.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK))  {  response.status  =  ClusterHealthStatus.RED;  }  else  {  for  (ClusterIndexHealth  indexHealth  :  response)  {  if  (indexHealth.status()  ==  ClusterHealthStatus.RED)  {  response.status  =  ClusterHealthStatus.RED;  break;  }  if  (indexHealth.status()  ==  ClusterHealthStatus.YELLOW)  {  	}  else  if  (clusterState.blocks().hasGlobalBlock(GatewayService.STATE_NOT_RECOVERED_BLOCK))  {  
elasticsearch_ee585ad96c96040fccca79524e3c1f53d6294bd3	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  NodeService  nodeService;  ClusterService  clusterService,  TransportService  transportService,  NodeService  nodeService)  {  super(settings,  clusterName,  threadPool,  clusterService,  transportService);  this.nodeService  =  nodeService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Cluster.Node.STATS;  }  return   "/cluster/nodes/stats/node ";  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_720b550a94467347cbfe0b697bd1a1bafa57705b	buggy:  float  factor(int  docId);  context:  public  interface  ScoreFunction  {  void  setNextReader(AtomicReaderContext  context);  float  score(int  docId,  float  subQueryScore);      float  factor(int  docId);      double  factor(int  docId);  Explanation  explainScore(int  docId,  Explanation  subQueryExpl);  Explanation  explainFactor(int  docId);  }  	double  factor(int  docId);  
elasticsearch_d657d4447b85aa7fc441a8df167807da8be3c94b	buggy:  threadPool.execute(new  Runnable()  {  context:  }  private  void  notifyDisconnectedFromMaster()  {  for  (Listener  listener  :  listeners)  {  listener.onDisconnectedFromMaster();  }  }  private  void  notifyMasterFailure(final  DiscoveryNode  masterNode,  final  String  reason)  {  if  (notifiedMasterFailure.compareAndSet(false,  true))  {              threadPool.execute(new  Runnable()  {              threadPool.cached().execute(new  Runnable()  {  for  (Listener  listener  :  listeners)  {  listener.onMasterFailure(masterNode,  reason);  }  }  });  stop( "master  failure,   "  +  reason);  }  	threadPool.cached().execute(new  Runnable()  {  
elasticsearch_c4bed91262394fcc26a2e8d20a5570fe70539fd2	buggy:  payload  =  parser.bytesOrNull();  context:  }  }  else  if  (Fields.CONTENT_FIELD_NAME_PAYLOAD.equals(currentFieldName))  {  if  (!isStoringPayloads())  {  throw  new  MapperException( "Payloads  disabled  in  mapping ");  }  if  (token  ==  XContentParser.Token.START_OBJECT)  {  XContentBuilder  payloadBuilder  =  XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);  payload  =  payloadBuilder.bytes().toBytesRef();  payloadBuilder.close();  }  else  if  (token.isValue())  {                          payload  =  parser.bytesOrNull();                          payload  =  parser.utf8BytesOrNull();  }  else  {  throw  new  MapperException( "payload  doesn't  support  type   "  +  token);  }  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  (Fields.CONTENT_FIELD_NAME_OUTPUT.equals(currentFieldName))  {  surfaceForm  =  parser.text();  }  if  (Fields.CONTENT_FIELD_NAME_INPUT.equals(currentFieldName))  {  	payload  =  parser.utf8BytesOrNull();  
elasticsearch_306b3939cfba5f76f07af00ac451fba2ff12b260	buggy:  return  TransportActions.Admin.Indices.STATUS;  context:  IndicesService  indicesService)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  }  return  ThreadPool.Names.CACHED;  }          return  TransportActions.Admin.Indices.STATUS;          return  TransportActions.Admin.Indices.STATS;  }  return   "indices/stats/shard ";  }  return  new  IndicesStatsRequest();  	return  TransportActions.Admin.Indices.STATS;  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  datagramPacket.setData(builder.copiedBytes());  context:  MulticastSocket  multicastSocket  =  null;  try  {  multicastSocket  =  new  MulticastSocket(54328);  multicastSocket.setReceiveBufferSize(2048);  multicastSocket.setSendBufferSize(2048);  multicastSocket.setSoTimeout(60000);  DatagramPacket  datagramPacket  =  new  DatagramPacket(new  byte[2048],  2048,  InetAddress.getByName( "224.2.2.4 "),  54328);  XContentBuilder  builder  =  XContentFactory.jsonBuilder().startObject().startObject( "request ").field( "cluster_name ",   "test ").endObject().endObject();              datagramPacket.setData(builder.copiedBytes());              datagramPacket.setData(builder.bytes().toBytes());  multicastSocket.send(datagramPacket);  Thread.sleep(100);  }  finally  {  if  (multicastSocket  !=  null)  multicastSocket.close();  zenPingA.close();  threadPool.shutdown();  }  	datagramPacket.setData(builder.bytes().toBytes());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  messageReceived(final  Request  request,  final  TransportChannel  channel)  throws  Exception  {  request.listenerThreaded(false);  execute(request,  new  ActionListener<Response>()  {  public  void  onResponse(Response  result)  {  try  {  channel.sendResponse(result);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
elasticsearch_46088b9f8acc057414ba222809b1b6bc3e1a435e	buggy:  InternalCountAndTotalHistogramFacet.registerStreams();  context:  public  abstract  class  InternalHistogramFacet  implements  HistogramFacet,  InternalFacet  {  public  static  void  registerStreams()  {          InternalCountAndTotalHistogramFacet.registerStreams();          InternalFullHistogramFacet.registerStreams();  InternalCountHistogramFacet.registerStreams();  }  public  abstract  Facet  reduce(String  name,  List<Facet>  facets);  }  	InternalFullHistogramFacet.registerStreams();  
elasticsearch_684e6986279ddbacdacd5470e27eddc25207427e	buggy:  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  context:  if  (parentDocMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  filter  configured  'parent_type'  [ "  +  parentType  +   "]  is  not  a  valid  type ");  }  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;          for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {          for  (DocumentMapper  documentMapper  :  parseContext.mapperService().docMappers(false))  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  	for  (DocumentMapper  documentMapper  :  parseContext.mapperService().docMappers(false))  {  
elasticsearch_2c2783875e1befec504247f8e843a7c031bba92f	buggy:  ThreadPool  threadPool  =  new  ThreadPool();  context:  public  class  UnicastZenPingTests  extends  ElasticsearchTestCase  {  public  void  testSimplePings()  {  Settings  settings  =  ImmutableSettings.EMPTY;  int  startPort  =  11000  +  randomIntBetween(0,  1000);  int  endPort  =  startPort  +  10;  settings  =  ImmutableSettings.builder().put(settings).put( "transport.tcp.port ",  startPort  +   "- "  +  endPort).build();          ThreadPool  threadPool  =  new  ThreadPool();          ThreadPool  threadPool  =  new  ThreadPool(getClass().getName());  ClusterName  clusterName  =  new  ClusterName( "test ");  NetworkService  networkService  =  new  NetworkService(settings);  NettyTransport  transportA  =  new  NettyTransport(settings,  threadPool,  networkService,  BigArrays.NON_RECYCLING_INSTANCE,  Version.CURRENT);  final  TransportService  transportServiceA  =  new  TransportService(transportA,  threadPool).start();  final  DiscoveryNode  nodeA  =  new  DiscoveryNode( "UZP_A ",  transportServiceA.boundAddress().publishAddress(),  Version.CURRENT);  InetSocketTransportAddress  addressA  =  (InetSocketTransportAddress)  transportA.boundAddress().publishAddress();  	ThreadPool  threadPool  =  new  ThreadPool(getClass().getName());  
elasticsearch_3b5b4b4c3ab0c5fb4edf16832d4aaf09169bba5b	buggy:  SearchResponse  mltResponse  =  client1.moreLikeThis(moreLikeThisRequest( "test ").type( "type1 ").id( "1 ").minTermFrequency(1).minDocFreq(1)).actionGet();  context:  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.GREEN));  client1.index(indexRequest( "test ").type( "type1 ").id( "1 ").source(binaryJsonBuilder().startObject().field( "text ",   "lucene ").endObject())).actionGet();  client1.index(indexRequest( "test ").type( "type1 ").id( "2 ").source(binaryJsonBuilder().startObject().field( "text ",   "lucene  release ").endObject())).actionGet();  client1.admin().indices().refresh(refreshRequest()).actionGet();          SearchResponse  mltResponse  =  client1.moreLikeThis(moreLikeThisRequest( "test ").type( "type1 ").id( "1 ").minTermFrequency(1).minDocFreq(1)).actionGet();          SearchResponse  mltResponse  =  client1.moreLikeThis(moreLikeThisRequest( "test ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  assertThat(mltResponse.successfulShards(),  equalTo(5));  assertThat(mltResponse.failedShards(),  equalTo(0));  assertThat(mltResponse.hits().totalHits(),  equalTo(1l));  }  }  	SearchResponse  mltResponse  =  client1.moreLikeThis(moreLikeThisRequest( "test ").type( "type1 ").id( "1 ").minTermFreq(1).minDocFreq(1)).actionGet();  
elasticsearch_d06a15ec3e359c3704b52fbca9444f56cc8489ab	buggy:  throw  new  FacetPhaseExecutionException(facetName,   "No  mapping  found  for  value_field  [ "  +  keyField  +   "] ");  context:  }  }  IndexNumericFieldData  keyIndexFieldData  =  context.fieldData().getForField(keyFieldMapper);  if  (valueField  ==  null  ||  keyField.equals(valueField))  {  return  new  RangeFacetExecutor(keyIndexFieldData,  rangeEntries,  context);  }  else  {  FieldMapper  valueFieldMapper  =  context.smartNameFieldMapper(valueField);  if  (valueFieldMapper  ==  null)  {                  throw  new  FacetPhaseExecutionException(facetName,   "No  mapping  found  for  value_field  [ "  +  keyField  +   "] ");                  throw  new  FacetPhaseExecutionException(facetName,   "No  mapping  found  for  value_field  [ "  +  valueField  +   "] ");  }  IndexNumericFieldData  valueIndexFieldData  =  context.fieldData().getForField(valueFieldMapper);  return  new  KeyValueRangeFacetExecutor(keyIndexFieldData,  valueIndexFieldData,  rangeEntries,  context);  }  }  }  	throw  new  FacetPhaseExecutionException(facetName,   "No  mapping  found  for  value_field  [ "  +  valueField  +   "] ");  
elasticsearch_720e6a6d5b2e952265551438919af2c944dc6e19	buggy:  StringBuilder  sb  =  new  StringBuilder( "Routing  Table:\n ");  context:  public  static  void  writeTo(RoutingTable  table,  StreamOutput  out)  throws  IOException  {  out.writeVInt(table.indicesRouting.size());  for  (IndexRoutingTable  index  :  table.indicesRouting.values())  {  IndexRoutingTable.Builder.writeTo(index,  out);  }  }  }  public  String  prettyPrint()  {          StringBuilder  sb  =  new  StringBuilder( "Routing  Table:\n ");          StringBuilder  sb  =  new  StringBuilder( "routing_table:\n ");  for  (Map.Entry<String,  IndexRoutingTable>  entry  :  indicesRouting.entrySet())  {  sb.append(entry.getValue().prettyPrint()).append('\n');  }  return  sb.toString();  }  }  	StringBuilder  sb  =  new  StringBuilder( "routing_table:\n ");  
libgdx_8c1eb89354495c8efffe82f0e21ce339c881aa83	buggy:  gdxBulletJNI.ContactProcessedListenerByValue_onContactProcessed(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  userValue0,  match0,  userValue1,  match1);  context:  swigCMemOwn  =  false;  gdxBulletJNI.ContactProcessedListenerByValue_change_ownership(this,  swigCPtr,  false);  }  public  void  swigTakeOwnership()  {  swigCMemOwn  =  true;  gdxBulletJNI.ContactProcessedListenerByValue_change_ownership(this,  swigCPtr,  true);  }  public  void  onContactProcessed(btManifoldPoint  cp,  int  userValue0,  boolean  match0,  int  userValue1,  boolean  match1)  {      gdxBulletJNI.ContactProcessedListenerByValue_onContactProcessed(swigCPtr,  this,  btManifoldPoint.getCPtr(cp),  cp,  userValue0,  match0,  userValue1,  match1);      gdxBulletJNI.ContactProcessedListenerByValue_onContactProcessed(swigCPtr,  this,  cp,  userValue0,  match0,  userValue1,  match1);  }  public  ContactProcessedListenerByValue()  {  this(gdxBulletJNI.new_ContactProcessedListenerByValue(),  true);  gdxBulletJNI.ContactProcessedListenerByValue_director_connect(this,  swigCPtr,  swigCMemOwn,  true);  }  }  	gdxBulletJNI.ContactProcessedListenerByValue_onContactProcessed(swigCPtr,  this,  cp,  userValue0,  match0,  userValue1,  match1);  
elasticsearch_3b21759bec0a668970de0ba0ef92af64dc9f866e	buggy:  query  =  smartNameFieldMappers.mapper().fieldQuery(value);  context:  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  term  query ");  }  Query  query  =  null;  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  query  =  smartNameFieldMappers.mapper().fieldQuery(value);                  query  =  smartNameFieldMappers.mapper().fieldQuery(value,  parseContext);  }  }  if  (query  ==  null)  {  query  =  new  TermQuery(new  Term(fieldName,  value));  }  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext);  }  	query  =  smartNameFieldMappers.mapper().fieldQuery(value,  parseContext);  
elasticsearch_a8969cd672cd025ecb2cd82356113980dd204327	buggy:  return  ThreadPool.Names.CACHED;  context:  private  final  MetaDataUpdateSettingsService  updateSettingsService;  MetaDataUpdateSettingsService  updateSettingsService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.updateSettingsService  =  updateSettingsService;  }          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.MANAGEMENT;  }  return  TransportActions.Admin.Indices.UPDATE_SETTINGS;  }  return  new  UpdateSettingsRequest();  	return  ThreadPool.Names.MANAGEMENT;  
elasticsearch_8d7aaa704a644569359e6a1cddc9e2c10b34da79	buggy:  FileSystemUtils.deleteRecursively(nodeEnv.indexLocation(new  Index(index)));  context:  indexInjector.getInstance(IndexGateway.class).close(delete);  indexInjector.getInstance(MapperService.class).close();  indexInjector.getInstance(IndexQueryParserService.class).close();  Injectors.close(injector);  indicesLifecycle.afterIndexClosed(indexService.index(),  delete);  if  (delete)  {              FileSystemUtils.deleteRecursively(nodeEnv.indexLocation(new  Index(index)));              FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(index)));  }  }  static  class  OldShardsStats  extends  IndicesLifecycle.Listener  {  final  SearchStats  searchStats  =  new  SearchStats();  final  GetStats  getStats  =  new  GetStats();  final  IndexingStats  indexingStats  =  new  IndexingStats();  	FileSystemUtils.deleteRecursively(nodeEnv.indexLocations(new  Index(index)));  
libgdx_3514decccff3cc1c4dd48b7f3db98f89830ba87e	buggy:  listener.cancled();  context:  return  0;  }  SwingUtilities.invokeLater(new  Runnable()  {  String  output  =  JOptionPane.showInputDialog(null,  title,  text);  if  (output  !=  null)  listener.input(output);  else  listener.cancled();  listener.canceled();  }  });  }  return  touchX;  }  	listener.canceled();  
elasticsearch_0e6bbf3f8526b4eb33a004f19c2213a94652957c	buggy:  engine.refresh(new  Engine.Refresh(false));  context:  if  (state  !=  IndexShardState.CLOSED)  {  refreshScheduledFuture  =  threadPool.schedule(refreshInterval,  ThreadPool.Names.SAME,  this);  }  }  return;  }  threadPool.cached().execute(new  Runnable()  {  try  {  if  (engine.refreshNeeded())  {                              engine.refresh(new  Engine.Refresh(false));                              refresh(new  Engine.Refresh(false));  }  }  catch  (EngineClosedException  e)  {  }  catch  (RefreshFailedEngineException  e)  {  if  (e.getCause()  instanceof  InterruptedException)  {  }  else  if  (e.getCause()  instanceof  ClosedByInterruptException)  {  	refresh(new  Engine.Refresh(false));  
elasticsearch_529b9c8b39cdf8becf5df17acc9df814e4dab68b	buggy:  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();  context:  public  boolean  doRestart(String  nodeName)  {  return  !nodeToRemove.equals(nodeName);  }  });  assertThat(awaitBusy(new  Predicate<Object>()  {  public  boolean  apply(Object  input)  {                  ClusterStateResponse  clusterStateResponse  =  client().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();                  ClusterStateResponse  clusterStateResponse  =  cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();  return  !clusterStateResponse.getState().routingTable().index( "test ").allPrimaryShardsActive();  }  },  30,  TimeUnit.SECONDS),  equalTo(true));  client().admin().indices().prepareUpdateSettings( "test ").setSettings(settingsBuilder().put( "recovery.initial_shards ",  1)).get();  	ClusterStateResponse  clusterStateResponse  =  cluster().smartClient().admin().cluster().prepareState().setMasterNodeTimeout( "500ms ").get();  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  request.indices(clusterService.state().metaData().concreteIndices(request.indices()));  context:  }  protected  DeleteWarmerResponse  newResponse()  {  return  new  DeleteWarmerResponse();  }  protected  void  doExecute(DeleteWarmerRequest  request,  ActionListener<DeleteWarmerResponse>  listener)  {          request.indices(clusterService.state().metaData().concreteIndices(request.indices()));          request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  super.doExecute(request,  listener);  }  protected  ClusterBlockException  checkBlock(DeleteWarmerRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  	request.indices(clusterService.state().metaData().concreteIndices(request.indices(),  request.indicesOptions()));  
elasticsearch_a2d72697eba5bc15c6b2b40f40bee4606141da2f	buggy:  stats.stats.fieldData  =  indexShard.fieldDataStats();  context:  if  (request.request.warmer())  {  stats.stats.warmer  =  indexShard.warmerStats();  }  if  (request.request.filterCache())  {  stats.stats.filterCache  =  indexShard.filterCacheStats();  }  if  (request.request.idCache())  {  stats.stats.idCache  =  indexShard.idCacheStats();  }  if  (request.request.fieldData())  {              stats.stats.fieldData  =  indexShard.fieldDataStats();              stats.stats.fieldData  =  indexShard.fieldDataStats(request.request.fieldDataFields());  }  return  stats;  }  public  static  class  IndexShardStatsRequest  extends  BroadcastShardOperationRequest  {  	stats.stats.fieldData  =  indexShard.fieldDataStats(request.request.fieldDataFields());  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  assertThat(nodesMap.size(),  equalTo(immutableCluster().size()));  context:  type  =  null;  }  final  CountDownLatch  latch  =  new  CountDownLatch(1);  nodesHotThreadsRequestBuilder.execute(new  ActionListener<NodesHotThreadsResponse>()  {  public  void  onResponse(NodesHotThreadsResponse  nodeHotThreads)  {  boolean  success  =  false;  try  {  assertThat(nodeHotThreads,  notNullValue());  Map<String,NodeHotThreads>  nodesMap  =  nodeHotThreads.getNodesMap();                          assertThat(nodesMap.size(),  equalTo(immutableCluster().size()));                          assertThat(nodesMap.size(),  equalTo(cluster().size()));  for  (NodeHotThreads  ht  :  nodeHotThreads)  {  assertNotNull(ht.getHotThreads());  }  success  =  true;  }  finally  {  if  (!success)  {  hasErrors.set(true);  	assertThat(nodesMap.size(),  equalTo(cluster().size()));  
elasticsearch_bc0c7f8f28ac5d8e6ec1d9e4624d552168ba582f	buggy:  TreeSet<HashedBytesArray>  parentTypes  =  new  TreeSet<HashedBytesArray>(UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder);  context:  synchronized  (idReaders)  {  if  (!refreshNeeded(atomicReaderContexts))  {  return;  }  Map<Object,  Map<String,  TypeBuilder>>  builders  =  new  HashMap<Object,  Map<String,  TypeBuilder>>();  Map<Object,  IndexReader>  cacheToReader  =  new  HashMap<Object,  IndexReader>();                  TreeSet<HashedBytesArray>  parentTypes  =  new  TreeSet<HashedBytesArray>(UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder);                  NavigableSet<HashedBytesArray>  parentTypes  =  new  TreeSet<HashedBytesArray>(UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder);  for  (String  type  :  indexService.mapperService().types())  {  ParentFieldMapper  parentFieldMapper  =  indexService.mapperService().documentMapper(type).parentFieldMapper();  if  (parentFieldMapper  !=  null)  {  parentTypes.add(new  HashedBytesArray(parentFieldMapper.type()));  }  }  	NavigableSet<HashedBytesArray>  parentTypes  =  new  TreeSet<HashedBytesArray>(UTF8SortedAsUnicodeComparator.utf8SortedAsUnicodeSortOrder);  
elasticsearch_526b46402530817f63c4c70ed382fee34b8b7cf3	buggy:  public  Set<String>  simpleMatchToIndexNames(String  pattern)  {  context:  }  public  String  indexName(String  name)  {  FieldMapper  smartMapper  =  fieldMapper(name);  if  (smartMapper  ==  null)  {  return  name;  }  return  smartMapper.names().indexName();  }      public  Set<String>  simpleMatchToIndexNames(String  pattern)  {      public  List<String>  simpleMatchToIndexNames(String  pattern)  {  return  indexQueryParser.mapperService.simpleMatchToIndexNames(pattern,  getTypes());  }  public  MapperService.SmartNameFieldMappers  smartFieldMappers(String  name)  {  return  failIfFieldMappingNotFound(name,  indexQueryParser.mapperService.smartName(name,  getTypes()));  }  public  FieldMapper  smartNameFieldMapper(String  name)  {  	public  List<String>  simpleMatchToIndexNames(String  pattern)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  PlainListenableActionFuture<Response>  future  =  new  PlainListenableActionFuture<Response>(request.listenerThreaded(),  client.threadPool());  context:  return  (RequestBuilder)  this;  }  public  final  RequestBuilder  putHeader(String  key,  Object  value)  {  request.putHeader(key,  value);  return  (RequestBuilder)  this;  }  public  ListenableActionFuture<Response>  execute()  {          PlainListenableActionFuture<Response>  future  =  new  PlainListenableActionFuture<Response>(request.listenerThreaded(),  client.threadPool());          PlainListenableActionFuture<Response>  future  =  new  PlainListenableActionFuture<>(request.listenerThreaded(),  client.threadPool());  execute(future);  return  future;  }  public  Response  get()  throws  ElasticsearchException  {  	PlainListenableActionFuture<Response>  future  =  new  PlainListenableActionFuture<>(request.listenerThreaded(),  client.threadPool());  
elasticsearch_7972f6f95903602f329dc3317ffab258d75911e1	buggy:  indexWriter.expungeDeletes(false);  context:  if  (optimizeMutex.compareAndSet(false,  true))  {  rwl.readLock().lock();  try  {  if  (indexWriter  ==  null)  {  throw  new  EngineClosedException(shardId,  failedEngine);  }  if  (indexWriter.getConfig().getMergePolicy()  instanceof  EnableMergePolicy)  {  ((EnableMergePolicy)  indexWriter.getConfig().getMergePolicy()).enableMerge();  }  if  (optimize.onlyExpungeDeletes())  {                      indexWriter.expungeDeletes(false);                      indexWriter.forceMergeDeletes(false);  }  else  if  (optimize.maxNumSegments()  <=  0)  {  indexWriter.maybeMerge();  possibleMergeNeeded  =  false;  }  else  {  indexWriter.forceMerge(optimize.maxNumSegments(),  false);  }  }  catch  (OutOfMemoryError  e)  {  failEngine(e);  	indexWriter.forceMergeDeletes(false);  
elasticsearch_ab6163898fd8c83dda01b6eb4dd42e1f900f393b	buggy:  masterOperation(request,  clusterState,  listener);  context:  clusterService.remove(this);  innerExecute(request,  listener,  false);  }  }  });  }  else  {  threadPool.executor(executor).execute(new  Runnable()  {  public  void  run()  {  try  {                              masterOperation(request,  clusterState,  listener);                              masterOperation(request,  clusterService.state(),  listener);  }  catch  (Throwable  e)  {  listener.onFailure(e);  }  }  });  }  }  else  {  if  (nodes.masterNode()  ==  null)  {  	masterOperation(request,  clusterService.state(),  listener);  
libgdx_9342bc7d93397d3f4915f4bda17f3376a70e27c1	buggy:  Texture  texture  =  new  Texture(Gdx.files.internal( "data/nskingr.jpg "));  context:  float  angle  =  0;  SpriteBatch  batch;  BitmapFont  font;  List<String>  animNames  =  new  ArrayList<String>();  String  animation;  float  time  =  0;  int  currAnimIdx  =  0;  Texture  texture  =  new  Texture(Gdx.files.internal( "data/nskingr.jpg "));  Texture  texture  =  new  Texture(Gdx.files.internal( "data/ninja.jpg "));  Material  mat  =  new  Material( "mat ",  new  TextureAttribute(texture,  0,   "s_tex "));  model  =  new  OgreXmlLoader().load(Gdx.files.internal( "data/ninja.mesh.xml "),  Gdx.files.internal( "data/ninja.skeleton.xml "));  model.setMaterial(mat);  cam  =  new  PerspectiveCamera(67,  Gdx.graphics.getWidth(),  Gdx.graphics.getHeight());  BoundingBox  bounds  =  model.subMeshes[0].mesh.calculateBoundingBox();  cam.position.set(bounds.getCenter().cpy().add(100,  100,  100));  	Texture  texture  =  new  Texture(Gdx.files.internal( "data/ninja.jpg "));  
libgdx_4b2c47746857998f18e311d9dacb458c23afbef8	buggy:  if  (app  instanceof  AndroidFragmentApplication)  {  context:  synch.notifyAll();  }  if  (destroy)  {  destroy  =  false;  synch.notifyAll();  }  }  if  (lresume)  {  if  (app  instanceof  AndroidFragmentApplication)  {  if  (app.isFragment())  {  ((AndroidAudio)((AndroidApplicationBase)app).getAudio()).resume();  }  Array<LifecycleListener>  listeners  =  ((AndroidApplicationBase)app).getLifecycleListeners();  synchronized  (listeners)  {  for  (LifecycleListener  listener  :  listeners)  {  listener.resume();  }  }  	if  (app.isFragment())  {  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  indexTemplateService.putTemplate(new  MetaDataIndexTemplateService.PutRequest(request.cause(),  request.name())  context:  protected  PutIndexTemplateResponse  masterOperation(PutIndexTemplateRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  String  cause  =  request.cause();  if  (cause.length()  ==  0)  {  cause  =   "api ";  }  final  AtomicReference<PutIndexTemplateResponse>  responseRef  =  new  AtomicReference<PutIndexTemplateResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          indexTemplateService.putTemplate(new  MetaDataIndexTemplateService.PutRequest(request.cause(),  request.name())          indexTemplateService.putTemplate(new  MetaDataIndexTemplateService.PutRequest(request.cause(),  request.getName())  .template(request.template())  .order(request.order())  .settings(request.settings())  .mappings(request.mappings())  .customs(request.customs())  .create(request.create()),  new  MetaDataIndexTemplateService.PutListener()  {  	indexTemplateService.putTemplate(new  MetaDataIndexTemplateService.PutRequest(request.cause(),  request.getName())  
elasticsearch_fd6798df699c1a9e755d02c85ea6f6603cf07ec7	buggy:  +  restResponse.getStatusCode()  +   "   "  +  restResponse.getReasonPhrase()  +   "]  [ "  +  restResponse.getBody()  +   "] ";  context:  }  private  void  assertStatusCode(RestResponse  restResponse)  {  Tuple<String,  org.hamcrest.Matcher<Integer>>  stringMatcherTuple  =  catches.get(catchParam);  assertThat(formatStatusCodeMessage(restResponse,  stringMatcherTuple.v1()),  restResponse.getStatusCode(),  stringMatcherTuple.v2());  }  private  String  formatStatusCodeMessage(RestResponse  restResponse,  String  expected)  {  return   "expected  [ "  +  expected  +   "]  status  code  but  api  [ "  +  apiCallSection.getApi()  +   "]  returned  [ "                  +  restResponse.getStatusCode()  +   "   "  +  restResponse.getReasonPhrase()  +   "]  [ "  +  restResponse.getBody()  +   "] ";                  +  restResponse.getStatusCode()  +   "   "  +  restResponse.getReasonPhrase()  +   "]  [ "  +  restResponse.getBodyAsString()  +   "] ";  }  private  static  Map<String,  Tuple<String,  org.hamcrest.Matcher<Integer>>>  catches  =  Maps.newHashMap();  static  {  catches.put( "missing ",  tuple( "404 ",  equalTo(404)));  catches.put( "conflict ",  tuple( "409 ",  equalTo(409)));  catches.put( "forbidden ",  tuple( "403 ",  equalTo(403)));  	+  restResponse.getStatusCode()  +   "   "  +  restResponse.getReasonPhrase()  +   "]  [ "  +  restResponse.getBodyAsString()  +   "] ";  
elasticsearch_94cf1411088e78eef1c7fb6cf8bc59fbde2f0720	buggy:  xcb.field( "language ",  forcedLanguage[0]);  context:  byte[]  html  =  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/ "  +  filename);  XContentBuilder  xcb  =  jsonBuilder()  .startObject()  .field( "_id ",  1)  .startObject( "file ")  .field( "_name ",  filename)  .field( "content ",  html);  if  (forcedLanguage.length  >  0)  {              xcb.field( "language ",  forcedLanguage[0]);              xcb.field( "_language ",  forcedLanguage[0]);  }  xcb.endObject().endObject();  ParseContext.Document  doc  =  docMapper.parse(xcb.bytes()).rootDoc();  assertThat(doc.get(docMapper.mappers().smartName( "file.language ").mapper().names().indexName()),  equalTo(expected));  	xcb.field( "_language ",  forcedLanguage[0]);  
elasticsearch_c20713530d2429346536354f297c96dea4353329	buggy:  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  context:  builder.put(SearchService.KEEPALIVE_INTERVAL_KEY,  TimeValue.timeValueSeconds(10  +  random.nextInt(5  *  60)));  }  if  (random.nextBoolean())  {  //  sometimes  set  a  builder.put(SearchService.DEFAUTL_KEEPALIVE_KEY,  TimeValue.timeValueSeconds(100  +  random.nextInt(5*60)));  }  if  (random.nextBoolean())  {  for  (String  name  :  Arrays.asList(ThreadPool.Names.BULK,  ThreadPool.Names.FLUSH,  ThreadPool.Names.GET,  ThreadPool.Names.INDEX,  ThreadPool.Names.MANAGEMENT,  ThreadPool.Names.MERGE,  ThreadPool.Names.OPTIMIZE,  ThreadPool.Names.PERCOLATE,  ThreadPool.Names.REFRESH,  ThreadPool.Names.SEARCH,  ThreadPool.Names.SNAPSHOT,                      ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {                      ThreadPool.Names.SNAPSHOT_DATA,  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  if  (random.nextBoolean())  {  final  String  type  =  RandomPicks.randomFrom(random,  Arrays.asList( "fixed ",   "cached ",   "scaling "));  builder.put(ThreadPool.THREADPOOL_GROUP  +  name  +   ".type ",  type);  }  }  }  builder.put( "plugins.isolation ",  random.nextBoolean());  builder.put(InternalGlobalOrdinalsBuilder.ORDINAL_MAPPING_THRESHOLD_INDEX_SETTING_KEY,  1  +  random.nextInt(InternalGlobalOrdinalsBuilder.ORDINAL_MAPPING_THRESHOLD_DEFAULT));  	ThreadPool.Names.SNAPSHOT_DATA,  ThreadPool.Names.SUGGEST,  ThreadPool.Names.WARMER))  {  
elasticsearch_235a68c3bdf65c2f0d6bebc63ebbb7737d949983	buggy:  stateIndexService.openIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()),  new  MetaDataStateIndexService.Listener()  {  context:  protected  ClusterBlockException  checkBlock(OpenIndexRequest  request,  ClusterState  state)  {  return  state.blocks().indicesBlockedException(ClusterBlockLevel.METADATA,  request.indices());  }  protected  OpenIndexResponse  masterOperation(OpenIndexRequest  request,  ClusterState  state)  throws  ElasticSearchException  {  final  AtomicReference<OpenIndexResponse>  responseRef  =  new  AtomicReference<OpenIndexResponse>();  final  AtomicReference<Throwable>  failureRef  =  new  AtomicReference<Throwable>();  final  CountDownLatch  latch  =  new  CountDownLatch(1);          stateIndexService.openIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()),  new  MetaDataStateIndexService.Listener()  {          stateIndexService.openIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataStateIndexService.Listener()  {  public  void  onResponse(MetaDataStateIndexService.Response  response)  {  responseRef.set(new  OpenIndexResponse(response.acknowledged()));  latch.countDown();  }  public  void  onFailure(Throwable  t)  {  	stateIndexService.openIndex(new  MetaDataStateIndexService.Request(request.indices()).timeout(request.timeout()).masterTimeout(request.masterNodeTimeout()),  new  MetaDataStateIndexService.Listener()  {  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  public  abstract  boolean  clearAndRelease();  context:  public  static  void  removeCurrent()  {  current.remove();  QueryParseContext.removeTypes();  }  public  static  SearchContext  current()  {  return  current.get();  }      public  abstract  boolean  clearAndRelease();      public  abstract  void  clearAndRelease();  public  abstract  void  preProcess();  public  abstract  Filter  searchFilter(String[]  types);  	public  abstract  void  clearAndRelease();  
elasticsearch_a76620e3ac9db256c7891ba922e5483ddac44954	buggy:  cluster2  =  new  TestCluster(randomLong(),  2,  cluster().getClusterName()  +   "-2 ");  context:  public  class  TribeTests  extends  ElasticsearchIntegrationTest  {  private  TestCluster  cluster2;  private  Node  tribeNode;  private  Client  tribeClient;  public  void  setupSecondCluster()  {          cluster2  =  new  TestCluster(randomLong(),  2,  cluster().getClusterName()  +   "-2 ");          cluster2  =  new  TestCluster(randomLong(),  2,  2,  cluster().getClusterName()  +   "-2 ");  cluster2.beforeTest(getRandom(),  getPerTestTransportClientRatio());  cluster2.ensureAtLeastNumNodes(2);  Settings  settings  =  ImmutableSettings.builder()  .put( "tribe.t1.cluster.name ",  cluster().getClusterName())  .put( "tribe.t2.cluster.name ",  cluster2.getClusterName())  .build();  	cluster2  =  new  TestCluster(randomLong(),  2,  2,  cluster().getClusterName()  +   "-2 ");  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  fieldName  =  smartNameFieldMappers.mapper().indexName();  context:  jp.nextToken();  }  if  (value  ==  null)  {  throw  new  QueryParsingException(index,   "No  value  specified  for  prefix  query ");  }  MapperService.SmartNameFieldMappers  smartNameFieldMappers  =  parseContext.smartFieldMappers(fieldName);  if  (smartNameFieldMappers  !=  null)  {  if  (smartNameFieldMappers.hasMapper())  {                  fieldName  =  smartNameFieldMappers.mapper().indexName();                  fieldName  =  smartNameFieldMappers.mapper().names().indexName();  value  =  smartNameFieldMappers.mapper().indexedValue(value);  }  }  WildcardQuery  query  =  new  WildcardQuery(new  Term(fieldName,  value));  query.setRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);  query.setBoost(boost);  return  wrapSmartNameQuery(query,  smartNameFieldMappers,  parseContext.filterCache());  	fieldName  =  smartNameFieldMappers.mapper().names().indexName();  
elasticsearch_fe3f5d45deb9862ae5399bebcb2b6ac0321f7705	buggy:  clusterState  =  ClusterState.Builder.readFrom(in,  null,  null);  context:  public  ClusterName  clusterName()  {  return  this.clusterName;  }  public  ClusterName  getClusterName()  {  return  clusterName();  }  clusterName  =  ClusterName.readClusterName(in);          clusterState  =  ClusterState.Builder.readFrom(in,  null,  null);          clusterState  =  ClusterState.Builder.readFrom(in,  null);  }  clusterName.writeTo(out);  ClusterState.Builder.writeTo(clusterState,  out);  }  }  	clusterState  =  ClusterState.Builder.readFrom(in,  null);  
elasticsearch_a8281065535d6e140c5d563d6487ad2a160605e0	buggy:  throw  new  QueryPhaseExecutionException(searchContext,  e);  context:  }  TopDocs  topDocs;  if  (searchContext.sort()  !=  null)  {  topDocs  =  searchContext.searcher().search(query,  null,  searchContext.from()  +  searchContext.size(),  searchContext.sort());  }  else  {  topDocs  =  searchContext.searcher().search(query,  searchContext.from()  +  searchContext.size());  }  searchContext.queryResult().topDocs(topDocs);  }  catch  (Exception  e)  {              throw  new  QueryPhaseExecutionException(searchContext,  e);              throw  new  QueryPhaseExecutionException(searchContext,   " ",  e);  }  facetsPhase.execute(searchContext);  }  }  	throw  new  QueryPhaseExecutionException(searchContext,   " ",  e);  
elasticsearch_5205a183e8324b53c2a2ac1c6b78b3403f56f765	buggy:  Query  query  =  new  ConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));  context:  if  (context.facets()  ==  null)  {  return;  }  if  (context.queryResult().facets()  !=  null)  {  return;  }  if  (context.searcher().globalCollectors()  !=  null)  {              Query  query  =  new  ConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));              Query  query  =  new  DeletionAwareConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));  if  (context.types().length  >  0)  {  if  (context.types().length  ==  1)  {  String  type  =  context.types()[0];  DocumentMapper  docMapper  =  context.mapperService().documentMapper(type);  Filter  typeFilter  =  new  TermFilter(docMapper.typeMapper().term(docMapper.type()));  typeFilter  =  context.filterCache().cache(typeFilter);  query  =  new  FilteredQuery(query,  typeFilter);  }  else  {  	Query  query  =  new  DeletionAwareConstantScoreQuery(context.filterCache().cache(Queries.MATCH_ALL_FILTER));  
elasticsearch_c0a7dc327c547e22f45dfc9f25090255969bb3f6	buggy:  return  new  InternalRangeDistanceFacet(facetName,  fieldName,  fieldName,  entries);  context:  fieldData  =  (NumericFieldData)  fieldDataCache.cache(fieldDataType,  reader,  indexFieldName);  }  fieldData.forEachValueInDoc(doc,  rangeProc);  }          return  new  InternalRangeDistanceFacet(facetName,  fieldName,  fieldName,  entries);          return  new  InternalRangeFacet(facetName,  fieldName,  fieldName,  entries);  }  public  static  class  RangeProc  implements  NumericFieldData.DoubleValueInDocProc  {  private  final  RangeFacet.Entry[]  entries;  public  RangeProc(RangeFacet.Entry[]  entries)  {  this.entries  =  entries;  	return  new  InternalRangeFacet(facetName,  fieldName,  fieldName,  entries);  
elasticsearch_cdc7dfbb2c33c3b243837b39c6a63c271a99940f	buggy:  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {  context:  XContentParser.Token  token;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.VALUE_STRING)  {  if  ( "field ".equals(currentFieldName))  {  field  =  parser.text();  }  else  if  ( "script ".equals(currentFieldName))  {  script  =  parser.text();                  }  else  if  ( "script_lang ".equals(currentFieldName)  ||   "scriptLang ".equals(currentFieldName))  {                  }  else  if  ( "lang ".equals(currentFieldName))  {  scriptLang  =  parser.text();  }  else  if  ( "value_type ".equals(currentFieldName)  ||   "valueType ".equals(currentFieldName))  {  valueType  =  Terms.ValueType.resolveType(parser.text());  }  else  if  ( "format ".equals(currentFieldName))  {  format  =  parser.text();  }  else  if  ( "include ".equals(currentFieldName))  {  include  =  parser.text();  }  else  if  ( "exclude ".equals(currentFieldName))  {  	}  else  if  ( "lang ".equals(currentFieldName))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Set<String>  expected  =  new  HashSet<String>();  context:  List<AtomicReaderContext>  leaves  =  reader.leaves();  assertThat(leaves.size(),  equalTo(1));  AtomicReader  ar  =  leaves.get(0).reader();  Terms  terms  =  ar.terms( "foo ");  Terms  some_other_field  =  ar.terms( "some_other_field ");  assertThat(terms.size(),  equalTo(2l));  assertThat(terms,  not(instanceOf(BloomFilterPostingsFormat.BloomFilteredTerms.class)));  assertThat(some_other_field,  not(instanceOf(BloomFilterPostingsFormat.BloomFilteredTerms.class)));  TermsEnum  iterator  =  terms.iterator(null);          Set<String>  expected  =  new  HashSet<String>();          Set<String>  expected  =  new  HashSet<>();  expected.add( "foo ");  expected.add( "bar ");  while(iterator.next()  !=  null)  {  expected.remove(iterator.term().utf8ToString());  }  assertThat(expected.size(),  equalTo(0));  reader.close();  writer.close();  	Set<String>  expected  =  new  HashSet<>();  
libgdx_213109c115e65588b265650eee80fad7652b2129	buggy:  }  catch  (Exception  e)  {  context:  return  new  JoglAudioDevice(isMono);  }  try  {  JoglMusic  music  =  new  JoglMusic(((JoglFileHandle)file));  return  music;  }  catch  (Exception  e)  {  }  catch  (Throwable  e)  {  throw  new  GdxRuntimeException( "Couldn't  create  Music  instance  from  file  ' "  +  file  +   "' ",  e);  }  }  	}  catch  (Throwable  e)  {  
elasticsearch_57023c8ba93a5c43793c4e109e1c020d00eebc80	buggy:  StreamOutput  stream  =  cachedEntry.cachedHandles(CompressorFactory.defaultCompressor());  context:  transportService.removeHandler(PublishClusterStateRequestHandler.ACTION);  }  public  void  publish(ClusterState  clusterState)  {  DiscoveryNode  localNode  =  nodesProvider.nodes().localNode();  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  byte[]  clusterStateInBytes;  try  {              StreamOutput  stream  =  cachedEntry.cachedHandles(CompressorFactory.defaultCompressor());              StreamOutput  stream  =  cachedEntry.handles(CompressorFactory.defaultCompressor());  ClusterState.Builder.writeTo(clusterState,  stream);  stream.close();  clusterStateInBytes  =  cachedEntry.bytes().copiedByteArray();  }  catch  (Exception  e)  {  return;  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  	StreamOutput  stream  =  cachedEntry.handles(CompressorFactory.defaultCompressor());  
libgdx_fb3d5f7fca120b4a94b2941fab57e5cec568d88b	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.UITest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.MeshMultitextureTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.MeshMultitextureTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_32201c762b739e0aeb4370fad2baed424caefe19	buggy:  Settings  settings  =  ImmutableSettings.builder().put( "client.transport.nodes_sampler_interval ",   "1s ")  context:  public  class  TransportClientBackwardsCompatibilityTest  extends  ElasticsearchBackwardsCompatIntegrationTest  {  public  void  testSniffMode()  throws  ExecutionException,  InterruptedException  {          Settings  settings  =  ImmutableSettings.builder().put( "client.transport.nodes_sampler_interval ",   "1s ")          Settings  settings  =  ImmutableSettings.builder().put(requiredSettings()).put( "client.transport.nodes_sampler_interval ",   "1s ")  .put( "name ",   "transport_client_sniff_mode ").put(ClusterName.SETTING,  cluster().getClusterName())  .put( "client.transport.sniff ",  true).build();  CompositeTestCluster  compositeTestCluster  =  backwardsCluster();  TransportAddress  transportAddress  =  compositeTestCluster.externalTransportAddress();  try(TransportClient  client  =  new  TransportClient(settings))  {  client.addTransportAddress(transportAddress);  	Settings  settings  =  ImmutableSettings.builder().put(requiredSettings()).put( "client.transport.nodes_sampler_interval ",   "1s ")  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  ArrayList<FieldInfo>  fieldInfoList  =  new  ArrayList<FieldInfo>();  context:  for  (FieldInfo  fi  :  fieldInfos)  {  fieldNumber  =  Math.max(fieldNumber,  fi.number  +  1);  }  newVersionInfo  =  new  FieldInfo(VersionFieldMapper.NAME,  false,  fieldNumber,  false,  true,  false,  IndexOptions.DOCS_ONLY,  DocValuesType.NUMERIC,  DocValuesType.NUMERIC,  Collections.<String,  String>emptyMap());  }  else  {  newVersionInfo  =  new  FieldInfo(VersionFieldMapper.NAME,  versionInfo.isIndexed(),  versionInfo.number,  versionInfo.hasVectors(),  versionInfo.omitsNorms(),  versionInfo.hasPayloads(),  versionInfo.getIndexOptions(),  versionInfo.getDocValuesType(),  versionInfo.getNormType(),  versionInfo.attributes());  }          final  ArrayList<FieldInfo>  fieldInfoList  =  new  ArrayList<FieldInfo>();          final  ArrayList<FieldInfo>  fieldInfoList  =  new  ArrayList<>();  for  (FieldInfo  info  :  fieldInfos)  {  if  (info  !=  versionInfo)  {  fieldInfoList.add(info);  }  }  fieldInfoList.add(newVersionInfo);  final  FieldInfos  newFieldInfos  =  new  FieldInfos(fieldInfoList.toArray(new  FieldInfo[fieldInfoList.size()]));  final  NumericDocValues  versionValues  =  new  NumericDocValues()  {  	final  ArrayList<FieldInfo>  fieldInfoList  =  new  ArrayList<>();  
elasticsearch_7beac4ddbfabc2e2cecc06708dc48783aed4b2a1	buggy:  if  (exp  instanceof  ConnectTransportException)  {  context:  }  public  void  handleException(TransportException  exp)  {  if  (!running)  {  return;  }  synchronized  (masterNodeMutex)  {  if  (masterToPing.equals(MasterFaultDetection.this.masterNode()))  {                                      if  (exp  instanceof  ConnectTransportException)  {                                      if  (exp  instanceof  ConnectTransportException  ||  exp.getCause()  instanceof  ConnectTransportException)  {  handleTransportDisconnect(masterToPing);  return;  }  else  if  (exp.getCause()  instanceof  NoLongerMasterException)  {  notifyMasterFailure(masterToPing,   "no  longer  master ");  return;  }  else  if  (exp.getCause()  instanceof  NotMasterException)  {  	if  (exp  instanceof  ConnectTransportException  ||  exp.getCause()  instanceof  ConnectTransportException)  {  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  AtomicReader  reader  =  new  SlowCompositeReaderWrapper(DirectoryReader.open(writer,  true));  context:  public  void  setup()  throws  Exception  {  ifdService  =  new  IndexFieldDataService(new  Index( "test "));  writer  =  new  IndexWriter(new  RAMDirectory(),  new  IndexWriterConfig(Lucene.VERSION,  new  StandardAnalyzer(Lucene.VERSION)).setMergePolicy(new  LogByteSizeMergePolicy()));  }  protected  AtomicReaderContext  refreshReader()  throws  Exception  {  if  (readerContext  !=  null)  {  readerContext.reader().close();  }          AtomicReader  reader  =  new  SlowCompositeReaderWrapper(DirectoryReader.open(writer,  true));          AtomicReader  reader  =  SlowCompositeReaderWrapper.wrap(DirectoryReader.open(writer,  true));  readerContext  =  reader.getContext();  return  readerContext;  }  public  void  tearDown()  throws  Exception  {  super.tearDown();  if  (readerContext  !=  null)  {  	AtomicReader  reader  =  SlowCompositeReaderWrapper.wrap(DirectoryReader.open(writer,  true));  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  if  (x  !=  null  &&  x.mapper().stored())  {  context:  for  (String  fieldName  :  context.fieldNames())  {  if  (fieldName.equals( "* "))  {  loadAllStored  =  true;  continue;  }  if  (fieldName.equals(SourceFieldMapper.NAME))  {  sourceRequested  =  true;  continue;  }  FieldMappers  x  =  context.smartNameFieldMappers(fieldName);                  if  (x  !=  null  &&  x.mapper().stored())  {                  if  (x  !=  null  &&  x.mapper().fieldType().stored())  {  if  (fieldNames  ==  null)  {  fieldNames  =  new  HashSet<String>();  }  fieldNames.add(x.mapper().names().indexName());  }  else  {  if  (extractFieldNames  ==  null)  {  extractFieldNames  =  newArrayList();  }  	if  (x  !=  null  &&  x.mapper().fieldType().stored())  {  
elasticsearch_30acba624dd7ca1dfccbad9e8fe5a95ae325dc9a	buggy:  scriptService,  pageCacheRecycler,  bigArrays);  context:  protected  ShardExistsResponse  shardOperation(ShardExistsRequest  request)  throws  ElasticsearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.shardId().getIndex());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId().id());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.shardId().getIndex(),  request.shardId().id());  SearchContext  context  =  new  DefaultSearchContext(0,  new  ShardSearchRequest(request).types(request.types())  .filteringAliases(request.filteringAliases())  .nowInMillis(request.nowInMillis()),  shardTarget,  indexShard.acquireSearcher( "exists "),  indexService,  indexShard,                  scriptService,  pageCacheRecycler,  bigArrays);                  scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  SearchContext.setCurrent(context);  try  {  if  (request.minScore()  !=  DEFAULT_MIN_SCORE)  {  context.minimumScore(request.minScore());  }  BytesReference  source  =  request.querySource();  if  (source  !=  null  &&  source.length()  >  0)  {  	scriptService,  pageCacheRecycler,  bigArrays,  threadPool.estimatedTimeInMillisCounter());  
elasticsearch_d80dd00424a6ff7a068161ec9683a19e19cde6b3	buggy:  int  numDocs  =  atLeast(10);  context:  for  (ShardOperationFailedException  failure  :  response.getIndices().get( "twitter ").getFailures())  {  assertThat(failure.reason(),  containsString( "[twitter]  [has_child]  No  mapping  for  for  type  [type] "));  assertThat(failure.status(),  equalTo(RestStatus.BAD_REQUEST));  assertThat(failure.shardId(),  greaterThan(-1));  }  }  public  void  testDeleteByFieldQuery()  throws  Exception  {  client().admin().indices().prepareCreate( "test ").execute().actionGet();          int  numDocs  =  atLeast(10);          int  numDocs  =  scaledRandomIntBetween(10,  100);  for  (int  i  =  0;  i  <  numDocs;  i++)  {  client().prepareIndex( "test ",   "test ",  Integer.toString(i))  .setRouting(randomAsciiOfLengthBetween(1,  5))  .setSource( "foo ",   "bar ").get();  }  refresh();  assertHitCount(client().prepareCount( "test ").setQuery(QueryBuilders.matchQuery( "_id ",  Integer.toString(between(0,  numDocs  -  1)))).get(),  1);  assertHitCount(client().prepareCount( "test ").setQuery(QueryBuilders.matchAllQuery()).get(),  numDocs);  	int  numDocs  =  scaledRandomIntBetween(10,  100);  
libgdx_074a5ac922953c158f91e5f9abe0f016f564cb2f	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.OrthoCamBorderTest(),   "Debug  Test ",  800,  480,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.OrthoCamBorderTest(),   "Debug  Test ",  800,  480,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.Gdx2DTest(),   "Debug  Test ",  480,  320,  false);  
elasticsearch_e12bdd9faf879f54818c0533a1d84e5f34206630	buggy:  recoveryStatus.updateStage(RecoveryStatus.Stage.RETRY);  context:  recoveryStatus  =  new  RecoveryStatus();  recoveryStatus.updateStage(RecoveryStatus.Stage.INIT);  while  (!recoveryThrottler.tryRecovery(shardId,   "gateway "))  {  if  (indexShard.state()  ==  IndexShardState.CLOSED)  {  listener.onIgnoreRecovery( "ignoring  recovery  while  waiting  on  retry,  closed ");  return;  }                      recoveryStatus.updateStage(RecoveryStatus.Stage.RETRY);                      recoveryStatus.updateStage(RecoveryStatus.Stage.THROTTLE);  try  {  Thread.sleep(recoveryThrottler.throttleInterval().millis());  recoveryStatus.retryTime(System.currentTimeMillis()  -  recoveryStatus.startTime());  }  catch  (InterruptedException  e)  {  recoveryStatus  =  null;  if  (indexShard.state()  ==  IndexShardState.CLOSED)  {  listener.onIgnoreRecovery( "Interrupted  while  waiting  for  recovery,  but  we  should  ignore  since  closed ");  }  else  {  	recoveryStatus.updateStage(RecoveryStatus.Stage.THROTTLE);  
elasticsearch_dd8512ddd1a328e32c3755964a8da3a79120883e	buggy:  indexRandom( "test ",  true,  indexBuilders.toArray(new  IndexRequestBuilder[indexBuilders.size()]));  context:  final  int  numDocs  =  between(10,  20);  for  (int  i  =  0;  i  <  numDocs;  i++)  {  indexBuilders.add(new  IndexRequestBuilder(client())  .setType( "type ")  .setId(Integer.toString(i))  .setIndex( "test ")  .setSource(  jsonBuilder().startObject().field( "test ",   "value ").startObject( "loc ").field( "lat ",  11).field( "lon ",  21)  .endObject().endObject()));  }          indexRandom( "test ",  true,  indexBuilders.toArray(new  IndexRequestBuilder[indexBuilders.size()]));          indexRandom(true,  indexBuilders.toArray(new  IndexRequestBuilder[indexBuilders.size()]));  final  int  numIters  =  atLeast(3);  for  (int  i  =  0;  i  <  numIters;  i++)  {  allowNodes( "test ",  between(1,3));  client().admin().cluster().prepareReroute().get();  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);  final  List<Throwable>  thrownExceptions  =  new  CopyOnWriteArrayList<Throwable>();  final  Thread  t  =  new  Thread()  {  public  void  run()  {  	indexRandom(true,  indexBuilders.toArray(new  IndexRequestBuilder[indexBuilders.size()]));  
elasticsearch_12d1bf848543b9e4c483ffa62161ac8b5be6c35d	buggy:  spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(topReader,  spare.term);  context:  continue;  }  if  (spare  ==  null)  {  spare  =  new  SignificantLongTerms.Bucket(0,  0,  0,  0,  0,  null);  }  spare.term  =  bucketOrds.key(i);  spare.subsetDf  =  bucketDocCount(ord);  spare.subsetSize  =  subsetSize;              spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(topReader,  spare.term);              spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(spare.term);  spare.supersetSize  =  supersetSize;  assert  spare.subsetDf  <=  spare.supersetDf;  spare.updateScore();  spare.bucketOrd  =  ord;  spare  =  (SignificantLongTerms.Bucket)  ordered.insertWithOverflow(spare);  	spare.supersetDf  =  termsAggFactory.getBackgroundFrequency(spare.term);  
elasticsearch_8e0a479316525c017c1a9a42bcf084778d3ddaf9	buggy:  return  weight.scorer(context,  true,  false,  acceptDocs);  context:  searcher  =  new  IndexSearcher(multiReader);  searcher.setSimilarity(similarity);  weight  =  searcher.createNormalizedWeight(query);  }  }  }  return  new  DocIdSet()  {  public  DocIdSetIterator  iterator()  throws  IOException  {                  return  weight.scorer(context,  true,  false,  acceptDocs);                  return  weight.scorer(context,  acceptDocs);  }  public  boolean  isCacheable()  {  return  false;  }  };  }  public  String  toString()  {  	return  weight.scorer(context,  acceptDocs);  
elasticsearch_0b730aae817d8eec9bb0c3cd6b819993a9a09955	buggy:  final  Query  rewritten  =  new  XFilteredQuery(queryRewritten,  filter);  context:  final  Query  rewritten  =  new  ConstantScoreQuery(filter);  rewritten.setBoost(this.getBoost()  *  queryRewritten.getBoost());  return  rewritten;  }  if  (queryRewritten  !=  query)  {              final  Query  rewritten  =  new  XFilteredQuery(queryRewritten,  filter);              final  Query  rewritten  =  new  XFilteredQuery(queryRewritten,  filter,  strategy);  rewritten.setBoost(this.getBoost());  return  rewritten;  }  else  {  return  this;  }  }  	final  Query  rewritten  =  new  XFilteredQuery(queryRewritten,  filter,  strategy);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage  =  new  Stage(480,  320,  false);  context:  OrthoCamController  camController;  Stage  stage;  Texture  texture;  SpriteBatch  batch;  BitmapFont  font;  public  void  create  ()  {  stage  =  new  Stage(480,  320,  false);  stage  =  new  Stage();;  camController  =  new  OrthoCamController((OrthographicCamera)stage.getCamera());  //  we  know  it's  an  ortho  cam  at  this  point!  Gdx.input.setInputProcessor(camController);  texture  =  new  Texture(Gdx.files.internal( "data/badlogicsmall.jpg "));  for  (int  i  =  0;  i  <  5000;  i++)  {  	stage  =  new  Stage();;  
elasticsearch_7aacc8d44859887fbc72a22cd78e22d75fd5b554	buggy:  public  Object  clone()  {  context:  }  else  {  currentBufferIndex--;  currentBuffer.position(currentBuffer.limit());  }  }  }  }      public  Object  clone()  {      public  IndexInput  clone()  {  ByteBufferIndexInput  cloned  =  (ByteBufferIndexInput)  super.clone();  cloned.file.incRef();  //  inc  ref  on  cloned  one  if  (currentBuffer  !=  EMPTY_BUFFER)  {  cloned.currentBuffer  =  currentBuffer.asReadOnlyBuffer();  cloned.currentBuffer.position(currentBuffer.position());  }  return  cloned;  }  	public  IndexInput  clone()  {  
elasticsearch_91144fc92f80d02282c7b741787200539566d713	buggy:  return  Queries.wrap(query);  context:  public  String[]  names()  {  return  new  String[]{NAME};  }  public  Filter  parse(QueryParseContext  parseContext)  throws  IOException,  QueryParsingException  {  Query  query  =  parseContext.parseInnerQuery();  if  (query  ==  null)  {  return  null;  }          return  Queries.wrap(query);          return  Queries.wrap(query,  parseContext);  }  }  	return  Queries.wrap(query,  parseContext);  
libgdx_56261622d837749a0af6348f418e9370b2139e0c	buggy:  final  TextField  textfield  =  new  TextField( " ",  skin.getStyle(TextFieldStyle.class),   "textfield ");  context:  window.x  =  window.y  =  0;  final  Button  button  =  new  Button( "Single ",  skin.getStyle(ButtonStyle.class),   "button-sl ");  final  Button  buttonMulti  =  new  Button( "Multi\nLine\nToggle ",  skin.getStyle( "toggle ",  ButtonStyle.class),   "button-ml-tgl ");  final  Button  imgButton  =  new  Button(new  Image(image),  skin.getStyle(ButtonStyle.class));  final  Button  imgToggleButton  =  new  Button(new  Image(image),  skin.getStyle( "toggle ",  ButtonStyle.class));  final  CheckBox  checkBox  =  new  CheckBox( "Check  me ",  skin.getStyle(CheckBoxStyle.class),   "checkbox ");  final  Slider  slider  =  new  Slider(0,  10,  1,  skin.getStyle(SliderStyle.class),   "slider ");  final  TextField  textfield  =  new  TextField( " ",  skin.getStyle(TextFieldStyle.class),   "textfield ");  final  TextField  textfield  =  new  TextField( " ",   "Click  here! ",  skin.getStyle(TextFieldStyle.class),   "textfield ");  final  ComboBox  combobox  =  new  ComboBox(new  String[]  { "Android ",   "Windows ",   "Linux ",   "OSX "},  ui,  skin.getStyle(ComboBoxStyle.class),   "combo ");  final  Image  imageActor  =  new  Image(image2);  final  FlickScrollPane  scrollPane  =  new  FlickScrollPane(imageActor,  ui,   "scroll ");  final  List  list  =  new  List(listEntries,  skin.getStyle(ListStyle.class),   "list ");  final  ScrollPane  scrollPane2  =  new  ScrollPane(list,  ui,  skin.getStyle(ScrollPaneStyle.class),   "scroll2 ");  final  SplitPane  splitPane  =  new  SplitPane(scrollPane,  scrollPane2,  false,  ui,  skin.getStyle( "default-horizontal ",  SplitPaneStyle.class),   "split ");  	final  TextField  textfield  =  new  TextField( " ",   "Click  here! ",  skin.getStyle(TextFieldStyle.class),   "textfield ");  
libgdx_eb6357b22bfe90d1c37fd4c279a28b771b1f2822	buggy:  if  (input.buttons[Input.SHOOT]  &&  !input.oldButtons[Input.SHOOT])  {  context:  }  }  spriteBatch.end();  }  public  void  tick(Input  input)  {  time++;  if  (time  /  4  >  lines.size()  *  6  +  250)  {  setScreen(new  TitleScreen());  }          if  (input.buttons[Input.SHOOT]  &&  !input.oldButtons[Input.SHOOT])  {          if  (input.buttons[Input.SHOOT]  &&  !input.oldButtons[Input.SHOOT]  ||  Gdx.input.isTouched())  {  setScreen(new  TitleScreen());  }  if  (input.buttons[Input.ESCAPE]  &&  !input.oldButtons[Input.ESCAPE])  {  setScreen(new  TitleScreen());  }  }  }  	if  (input.buttons[Input.SHOOT]  &&  !input.oldButtons[Input.SHOOT]  ||  Gdx.input.isTouched())  {  
elasticsearch_cd0e1226e1788c376ba1030a241d7d83d36a7cf1	buggy:  ignoreMalformed);  context:  public  Builder  nullValue(long  nullValue)  {  this.nullValue  =  nullValue;  return  this;  }  public  LongFieldMapper  build(BuilderContext  context)  {  LongFieldMapper  fieldMapper  =  new  LongFieldMapper(buildNames(context),  precisionStep,  fuzzyFactor,  index,  store,  boost,  omitNorms,  indexOptions,  nullValue,                      ignoreMalformed);                      ignoreMalformed(context));  fieldMapper.includeInAll(includeInAll);  return  fieldMapper;  }  }  public  static  class  TypeParser  implements  Mapper.TypeParser  {  public  Mapper.Builder  parse(String  name,  Map<String,  Object>  node,  ParserContext  parserContext)  throws  MapperParsingException  {  	ignoreMalformed(context));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  LinkedHashMap<String,  Object>  args  =  new  LinkedHashMap<String,  Object>();  context:  testSuiteDescription.addChild(parentDescription);  }  else  {  parentDescription  =  testSuiteDescription;  }  final  long  testSectionSeed  =  determineTestSectionSeed(restTestSuite.getDescription()  +   "/ "  +  testSection.getName());  for  (int  i  =  0;  i  <  iterations;  i++)  {  long  thisSeed  =  (fixedSeed  ?  testSectionSeed  :  testSectionSeed  ^  MurmurHash3.hash((long)  i));                          final  LinkedHashMap<String,  Object>  args  =  new  LinkedHashMap<String,  Object>();                          final  LinkedHashMap<String,  Object>  args  =  new  LinkedHashMap<>();  if  (hasRepetitions)  {  args.put( "# ",  i);  }  if  (hasRepetitions  ||  appendSeedParameter)  {  args.put( "seed= ",  SeedUtils.formatSeedChain(runnerRandomness,  new  Randomness(thisSeed)));  }  Description  testSectionDescription  =  createTestSectionIterationDescription(restTestSuite,  testSection,  args);  	final  LinkedHashMap<String,  Object>  args  =  new  LinkedHashMap<>();  
elasticsearch_ac253178bda20a4b1172092a1032ce1cc048b4cd	buggy:  return  includeInAll(includeInAll,  mapper.indexed());  context:  }  public  void  uid(UidField  uid)  {  this.uid  =  uid;  }  public  boolean  includeInAll(Boolean  includeInAll,  FieldMapper  mapper)  {          return  includeInAll(includeInAll,  mapper.indexed());          return  includeInAll(includeInAll,  mapper.fieldType().indexed());  }  private  boolean  includeInAll(Boolean  specificIncludeInAll,  boolean  indexed)  {  	return  includeInAll(includeInAll,  mapper.fieldType().indexed());  
elasticsearch_32127c4d73357da9bf657fcafe70ba3e9842870e	buggy:  threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {  context:  if  (index.equals(request.index))  {  if  (counter.decrementAndGet()  ==  0)  {  listener.onResponse(new  Response(true));  nodeIndexDeletedAction.remove(this);  }  }  }  };  nodeIndexDeletedAction.add(nodeIndexDeleteListener);                          threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {                          listener.future  =  threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {  listener.onResponse(new  Response(false));  nodeIndexDeletedAction.remove(nodeIndexDeleteListener);  }  });  }  return  newClusterStateBuilder().state(currentState).routingResult(routingResult).metaData(newMetaData).blocks(blocks).build();  	listener.future  =  threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {  
elasticsearch_ed2b009f076a9f8d4c96f469f83a896d5991c04e	buggy:  }  else  if  (value  instanceof  Short)  {  context:  writeLong(((Date)  value).getTime());  }  else  if  (value  instanceof  ReadableInstant)  {  writeByte((byte)  13);  writeLong(((ReadableInstant)  value).getMillis());  }  else  if  (value  instanceof  BytesReference)  {  writeByte((byte)  14);  writeBytesReference((BytesReference)  value);  }  else  if  (value  instanceof  Text)  {  writeByte((byte)  15);  writeText((Text)  value);          }  else  if  (value  instanceof  Short)  {          }  else  if  (value  ==  Short.class)  {  writeByte((byte)  16);  writeShort((Short)  value);  }  else  {  throw  new  IOException( "Can't  write  type  [ "  +  type  +   "] ");  }  }  }  	}  else  if  (value  ==  Short.class)  {  
elasticsearch_15ccd787a5f406b0ae2d59920ec960d5a26ecdce	buggy:  b.append( "REPRODUCE  WITH  :  mvn  test ");  context:  public  void  testFailure(Failure  failure)  throws  Exception  {  if  (failure.getException()  instanceof  AssumptionViolatedException)  {  return;  }  final  Description  d  =  failure.getDescription();  final  StringBuilder  b  =  new  StringBuilder();  b.append( "FAILURE  :   ").append(d.getDisplayName()).append( "\n ");          b.append( "REPRODUCE  WITH  :  mvn  test ");          b.append( "REPRODUCE  WITH  :  mvn  clean  test ");  MavenMessageBuilder  mavenMessageBuilder  =  new  MavenMessageBuilder(b);  mavenMessageBuilder.appendAllOpts(failure.getDescription());  if  (ElasticsearchRestTests.class.isAssignableFrom(failure.getDescription().getTestClass()))  {  mavenMessageBuilder.appendRestTestsProperties();  }  	b.append( "REPRODUCE  WITH    :  mvn  clean  test ");  
elasticsearch_8ccfca3a2f0193f0a4da38e206c35cf08402218f	buggy:  return  values.copyShared();  context:  public  boolean  nextPosition()  {  if  (++position  >=  maxOrd)  {  return  false;  }  current  =  values.getValueByOrd(position);  return  true;  }  public  BytesRef  copyCurrent()  {              return  values.copyShared();              return  BytesRef.deepCopyOf(current);  }  public  void  close()  {  Releasables.close(counts);  }  }  	return  BytesRef.deepCopyOf(current);  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  searcher.release();  context:  shardStatus.translogId  =  indexShard.translog().currentId();  shardStatus.translogOperations  =  indexShard.translog().estimatedNumberOfOperations();  Engine.Searcher  searcher  =  indexShard.acquireSearcher( "indices_status ");  try  {  shardStatus.docs  =  new  DocsStatus();  shardStatus.docs.numDocs  =  searcher.reader().numDocs();  shardStatus.docs.maxDoc  =  searcher.reader().maxDoc();  shardStatus.docs.deletedDocs  =  searcher.reader().numDeletedDocs();  }  finally  {                  searcher.release();                  searcher.close();  }  shardStatus.mergeStats  =  indexShard.mergeScheduler().stats();  shardStatus.refreshStats  =  indexShard.refreshStats();  shardStatus.flushStats  =  indexShard.flushStats();  }  if  (request.recovery)  {  	searcher.close();  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(action.indices(),  request.indicesOptions());  context:  protected  void  masterOperation(final  IndicesAliasesRequest  request,  final  ClusterState  state,  final  ActionListener<IndicesAliasesResponse>  listener)  throws  ElasticsearchException  {  List<AliasActions>  actions  =  request.aliasActions();  List<AliasAction>  finalActions  =  new  ArrayList<>();  boolean  hasOnlyDeletesButNoneCanBeDone  =  true;  Set<String>  aliases  =  new  HashSet<>();  for  (AliasActions  action  :  actions)  {              String[]  concreteIndices  =  state.metaData().concreteIndices(action.indices(),  request.indicesOptions());              String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  action.indices());  for  (String  alias  :  action.aliases())  {  aliases.add(alias);  }  for  (String  index  :  concreteIndices)  {  for  (String  alias  :  action.concreteAliases(state.metaData(),  index))  {  AliasAction  finalAction  =  new  AliasAction(action.aliasAction());  finalAction.index(index);  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  action.indices());  
elasticsearch_c08791f8164052072bc197789591e367a66d69cc	buggy:  builder.field( "_type ",   "histogram ");  context:  for  (Entry  entry  :  entries)  {  out.writeDouble(entry.from);  out.writeDouble(entry.to);  out.writeVLong(entry.count);  out.writeDouble(entry.total);  }  }  builder.startObject(name);          builder.field( "_type ",   "histogram ");          builder.field( "_type ",   "geo_distance ");  builder.field( "_field ",  fieldName);  builder.field( "_value_field ",  valueFieldName);  builder.field( "_unit ",  unit);  builder.startArray( "ranges ");  for  (Entry  entry  :  entries)  {  builder.startObject();  if  (!Double.isInfinite(entry.from))  {  builder.field( "from ",  entry.from);  	builder.field( "_type ",   "geo_distance ");  
elasticsearch_d86c116273dd3916195ba1cf39e108a7475e5fa6	buggy:  ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  context:  public  class  ReplicaAllocatedAfterPrimaryTests  {  private  final  ESLogger  logger  =  Loggers.getLogger(ReplicaAllocatedAfterPrimaryTests.class);          ShardsAllocation  strategy  =  new  ShardsAllocation(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());          AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  MetaData  metaData  =  newMetaDataBuilder()  .put(newIndexMetaDataBuilder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  routingTable()  	AllocationService  strategy  =  new  AllocationService(settingsBuilder().put( "cluster.routing.allocation.concurrent_recoveries ",  10).build());  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {  fieldData  =  (LongFieldData)  fieldDataCache.cache(fieldDataType,  context.reader(),  indexFieldName);  if  (script  !=  null)  {              script.setNextReader(context.reader());              script.setNextReader(context);  }  }  protected  void  doCollect(int  doc)  throws  IOException  {  fieldData.forEachValueInDoc(doc,  aggregator);  }  	script.setNextReader(context);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  ContextQuery>  querySet  =  new  HashMap<String,  ContextMapping.ContextQuery>();  context:  public  static  List<ContextQuery>  parseQueries(Map<String,  ContextMapping>  mappings,  XContentParser  parser)  throws  IOException,  ElasticsearchParseException  {              Map<String,  ContextQuery>  querySet  =  new  HashMap<String,  ContextMapping.ContextQuery>();              Map<String,  ContextQuery>  querySet  =  new  HashMap<>();  Token  token  =  parser.currentToken();  if(token  ==  Token.START_OBJECT)  {  while  ((token  =  parser.nextToken())  !=  Token.END_OBJECT)  {  String  name  =  parser.text();  ContextMapping  mapping  =  mappings.get(name);  if  (mapping  ==  null)  {  throw  new  ElasticsearchParseException( "no  mapping  defined  for  [ "  +  name  +   "] ");  }  	Map<String,  ContextQuery>  querySet  =  new  HashMap<>();  
elasticsearch_a0fd47159e7e91d8858e686bae4b97dcda6c59f5	buggy:  }  else  if  (searchContext.scanning())  {  context:  }  if  (searchContext.searchType()  ==  SearchType.COUNT)  {  CountCollector  countCollector  =  new  CountCollector();  try  {  searchContext.searcher().search(query,  countCollector);  }  catch  (ScanCollector.StopCollectingException  e)  {  }  topDocs  =  countCollector.topDocs();              }  else  if  (searchContext.scanning())  {              }  else  if  (searchContext.searchType()  ==  SearchType.SCAN)  {  ScanCollector  scanCollector  =  new  ScanCollector(searchContext.from(),  searchContext.size());  try  {  searchContext.searcher().search(query,  scanCollector);  }  catch  (ScanCollector.StopCollectingException  e)  {  }  topDocs  =  scanCollector.topDocs();  }  else  if  (sort)  {  	}  else  if  (searchContext.searchType()  ==  SearchType.SCAN)  {  
elasticsearch_11bdad1338ef053e4182805ff590470be1cb5951	buggy:  public  NumericRangeFilterBuilder  lte(String  to)  {  context:  public  NumericRangeFilterBuilder  lt(double  to)  {  this.to  =  to;  this.includeUpper  =  false;  return  this;  }      public  NumericRangeFilterBuilder  lte(String  to)  {      public  NumericRangeFilterBuilder  lte(Object  to)  {  this.to  =  to;  this.includeUpper  =  true;  return  this;  }  	public  NumericRangeFilterBuilder  lte(Object  to)  {  
libgdx_98a2796045b849587ca938f3c1c7c863bb40ee8c	buggy:  Texture  newTex  =  new  Texture(texFile,  TextureFilter.isMipMap(minFilter)  ||  TextureFilter.isMipMap(magFilter)?true:false);  context:  TextureFilter  minFilter,  TextureFilter  magFilter,  TextureWrap  uwrap,  TextureWrap  vwrap)  {  if(sDictionary.containsKey(path))  {  TextureRef  ref  =  sDictionary.get(path);  ref.addRef();  return  ref;  }  FileHandle  texFile  =  Gdx.app.getFiles().getFileHandle(path,  FileType.Internal);  Texture  newTex  =  new  Texture(texFile,  TextureFilter.isMipMap(minFilter)  ||  TextureFilter.isMipMap(magFilter)?true:false);  Texture  newTex  =  new  Texture(texFile,  minFilter.isMipMap()  ||  magFilter.isMipMap()?true:false);  newTex.setFilter(minFilter,  magFilter);  newTex.setWrap(uwrap,  vwrap);  TextureRef  ref  =  new  TextureRef(path,  newTex);  sDictionary.put(path,  ref);  return  ref;  }  	Texture  newTex  =  new  Texture(texFile,  minFilter.isMipMap()  ||  magFilter.isMipMap()?true:false);  
elasticsearch_ec74a7e76f96cae3c7ebf335cdfec16d68a2a040	buggy:  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);  context:  query  =  new  XFilteredQuery(query,  parseContext.cacheFilter(parentDocMapper.typeFilter(),  null));  Set<String>  parentTypes  =  new  HashSet<>(5);  parentTypes.add(parentType);  ParentChildIndexFieldData  parentChildIndexFieldData  =  null;  for  (DocumentMapper  documentMapper  :  parseContext.mapperService())  {  ParentFieldMapper  parentFieldMapper  =  documentMapper.parentFieldMapper();  if  (parentFieldMapper.active())  {  DocumentMapper  parentTypeDocumentMapper  =  parseContext.mapperService().documentMapper(parentFieldMapper.type());                  parentChildIndexFieldData  =  parseContext.fieldData().getForField(parentFieldMapper);                  parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  if  (parentTypeDocumentMapper  ==  null)  {  parentTypes.add(parentFieldMapper.type());  }  }  }  if  (parentChildIndexFieldData  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[has_parent]  no  _parent  field  configured ");  	parentChildIndexFieldData  =  parseContext.getForField(parentFieldMapper);  
elasticsearch_83d5084f620e13678e7786b5c735de32c4e9fb80	buggy:  Tuple<XContentType,  Map<String,  Object>>  mapTuple  =  XContentHelper.convertToMap(data,  dataOffset,  dataLength);  context:  return  null;  }  byte[]  data  =  context.source();  int  dataOffset  =  context.sourceOffset();  int  dataLength  =  context.sourceLength();  boolean  filtered  =  includes.length  >  0  ||  excludes.length  >  0;  if  (filtered)  {              Tuple<XContentType,  Map<String,  Object>>  mapTuple  =  XContentHelper.convertToMap(data,  dataOffset,  dataLength);              Tuple<XContentType,  Map<String,  Object>>  mapTuple  =  XContentHelper.convertToMap(data,  dataOffset,  dataLength,  true);  Map<String,  Object>  filteredSource  =  XContentMapValues.filter(mapTuple.v2(),  includes,  excludes);  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  StreamOutput  streamOutput;  if  (compress  !=  null  &&  compress  &&  (compressThreshold  ==  -1  ||  dataLength  >  compressThreshold))  {  streamOutput  =  cachedEntry.cachedLZFBytes();  }  else  {  streamOutput  =  cachedEntry.cachedBytes();  }  	Tuple<XContentType,  Map<String,  Object>>  mapTuple  =  XContentHelper.convertToMap(data,  dataOffset,  dataLength,  true);  
elasticsearch_6a146e7ad0b939c56ceb8759dba34139de5e687b	buggy:  FieldMapper  fieldMapper  =  context.mapperService().smartNameFieldMapper(field);  context:  if  (regex  !=  null)  {  pattern  =  Regex.compile(regex,  regexFlags);  }  if  (fieldsNames  !=  null)  {  return  new  FieldsTermsStringFacetCollector(facetName,  fieldsNames,  size,  comparatorType,  allTerms,  context,  excluded,  pattern,  scriptLang,  script,  params);  }  if  (field  ==  null  &&  fieldsNames  ==  null  &&  script  !=  null)  {  return  new  ScriptTermsStringFieldFacetCollector(facetName,  size,  comparatorType,  context,  excluded,  pattern,  scriptLang,  script,  params);  }          FieldMapper  fieldMapper  =  context.mapperService().smartNameFieldMapper(field);          FieldMapper  fieldMapper  =  context.smartNameFieldMapper(field);  if  (fieldMapper  !=  null)  {  if  (fieldMapper  instanceof  IpFieldMapper)  {  if  (script  !=  null  ||   "map ".equals(executionHint))  {  return  new  TermsIpFacetCollector(facetName,  field,  size,  comparatorType,  allTerms,  context,  scriptLang,  script,  params);  }  else  {  return  new  TermsIpOrdinalsFacetCollector(facetName,  field,  size,  comparatorType,  allTerms,  context,  null);  }  }  else  if  (fieldMapper.fieldDataType()  ==  FieldDataType.DefaultTypes.LONG)  {  	FieldMapper  fieldMapper  =  context.smartNameFieldMapper(field);  
elasticsearch_ac1e9856703960d953b81ba987f04596c925d153	buggy:  query  =  new  ParentConstantScoreQuery(innerQuery,  parentType,  childrenFilter,  true);  context:  }  parentFilter  =  parentsFilter;  }  Filter  childrenFilter  =  parseContext.cacheFilter(new  NotFilter(parentFilter),  null);  boolean  deleteByQuery  =   "delete_by_query ".equals(SearchContext.current().source());  Query  query;  if  (!deleteByQuery  &&  score)  {  query  =  new  ParentQuery(innerQuery,  parentType,  childrenFilter);  }  else  {              query  =  new  ParentConstantScoreQuery(innerQuery,  parentType,  childrenFilter,  true);              query  =  new  ParentConstantScoreQuery(innerQuery,  parentType,  childrenFilter);  if  (deleteByQuery)  {  query  =  new  XConstantScoreQuery(new  DeleteByQueryWrappingFilter(query));  }  }  query.setBoost(boost);  if  (queryName  !=  null)  {  parseContext.addNamedQuery(queryName,  query);  }  	query  =  new  ParentConstantScoreQuery(innerQuery,  parentType,  childrenFilter);  
libgdx_0ece738e446b601c725634e97e4626dc349bd4f1	buggy:  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  context:  MD5Model  model;  MD5Animation  anim;  MD5AnimationInfo  animInfo;  MD5Joints  skeleton;  MD5Renderer  renderer;  SpriteBatch  batch;  BitmapFont  font;  Gdx.app.log( "MD5  Test ",   "created ");  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  true);  model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  anim  =  MD5Loader.loadAnimation(Gdx.files.internal( "data/walk1.md5anim ").read());  skeleton  =  new  MD5Joints();  skeleton.joints  =  new  float[anim.frames[0].joints.length];  animInfo  =  new  MD5AnimationInfo(anim.frames.length,  anim.secondsPerFrame);  renderer  =  new  MD5Renderer(model,  false,  true);  renderer.setSkeleton(model.baseSkeleton);  	model  =  MD5Loader.loadModel(Gdx.files.internal( "data/zfat.md5mesh ").read(),  false);  
elasticsearch_245d241a5c69286c5eb53254d3bc16fc047df4ae	buggy:  }  catch  (IOException  e)  {  context:  rwl.writeLock().lock();  try  {  disableFlushCounter++;  }  finally  {  rwl.writeLock().unlock();  }  SnapshotIndexCommit  phase1Snapshot;  try  {  phase1Snapshot  =  deletionPolicy.snapshot();          }  catch  (IOException  e)  {          }  catch  (Exception  e)  {  -disableFlushCounter;  throw  new  RecoveryEngineException(shardId,  1,   "Snapshot  failed ",  e);  }  try  {  recoveryHandler.phase1(phase1Snapshot);  }  catch  (Exception  e)  {  -disableFlushCounter;  	}  catch  (Exception  e)  {  
elasticsearch_0faa05b3f29d23e8d4e647de25d2616c4408c2dc	buggy:  listener.onFailure(new  ReplicationShardOperationFailedException(shardIt.shardId(),  e));  context:  performReplicas(response,  alreadyThreaded);  }  catch  (Exception  e)  {  if  (e  instanceof  IndexShardMissingException  ||  e  instanceof  IllegalIndexShardStateException  ||  e  instanceof  IndexMissingException)  {  retry(fromDiscoveryListener,  shard.shardId());  return;  }  if  (logger.isDebugEnabled())  {  }                  listener.onFailure(new  ReplicationShardOperationFailedException(shardIt.shardId(),  e));                  listener.onFailure(e);  }  }  private  void  performReplicas(final  Response  response,  boolean  alreadyThreaded)  {  if  (ignoreReplicas()  ||  shardIt.size()  ==  1  /*  no  replicas  */)  {  if  (alreadyThreaded  ||  !request.listenerThreaded())  {  listener.onResponse(response);  }  else  {  	listener.onFailure(e);  
elasticsearch_442f1d76771bc07659f89836c543bd62b90f8a1d	buggy:  logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);  context:  return  serverHandlers.get(action);  }  RequestHolder  holder  =  clientHandlers.remove(requestId);  if  (holder  ==  null)  {  TimeoutInfoHolder  timeoutInfoHolder  =  timeoutInfoHandlers.remove(requestId);  if  (timeoutInfoHolder  !=  null)  {                      logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);                      logger.warn( "Received  response  for  a  request  that  has  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);  }  else  {  }  return  null;  }  if  (holder.timeout()  !=  null)  {  holder.timeout().cancel();  }  	logger.warn( "Received  response  for  a  request  that  has  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);  
elasticsearch_454dc53483c69a59090bf1c50bb2708e480c5858	buggy:  values[i]  =  indexFieldDatas[i].load(context).getBytesValues();  context:  public  void  setScorer(Scorer  scorer)  throws  IOException  {  if  (script  !=  null)  {  script.setScorer(scorer);  }  }  public  void  setNextReader(AtomicReaderContext  context)  throws  IOException  {  for  (int  i  =  0;  i  <  indexFieldDatas.length;  i++)  {                  values[i]  =  indexFieldDatas[i].load(context).getBytesValues();                  values[i]  =  indexFieldDatas[i].load(context).getBytesValues(true);  }  if  (script  !=  null)  {  script.setNextReader(context);  }  }  public  void  collect(int  doc)  throws  IOException  {  	values[i]  =  indexFieldDatas[i].load(context).getBytesValues(true);  
elasticsearch_34a3e8af352ed5bb241cc1b22b934c1002785192	buggy:  assert  parser.currentToken()  ==  XContentParser.Token.END_OBJECT;  context:  if  (parser.currentToken()  ==  XContentParser.Token.START_OBJECT)  {  level++;  }  if  (parser.currentToken()  ==  XContentParser.Token.END_OBJECT)  {  level--;  }  }  parser.nextToken();              assert  parser.currentToken()  ==  XContentParser.Token.END_OBJECT;              assert  parser.currentToken()  ==  XContentParser.Token.END_OBJECT  :   "Expected  [END_OBJECT]  but  was  [ "  +  parser.currentToken()  + "] ";  parser.nextToken();  return  restApi;  }  finally  {  parser.close();  }  }  	assert  parser.currentToken()  ==  XContentParser.Token.END_OBJECT  :   "Expected  [END_OBJECT]  but  was  [ "    +  parser.currentToken()  + "] ";  
elasticsearch_4bdae621f92beb226cf5873a9efe721b38c7e0c7	buggy:  new  ScriptModule(),  context:  bindings.processXContentQueryFilter( "my ",  PluginJsonFilterParser.class);  }  });  Index  index  =  new  Index( "test ");  Injector  injector  =  new  ModulesBuilder().add(  new  SettingsModule(settings),  new  ThreadPoolModule(settings),                  new  ScriptModule(),                  new  ScriptModule(settings),  new  IndexSettingsModule(settings),  new  IndexCacheModule(settings),  new  AnalysisModule(settings),  new  IndexEngineModule(settings),  new  SimilarityModule(settings),  queryParserModule,  new  IndexNameModule(index)  ).createInjector();  	new  ScriptModule(settings),  
elasticsearch_f444ed4dff95fe49d2a11f8eac287e48c563ce9c	buggy:  return  indexNameTermFactory.createTerm(value);  context:  public  Term  indexNameTerm()  {  return  this.indexNameTermFactory;  }  public  Term  createIndexNameTerm(String  value)  {              return  indexNameTermFactory.createTerm(value);              return  new  Term(indexName,  value);  }  }  Names  names();  boolean  indexed();  	return  new  Term(indexName,  value);  
elasticsearch_cb0cf3167c77d80ea43221a5107e8f1d59f526b9	buggy:  assertThat(searchResponse.getHits().getAt(0).id(),  equalTo( "1 "));  context:  searchResponse  =  client().prepareSearch( "test ")  .setQuery(customFiltersScoreQuery(matchAllQuery()).scoreMode( "max ")  .add(termFilter( "field ",   "value4 "),  2)  .add(termFilter( "field ",   "value1 "),  3)  .add(termFilter( "color ",   "red "),  5))  .setExplain(true)  .execute().actionGet();  assertThat(Arrays.toString(searchResponse.getShardFailures()),  searchResponse.getFailedShards(),  equalTo(0));  assertThat(searchResponse.getHits().totalHits(),  equalTo(4l));          assertThat(searchResponse.getHits().getAt(0).id(),  equalTo( "1 "));          assertThat(searchResponse.getHits().getAt(0).id(),  anyOf(equalTo( "1 "),  equalTo( "3 ")));  //  could  be  both  depending  on  the  order  of  the  docs  internally  (lucene  order)  assertThat(searchResponse.getHits().getAt(0).score(),  equalTo(5.0f));  searchResponse  =  client().prepareSearch( "test ")  .setQuery(customFiltersScoreQuery(matchAllQuery()).scoreMode( "avg ")  .add(termFilter( "field ",   "value4 "),  2)  .add(termFilter( "field ",   "value1 "),  3)  .add(termFilter( "color ",   "red "),  5))  	assertThat(searchResponse.getHits().getAt(0).id(),  anyOf(equalTo( "1 "),  equalTo( "3 ")));  //  could  be  both  depending  on  the  order  of  the  docs  internally  (lucene  order)  
elasticsearch_8a8a4d648aeffd8b196f31a866de2c12a5b5663b	buggy:  filter  =  parseContext.cacheFilterIfPossible(filter);  context:  }  if  (query  ==  null)  {  throw  new  QueryParsingException(index,   "[filtered]  requires  'query'  element ");  }  if  (filter  ==  null)  {  throw  new  QueryParsingException(index,   "[filtered]  requires  'filter'  element ");  }  if  (cache)  {              filter  =  parseContext.cacheFilterIfPossible(filter);              filter  =  parseContext.cacheFilter(filter);  }  FilteredQuery  filteredQuery  =  new  FilteredQuery(query,  filter);  filteredQuery.setBoost(boost);  return  filteredQuery;  }  }  	filter  =  parseContext.cacheFilter(filter);  
elasticsearch_6a476f440b3991553cb60719c595249dbe5f7c05	buggy:  getRequest.threadedOperation(true);  context:  super(settings,  client);  controller.registerHandler(GET,   "/{index}/{type}/{id} ",  this);  }  final  GetRequest  getRequest  =  new  GetRequest(request.param( "index "),  request.param( "type "),  request.param( "id "));  getRequest.listenerThreaded(false);          getRequest.threadedOperation(true);          getRequest.operationThreaded(true);  List<String>  fields  =  request.params( "field ");  String  sField  =  request.param( "fields ");  if  (sField  !=  null)  {  String[]  sFields  =  fieldsPattern.split(sField);  if  (sFields  !=  null)  {  if  (fields  ==  null)  {  	getRequest.operationThreaded(true);  
libgdx_882cbfd58168f6cb14cff3b09db2d6c2725c0192	buggy:  stage.setViewport(width,  height,  true);  context:  stage.act(Gdx.graphics.getDeltaTime());  stage.draw();  Table.drawDebug(stage);  stage.getSpriteBatch().begin();  patch.draw(stage.getSpriteBatch(),  300,  100,  126,  126);  stage.getSpriteBatch().end();  }  public  void  resize  (int  width,  int  height)  {  stage.setViewport(width,  height,  true);  stage.getViewport().update(width,  height,  true);  }  public  void  dispose  ()  {  stage.dispose();  }  }  	stage.getViewport().update(width,  height,  true);  
elasticsearch_74e8d299d607bbb4fb2f2324f88335fc80fb19fe	buggy:  logger.debug( "Serving  getMapping  request  based  on  version  {} ",  state.version());  context:  return  new  GetMappingsRequest();  }  protected  GetMappingsResponse  newResponse()  {  return  new  GetMappingsResponse();  }  protected  void  doMasterOperation(final  GetMappingsRequest  request,  final  ClusterState  state,  final  ActionListener<GetMappingsResponse>  listener)  throws  ElasticSearchException  {          logger.debug( "Serving  getMapping  request  based  on  version  {} ",  state.version());          logger.trace( "serving  getMapping  request  based  on  version  {} ",  state.version());  ImmutableMap<String,  ImmutableMap<String,  MappingMetaData>>  result  =  state.metaData().findMappings(  request.indices(),  request.types()  );  listener.onResponse(new  GetMappingsResponse(result));  }  }  	logger.trace( "serving  getMapping  request  based  on  version  {} ",  state.version());  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  counts.release();  context:  final  boolean[]  states  =  counts.v().allocated;  final  long[]  keys  =  counts.v().keys;  final  long[]  values  =  counts.v().values;  int  entryIndex  =  0;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  countEntries[entryIndex++]  =  new  InternalCountDateHistogramFacet.CountEntry(keys[i],  values[i]);  }  }          counts.release();          counts.close();  return  new  InternalCountDateHistogramFacet(facetName,  comparatorType,  countEntries);  }  class  Collector  extends  FacetExecutor.Collector  {  private  LongValues  values;  private  final  DateHistogramProc  histoProc;  	counts.close();  
elasticsearch_71c3bd7c6439679f31af4758a70f956d9337b5ac	buggy:  script.setNextReader(context.reader());  context:  this.facets  =  CacheRecycler.popObjectIntMap();  }  public  void  setScorer(Scorer  scorer)  throws  IOException  {  script.setScorer(scorer);  }  protected  void  doSetNextReader(AtomicReaderContext  context)  throws  IOException  {          script.setNextReader(context.reader());          script.setNextReader(context);  }  protected  void  doCollect(int  doc)  throws  IOException  {  script.setNextDocId(doc);  Object  o  =  script.run();  if  (o  ==  null)  {  missing++;  	script.setNextReader(context);  
elasticsearch_8a70b115f29b41effaff26381c3afcc42fe221b0	buggy:  return  builder.field( "aggregation ",  aggregation);  context:  out.writeString(name);  out.writeOptionalString(scriptLang);  ScriptType.writeTo(scriptType,  out);  out.writeOptionalString(reduceScript);  out.writeMap(reduceParams);  out.writeGenericValue(aggregation);  }  public  XContentBuilder  doXContentBody(XContentBuilder  builder,  Params  params)  throws  IOException  {          return  builder.field( "aggregation ",  aggregation);          return  builder.field( "value ",  aggregation);  }  }  	return  builder.field( "value ",  aggregation);  
elasticsearch_d1d3f8c4ca39471ff551330eea508d31d9aea2ea	buggy:  channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));  context:  }  }  builder.endArray();  builder.endObject();  }  builder.endArray();  }  builder.endObject();                      channel.sendResponse(new  XContentRestResponse(request,  RestResponse.Status.OK,  builder));                      channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  }  catch  (Exception  e)  {  onFailure(e);  }  }  private  void  jsonShardRouting(XContentBuilder  builder,  ShardRouting  shardRouting)  throws  IOException  {  builder.startObject()  .field( "state ",  shardRouting.state())  	channel.sendResponse(new  XContentRestResponse(request,  RestStatus.OK,  builder));  
libgdx_2f3f22689477e3e42bcfbc5d1194f5c34e9d0e73	buggy:  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  context:  package  com.badlogic.gdx.tests.jogl;  public  class  JoglDebugStarter  {  public  static  void  main  (String[]  argv)  {  new  JoglApplication(new  com.badlogic.gdx.tests.CullTest(),   "Debug  Test ",  480,  320,  false);  new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  }  }  	new  JoglApplication(new  com.badlogic.gdx.tests.PickingTest(),   "Debug  Test ",  480,  320,  false);  
libgdx_ee8804fe997e775348e202b10f495b9a700cfb70	buggy:  translate(tmpVec.set(-tmpVec.x,  -tmpVec.y,  -tmpVec.z));  context:  public  void  rotateAround  (Vector3  point,  Vector3  axis,  float  angle)  {  tmpVec.set(point);  tmpVec.sub(position);  translate(tmpVec);  rotate(axis,  angle);  tmpVec.rotate(axis,  angle);  translate(tmpVec.set(-tmpVec.x,  -tmpVec.y,  -tmpVec.z));  translate(-tmpVec.x,  -tmpVec.y,  -tmpVec.z);  }  public  void  translate  (float  x,  float  y,  float  z)  {  position.add(x,  y,  z);  	translate(-tmpVec.x,  -tmpVec.y,  -tmpVec.z);  
elasticsearch_7c53ef10849b327cd1ecb54365ff1055d062249d	buggy:  if  (length  >  1  &&  data[0]  ==  0x00  &&  data[1]  ==  0x00)  {  context:  public  static  XContentType  xContentType(byte[]  data)  {  return  xContentType(data,  0,  data.length);  }  public  static  XContentType  xContentType(byte[]  data,  int  offset,  int  length)  {  length  =  length  <  GUESS_HEADER_LENGTH  ?  length  :  GUESS_HEADER_LENGTH;          if  (length  >  1  &&  data[0]  ==  0x00  &&  data[1]  ==  0x00)  {          if  (length  >  1  &&  data[offset]  ==  0x00  &&  data[offset  +  1]  ==  0x00)  {  return  XContentType.XSON;  }  for  (int  i  =  offset;  i  <  length;  i++)  {  if  (data[i]  ==  '{')  {  return  XContentType.JSON;  }  }  return  null;  	if  (length  >  1  &&  data[offset]  ==  0x00  &&  data[offset  +  1]  ==  0x00)  {  
elasticsearch_549e9c7019213b58f05081f16cb4f0537f7bcfc3	buggy:  return  clusterState.routingTable().allShardsGrouped(concreteIndices);  context:  service.cache().clear();  }  }  return  new  ShardClearIndicesCacheResponse(request.index(),  request.shardId());  }          return  clusterState.routingTable().allShardsGrouped(concreteIndices);          return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  }  }  	return  clusterState.routingTable().allActiveShardsGrouped(concreteIndices,  true);  
libgdx_17cd60e4fd41cf261f05d3270b56c3ef79ace256	buggy:  return  new  IOSApplication(new  DownloadTest(),  config);  context:  public  class  IOSRobovmTests  extends  IOSApplication.Delegate  {  protected  IOSApplication  createApplication()  {  IOSApplicationConfiguration  config  =  new  IOSApplicationConfiguration();  config.useAccelerometer  =  false;  return  new  IOSApplication(new  DownloadTest(),  config);  return  new  IOSApplication(new  BulletTestCollection(),  config);  }  public  static  void  main(String[]  argv)  {  NSAutoreleasePool  pool  =  new  NSAutoreleasePool();  UIApplication.main(argv,  null,  IOSRobovmTests.class);  pool.close();  }  }  	return  new  IOSApplication(new  BulletTestCollection(),  config);  
elasticsearch_f7b538e17f294eb93cad2b34d027c60425906153	buggy:  out.writeBytesReference(content,  true);  context:  shardId.writeTo(out);  out.writeUTF(name);  out.writeVLong(position);  out.writeVLong(length);  if  (checksum  ==  null)  {  out.writeBoolean(false);  }  else  {  out.writeBoolean(true);  out.writeUTF(checksum);  }          out.writeBytesReference(content,  true);          out.writeBytesReference(content);  }  public  String  toString()  {  return  shardId  +   ":  name=' "  +  name  +  '\''  +   ",  position= "  +  position  +   ",  length= "  +  length;  }  	out.writeBytesReference(content);  
elasticsearch_faf34d745d9fa30897e4e22fb09e3141900042d6	buggy:  builder.field( "_indexed_chars ",  10);  context:  boolean  exists  =  file.exists();  if  (!exists)  {  return  ExitStatus.IO_ERROR;  }  byte[]  bytes  =  copyToByteArray(file);  builder.field( "_content ",  bytes);  }  if  (size  >=  0)  {                  builder.field( "_indexed_chars ",  10);                  builder.field( "_indexed_chars ",  size);  }  BytesReference  json  =  builder.endObject().endObject().bytes();  ParseContext.Document  doc  =  docMapper.parse(json).rootDoc();  terminal.println( "##  Extracted  text ");  terminal.println( "---------------------  BEGIN  ----------------------- ");  	builder.field( "_indexed_chars ",  size);  
elasticsearch_76d042f3c5c4c4fcce91a09e1d10204ff7dace36	buggy:  if  (params  ==  null)  {  context:  public  CustomScoreQueryBuilder  lang(String  lang)  {  this.lang  =  lang;  return  this;  }  public  CustomScoreQueryBuilder  params(Map<String,  Object>  params)  {          if  (params  ==  null)  {          if  (this.params  ==  null)  {  this.params  =  params;  }  else  {  this.params.putAll(params);  }  return  this;  }  	if  (this.params  ==  null)  {  
elasticsearch_e58930180693ca4505030d76bc417a45d3e7e273	buggy:  entries.release();  context:  List<InternalFullHistogramFacet.FullEntry>  entries1  =  new  ArrayList<>(entries.v().size());  final  boolean[]  states  =  entries.v().allocated;  final  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  InternalFullHistogramFacet.FullEntry  value  =  (InternalFullHistogramFacet.FullEntry)  values[i];  entries1.add(value);  }  }          entries.release();          entries.close();  return  new  InternalFullHistogramFacet(facetName,  comparatorType,  entries1);  }  public  static  long  bucket(double  value,  long  interval)  {  return  (((long)  (value  /  interval))  *  interval);  }  class  Collector  extends  FacetExecutor.Collector  {  	entries.close();  
elasticsearch_fc6bc4c4776a2f710f57616e3495aaf6a230c4d3	buggy:  Histogram.Bucket  bucket  =  histo.getByKey(1l);  context:  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0)  .subAggregation(filter( "filter ").filter(matchAllFilter())))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  Matchers.notNullValue());          Histogram.Bucket  bucket  =  histo.getByKey(1l);          Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  assertThat(bucket,  Matchers.notNullValue());  Filter  filter  =  bucket.getAggregations().get( "filter ");  assertThat(filter,  Matchers.notNullValue());  assertThat(filter.getName(),  equalTo( "filter "));  assertThat(filter.getDocCount(),  is(0l));  }  }  	Histogram.Bucket  bucket  =  histo.getBucketByKey(1l);  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  request.indices(indices);  context:  public  class  IndicesExistsRequestBuilder  extends  MasterNodeOperationRequestBuilder<IndicesExistsRequest,  IndicesExistsResponse,  IndicesExistsRequestBuilder>  {  public  IndicesExistsRequestBuilder(IndicesAdminClient  indicesClient,  String...  indices)  {  super((InternalIndicesAdminClient)  indicesClient,  new  IndicesExistsRequest(indices));  }  public  IndicesExistsRequestBuilder  setIndices(String...  indices)  {          request.indices(indices);          request.setIndices(indices);  return  this;  }  protected  void  doExecute(ActionListener<IndicesExistsResponse>  listener)  {  ((IndicesAdminClient)  client).exists(request,  listener);  }  }  	request.setIndices(indices);  
elasticsearch_61eac483ede9f6c6c72439abcddc838d6a41a588	buggy:  if  ( "benchmark ".equals(feature)  &&  ElasticsearchIntegrationTest.immutableCluster().numBenchNodes()  >  0)  {  context:  private  Features()  {  }  public  static  boolean  areAllSupported(List<String>  features)  {  for  (String  feature  :  features)  {              if  ( "benchmark ".equals(feature)  &&  ElasticsearchIntegrationTest.immutableCluster().numBenchNodes()  >  0)  {              if  ( "benchmark ".equals(feature)  &&  ElasticsearchIntegrationTest.cluster().numBenchNodes()  >  0)  {  continue;  }  if  (!SUPPORTED.contains(feature))  {  return  false;  }  }  return  true;  }  	if  ( "benchmark ".equals(feature)  &&  ElasticsearchIntegrationTest.cluster().numBenchNodes()  >  0)  {  
libgdx_f051bfd17154fe5974bd0af2b10e2926fe8191e8	buggy:  WorldManifold  manifold  =  contact.GetWorldManifold();  context:  gl.glPointSize(4);  renderer.begin(GL10.GL_POINTS);  for  (int  i  =  0;  i  <  world.getContactCount();  i++)  {  Contact  contact  =  world.getContactList().get(i);  if  (contact.isTouching())  {  WorldManifold  manifold  =  contact.GetWorldManifold();  WorldManifold  manifold  =  contact.getWorldManifold();  int  numContactPoints  =  manifold.getNumberOfContactPoints();  for  (int  j  =  0;  j  <  numContactPoints;  j++)  {  Vector2  point  =  manifold.getPoints()[j];  renderer.color(0,  1,  0,  1);  renderer.vertex(point.x,  point.y,  0);  }  }  }  	WorldManifold  manifold  =  contact.getWorldManifold();  
libgdx_5c4859567826eafeea62de32da1c910baa1115b8	buggy:  throw  new  RuntimeException( "Couldn't  load  shared  library:  ' "  +  sharedLibName  +   "'  for  target   "  context:  if  (isMac)  {  loaded  =  loadLibrary( "lib "  +  sharedLibName  +   ".dylib ");  }  if  (isAndroid)  {  System.loadLibrary(sharedLibName);  loaded  =  true;  }  if  (loaded)  {  loadedLibraries.add(sharedLibName);  }  else  {  throw  new  RuntimeException( "Couldn't  load  shared  library:  ' "  +  sharedLibName  +   "'  for  target   "  throw  new  RuntimeException( "Couldn't  load  shared  library  ' "  +  sharedLibName  +   "'  for  target:   "  System.getProperty( "os.name ")  +   ",   "  +  (is64Bit  ?   "64-bit "  :   "32-bit "));  }  }  }  	throw  new  RuntimeException( "Couldn't  load  shared  library  ' "  +  sharedLibName  +   "'  for  target:   "  
elasticsearch_60a73c475f37e7ed4d0db2ae372183536dfa8ab4	buggy:  if  (!IndexMetaData.dynamicSettings().contains(key))  {  context:  if  (key.equals(IndexMetaData.SETTING_NUMBER_OF_SHARDS))  {  listener.onFailure(new  ElasticSearchIllegalArgumentException( "can't  change  the  number  of  shards  for  an  index "));  return;  }  }  final  Settings  closeSettings  =  updatedSettingsBuilder.build();  final  Set<String>  removedSettings  =  Sets.newHashSet();  for  (String  key  :  updatedSettingsBuilder.internalMap().keySet())  {              if  (!IndexMetaData.dynamicSettings().contains(key))  {              if  (!IndexMetaData.hasDynamicSetting(key))  {  removedSettings.add(key);  }  }  if  (!removedSettings.isEmpty())  {  for  (String  removedSetting  :  removedSettings)  {  updatedSettingsBuilder.remove(removedSetting);  }  }  	if  (!IndexMetaData.hasDynamicSetting(key))  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<Throwable>(null);  context:  public  class  MemoryCircuitBreakerTests  extends  ElasticsearchTestCase  {  public  void  testThreadedUpdatesToBreaker()  throws  Exception  {  final  int  NUM_THREADS  =  5;  final  int  BYTES_PER_THREAD  =  1000;  final  Thread[]  threads  =  new  Thread[NUM_THREADS];  final  AtomicBoolean  tripped  =  new  AtomicBoolean(false);          final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<Throwable>(null);          final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<>(null);  final  MemoryCircuitBreaker  breaker  =  new  MemoryCircuitBreaker(new  ByteSizeValue((BYTES_PER_THREAD  *  NUM_THREADS)  -  1),  1.0,  logger);  for  (int  i  =  0;  i  <  NUM_THREADS;  i++)  {  threads[i]  =  new  Thread(new  Runnable()  {  public  void  run()  {  for  (int  j  =  0;  j  <  BYTES_PER_THREAD;  j++)  {  	final  AtomicReference<Throwable>  lastException  =  new  AtomicReference<>(null);  
elasticsearch_880f6266ec1fb1ff003caab39106b8c442e6c0c3	buggy:  throw  new  MapperException( "Malformed  json,  after  type  is  must  start  with  an  object ");  context:  }  if  (!jp.getCurrentName().equals(type))  {  if  (type  ==  null)  {  throw  new  MapperException( "Json  content  type  [ "  +  jp.getCurrentName()  +   "]  does  not  match  the  type  of  the  mapper  [ "  +  type  +   "] ");  }  }  else  {  token  =  jp.nextToken();  if  (token  !=  JsonToken.START_OBJECT)  {                      throw  new  MapperException( "Malformed  json,  after  type  is  must  start  with  an  object ");                      throw  new  MapperException( "Malformed  json,  a  field  with  the  same  name  as  the  type  much  be  an  object  json  with  the  properties/fields  within  it ");  }  }  if  (sourceFieldMapper.enabled())  {  sourceFieldMapper.parse(jsonContext);  }  if  (id  !=  null)  {  	throw  new  MapperException( "Malformed  json,  a  field  with  the  same  name  as  the  type  much  be  an  object  json  with  the  properties/fields  within  it ");  
elasticsearch_66f011ae76d54f32d4c925315e9179527cc2ff4e	buggy:  channel.sendResponse(new  JsonThrowableRestResponse(request,  e));  context:  public  void  dispatchRequest(final  RestRequest  request,  final  RestChannel  channel)  {  final  RestHandler  handler  =  getHandler(request);  if  (handler  ==  null)  {  channel.sendResponse(new  StringRestResponse(BAD_REQUEST,   "No  handler  found  for  uri  [ "  +  request.uri()  +   "]  and  method  [ "  +  request.method()  +   "] "));  return;  }  try  {  handler.handleRequest(request,  channel);  }  catch  (Exception  e)  {  try  {                  channel.sendResponse(new  JsonThrowableRestResponse(request,  e));                  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  }  catch  (IOException  e1)  {  }  }  }  private  RestHandler  getHandler(RestRequest  request)  {  String  path  =  getPath(request);  	channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  
elasticsearch_16ee74268240118c59b64ea3ee2ee854c7566505	buggy:  run(prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1)));  context:  public  class  SimpleQueryTests  extends  ElasticsearchIntegrationTest  {  public  void  testIssue3177()  {          run(prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1)));          prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1)).get();  client().prepareIndex( "test ",   "type1 ",   "1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "2 ").setSource( "field1 ",   "value2 ").execute().actionGet();  client().prepareIndex( "test ",   "type1 ",   "3 ").setSource( "field1 ",   "value3 ").execute().actionGet();  ensureGreen();  waitForRelocation();  optimize();  refresh();  assertThat(  	prepareCreate( "test ").setSettings(ImmutableSettings.settingsBuilder().put( "index.number_of_shards ",  1)).get();  
elasticsearch_8e54319a1d5da66a8a407f01febd5781a72f1ada	buggy:  FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[0]));  context:  final  Collection<NodeAndClient>  nodesAndClients  =  nodes.values();  for  (NodeAndClient  nodeAndClient  :  nodesAndClients)  {  nodeAndClient.resetClient();  }  }  private  void  wipeDataDirectories()  {  if  (!dataDirToClean.isEmpty())  {  try  {                  FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[0]));                  FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[dataDirToClean.size()]));  }  finally  {  this.dataDirToClean.clear();  }  }  }  	FileSystemUtils.deleteRecursively(dataDirToClean.toArray(new  File[dataDirToClean.size()]));  
elasticsearch_cc83c2f848be69a77f1275fe1ff5363dcdd4c955	buggy:  client1.admin().indices().create(createIndexRequest( "test1 ").settings(settingsBuilder().putArray( "index.aliases ",   "test "))).actionGet();  context:  public  class  AliasedIndexDocumentActionsTests  extends  DocumentActionsTests  {  protected  void  createIndex()  {  try  {  client1.admin().indices().prepareDelete( "test1 ").execute().actionGet();  }  catch  (Exception  e)  {  }          client1.admin().indices().create(createIndexRequest( "test1 ").settings(settingsBuilder().putArray( "index.aliases ",   "test "))).actionGet();          client1.admin().indices().create(createIndexRequest( "test1 ").setSettings(settingsBuilder().putArray( "index.aliases ",   "test "))).actionGet();  }  protected  String  getConcreteIndexName()  {  return   "test1 ";  }  	client1.admin().indices().create(createIndexRequest( "test1 ").setSettings(settingsBuilder().putArray( "index.aliases ",   "test "))).actionGet();  
elasticsearch_8ee038574def7f43f5e8501dba57a9c23c82f7f8	buggy:  this.listener  =  listener;  context:  public  void  reset(XContentParser  parser,  Document  document,  String  type,  byte[]  source,  DocumentMapper.ParseListener  listener)  {  this.parser  =  parser;  this.document  =  document;  this.analyzer  =  null;  this.type  =  type;  this.source  =  source;  this.path.reset();  this.parsedIdState  =  ParsedIdState.NO;  this.mappersAdded  =  false;          this.listener  =  listener;          this.listener  =  listener  ==  null  ?  DocumentMapper.ParseListener.EMPTY  :  listener;  this.allEntries  =  new  AllEntries();  this.ignoredValues.clear();  }  public  XContentDocumentMapperParser  docMapperParser()  {  return  this.docMapperParser;  }  	this.listener  =  listener  ==  null  ?  DocumentMapper.ParseListener.EMPTY  :  listener;  
elasticsearch_fe4ba2ad559451ba1cdf61cb7832855e10a93b6e	buggy:  textsToHighlight  =  lookup.source().extractRawValues(mapper.names().fullName());  context:  textsToHighlight.add(docField.stringValue());  }  }  }  catch  (Exception  e)  {  throw  new  FetchPhaseExecutionException(context,   "Failed  to  highlight  field  [ "  +  field.field()  +   "] ",  e);  }  }  else  {  SearchLookup  lookup  =  context.lookup();  lookup.setNextReader(hitContext.reader());  lookup.setNextDocId(hitContext.docId());                      textsToHighlight  =  lookup.source().extractRawValues(mapper.names().fullName());                      textsToHighlight  =  lookup.source().extractRawValues(mapper.names().sourcePath());  }  int  numberOfFragments  =  field.numberOfFragments()  ==  0  ?  1  :  field.numberOfFragments();  ArrayList<TextFragment>  fragsList  =  new  ArrayList<TextFragment>();  try  {  for  (Object  textToHighlight  :  textsToHighlight)  {  String  text  =  textToHighlight.toString();  	textsToHighlight  =  lookup.source().extractRawValues(mapper.names().sourcePath());  
elasticsearch_ce58723cc5b463097725c56aed70941cdb2aefb6	buggy:  indexFieldName  =  fieldMapper.indexName();  context:  Pattern  regexpPattern  =  null;  if  (request.regexp()  !=  null)  {  regexpPattern  =  Pattern.compile(request.regexp(),  Pattern.DOTALL  |  Pattern.CASE_INSENSITIVE);  }  for  (String  fieldName  :  request.fields())  {  TObjectIntHashMap<String>  termsFreqs  =  new  TObjectIntHashMap<String>();  FieldMapper  fieldMapper  =  indexService.mapperService().smartNameFieldMapper(fieldName);  String  indexFieldName  =  fieldName;  if  (fieldMapper  !=  null)  {                      indexFieldName  =  fieldMapper.indexName();                      indexFieldName  =  fieldMapper.names().indexName();  }  indexFieldName  =  StringHelper.intern(indexFieldName);  String  from  =  request.from();  if  (from  ==  null)  {  from  =  request.prefix();  }  else  {  	indexFieldName  =  fieldMapper.names().indexName();  
elasticsearch_e7d13971f35009293a7c1f1145f4fe63c29bbe01	buggy:  if(doc  ==  null  &&  docAsUpsert  ==  true){  context:  }  if  (id  ==  null)  {  validationException  =  addValidationError( "id  is  missing ",  validationException);  }  if  (script  ==  null  &&  doc  ==  null)  {  validationException  =  addValidationError( "script  or  doc  is  missing ",  validationException);  }  if  (script  !=  null  &&  doc  !=  null)  {  validationException  =  addValidationError( "can't  provide  both  script  and  doc ",  validationException);  }          if(doc  ==  null  &&  docAsUpsert  ==  true){          if(doc  ==  null  &&  docAsUpsert){  validationException  =  addValidationError( "can't  say  to  upsert  doc  without  providing  doc ",  validationException);  }  return  validationException;  }  	if(doc  ==  null  &&  docAsUpsert){  
elasticsearch_5014158d6be2ec827f4fc220b8b018b970b11b48	buggy:  .percentTermsToMatch(request.percentTermsToMatch())  context:  }  }  private  void  addMoreLikeThis(MoreLikeThisRequest  request,  BoolQueryBuilder  boolBuilder,  FieldMapper  fieldMapper,  Field  field,  boolean  failOnUnsupportedField)  {  addMoreLikeThis(request,  boolBuilder,  field.name(),  fieldMapper.value(convertField(field)).toString(),  failOnUnsupportedField);  }  private  void  addMoreLikeThis(MoreLikeThisRequest  request,  BoolQueryBuilder  boolBuilder,  String  fieldName,  String  likeText,  boolean  failOnUnsupportedField)  {  MoreLikeThisFieldQueryBuilder  mlt  =  moreLikeThisFieldQuery(fieldName)  .likeText(likeText)                  .percentTermsToMatch(request.percentTermsToMatch())                  .minimumShouldMatch(request.minimumShouldMatch())  .boostTerms(request.boostTerms())  .minDocFreq(request.minDocFreq())  .maxDocFreq(request.maxDocFreq())  .minWordLength(request.minWordLength())  .maxWordLen(request.maxWordLength())  .minTermFreq(request.minTermFreq())  .maxQueryTerms(request.maxQueryTerms())  .stopWords(request.stopWords())  	.minimumShouldMatch(request.minimumShouldMatch())  
elasticsearch_d16efbe47fb0fb48f7d266ba0a1bcf8590fd556e	buggy:  throw  new  NoClassSettingsException( "Failed  to  load  class  setting  [ "  +  setting  +   "]  with  value  [ "  +  get(setting)  +   "] ",  e);  context:  sValue  =  sValue.substring(packageSeparator  +  1);  }  fullClassName  =  prefixValue  +  Strings.capitalize(toCamelCase(sValue))  +  suffixClassName;  try  {  return  (Class<?  extends  T>)  getClassLoader().loadClass(fullClassName);  }  catch  (ClassNotFoundException  e1)  {  fullClassName  =  prefixValue  +  toCamelCase(sValue).toLowerCase()  +   ". "  +  Strings.capitalize(toCamelCase(sValue))  +  suffixClassName;  try  {  return  (Class<?  extends  T>)  getClassLoader().loadClass(fullClassName);  }  catch  (ClassNotFoundException  e2)  {                      throw  new  NoClassSettingsException( "Failed  to  load  class  setting  [ "  +  setting  +   "]  with  value  [ "  +  get(setting)  +   "] ",  e);                      throw  new  NoClassSettingsException( "Failed  to  load  class  setting  [ "  +  setting  +   "]  with  value  [ "  +  get(setting)  +   "] ",  e2);  }  }  }  }  public  String[]  getAsArray(String  settingPrefix)  throws  SettingsException  {  return  getAsArray(settingPrefix,  Strings.EMPTY_ARRAY);  	throw  new  NoClassSettingsException( "Failed  to  load  class  setting  [ "  +  setting  +   "]  with  value  [ "  +  get(setting)  +   "] ",  e2);  
libgdx_7e63bb0ce9d920b9c8e2816164a974732742829b	buggy:  return  this.x  <  x  &&  this.x  +  this.width  >  x  &&  this.y  <  y  &&  this.y  +  this.height  >  y;  context:  public  void  setHeight  (float  height)  {  this.height  =  height;  }  public  boolean  contains  (float  x,  float  y)  {  return  this.x  <  x  &&  this.x  +  this.width  >  x  &&  this.y  <  y  &&  this.y  +  this.height  >  y;  return  this.x  <=  x  &&  this.x  +  this.width  >=  x  &&  this.y  <=  y  &&  this.y  +  this.height  >=  y;  }  public  boolean  contains  (Rectangle  rectangle)  {  float  xmin  =  rectangle.x;  float  xmax  =  xmin  +  rectangle.width;  	return  this.x  <=  x  &&  this.x  +  this.width  >=  x  &&  this.y  <=  y  &&  this.y  +  this.height  >=  y;  
libgdx_22deb2e572586fd56b080714cd706501de3403b4	buggy:  app.listener.destroy();  context:  pause  =  false;  }  if(resume)  {  app.listener.resume();  resume  =  false;  running  =  true;  }  if(destroy)  {  app.listener.destroy();  app.listener.dispose();  destroy  =  false;  }  }  Gdx.input.processEvents(null);  if  (System.nanoTime()  -  frameStart  >  1000000000)  {  fps  =  frames;  	app.listener.dispose();  
libgdx_5fe52950ace33f02fc9f0d3af249263db27290e3	buggy:  float  angle  =  particle.angle  +=  particle.angleDiff  *  angleValue.getScale(percent);  context:  int  updateFlags  =  this.updateFlags;  if  ((updateFlags  &  UPDATE_SCALE)  !=  0)  particle.setScale(particle.scale  +  particle.scaleDiff  *  scaleValue.getScale(percent));  if  ((updateFlags  &  UPDATE_VELOCITY)  !=  0)  {  float  velocity  =  (particle.velocity  +  particle.velocityDiff  *  velocityValue.getScale(percent))  *  delta;  float  velocityX,  velocityY;  if  ((updateFlags  &  UPDATE_ANGLE)  !=  0)  {  float  angle  =  particle.angle  +=  particle.angleDiff  *  angleValue.getScale(percent);  float  angle  =  particle.angle  +  particle.angleDiff  *  angleValue.getScale(percent);  velocityX  =  velocity  *  MathUtils.cosDeg(angle);  velocityY  =  velocity  *  MathUtils.sinDeg(angle);  if  ((updateFlags  &  UPDATE_ROTATION)  !=  0)  {  float  rotation  =  particle.rotation  +  particle.rotationDiff  *  rotationValue.getScale(percent);  if  (aligned)  rotation  +=  angle;  particle.setRotation(rotation);  }  }  else  {  	float  angle  =  particle.angle  +  particle.angleDiff  *  angleValue.getScale(percent);  
elasticsearch_fbd6e85eac4e7fa565c634c6d6fae7e4572e0137	buggy:  return  new  DeletionAwareConstantScoreQuery(context.cacheFilter(fieldFilter(value)));  context:  }  if  (index  ==  Field.Index.NO)  {  return  new  PrefixFilter(UidFieldMapper.TERM_FACTORY.createTerm(Uid.typePrefix(value)));  }  return  new  TermFilter(termFactory.createTerm(value));  }          return  new  DeletionAwareConstantScoreQuery(context.cacheFilter(fieldFilter(value)));          return  new  DeletionAwareConstantScoreQuery(context.cacheFilter(fieldFilter(value),  null));  }  return  true;  }  if  (index  ==  Field.Index.NO  &&  store  ==  Field.Store.NO)  {  	return  new  DeletionAwareConstantScoreQuery(context.cacheFilter(fieldFilter(value),  null));  
elasticsearch_8458138b8c1fb9e3bae572799a17e0269510f8c5	buggy:  final  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest();  context:  PercolateRequest  percolateRequest  =  request.requests().get(slot);  percolateRequest.startTime  =  System.currentTimeMillis();  percolateRequests.add(percolateRequest);  if  (percolateRequest.getRequest()  !=  null)  {  existingDocsRequests.add(percolateRequest.getRequest());  getRequestSlots.add(slot);  }  }  if  (!existingDocsRequests.isEmpty())  {              final  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest();              final  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest(request);  for  (GetRequest  getRequest  :  existingDocsRequests)  {  multiGetRequest.add(  new  MultiGetRequest.Item(getRequest.index(),  getRequest.type(),  getRequest.id())  .routing(getRequest.routing())  );  }  multiGetAction.execute(multiGetRequest,  new  ActionListener<MultiGetResponse>()  {  	final  MultiGetRequest  multiGetRequest  =  new  MultiGetRequest(request);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  AliasMetaData.Builder.toXContent(alias,  builder,  ToXContent.EMPTY_PARAMS);  }  builder.endObject();  builder.endObject();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_25bd9cecd066e7920776eef0885b1c4a905a3156	buggy:  suggest  =  Suggest.readSuggest(in);  context:  return  response;  }  public  void  readFrom(StreamInput  in)  throws  IOException  {  hits  =  readSearchHits(in);  if  (in.readBoolean())  {  facets  =  InternalFacets.readFacets(in);  }  if  (in.readBoolean())  {              suggest  =  Suggest.readSuggest(in);              suggest  =  Suggest.readSuggest(Suggest.Fields.SUGGEST,  in);  }  timedOut  =  in.readBoolean();  }  public  void  writeTo(StreamOutput  out)  throws  IOException  {  hits.writeTo(out);  if  (facets  ==  null)  {  	suggest  =  Suggest.readSuggest(Suggest.Fields.SUGGEST,  in);  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  final  Version  indexVersion  =  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);  context:  private  String  language;  public  StemmerTokenFilterFactory(Index  index,  @IndexSettings  Settings  indexSettings,  @Assisted  String  name,  @Assisted  Settings  settings)  {  super(index,  indexSettings,  name,  settings);  this.language  =  Strings.capitalize(settings.get( "language ",  settings.get( "name ",   "porter ")));  }  public  TokenStream  create(TokenStream  tokenStream)  {          final  Version  indexVersion  =  indexSettings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);          final  Version  indexVersion  =  Version.indexCreated(indexSettings);  if  ( "arabic ".equalsIgnoreCase(language))  {  return  new  ArabicStemFilter(tokenStream);  }  else  if  ( "armenian ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  ArmenianStemmer());  }  else  if  ( "basque ".equalsIgnoreCase(language))  {  return  new  SnowballFilter(tokenStream,  new  BasqueStemmer());  }  else  if  ( "brazilian ".equalsIgnoreCase(language))  {  	final  Version  indexVersion  =  Version.indexCreated(indexSettings);  
elasticsearch_4b25e6b63e67bd5ebf42c8a62faf7ac12dbea5ec	buggy:  BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);  context:  }  if  (request.hasParam( "id_cache "))  {  clearIndicesCacheRequest.idCache(request.paramAsBoolean( "id_cache ",  clearIndicesCacheRequest.idCache()));  }  if  (request.hasParam( "recycler "))  {  clearIndicesCacheRequest.recycler(request.paramAsBoolean( "recycler ",  clearIndicesCacheRequest.recycler()));  }  clearIndicesCacheRequest.fields(request.paramAsStringArray( "fields ",  clearIndicesCacheRequest.fields()));  clearIndicesCacheRequest.filterKeys(request.paramAsStringArray( "filter_keys ",  clearIndicesCacheRequest.filterKeys()));              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.SINGLE_THREAD);              BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  if  (operationThreading  ==  BroadcastOperationThreading.NO_THREADS)  {  operationThreading  =  BroadcastOperationThreading.THREAD_PER_SHARD;  }  clearIndicesCacheRequest.operationThreading(operationThreading);  }  catch  (Exception  e)  {  try  {  XContentBuilder  builder  =  RestXContentBuilder.restContentBuilder(request);  	BroadcastOperationThreading  operationThreading  =  BroadcastOperationThreading.fromString(request.param( "operationThreading "),  BroadcastOperationThreading.THREAD_PER_SHARD);  
elasticsearch_e33dbcd93e3b1d0beac7e1629a790a28e5cab749	buggy:  return  termFactory.createTerm(uid);  context:  return  Uid.createUid(type,  value);  }  return  value;  }  public  Term  term(String  type,  String  id)  {  return  term(Uid.createUid(type,  id));  }  public  Term  term(String  uid)  {          return  termFactory.createTerm(uid);          return  names().createIndexNameTerm(uid);  }  return  CONTENT_TYPE;  }  builder.startObject(CONTENT_TYPE);  	return  names().createIndexNameTerm(uid);  
elasticsearch_673655cc7b7ab115257f75e64be4c9d918fc9144	buggy:  MapperService.SmartNameObjectMapper  mapper  =  parseContext.mapperService().smartNameObjectMapper(path);  context:  if  (path  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  requires  'path'  field ");  }  if  (filter  !=  null)  {  query  =  new  DeletionAwareConstantScoreQuery(filter);  }  query.setBoost(boost);          MapperService.SmartNameObjectMapper  mapper  =  parseContext.mapperService().smartNameObjectMapper(path);          MapperService.SmartNameObjectMapper  mapper  =  parseContext.smartObjectMapper(path);  if  (mapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  failed  to  find  nested  object  under  path  [ "  +  path  +   "] ");  }  ObjectMapper  objectMapper  =  mapper.mapper();  if  (objectMapper  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[nested]  failed  to  find  nested  object  under  path  [ "  +  path  +   "] ");  }  if  (!objectMapper.nested().isNested())  {  	MapperService.SmartNameObjectMapper  mapper  =  parseContext.smartObjectMapper(path);  
libgdx_e2568bc8ae60e5f9137e8ec0c9d2f2bc5ae61a2b	buggy:  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler  clean  postcompile  -v ");  context:   "ois-v1-4svn/src/win32/*.cpp "  };  win32home.headerDirs  =  new  String[]  {   "ois-v1-4svn/includes ",   "dinput/ "  };  win32home.cIncludes  =  new  String[0];  win32home.linkerFlags  +=   "   ";  //  FIXME  -  Needs  to  be   "-shared  -o  [modules]  -ldinput8  -ldxguid ".  new  AntScriptGenerator().generate(buildConfig,  win32home);  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler  clean  postcompile  -v ");  BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler=true  clean  postcompile  -v ");  BuildExecutor.executeAnt( "jni/build.xml ",   "pack-natives ");  }  }  	BuildExecutor.executeAnt( "jni/build-windows32home.xml ",   "-Dhas-compiler=true  clean  postcompile  -v ");  
elasticsearch_77b6d1d8b8d304578fd97ea159b7109671eaacc6	buggy:  logger.debug( "starting  recovery  from  {} ",  shardGateway);  context:  if  (indexShard.ignoreRecoveryAttempt())  {  listener.onIgnoreRecovery( "Interrupted  while  waiting  for  recovery,  but  we  should  ignore  ... ");  return;  }  listener.onRecoveryFailed(new  IndexShardGatewayRecoveryException(shardId,   "Interrupted  while  waiting  to  recovery ",  e));  }  }  throttlingWaitTime.stop();  try  {                      logger.debug( "starting  recovery  from  {} ",  shardGateway);                      logger.debug( "starting  recovery  from  {}  ... ",  shardGateway);  StopWatch  stopWatch  =  new  StopWatch().start();  IndexShardGateway.RecoveryStatus  recoveryStatus  =  shardGateway.recover();  lastIndexVersion  =  recoveryStatus.index().version();  lastTranslogId  =  -1;  lastTranslogPosition  =  0;  lastTranslogLength  =  0;  	logger.debug( "starting  recovery  from  {}  ... ",  shardGateway);  
elasticsearch_1114835de500230f14972f41aee2ae6be9b6aead	buggy:  return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true);  context:  return  new  ShardRefreshResponse(request.index(),  request.shardId());  }  protected  GroupShardsIterator  shards(ClusterState  clusterState,  RefreshRequest  request,  String[]  concreteIndices)  {          return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true);          return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true,  true);  }  protected  ClusterBlockException  checkGlobalBlock(ClusterState  state,  RefreshRequest  request)  {  return  state.blocks().globalBlockedException(ClusterBlockLevel.METADATA);  }  	return  clusterState.routingTable().allAssignedShardsGrouped(concreteIndices,  true,  true);  
elasticsearch_7aac88cf5c6f644858460dccdd4386c630b1596c	buggy:  return  acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));  context:  ParentDocSet(IndexReader  reader,  THashSet<HashedBytesArray>  parents,  IdReaderTypeCache  typeCache,  Bits  acceptDocs)  {  super(reader.maxDoc());  this.reader  =  reader;  this.parents  =  parents;  this.typeCache  =  typeCache;  this.acceptDocs  =  acceptDocs;  }  public  boolean  get(int  doc)  {                  return  acceptDocs.get(doc)  &&  parents.contains(typeCache.idByDoc(doc));                  return  (acceptDocs  ==  null  ||  acceptDocs.get(doc))  &&  parents.contains(typeCache.idByDoc(doc));  }  }  static  class  UidCollector  extends  NoopCollector  {  final  String  parentType;  final  SearchContext  context;  final  THashSet<HashedBytesArray>  collectedUids;  	return  (acceptDocs  ==  null  ||  acceptDocs.get(doc))  &&  parents.contains(typeCache.idByDoc(doc));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  List<String>  result  =  new  ArrayList<String>();  context:  try  {  return  loadWordList(new  InputStreamReader(wordListFile.openStream(),  Charsets.UTF_8),   "# ");  }  catch  (IOException  ioe)  {  String  message  =  String.format(Locale.ROOT,   "IOException  while  reading  %s_path:  %s ",  settingPrefix,  ioe.getMessage());  throw  new  ElasticsearchIllegalArgumentException(message);  }  }  public  static  List<String>  loadWordList(Reader  reader,  String  comment)  throws  IOException  {          final  List<String>  result  =  new  ArrayList<String>();          final  List<String>  result  =  new  ArrayList<>();  BufferedReader  br  =  null;  try  {  if  (reader  instanceof  BufferedReader)  {  br  =  (BufferedReader)  reader;  }  else  {  br  =  new  BufferedReader(reader);  }  String  word  =  null;  	final  List<String>  result  =  new  ArrayList<>();  
elasticsearch_66825ac851a2578686eefca08f1900bf86f3d443	buggy:  addDocValue(context,  value);  context:  context.allEntries().addText(names.fullName(),  parser.text(),  boost);  }  }  }  if  (fieldType.indexed()  ||  fieldType.stored())  {  CustomShortNumericField  field  =  new  CustomShortNumericField(this,  value,  fieldType);  field.setBoost(boost);  fields.add(field);  }  if  (hasDocValues())  {              addDocValue(context,  value);              addDocValue(context,  fields,  value);  }  }  protected  String  contentType()  {  return  CONTENT_TYPE;  }  	addDocValue(context,  fields,  value);  
libgdx_ddafe13ef1a0081a217a6107e430d2e160c3b847	buggy:  if  (particle  ==  null)  continue;  context:  }  public  void  setSprite  (Sprite  sprite)  {  this.sprite  =  sprite;  if  (sprite  ==  null)  return;  float  originX  =  sprite.getOriginX();  float  originY  =  sprite.getOriginY();  Texture  texture  =  sprite.getTexture();  for  (int  i  =  0,  n  =  particles.length;  i  <  n;  i++)  {  Particle  particle  =  particles[i];  if  (particle  ==  null)  continue;  if  (particle  ==  null)  break;  particle.setTexture(texture);  particle.setOrigin(originX,  originY);  }  }  	if  (particle  ==  null)  break;  
elasticsearch_8ab22a53fe2a3718adfd138e57b89b135a0a4b5e	buggy:  return  mapping.containsKey( "type ")  ?  mapping.get( "type ").toString()  :  dynamicType;  context:  }  }  return  true;  }  public  boolean  hasType()  {  return  mapping.containsKey( "type ");  }  public  String  mappingType(String  dynamicType)  {          return  mapping.containsKey( "type ")  ?  mapping.get( "type ").toString()  :  dynamicType;          return  mapping.containsKey( "type ")  ?  mapping.get( "type ").toString().replace( "{dynamic_type} ",  dynamicType).replace( "{dynamicType} ",  dynamicType)  :  dynamicType;  }  private  boolean  patternMatch(String  pattern,  String  str)  {  if  (matchType  ==  MatchType.SIMPLE)  {  return  Regex.simpleMatch(pattern,  str);  }  return  str.matches(pattern);  }  	return  mapping.containsKey( "type ")  ?  mapping.get( "type ").toString().replace( "{dynamic_type} ",  dynamicType).replace( "{dynamicType} ",  dynamicType)  :  dynamicType;  
elasticsearch_1ed07a0c5077a16bff2fd30440d032543e1d6eaf	buggy:  return  ThreadPool.Names.SEARCH;  context:  public  TransportShardMultiGetAction(Settings  settings,  ClusterService  clusterService,  TransportService  transportService,  IndicesService  indicesService,  ThreadPool  threadPool)  {  super(settings,  threadPool,  clusterService,  transportService);  this.indicesService  =  indicesService;  this.realtime  =  settings.getAsBoolean( "action.get.realtime ",  true);  }  protected  String  executor()  {          return  ThreadPool.Names.SEARCH;          return  ThreadPool.Names.GET;  }  protected  String  transportAction()  {  return  MultiGetAction.NAME  +   "/shard ";  }  	return  ThreadPool.Names.GET;  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  PrimaryResponse<BulkShardResponse,  BulkShardRequest>(shardRequest.request,  response,  ops);  context:  }  if  (request.refresh())  {  try  {  indexShard.refresh(new  Engine.Refresh( "refresh_flag_bulk ").force(false));  }  catch  (Throwable  e)  {  }  }  BulkShardResponse  response  =  new  BulkShardResponse(new  ShardId(request.index(),  request.shardId()),  responses);          return  new  PrimaryResponse<BulkShardResponse,  BulkShardRequest>(shardRequest.request,  response,  ops);          return  new  PrimaryResponse<>(shardRequest.request,  response,  ops);  }  static  class  WriteResult  {  final  Object  response;  final  Tuple<String,  String>  mappingToUpdate;  final  Engine.IndexingOperation  op;  	return  new  PrimaryResponse<>(shardRequest.request,  response,  ops);  
elasticsearch_f4bf0d5112b5c6f29b651586d72c3972db5a2834	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);  context:  return  new  GetAliasesRequest();  }  protected  GetAliasesResponse  newResponse()  {  return  new  GetAliasesResponse();  }  protected  void  masterOperation(GetAliasesRequest  request,  ClusterState  state,  ActionListener<GetAliasesResponse>  listener)  throws  ElasticSearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.ignoreIndices(),  true);          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  request.indices(concreteIndices);  ImmutableOpenMap<String,  List<AliasMetaData>>  result  =  (ImmutableOpenMap)  state.metaData().findAliases(request.aliases(),  request.indices());  listener.onResponse(new  GetAliasesResponse(result));  }  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  
elasticsearch_d4547c629f53ad76ea463dc0acb1f26f0a2b784b	buggy:  ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealth( "test ")  context:  }  catch  (ElasticSearchException  e)  {  assertThat(e.unwrapCause(),  instanceOf(SearchPhaseExecutionException.class));  }  }  startNode( "server2 ");  assertThat(client( "server1 ").admin().cluster().prepareHealth().setWaitForNodes( "2 ").execute().actionGet().timedOut(),  equalTo(false));          ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealth( "test ")          ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest( "test ")  .waitForYellowStatus().waitForRelocatingShards(0).waitForActiveShards(6)).actionGet();  assertThat(clusterHealth.timedOut(),  equalTo(false));  assertThat(clusterHealth.status(),  equalTo(ClusterHealthStatus.YELLOW));  assertThat(clusterHealth.activeShards(),  equalTo(6));  refreshResponse  =  client( "server1 ").admin().indices().refresh(refreshRequest( "test ")).actionGet();  assertThat(refreshResponse.totalShards(),  equalTo(9));  	ClusterHealthResponse  clusterHealth  =  client( "server1 ").admin().cluster().health(clusterHealthRequest( "test ")  
libgdx_73ecf9f3bb8249bbf68e29fc4e654fdbb912b01d	buggy:  mesh  =  new  Mesh(true,  false,  chunk.vertices.length  /  3,  chunk.indices.length,  new  VertexAttribute(  context:  if  (chunk  ==  null)  {  renderer  =  new  ImmediateModeRenderer();  chunk  =  new  TerrainChunk(32,  32,  4);  Random  rand  =  new  Random();  int  len  =  chunk.vertices.length;  for  (int  i  =  3;  i  <  len;  i  +=  4)  chunk.vertices[i]  =  Color.toFloatBits(rand.nextInt(255),  rand.nextInt(255),  rand.nextInt(255),  255);  mesh  =  new  Mesh(true,  false,  chunk.vertices.length  /  3,  chunk.indices.length,  new  VertexAttribute(  mesh  =  new  Mesh(true,  chunk.vertices.length  /  3,  chunk.indices.length,  new  VertexAttribute(  VertexAttributes.Usage.Position,  3,   "a_position "),  new  VertexAttribute(VertexAttributes.Usage.ColorPacked,  4,   "a_color "));  mesh.setVertices(chunk.vertices);  mesh.setIndices(chunk.indices);  camera  =  new  PerspectiveCamera();  camera.getPosition().set(0,  5,  5);  	mesh  =  new  Mesh(true,  chunk.vertices.length  /  3,  chunk.indices.length,  new  VertexAttribute(  
elasticsearch_384f8a4f4268b7261ac5f4807f91f2346abee495	buggy:  context.fetchResult().hits(new  InternalSearchHits(hits,  context.queryResult().topDocs().totalHits));  context:  if  (hitField  ==  null)  {  hitField  =  new  InternalSearchHitField(scriptField.name(),  new  ArrayList<Object>(2));  searchHit.fields().put(scriptField.name(),  hitField);  }  hitField.values().add(value);  }  }  doExplanation(context,  docId,  searchHit);  }          context.fetchResult().hits(new  InternalSearchHits(hits,  context.queryResult().topDocs().totalHits));          context.fetchResult().hits(new  InternalSearchHits(hits,  context.queryResult().topDocs().totalHits,  context.queryResult().topDocs().getMaxScore()));  highlightPhase.execute(context);  }  private  void  doExplanation(SearchContext  context,  int  docId,  InternalSearchHit  searchHit)  {  if  (context.explain())  {  try  {  searchHit.explanation(context.searcher().explain(context.query(),  docId));  	context.fetchResult().hits(new  InternalSearchHits(hits,  context.queryResult().topDocs().totalHits,  context.queryResult().topDocs().getMaxScore()));  
elasticsearch_595acd695e43bc3de3afe8c537866066ba9e5ff6	buggy:  stream  =  analyzer.reusableTokenStream(field,  new  FastStringReader(request.text()));  context:  analyzer  =  indexService.analysisService().defaultIndexAnalyzer();  }  }  if  (analyzer  ==  null)  {  throw  new  ElasticSearchIllegalArgumentException( "failed  to  find  analyzer ");  }  List<AnalyzeResponse.AnalyzeToken>  tokens  =  Lists.newArrayList();  TokenStream  stream  =  null;  try  {              stream  =  analyzer.reusableTokenStream(field,  new  FastStringReader(request.text()));              stream  =  analyzer.tokenStream(field,  new  FastStringReader(request.text()));  stream.reset();  CharTermAttribute  term  =  stream.addAttribute(CharTermAttribute.class);  PositionIncrementAttribute  posIncr  =  stream.addAttribute(PositionIncrementAttribute.class);  OffsetAttribute  offset  =  stream.addAttribute(OffsetAttribute.class);  TypeAttribute  type  =  stream.addAttribute(TypeAttribute.class);  int  position  =  0;  while  (stream.incrementToken())  {  	stream  =  analyzer.tokenStream(field,  new  FastStringReader(request.text()));  
elasticsearch_27481800bc6fe4fea9ca13896e30ed650d621a29	buggy:  Query  query  =  mapper.fuzzyQuery(term.text(),  fuzziness,  fuzzyPrefixLength,  maxExpansions);  context:  }  return  wrapSmartNameQuery(mpq,  smartNameFieldMappers,  parseContext);  }  throw  new  ElasticSearchIllegalStateException( "No  type  found  for  [ "  +  type  +   "] ");  }  private  Query  newTermQuery(@Nullable  FieldMapper  mapper,  Term  term)  {  if  (fuzziness  !=  null)  {  if  (mapper  !=  null)  {                  Query  query  =  mapper.fuzzyQuery(term.text(),  fuzziness,  fuzzyPrefixLength,  maxExpansions);                  Query  query  =  mapper.fuzzyQuery(term.text(),  fuzziness,  fuzzyPrefixLength,  maxExpansions,  transpositions);  if  (query  instanceof  FuzzyQuery)  {  QueryParsers.setRewriteMethod((FuzzyQuery)  query,  fuzzyRewriteMethod);  }  }  String  text  =  term.text();  int  edits  =  FuzzyQuery.floatToEdits(Float.parseFloat(fuzziness),  text.codePointCount(0,  text.length()));  	Query  query  =  mapper.fuzzyQuery(term.text(),  fuzziness,  fuzzyPrefixLength,  maxExpansions,  transpositions);  
libgdx_00bc8c303c1f7c1bb905a0bba4e9aa90d0bfef91	buggy:  public  void  click  (Actor  actor)  {  context:  Table  table  =  new  Table();  table.setBackground(patch);  table.enableClipping(stage);  table.size(75,  75);  table.add(label);  table.setClickListener(new  ClickListener()  {  public  void  click  (Actor  actor)  {  public  void  click  (Actor  actor,  float  x,  float  y)  {  }  });  root.debug();  root.add(new  Label( "meow  meow  meow  meow  meow  meow  meow  meow  meow  meow  meow  meow  meow   ",  skin)).colspan(3);  root.row();  root.add(new  Button( "Text  Button ",  skin));  	public  void  click  (Actor  actor,  float  x,  float  y)  {  
elasticsearch_02cb2976917e3a6edb5e0caf5a65a95e3bff5f3a	buggy:  putMappingRequest.mappingSource(request.contentAsString());  context:  super(settings,  client);  controller.registerHandler(PUT,   "/{index}/_mapping ",  this);  controller.registerHandler(PUT,   "/{index}/{type}/_mapping ",  this);  }  PutMappingRequest  putMappingRequest  =  putMappingRequest(splitIndices(request.param( "index ")));  putMappingRequest.type(request.param( "type "));          putMappingRequest.mappingSource(request.contentAsString());          putMappingRequest.source(request.contentAsString());  putMappingRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));  putMappingRequest.ignoreConflicts(request.paramAsBoolean( "ignore_conflicts ",  putMappingRequest.ignoreConflicts()));  client.admin().indices().putMapping(putMappingRequest,  new  ActionListener<PutMappingResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  	putMappingRequest.source(request.contentAsString());  
elasticsearch_5c00dc577388c9efbb13e612dec88a49b7165141	buggy:  Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.searcher()  :  searcher;  context:  SearchContext  createContext(ShardSearchRequest  request)  throws  ElasticSearchException  {  return  createContext(request,  null);  }  SearchContext  createContext(ShardSearchRequest  request,  @Nullable  Engine.Searcher  searcher)  throws  ElasticSearchException  {  IndexService  indexService  =  indicesService.indexServiceSafe(request.index());  IndexShard  indexShard  =  indexService.shardSafe(request.shardId());  SearchShardTarget  shardTarget  =  new  SearchShardTarget(clusterService.localNode().id(),  request.index(),  request.shardId());          Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.searcher()  :  searcher;          Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher()  :  searcher;  SearchContext  context  =  new  DefaultSearchContext(idGenerator.incrementAndGet(),  request,  shardTarget,  engineSearcher,  indexService,  indexShard,  scriptService,  cacheRecycler);  SearchContext.setCurrent(context);  try  {  context.scroll(request.scroll());  parseSource(context,  request.source());  parseSource(context,  request.extraSource());  	Engine.Searcher  engineSearcher  =  searcher  ==  null  ?  indexShard.acquireSearcher()  :  searcher;  
elasticsearch_01b18ad219933679256753fa8639c37d11cac1ff	buggy:  BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator());  context:  }  }  if  (reduced  ==  null)  {  return  (UnmappedTerms)  aggregations.get(0);  }  final  int  size  =  Math.min(requiredSize,  buckets.v().size());          BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator());          BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  boolean[]  states  =  buckets.v().allocated;  Object[]  internalBuckets  =  buckets.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  List<DoubleTerms.Bucket>  sameTermBuckets  =  (List<DoubleTerms.Bucket>)  internalBuckets[i];  ordered.insertWithOverflow(sameTermBuckets.get(0).reduce(sameTermBuckets,  reduceContext.cacheRecycler()));  }  }  	BucketPriorityQueue  ordered  =  new  BucketPriorityQueue(size,  order.comparator(null));  
elasticsearch_013e7699c34f84ae6fa899924002fdd59b054397	buggy:  searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());  context:  }  }  });  }  private  SearchRequest  parseSearchRequest(RestRequest  request)  {  String[]  indices  =  RestActions.splitIndices(request.param( "index "));  SearchRequest  searchRequest  =  new  SearchRequest(indices);  if  (request.hasContent())  {              searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength());              searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  }  else  {  String  source  =  request.param( "source ");  if  (source  !=  null)  {  searchRequest.source(source);  }  }  searchRequest.extraSource(parseSearchSource(request));  	searchRequest.source(request.contentByteArray(),  request.contentByteArrayOffset(),  request.contentLength(),  request.contentUnsafe());  
elasticsearch_3770924300a0c22f1db4d31e29bab702216edd79	buggy:  byte[]  buffer  =  new  byte[16  *  1024];  context:  FSDataOutputStream  fileStream;  try  {  fileStream  =  blobStore.fileSystem().create(file,  true);  }  catch  (IOException  e)  {  listener.onFailure(e);  return;  }  try  {  try  {                          byte[]  buffer  =  new  byte[16  *  1024];                          byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  int  bytesRead;  while  ((bytesRead  =  is.read(buffer))  !=  -1)  {  fileStream.write(buffer,  0,  bytesRead);  }  }  finally  {  try  {  is.close();  }  catch  (IOException  ex)  {  	byte[]  buffer  =  new  byte[blobStore.bufferSizeInBytes()];  
libgdx_cf574945282e8bbc934542336be6b0b59036e965	buggy:  if  (pointer  !=  0)  return  false;  context:  this.clipboard  =  Clipboard.getDefaultClipboard();  setText(text);  setWidth(getPrefWidth());  setHeight(getPrefHeight());  initialize();  }  private  void  initialize  ()  {  addListener(new  InputListener()  {  public  boolean  touchDown  (InputEvent  event,  float  x,  float  y,  int  pointer,  int  button)  {  if  (pointer  !=  0)  return  false;  if  (pointer  ==  0  &&  button  !=  0)  return  false;  Stage  stage  =  getStage();  if  (stage  !=  null)  stage.setKeyboardFocus(TextField.this);  keyboard.show(true);  clearSelection();  setCursorPosition(x);  selectionStart  =  cursor;  return  true;  }  	if  (pointer  ==  0  &&  button  !=  0)  return  false;  
elasticsearch_0bef2c66a996d7a30dc369df7db5e7bc34dcf292	buggy:  String  template  =  Streams.copyToStringFromClasspath( "/org/elasticsearch/indices/template/template "  +  randomInt(1)  +   ".json ");  context:  try  {  File  directory  =  temporaryFolder.newFolder();  settingsBuilder.put( "path.conf ",  directory.getPath());  File  templatesDir  =  new  File(directory  +  File.separator  +   "templates ");  templatesDir.mkdir();  File  dst  =  new  File(templatesDir,   "template.json ");              String  template  =  Streams.copyToStringFromClasspath( "/org/elasticsearch/indices/template/template "  +  randomInt(1)  +   ".json ");              String  template  =  Streams.copyToStringFromClasspath( "/org/elasticsearch/indices/template/template "  +  randomInt(2)  +   ".json ");  Files.write(template,  dst,  Charsets.UTF_8);  }  catch  (Exception  e)  {  throw  new  RuntimeException(e);  }  return  settingsBuilder.build();  }  	String  template  =  Streams.copyToStringFromClasspath( "/org/elasticsearch/indices/template/template "  +  randomInt(2)  +   ".json ");  
elasticsearch_185cd680451f283087e515b7ad3a98c14ac0a513	buggy:  interval  =  TimeValue.parseTimeValue(parser.text(),  null).millis();  context:  }  dateTime.setRounding(field,  rounding);  }  else  {  DateFieldParser  fieldParser  =  dateFieldParsers.get(sInterval);  if  (fieldParser  !=  null)  {  DateTimeField  field  =  fieldParser.parse(dateTime.getChronology());  dateTime.setRounding(field,  MutableDateTime.ROUND_FLOOR);  }  else  {  try  {                          interval  =  TimeValue.parseTimeValue(parser.text(),  null).millis();                          interval  =  TimeValue.parseTimeValue(sInterval,  null).millis();  }  catch  (Exception  e)  {  throw  new  FacetPhaseExecutionException(facetName,   "failed  to  parse  interval  [ "  +  sInterval  +   "],  tried  both  as  built  in  intervals  (year/month/...)  and  as  a  time  format ");  }  }  }  }  	interval  =  TimeValue.parseTimeValue(sInterval,  null).millis();  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  target_fuzzy_pos.set(target.collisionCenter).add(random.mul(250));  context:  if  (target  ==  null)  {  target  =  Targeting.getNearestOfType(frigate,  2);  }  if  (target  ==  null)  {  target  =  Targeting.getNearestOfType(frigate,  3);  }  if  (target  !=  null)  {  Vector2  random  =  new  Vector2(MathUtils.cos((float)  ((MathUtils.random()  *  MathUtils.PI  *  2)  *  Math.sqrt(MathUtils.random()))),  MathUtils.sin((float)  ((MathUtils.random()  *  MathUtils.PI  *  2)  *  Math.sqrt(MathUtils.random()))));  target_fuzzy_pos.set(target.collisionCenter).add(random.mul(250));  target_fuzzy_pos.set(target.collisionCenter).add(random.scl(250));  }  }  public  void  update()  {  if  (target  ==  null  ||  !target.alive  ||  MathUtils.random()  <  0.001f)  {  retarget();  }  	target_fuzzy_pos.set(target.collisionCenter).add(random.scl(250));  
libgdx_34ed5fbfe5d918ed411939d351930b0ab1457dd2	buggy:  if  (numUV  >  0)  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  context:  verts[vi++]  =  uv[uvIdx];  verts[vi++]  =  uv[uvIdx  +  1];  }  }  Mesh  mesh  =  null;  ArrayList<VertexAttribute>  attributes  =  new  ArrayList<VertexAttribute>();  attributes.add(new  VertexAttribute(Usage.Position,  3,  ShaderProgram.POSITION_ATTRIBUTE));  if  (numNormals  >  0)  attributes.add(new  VertexAttribute(Usage.Normal,  3,  ShaderProgram.NORMAL_ATTRIBUTE));  if  (numUV  >  0)  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORDS_ATTRIBUTE  +   "0 "));  if  (numUV  >  0)  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  mesh  =  new  Mesh(true,  numFaces  *  3,  0,  attributes.toArray(new  VertexAttribute[attributes.size()]));  mesh.setVertices(verts);  return  mesh;  }  private  static  int  getIndex  (String  index,  int  size)  {  if  (index  ==  null  ||  index.length()  ==  0)  return  0;  	if  (numUV  >  0)  attributes.add(new  VertexAttribute(Usage.TextureCoordinates,  2,  ShaderProgram.TEXCOORD_ATTRIBUTE  +   "0 "));  
libgdx_44747471b08723cfd7ee5c2ff9016c0a4c6fe162	buggy:  return  BufferFactory.newDirectByteBuffer(capacity);  context:  public  static  ByteBuffer  allocateDirect  (int  capacity)  {  if  (capacity  <  0)  {  throw  new  IllegalArgumentException();  }  return  BufferFactory.newDirectByteBuffer(capacity);  return  BufferFactory.newByteBuffer(capacity);  }  	return  BufferFactory.newByteBuffer(capacity);  
elasticsearch_89dd722340df8abe8fdfd30ae6e6ee3bce96ce44	buggy:  wipeIndices(getConcreteIndexName());  context:  public  class  DocumentActionsTests  extends  ElasticsearchIntegrationTest  {  protected  void  createIndex()  {          wipeIndices(getConcreteIndexName());          cluster().wipeIndices(getConcreteIndexName());  createIndex(getConcreteIndexName());  }  protected  String  getConcreteIndexName()  {  return   "test ";  }  	cluster().wipeIndices(getConcreteIndexName());  
elasticsearch_30b34b975c59b0792d35eefa7131140763984698	buggy:  logger.info( "[cluster_shutdown]:  done  shutting  done  all  nodes  except  master,  proceeding  to  master ");  context:  latch.countDown();  }  });  }  }  try  {  latch.await();  }  catch  (InterruptedException  e)  {  }                      logger.info( "[cluster_shutdown]:  done  shutting  done  all  nodes  except  master,  proceeding  to  master ");                      logger.info( "[cluster_shutdown]:  done  shutting  down  all  nodes  except  master,  proceeding  to  master ");  transportService.sendRequest(state.nodes().masterNode(),  NodeShutdownRequestHandler.ACTION,  VoidStreamable.INSTANCE,  new  VoidTransportResponseHandler()  {  }  	logger.info( "[cluster_shutdown]:  done  shutting  down  all  nodes  except  master,  proceeding  to  master ");  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  List<InternalFullHistogramFacet.FullEntry>  fullEntries  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());  context:  this.entries  =  context.cacheRecycler().longObjectMap(-1);  }  public  Collector  collector()  {  return  new  Collector();  }  public  InternalFacet  buildFacet(String  facetName)  {          List<InternalFullHistogramFacet.FullEntry>  fullEntries  =  new  ArrayList<InternalFullHistogramFacet.FullEntry>(entries.v().size());          List<InternalFullHistogramFacet.FullEntry>  fullEntries  =  new  ArrayList<>(entries.v().size());  boolean[]  states  =  entries.v().allocated;  Object[]  values  =  entries.v().values;  for  (int  i  =  0;  i  <  states.length;  i++)  {  if  (states[i])  {  fullEntries.add((InternalFullHistogramFacet.FullEntry)  values[i]);  }  }  entries.release();  	List<InternalFullHistogramFacet.FullEntry>  fullEntries  =  new  ArrayList<>(entries.v().size());  
libgdx_05a0a877e531297d62fabe94c8bc5f19f87af5e8	buggy:  if(this  ==  Buffer)  return   "char* ";  context:  public  boolean  isString()  {  return  toString().equals( "String ");  }  public  boolean  isPlainOldDataType()  {  return  !isString()  &&  !isArray()  &&  !isBuffer()  &&  !isObject();  }  public  String  getBufferCType()  {  if(!this.isBuffer())  throw  new  RuntimeException( "ArgumentType   "  +  this  +   "  is  not  a  Buffer! ");  if(this  ==  Buffer)  return   "char* ";  if(this  ==  Buffer)  return   "unsigned  char* ";  if(this  ==  ByteBuffer)  return   "char* ";  if(this  ==  CharBuffer)  return   "unsigned  short* ";  if(this  ==  ShortBuffer)  return   "short* ";  if(this  ==  IntBuffer)  return   "int* ";  if(this  ==  LongBuffer)  return   "long  long* ";  if(this  ==  FloatBuffer)  return   "float* ";  if(this  ==  DoubleBuffer)  return   "double* ";  throw  new  RuntimeException( "Unknown  Buffer  type   "  +  this);  	if(this  ==  Buffer)  return   "unsigned  char* ";  
elasticsearch_d72de60b6f77b147ca3ec9ac0cb407c5be5ead07	buggy:  XContentDocumentMapper  builderDocMapper  =  doc(object( "person ").add(  context:  f  =  doc.getField( "object1.multi1 ");  assertThat(f.name(),  equalTo( "object1.multi1 "));  f  =  doc.getField( "object1.multi1.string ");  assertThat(f.name(),  equalTo( "object1.multi1.string "));  assertThat(f.stringValue(),  equalTo( "2010-01-01 "));  }          XContentDocumentMapper  builderDocMapper  =  doc(object( "person ").add(          XContentDocumentMapper  builderDocMapper  =  doc( "test ",  object( "person ").add(  multiField( "name ")  .add(stringField( "name ").store(Field.Store.YES))  .add(stringField( "indexed ").index(Field.Index.ANALYZED))  .add(stringField( "not_indexed ").index(Field.Index.NO).store(Field.Store.YES))  )).build();  String  builtMapping  =  builderDocMapper.buildSource();  	XContentDocumentMapper  builderDocMapper  =  doc( "test ",  object( "person ").add(  
elasticsearch_811559f3932db4ab9b4d28954c1e9195cf89ff1b	buggy:  canExit  =  runState  >=  STOP  ||  queueSize.get()  ==  0;  context:  private  boolean  workerCanExit()  {  final  ReentrantLock  mainLock  =  this.mainLock;  mainLock.lock();  boolean  canExit;  try  {              canExit  =  runState  >=  STOP  ||  queueSize.get()  ==  0;              canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  poolSize.get()  >  corePoolSize);  }  finally  {  mainLock.unlock();  }  return  canExit;  }  	canExit  =  runState  >=  STOP  ||  (queueSize.get()  ==  0  &&  poolSize.get()  >  corePoolSize);  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  return  os.copiedByteArray();  context:  public  ClusterState  build()  {  return  new  ClusterState(version,  metaData,  routingTable,  nodes,  blocks,  allocationExplanation);  }  public  static  byte[]  toBytes(ClusterState  state)  throws  IOException  {  CachedStreamOutput.Entry  cachedEntry  =  CachedStreamOutput.popEntry();  try  {  BytesStreamOutput  os  =  cachedEntry.bytes();  writeTo(state,  os);                  return  os.copiedByteArray();                  return  os.bytes().copyBytesArray().toBytes();  }  finally  {  CachedStreamOutput.pushEntry(cachedEntry);  }  }  public  static  ClusterState  fromBytes(byte[]  data,  DiscoveryNode  localNode)  throws  IOException  {  return  readFrom(new  BytesStreamInput(data,  false),  localNode);  }  	return  os.bytes().copyBytesArray().toBytes();  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());  context:  }  protected  String  executor()  {  return  ThreadPool.Names.SAME;  }  protected  final  void  masterOperation(final  Request  request,  final  ClusterState  state,  final  ActionListener<Response>  listener)  throws  ElasticsearchException  {          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indices(),  request.indicesOptions());          String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  request.indices(concreteIndices);  doMasterOperation(request,  state,  listener);  }  protected  abstract  void  doMasterOperation(Request  request,  ClusterState  state,  final  ActionListener<Response>  listener)  throws  ElasticsearchException;  }  	String[]  concreteIndices  =  state.metaData().concreteIndices(request.indicesOptions(),  request.indices());  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  listener.future  =  threadPool.schedule(request.timeout,  ThreadPool.Names.SAME,  new  Runnable()  {  public  void  run()  {  listener.onResponse(new  Response(false));  nodeIndexDeletedAction.remove(nodeIndexDeleteListener);  }  });  return  newClusterStateBuilder().state(currentState).routingResult(routingResult).metaData(newMetaData).blocks(blocks).build();                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  listener.onFailure(e);  return  currentState;  }  }  });  }  class  DeleteIndexListener  implements  Listener  {  	}  catch  (Throwable  e)  {  
elasticsearch_df7474b9fcf849bbfea4222c1d2aa58b6669e52a	buggy:  ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();  context:  MetaData  metaData  =  MetaData.builder()  .put(IndexMetaData.builder( "test ").numberOfShards(1).numberOfReplicas(1))  .build();  RoutingTable  routingTable  =  RoutingTable.builder()  .addAsNew(metaData.index( "test "))  .build();          ClusterState  clusterState  =  ClusterState.builder().metaData(metaData).routingTable(routingTable).build();          ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  assertThat(routingTable.index( "test ").shards().size(),  equalTo(1));  assertThat(routingTable.index( "test ").shard(0).size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().size(),  equalTo(2));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(1).state(),  equalTo(UNASSIGNED));  assertThat(routingTable.index( "test ").shard(0).shards().get(0).currentNodeId(),  nullValue());  assertThat(routingTable.index( "test ").shard(0).shards().get(1).currentNodeId(),  nullValue());  	ClusterState  clusterState  =  ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();  
elasticsearch_64a01c28c31ba669a637fb497d4df034dc86b63a	buggy:  return  fieldFilter(nullValue,  null);  context:  public  Analyzer  searchQuoteAnalyzer()  {  return  this.searchQuotedAnalyzer;  }  public  Filter  nullValueFilter()  {  if  (nullValue  ==  null)  {  return  null;  }          return  fieldFilter(nullValue,  null);          return  termFilter(nullValue,  null);  }  protected  Field  parseCreateField(ParseContext  context)  throws  IOException  {  String  value  =  nullValue;  float  boost  =  this.boost;  if  (context.externalValueSet())  {  value  =  (String)  context.externalValue();  	return  termFilter(nullValue,  null);  
libgdx_c2f92ec6712126822d211b3c5e5052d6aee3be84	buggy:  transform.translate(0,  0,  3);  context:  shapeRenderer.begin(ShapeType.Line);  shapeRenderer.setColor(Color.RED);  shapeRenderer.line(0,  0,  0,  100,  0,  0);  shapeRenderer.setColor(Color.GREEN);  shapeRenderer.line(0,  0,  0,  0,  100,  0);  shapeRenderer.setColor(Color.BLUE);  shapeRenderer.line(0,  0,  0,  0,  0,  100);  shapeRenderer.end();  transform.idt();  transform.translate(0,  0,  3);  transform.translate(0,  0,  -3);  modelBatch.begin(cam);  modelBatch.render(model,  transform,  lights);  modelBatch.end();  }  public  void  dispose  ()  {  	transform.translate(0,  0,  -3);  
libgdx_c1c8470e27f778ff5bb4984238a413748d03394a	buggy:  new  JoglApplication(new  StillModelViewer( "data/blobbie_world_test.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  context:  }  public  static  void  main(String[]  argv)  {  new  JoglApplication(new  StillModelViewer( "data/blobbie_world_test.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  new  JoglApplication(new  StillModelViewer( "data/boy_static.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  }  }  	new  JoglApplication(new  StillModelViewer( "data/boy_static.dae ",   "data/world_blobbie_blocks.png "),   "StillModel  Viewer ",  800,  480,  false);  
elasticsearch_016e5bce047d4e81947e7c511c5d46f9019efc61	buggy:  new  IndexSettingsModule(ImmutableSettings.Builder.EMPTY_SETTINGS),  context:  public  static  XContentDocumentMapperParser  newParser()  {  return  new  XContentDocumentMapperParser(new  Index( "test "),  newAnalysisService());  }  public  static  MapperService  newMapperService()  {  return  new  MapperService(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS,  new  Environment(),  newAnalysisService());  }  public  static  AnalysisService  newAnalysisService()  {  Injector  injector  =  new  ModulesBuilder().add(                  new  IndexSettingsModule(ImmutableSettings.Builder.EMPTY_SETTINGS),                  new  IndexSettingsModule(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS),  new  IndexNameModule(new  Index( "test ")),  new  AnalysisModule(ImmutableSettings.Builder.EMPTY_SETTINGS)).createInjector();  return  injector.getInstance(AnalysisService.class);  }  }  	new  IndexSettingsModule(new  Index( "test "),  ImmutableSettings.Builder.EMPTY_SETTINGS),  
elasticsearch_5af634369737765bb4f6b52817b2570ade149429	buggy:  if  (!build.isMultiValued())  {  context:  values.add(0);  //  first   "t "  indicates  null  value  OrdinalsBuilder  builder  =  new  OrdinalsBuilder(terms,  reader.maxDoc());  try  {  BytesRefIterator  iter  =  builder.buildFromTerms(builder.wrapNumeric32Bit(terms.iterator(null)),  reader.getLiveDocs());  BytesRef  term;  while  ((term  =  iter.next())  !=  null)  {  values.add(NumericUtils.sortableIntToFloat(NumericUtils.prefixCodedToInt(term)));  }  Ordinals  build  =  builder.build(fieldDataType.getSettings());              if  (!build.isMultiValued())  {              if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  Docs  ordinals  =  build.ordinals();  float[]  sValues  =  new  float[reader.maxDoc()];  int  maxDoc  =  reader.maxDoc();  for  (int  i  =  0;  i  <  maxDoc;  i++)  {  sValues[i]  =  values.get(ordinals.getOrd(i));  }  final  FixedBitSet  set  =  builder.buildDocsWithValuesSet();  if  (set  ==  null)  {  	if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  public  TransportClusterRerouteAction(Settings  settings,  TransportService  transportService,  ClusterService  clusterService,  ThreadPool  threadPool,  AllocationService  allocationService)  {  super(settings,  transportService,  clusterService,  threadPool);  this.allocationService  =  allocationService;  }  protected  String  executor()  {          return  ThreadPool.Names.CACHED;          return  ThreadPool.Names.GENERIC;  }  protected  String  transportAction()  {  return  ClusterRerouteAction.NAME;  }  	return  ThreadPool.Names.GENERIC;  
elasticsearch_52c750fc42adc3f7318581984f4693f3f8f73685	buggy:  scrollId  =  buildScrollId(request.searchType(),  queryResults.values());  context:  queryResults.put(result.shardTarget(),  result);  }  long  totalHits  =  0;  final  InternalSearchResponse  internalResponse  =  searchPhaseController.merge(EMPTY_DOCS,  queryResults,  ImmutableMap.<SearchShardTarget,  FetchSearchResultProvider>of());  String  scrollId  =  null;  if  (request.scroll()  !=  null)  {                  scrollId  =  buildScrollId(request.searchType(),  queryResults.values());                  scrollId  =  buildScrollId(request.searchType(),  queryResults.values(),  null);  }  listener.onResponse(new  SearchResponse(internalResponse,  scrollId,  expectedSuccessfulOps,  successulOps.get(),  buildTookInMillis(),  buildShardFailures()));  searchCache.releaseQueryResults(queryResults);  }  }  private  static  ShardDoc[]  EMPTY_DOCS  =  new  ShardDoc[0];  }  	scrollId  =  buildScrollId(request.searchType(),  queryResults.values(),  null);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<Throwable>();  context:  int  allowNodes  =  2;  assertAcked(prepareCreate( "test ",  3,  settingsBuilder().put(SETTING_NUMBER_OF_SHARDS,  numShards).put(SETTING_NUMBER_OF_REPLICAS,  numReplicas)));  final  AtomicLong  idGenerator  =  new  AtomicLong();  final  AtomicLong  indexCounter  =  new  AtomicLong();  final  AtomicBoolean  stop  =  new  AtomicBoolean(false);  Thread[]  writers  =  new  Thread[scaledRandomIntBetween(3,  10)];  final  CountDownLatch  stopLatch  =  new  CountDownLatch(writers.length);          final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<Throwable>();          final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<>();  for  (int  i  =  0;  i  <  writers.length;  i++)  {  final  int  indexerId  =  i;  final  Client  client  =  client();  writers[i]  =  new  Thread()  {  public  void  run()  {  long  id  =  -1;  try  {  	final  CopyOnWriteArrayList<Throwable>  failures  =  new  CopyOnWriteArrayList<>();  
elasticsearch_45f062792cf7f34659085ba4541610db643eea3a	buggy:  builder.append('-').append(NetworkUtils.getLocalAddress().getHostName());  context:  }  if  (random.nextBoolean())  {  builder.put(MapperService.DEFAULT_FIELD_MAPPERS_COLLECTION_SWITCH,  RandomInts.randomIntBetween(random,  0,  5));  }  return  builder.build();  }  public  static  String  clusterName(String  prefix,  String  childVMId,  long  clusterSeed)  {  StringBuilder  builder  =  new  StringBuilder(prefix);          builder.append('-').append(NetworkUtils.getLocalAddress().getHostName());          builder.append('-').append(NetworkUtils.getLocalHostName( "__default_host__ "));  builder.append( "-CHILD_VM=[ ").append(childVMId).append(']');  builder.append( "-CLUSTER_SEED=[ ").append(clusterSeed).append(']');  builder.append( "-HASH=[ ").append(SeedUtils.formatSeed(System.nanoTime())).append(']');  return  builder.toString();  }  private  void  ensureOpen()  {  	builder.append('-').append(NetworkUtils.getLocalHostName( "__default_host__ "));  
elasticsearch_c08b96824605b62841193a80a75a2255d8348515	buggy:  return  ThreadPool.Names.CACHED;  context:  transportServiceClient.connectToNode(smallNode);  transportServiceServer.registerHandler( "benchmark ",  new  BaseTransportRequestHandler<BenchmarkMessage>()  {  public  BenchmarkMessage  newInstance()  {  return  new  BenchmarkMessage();  }  public  String  executor()  {                  return  ThreadPool.Names.CACHED;                  return  ThreadPool.Names.GENERIC;  }  public  void  messageReceived(BenchmarkMessage  request,  TransportChannel  channel)  throws  Exception  {  channel.sendResponse(request);  }  });  	return  ThreadPool.Names.GENERIC;  
elasticsearch_5c237fe834625cdaa7f8850f4d565733ce78e687	buggy:  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(max( "max ")))  context:  public  class  MaxTests  extends  AbstractNumericTests  {  public  void  testEmptyAggregation()  throws  Exception  {  SearchResponse  searchResponse  =  client().prepareSearch( "empty_bucket_idx ")  .setQuery(matchAllQuery())                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).emptyBuckets(true).subAggregation(max( "max ")))                  .addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(max( "max ")))  .execute().actionGet();  assertThat(searchResponse.getHits().getTotalHits(),  equalTo(2l));  Histogram  histo  =  searchResponse.getAggregations().get( "histo ");  assertThat(histo,  notNullValue());  Histogram.Bucket  bucket  =  histo.getByKey(1l);  assertThat(bucket,  notNullValue());  	.addAggregation(histogram( "histo ").field( "value ").interval(1l).minDocCount(0).subAggregation(max( "max ")))  
elasticsearch_c8e553054b40705086a6f2970157a2d798685731	buggy:  if  (field.name()  ==  path)  {  context:  }  public  void  postParse(ParseContext  context)  throws  IOException  {  Analyzer  analyzer  =  context.docMapper().mappers().indexAnalyzer();  if  (path  !=  null)  {  String  value  =  null;  List<IndexableField>  fields  =  context.doc().getFields();  for  (int  i  =  0,  fieldsSize  =  fields.size();  i  <  fieldsSize;  i++)  {  IndexableField  field  =  fields.get(i);                  if  (field.name()  ==  path)  {                  if  (field.name().equals(path))  {  value  =  field.stringValue();  break;  }  }  if  (value  ==  null)  {  value  =  context.ignoredValue(path);  }  if  (value  !=  null)  {  	if  (field.name().equals(path))  {  
elasticsearch_598854dd72d7fb01a7e26a9dad065de3deaa5eb7	buggy:  .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,  size)  context:  bytearray.set(i,  bytes[i]);  }  return  bytearray;  }  public  void  testMaxSizeExceededOnNew()  throws  Exception  {  final  int  size  =  scaledRandomIntBetween(5,  1  <<  22);  for  (String  type  :  Arrays.asList( "Byte ",   "Int ",   "Long ",   "Float ",   "Double ",   "Object "))  {  HierarchyCircuitBreakerService  hcbs  =  new  HierarchyCircuitBreakerService(  ImmutableSettings.builder()                              .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,  size)                              .put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,  size  -  1)  .build(),  new  NodeSettingsService(ImmutableSettings.EMPTY));  BigArrays  bigArrays  =  new  BigArrays(ImmutableSettings.EMPTY,  null,  hcbs).withCircuitBreaking();  Method  create  =  BigArrays.class.getMethod( "new "  +  type  +   "Array ",  long.class);  try  {  create.invoke(bigArrays,  size);  fail( "expected  an  exception  on   "  +  create);  }  catch  (InvocationTargetException  e)  {  	.put(HierarchyCircuitBreakerService.REQUEST_CIRCUIT_BREAKER_LIMIT_SETTING,  size  -  1)  
elasticsearch_81deb833deb2a91b65591b2296fbc6911a37ec55	buggy:  builder.field( "_type ",   "stats ");  context:  }  total  +=  statsFacet.total();  count  +=  statsFacet.count();  }  return  new  InternalStatisticalFacet(name,  min,  max,  total,  count);  }  builder.startObject(name);          builder.field( "_type ",   "stats ");          builder.field( "_type ",   "statistical ");  builder.field( "count ",  count);  builder.field( "total ",  total);  builder.field( "min ",  min);  builder.field( "max ",  max);  builder.endObject();  }  public  static  StatisticalFacet  readStatisticalFacet(StreamInput  in)  throws  IOException  {  	builder.field( "_type ",   "statistical ");  
elasticsearch_8e17d636ef441a9be80977d34acfaabc12982eb7	buggy:  protected  XPassageFormatter  getFormatter(String  field)  {  context:  XPostingsHighlighter  highlighter2  =  new  XPostingsHighlighter(Integer.MAX_VALUE  -  1)  {  protected  char  getMultiValuedSeparator(String  field)  {  return  HighlightUtils.PARAGRAPH_SEPARATOR;  }              protected  XPassageFormatter  getFormatter(String  field)  {              protected  PassageFormatter  getFormatter(String  field)  {  return  new  CustomPassageFormatter( "<b> ",   "</b> ",  new  DefaultEncoder());  }  };  Map<String,  Object[]>  highlightMap  =  highlighter2.highlightFieldsAsObjects(new  String[]{ "body "},  query,  searcher,  new  int[]{docId},  new  int[]{5});  Object[]  objects  =  highlightMap.get( "body ");  assertThat(objects,  notNullValue());  assertThat(objects.length,  equalTo(1));  	protected  PassageFormatter  getFormatter(String  field)  {  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  return  new  Dependency<T>(null,  key,  true,  -1);  context:  this.key  =  key;  this.nullable  =  nullable;  this.parameterIndex  =  parameterIndex;  }  public  static  <T>  Dependency<T>  get(Key<T>  key)  {          return  new  Dependency<T>(null,  key,  true,  -1);          return  new  Dependency<>(null,  key,  true,  -1);  }  public  static  Set<Dependency<?>>  forInjectionPoints(Set<InjectionPoint>  injectionPoints)  {  List<Dependency<?>>  dependencies  =  Lists.newArrayList();  for  (InjectionPoint  injectionPoint  :  injectionPoints)  {  	return  new  Dependency<>(null,  key,  true,  -1);  
elasticsearch_6b026119718a616fc76578aff3b20ceda023d403	buggy:  TermContext  termContext  =  TermContext.build(indexReaderContext,  terms[i],  false);  context:  context.query().extractTerms(new  DelegateSet(termsSet));  if  (context.rescore()  !=  null)  {  context.rescore().rescorer().extractTerms(context,  context.rescore(),  new  DelegateSet(termsSet));  }  Term[]  terms  =  termsSet.toArray(Term.class);  TermStatistics[]  termStatistics  =  new  TermStatistics[terms.length];  IndexReaderContext  indexReaderContext  =  context.searcher().getTopReaderContext();  for  (int  i  =  0;  i  <  terms.length;  i++)  {                  TermContext  termContext  =  TermContext.build(indexReaderContext,  terms[i],  false);                  TermContext  termContext  =  TermContext.build(indexReaderContext,  terms[i]);  termStatistics[i]  =  context.searcher().termStatistics(terms[i],  termContext);  }  ObjectObjectOpenHashMap<String,  CollectionStatistics>  fieldStatistics  =  HppcMaps.newNoNullKeysMap();  for  (Term  term  :  terms)  {  assert  term.field()  !=  null  :   "field  is  null ";  if  (!fieldStatistics.containsKey(term.field()))  {  final  CollectionStatistics  collectionStatistics  =  context.searcher().collectionStatistics(term.field());  	TermContext  termContext  =  TermContext.build(indexReaderContext,  terms[i]);  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  parents.get(docID);  context:  Filter  parentFilter  =  new  TermFilter(new  Term( "type ",   "parent "));  Filter  childFilter  =  new  NotFilter(parentFilter);  NestedFieldComparatorSource  nestedComparatorSource  =  new  NestedFieldComparatorSource(sortMode,  innerSource,  parentFilter,  childFilter);  ToParentBlockJoinQuery  query  =  new  ToParentBlockJoinQuery(new  XFilteredQuery(new  MatchAllDocsQuery(),  childFilter),  new  FixedBitSetCachingWrapperFilter(parentFilter),  ScoreMode.None);  Sort  sort  =  new  Sort(new  SortField( "text ",  nestedComparatorSource));  TopFieldDocs  topDocs  =  searcher.search(query,  randomIntBetween(1,  numParents),  sort);  assertTrue(topDocs.scoreDocs.length  >  0);  BytesRef  previous  =  null;  for  (int  i  =  0;  i  <  topDocs.scoreDocs.length;  ++i)  {  final  int  docID  =  topDocs.scoreDocs[i].doc;              assert  parents.get(docID);              assertTrue( "expected   "  +  docID  +   "  to  be  a  parent ",  parents.get(docID));  BytesRef  cmpValue  =  null;  for  (int  child  =  parents.prevSetBit(docID  -  1)  +  1;  child  <  docID;  ++child)  {  String[]  vals  =  searcher.doc(child).getValues( "text ");  if  (vals.length  ==  0)  {  vals  =  new  String[]  {missingValue.utf8ToString()};  }  for  (String  value  :  vals)  {  final  BytesRef  bytesValue  =  new  BytesRef(value);  	assertTrue( "expected   "  +  docID  +   "  to  be  a  parent ",  parents.get(docID));  
elasticsearch_0d63fd68a87299732a29c1e018de1d94c8d4b9a8	buggy:  return  new  EntriesStats(sizeInBytes,  totalCount  /  segmentsCount);  context:  long  sizeInBytes  =  0;  long  totalCount  =  0;  int  segmentsCount  =  0;  for  (ReaderValue  readerValue  :  cache.values())  {  segmentsCount++;  for  (DocSet  docSet  :  readerValue.filters().values())  {  sizeInBytes  +=  docSet.sizeInBytes();  totalCount++;  }  }          return  new  EntriesStats(sizeInBytes,  totalCount  /  segmentsCount);          return  new  EntriesStats(sizeInBytes,  segmentsCount  ==  0  ?  0  :  totalCount  /  segmentsCount);  }  if  (isCached(filterToCache))  {  return  filterToCache;  }  return  new  FilterCacheFilterWrapper(filterToCache,  this);  }  	return  new  EntriesStats(sizeInBytes,  segmentsCount  ==  0  ?  0  :  totalCount  /  segmentsCount);  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  builder.map(mapping);  }  builder.endObject();  builder.endObject();  }  builder.endObject();  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_8d45901a8a8152de94e334c5021f4e99b1835dff	buggy:  logger.warn( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  context:  public  void  publish(ClusterState  clusterState)  {  DiscoveryNode  localNode  =  nodesProvider.nodes().localNode();  for  (final  DiscoveryNode  node  :  clusterState.nodes())  {  if  (node.equals(localNode))  {  continue;  }  transportService.sendRequest(node,  PublishClusterStateRequestHandler.ACTION,  new  PublishClusterStateRequest(clusterState),  new  VoidTransportResponseHandler(false)  {                      logger.warn( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);                      logger.debug( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  }  });  }  }  private  class  PublishClusterStateRequest  implements  Streamable  {  private  ClusterState  clusterState;  	logger.debug( "failed  to  send  cluster  state  to  [{}],  should  be  detected  as  failed  soon... ",  exp,  node);  
libgdx_19e0a888394eed8b4097a264186a1c8da600ed6b	buggy:  titleCache.setColors(Color.tmp.set(getColor()).mul(style.titleFontColor));  context:  else  if  ((titleAlignment  &  Align.right)  !=  0)  x  +=  width  -  bounds.width  -  getPadRight();  else  x  +=  (width  -  bounds.width)  /  2;  if  ((titleAlignment  &  Align.top)  ==  0)  {  if  ((titleAlignment  &  Align.bottom)  !=  0)  y  -=  padTop  -  bounds.height;  else  y  -=  (padTop  -  bounds.height)  /  2;  }  titleCache.setColors(Color.tmp.set(getColor()).mul(style.titleFontColor));  titleCache.tint(Color.tmp.set(getColor()).mul(style.titleFontColor));  titleCache.setPosition((int)x,  (int)y);  titleCache.draw(batch,  parentAlpha);  }  public  Actor  hit  (float  x,  float  y,  boolean  touchable)  {  Actor  hit  =  super.hit(x,  y,  touchable);  if  (hit  ==  null  &&  isModal  &&  (!touchable  ||  getTouchable()  ==  Touchable.enabled))  return  this;  float  height  =  getHeight();  	titleCache.tint(Color.tmp.set(getColor()).mul(style.titleFontColor));  
elasticsearch_11ff90420a6e91e87743f59f786216678515e819	buggy:  logger.debug( "All  shards  failied  for  phase:  [{}] ",  firstPhaseName(),  t);  context:  if  (t  !=  null  &&  !TransportActions.isShardNotAvailableException(t))  {  if  (shard  !=  null)  {  }  else  {  }  }  }  if  (successulOps.get()  ==  0)  {  if  (logger.isDebugEnabled())  {                          logger.debug( "All  shards  failied  for  phase:  [{}] ",  firstPhaseName(),  t);                          logger.debug( "All  shards  failed  for  phase:  [{}] ",  firstPhaseName(),  t);  }  listener.onFailure(new  SearchPhaseExecutionException(firstPhaseName(),   "all  shards  failed ",  buildShardFailures()));  }  else  {  try  {  innerMoveToSecondPhase();  }  catch  (Throwable  e)  {  listener.onFailure(new  ReduceSearchPhaseException(firstPhaseName(),   " ",  e,  buildShardFailures()));  	logger.debug( "All  shards  failed  for  phase:  [{}] ",  firstPhaseName(),  t);  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  noMatchQuery  =  MatchNoDocsQuery.INSTANCE;  context:  throw  new  QueryParsingException(parseContext.index(),   "[indices]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token.isValue())  {  if  ( "index ".equals(currentFieldName))  {  indices.add(parser.text());  }  else  if  ( "no_match_query ".equals(currentFieldName))  {  String  type  =  parser.text();  if  ( "all ".equals(type))  {  noMatchQuery  =  Queries.newMatchAllQuery();  }  else  if  ( "none ".equals(type))  {                          noMatchQuery  =  MatchNoDocsQuery.INSTANCE;                          noMatchQuery  =  Queries.newMatchNoDocsQuery();  }  }  else  if  ( "_name ".equals(currentFieldName))  {  queryName  =  parser.text();  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  query  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  }  	noMatchQuery  =  Queries.newMatchNoDocsQuery();  
elasticsearch_5a5a892cc7b89f10dad8aad7cd90c553395186d5	buggy:  return   "application/json;  charset=UTF-8 ";  context:  this.prefixUtf8Result  =  startJsonp(request);  }  public  XContentRestResponse(RestRequest  request,  Status  status,  XContentBuilder  builder)  throws  IOException  {  this.builder  =  builder;  this.status  =  status;  this.prefixUtf8Result  =  startJsonp(request);  }          return   "application/json;  charset=UTF-8 ";          return  builder.contentType().restContentType();  }  return  false;  }  return  builder.unsafeBytes();  	return  builder.contentType().restContentType();  
libgdx_6b1f6e2e139683a01b4f19b1765b466de095cb9a	buggy:  int  result  =  (int)type;  context:  scaleV  =  region.getV2()  -  offsetV;  }  public  Attribute  copy  ()  {  return  new  TextureAttribute(this);  }  public  int  hashCode  ()  {  int  result  =  (int)type;  int  result  =  super.hashCode();  result  =  991  *  result  +  textureDescription.hashCode();  result  =  991  *  result  +  NumberUtils.floatToRawIntBits(offsetU);  result  =  991  *  result  +  NumberUtils.floatToRawIntBits(offsetV);  result  =  991  *  result  +  NumberUtils.floatToRawIntBits(scaleU);  result  =  991  *  result  +  NumberUtils.floatToRawIntBits(scaleV);  return  result;  }  }  	int  result  =  super.hashCode();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Collection<String>  indices  =  new  ArrayList<String>();  context:  }  }  else  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  filter  does  not  support  [ "  +  currentFieldName  +   "] ");  }  }  else  if  (token  ==  XContentParser.Token.START_ARRAY)  {  if  ( "indices ".equals(currentFieldName))  {  if  (indicesFound)  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  indices  or  index  already  specified ");  }  indicesFound  =  true;                      Collection<String>  indices  =  new  ArrayList<String>();                      Collection<String>  indices  =  new  ArrayList<>();  while  (parser.nextToken()  !=  XContentParser.Token.END_ARRAY)  {  String  value  =  parser.textOrNull();  if  (value  ==  null)  {  throw  new  QueryParsingException(parseContext.index(),   "[indices]  no  value  specified  for  'indices'  entry ");  }  indices.add(value);  }  currentIndexMatchesIndices  =  matchesIndices(parseContext.index().name(),  indices.toArray(new  String[indices.size()]));  	Collection<String>  indices  =  new  ArrayList<>();  
libgdx_c69bc86393d3c9c9ed58071c9733a2b6949e8704	buggy:  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  state  ==  FIXED  &&  stateTime  >  0.5f)  {  context:  state  =  FIXED;  return;  }  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  controlButton)  &&  state  ==  FIXED  &&  stateTime  >  0.5f)  {  stateTime  =  0;  state  =  CONTROLLED;  return;  }  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  state  ==  FIXED  &&  stateTime  >  0.5f)  {  if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  stateTime  >  0.5f)  {  stateTime  =  0;  state  =  FOLLOW;  return;  }  boolean  touch0  =  Gdx.input.isTouched(0);  boolean  touch1  =  Gdx.input.isTouched(1);  boolean  left  =  (touch0  &&  x0  <  60)  ||  (touch1  &&  x1  <  60);  	if((Gdx.input.isKeyPressed(Keys.SPACE)  ||  followButton)  &&  stateTime  >  0.5f)  {  
elasticsearch_858195351b03a1101cef26825e89913d534b06de	buggy:  StreamInput  input  =  CachedStreamInput.cachedHandles(new  BytesStreamInput(datagramPacketReceive.getData(),  datagramPacketReceive.getOffset()  +  INTERNAL_HEADER.length,  datagramPacketReceive.getLength()));  context:  for  (;  counter  <  INTERNAL_HEADER.length;  counter++)  {  if  (datagramPacketReceive.getData()[datagramPacketReceive.getOffset()  +  counter]  !=  INTERNAL_HEADER[counter])  {  break;  }  }  if  (counter  ==  INTERNAL_HEADER.length)  {  internal  =  true;  }  }  if  (internal)  {                                  StreamInput  input  =  CachedStreamInput.cachedHandles(new  BytesStreamInput(datagramPacketReceive.getData(),  datagramPacketReceive.getOffset()  +  INTERNAL_HEADER.length,  datagramPacketReceive.getLength()));                                  StreamInput  input  =  CachedStreamInput.cachedHandles(new  BytesStreamInput(datagramPacketReceive.getData(),  datagramPacketReceive.getOffset()  +  INTERNAL_HEADER.length,  datagramPacketReceive.getLength(),  true));  Version  version  =  Version.readVersion(input);  id  =  input.readInt();  clusterName  =  ClusterName.readClusterName(input);  requestingNodeX  =  readNode(input);  }  else  {  xContentType  =  XContentFactory.xContentType(datagramPacketReceive.getData(),  datagramPacketReceive.getOffset(),  datagramPacketReceive.getLength());  if  (xContentType  !=  null)  {  	StreamInput  input  =  CachedStreamInput.cachedHandles(new  BytesStreamInput(datagramPacketReceive.getData(),  datagramPacketReceive.getOffset()  +  INTERNAL_HEADER.length,  datagramPacketReceive.getLength(),  true));  
elasticsearch_7bf0f1ffca589df6e626d61182689bde005ce649	buggy:  client.admin().indices().execDelete(deleteIndexRequest,  new  ActionListener<DeleteIndexResponse>()  {  context:  public  class  RestDeleteIndexAction  extends  BaseRestHandler  {  super(settings,  client);  controller.registerHandler(RestRequest.Method.DELETE,   "/{index} ",  this);  }  DeleteIndexRequest  deleteIndexRequest  =  new  DeleteIndexRequest(request.param( "index "));  deleteIndexRequest.timeout(request.paramAsTime( "timeout ",  timeValueSeconds(10)));          client.admin().indices().execDelete(deleteIndexRequest,  new  ActionListener<DeleteIndexResponse>()  {          client.admin().indices().delete(deleteIndexRequest,  new  ActionListener<DeleteIndexResponse>()  {  try  {  JsonBuilder  builder  =  RestJsonBuilder.restJsonBuilder(request);  builder.startObject()  .field( "ok ",  true)  .field( "acknowledged ",  response.acknowledged())  .endObject();  channel.sendResponse(new  JsonRestResponse(request,  OK,  builder));  	client.admin().indices().delete(deleteIndexRequest,  new  ActionListener<DeleteIndexResponse>()  {  
elasticsearch_c10544479f3d774548a0b1243010ab36a8f9d3e8	buggy:  HandlesStreamOutput  stream  =  BytesStreamOutput.Cached.cachedHandles();  context:  synchronized  (this)  {  LocalTransport  removed  =  connectedNodes.remove(node);  if  (removed  !=  null)  {  transportServiceAdapter.raiseNodeDisconnected(node);  }  }  }          HandlesStreamOutput  stream  =  BytesStreamOutput.Cached.cachedHandles();          HandlesStreamOutput  stream  =  CachedStreamOutput.cachedHandles();  stream.writeLong(requestId);  byte  status  =  0;  status  =  setRequest(status);  stream.writeByte(status);  //  0  for  request,  1  for  response.  stream.writeUTF(action);  message.writeTo(stream);  	HandlesStreamOutput  stream  =  CachedStreamOutput.cachedHandles();  
elasticsearch_bae3203e3beee284ca79ef9e004dd7abb1cb5b94	buggy:  for  (int  i  =  0;  i  <  (cluster().size()  *  5);  i++)  {  context:  }  latch.await();  assertThat(failure.get(),  nullValue());  client().admin().indices().prepareRefresh().execute().actionGet();  Map  masterSource  =  client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet().getSourceAsMap();          for  (int  i  =  0;  i  <  (cluster().size()  *  5);  i++)  {          for  (int  i  =  0;  i  <  (immutableCluster().size()  *  5);  i++)  {  assertThat(client().prepareGet( "test ",   "type1 ",   "1 ").execute().actionGet().getSourceAsMap(),  equalTo(masterSource));  }  }  }  	for  (int  i  =  0;  i  <  (immutableCluster().size()  *  5);  i++)  {  
elasticsearch_d570d588a8fdfd7feca537d97f1455c6a5a52220	buggy:  .put( "number_of_shards ",  between(cluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))  context:  }  }  }  }  }  public  void  testClusterUpdateSettingsNoAcknowledgement()  {  client().admin().indices().prepareCreate( "test ")  .setSettings(settingsBuilder()                          .put( "number_of_shards ",  between(cluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))                          .put( "number_of_shards ",  between(immutableCluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))  .put( "number_of_replicas ",  0)).get();  ensureGreen();  NodesInfoResponse  nodesInfo  =  client().admin().cluster().prepareNodesInfo().get();  String  excludedNodeId  =  null;  for  (NodeInfo  nodeInfo  :  nodesInfo)  {  if  (nodeInfo.getNode().isDataNode())  {  excludedNodeId  =  nodeInfo.getNode().id();  	.put( "number_of_shards ",  between(immutableCluster().dataNodes(),  DEFAULT_MAX_NUM_SHARDS))  
elasticsearch_51273587dedb78ceba2b8f905fbd2e3ac330c237	buggy:  BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  requests.toArray(new  BulkItemRequest[requests.size()]));  context:  }  list.add(new  BulkItemRequest(i,  request));  }  }  }  final  AtomicInteger  counter  =  new  AtomicInteger(requestsByShard.size());  for  (Map.Entry<ShardId,  List<BulkItemRequest>>  entry  :  requestsByShard.entrySet())  {  final  ShardId  shardId  =  entry.getKey();  final  List<BulkItemRequest>  requests  =  entry.getValue();              BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  requests.toArray(new  BulkItemRequest[requests.size()]));              BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));  bulkShardRequest.replicationType(bulkRequest.replicationType());  bulkShardRequest.consistencyLevel(bulkRequest.consistencyLevel());  shardBulkAction.execute(bulkShardRequest,  new  ActionListener<BulkShardResponse>()  {  synchronized  (responses)  {  for  (BulkItemResponse  bulkItemResponse  :  bulkShardResponse.responses())  {  responses[bulkItemResponse.itemId()]  =  bulkItemResponse;  }  	BulkShardRequest  bulkShardRequest  =  new  BulkShardRequest(shardId.index().name(),  shardId.id(),  bulkRequest.refresh(),  requests.toArray(new  BulkItemRequest[requests.size()]));  
elasticsearch_f01f5ab3235b960c729c7e873edac98d64c1b50c	buggy:  String  file  =   "/ "  +  couchDb  +   "/_changes?feed=continuous&include_docs=true&&heartbeat=10000 ";  context:  try  {  Thread.sleep(5000);  continue;  }  catch  (InterruptedException  e1)  {  if  (closed)  {  return;  }  }  }                  String  file  =   "/ "  +  couchDb  +   "/_changes?feed=continuous&include_docs=true&&heartbeat=10000 ";                  String  file  =   "/ "  +  couchDb  +   "/_changes?feed=continuous&include_docs=true&heartbeat=10000 ";  if  (couchFilter  !=  null)  {  file  =  file  +   "&filter= "  +  couchFilter;  }  if  (lastSeq  !=  null)  {  file  =  file  +   "&since= "  +  lastSeq;  }  HttpURLConnection  connection  =  null;  	String  file  =   "/ "  +  couchDb  +   "/_changes?feed=continuous&include_docs=true&heartbeat=10000 ";  
elasticsearch_5d781961a07368ae458126e4fad0a8db566637da	buggy:  context.dfsResult().numDocs(context.searcher().getIndexReader().numDocs());  context:  public  void  execute(SearchContext  context)  {  try  {  context.rewriteQuery();  THashSet<Term>  termsSet  =  new  THashSet<Term>();  context.query().extractTerms(termsSet);  Term[]  terms  =  termsSet.toArray(new  Term[termsSet.size()]);  int[]  freqs  =  context.searcher().docFreqs(terms);  context.dfsResult().termsAndFreqs(terms,  freqs);              context.dfsResult().numDocs(context.searcher().getIndexReader().numDocs());              context.dfsResult().maxDoc(context.searcher().getIndexReader().maxDoc());  }  catch  (Exception  e)  {  throw  new  DfsPhaseExecutionException(context);  }  }  }  	context.dfsResult().maxDoc(context.searcher().getIndexReader().maxDoc());  
elasticsearch_8c7e0f5ca1bec303b0ffdad76974e56828e5877d	buggy:  intsScratch.values[0]  =  docId;  context:  public  int  getOrd(int  docId)  {  return  (int)  reader.get(docId);  }  public  IntArrayRef  getOrds(int  docId)  {  int  ordinal  =  (int)  reader.get(docId);  if  (ordinal  ==  0)  return  IntArrayRef.EMPTY;              intsScratch.values[0]  =  docId;              intsScratch.values[0]  =  ordinal;  return  intsScratch;  }  public  Iter  getIter(int  docId)  {  return  iter.reset((int)  reader.get(docId));  }  	intsScratch.values[0]  =  ordinal;  
elasticsearch_61fadb4dc0608380a8da533877d75bb0d9905c19	buggy:  RecoveryAction  recoveryAction  =  indexService.shardInjector(shardId).getInstance(RecoveryAction.class);  context:  return;  }  threadPool.execute(new  Runnable()  {  if  (indexShard.ignoreRecoveryAttempt())  {  return;  }  try  {                      RecoveryAction  recoveryAction  =  indexService.shardInjector(shardId).getInstance(RecoveryAction.class);                      RecoveryAction  recoveryAction  =  indexService.shardInjectorSafe(shardId).getInstance(RecoveryAction.class);  if  (!shardRouting.primary())  {  IndexShardRoutingTable  shardRoutingTable  =  routingTable.index(shardRouting.index()).shard(shardRouting.id());  for  (ShardRouting  entry  :  shardRoutingTable)  {  if  (entry.primary()  &&  entry.started())  {  DiscoveryNode  node  =  nodes.get(entry.currentNodeId());  try  {  	RecoveryAction  recoveryAction  =  indexService.shardInjectorSafe(shardId).getInstance(RecoveryAction.class);  
elasticsearch_a84e0a49b7ad85ca49f4ff84c55f718acdfa23ab	buggy:  }  else  if  ( "scope ".equals(currentFieldName))  {  context:  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  currentFieldName  =  parser.currentName();  }  else  if  (token  ==  XContentParser.Token.START_OBJECT)  {  if  ( "query ".equals(currentFieldName))  {  query  =  parseContext.parseInnerQuery();  }  }  else  if  (token.isValue())  {  if  ( "type ".equals(currentFieldName))  {  childType  =  parser.text();                  }  else  if  ( "scope ".equals(currentFieldName))  {                  }  else  if  ( "_scope ".equals(currentFieldName))  {  scope  =  parser.text();  }  }  }  if  (query  ==  null)  {  throw  new  QueryParsingException(index,   "[has_child]  requires  'query'  field ");  }  if  (childType  ==  null)  {  	}  else  if  ( "_scope ".equals(currentFieldName))  {  
elasticsearch_11de330246643418cf57509f77543b21e862bed5	buggy:  TEST_VERSION_CURRENT),  options,  256,  -1,  preservePositionIncrements,  null,  false,  1,  XAnalyzingSuggester.SEP_LABEL,  XAnalyzingSuggester.PAYLOAD_SEP,  XAnalyzingSuggester.END_BYTE);  context:  public  void  testDuellCompletions()  throws  IOException,  NoSuchFieldException,  SecurityException,  IllegalArgumentException,  IllegalAccessException  {  final  boolean  preserveSeparators  =  getRandom().nextBoolean();  final  boolean  preservePositionIncrements  =  getRandom().nextBoolean();  final  boolean  usePayloads  =  getRandom().nextBoolean();  final  int  options  =  preserveSeparators  ?  AnalyzingSuggester.PRESERVE_SEP  :  0;  XAnalyzingSuggester  reference  =  new  XAnalyzingSuggester(new  StandardAnalyzer(TEST_VERSION_CURRENT),  new  StandardAnalyzer(                  TEST_VERSION_CURRENT),  options,  256,  -1,  preservePositionIncrements,  null,  false,  1,  XAnalyzingSuggester.SEP_LABEL,  XAnalyzingSuggester.PAYLOAD_SEP,  XAnalyzingSuggester.END_BYTE);                  TEST_VERSION_CURRENT),  options,  256,  -1,  preservePositionIncrements,  null,  false,  1,  XAnalyzingSuggester.SEP_LABEL,  XAnalyzingSuggester.PAYLOAD_SEP,  XAnalyzingSuggester.END_BYTE,  XAnalyzingSuggester.HOLE_CHARACTER);  LineFileDocs  docs  =  new  LineFileDocs(getRandom());  int  num  =  atLeast(150);  final  String[]  titles  =  new  String[num];  final  long[]  weights  =  new  long[num];  for  (int  i  =  0;  i  <  titles.length;  i++)  {  Document  nextDoc  =  docs.nextDoc();  IndexableField  field  =  nextDoc.getField( "title ");  titles[i]  =  field.stringValue();  	TEST_VERSION_CURRENT),  options,  256,  -1,  preservePositionIncrements,  null,  false,  1,  XAnalyzingSuggester.SEP_LABEL,  XAnalyzingSuggester.PAYLOAD_SEP,  XAnalyzingSuggester.END_BYTE,  XAnalyzingSuggester.HOLE_CHARACTER);  
elasticsearch_c59bfea43c21a416a27e54d6a08f901698f3a827	buggy:  logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node());  context:  return  serverHandlers.get(action);  }  RequestHolder  holder  =  clientHandlers.remove(requestId);  if  (holder  ==  null)  {  TimeoutInfoHolder  timeoutInfoHolder  =  timeoutInfoHandlers.remove(requestId);  if  (timeoutInfoHolder  !=  null)  {                      logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node());                      logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);  }  else  {  }  return  null;  }  if  (holder.timeout()  !=  null)  {  holder.timeout().cancel();  }  	logger.warn( "Transport  response  handler  timed  out,  action  [{}],  node  [{}],  id  [{}] ",  timeoutInfoHolder.action(),  timeoutInfoHolder.node(),  requestId);  
elasticsearch_f62f7b8ffe323ec83ea4079ba9dcd525cdaaacef	buggy:  if  (indexSize  ==  reusedIndexSize)  {  context:  public  ByteSizeValue  getRecoveredIndexSize()  {  return  recoveredIndexSize();  }  public  int  indexRecoveryProgress()  {  if  (recoveredIndexSize  ==  0)  {              if  (indexSize  ==  reusedIndexSize)  {              if  (indexSize  !=  0  &&  indexSize  ==  reusedIndexSize)  {  return  100;  }  return  0;  }  return  (int)  (((double)  recoveredIndexSize)  /  expectedRecoveredIndexSize().bytes()  *  100);  }  public  int  getIndexRecoveryProgress()  {  	if  (indexSize  !=  0  &&  indexSize  ==  reusedIndexSize)  {  
elasticsearch_8c7779057ccc50e15cbae90e26ed4e5acebdb0e8	buggy:  return  new  DoubleValuesComparator(indexFieldData,  dMissingValue,  numHits);  context:  double  dMissingValue;  if  (missingValue  ==  null  ||   "_last ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Double.NEGATIVE_INFINITY  :  Double.POSITIVE_INFINITY;  }  else  if  ( "_first ".equals(missingValue))  {  dMissingValue  =  reversed  ?  Double.POSITIVE_INFINITY  :  Double.NEGATIVE_INFINITY;  }  else  {  dMissingValue  =  missingValue  instanceof  Number  ?  ((Number)  missingValue).doubleValue()  :  Double.parseDouble(missingValue.toString());  }          return  new  DoubleValuesComparator(indexFieldData,  dMissingValue,  numHits);          return  new  DoubleValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  }  }  	return  new  DoubleValuesComparator(indexFieldData,  dMissingValue,  numHits,  reversed);  
libgdx_0cb25d0e4b20fb5fe0f1079fed5200039fd715a5	buggy:  json.writeValue(patches[4]);  context:  if  (!file.exists())  file  =  Gdx.files.internal(path);  return  new  BitmapFont(file,  false);  }  });  json.setSerializer(NinePatch.class,  new  Serializer<NinePatch>()  {  public  void  write  (Json  json,  NinePatch  ninePatch,  Class  valueType)  {  TextureRegion[]  patches  =  ninePatch.getPatches();  if  (patches[0]  ==  null  &&  patches[1]  ==  null  &&  patches[2]  ==  null  &&  patches[3]  ==  null  &&  patches[4]  !=  null  &&  patches[5]  ==  null  &&  patches[6]  ==  null  &&  patches[7]  ==  null  &&  patches[8]  ==  null)  json.writeValue(patches[4]);  json.writeValue(new  TextureRegion[]  {patches[4]});  else  json.writeValue(ninePatch.getPatches());  }  public  NinePatch  read  (Json  json,  Object  jsonData,  Class  type)  {  TextureRegion[]  regions  =  json.readValue(TextureRegion[].class,  jsonData);  if  (regions.length  ==  1)  return  new  NinePatch(regions[0]);  return  new  NinePatch(regions);  	json.writeValue(new  TextureRegion[]  {patches[4]});  
elasticsearch_ac4b39bd8f54c38f55a0b02f432c4ee5f47caf03	buggy:  Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);  context:  public  class  PreBuiltTokenFilterFactoryFactory  implements  TokenFilterFactoryFactory  {  private  final  TokenFilterFactory  tokenFilterFactory;  public  PreBuiltTokenFilterFactoryFactory(TokenFilterFactory  tokenFilterFactory)  {  this.tokenFilterFactory  =  tokenFilterFactory;  }  public  TokenFilterFactory  create(String  name,  Settings  settings)  {          Version  indexVersion  =  settings.getAsVersion(IndexMetaData.SETTING_VERSION_CREATED,  Version.CURRENT);          Version  indexVersion  =  Version.indexCreated(settings);  if  (!Version.CURRENT.equals(indexVersion))  {  PreBuiltTokenFilters  preBuiltTokenFilters  =  PreBuiltTokenFilters.getOrDefault(name,  null);  if  (preBuiltTokenFilters  !=  null)  {  return  preBuiltTokenFilters.getTokenFilterFactory(indexVersion);  }  }  return  tokenFilterFactory;  }  	Version  indexVersion  =  Version.indexCreated(settings);  
elasticsearch_f993c4b72b4b2126dd02f02fa0e01c86aa5ab45c	buggy:  builder.field(QueryFacetCollectorParser.NAME);  context:  public  QueryFacetBuilder  query(XContentQueryBuilder  query)  {  this.query  =  query;  return  this;  }  if  (query  ==  null)  {  throw  new  SearchSourceBuilderException( "query  must  be  set  on  query  facet  for  facet  [ "  +  name  +   "] ");  }  builder.startObject(name);          builder.field(QueryFacetCollectorParser.NAME);          builder.field(QueryFacet.TYPE);  query.toXContent(builder,  params);  addFilterFacetAndGlobal(builder,  params);  builder.endObject();  }  }  	builder.field(QueryFacet.TYPE);  
elasticsearch_90d2cb7dd506f188b534c72de7ba125e74f6ec21	buggy:  logger.error( "Shard  Failure:  {} ",  failure.failure(),  failure.toString());  context:  assertThat(stats.getSumOfSquares(),  equalTo((double)  1+4+9+16+25+36+49+64+81+100+0+1+4+9+16+25+36+49+64+81));  assertThat(stats.getVariance(),  equalTo(variance(1,  2,  3,  4,  5,  6,  7,  8  ,9,  10,  0,  1,  2,  3,  4,  5,  6,  7,  8  ,9)));  assertThat(stats.getStdDeviation(),  equalTo(stdDev(1,  2,  3,  4,  5,  6,  7,  8  ,9,  10,  0,  1,  2,  3,  4,  5,  6,  7,  8  ,9)));  }  private  void  assertShardExecutionState(SearchResponse  response,  int  expectedFailures)  throws  Exception  {  ShardSearchFailure[]  failures  =  response.getShardFailures();  if  (failures.length  !=  expectedFailures)  {  for  (ShardSearchFailure  failure  :  failures)  {                  logger.error( "Shard  Failure:  {} ",  failure.failure(),  failure.toString());                  logger.error( "Shard  Failure:  {} ",  failure.reason(),  failure.toString());  }  fail( "Unexpected  shard  failures! ");  }  assertThat( "Not  all  shards  are  initialized ",  response.getSuccessfulShards(),  equalTo(response.getTotalShards()));  }  }  	logger.error( "Shard  Failure:  {} ",  failure.reason(),  failure.toString());  
elasticsearch_0d8330b50a081d4959ca4b4e245bf4d3594e0c8b	buggy:  assert  !Float.isNaN(hit.getScore());  context:  public  void  testIssue2986()  {  prepareCreate( "test ").setSettings(indexSettings()).execute().actionGet();  client().prepareIndex( "test ",   "post ",   "1 ").setSource( "{\ "field1\ ":\ "value1\ "} ").execute().actionGet();  client().prepareIndex( "test ",   "post ",   "2 ").setSource( "{\ "field1\ ":\ "value2\ "} ").execute().actionGet();  client().prepareIndex( "test ",   "post ",   "3 ").setSource( "{\ "field1\ ":\ "value3\ "} ").execute().actionGet();  refresh();  SearchResponse  result  =  client().prepareSearch( "test ").setQuery(matchAllQuery()).setTrackScores(true).addSort( "field1 ",  SortOrder.ASC).execute().actionGet();  for  (SearchHit  hit  :  result.getHits())  {              assert  !Float.isNaN(hit.getScore());              assertFalse(Float.isNaN(hit.getScore()));  }  }  public  void  testIssue2991()  {  for  (int  i  =  1;  i  <  4;  i++)  {  try  {  client().admin().indices().prepareDelete( "test ").execute().actionGet();  	assertFalse(Float.isNaN(hit.getScore()));  
elasticsearch_78af818d72a1c08663e15578a425f2534911b036	buggy:  final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();  context:  super(shardId,  indexSettings);  }  public  ShardTermVectorService  setIndexShard(IndexShard  indexShard)  {  this.indexShard  =  indexShard;  return  this;  }  public  TermVectorResponse  getTermVector(TermVectorRequest  request)  {          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher();          final  Engine.Searcher  searcher  =  indexShard.acquireSearcher( "term_vector ");  IndexReader  topLevelReader  =  searcher.reader();  final  TermVectorResponse  termVectorResponse  =  new  TermVectorResponse(request.index(),  request.type(),  request.id());  final  Term  uidTerm  =  new  Term(UidFieldMapper.NAME,  Uid.createUidAsBytes(request.type(),  request.id()));  try  {  Fields  topLevelFields  =  MultiFields.getFields(topLevelReader);  Versions.DocIdAndVersion  docIdAndVersion  =  Versions.loadDocIdAndVersion(topLevelReader,  uidTerm);  if  (docIdAndVersion  !=  null)  {  	final  Engine.Searcher  searcher  =  indexShard.acquireSearcher( "term_vector ");  
elasticsearch_a1d58bf486423ce0b13e2bbb4579c403b55e3793	buggy:  client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "type ")  context:  String  clusterName  =  ChildSearchAndIndexingBenchmark.class.getSimpleName();  Node  node1  =  nodeBuilder().settings(settingsBuilder().put(settings).put( "name ",   "node1 "))  .clusterName(clusterName)  .node();  Client  client  =  node1.client();  client.admin().cluster().prepareHealth(indexName).setWaitForGreenStatus().setTimeout( "10s ").execute().actionGet();  try  {  client.admin().indices().create(createIndexRequest(indexName)).actionGet();              client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "type ")              client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "child ")  .startObject( "_parent ").field( "type ",   "parent ").endObject()  .endObject().endObject()).execute().actionGet();  Thread.sleep(5000);  StopWatch  stopWatch  =  new  StopWatch().start();  long  ITERS  =  COUNT  /  BATCH;  	client.admin().indices().preparePutMapping(indexName).setType( "child ").setSource(XContentFactory.jsonBuilder().startObject().startObject( "child ")  
elasticsearch_bf70836e9251d2a7f92e1d328f8f9fab3a0501d7	buggy:  proc.onOrdinal(docId,  ordinal[docId]);  context:  proc.onMissing(docId);  }  }  boolean  found  =  false;  for  (int[]  ordinal  :  ordinals)  {  int  loc  =  ordinal[docId];  if  (loc  !=  0)  {  found  =  true;                  proc.onOrdinal(docId,  ordinal[docId]);                  proc.onOrdinal(docId,  loc);  }  }  if  (!found)  {  proc.onOrdinal(docId,  0);  }  }  	proc.onOrdinal(docId,  loc);  
elasticsearch_1d1ca3befc8bbe57bc58f32633c02d47922e651d	buggy:  if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {  context:  boolean  success  =  false;  try  (OrdinalsBuilder  builder  =  new  OrdinalsBuilder(terms.size(),  reader.maxDoc(),  acceptableTransientOverheadRatio))  {  final  GeoPointEnum  iter  =  new  GeoPointEnum(builder.buildFromTerms(terms.iterator(null)));  GeoPoint  point;  while  ((point  =  iter.next())  !=  null)  {  lat.add(point.getLat());  lon.add(point.getLon());  }  Ordinals  build  =  builder.build(fieldDataType.getSettings());              if  (!build.isMultiValued()  &&  CommonSettings.removeOrdsOnSingleValue(fieldDataType))  {              if  (!(build.isMultiValued()  ||  CommonSettings.getMemoryStorageHint(fieldDataType)  ==  CommonSettings.MemoryStorageFormat.ORDINALS))  {  Docs  ordinals  =  build.ordinals();  int  maxDoc  =  reader.maxDoc();  BigDoubleArrayList  sLat  =  new  BigDoubleArrayList(reader.maxDoc());  BigDoubleArrayList  sLon  =  new  BigDoubleArrayList(reader.maxDoc());  for  (int  i  =  0;  i  <  maxDoc;  i++)  {  long  nativeOrdinal  =  ordinals.getOrd(i);  sLat.add(lat.get(nativeOrdinal));  sLon.add(lon.get(nativeOrdinal));  	if  (!(build.isMultiValued()  ||  CommonSettings.getMemoryStorageHint(fieldDataType)  ==  CommonSettings.MemoryStorageFormat.ORDINALS))  {  
elasticsearch_65ae606c41b165a72f8d0d8acbaa47829d8c15ff	buggy:  return   "Index  [ "  +  name  +   "] ";  context:  public  String  name()  {  return  this.name;  }  public  String  getName()  {  return  name();  }  public  String  toString()  {          return   "Index  [ "  +  name  +   "] ";          return   "[ "  +  name  +   "] ";  }  public  boolean  equals(Object  o)  {  if  (this  ==  o)  return  true;  if  (o  ==  null)  return  false;  Index  index1  =  (Index)  o;  return  name.equals(index1.name);  	return   "[ "  +  name  +   "] ";  
elasticsearch_0cb1a2ebe1db6fde1621c926e7dba17abfbe99f0	buggy:  return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,  null);  context:  protected  ShardValidateResponse  newShardResponse()  {  return  new  ShardValidateResponse();  }  protected  GroupShardsIterator  shards(ValidateRequest  request,  String[]  concreteIndices,  ClusterState  clusterState)  {  Map<String,  Set<String>>  routingMap  =  clusterState.metaData().resolveSearchRouting( "0 ",  request.indices());          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,  null);          return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,   "_local ");  }  protected  void  checkBlock(ValidateRequest  request,  String[]  concreteIndices,  ClusterState  state)  {  for  (String  index  :  concreteIndices)  {  state.blocks().indexBlocked(ClusterBlockLevel.READ,  index);  }  }  	return  clusterService.operationRouting().searchShards(clusterState,  request.indices(),  concreteIndices,  null,  routingMap,   "_local ");  
elasticsearch_d487d809ea2e99a853cd7c845db1b14d8a160e72	buggy:  boolean  cache  =  false;  context:  super(index,  settings);  }  return  new  String[]{NAME};  }  XContentParser  parser  =  parseContext.parser();          boolean  cache  =  false;          boolean  cache  =  true;  String  fieldName  =  null;  String  value  =  null;  String  filterName  =  null;  String  currentFieldName  =  null;  XContentParser.Token  token;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  	boolean  cache  =  true;  
elasticsearch_2e8bbe9e308cc2e55da7a6a995e1f74afc89688d	buggy:  if  (getClass()  !=  o.getClass())  context:  sb.append( "function  score  ( ").append(subQuery.toString(field)).append( ",  functions:  [ ");  for  (FilterFunction  filterFunction  :  filterFunctions)  {  sb.append( "{filter( ").append(filterFunction.filter).append( "),  function  [ ").append(filterFunction.function).append( "]} ");  }  sb.append( "]) ");  sb.append(ToStringUtils.boost(getBoost()));  return  sb.toString();  }  public  boolean  equals(Object  o)  {          if  (getClass()  !=  o.getClass())          if  (o  ==  null  ||  getClass()  !=  o.getClass())  return  false;  FiltersFunctionScoreQuery  other  =  (FiltersFunctionScoreQuery)  o;  if  (this.getBoost()  !=  other.getBoost())  return  false;  if  (!this.subQuery.equals(other.subQuery))  {  return  false;  }  return  Arrays.equals(this.filterFunctions,  other.filterFunctions);  	if  (o  ==  null  ||  getClass()  !=  o.getClass())  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  public  void  onResponse(GetResponse  response)  {  try  {  XContentBuilder  builder  =  restContentBuilder(request);  response.toXContent(builder,  request);  if  (!response.isExists())  {  channel.sendResponse(new  XContentRestResponse(request,  NOT_FOUND,  builder));  }  else  {  channel.sendResponse(new  XContentRestResponse(request,  OK,  builder));  }                  }  catch  (Exception  e)  {                  }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(new  XContentThrowableRestResponse(request,  e));  	}  catch  (Throwable  e)  {  
elasticsearch_aac1374c76bec0d985c61d1c16502da4db8cfda3	buggy:  cluster().wipeIndices( "test ");  context:  client().prepareIndex( "test ",   "test ",   "1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "my-queries-index ",  PercolatorService.TYPE_NAME,   "kuku ")  .setSource(jsonBuilder().startObject()  .field( "color ",   "blue ")  .field( "query ",  termQuery( "field1 ",   "value1 "))  .endObject())  .setRefresh(true)  .execute().actionGet();          cluster().wipeIndices( "test ");          immutableCluster().wipeIndices( "test ");  createIndex( "test ");  ensureGreen();  client().prepareIndex( "test ",   "test ",   "1 ").setSource( "field1 ",   "value1 ").execute().actionGet();  client().prepareIndex( "my-queries-index ",  PercolatorService.TYPE_NAME,   "kuku ")  .setSource(jsonBuilder().startObject()  .field( "color ",   "blue ")  	immutableCluster().wipeIndices( "test ");  
elasticsearch_4a27671d0cb5d88129f6ded1192e8b8c637e4b4f	buggy:  bytes  +=  translog.estimateMemorySize().bytes();  context:  }  Thread.yield();  }  return  new  RobinSearchResult(holder);  }  rwl.readLock().lock();  try  {  long  bytes  =  IndexWriters.estimateRamSize(indexWriter);              bytes  +=  translog.estimateMemorySize().bytes();              bytes  +=  translog.memorySizeInBytes();  return  new  ByteSizeValue(bytes);  }  catch  (Exception  e)  {  return  null;  }  finally  {  rwl.readLock().unlock();  }  }  	bytes  +=  translog.memorySizeInBytes();  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  Map<String,  Object>  values  =  new  HashMap<String,  Object>(2);  context:  public  static  class  DocBuilder  implements  ToXContent  {  private  BytesReference  doc;  public  DocBuilder  setDoc(BytesReference  doc)  {  this.doc  =  doc;  return  this;  }  public  DocBuilder  setDoc(String  field,  Object  value)  {              Map<String,  Object>  values  =  new  HashMap<String,  Object>(2);              Map<String,  Object>  values  =  new  HashMap<>(2);  values.put(field,  value);  setDoc(values);  return  this;  }  public  DocBuilder  setDoc(String  doc)  {  this.doc  =  new  BytesArray(doc);  return  this;  	Map<String,  Object>  values  =  new  HashMap<>(2);  
elasticsearch_c7f6c5266d15fefa1a5ce9ae7ffc519c5ff8abbe	buggy:  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  false);  context:  protected  final  void  addShardFailure(final  int  shardIndex,  ShardSearchFailure  failure)  {  if  (shardFailures  ==  null)  {  shardFailures  =  new  AtomicArray<ShardSearchFailure>(scrollId.getContext().length);  }  shardFailures.set(shardIndex,  failure);  }  public  void  start()  {  if  (scrollId.getContext().length  ==  0)  {                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  false);                  final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false);  listener.onResponse(new  SearchResponse(internalResponse,  request.scrollId(),  0,  0,  0l,  buildShardFailures()));  return;  }  int  localOperations  =  0;  Tuple<String,  Long>[]  context  =  scrollId.getContext();  for  (int  i  =  0;  i  <  context.length;  i++)  {  Tuple<String,  Long>  target  =  context[i];  	final  InternalSearchResponse  internalResponse  =  new  InternalSearchResponse(new  InternalSearchHits(InternalSearchHits.EMPTY,  Long.parseLong(this.scrollId.getAttributes().get( "total_hits ")),  0.0f),  null,  null,  null,  false);  
elasticsearch_12e2ba822f52bcab5a74603f41233a6d5cb423f6	buggy:  builder.string(dateTimeFormatter.format());  context:  builder.startObject(name);  builder.field( "type ",  JSON_TYPE);  builder.field( "dynamic ",  dynamic);  builder.field( "enabled ",  enabled);  builder.field( "pathType ",  pathType.name().toLowerCase());  if  (dateTimeFormatters.length  >  0)  {  builder.startArray( "dateFormats ");  for  (FormatDateTimeFormatter  dateTimeFormatter  :  dateTimeFormatters)  {                  builder.string(dateTimeFormatter.format());                  builder.value(dateTimeFormatter.format());  }  builder.endArray();  }  for  (JsonMapper  mapper  :  mappers.values())  {  if  (mapper  instanceof  InternalMapper)  {  mapper.toJson(builder,  params);  	builder.value(dateTimeFormatter.format());  
elasticsearch_b7a5537d8397e6bb525988569d05976702547a1e	buggy:  assertThat(corrections[3].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "tarr  the  god  jewel "));  context:  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "america  cae "),  generator,  2,  1,  ir,   "body ",  wordScorer,  1,  2).corrections;  assertThat(corrections.length,  equalTo(1));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "american  ace "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Zorr  the  Got-Jewel "),  generator,  0.5f,  4,  ir,   "body ",  wordScorer,  0,  2).corrections;  assertThat(corrections.length,  equalTo(4));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "xorr  the  god  jewel "));  assertThat(corrections[1].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "zorr  the  god  jewel "));  assertThat(corrections[2].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "gorr  the  god  jewel "));          assertThat(corrections[3].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "tarr  the  god  jewel "));          assertThat(corrections[3].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "varr  the  god  jewel "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Zorr  the  Got-Jewel "),  generator,  0.5f,  1,  ir,   "body ",  wordScorer,  1.5f,  2).corrections;  assertThat(corrections.length,  equalTo(1));  assertThat(corrections[0].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "xorr  the  god  jewel "));  corrections  =  suggester.getCorrections(wrapper,  new  BytesRef( "Xor  the  Got-Jewel "),  generator,  0.5f,  1,  ir,   "body ",  wordScorer,  1.5f,  2).corrections;  	assertThat(corrections[3].join(new  BytesRef( "   ")).utf8ToString(),  equalTo( "varr  the  god  jewel "));  
elasticsearch_411739fe3b5b2410fa9594edf27087718162225f	buggy:  DeleteWarmerResponse  deleteWarmerResponse  =  client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setName( "warmer_1 ").execute().actionGet();  context:  IndexWarmersMetaData  recoveredTemplateWarmers  =  clusterState.metaData().templates().get( "template_1 ").custom(IndexWarmersMetaData.TYPE);  assertThat(recoveredTemplateWarmers.entries().size(),  equalTo(templateWarmers.entries().size()));  for  (int  i  =  0;  i  <  templateWarmers.entries().size();  i++)  {  assertThat(recoveredTemplateWarmers.entries().get(i).name(),  equalTo(templateWarmers.entries().get(i).name()));  assertThat(recoveredTemplateWarmers.entries().get(i).source(),  equalTo(templateWarmers.entries().get(i).source()));  }          DeleteWarmerResponse  deleteWarmerResponse  =  client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setName( "warmer_1 ").execute().actionGet();          DeleteWarmerResponse  deleteWarmerResponse  =  client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setNames( "warmer_1 ").execute().actionGet();  assertThat(deleteWarmerResponse.isAcknowledged(),  equalTo(true));  clusterState  =  client().admin().cluster().prepareState().execute().actionGet().getState();  warmersMetaData  =  clusterState.metaData().index( "test ").custom(IndexWarmersMetaData.TYPE);  assertThat(warmersMetaData,  Matchers.notNullValue());  assertThat(warmersMetaData.entries().size(),  equalTo(1));  	DeleteWarmerResponse  deleteWarmerResponse  =  client().admin().indices().prepareDeleteWarmer().setIndices( "test ").setNames( "warmer_1 ").execute().actionGet();  
elasticsearch_a005dc2c1f0886466c15b4f834d21cb63b9a669a	buggy:  threadPool.stats());  context:  }  return  new  NodeStats();  }  return  new  NodeStats(clusterService.state().nodes().localNode(),  monitorService.osService().stats(),  monitorService.processService().stats(),  monitorService.jvmService().stats(),  monitorService.networkService().stats(),                  threadPool.stats());                  threadPool.stats(),  transportService.stats());  }  return  false;  }  protected  static  class  NodeStatsRequest  extends  NodeOperationRequest  {  	threadPool.stats(),  transportService.stats());  
elasticsearch_1c93c8dfb817f0a60a0d556f8e4b4fa9b6771d17	buggy:  filter  =  new  TermFilter(new  Term(TypeFieldMapper.TERM_FACTORY.field(),  type));  context:  throw  new  QueryParsingException(parseContext.index(),   "[type]  filter  should  have  a  value  field,  and  the  type  name ");  }  BytesRef  type  =  parser.bytes();  parser.nextToken();  Filter  filter;  DocumentMapper  documentMapper  =  parseContext.mapperService().documentMapper(type.utf8ToString());  if  (documentMapper  ==  null)  {              filter  =  new  TermFilter(new  Term(TypeFieldMapper.TERM_FACTORY.field(),  type));              filter  =  new  TermFilter(new  Term(TypeFieldMapper.NAME,  type));  }  else  {  filter  =  documentMapper.typeFilter();  }  return  parseContext.cacheFilter(filter,  null);  }  }  	filter  =  new  TermFilter(new  Term(TypeFieldMapper.NAME,  type));  
elasticsearch_436e23b8d4fb5271263256cb163d8d59722f8d6b	buggy:  out.writeVLong(DfsSearchResult.makePositive(stats.totalTermFreq()));  context:  public  void  writeTo(final  StreamOutput  out)  throws  IOException  {  out.writeVInt(termStatistics.size());  for  (Map.Entry<Term,  TermStatistics>  termTermStatisticsEntry  :  termStatistics.entrySet())  {  Term  term  =  termTermStatisticsEntry.getKey();  out.writeString(term.field());  out.writeBytesRef(term.bytes());  TermStatistics  stats  =  termTermStatisticsEntry.getValue();  out.writeBytesRef(stats.term());  out.writeVLong(stats.docFreq());              out.writeVLong(DfsSearchResult.makePositive(stats.totalTermFreq()));              out.writeVLong(DfsSearchResult.plusOne(stats.totalTermFreq()));  }  DfsSearchResult.writeFieldStats(out,  fieldStatistics);  out.writeVLong(maxDoc);  }  }  	out.writeVLong(DfsSearchResult.plusOne(stats.totalTermFreq()));  
elasticsearch_e52dbf4fdaf148cfd45b92c8301fe3d6af468ec2	buggy:  long  ttl  =  -1;  context:  token  =  parser.nextToken();  assert  token  ==  XContentParser.Token.START_OBJECT;  String  index  =  null;  String  type  =  null;  String  id  =  null;  String  routing  =  null;  String  parent  =  null;  String  timestamp  =  null;              long  ttl  =  -1;              Long  ttl  =  null;  String  opType  =  null;  long  version  =  0;  VersionType  versionType  =  VersionType.INTERNAL;  String  percolate  =  null;  String  currentFieldName  =  null;  while  ((token  =  parser.nextToken())  !=  XContentParser.Token.END_OBJECT)  {  if  (token  ==  XContentParser.Token.FIELD_NAME)  {  	Long  ttl  =  null;  
elasticsearch_4271d573d60f39564c458e2d3fb7c14afb82d4d8	buggy:  return  new  QueueRecycler<byte[]>(RECYCLER_C);  context:  package  org.elasticsearch.common.recycler;  public  class  QueueRecyclerTests  extends  AbstractRecyclerTests  {  protected  Recycler<byte[]>  newRecycler()  {          return  new  QueueRecycler<byte[]>(RECYCLER_C);          return  new  QueueRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));  }  }  	return  new  QueueRecycler<byte[]>(RECYCLER_C,  randomIntBetween(5,  10));  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();  context:  InetAddress  hostAddressX;  try  {  hostAddressX  =  networkService.resolveBindHostAddress(host);  }  catch  (IOException  e)  {  return;  }  final  InetAddress  hostAddress  =  hostAddressX;  PortsRange  portsRange  =  new  PortsRange(port);          final  AtomicReference<Exception>  lastException  =  new  AtomicReference<Exception>();          final  AtomicReference<Exception>  lastException  =  new  AtomicReference<>();  boolean  success  =  portsRange.iterate(new  PortsRange.PortCallback()  {  public  boolean  onPortNumber(int  portNumber)  {  try  {  channel  =  bootstrap.bind(new  InetSocketAddress(hostAddress,  portNumber));  }  catch  (Exception  e)  {  lastException.set(e);  return  false;  	final  AtomicReference<Exception>  lastException  =  new  AtomicReference<>();  
elasticsearch_523a8b4c3e8003316f3e7c6a74bdd5e4e1818dd6	buggy:  mapperParser.putTypeParser(XContentAttachmentMapper.CONTENT_TYPE,  new  XContentAttachmentMapper.TypeParser());  context:  public  class  SimpleAttachmentMapperTests  {  private  XContentDocumentMapperParser  mapperParser;  mapperParser  =  new  XContentDocumentMapperParser(new  Index( "test "),  new  AnalysisService(new  Index( "test ")));          mapperParser.putTypeParser(XContentAttachmentMapper.CONTENT_TYPE,  new  XContentAttachmentMapper.TypeParser());          mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE,  new  AttachmentMapper.TypeParser());  }  String  mapping  =  copyToStringFromClasspath( "/org/elasticsearch/index/mapper/xcontent/test-mapping.json ");  XContentDocumentMapper  docMapper  =  mapperParser.parse(mapping);  byte[]  json  =  jsonBuilder().startObject().field( "_id ",  1).field( "file ",  copyToBytesFromClasspath( "/org/elasticsearch/index/mapper/xcontent/testXHTML.html ")).endObject().copiedBytes();  Document  doc  =  docMapper.parse(json).doc();  	mapperParser.putTypeParser(AttachmentMapper.CONTENT_TYPE,  new  AttachmentMapper.TypeParser());  
elasticsearch_d9ff42f88a93f1219b23e4a7861cfbf9bc7242c8	buggy:  request.index(state.metaData().concreteSingleIndex(request.index()));  context:  .getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  }  protected  void  resolveRequest(ClusterState  state,  GetRequest  request)  {  if  (request.realtime  ==  null)  {  request.realtime  =  this.realtime;  }  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  }  	request.index(state.metaData().concreteSingleIndex(request.index(),  request.indicesOptions()));  
elasticsearch_e44604b44174a6d2d91b6c65590668ef7e308ee0	buggy:  @Override  public  void  handleException(RemoteTransportException  exp)  {  context:  if  (!node.masterNode()  &&  !RiverNodeHelper.isRiverNode(node))  {  continue;  }  transportService.sendRequest(node,  PublishClusterStateRequestHandler.ACTION,  new  PublishClusterStateRequest(clusterState),  new  VoidTransportResponseHandler(false)  {                  @Override  public  void  handleException(RemoteTransportException  exp)  {                  @Override  public  void  handleException(TransportException  exp)  {  }  });  }  }  private  class  PublishClusterStateRequest  implements  Streamable  {  	@Override  public  void  handleException(TransportException  exp)  {  
elasticsearch_ebd95b7eb80cb89dfc4c9567a00cca715f4e999b	buggy:  lastTotalTranslogOperations  =  translogSnapshot.totalOperations();  context:  if  (lastIndexVersion  !=  snapshotIndexCommit.getVersion()  ||  lastTranslogId  !=  translogSnapshot.translogId()  ||  lastTranslogLength  <  translogSnapshot.length())  {  SnapshotStatus  snapshotStatus  =  shardGateway.snapshot(new  IndexShardGateway.Snapshot(snapshotIndexCommit,  translogSnapshot,  lastIndexVersion,  lastTranslogId,  lastTranslogLength,  lastTotalTranslogOperations));  lastIndexVersion  =  snapshotIndexCommit.getVersion();  lastTranslogId  =  translogSnapshot.translogId();  lastTranslogLength  =  translogSnapshot.length();                          lastTotalTranslogOperations  =  translogSnapshot.totalOperations();                          lastTotalTranslogOperations  =  translogSnapshot.estimatedTotalOperations();  return  snapshotStatus;  }  return  null;  }  });  if  (snapshotStatus  !=  null)  {  if  (logger.isDebugEnabled())  {  StringBuilder  sb  =  new  StringBuilder();  	lastTotalTranslogOperations  =  translogSnapshot.estimatedTotalOperations();  
libgdx_3dfecca10fb630321d028b8a51e5eb6fa14f2530	buggy:  cache.add(region,  col*unitsPerTileX,  ((layer.length  -  row))*unitsPerTileY,  (float)region.offsetX*unitsPerTileX/tileWidth,  -(float)(region.packedHeight  +  region.offsetY)*unitsPerTileY/tileHeight,  region.packedWidth,  region.packedHeight,  unitsPerTileX/tileWidth,  unitsPerTileY/tileHeight,  (region.rotate)?90:0);  context:  int  row,  col;  float  x,  y;  for  (row  =  firstRow;  row  <  lastRow  &&  row  <  layer.length;  row++)  {  for  (col  =  firstCol;  col  <  lastCol  &&  col  <  layer[row].length;  col++)  {  tile  =  layer[row][col];  if  (tile  !=  0)  {  if  (blended  ==  blendedTiles.contains(tile))  {  region  =  atlas.getRegion(tile);  if  (region  !=  null)  {  cache.add(region,  col*unitsPerTileX,  ((layer.length  -  row))*unitsPerTileY,  (float)region.offsetX*unitsPerTileX/tileWidth,  -(float)(region.packedHeight  +  region.offsetY)*unitsPerTileY/tileHeight,  region.packedWidth,  region.packedHeight,  unitsPerTileX/tileWidth,  unitsPerTileY/tileHeight,  (region.rotate)?90:0);  cache.add(region,  col*unitsPerTileX,  (layer.length  -  row  -  1)*unitsPerTileY,  (float)region.offsetX*unitsPerTileX/tileWidth,  -(float)(region.offsetY)*unitsPerTileY/tileHeight,  region.packedWidth,  region.packedHeight,  unitsPerTileX/tileWidth,  unitsPerTileY/tileHeight,  (region.rotate)?90:0);  }  }  }  }  }  return  cache.endCache();  }  	cache.add(region,  col*unitsPerTileX,  (layer.length  -  row  -  1)*unitsPerTileY,  (float)region.offsetX*unitsPerTileX/tileWidth,  -(float)(region.offsetY)*unitsPerTileY/tileHeight,  region.packedWidth,  region.packedHeight,  unitsPerTileX/tileWidth,  unitsPerTileY/tileHeight,  (region.rotate)?90:0);  
libgdx_21c209669e25d242d7386b0c1bf962af26d535aa	buggy:  logoSprite.getTextureRegion().flip(false,  true);  context:  pixS1  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/test4.png ",  Files.FileType.Internal));  pixS2  =  Gdx.graphics.newPixmap(Gdx.files.getFileHandle( "data/test3.png ",  Files.FileType.Internal));  pixD  =  Gdx.graphics.newPixmap(64,  128,  Pixmap.Format.RGBA8888);  pixD.drawPixmap(pixS1,  0,  0,  0,  0,  76,  76);  pixD.drawPixmap(pixS2,  0,  0,  0,  0,  76,  76);  logoSprite  =  new  Sprite(Gdx.graphics.newUnmanagedTexture(pixD,  TextureFilter.Nearest,  TextureFilter.Linear,  TextureWrap.ClampToEdge,  TextureWrap.ClampToEdge));  logoSprite.getTextureRegion().flip(false,  true);  logoSprite.getRegion().flip(false,  true);  }  GL10  gl  =  Gdx.graphics.getGL10();  gl.glClearColor(0,  1,  0,  1);  gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  	logoSprite.getRegion().flip(false,  true);  
elasticsearch_d9979f8dfeceb3ef31e38fa74f928514c17c44c7	buggy:  raf.decreaseRefCount();  context:  return  this.lastOperationRead;  }  this.position  +=  length;  }          raf.decreaseRefCount();          raf.decreaseRefCount(true);  return  true;  }  }  	raf.decreaseRefCount(true);  
elasticsearch_e551ec282faab265315fea299bbe04cfc8e640c9	buggy:  return  ClusterState.builder().state(currentState).metaData(mdBuilder).build();  context:  if  (warmers  !=  null)  {  for  (IndexWarmersMetaData.Entry  entry  :  warmers.entries())  {  if  (Regex.simpleMatch(request.name(),  entry.name()))  {  }  }  }  }  }                  return  ClusterState.builder().state(currentState).metaData(mdBuilder).build();                  return  ClusterState.builder(currentState).metaData(mdBuilder).build();  }  public  void  clusterStateProcessed(String  source,  ClusterState  oldState,  ClusterState  newState)  {  }  });  }  	return  ClusterState.builder(currentState).metaData(mdBuilder).build();  
libgdx_b20f05fbf3eb0a13d31026145e99ea8336540357	buggy:  vel.sub(pos).nor().mul(VELOCITY);  context:  this.bounds.width  =  0.6f;  this.bounds.height  =  0.6f;  this.vel.set(-VELOCITY,  0);  }  public  void  update  (float  deltaTime)  {  if  (state  ==  FLYING)  {  vel.set(map.bob.pos);  vel.sub(pos).nor().mul(VELOCITY);  vel.sub(pos).nor().scl(VELOCITY);  pos.add(vel.x  *  deltaTime,  vel.y  *  deltaTime);  bounds.x  =  pos.x  +  0.2f;  bounds.y  =  pos.y  +  0.2f;  if  (checkHit())  {  state  =  EXPLODING;  stateTime  =  0;  }  }  	vel.sub(pos).nor().scl(VELOCITY);  
libgdx_b5a1b187681215b53d045d90c3d78b4126e13790	buggy:  currTexture  =  hwMipMap.isChecked  ?  textureHW  :  textureSW;  context:  ui.addActor(table);  }  public  void  render  ()  {  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  Gdx.gl.glEnable(GL10.GL_TEXTURE_2D);  camera.update();  currTexture  =  hwMipMap.isChecked  ?  textureHW  :  textureSW;  currTexture  =  hwMipMap.isChecked()  ?  textureHW  :  textureSW;  currTexture.bind();  currTexture.setFilter(TextureFilter.valueOf(minFilter.getSelection()),  TextureFilter.valueOf(magFilter.getSelection()));  shader.begin();  shader.setUniformMatrix( "u_projTrans ",  camera.combined);  shader.setUniformi( "s_texture ",  0);  mesh.render(shader,  GL10.GL_TRIANGLE_FAN);  shader.end();  	currTexture  =  hwMipMap.isChecked()  ?  textureHW  :  textureSW;  
libgdx_f547e6d8e6bd1228f9aab01adc68fc51f1c0824e	buggy:  return  new  DisplayMode[0];  context:  return  false;  }  return  false;  }  return  new  DisplayMode[0];  return  new  DisplayMode[]  {  getDesktopDisplayMode()  };  }  return  false;  }  	return  new  DisplayMode[]  {  getDesktopDisplayMode()  };  
elasticsearch_f1dd867c4f574e457eeca91cd842179725f2e010	buggy:  }  catch  (Exception  e)  {  context:  request.listenerThreaded(false);  if  (request.operationThreading()  ==  SearchOperationThreading.NO_THREADS)  {  request.operationThreading(SearchOperationThreading.SINGLE_THREAD);  }  execute(request,  new  ActionListener<SearchResponse>()  {  public  void  onResponse(SearchResponse  result)  {  try  {  channel.sendResponse(result);                      }  catch  (Exception  e)  {                      }  catch  (Throwable  e)  {  onFailure(e);  }  }  public  void  onFailure(Throwable  e)  {  try  {  channel.sendResponse(e);  	}  catch  (Throwable  e)  {  
elasticsearch_7548b2edb782a2732aca5e9bae9016c6a01cb6e6	buggy:  request.index(state.metaData().concreteIndex(request.index()));  context:  .getShards(clusterService.state(),  request.index(),  request.type(),  request.id(),  request.routing(),  request.preference());  }  protected  void  resolveRequest(ClusterState  state,  GetRequest  request)  {  if  (request.realtime  ==  null)  {  request.realtime  =  this.realtime;  }  request.routing(state.metaData().resolveIndexRouting(request.routing(),  request.index()));          request.index(state.metaData().concreteIndex(request.index()));          request.index(state.metaData().concreteSingleIndex(request.index()));  if  (request.routing()  ==  null  &&  state.getMetaData().routingRequired(request.index(),  request.type()))  {  throw  new  RoutingMissingException(request.index(),  request.type(),  request.id());  }  }  	request.index(state.metaData().concreteSingleIndex(request.index()));  
elasticsearch_794a927c43711d1ce489c16ca3624d0bdbde2e3d	buggy:  Node  node  =  NodeBuilder.nodeBuilder().node();  context:  public  class  GeoDistanceSearchBenchmark  {  public  static  void  main(String[]  args)  throws  Exception  {          Node  node  =  NodeBuilder.nodeBuilder().node();          Node  node  =  NodeBuilder.nodeBuilder().clusterName(GeoDistanceSearchBenchmark.class.getSimpleName()).node();  Client  client  =  node.client();  ClusterHealthResponse  clusterHealthResponse  =  client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();  if  (clusterHealthResponse.isTimedOut())  {  System.err.println( "Failed  to  wait  for  green  status,  bailing ");  System.exit(1);  }  	Node  node  =  NodeBuilder.nodeBuilder().clusterName(GeoDistanceSearchBenchmark.class.getSimpleName()).node();  
elasticsearch_35233564fdc6d455f4492085c18038e76b1ae1b6	buggy:  HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray(),  false));  context:  HandlesStreamOutput  out  =  new  HandlesStreamOutput(bytesOut,  5);  String  lowerThresholdValue  =   "test ";  String  higherThresholdValue  =   "something  that  is  higher  than  5 ";  out.writeUTF(lowerThresholdValue);  out.writeUTF(higherThresholdValue);  out.writeInt(1);  out.writeUTF( "else ");  out.writeUTF(higherThresholdValue);  out.writeUTF(lowerThresholdValue);          HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.copiedByteArray(),  false));          HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.bytes().toBytes(),  false));  assertThat(in.readUTF(),  equalTo(lowerThresholdValue));  assertThat(in.readUTF(),  equalTo(higherThresholdValue));  assertThat(in.readInt(),  equalTo(1));  assertThat(in.readUTF(),  equalTo( "else "));  assertThat(in.readUTF(),  equalTo(higherThresholdValue));  assertThat(in.readUTF(),  equalTo(lowerThresholdValue));  }  }  	HandlesStreamInput  in  =  new  HandlesStreamInput(new  BytesStreamInput(bytesOut.bytes().toBytes(),  false));  
libgdx_a115dd10128240c0f8c7784b2153f2840948aedd	buggy:  font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  context:  handle.deleteDirectory();  }  private  void  fail  ()  {  throw  new  RuntimeException();  }  Gdx.gl.glClear(GL10.GL_COLOR_BUFFER_BIT);  batch.begin();  font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20,  Color.WHITE);  font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20);  batch.end();  }  return  false;  }  }  	font.drawMultiLine(batch,  message,  20,  Gdx.graphics.getHeight()  -  20);  
elasticsearch_1952df982b69873544c00470293ee851697abbf4	buggy:  ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);  context:  }  public  String  type()  {  return  InternalDateHistogram.TYPE.name();  }  public  AggregatorFactory  parse(String  aggregationName,  XContentParser  parser,  SearchContext  context)  throws  IOException  {          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<NumericValuesSource>(NumericValuesSource.class);          ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  String  field  =  null;  String  script  =  null;  String  scriptLang  =  null;  Map<String,  Object>  scriptParams  =  null;  boolean  keyed  =  false;  long  minDocCount  =  1;  ExtendedBounds  extendedBounds  =  null;  	ValuesSourceConfig<NumericValuesSource>  config  =  new  ValuesSourceConfig<>(NumericValuesSource.class);  
elasticsearch_270b109e655cf5165b3cccd51dcf0ab0920a0e8c	buggy:  return  new  ShardCountRequest(shard.index(),  shard.id(),  filteringAliases,  request);  context:  }  protected  ShardCountRequest  newShardRequest()  {  return  new  ShardCountRequest();  }  protected  ShardCountRequest  newShardRequest(int  numShards,  ShardRouting  shard,  CountRequest  request)  {  String[]  filteringAliases  =  clusterService.state().metaData().filteringAliases(shard.index(),  request.indices());          return  new  ShardCountRequest(shard.index(),  shard.id(),  filteringAliases,  request);          return  new  ShardCountRequest(shard.shardId(),  filteringAliases,  request);  }  protected  ShardCountResponse  newShardResponse()  {  return  new  ShardCountResponse();  }  	return  new  ShardCountRequest(shard.shardId(),  filteringAliases,  request);  
